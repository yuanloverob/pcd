{
  "cve_id": "CVE-2024-25115",
  "cve_desc": "RedisBloom adds a set of probabilistic data structures to Redis. Starting in version 2.0.0 and prior to version 2.4.7 and 2.6.10, specially crafted `CF.LOADCHUNK` commands may be used by authenticated users to perform heap overflow, which may lead to remote code execution. The problem is fixed in RedisBloom 2.4.7 and 2.6.10.\n",
  "repo": "RedisBloom/RedisBloom",
  "patch_hash": "2f3b38394515fc6c9b130679bcd2435a796a49ad",
  "patch_info": {
    "commit_hash": "2f3b38394515fc6c9b130679bcd2435a796a49ad",
    "repo": "RedisBloom/RedisBloom",
    "commit_url": "https://github.com/RedisBloom/RedisBloom/commit/2f3b38394515fc6c9b130679bcd2435a796a49ad",
    "files": [
      "src/cf.c",
      "src/rebloom.c",
      "tests/flow/test_cuckoo.py"
    ],
    "message": "MOD-6344 Fix potential crash for cf.scandump and cf.loadchunk (#726)\n\nAdd boundary checks for cf.scandump and cf.loadchunk\n\nCo-authored-by: Ozan Tezcan <ozantezcan@gmail.com>",
    "before_after_code_files": [
      "src/cf.c||src/cf.c",
      "src/rebloom.c||src/rebloom.c",
      "tests/flow/test_cuckoo.py||tests/flow/test_cuckoo.py"
    ]
  },
  "patch_diff": {
    "src/cf.c||src/cf.c": [
      "File: src/cf.c -> src/cf.c",
      "--- Hunk 1 ---",
      "[Context before]",
      "84: }",
      "86: int CF_LoadEncodedChunk(const CuckooFilter *cf, long long pos, const char *data, size_t datalen) {",
      "88:         return REDISMODULE_ERR;",
      "89:     }",
      "",
      "[Removed Lines]",
      "87:     if (datalen == 0) {",
      "",
      "[Added Lines]",
      "87:     if (datalen == 0 || pos <= 0 || (size_t)(pos - 1) < datalen) {",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "102:         offset -= currentSize;",
      "103:     }",
      "106:     memcpy(filter->data + offset, data, datalen);",
      "107:     return REDISMODULE_OK;",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "106:     if (!filter || ((size_t)offset > SIZE_MAX - datalen) ||",
      "107:         filter->bucketSize * filter->numBuckets < offset + datalen) {",
      "108:         return REDISMODULE_ERR;",
      "109:     }",
      "",
      "---------------"
    ],
    "src/rebloom.c||src/rebloom.c": [
      "File: src/rebloom.c -> src/rebloom.c",
      "--- Hunk 1 ---",
      "[Context before]",
      "850:     }",
      "852:     long long pos;",
      "854:         return RedisModule_ReplyWithError(ctx, \"Invalid position\");",
      "855:     }",
      "",
      "[Removed Lines]",
      "853:     if (RedisModule_StringToLongLong(argv[2], &pos) != REDISMODULE_OK) {",
      "",
      "[Added Lines]",
      "853:     if (RedisModule_StringToLongLong(argv[2], &pos) != REDISMODULE_OK || pos < 0) {",
      "",
      "---------------"
    ],
    "tests/flow/test_cuckoo.py||tests/flow/test_cuckoo.py": [
      "File: tests/flow/test_cuckoo.py -> tests/flow/test_cuckoo.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "454:         # check loaded filter",
      "455:         for x in range(6):",
      "456:             self.assertEqual(1, self.cmd('cf.exists', 'cf', 'foo'))",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "458:     def test_scandump_invalid(self):",
      "459:         self.cmd('FLUSHALL')",
      "460:         self.cmd('cf.reserve', 'cf', 4)",
      "461:         self.assertRaises(ResponseError, self.cmd, 'cf.loadchunk', 'cf', '-9223372036854775808', '1')",
      "462:         self.assertRaises(ResponseError, self.cmd, 'cf.loadchunk', 'cf', '922337203685477588', '1')",
      "463:         self.assertRaises(ResponseError, self.cmd, 'cf.loadchunk', 'cf', '4', 'kdoasdksaodsadsadsadsadsadadsadadsdad')",
      "464:         self.assertRaises(ResponseError, self.cmd, 'cf.loadchunk', 'cf', '4', 'abcd')",
      "465:         self.cmd('cf.add', 'cf', 'x')",
      "466:         self.assertRaises(ResponseError, self.cmd, 'cf.scandump', 'cf', '-1')",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "18ace682d6e00486dc346e4010b00ec186bb3c39",
      "candidate_info": {
        "commit_hash": "18ace682d6e00486dc346e4010b00ec186bb3c39",
        "repo": "RedisBloom/RedisBloom",
        "commit_url": "https://github.com/RedisBloom/RedisBloom/commit/18ace682d6e00486dc346e4010b00ec186bb3c39",
        "files": [
          ".github/workflows/ci-full.yml",
          ".install/mariner2.sh"
        ],
        "message": "change requirements to  build_package_requirements (#23)\n\n(cherry picked from commit 7d8eecafb1925ab5d4b1613e58cf6be6b4381d57)",
        "before_after_code_files": [
          ".install/mariner2.sh||.install/mariner2.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/RedisBloom/RedisBloom/pull/859"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        ".install/mariner2.sh||.install/mariner2.sh": [
          "File: .install/mariner2.sh -> .install/mariner2.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "6: pip install --upgrade setuptools",
          "7: pip install -r tests/flow/requirements.txt",
          "11: # Install aws-cli for uploading artifacts to s3",
          "12: curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"",
          "",
          "[Removed Lines]",
          "9: install -r .install/requirements.txt  # required for packing the module (todo: move to pack.sh after refactor)",
          "",
          "[Added Lines]",
          "9: install -r .install/build_package_requirements.txt  # required for packing the module (todo: move to pack.sh after refactor)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "c63842c218994020e84fb534a5a0492c01935bae",
      "candidate_info": {
        "commit_hash": "c63842c218994020e84fb534a5a0492c01935bae",
        "repo": "RedisBloom/RedisBloom",
        "commit_url": "https://github.com/RedisBloom/RedisBloom/commit/c63842c218994020e84fb534a5a0492c01935bae",
        "files": [
          "deps/bloom/bloom.c",
          "tests/flow/test_overall.py"
        ],
        "message": "Fix crash when error rate is very high (#720)\n\nCrash scenario:\n\n```\nBF.RESERVE b 0.99 3 NONSCALING\nBF.ADD b 1\n```\n\nIt seems like crash is only possible with NONSCALING filters with \na very high error rate and relatively small capacity. Creating filter \nwith these parameters does not make much sense but it can happen\nif wrong arguments are passed. \n\nWith the above parameters, we calculate number of required bits in \nthe filter as zero and it leads to crash later. \n\nTo fix the issue, we can limit minimum number of bits to 1.",
        "before_after_code_files": [
          "deps/bloom/bloom.c||deps/bloom/bloom.c",
          "tests/flow/test_overall.py||tests/flow/test_overall.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/RedisBloom/RedisBloom/pull/859"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "deps/bloom/bloom.c||deps/bloom/bloom.c": [
          "File: deps/bloom/bloom.c -> deps/bloom/bloom.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "150:     } else if (options & BLOOM_OPT_NOROUND) {",
          "153:         bloom->n2 = 0;",
          "155:     } else {",
          "",
          "[Removed Lines]",
          "152:         bits = bloom->bits = (uint64_t)(entries * bloom->bpe);",
          "",
          "[Added Lines]",
          "152:         bits = (uint64_t)(entries * bloom->bpe);",
          "155:         if (bits == 0) {",
          "156:             bits = 1;",
          "157:         }",
          "158:         bloom->bits = bits;",
          "",
          "---------------"
        ],
        "tests/flow/test_overall.py||tests/flow/test_overall.py": [
          "File: tests/flow/test_overall.py -> tests/flow/test_overall.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "426:         env.assertEqual(info[\"Capacity\"], 300000000)",
          "427:         env.assertEqual(info[\"Size\"], 1132420232)",
          "429: class testRedisBloomNoCodec():",
          "430:     def __init__(self):",
          "431:         self.env = Env(decodeResponses=False)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "429:     def test_very_high_error_rate(self):",
          "430:         env = self.env",
          "431:         env.cmd('FLUSHALL')",
          "433:         env.cmd('bf.reserve', 'bf1', 0.99, 3, \"NONSCALING\")",
          "434:         env.cmd('bf.add', 'bf1', 1)",
          "436:         env.cmd('bf.reserve', 'bf2', 0.95, 8, \"NONSCALING\")",
          "437:         env.cmd('bf.add', 'bf2', 1)",
          "439:         env.cmd('bf.reserve', 'bf3', 0.9999999999999999, 100, \"NONSCALING\")",
          "440:         env.cmd('bf.add', 'bf3', 1)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "c02d40caceeebc77bf1bca99b06b49f4d0f3deff",
      "candidate_info": {
        "commit_hash": "c02d40caceeebc77bf1bca99b06b49f4d0f3deff",
        "repo": "RedisBloom/RedisBloom",
        "commit_url": "https://github.com/RedisBloom/RedisBloom/commit/c02d40caceeebc77bf1bca99b06b49f4d0f3deff",
        "files": [
          "deps/bloom/bloom.c",
          "deps/bloom/bloom.h",
          "src/cf.c",
          "src/cuckoo.c",
          "src/cuckoo.h",
          "src/rebloom.c",
          "src/sb.c",
          "src/sb.h",
          "tests/flow/test_cuckoo.py",
          "tests/flow/test_overall.py"
        ],
        "message": "Add tests for bf and cf, fix findings (#745)\n\nAdded some extra tests for bf and cf\nAdded fixes/boundary checks to make related parts more robust",
        "before_after_code_files": [
          "deps/bloom/bloom.c||deps/bloom/bloom.c",
          "deps/bloom/bloom.h||deps/bloom/bloom.h",
          "src/cf.c||src/cf.c",
          "src/cuckoo.c||src/cuckoo.c",
          "src/cuckoo.h||src/cuckoo.h",
          "src/rebloom.c||src/rebloom.c",
          "src/sb.c||src/sb.c",
          "src/sb.h||src/sb.h",
          "tests/flow/test_cuckoo.py||tests/flow/test_cuckoo.py",
          "tests/flow/test_overall.py||tests/flow/test_overall.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/RedisBloom/RedisBloom/pull/859"
        ],
        "olp_code_files": {
          "patch": [
            "src/cf.c||src/cf.c",
            "src/rebloom.c||src/rebloom.c",
            "tests/flow/test_cuckoo.py||tests/flow/test_cuckoo.py"
          ],
          "candidate": [
            "src/cf.c||src/cf.c",
            "src/rebloom.c||src/rebloom.c",
            "tests/flow/test_cuckoo.py||tests/flow/test_cuckoo.py"
          ]
        }
      },
      "candidate_diff": {
        "deps/bloom/bloom.c||deps/bloom/bloom.c": [
          "File: deps/bloom/bloom.c -> deps/bloom/bloom.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "42: #define MODE_READ 0",
          "43: #define MODE_WRITE 1",
          "45: inline static int test_bit_set_bit(unsigned char *buf, uint64_t x, int mode) {",
          "46:     uint64_t byte = x >> 3;",
          "47:     uint8_t mask = 1 << (x % 8);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "45: #define LN2 (0.693147180559945)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "176:     bloom->bits = bloom->bytes * 8;",
          "178:     bloom->force64 = (options & BLOOM_OPT_FORCE64);",
          "180:     bloom->bf = (unsigned char *)BLOOM_CALLOC(bloom->bytes, sizeof(unsigned char));",
          "181:     if (bloom->bf == NULL) {",
          "182:         return 1;",
          "",
          "[Removed Lines]",
          "179:     bloom->hashes = (int)ceil(0.693147180559945 * bloom->bpe); // ln(2)",
          "",
          "[Added Lines]",
          "181:     bloom->hashes = (int)ceil(LN2 * bloom->bpe); // ln(2)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "220: void bloom_free(struct bloom *bloom) { BLOOM_FREE(bloom->bf); }",
          "222: const char *bloom_version() { return MAKESTRING(BLOOM_VERSION); }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "227: int bloom_validate_integrity(struct bloom *bloom) {",
          "228:     if (bloom->error <= 0 || bloom->error >= 1.0 ||",
          "229:         (bloom->n2 != 0 && bloom->bits < (1ULL << bloom->n2)) ||",
          "230:         bloom->bits == 0 || bloom->bits != bloom->bytes * 8 ||",
          "231:         bloom->hashes != (int)ceil(LN2 * bloom->bpe)) {",
          "232:         return 1;",
          "233:     }",
          "235:     return 0;",
          "236: }",
          "",
          "---------------"
        ],
        "deps/bloom/bloom.h||deps/bloom/bloom.h": [
          "File: deps/bloom/bloom.h -> deps/bloom/bloom.h",
          "--- Hunk 1 ---",
          "[Context before]",
          "161: const char *bloom_version();",
          "163: #ifdef __cplusplus",
          "164: }",
          "165: #endif",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "168: int bloom_validate_integrity(struct bloom *bloom);",
          "",
          "---------------"
        ],
        "src/cf.c||src/cf.c": [
          "File: src/cf.c -> src/cf.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "122:     filter->bucketSize = header->bucketSize;",
          "123:     filter->maxIterations = header->maxIterations;",
          "124:     filter->expansion = header->expansion;",
          "126:     for (size_t ii = 0; ii < filter->numFilters; ++ii) {",
          "127:         SubCF *cur = filter->filters + ii;",
          "128:         cur->bucketSize = header->bucketSize;",
          "",
          "[Removed Lines]",
          "125:     filter->filters = RedisModule_Alloc(sizeof(*filter->filters) * header->numFilters);",
          "",
          "[Added Lines]",
          "125:     filter->filters = RedisModule_Calloc(sizeof(*filter->filters), filter->numFilters);",
          "127:     if (CuckooFilter_ValidateIntegrity(filter) != 0) {",
          "128:         goto error;",
          "129:     }",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "131:             RedisModule_Calloc((size_t)cur->numBuckets * filter->bucketSize, sizeof(CuckooBucket));",
          "132:     }",
          "133:     return filter;",
          "134: }",
          "136: void fillCFHeader(CFHeader *header, const CuckooFilter *cf) {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "140: error:",
          "141:     CuckooFilter_Free(filter);",
          "142:     RedisModule_Free(filter);",
          "143:     return NULL;",
          "",
          "---------------"
        ],
        "src/cuckoo.c||src/cuckoo.c": [
          "File: src/cuckoo.c -> src/cuckoo.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "397:     assert(getAltHash(params.fp, out->h1, cf->numBuckets) == out->h2);",
          "398:     assert(getAltHash(params.fp, out->h2, cf->numBuckets) == out->h1);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "402: int CuckooFilter_ValidateIntegrity(const CuckooFilter *cf) {",
          "403:     if (cf->bucketSize == 0 || cf->bucketSize > CF_MAX_BUCKET_SIZE ||",
          "404:         cf->numBuckets == 0 || cf->numBuckets > CF_MAX_NUM_BUCKETS ||",
          "405:         cf->numFilters == 0 || cf->numFilters > CF_MAX_NUM_FILTERS ||",
          "406:         cf->maxIterations == 0 || !isPower2(cf->numBuckets) ) {",
          "407:         return 1;",
          "408:     }",
          "410:     return 0;",
          "411: }",
          "",
          "---------------"
        ],
        "src/cuckoo.h||src/cuckoo.h": [
          "File: src/cuckoo.h -> src/cuckoo.h",
          "--- Hunk 1 ---",
          "[Context before]",
          "24: typedef uint8_t CuckooBucket[1];",
          "25: typedef uint8_t MyCuckooBucket;",
          "27: typedef struct {",
          "28:     uint64_t numBuckets : 56;",
          "29:     uint64_t bucketSize : 8;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "27: #define CF_DEFAULT_MAX_ITERATIONS 20",
          "28: #define CF_DEFAULT_BUCKETSIZE 2",
          "29: #define CF_DEFAULT_EXPANSION 1",
          "30: #define CF_MAX_EXPANSION 32768",
          "31: #define CF_MAX_ITERATIONS 65535",
          "32: #define CF_MAX_BUCKET_SIZE 255                     // 8 bits, see struct SubCF",
          "33: #define CF_MAX_NUM_BUCKETS (0x00FFFFFFFFFFFFFFULL) // 56 bits, see struct SubCF",
          "34: #define CF_MAX_NUM_FILTERS (UINT16_MAX)            // 16 bits, see struct CuckooFilter",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "72: uint64_t CuckooFilter_Count(const CuckooFilter *filter, CuckooHash);",
          "73: void CuckooFilter_Compact(CuckooFilter *filter, bool cont);",
          "74: void CuckooFilter_GetInfo(const CuckooFilter *cf, CuckooHash hash, CuckooKey *out);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "84: int CuckooFilter_ValidateIntegrity(const CuckooFilter *cf);",
          "",
          "---------------"
        ],
        "src/rebloom.c||src/rebloom.c": [
          "File: src/rebloom.c -> src/rebloom.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "24: #define REDISBLOOM_GIT_SHA \"unknown\"",
          "25: #endif",
          "33: #define BF_DEFAULT_EXPANSION 2",
          "",
          "[Removed Lines]",
          "27: #define CF_DEFAULT_MAX_ITERATIONS 20",
          "28: #define CF_DEFAULT_BUCKETSIZE 2",
          "29: #define CF_DEFAULT_EXPANSION 1",
          "30: #define CF_MAX_EXPANSION 32768",
          "31: #define CF_MAX_BUCKET_SIZE 255",
          "32: #define CF_MAX_ITERATIONS 65535",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "src/sb.c||src/sb.c": [
          "File: src/sb.c -> src/sb.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "26: #define CUR_FILTER(sb) ((sb)->filters + ((sb)->nfilters - 1))",
          "28: static int SBChain_AddLink(SBChain *chain, uint64_t size, double error_rate) {",
          "36:     SBLink *newlink = chain->filters + chain->nfilters;",
          "38:     chain->nfilters++;",
          "39:     return bloom_init(&newlink->inner, size, error_rate, chain->options);",
          "40: }",
          "",
          "[Removed Lines]",
          "29:     if (!chain->filters) {",
          "30:         chain->filters = RedisModule_Calloc(1, sizeof(*chain->filters));",
          "31:     } else {",
          "32:         chain->filters =",
          "33:             RedisModule_Realloc(chain->filters, sizeof(*chain->filters) * (chain->nfilters + 1));",
          "34:     }",
          "37:     newlink->size = 0;",
          "",
          "[Added Lines]",
          "29:     chain->filters =",
          "30:         RedisModule_Realloc(chain->filters, sizeof(*chain->filters) * (chain->nfilters + 1));",
          "34:         .size = 0,",
          "35:     };",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "150: } dumpedChainHeader;",
          "152: static SBLink *getLinkPos(const SBChain *sb, long long curIter, size_t *offset) {",
          "155:     curIter--;",
          "156:     SBLink *link = NULL;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "152:     if (curIter < 1) {",
          "153:         return NULL;",
          "154:     }",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "219: void SB_FreeEncodedHeader(char *s) { RedisModule_Free(s); }",
          "221: SBChain *SB_NewChainFromHeader(const char *buf, size_t bufLen, const char **errmsg) {",
          "222:     const dumpedChainHeader *header = (const void *)buf;",
          "223:     if (bufLen < sizeof(dumpedChainHeader)) {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "223: int SB_ValidateIntegrity(const SBChain *sb) {",
          "224:     if (sb->options &",
          "225:         ~(BLOOM_OPT_NOROUND | BLOOM_OPT_ENTS_IS_BITS | BLOOM_OPT_FORCE64 | BLOOM_OPT_NO_SCALING)) {",
          "226:         return 1;",
          "227:     }",
          "229:     size_t total = 0;",
          "230:     for (size_t i = 0; i < sb->nfilters; i++) {",
          "231:         if (sb->filters[i].size > SIZE_MAX - total) {",
          "232:             return 1;",
          "233:         }",
          "234:         total += sb->filters[i].size;",
          "235:     }",
          "237:     if (sb->size != total) {",
          "238:         return 1;",
          "239:     }",
          "241:     return 0;",
          "242: }",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "243: #define X(encfld, dstfld) dstfld = encfld;",
          "244:         X_ENCODED_LINK(X, srclink, dstlink)",
          "245: #undef X",
          "247:         if (sb->options & BLOOM_OPT_FORCE64) {",
          "248:             dstlink->inner.force64 = 1;",
          "249:         }",
          "250:     }",
          "252:     return sb;",
          "253: }",
          "255: int SBChain_LoadEncodedChunk(SBChain *sb, long long iter, const char *buf, size_t bufLen,",
          "256:                              const char **errmsg) {",
          "258:     size_t offset;",
          "259:     iter -= bufLen;",
          "",
          "[Removed Lines]",
          "246:         dstlink->inner.bf = RedisModule_Alloc(dstlink->inner.bytes);",
          "",
          "[Added Lines]",
          "270:         if (bloom_validate_integrity(&dstlink->inner) != 0) {",
          "271:             SBChain_Free(sb);",
          "273:             return NULL;",
          "274:         }",
          "276:         dstlink->inner.bf = RedisModule_Calloc(1, dstlink->inner.bytes);",
          "282:     if (SB_ValidateIntegrity(sb) != 0) {",
          "283:         SBChain_Free(sb);",
          "285:         return NULL;",
          "286:     }",
          "293:     if (!buf || iter <= 0 || iter < bufLen) {",
          "295:         return -1;",
          "296:     }",
          "",
          "---------------"
        ],
        "src/sb.h||src/sb.h": [
          "File: src/sb.h -> src/sb.h",
          "--- Hunk 1 ---",
          "[Context before]",
          "105: int SBChain_LoadEncodedChunk(SBChain *sb, long long iter, const char *buf, size_t bufLen,",
          "106:                              const char **errmsg);",
          "107: #ifdef __cplusplus",
          "108: }",
          "109: #endif",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "108: int SB_ValidateIntegrity(const SBChain *sb);",
          "",
          "---------------"
        ],
        "tests/flow/test_cuckoo.py||tests/flow/test_cuckoo.py": [
          "File: tests/flow/test_cuckoo.py -> tests/flow/test_cuckoo.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "2: from common import *",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: import random",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "468:         for x in range(6):",
          "469:             self.assertEqual(1, self.cmd('cf.exists', 'cf', 'foo'))",
          "471:     def test_scandump_invalid(self):",
          "472:         self.cmd('FLUSHALL')",
          "473:         self.cmd('cf.reserve', 'cf', 4)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "472:     def test_scandump_with_content(self):",
          "473:         # Basic success scenario with content validation",
          "475:         self.cmd('FLUSHALL')",
          "476:         self.cmd('cf.reserve', 'cf', 1024 * 1024 * 64)",
          "478:         for x in range(1000):",
          "479:             self.cmd('cf.add', 'cf', 'foo' + str(x))",
          "480:         for x in range(1000):",
          "481:             self.assertEqual(1, self.cmd('cf.exists', 'cf', 'foo' + str(x)))",
          "483:         chunks = []",
          "484:         while True:",
          "485:             last_pos = chunks[-1][0] if chunks else 0",
          "486:             chunk = self.cmd('cf.scandump', 'cf', last_pos)",
          "487:             if not chunk[0]:",
          "488:                 break",
          "489:             chunks.append(chunk)",
          "491:         for chunk in chunks:",
          "492:             self.cmd('cf.loadchunk', 'cf2', *chunk)",
          "494:         # check loaded filter",
          "495:         for x in range(1000):",
          "496:             self.assertEqual(1, self.cmd('cf.exists', 'cf2', 'foo' + str(x)))",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "477:         self.assertRaises(ResponseError, self.cmd, 'cf.loadchunk', 'cf', '4', 'abcd')",
          "478:         self.cmd('cf.add', 'cf', 'x')",
          "479:         self.assertRaises(ResponseError, self.cmd, 'cf.scandump', 'cf', '-1')",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "510:     def test_scandump_invalid_header(self):",
          "511:         env = self.env",
          "512:         env.cmd('FLUSHALL')",
          "514:         env.cmd('cf.reserve', 'cf', 100)",
          "515:         for x in range(50):",
          "516:             env.cmd('cf.add', 'cf', 'foo' + str(x))",
          "518:         chunk = env.cmd('cf.scandump', 'cf', 0)",
          "519:         env.cmd('del', 'cf')",
          "521:         arr = bytearray(chunk[1])",
          "523:         # It corrupts first 8 bytes in the response. See struct CFHeader",
          "524:         # for internals.",
          "525:         for i in range(9):",
          "526:             arr[i] = 0",
          "528:         thrown = None",
          "529:         try:",
          "530:             env.cmd('cf.loadchunk', 'cf', 1, bytes(arr))",
          "531:         except Exception as e:",
          "532:             thrown = e",
          "534:         if thrown is None or str(thrown) != \"Couldn't create filter!\":",
          "535:             print(\"Exception was: \" + str(thrown))",
          "536:             assert False",
          "539:     def test_scandump_random_scan_small(self):",
          "540:         self.cmd('FLUSHALL')",
          "541:         self.cmd('cf.reserve', 'cf', 50)",
          "543:         for i in range(0, 10000):",
          "544:             try:",
          "545:                 self.cmd('cf.add', 'cf', 'x' + str(i))",
          "546:             except ResponseError as e:",
          "547:                 if str(e) == \"Maximum expansions reached\":",
          "548:                     break",
          "549:                 raise e",
          "551:         info = self.cmd('CF.INFO', 'cf')",
          "552:         size = info[info.index(b'Size') + 1]",
          "554:         for i in range(0, size + 1024):",
          "555:             self.cmd('cf.scandump', 'cf', i)",
          "558:     def test_scandump_scan_big(self):",
          "559:         self.cmd('FLUSHALL')",
          "560:         self.cmd('cf.reserve', 'cf', 1024, 'EXPANSION', 30000)",
          "562:         for i in range(0, 100):",
          "563:             arr = []",
          "564:             for j in range(0, 10000):",
          "565:                 arr.append('x' + str(i) + str(j))",
          "567:             try:",
          "568:                 self.cmd('cf.insert', 'cf', 'ITEMS', *arr)",
          "569:             except ResponseError as e:",
          "570:                 if str(e) == \"Maximum expansions reached\":",
          "571:                     break",
          "572:                 raise e",
          "574:         info = self.cmd('CF.INFO', 'cf')",
          "575:         size = info[info.index(b'Size') + 1]",
          "577:         for i in range(0, 100):",
          "578:             self.cmd('cf.scandump', 'cf', random.randint(0, size * 2))",
          "581:     def test_scandump_load_small(self):",
          "582:         self.cmd('FLUSHALL')",
          "583:         self.cmd('cf.reserve', 'cf', 10)",
          "585:         for i in range(0, 100):",
          "586:             arr = []",
          "587:             for j in range(0, 1000):",
          "588:                 arr.append('x' + str(i) + str(j))",
          "590:             try:",
          "591:                 self.cmd('cf.insert', 'cf', 'ITEMS', *arr)",
          "592:             except ResponseError as e:",
          "593:                 if str(e) == \"Maximum expansions reached\":",
          "594:                     break",
          "595:                 raise e",
          "597:         info = self.cmd('CF.INFO', 'cf')",
          "598:         size = info[info.index(b'Size') + 1]",
          "600:         for i in range (0, size + 100):",
          "601:             b = bytearray(os.urandom(random.randint(0, 100)))",
          "602:             try:",
          "603:                 self.cmd('cf.loadchunk', 'cf', random.randint(0, 10000), bytes(b))",
          "604:             except Exception as e:",
          "605:                 if (str(e) != \"Couldn't load chunk!\" and",
          "606:                         str(e) != \"Invalid position\" and",
          "607:                         str(e) != \"item exists\"):",
          "608:                     raise e",
          "611:     def test_scandump_load_big(self):",
          "612:         self.cmd('FLUSHALL')",
          "613:         self.cmd('cf.reserve', 'cf', 1024, 'EXPANSION', 30000)",
          "615:         for i in range(0, 100):",
          "616:             arr = []",
          "617:             for j in range(0, 1000):",
          "618:                 arr.append('x' + str(i) + str(j))",
          "620:             try:",
          "621:                 self.cmd('cf.insert', 'cf', 'ITEMS', *arr)",
          "622:             except ResponseError as e:",
          "623:                 if str(e) == \"Maximum expansions reached\":",
          "624:                     break",
          "625:                 raise e",
          "627:         info = self.cmd('CF.INFO', 'cf')",
          "628:         size = info[info.index(b'Size') + 1]",
          "630:         for i in range (0, 100):",
          "631:             b = bytearray(os.urandom(random.randint(1024, 36 * 1024 * 1024)))",
          "632:             try:",
          "633:                 self.cmd('cf.loadchunk', 'cf', random.randint(2, size), bytes(b))",
          "634:             except Exception as e:",
          "635:                 if str(e) != \"Couldn't load chunk!\":",
          "636:                     raise e",
          "",
          "---------------"
        ],
        "tests/flow/test_overall.py||tests/flow/test_overall.py": [
          "File: tests/flow/test_overall.py -> tests/flow/test_overall.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "2: from common import *",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: import random",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "521:         # check loaded filter",
          "522:         for x in range(6):",
          "523:             env.assertEqual(1, env.cmd('bf.exists', 'bf', 'foo'))",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "527:     def test_scandump_with_content(self):",
          "528:         # Basic success scenario with content validation",
          "530:         env = self.env",
          "531:         env.cmd('FLUSHALL')",
          "533:         env.cmd('bf.reserve', 'bf', 0.01, 1024 * 1024 * 64)",
          "534:         for x in range(1000):",
          "535:             env.cmd('bf.add', 'bf', 'foo' + str(x))",
          "536:         for x in range(1000):",
          "537:             env.assertEqual(1, env.cmd('bf.exists', 'bf', 'foo' + str(x)))",
          "539:         chunks = []",
          "540:         while True:",
          "541:             last_pos = chunks[-1][0] if chunks else 0",
          "542:             chunk = env.cmd('bf.scandump', 'bf', last_pos)",
          "543:             if not chunk[0]:",
          "544:                 break",
          "545:             chunks.append(chunk)",
          "547:         env.cmd('del', 'bf')",
          "549:         for chunk in chunks:",
          "550:             env.cmd('bf.loadchunk', 'bf2', *chunk)",
          "552:         # Validate items in the loaded filter",
          "553:         for x in range(1000):",
          "554:             env.assertEqual(1, env.cmd('bf.exists', 'bf2', 'foo' + str(x)))",
          "557:     def test_scandump_invalid(self):",
          "558:         env = self.env",
          "559:         env.cmd('FLUSHALL')",
          "560:         env.cmd('bf.reserve', 'bf', 0.1, 4)",
          "561:         env.assertRaises(ResponseError, env.cmd, 'bf.loadchunk', 'bf', '-9223372036854775808', '1')",
          "562:         env.assertRaises(ResponseError, env.cmd, 'bf.loadchunk', 'bf', '922337203685477588', '1')",
          "563:         env.assertRaises(ResponseError, env.cmd, 'bf.loadchunk', 'bf', '4', 'kdoasdksaodsadsadsadsadsadadsadadsdad')",
          "564:         env.assertRaises(ResponseError, env.cmd, 'bf.loadchunk', 'bf', '4', 'abcd')",
          "565:         env.cmd('bf.add', 'bf', 'x')",
          "566:         env.cmd('bf.add', 'bf', 'y')",
          "569:     def test_scandump_invalid_header(self):",
          "570:         env = self.env",
          "571:         env.cmd('FLUSHALL')",
          "573:         env.cmd('bf.reserve', 'bf', 0.01, 5)",
          "574:         for x in range(50):",
          "575:             env.cmd('bf.add', 'bf', 'foo' + str(x))",
          "577:         chunk = env.cmd('bf.scandump', 'bf', 0)",
          "579:         env.cmd('del', 'bf')",
          "580:         arr = bytearray(chunk[1])",
          "582:         # See 'struct dumpedChainHeader' for internals.",
          "583:         # It corrupts second link in the response.",
          "584:         for i in range(8):",
          "585:             arr[72 + i] = 0",
          "587:         thrown = None",
          "588:         try:",
          "589:             env.cmd('bf.loadchunk', 'bf', 1, bytes(arr))",
          "590:         except Exception as e:",
          "591:             thrown = e",
          "593:         if thrown is None or str(thrown) != \"received bad data\":",
          "594:             raise thrown",
          "596:         # It corrupts 'options' field in the response.",
          "597:         arr = bytearray(chunk[1])",
          "598:         for i in range(4):",
          "599:             arr[12 + i] = 255",
          "601:         thrown = None",
          "602:         try:",
          "603:             env.cmd('bf.loadchunk', 'bf', 1, bytes(arr))",
          "604:         except Exception as e:",
          "605:             thrown = e",
          "607:         if thrown is None or str(thrown) != \"received bad data\":",
          "608:             raise thrown",
          "610:         # It corrupts first field in the response.",
          "611:         arr = bytearray(chunk[1])",
          "612:         for i in range(4):",
          "613:             arr[i] = 255",
          "615:         thrown = None",
          "616:         try:",
          "617:             env.cmd('bf.loadchunk', 'bf', 1, bytes(arr))",
          "618:         except Exception as e:",
          "619:             thrown = e",
          "621:         if thrown is None or str(thrown) != \"received bad data\":",
          "622:             raise thrown",
          "624:         # It corrupts second link in the response.",
          "625:         arr = bytearray(chunk[1])",
          "626:         for i in range(8):",
          "627:             arr[36 + i] = 255",
          "628:             arr[0 + i] = 255",
          "630:         thrown = None",
          "631:         try:",
          "632:             env.cmd('bf.loadchunk', 'bf', 1, bytes(arr))",
          "633:         except Exception as e:",
          "634:             thrown = e",
          "636:         if thrown is None or str(thrown) != \"received bad data\":",
          "637:             raise thrown",
          "640:     def test_scandump_scan_small(self):",
          "641:         env = self.env",
          "642:         env.cmd('FLUSHALL')",
          "643:         env.cmd('bf.reserve', 'bf', 0.1, 50)",
          "645:         for i in range(0, 1500):",
          "646:             try:",
          "647:                 env.cmd('bf.add', 'bf', 'x' + str(i))",
          "648:             except ResponseError as e:",
          "649:                 if str(e) == \"Maximum expansions reached\":",
          "650:                     break",
          "651:                 raise e",
          "653:         info = env.cmd('BF.INFO', 'bf')",
          "654:         size = info[info.index(b'Size') + 1]",
          "656:         # Verify random scandump does not cause any problem",
          "657:         for i in range(0, size + 1024):",
          "658:             env.cmd('bf.scandump', 'bf', i)",
          "661:     def test_scandump_scan_big(self):",
          "662:         env = self.env",
          "663:         env.cmd('FLUSHALL')",
          "664:         env.cmd('bf.reserve', 'bf', 0.001, 1024, 'EXPANSION', 30000)",
          "666:         for i in range(0, 100):",
          "667:             arr = []",
          "668:             for j in range(0, 10000):",
          "669:                 arr.append('x' + str(i) + str(j))",
          "671:             try:",
          "672:                 env.cmd('bf.insert', 'bf', 'ITEMS', *arr)",
          "673:             except ResponseError as e:",
          "674:                 if str(e) == \"Maximum expansions reached\":",
          "675:                     break",
          "676:                 raise e",
          "678:         info = env.cmd('bf.INFO', 'bf')",
          "679:         size = info[info.index(b'Size') + 1]",
          "681:         # Verify random scandump does not cause any problem",
          "682:         for i in range(0, 100):",
          "683:             env.cmd('bf.scandump', 'bf', random.randint(0, size * 2))",
          "686:     def test_scandump_load_small(self):",
          "687:         env = self.env",
          "688:         env.cmd('FLUSHALL')",
          "689:         env.cmd('bf.reserve', 'bf', 0.01, 10)",
          "691:         for i in range(0, 100):",
          "692:             arr = []",
          "693:             for j in range(0, 1000):",
          "694:                 arr.append('x' + str(i) + str(j))",
          "696:             try:",
          "697:                 env.cmd('bf.insert', 'bf', 'ITEMS', *arr)",
          "698:             except ResponseError as e:",
          "699:                 if str(e) == \"Maximum expansions reached\":",
          "700:                     break",
          "701:                 raise e",
          "703:         info = env.cmd('BF.INFO', 'bf')",
          "704:         size = info[info.index(b'Size') + 1]",
          "706:         # Try loading chunks with random size and content",
          "707:         for i in range (0, 100):",
          "708:             b = bytearray(os.urandom(random.randint(0, 4096)))",
          "709:             try:",
          "710:                 env.cmd('bf.loadchunk', 'bf', random.randint(0, size * 2), bytes(b))",
          "711:             except Exception as e:",
          "712:                 if (str(e) != \"invalid offset - no link found\" and",
          "713:                         str(e) != \"invalid chunk - Too big for current filter\" and",
          "714:                         str(e) != \"received bad data\"):",
          "715:                     raise e",
          "718:     def test_scandump_load_big(self):",
          "719:         env = self.env",
          "720:         env.cmd('FLUSHALL')",
          "721:         env.cmd('bf.reserve', 'bf', 0.01, 1024, 'EXPANSION', 30000)",
          "723:         for i in range(0, 100):",
          "724:             arr = []",
          "725:             for j in range(0, 1000):",
          "726:                 arr.append('x' + str(i) + str(j))",
          "728:             try:",
          "729:                 env.cmd('bf.insert', 'bf', 'ITEMS', *arr)",
          "730:             except ResponseError as e:",
          "731:                 if str(e) == \"Maximum expansions reached\":",
          "732:                     break",
          "733:                 raise e",
          "735:         info = env.cmd('BF.INFO', 'bf')",
          "736:         size = info[info.index(b'Size') + 1]",
          "738:         # Try loading chunks with random size and content",
          "739:         for i in range (0, 100):",
          "740:             b = bytearray(os.urandom(random.randint(1024, 36 * 1024 * 1024)))",
          "741:             try:",
          "742:                 env.cmd('bf.loadchunk', 'bf', random.randint(0, size), bytes(b))",
          "743:             except Exception as e:",
          "744:                 if (str(e) != \"invalid offset - no link found\" and",
          "745:                         str(e) != \"received bad data\"):",
          "746:                     raise e",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "9813bff95ff73684e6df4138dea38f652e9fc68d",
      "candidate_info": {
        "commit_hash": "9813bff95ff73684e6df4138dea38f652e9fc68d",
        "repo": "RedisBloom/RedisBloom",
        "commit_url": "https://github.com/RedisBloom/RedisBloom/commit/9813bff95ff73684e6df4138dea38f652e9fc68d",
        "files": [
          "src/version.h"
        ],
        "message": "Bump version v2.6.16, see MOD-8318 (#836)",
        "before_after_code_files": [
          "src/version.h||src/version.h"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/RedisBloom/RedisBloom/pull/859"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "src/version.h||src/version.h": [
          "File: src/version.h -> src/version.h",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: #endif",
          "19: #ifndef REBLOOM_VERSION_PATCH",
          "21: #endif",
          "23: #define REBLOOM_MODULE_VERSION                                                                     \\",
          "",
          "[Removed Lines]",
          "20: #define REBLOOM_VERSION_PATCH 15",
          "",
          "[Added Lines]",
          "20: #define REBLOOM_VERSION_PATCH 16",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "d3fcd0536fbedecf4172755233e9c823b1ac58e8",
      "candidate_info": {
        "commit_hash": "d3fcd0536fbedecf4172755233e9c823b1ac58e8",
        "repo": "RedisBloom/RedisBloom",
        "commit_url": "https://github.com/RedisBloom/RedisBloom/commit/d3fcd0536fbedecf4172755233e9c823b1ac58e8",
        "files": [
          ".github/workflows/ci-full.yml",
          ".install/build_package_requirements.txt",
          ".install/mariner2.sh"
        ],
        "message": "pin ramp-packer to 2.5.10 (#20)\n\n(cherry picked from commit c42fd3d31bdf1a8be45038079dedf46095b6e152)",
        "before_after_code_files": [
          ".install/mariner2.sh||.install/mariner2.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/RedisBloom/RedisBloom/pull/859"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        ".install/mariner2.sh||.install/mariner2.sh": [
          "File: .install/mariner2.sh -> .install/mariner2.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "6: pip install --upgrade setuptools",
          "7: pip install -r tests/flow/requirements.txt",
          "11: # Install aws-cli for uploading artifacts to s3",
          "12: curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"",
          "",
          "[Removed Lines]",
          "9: pip install jinja2 ramp-packer  # required for packing the module (todo: move to pack.sh after refactor)",
          "",
          "[Added Lines]",
          "9: install -r .install/requirements.txt  # required for packing the module (todo: move to pack.sh after refactor)",
          "",
          "---------------"
        ]
      }
    }
  ]
}