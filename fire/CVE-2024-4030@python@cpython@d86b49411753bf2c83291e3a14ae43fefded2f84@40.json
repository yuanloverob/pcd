{
  "cve_id": "CVE-2024-4030",
  "cve_desc": "On Windows a directory returned by tempfile.mkdtemp() would not always have permissions set to restrict reading and writing to the temporary directory by other users, instead usually inheriting the correct permissions from the default location. Alternate configurations or users without a profile directory may not have the intended permissions.\n\nIf you\u2019re not using Windows or haven\u2019t changed the temporary directory location then you aren\u2019t affected by this vulnerability. On other platforms the returned directory is consistently readable and writable only by the current user.\n\nThis issue was caused by Python not supporting Unix permissions on Windows. The fix adds support for Unix \u201c700\u201d for the mkdir function on Windows which is used by mkdtemp() to ensure the newly created directory has the proper permissions.",
  "repo": "python/cpython",
  "patch_hash": "d86b49411753bf2c83291e3a14ae43fefded2f84",
  "patch_info": {
    "commit_hash": "d86b49411753bf2c83291e3a14ae43fefded2f84",
    "repo": "python/cpython",
    "commit_url": "https://github.com/python/cpython/commit/d86b49411753bf2c83291e3a14ae43fefded2f84",
    "files": [
      "Doc/whatsnew/3.13.rst",
      "Misc/NEWS.d/next/Security/2024-05-01-20-57-09.gh-issue-118486.K44KJG.rst"
    ],
    "message": "gh-118486: Update docs for CVE-2024-4030 reference (GH-118737)\n\nUpdate docs for CVE-2024-4030 reference",
    "before_after_code_files": []
  },
  "patch_diff": {},
  "candidates": [
    {
      "candidate_hash": "d96a52e1366ad5e798839a63e68a0a1b9d728f9c",
      "candidate_info": {
        "commit_hash": "d96a52e1366ad5e798839a63e68a0a1b9d728f9c",
        "repo": "python/cpython",
        "commit_url": "https://github.com/python/cpython/commit/d96a52e1366ad5e798839a63e68a0a1b9d728f9c",
        "files": [
          "Doc/using/cmdline.rst",
          "Misc/python.man"
        ],
        "message": "[3.13] gh-121101: Document -Wall option (an alias for -Walways) (GH-121102) (#121146)\n\ngh-121101: Document -Wall option (an alias for -Walways) (GH-121102)\n(cherry picked from commit 0a1e8ff9c15675fdc4d07fa6c59f83808bf00798)\n\nCo-authored-by: Wim Jeantine-Glenn <jump@wimglenn.com>",
        "before_after_code_files": [
          "Misc/python.man||Misc/python.man"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/AcreetionOS-Linux/python/pull/2"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "Misc/python.man||Misc/python.man": [
          "File: Misc/python.man -> Misc/python.man",
          "--- Hunk 1 ---",
          "[Context before]",
          "251:   -Wdefault  # Warn once per call location",
          "252:   -Werror    # Convert to exceptions",
          "253:   -Walways   # Warn every time",
          "254:   -Wmodule   # Warn once per calling module",
          "255:   -Wonce     # Warn once per Python process",
          "256:   -Wignore   # Never warn",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "254:   -Wall      # Same as -Walways",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "eb6a99485fcb264f001a5ac67cc82a6a4ec1f727",
      "candidate_info": {
        "commit_hash": "eb6a99485fcb264f001a5ac67cc82a6a4ec1f727",
        "repo": "python/cpython",
        "commit_url": "https://github.com/python/cpython/commit/eb6a99485fcb264f001a5ac67cc82a6a4ec1f727",
        "files": [
          "configure",
          "configure.ac"
        ],
        "message": "[3.13] gh-120154: Fix Emscripten/WASI pattern in case statement for LDSHARED (GH-120173) (#120199)\n\nFix Emscripten/WASI pattern in case statement for LDSHARED\n(cherry picked from commit 47816f465e833a5257a82b759b1081e06381e528)\n\nCo-authored-by: Michael Allwright <contact@allwright.io>",
        "before_after_code_files": [
          "configure.ac||configure.ac"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/AcreetionOS-Linux/python/pull/2"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "configure.ac||configure.ac": [
          "File: configure.ac -> configure.ac",
          "--- Hunk 1 ---",
          "[Context before]",
          "3417:   LDCXXSHARED='$(CXX) -dynamiclib -F . -framework $(PYTHONFRAMEWORK)'",
          "3418:   BLDSHARED=\"$LDSHARED\"",
          "3419:   ;;",
          "3421:   LDSHARED='$(CC) -shared'",
          "3422:   LDCXXSHARED='$(CXX) -shared';;",
          "3423:  Linux*|GNU*|QNX*|VxWorks*|Haiku*)",
          "",
          "[Removed Lines]",
          "3420:  Emscripten|WASI)",
          "",
          "[Added Lines]",
          "3420:  Emscripten*|WASI*)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "34a6d897883935f13fc22d80e6c443e25cea3e2c",
      "candidate_info": {
        "commit_hash": "34a6d897883935f13fc22d80e6c443e25cea3e2c",
        "repo": "python/cpython",
        "commit_url": "https://github.com/python/cpython/commit/34a6d897883935f13fc22d80e6c443e25cea3e2c",
        "files": [
          "Doc/library/zipfile.rst",
          "Lib/test/test_zipfile/_path/test_path.py",
          "Lib/zipfile/_path/__init__.py",
          "Misc/NEWS.d/next/Library/2024-05-26-21-28-11.gh-issue-119588.wlLBK5.rst"
        ],
        "message": "[3.13] gh-119588: Implement zipfile.Path.is_symlink (zipp 3.19.0). (GH-119591) (#119985)\n\ngh-119588: Implement zipfile.Path.is_symlink (zipp 3.19.0). (GH-119591)\n(cherry picked from commit 42a34ddb0b63e638905b01e17a7254623a0de427)\n\nCo-authored-by: Jason R. Coombs <jaraco@jaraco.com>",
        "before_after_code_files": [
          "Lib/test/test_zipfile/_path/test_path.py||Lib/test/test_zipfile/_path/test_path.py",
          "Lib/zipfile/_path/__init__.py||Lib/zipfile/_path/__init__.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/AcreetionOS-Linux/python/pull/2"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "Lib/test/test_zipfile/_path/test_path.py||Lib/test/test_zipfile/_path/test_path.py": [
          "File: Lib/test/test_zipfile/_path/test_path.py -> Lib/test/test_zipfile/_path/test_path.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "3: import contextlib",
          "4: import pathlib",
          "5: import pickle",
          "6: import sys",
          "7: import unittest",
          "8: import zipfile",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "6: import stat",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "21:         Counter = Counter",
          "24: def build_alpharep_fixture():",
          "25:     \"\"\"",
          "26:     Create a zip file with this structure:",
          "28:     .",
          "29:     \u251c\u2500\u2500 a.txt",
          "30:     \u251c\u2500\u2500 b",
          "31:     \u2502   \u251c\u2500\u2500 c.txt",
          "32:     \u2502   \u251c\u2500\u2500 d",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "25: def _make_link(info: zipfile.ZipInfo):  # type: ignore[name-defined]",
          "26:     info.external_attr |= stat.S_IFLNK << 16",
          "35:     \u251c\u2500\u2500 n.txt (-> a.txt)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "47:     - multiple files in a directory (b/c, b/f)",
          "48:     - a directory containing only a directory (g/h)",
          "49:     - a directory with files of different extensions (j/klm)",
          "51:     \"alpha\" because it uses alphabet",
          "52:     \"rep\" because it's a representative example",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "56:     - a symlink (n) pointing to (a)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "61:     zf.writestr(\"j/k.bin\", b\"content of k\")",
          "62:     zf.writestr(\"j/l.baz\", b\"content of l\")",
          "63:     zf.writestr(\"j/m.bar\", b\"content of m\")",
          "64:     zf.filename = \"alpharep.zip\"",
          "65:     return zf",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "71:     zf.writestr(\"n.txt\", b\"a.txt\")",
          "72:     _make_link(zf.infolist()[-1])",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "91:     def test_iterdir_and_types(self, alpharep):",
          "92:         root = zipfile.Path(alpharep)",
          "93:         assert root.is_dir()",
          "95:         assert a.is_file()",
          "96:         assert b.is_dir()",
          "97:         assert g.is_dir()",
          "",
          "[Removed Lines]",
          "94:         a, b, g, j = root.iterdir()",
          "",
          "[Added Lines]",
          "104:         a, k, b, g, j = root.iterdir()",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "111:     @pass_alpharep",
          "112:     def test_iterdir_on_file(self, alpharep):",
          "113:         root = zipfile.Path(alpharep)",
          "115:         with self.assertRaises(ValueError):",
          "116:             a.iterdir()",
          "",
          "[Removed Lines]",
          "114:         a, b, g, j = root.iterdir()",
          "",
          "[Added Lines]",
          "124:         a, k, b, g, j = root.iterdir()",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "126:     @pass_alpharep",
          "127:     def test_open(self, alpharep):",
          "128:         root = zipfile.Path(alpharep)",
          "130:         with a.open(encoding=\"utf-8\") as strm:",
          "131:             data = strm.read()",
          "132:         self.assertEqual(data, \"content of a\")",
          "",
          "[Removed Lines]",
          "129:         a, b, g, j = root.iterdir()",
          "",
          "[Added Lines]",
          "139:         a, k, b, g, j = root.iterdir()",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "230:     @pass_alpharep",
          "231:     def test_read(self, alpharep):",
          "232:         root = zipfile.Path(alpharep)",
          "234:         assert a.read_text(encoding=\"utf-8\") == \"content of a\"",
          "235:         # Also check positional encoding arg (gh-101144).",
          "236:         assert a.read_text(\"utf-8\") == \"content of a\"",
          "",
          "[Removed Lines]",
          "233:         a, b, g, j = root.iterdir()",
          "",
          "[Added Lines]",
          "243:         a, k, b, g, j = root.iterdir()",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "296:         reflect that change.",
          "297:         \"\"\"",
          "298:         root = zipfile.Path(alpharep)",
          "300:         alpharep.writestr('foo.txt', 'foo')",
          "301:         alpharep.writestr('bar/baz.txt', 'baz')",
          "302:         assert any(child.name == 'foo.txt' for child in root.iterdir())",
          "",
          "[Removed Lines]",
          "299:         a, b, g, j = root.iterdir()",
          "",
          "[Added Lines]",
          "309:         a, k, b, g, j = root.iterdir()",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "514:     @pass_alpharep",
          "515:     def test_is_symlink(self, alpharep):",
          "520:         root = zipfile.Path(alpharep)",
          "523:     @pass_alpharep",
          "524:     def test_relative_to(self, alpharep):",
          "",
          "[Removed Lines]",
          "516:         \"\"\"",
          "517:         See python/cpython#82102 for symlink support beyond this object.",
          "518:         \"\"\"",
          "521:         assert not root.is_symlink()",
          "",
          "[Added Lines]",
          "527:         assert not root.joinpath('a.txt').is_symlink()",
          "528:         assert root.joinpath('n.txt').is_symlink()",
          "",
          "---------------"
        ],
        "Lib/zipfile/_path/__init__.py||Lib/zipfile/_path/__init__.py": [
          "File: Lib/zipfile/_path/__init__.py -> Lib/zipfile/_path/__init__.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "5: import contextlib",
          "6: import pathlib",
          "7: import re",
          "8: import sys",
          "10: from .glob import Translator",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "8: import stat",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "391:     def is_symlink(self):",
          "392:         \"\"\"",
          "394:         \"\"\"",
          "397:     def glob(self, pattern):",
          "398:         if not pattern:",
          "",
          "[Removed Lines]",
          "393:         Return whether this path is a symlink. Always false (python/cpython#82102).",
          "395:         return False",
          "",
          "[Added Lines]",
          "394:         Return whether this path is a symlink.",
          "396:         info = self.root.getinfo(self.at)",
          "397:         mode = info.external_attr >> 16",
          "398:         return stat.S_ISLNK(mode)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "0d0be6b3efeace4743329f81c08f9720cc221207",
      "candidate_info": {
        "commit_hash": "0d0be6b3efeace4743329f81c08f9720cc221207",
        "repo": "python/cpython",
        "commit_url": "https://github.com/python/cpython/commit/0d0be6b3efeace4743329f81c08f9720cc221207",
        "files": [
          "Misc/NEWS.d/next/Library/2024-05-28-12-15-03.gh-issue-119118.FMKz1F.rst",
          "Parser/pegen.c",
          "Parser/pegen.h",
          "Python/Python-tokenize.c"
        ],
        "message": "[3.13] gh-119118: Fix performance regression in tokenize module (GH-119615) (#119682)\n\n- Cache line object to avoid creating a Unicode object\n  for all of the tokens in the same line.\n- Speed up byte offset to column offset conversion by using the\n  smallest buffer possible to measure the difference.\n\n(cherry picked from commit d87b0151062e36e67f9e42e1595fba5bf23a485c)\n\nCo-authored-by: Lysandros Nikolaou <lisandrosnik@gmail.com>\nCo-authored-by: Pablo Galindo <pablogsal@gmail.com>",
        "before_after_code_files": [
          "Parser/pegen.c||Parser/pegen.c",
          "Parser/pegen.h||Parser/pegen.h",
          "Python/Python-tokenize.c||Python/Python-tokenize.c"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/AcreetionOS-Linux/python/pull/2"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "Parser/pegen.c||Parser/pegen.c": [
          "File: Parser/pegen.c -> Parser/pegen.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "18:     return NULL;",
          "19: }",
          "21: Py_ssize_t",
          "22: _PyPegen_byte_offset_to_character_offset_raw(const char* str, Py_ssize_t col_offset)",
          "23: {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "21: Py_ssize_t",
          "22: _PyPegen_byte_offset_to_character_offset_line(PyObject *line, Py_ssize_t col_offset, Py_ssize_t end_col_offset)",
          "23: {",
          "24:     const char *data = PyUnicode_AsUTF8(line);",
          "26:     Py_ssize_t len = 0;",
          "27:     while (col_offset < end_col_offset) {",
          "28:         Py_UCS4 ch = data[col_offset];",
          "29:         if (ch < 0x80) {",
          "30:             col_offset += 1;",
          "31:         } else if ((ch & 0xe0) == 0xc0) {",
          "32:             col_offset += 2;",
          "33:         } else if ((ch & 0xf0) == 0xe0) {",
          "34:             col_offset += 3;",
          "35:         } else if ((ch & 0xf8) == 0xf0) {",
          "36:             col_offset += 4;",
          "37:         } else {",
          "38:             PyErr_SetString(PyExc_ValueError, \"Invalid UTF-8 sequence\");",
          "39:             return -1;",
          "40:         }",
          "41:         len++;",
          "42:     }",
          "43:     return len;",
          "44: }",
          "",
          "---------------"
        ],
        "Parser/pegen.h||Parser/pegen.h": [
          "File: Parser/pegen.h -> Parser/pegen.h",
          "--- Hunk 1 ---",
          "[Context before]",
          "148: expr_ty _PyPegen_name_token(Parser *p);",
          "149: expr_ty _PyPegen_number_token(Parser *p);",
          "150: void *_PyPegen_string_token(Parser *p);",
          "151: Py_ssize_t _PyPegen_byte_offset_to_character_offset(PyObject *line, Py_ssize_t col_offset);",
          "152: Py_ssize_t _PyPegen_byte_offset_to_character_offset_raw(const char*, Py_ssize_t col_offset);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "151: Py_ssize_t _PyPegen_byte_offset_to_character_offset_line(PyObject *line, Py_ssize_t col_offset, Py_ssize_t end_col_offset);",
          "",
          "---------------"
        ],
        "Python/Python-tokenize.c||Python/Python-tokenize.c": [
          "File: Python/Python-tokenize.c -> Python/Python-tokenize.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "32: {",
          "33:     PyObject_HEAD struct tok_state *tok;",
          "34:     int done;",
          "35: } tokenizeriterobject;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "37:     PyObject *last_line;",
          "38:     Py_ssize_t last_lineno;",
          "39:     Py_ssize_t byte_col_offset_diff;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "68:         self->tok->tok_extra_tokens = 1;",
          "69:     }",
          "70:     self->done = 0;",
          "71:     return (PyObject *)self;",
          "72: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "77:     self->last_line = NULL;",
          "78:     self->byte_col_offset_diff = 0;",
          "79:     self->last_lineno = 0;",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "210:         if (size >= 1 && it->tok->implicit_newline) {",
          "211:             size -= 1;",
          "212:         }",
          "214:     }",
          "215:     if (line == NULL) {",
          "216:         Py_DECREF(str);",
          "",
          "[Removed Lines]",
          "213:         line = PyUnicode_DecodeUTF8(line_start, size, \"replace\");",
          "",
          "[Added Lines]",
          "224:         if (it->tok->lineno != it->last_lineno) {",
          "227:             Py_XDECREF(it->last_line);",
          "228:             line = PyUnicode_DecodeUTF8(line_start, size, \"replace\");",
          "229:             it->last_line = line;",
          "230:             it->byte_col_offset_diff = 0;",
          "231:         } else {",
          "233:             line = it->last_line;",
          "234:         }",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "220:     Py_ssize_t lineno = ISSTRINGLIT(type) ? it->tok->first_lineno : it->tok->lineno;",
          "221:     Py_ssize_t end_lineno = it->tok->lineno;",
          "222:     Py_ssize_t col_offset = -1;",
          "223:     Py_ssize_t end_col_offset = -1;",
          "224:     if (token.start != NULL && token.start >= line_start) {",
          "226:     }",
          "227:     if (token.end != NULL && token.end >= it->tok->line_start) {",
          "229:     }",
          "231:     if (it->tok->tok_extra_tokens) {",
          "",
          "[Removed Lines]",
          "225:         col_offset = _PyPegen_byte_offset_to_character_offset(line, token.start - line_start);",
          "228:         end_col_offset = _PyPegen_byte_offset_to_character_offset_raw(it->tok->line_start, token.end - it->tok->line_start);",
          "",
          "[Added Lines]",
          "243:     it->last_lineno = lineno;",
          "247:     Py_ssize_t byte_offset = -1;",
          "249:         byte_offset = token.start - line_start;",
          "250:         col_offset = byte_offset - it->byte_col_offset_diff;",
          "253:         Py_ssize_t end_byte_offset = token.end - it->tok->line_start;",
          "254:         if (lineno == end_lineno) {",
          "258:             Py_ssize_t token_col_offset = _PyPegen_byte_offset_to_character_offset_line(line, byte_offset, end_byte_offset);",
          "259:             end_col_offset = col_offset + token_col_offset;",
          "260:             it->byte_col_offset_diff += token.end - token.start - token_col_offset;",
          "261:         } else {",
          "262:             end_col_offset = _PyPegen_byte_offset_to_character_offset_raw(it->tok->line_start, end_byte_offset);",
          "263:             it->byte_col_offset_diff += end_byte_offset - end_col_offset;",
          "264:         }",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "262:         }",
          "263:     }",
          "266: exit:",
          "267:     _PyToken_Free(&token);",
          "268:     if (type == ENDMARKER) {",
          "",
          "[Removed Lines]",
          "265:     result = Py_BuildValue(\"(iN(nn)(nn)N)\", type, str, lineno, col_offset, end_lineno, end_col_offset, line);",
          "",
          "[Added Lines]",
          "301:     result = Py_BuildValue(\"(iN(nn)(nn)O)\", type, str, lineno, col_offset, end_lineno, end_col_offset, line);",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "cd35e9d85a8976facebda41692d38a82a4e168c9",
      "candidate_info": {
        "commit_hash": "cd35e9d85a8976facebda41692d38a82a4e168c9",
        "repo": "python/cpython",
        "commit_url": "https://github.com/python/cpython/commit/cd35e9d85a8976facebda41692d38a82a4e168c9",
        "files": [
          "Objects/dictobject.c"
        ],
        "message": "[3.13] gh-117657: Fix missing atomic in dict_resize (GH-119312) (#119417)\n\ngh-117657: Fix missing atomic in dict_resize (GH-119312)\n\nFix missing atomic in dict_resize\n(cherry picked from commit 2b3fb767bea1f96c9e0523f6cc341b40f0fa1ca1)\n\nCo-authored-by: Dino Viehland <dinoviehland@meta.com>",
        "before_after_code_files": [
          "Objects/dictobject.c||Objects/dictobject.c"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/AcreetionOS-Linux/python/pull/2"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "Objects/dictobject.c||Objects/dictobject.c": [
          "File: Objects/dictobject.c -> Objects/dictobject.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "2003:         if (oldvalues->embedded) {",
          "2004:             assert(oldvalues->embedded == 1);",
          "2005:             assert(oldvalues->valid == 1);",
          "2007:         }",
          "2008:         else {",
          "2009:             free_values(oldvalues, IS_DICT_SHARED(mp));",
          "",
          "[Removed Lines]",
          "2006:             oldvalues->valid = 0;",
          "",
          "[Added Lines]",
          "2006:             FT_ATOMIC_STORE_UINT8(oldvalues->valid, 0);",
          "",
          "---------------"
        ]
      }
    }
  ]
}