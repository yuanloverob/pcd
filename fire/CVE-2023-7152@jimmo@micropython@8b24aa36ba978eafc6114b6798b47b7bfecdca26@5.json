{
  "cve_id": "CVE-2023-7152",
  "cve_desc": "A vulnerability, which was classified as critical, has been found in MicroPython 1.21.0/1.22.0-preview. Affected by this issue is the function poll_set_add_fd of the file extmod/modselect.c. The manipulation leads to use after free. The exploit has been disclosed to the public and may be used. The patch is identified as 8b24aa36ba978eafc6114b6798b47b7bfecdca26. It is recommended to apply a patch to fix this issue. VDB-249158 is the identifier assigned to this vulnerability.",
  "repo": "jimmo/micropython",
  "patch_hash": "8b24aa36ba978eafc6114b6798b47b7bfecdca26",
  "patch_info": {
    "commit_hash": "8b24aa36ba978eafc6114b6798b47b7bfecdca26",
    "repo": "jimmo/micropython",
    "commit_url": "https://github.com/jimmo/micropython/commit/8b24aa36ba978eafc6114b6798b47b7bfecdca26",
    "files": [
      "extmod/modselect.c",
      "tests/extmod/select_poll_fd.py"
    ],
    "message": "extmod/modselect: Handle growing the pollfds allocation correctly.\n\nThe poll_obj_t instances have their pollfd field point into this\nallocation.  So if re-allocating results in a move, we need to update the\nexisting poll_obj_t's.\n\nUpdate the test to cover this case.\n\nFixes issue #12887.\n\nThis work was funded through GitHub Sponsors.\n\nSigned-off-by: Jim Mussared <jim.mussared@gmail.com>",
    "before_after_code_files": [
      "extmod/modselect.c||extmod/modselect.c",
      "tests/extmod/select_poll_fd.py||tests/extmod/select_poll_fd.py"
    ]
  },
  "patch_diff": {
    "extmod/modselect.c||extmod/modselect.c": [
      "File: extmod/modselect.c -> extmod/modselect.c",
      "--- Hunk 1 ---",
      "[Context before]",
      "42: #if MICROPY_PY_SELECT_POSIX_OPTIMISATIONS",
      "44: #include <poll.h>",
      "46: #if !((MP_STREAM_POLL_RD) == (POLLIN) && \\",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "44: #include <string.h>",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "142:     }",
      "143: }",
      "145: STATIC struct pollfd *poll_set_add_fd(poll_set_t *poll_set, int fd) {",
      "146:     struct pollfd *free_slot = NULL;",
      "148:     if (poll_set->used == poll_set->max_used) {",
      "150:         if (poll_set->max_used >= poll_set->alloc) {",
      "153:         }",
      "154:         free_slot = &poll_set->pollfds[poll_set->max_used++];",
      "155:     } else {",
      "",
      "[Removed Lines]",
      "151:             poll_set->pollfds = m_renew(struct pollfd, poll_set->pollfds, poll_set->alloc, poll_set->alloc + 4);",
      "152:             poll_set->alloc += 4;",
      "",
      "[Added Lines]",
      "147: #define POLL_SET_ALLOC_INCREMENT (4)",
      "155:             size_t new_alloc = poll_set->alloc + POLL_SET_ALLOC_INCREMENT;",
      "157:             struct pollfd *new_fds = m_renew_maybe(struct pollfd, poll_set->pollfds, poll_set->alloc, new_alloc, false);",
      "158:             if (!new_fds) {",
      "160:                 new_fds = m_new(struct pollfd, new_alloc);",
      "161:                 memcpy(new_fds, poll_set->pollfds, sizeof(struct pollfd) * poll_set->alloc);",
      "165:                 for (mp_uint_t i = 0; i < poll_set->map.alloc; ++i) {",
      "166:                     if (!mp_map_slot_is_filled(&poll_set->map, i)) {",
      "167:                         continue;",
      "168:                     }",
      "170:                     poll_obj_t *poll_obj = MP_OBJ_TO_PTR(poll_set->map.table[i].value);",
      "171:                     if (!poll_obj) {",
      "175:                         continue;",
      "176:                     }",
      "178:                     poll_obj->pollfd = new_fds + (poll_obj->pollfd - poll_set->pollfds);",
      "179:                 }",
      "182:                 m_del(struct pollfd, poll_set->pollfds, poll_set->alloc);",
      "183:             }",
      "185:             poll_set->pollfds = new_fds;",
      "186:             poll_set->alloc = new_alloc;",
      "",
      "---------------"
    ],
    "tests/extmod/select_poll_fd.py||tests/extmod/select_poll_fd.py": [
      "File: tests/extmod/select_poll_fd.py -> tests/extmod/select_poll_fd.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "34: # Poll for input, should return an empty list.",
      "35: print(poller.poll(0))",
      "38: poller = select.poll()",
      "39: for fd in range(6000):",
      "40:     poller.register(fd)",
      "41: try:",
      "42:     poller.poll()",
      "43: except OSError as er:",
      "44:     print(er.errno == errno.EINVAL)",
      "",
      "[Removed Lines]",
      "37: # Test registering a very large number of file descriptors.",
      "",
      "[Added Lines]",
      "37: # Test registering a very large number of file descriptors (will trigger",
      "38: # EINVAL due to more than OPEN_MAX fds).",
      "44:     assert False",
      "48: # Register stdout/stderr, plus many extra ones to trigger the fd vector",
      "49: # resizing. Then unregister the excess ones and verify poll still works.",
      "50: poller = select.poll()",
      "51: for fd in range(1, 1000):",
      "52:     poller.register(fd)",
      "53: for i in range(3, 1000):",
      "54:     poller.unregister(i)",
      "55: print(sorted(poller.poll()))",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "2037edb5a22cf9c7d2dd665a3ce8b1eb470cadd1",
      "candidate_info": {
        "commit_hash": "2037edb5a22cf9c7d2dd665a3ce8b1eb470cadd1",
        "repo": "jimmo/micropython",
        "commit_url": "https://github.com/jimmo/micropython/commit/2037edb5a22cf9c7d2dd665a3ce8b1eb470cadd1",
        "files": [
          "py/mpconfig.h"
        ],
        "message": "all: Bump version to 1.23.0-preview.\n\nSigned-off-by: Damien George <damien@micropython.org>",
        "before_after_code_files": [
          "py/mpconfig.h||py/mpconfig.h"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/micropython/micropython/pull/12644"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "py/mpconfig.h||py/mpconfig.h": [
          "File: py/mpconfig.h -> py/mpconfig.h",
          "--- Hunk 1 ---",
          "[Context before]",
          "32: #define MICROPY_VERSION_MAJOR 1",
          "34: #define MICROPY_VERSION_MICRO 0",
          "",
          "[Removed Lines]",
          "33: #define MICROPY_VERSION_MINOR 22",
          "35: #define MICROPY_VERSION_PRERELEASE 0",
          "",
          "[Added Lines]",
          "33: #define MICROPY_VERSION_MINOR 23",
          "35: #define MICROPY_VERSION_PRERELEASE 1",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "2b56bab22673797b1a8753d018bf8759e11df3a3",
      "candidate_info": {
        "commit_hash": "2b56bab22673797b1a8753d018bf8759e11df3a3",
        "repo": "jimmo/micropython",
        "commit_url": "https://github.com/jimmo/micropython/commit/2b56bab22673797b1a8753d018bf8759e11df3a3",
        "files": [
          "tests/run-tests.py"
        ],
        "message": "tests/run-tests.py: Add an option for running only the failed tests.\n\nImplement the typical 're-run the failed tests' most test runners have, for\nconvenience.  Accessible via the new --run-failures argument, and\nimplemented using a json file containing a list of the failed tests.\n\nSigned-off-by: stijn <stijn@ignitron.net>",
        "before_after_code_files": [
          "tests/run-tests.py||tests/run-tests.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/micropython/micropython/pull/12644"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "tests/run-tests.py||tests/run-tests.py": [
          "File: tests/run-tests.py -> tests/run-tests.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "6: import platform",
          "7: import argparse",
          "8: import inspect",
          "9: import re",
          "10: from glob import glob",
          "11: import multiprocessing",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "9: import json",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "47: # (not site packages which may clash with u-module names), and improve start up time.",
          "48: CPYTHON3_CMD = [CPYTHON3, \"-BS\"]",
          "51: # For diff'ing test output",
          "52: DIFF = os.getenv(\"MICROPY_DIFF\", \"diff -u\")",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "51: # File with the test results.",
          "52: RESULTS_FILE = \"_results.json\"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "770:             with open(filename_mupy, \"wb\") as f:",
          "771:                 f.write(output_mupy)",
          "772:             print(\"FAIL \", test_file)",
          "775:         test_count.increment()",
          "",
          "[Removed Lines]",
          "773:             failed_tests.append(test_name)",
          "",
          "[Added Lines]",
          "776:             failed_tests.append((test_name, test_file))",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "784:         for test in tests:",
          "785:             run_one_test(test)",
          "787:     if args.list_tests:",
          "788:         return True",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "790:     # Leave RESULTS_FILE untouched here for future runs.",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "798:     if len(skipped_tests) > 0:",
          "799:         print(\"{} tests skipped: {}\".format(len(skipped_tests), \" \".join(skipped_tests)))",
          "800:     failed_tests = sorted(failed_tests.value)",
          "801:     if len(failed_tests) > 0:",
          "803:         return False",
          "805:     # all tests succeeded",
          "",
          "[Removed Lines]",
          "802:         print(\"{} tests failed: {}\".format(len(failed_tests), \" \".join(failed_tests)))",
          "",
          "[Added Lines]",
          "806:     # Serialize regex added by append_filter.",
          "807:     def to_json(obj):",
          "808:         if isinstance(obj, re.Pattern):",
          "809:             return obj.pattern",
          "810:         return obj",
          "812:     with open(os.path.join(result_dir, RESULTS_FILE), \"w\") as f:",
          "813:         json.dump(",
          "814:             {\"args\": vars(args), \"failed_tests\": [test[1] for test in failed_tests]},",
          "815:             f,",
          "816:             default=to_json,",
          "817:         )",
          "820:         print(",
          "821:             \"{} tests failed: {}\".format(",
          "822:                 len(failed_tests), \" \".join(test[0] for test in failed_tests)",
          "823:             )",
          "824:         )",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "915:         action=\"store_true\",",
          "916:         help=\"delete the .exp and .out files from failed tests and exit\",",
          "917:     )",
          "918:     args = cmd_parser.parse_args()",
          "920:     if args.print_failures:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "940:     cmd_parser.add_argument(",
          "941:         \"--run-failures\",",
          "942:         action=\"store_true\",",
          "943:         help=\"re-run only the failed tests\",",
          "944:     )",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "931:             os.path.join(args.result_dir, \"*.out\")",
          "932:         ):",
          "933:             os.remove(f)",
          "935:         sys.exit(0)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "961:         rm_f(os.path.join(args.result_dir, RESULTS_FILE))",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "979:     else:",
          "980:         raise ValueError(\"target must be one of %s\" % \", \".join(LOCAL_TARGETS + EXTERNAL_TARGETS))",
          "983:         if args.test_dirs is None:",
          "984:             test_dirs = (",
          "985:                 \"basics\",",
          "",
          "[Removed Lines]",
          "982:     if len(args.files) == 0:",
          "",
          "[Added Lines]",
          "1010:     if args.run_failures and (any(args.files) or args.test_dirs is not None):",
          "1011:         raise ValueError(",
          "1012:             \"--run-failures cannot be used together with files or --test-dirs arguments\"",
          "1013:         )",
          "1015:     if args.run_failures:",
          "1016:         results_file = os.path.join(args.result_dir, RESULTS_FILE)",
          "1017:         if os.path.exists(results_file):",
          "1018:             with open(results_file, \"r\") as f:",
          "1019:                 tests = json.load(f)[\"failed_tests\"]",
          "1020:         else:",
          "1021:             tests = []",
          "1022:     elif len(args.files) == 0:",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "2265d70add3ecfaf2ffbfb8393ab29a887d8d7fd",
      "candidate_info": {
        "commit_hash": "2265d70add3ecfaf2ffbfb8393ab29a887d8d7fd",
        "repo": "jimmo/micropython",
        "commit_url": "https://github.com/jimmo/micropython/commit/2265d70add3ecfaf2ffbfb8393ab29a887d8d7fd",
        "files": [
          "tests/run-tests.py",
          "tests/thread/stress_schedule.py",
          "tests/thread/thread_gc1.py",
          "tests/thread/thread_ident1.py",
          "tests/thread/thread_lock4.py",
          "tests/thread/thread_qstr1.py",
          "tests/thread/thread_shared1.py",
          "tests/thread/thread_sleep1.py"
        ],
        "message": "tests/thread: Adjust thread tests so most are able to run on rp2 port.\n\nThe aim of this commit is to make it so that the existing thread tests can\nbe used to test the _thread module on the rp2 port.  The rp2 port only\nallows up to one thread to be created at a time, and does not have the GIL\nenabled.\n\nThe following changes have been made:\n- run-tests.py skips mutation tests on rp2, because there's no GIL.\n- run-tests.py skips other tests on rp2 that require more than one thread.\n- The tests stop trying to start a new thread after there is an OSError,\n  which indicates that the system cannot create more threads.\n- Some of these tests also now run the test function on the main thread,\n  not just the spawned threads.\n- In some tests the output printing is adjusted so it's the same regardless\n  of how many threads were spawned.\n- Some time.sleep(1) are replaced with time.sleep(0) to make the tests run\n  a little faster (finish sooner when the work is done).\n\nFor the most part the tests are unchanged for existing platforms like esp32\nand unix.\n\nSigned-off-by: Damien George <damien@micropython.org>",
        "before_after_code_files": [
          "tests/run-tests.py||tests/run-tests.py",
          "tests/thread/stress_schedule.py||tests/thread/stress_schedule.py",
          "tests/thread/thread_gc1.py||tests/thread/thread_gc1.py",
          "tests/thread/thread_ident1.py||tests/thread/thread_ident1.py",
          "tests/thread/thread_lock4.py||tests/thread/thread_lock4.py",
          "tests/thread/thread_qstr1.py||tests/thread/thread_qstr1.py",
          "tests/thread/thread_shared1.py||tests/thread/thread_shared1.py",
          "tests/thread/thread_sleep1.py||tests/thread/thread_sleep1.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/micropython/micropython/pull/12644"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "tests/run-tests.py||tests/run-tests.py": [
          "File: tests/run-tests.py -> tests/run-tests.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "562:         skip_tests.add(\"cmdline/repl_sys_ps1_ps2.py\")",
          "563:         skip_tests.add(\"extmod/ssl_poll.py\")",
          "568:         for t in tests:",
          "569:             if t.startswith(\"thread/mutate_\"):",
          "570:                 skip_tests.add(t)",
          "572:     # Some tests shouldn't be run on pyboard",
          "573:     if args.target != \"unix\":",
          "574:         skip_tests.add(\"basics/exception_chain.py\")  # warning is not printed",
          "",
          "[Removed Lines]",
          "565:     # Some tests shouldn't be run on a PC",
          "566:     if args.target == \"unix\":",
          "567:         # unix build does not have the GIL so can't run thread mutation tests",
          "",
          "[Added Lines]",
          "565:     # Skip thread mutation tests on targets that don't have the GIL.",
          "566:     if args.target in (\"rp2\", \"unix\"):",
          "571:     # Skip thread tests that require many threads on targets that don't support multiple threads.",
          "572:     if args.target == \"rp2\":",
          "573:         skip_tests.add(\"thread/stress_heap.py\")",
          "574:         skip_tests.add(\"thread/thread_lock2.py\")",
          "575:         skip_tests.add(\"thread/thread_lock3.py\")",
          "576:         skip_tests.add(\"thread/thread_shared2.py\")",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "987:             elif args.target in (\"renesas-ra\"):",
          "988:                 test_dirs += (\"float\", \"inlineasm\", \"renesas-ra\")",
          "989:             elif args.target == \"rp2\":",
          "991:             elif args.target in (\"esp8266\", \"esp32\", \"minimal\", \"nrf\"):",
          "992:                 test_dirs += (\"float\",)",
          "993:             elif args.target == \"wipy\":",
          "",
          "[Removed Lines]",
          "990:                 test_dirs += (\"float\", \"stress\", \"inlineasm\")",
          "",
          "[Added Lines]",
          "996:                 test_dirs += (\"float\", \"stress\", \"inlineasm\", \"thread\")",
          "",
          "---------------"
        ],
        "tests/thread/stress_schedule.py||tests/thread/stress_schedule.py": [
          "File: tests/thread/stress_schedule.py -> tests/thread/stress_schedule.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: n = 0  # How many times the task successfully ran.",
          "21: t = None  # Start time of test, assigned here to preallocate entry in globals dict.",
          "24: def task(x):",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "22: thread_run = True  # If the thread should continue running.",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "29: def thread():",
          "31:         try:",
          "32:             micropython.schedule(task, None)",
          "33:         except RuntimeError:",
          "",
          "[Removed Lines]",
          "30:     while True:",
          "",
          "[Added Lines]",
          "31:     while thread_run:",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "38: for i in range(8):",
          "41: # Wait up to 10 seconds for 10000 tasks to be scheduled.",
          "42: t = time.ticks_ms()",
          "43: while n < _NUM_TASKS and time.ticks_diff(time.ticks_ms(), t) < _TIMEOUT_MS:",
          "44:     pass",
          "46: if n < _NUM_TASKS:",
          "47:     # Not all the tasks were scheduled, likely the scheduler stopped working.",
          "48:     print(n)",
          "",
          "[Removed Lines]",
          "39:     _thread.start_new_thread(thread, ())",
          "",
          "[Added Lines]",
          "40:     try:",
          "41:         _thread.start_new_thread(thread, ())",
          "42:     except OSError:",
          "43:         # System cannot create a new thead, so stop trying to create them.",
          "44:         break",
          "51: # Stop all threads.",
          "52: thread_run = False",
          "53: time.sleep_ms(20)",
          "",
          "---------------"
        ],
        "tests/thread/thread_gc1.py||tests/thread/thread_gc1.py": [
          "File: tests/thread/thread_gc1.py -> tests/thread/thread_gc1.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "16:             data[i] = data[i]",
          "17:         gc.collect()",
          "20:     with lock:",
          "23:         n_finished += 1",
          "26: lock = _thread.allocate_lock()",
          "28: n_finished = 0",
          "30: # spawn threads",
          "34: # busy wait for threads to finish",
          "35: while n_finished < n_thread:",
          "36:     pass",
          "",
          "[Removed Lines]",
          "19:     # print whether the data remains intact and indicate we are finished",
          "21:         print(list(data) == list(range(256)))",
          "22:         global n_finished",
          "27: n_thread = 4",
          "31: for i in range(n_thread):",
          "32:     _thread.start_new_thread(thread_entry, (10,))",
          "",
          "[Added Lines]",
          "19:     # check whether the data remains intact and indicate we are finished",
          "21:         global n_correct, n_finished",
          "22:         n_correct += list(data) == list(range(256))",
          "27: n_thread = 0",
          "28: n_thread_max = 4",
          "29: n_correct = 0",
          "33: for _ in range(n_thread_max):",
          "34:     try:",
          "35:         _thread.start_new_thread(thread_entry, (10,))",
          "36:         n_thread += 1",
          "37:     except OSError:",
          "38:         # System cannot create a new thead, so stop trying to create them.",
          "39:         break",
          "41: # also run the function on this main thread",
          "42: thread_entry(10)",
          "43: n_thread += 1",
          "49: print(n_correct == n_finished)",
          "",
          "---------------"
        ],
        "tests/thread/thread_ident1.py||tests/thread/thread_ident1.py": [
          "File: tests/thread/thread_ident1.py -> tests/thread/thread_ident1.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "5: import _thread",
          "8: tid = None",
          "11: def thread_entry():",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "8: # Initialise variables (also preallocate their spot in the globals dict so the",
          "9: # globals dict is not resized while threads are running).",
          "11: tid_main = None",
          "12: new_tid = None",
          "13: finished = False",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "19: tid_main = _thread.get_ident()",
          "20: print(\"main\", type(tid_main) == int, tid_main != 0)",
          "23: new_tid = _thread.start_new_thread(thread_entry, ())",
          "25: while not finished:",
          "",
          "[Removed Lines]",
          "22: finished = False",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "tests/thread/thread_lock4.py||tests/thread/thread_lock4.py": [
          "File: tests/thread/thread_lock4.py -> tests/thread/thread_lock4.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "37: # spawn threads to do the jobs",
          "38: for i in range(4):",
          "41: # wait for the jobs to complete",
          "42: while True:",
          "43:     with jobs_lock:",
          "44:         if len(output) == n_jobs:",
          "45:             break",
          "48: # sort and print the results",
          "49: output.sort(key=lambda x: x[0])",
          "",
          "[Removed Lines]",
          "39:     _thread.start_new_thread(thread_entry, ())",
          "46:     time.sleep(1)",
          "",
          "[Added Lines]",
          "39:     try:",
          "40:         _thread.start_new_thread(thread_entry, ())",
          "41:     except OSError:",
          "42:         # System cannot create a new thead, so stop trying to create them.",
          "43:         break",
          "50:     time.sleep(0)",
          "",
          "---------------"
        ],
        "tests/thread/thread_qstr1.py||tests/thread/thread_qstr1.py": [
          "File: tests/thread/thread_qstr1.py -> tests/thread/thread_qstr1.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "26: lock = _thread.allocate_lock()",
          "28: n_finished = 0",
          "29: n_qstr_per_thread = 100  # make 1000 for a more stressful test (uses more heap)",
          "31: # spawn threads",
          "35: # wait for threads to finish",
          "36: while n_finished < n_thread:",
          "39: print(\"pass\")",
          "",
          "[Removed Lines]",
          "27: n_thread = 4",
          "32: for i in range(n_thread):",
          "33:     _thread.start_new_thread(th, (i * n_qstr_per_thread, n_qstr_per_thread))",
          "37:     time.sleep(1)",
          "",
          "[Added Lines]",
          "27: n_thread = 0",
          "28: n_thread_max = 4",
          "33: for _ in range(n_thread_max):",
          "34:     try:",
          "35:         _thread.start_new_thread(th, (n_thread * n_qstr_per_thread, n_qstr_per_thread))",
          "36:         n_thread += 1",
          "37:     except OSError:",
          "38:         # System cannot create a new thead, so stop trying to create them.",
          "39:         break",
          "41: # also run the function on this main thread",
          "42: th(n_thread * n_qstr_per_thread, n_qstr_per_thread)",
          "43: n_thread += 1",
          "47:     time.sleep(0)",
          "",
          "---------------"
        ],
        "tests/thread/thread_shared1.py||tests/thread/thread_shared1.py": [
          "File: tests/thread/thread_shared1.py -> tests/thread/thread_shared1.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: lock = _thread.allocate_lock()",
          "22: n_finished = 0",
          "24: # the shared data structure",
          "25: tup = (1, 2, 3, 4)",
          "27: # spawn threads",
          "31: # busy wait for threads to finish",
          "32: while n_finished < n_thread:",
          "",
          "[Removed Lines]",
          "21: n_thread = 2",
          "28: for i in range(n_thread):",
          "29:     _thread.start_new_thread(thread_entry, (100, tup))",
          "",
          "[Added Lines]",
          "21: n_thread = 0",
          "22: n_thread_max = 2",
          "29: for _ in range(n_thread_max):",
          "30:     try:",
          "31:         _thread.start_new_thread(thread_entry, (100, tup))",
          "32:         n_thread += 1",
          "33:     except OSError:",
          "34:         # System cannot create a new thead, so stop trying to create them.",
          "35:         break",
          "37: # also run the function on this main thread",
          "38: thread_entry(100, tup)",
          "39: n_thread += 1",
          "",
          "---------------"
        ],
        "tests/thread/thread_sleep1.py||tests/thread/thread_sleep1.py": [
          "File: tests/thread/thread_sleep1.py -> tests/thread/thread_sleep1.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "12: import _thread",
          "14: lock = _thread.allocate_lock()",
          "16: n_finished = 0",
          "",
          "[Removed Lines]",
          "15: n_thread = 4",
          "",
          "[Added Lines]",
          "15: n_thread = 0",
          "16: n_thread_max = 4",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "24:         n_finished += 1",
          "30: # wait for threads to finish",
          "31: while n_finished < n_thread:",
          "32:     sleep_ms(100)",
          "",
          "[Removed Lines]",
          "27: for i in range(n_thread):",
          "28:     _thread.start_new_thread(thread_entry, (10 * i,))",
          "33: print(\"done\", n_thread)",
          "",
          "[Added Lines]",
          "28: # spawn threads",
          "29: for _ in range(n_thread_max):",
          "30:     try:",
          "31:         _thread.start_new_thread(thread_entry, (10 * n_thread,))",
          "32:         n_thread += 1",
          "33:     except OSError:",
          "34:         # System cannot create a new thead, so stop trying to create them.",
          "35:         break",
          "37: # also run the function on this main thread",
          "38: thread_entry(10 * n_thread)",
          "39: n_thread += 1",
          "44: print(\"done\")",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "d69e69adb689de91f97bc184c9ebc1022d0e4fc1",
      "candidate_info": {
        "commit_hash": "d69e69adb689de91f97bc184c9ebc1022d0e4fc1",
        "repo": "jimmo/micropython",
        "commit_url": "https://github.com/jimmo/micropython/commit/d69e69adb689de91f97bc184c9ebc1022d0e4fc1",
        "files": [
          "py/mkrules.mk"
        ],
        "message": "py/mkrules.mk: Fix dependency file generation for compiler wrappers.\n\nWhen compiling with distcc, it does not understand the -MD flag on its own.\nThis fixes the interaction by explicitly adding the -MF option.\n\nThe error in distcc is described here under \"Problems with gcc -MD\":\nhttps://www.distcc.org/faq.html\n\nSigned-off-by: Peter Z\u00fcger <zueger.peter@icloud.com>",
        "before_after_code_files": [
          "py/mkrules.mk||py/mkrules.mk"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/micropython/micropython/pull/12644"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "py/mkrules.mk||py/mkrules.mk": [
          "File: py/mkrules.mk -> py/mkrules.mk",
          "--- Hunk 1 ---",
          "[Context before]",
          "64: define compile_c",
          "65: $(ECHO) \"CC $<\"",
          "67: @# The following fixes the dependency file.",
          "68: @# See http://make.paulandlesley.org/autodep.html for details.",
          "69: @# Regex adjusted from the above to play better with Windows paths, etc.",
          "",
          "[Removed Lines]",
          "66: $(Q)$(CC) $(CFLAGS) -c -MD -o $@ $< || (echo -e $(HELP_BUILD_ERROR); false)",
          "",
          "[Added Lines]",
          "66: $(Q)$(CC) $(CFLAGS) -c -MD -MF $(@:.o=.d) -o $@ $< || (echo -e $(HELP_BUILD_ERROR); false)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "76: define compile_cxx",
          "77: $(ECHO) \"CXX $<\"",
          "79: @# The following fixes the dependency file.",
          "80: @# See http://make.paulandlesley.org/autodep.html for details.",
          "81: @# Regex adjusted from the above to play better with Windows paths, etc.",
          "",
          "[Removed Lines]",
          "78: $(Q)$(CXX) $(CXXFLAGS) -c -MD -o $@ $< || (echo -e $(HELP_BUILD_ERROR); false)",
          "",
          "[Added Lines]",
          "78: $(Q)$(CXX) $(CXXFLAGS) -c -MD -MF $(@:.o=.d) -o $@ $< || (echo -e $(HELP_BUILD_ERROR); false)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "f6d630877c3b31a5091dff2fd615ddb92189a46c",
      "candidate_info": {
        "commit_hash": "f6d630877c3b31a5091dff2fd615ddb92189a46c",
        "repo": "jimmo/micropython",
        "commit_url": "https://github.com/jimmo/micropython/commit/f6d630877c3b31a5091dff2fd615ddb92189a46c",
        "files": [
          "ports/esp32/main.c",
          "ports/esp32/mpconfigport.h"
        ],
        "message": "esp32: Add MICROPY_GC_INITIAL_HEAP_SIZE option and tune it.\n\nThis gets back the old heap-size behaviour on ESP32, before auto-split-heap\nwas introduced: after the heap is grown one time the size is 111936 bytes,\nwith about 40k left for the IDF.  That's enough to start WiFi and do a\nHTTPS request.\n\nSigned-off-by: Damien George <damien@micropython.org>",
        "before_after_code_files": [
          "ports/esp32/main.c||ports/esp32/main.c",
          "ports/esp32/mpconfigport.h||ports/esp32/mpconfigport.h"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/micropython/micropython/pull/12644"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "ports/esp32/main.c||ports/esp32/main.c": [
          "File: ports/esp32/main.c -> ports/esp32/main.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "79: #define MP_TASK_STACK_LIMIT_MARGIN (1024)",
          "80: #endif",
          "86: int vprintf_null(const char *format, va_list ap) {",
          "88:     return 0;",
          "",
          "[Removed Lines]",
          "84: #define MP_TASK_HEAP_SIZE (64 * 1024)",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "120:         ESP_LOGE(\"esp_init\", \"can't create event loop: 0x%x\\n\", err);",
          "121:     }",
          "125: soft_reset:",
          "127:     mp_stack_set_top((void *)sp);",
          "128:     mp_stack_set_limit(MICROPY_TASK_STACK_SIZE - MP_TASK_STACK_LIMIT_MARGIN);",
          "130:     mp_init();",
          "131:     mp_obj_list_append(mp_sys_path, MP_OBJ_NEW_QSTR(MP_QSTR__slash_lib));",
          "132:     readline_init0();",
          "",
          "[Removed Lines]",
          "123:     void *mp_task_heap = MP_PLAT_ALLOC_HEAP(MP_TASK_HEAP_SIZE);",
          "129:     gc_init(mp_task_heap, mp_task_heap + MP_TASK_HEAP_SIZE);",
          "",
          "[Added Lines]",
          "119:     void *mp_task_heap = MP_PLAT_ALLOC_HEAP(MICROPY_GC_INITIAL_HEAP_SIZE);",
          "125:     gc_init(mp_task_heap, mp_task_heap + MICROPY_GC_INITIAL_HEAP_SIZE);",
          "",
          "---------------"
        ],
        "ports/esp32/mpconfigport.h||ports/esp32/mpconfigport.h": [
          "File: ports/esp32/mpconfigport.h -> ports/esp32/mpconfigport.h",
          "--- Hunk 1 ---",
          "[Context before]",
          "27: #define MICROPY_ALLOC_PATH_MAX              (128)",
          "30: #define MICROPY_PERSISTENT_CODE_LOAD        (1)",
          "31: #if !CONFIG_IDF_TARGET_ESP32C3",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "33: #ifndef MICROPY_GC_INITIAL_HEAP_SIZE",
          "34: #if CONFIG_IDF_TARGET_ESP32",
          "35: #define MICROPY_GC_INITIAL_HEAP_SIZE        (56 * 1024)",
          "36: #elif CONFIG_IDF_TARGET_ESP32S2 && !CONFIG_SPIRAM",
          "37: #define MICROPY_GC_INITIAL_HEAP_SIZE        (36 * 1024)",
          "38: #else",
          "39: #define MICROPY_GC_INITIAL_HEAP_SIZE        (64 * 1024)",
          "40: #endif",
          "41: #endif",
          "",
          "---------------"
        ]
      }
    }
  ]
}