{
  "cve_id": "CVE-2024-41130",
  "cve_desc": "llama.cpp provides LLM inference in C/C++. Prior to b3427, llama.cpp contains a null pointer dereference in gguf_init_from_file. This vulnerability is fixed in b3427.",
  "repo": "ggerganov/llama.cpp",
  "patch_hash": "07283b1a90e1320aae4762c7e03c879043910252",
  "patch_info": {
    "commit_hash": "07283b1a90e1320aae4762c7e03c879043910252",
    "repo": "ggerganov/llama.cpp",
    "commit_url": "https://github.com/ggerganov/llama.cpp/commit/07283b1a90e1320aae4762c7e03c879043910252",
    "files": [
      "examples/gguf/gguf.cpp",
      "ggml/src/ggml.c"
    ],
    "message": "gguf : handle null name during init (#8587)",
    "before_after_code_files": [
      "examples/gguf/gguf.cpp||examples/gguf/gguf.cpp",
      "ggml/src/ggml.c||ggml/src/ggml.c"
    ]
  },
  "patch_diff": {
    "examples/gguf/gguf.cpp||examples/gguf/gguf.cpp": [
      "File: examples/gguf/gguf.cpp -> examples/gguf/gguf.cpp",
      "--- Hunk 1 ---",
      "[Context before]",
      "93:     struct gguf_context * ctx = gguf_init_from_file(fname.c_str(), params);",
      "95:     printf(\"%s: version:      %d\\n\", __func__, gguf_get_version(ctx));",
      "96:     printf(\"%s: alignment:   %zu\\n\", __func__, gguf_get_alignment(ctx));",
      "97:     printf(\"%s: data offset: %zu\\n\", __func__, gguf_get_data_offset(ctx));",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "95:     if (!ctx) {",
      "96:         fprintf(stderr, \"%s: failed to load '%s'\\n\", __func__, fname.c_str());",
      "97:         return false;",
      "98:     }",
      "",
      "---------------"
    ],
    "ggml/src/ggml.c||ggml/src/ggml.c": [
      "File: ggml/src/ggml.c -> ggml/src/ggml.c",
      "--- Hunk 1 ---",
      "[Context before]",
      "21015:             gguf_tensor_info_sanitize(info);",
      "21019:                 if (strcmp(info->name.data, ctx->infos[j].name.data) == 0) {",
      "21020:                     fprintf(stderr, \"%s: duplicated tensor name %s\\n\", __func__, info->name.data);",
      "21021:                     ok = false;",
      "",
      "[Removed Lines]",
      "21018:             for (uint64_t j = 0; j < i; ++j) {",
      "",
      "[Added Lines]",
      "21018:             for (uint64_t j = 0; j < i && ok; ++j) {",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "38061254b9fa8b6a0b6c86eef906c9d0ce2d18cd",
      "candidate_info": {
        "commit_hash": "38061254b9fa8b6a0b6c86eef906c9d0ce2d18cd",
        "repo": "ggerganov/llama.cpp",
        "commit_url": "https://github.com/ggerganov/llama.cpp/commit/38061254b9fa8b6a0b6c86eef906c9d0ce2d18cd",
        "files": [
          "examples/gguf/gguf.cpp",
          "ggml/src/ggml.c"
        ],
        "message": "gguf : handle null name during init",
        "before_after_code_files": [
          "examples/gguf/gguf.cpp||examples/gguf/gguf.cpp",
          "ggml/src/ggml.c||ggml/src/ggml.c"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/ggml-org/llama.cpp/pull/8587"
        ],
        "olp_code_files": {
          "patch": [
            "examples/gguf/gguf.cpp||examples/gguf/gguf.cpp",
            "ggml/src/ggml.c||ggml/src/ggml.c"
          ],
          "candidate": [
            "examples/gguf/gguf.cpp||examples/gguf/gguf.cpp",
            "ggml/src/ggml.c||ggml/src/ggml.c"
          ]
        }
      },
      "candidate_diff": {
        "examples/gguf/gguf.cpp||examples/gguf/gguf.cpp": [
          "File: examples/gguf/gguf.cpp -> examples/gguf/gguf.cpp",
          "--- Hunk 1 ---",
          "[Context before]",
          "93:     struct gguf_context * ctx = gguf_init_from_file(fname.c_str(), params);",
          "95:     printf(\"%s: version:      %d\\n\", __func__, gguf_get_version(ctx));",
          "96:     printf(\"%s: alignment:   %zu\\n\", __func__, gguf_get_alignment(ctx));",
          "97:     printf(\"%s: data offset: %zu\\n\", __func__, gguf_get_data_offset(ctx));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "95:     if (!ctx) {",
          "96:         fprintf(stderr, \"%s: failed to load '%s'\\n\", __func__, fname.c_str());",
          "97:         return false;",
          "98:     }",
          "",
          "---------------"
        ],
        "ggml/src/ggml.c||ggml/src/ggml.c": [
          "File: ggml/src/ggml.c -> ggml/src/ggml.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "21014:             gguf_tensor_info_sanitize(info);",
          "21018:                 if (strcmp(info->name.data, ctx->infos[j].name.data) == 0) {",
          "21019:                     fprintf(stderr, \"%s: duplicated tensor name %s\\n\", __func__, info->name.data);",
          "21020:                     ok = false;",
          "",
          "[Removed Lines]",
          "21017:             for (uint64_t j = 0; j < i; ++j) {",
          "",
          "[Added Lines]",
          "21017:             for (uint64_t j = 0; j < i && ok; ++j) {",
          "",
          "---------------"
        ]
      }
    }
  ]
}