{
  "cve_id": "CVE-2022-41902",
  "cve_desc": "TensorFlow is an open source platform for machine learning. The function MakeGrapplerFunctionItem takes arguments that determine the sizes of inputs and outputs. If the inputs given are greater than or equal to the sizes of the outputs, an out-of-bounds memory read or a crash is triggered. We have patched the issue in GitHub commit a65411a1d69edfb16b25907ffb8f73556ce36bb7. The fix will be included in TensorFlow 2.11.0. We will also cherrypick this commit on TensorFlow 2.8.4, 2.9.3, and 2.10.1.",
  "repo": "tensorflow/tensorflow",
  "patch_hash": "a65411a1d69edfb16b25907ffb8f73556ce36bb7",
  "patch_info": {
    "commit_hash": "a65411a1d69edfb16b25907ffb8f73556ce36bb7",
    "repo": "tensorflow/tensorflow",
    "commit_url": "https://github.com/tensorflow/tensorflow/commit/a65411a1d69edfb16b25907ffb8f73556ce36bb7",
    "files": [
      "tensorflow/core/grappler/utils/functions.cc"
    ],
    "message": "Fix OOB write in grappler.\n\nDiscovered via internal fuzzing.\n\nPiperOrigin-RevId: 482097391",
    "before_after_code_files": [
      "tensorflow/core/grappler/utils/functions.cc||tensorflow/core/grappler/utils/functions.cc"
    ]
  },
  "patch_diff": {
    "tensorflow/core/grappler/utils/functions.cc||tensorflow/core/grappler/utils/functions.cc": [
      "File: tensorflow/core/grappler/utils/functions.cc -> tensorflow/core/grappler/utils/functions.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "292:   std::vector<const FunctionDef::ArgAttrs*> arg_attr(inputs.size(), nullptr);",
      "293:   for (const auto& attr : func.arg_attr()) {",
      "294:     arg_attr.at(attr.first) = &attr.second;",
      "295:   }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "294:     if (attr.first >= inputs.size()) {",
      "295:       return errors::InvalidArgument(\"Invalid attribute index, got \",",
      "296:                                      attr.first, \" but expected less than \",",
      "297:                                      inputs.size());",
      "298:     }",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "437ca4f6953c6adbb804413df43b13969cc923ef",
      "candidate_info": {
        "commit_hash": "437ca4f6953c6adbb804413df43b13969cc923ef",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/437ca4f6953c6adbb804413df43b13969cc923ef",
        "files": [
          "tensorflow/core/grappler/BUILD",
          "tensorflow/core/grappler/clusters/BUILD",
          "tensorflow/core/grappler/clusters/cluster.h",
          "tensorflow/core/grappler/clusters/single_machine.cc",
          "tensorflow/core/grappler/graph_view.h",
          "tensorflow/core/grappler/grappler_item_builder.cc",
          "tensorflow/core/grappler/optimizers/BUILD",
          "tensorflow/core/grappler/optimizers/constant_folding.cc",
          "tensorflow/core/grappler/optimizers/data/BUILD",
          "tensorflow/core/grappler/optimizers/data/autotune_buffer_sizes.cc",
          "tensorflow/core/grappler/optimizers/data/autotune_buffer_sizes.h",
          "tensorflow/core/grappler/optimizers/function_optimizer.cc",
          "tensorflow/core/grappler/optimizers/gpu_swapping_kernels.cc",
          "tensorflow/core/grappler/optimizers/graph_optimizer.h",
          "tensorflow/core/grappler/optimizers/inference/batch_op_rewriter.cc",
          "tensorflow/core/grappler/optimizers/shape_optimizer.cc",
          "tensorflow/core/grappler/optimizers/tfg_optimizer_hook.cc",
          "tensorflow/core/grappler/utils/BUILD",
          "tensorflow/core/grappler/utils/functions.cc"
        ],
        "message": "Replace calls to TF errors constructors to use absl constructors instead.\n\nPiperOrigin-RevId: 531577434",
        "before_after_code_files": [
          "tensorflow/core/grappler/clusters/cluster.h||tensorflow/core/grappler/clusters/cluster.h",
          "tensorflow/core/grappler/clusters/single_machine.cc||tensorflow/core/grappler/clusters/single_machine.cc",
          "tensorflow/core/grappler/graph_view.h||tensorflow/core/grappler/graph_view.h",
          "tensorflow/core/grappler/grappler_item_builder.cc||tensorflow/core/grappler/grappler_item_builder.cc",
          "tensorflow/core/grappler/optimizers/constant_folding.cc||tensorflow/core/grappler/optimizers/constant_folding.cc",
          "tensorflow/core/grappler/optimizers/data/autotune_buffer_sizes.cc||tensorflow/core/grappler/optimizers/data/autotune_buffer_sizes.cc",
          "tensorflow/core/grappler/optimizers/data/autotune_buffer_sizes.h||tensorflow/core/grappler/optimizers/data/autotune_buffer_sizes.h",
          "tensorflow/core/grappler/optimizers/function_optimizer.cc||tensorflow/core/grappler/optimizers/function_optimizer.cc",
          "tensorflow/core/grappler/optimizers/gpu_swapping_kernels.cc||tensorflow/core/grappler/optimizers/gpu_swapping_kernels.cc",
          "tensorflow/core/grappler/optimizers/graph_optimizer.h||tensorflow/core/grappler/optimizers/graph_optimizer.h",
          "tensorflow/core/grappler/optimizers/inference/batch_op_rewriter.cc||tensorflow/core/grappler/optimizers/inference/batch_op_rewriter.cc",
          "tensorflow/core/grappler/optimizers/shape_optimizer.cc||tensorflow/core/grappler/optimizers/shape_optimizer.cc",
          "tensorflow/core/grappler/optimizers/tfg_optimizer_hook.cc||tensorflow/core/grappler/optimizers/tfg_optimizer_hook.cc",
          "tensorflow/core/grappler/utils/functions.cc||tensorflow/core/grappler/utils/functions.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/grappler/utils/functions.cc||tensorflow/core/grappler/utils/functions.cc"
          ],
          "candidate": [
            "tensorflow/core/grappler/utils/functions.cc||tensorflow/core/grappler/utils/functions.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/grappler/clusters/cluster.h||tensorflow/core/grappler/clusters/cluster.h": [
          "File: tensorflow/core/grappler/clusters/cluster.h -> tensorflow/core/grappler/clusters/cluster.h",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: #include <utility>",
          "22: #include <vector>",
          "24: #include \"tensorflow/core/common_runtime/device_set.h\"",
          "25: #include \"tensorflow/core/framework/tensor.h\"",
          "26: #include \"tensorflow/core/grappler/grappler_item.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "24: #include \"absl/status/status.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "108:   virtual Status EnablePeakMemoryStats() {",
          "110:         \"Peak Memory Stats are not supported on \", type(), \" clusters\"));",
          "111:   }",
          "",
          "[Removed Lines]",
          "109:     return errors::Unimplemented(strings ::StrCat(",
          "",
          "[Added Lines]",
          "110:     return absl::UnimplementedError(strings ::StrCat(",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "115:   virtual Status GetPeakMemoryUsage(",
          "116:       std::unordered_map<string, uint64>* device_peak_memory) const {",
          "118:         \"GetPeakMemoryUsage is not implemented for this type of cluster.\");",
          "119:   }",
          "",
          "[Removed Lines]",
          "117:     return errors::Unimplemented(",
          "",
          "[Added Lines]",
          "118:     return absl::UnimplementedError(",
          "",
          "---------------"
        ],
        "tensorflow/core/grappler/clusters/single_machine.cc||tensorflow/core/grappler/clusters/single_machine.cc": [
          "File: tensorflow/core/grappler/clusters/single_machine.cc -> tensorflow/core/grappler/clusters/single_machine.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: #include <atomic>",
          "19: #include <memory>",
          "21: #include \"tensorflow/cc/training/queue_runner.h\"",
          "22: #include \"tensorflow/core/common_runtime/device.h\"",
          "23: #include \"tensorflow/core/common_runtime/device_mgr.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "21: #include \"absl/status/status.h\"",
          "22: #include \"absl/strings/str_cat.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "76:   if (already_provisioned) {",
          "78:         \"Can't provision more than one single cluster at a time\");",
          "79:   }",
          "",
          "[Removed Lines]",
          "77:     return errors::Unavailable(",
          "",
          "[Added Lines]",
          "79:     return absl::UnavailableError(",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "89:     } else if (dev.device_type() == \"GPU\") {",
          "90:       DeviceNameUtils::ParsedName parsed;",
          "91:       if (!DeviceNameUtils::ParseFullName(dev.name(), &parsed)) {",
          "94:       }",
          "95:       TfDeviceId tf_device_id(parsed.id);",
          "96:       PlatformDeviceId platform_device_id;",
          "97:       Status s =",
          "98:           GpuIdManager::TfToPlatformDeviceId(tf_device_id, &platform_device_id);",
          "99:       if (!s.ok()) {",
          "102:       }",
          "103:       attr = GetLocalGPUInfo(platform_device_id);",
          "104:     } else if (dev.device_type().find(\"XLA\") == string::npos) {",
          "",
          "[Removed Lines]",
          "92:         return errors::InvalidArgument(",
          "93:             strings::StrCat(\"Not able to parse GPU device name: \", dev.name()));",
          "100:         return errors::Unavailable(\"Unknown TF GPU device with id \",",
          "101:                                    tf_device_id.value(), \": \", s.message());",
          "",
          "[Added Lines]",
          "94:         return absl::InvalidArgumentError(",
          "95:             absl::StrCat(\"Not able to parse GPU device name: \", dev.name()));",
          "102:         return absl::UnavailableError(",
          "103:             absl::StrCat(\"Unknown TF GPU device with id \", tf_device_id.value(),",
          "104:                          \": \", s.message()));",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "263:       },",
          "264:       timeout_s * 1000, thread_pool_.get());",
          "265:   if (!executed_in_time) {",
          "268:   } else if (run_metadata && status->ok()) {",
          "270:   }",
          "",
          "[Removed Lines]",
          "266:     return errors::DeadlineExceeded(\"Failed to run the graph after \", timeout_s,",
          "267:                                     \" seconds, aborting\");",
          "",
          "[Added Lines]",
          "269:     return absl::DeadlineExceededError(absl::StrCat(",
          "270:         \"Failed to run the graph after \", timeout_s, \" seconds, aborting\"));",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "309:   if (!executed_in_time) {",
          "314:   }",
          "316:   return OkStatus();",
          "",
          "[Removed Lines]",
          "312:     return errors::Unavailable(\"Failed to close the previous session after \",",
          "313:                                timeout_s_, \" seconds, aborting\");",
          "",
          "[Added Lines]",
          "315:     return absl::UnavailableError(",
          "316:         absl::StrCat(\"Failed to close the previous session after \", timeout_s_,",
          "317:                      \" seconds, aborting\"));",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "335:   if (!notified) {",
          "340:   }",
          "342:   return OkStatus();",
          "",
          "[Removed Lines]",
          "338:     return errors::Unavailable(\"The session is still running graphs after \",",
          "339:                                timeout_s_, \" seconds\");",
          "",
          "[Added Lines]",
          "342:     return absl::UnavailableError(absl::StrCat(",
          "343:         \"The session is still running graphs after \", timeout_s_, \" seconds\"));",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "363:   session_.reset(NewSession(options_));",
          "364:   if (!session_) {",
          "366:   }",
          "367:   coordinator_.reset(new Coordinator());",
          "",
          "[Removed Lines]",
          "365:     return errors::Unknown(\"Failed to create session\");",
          "",
          "[Added Lines]",
          "369:     return absl::UnknownError(\"Failed to create session\");",
          "",
          "---------------"
        ],
        "tensorflow/core/grappler/graph_view.h||tensorflow/core/grappler/graph_view.h": [
          "File: tensorflow/core/grappler/graph_view.h -> tensorflow/core/grappler/graph_view.h",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: #include <unordered_map>",
          "20: #include <unordered_set>",
          "21: #include \"absl/container/flat_hash_map.h\"",
          "22: #include \"absl/container/flat_hash_set.h\"",
          "23: #include \"absl/hash/hash.h\"",
          "24: #include \"absl/strings/string_view.h\"",
          "25: #include \"tensorflow/core/framework/graph.pb.h\"",
          "26: #include \"tensorflow/core/framework/node_def.pb.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "25: #include \"absl/status/status.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "322:     auto inserted = nodes_.emplace(node->name(), node);",
          "323:     return inserted.second",
          "324:                ? OkStatus()",
          "327:   }",
          "",
          "[Removed Lines]",
          "325:                : errors::InvalidArgument(\"Non unique node name detected: \",",
          "326:                                          node->name());",
          "",
          "[Added Lines]",
          "327:                : absl::InvalidArgumentError(absl::StrCat(",
          "328:                      \"Non unique node name detected: \", node->name()));",
          "",
          "---------------"
        ],
        "tensorflow/core/grappler/grappler_item_builder.cc||tensorflow/core/grappler/grappler_item_builder.cc": [
          "File: tensorflow/core/grappler/grappler_item_builder.cc -> tensorflow/core/grappler/grappler_item_builder.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: #include <unordered_set>",
          "20: #include <vector>",
          "22: #include \"tensorflow/core/common_runtime/device.h\"",
          "23: #include \"tensorflow/core/common_runtime/device_factory.h\"",
          "24: #include \"tensorflow/core/common_runtime/device_mgr.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "22: #include \"absl/status/status.h\"",
          "23: #include \"absl/strings/str_cat.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "118:     const std::unordered_set<string>& signature_feed_nodes,",
          "119:     GrapplerItem* new_item, NodeDef* node) {",
          "120:   if (node->attr().count(\"dtype\") == 0) {",
          "123:   }",
          "124:   DataType type = node->attr().at(\"dtype\").type();",
          "128:   if (node->attr().count(\"shape\") == 0) {",
          "131:   }",
          "",
          "[Removed Lines]",
          "121:     return errors::Internal(\"Unknown type for placeholder \", node->name(),",
          "122:                             \", skipping this input\");",
          "129:     return errors::Internal(\"Unknown shape for placeholder \", node->name(),",
          "130:                             \", skipping this input\");",
          "",
          "[Added Lines]",
          "123:     return absl::InternalError(absl::StrCat(\"Unknown type for placeholder \",",
          "124:                                             node->name(),",
          "125:                                             \", skipping this input\"));",
          "132:     return absl::InternalError(absl::StrCat(\"Unknown shape for placeholder \",",
          "133:                                             node->name(),",
          "134:                                             \", skipping this input\"));",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "139:   Status make_shape_status = ReplaceUnknownShapeDim(",
          "140:       cfg, node->attr().at(\"shape\").shape(), &shape_proto, &shape);",
          "141:   if (!make_shape_status.ok()) {",
          "144:   }",
          "",
          "[Removed Lines]",
          "142:     return errors::Internal(\"Invalid shape for placeholder \", node->name(),",
          "143:                             \": \", make_shape_status, \", skipping this input\");",
          "",
          "[Added Lines]",
          "146:     return absl::InternalError(",
          "147:         absl::StrCat(\"Invalid shape for placeholder \", node->name(), \": \",",
          "148:                      make_shape_status.ToString(), \", skipping this input\"));",
          "",
          "---------------"
        ],
        "tensorflow/core/grappler/optimizers/constant_folding.cc||tensorflow/core/grappler/optimizers/constant_folding.cc": [
          "File: tensorflow/core/grappler/optimizers/constant_folding.cc -> tensorflow/core/grappler/optimizers/constant_folding.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: #include <cmath>",
          "22: #include \"absl/strings/string_view.h\"",
          "23: #include \"absl/strings/substitute.h\"",
          "24: #include \"tensorflow/core/framework/allocator.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "22: #include \"absl/status/status.h\"",
          "23: #include \"absl/strings/str_cat.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "868:       Tensor t;",
          "869:       if (!t.FromProto(input_tensor)) {",
          "871:             \"Could not construct Tensor form TensorProto in node: \",",
          "873:       }",
          "874:       tensor->clear_tensor_content();",
          "875:       t.AsProtoField(tensor);",
          "",
          "[Removed Lines]",
          "870:         return errors::InvalidArgument(",
          "872:             input_node->name());",
          "",
          "[Added Lines]",
          "872:         return absl::InvalidArgumentError(absl::StrCat(",
          "874:             input_node->name()));",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "1176:       SET_TENSOR_VAL_CASE(DT_QUINT8, int32, int);",
          "1177:       SET_TENSOR_VAL_CASE(DT_BOOL, bool, bool);",
          "1178:     default:",
          "1182:   }",
          "1183:   return OkStatus();",
          "1184: }",
          "",
          "[Removed Lines]",
          "1179:       return errors::InvalidArgument(",
          "1180:           \"Unsupported type in CreateConstantTensorAttrValue: \",",
          "1181:           DataTypeString(type));",
          "",
          "[Added Lines]",
          "1181:       return absl::InvalidArgumentError(",
          "1182:           absl::StrCat(\"Unsupported type in CreateConstantTensorAttrValue: \",",
          "1183:                        DataTypeString(type)));",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "1262:   if (tensor->NumElements() > 4) {",
          "1285:   break",
          "1287:     switch (tensor->dtype()) {",
          "",
          "[Removed Lines]",
          "1263: #define POPULATE_TENSOR_PROTO(tensor, t, TYPE, FIELDTYPE)                      \\",
          "1264:   {                                                                            \\",
          "1265:     const auto* val_ptr = tensor->flat<TYPE>().data();                         \\",
          "1266:     auto last = *val_ptr;                                                      \\",
          "1267:     int64_t last_index = 0;                                                    \\",
          "1268:     for (int64_t i = 0; i < tensor->NumElements(); ++i) {                      \\",
          "1269:       TYPE cur = *val_ptr++;                                                   \\",
          "1270:       if (PackedValuesNotEqual(cur, last)) {                                   \\",
          "1271:         last = cur;                                                            \\",
          "1272:         last_index = i;                                                        \\",
          "1273:       }                                                                        \\",
          "1274:     }                                                                          \\",
          "1275:     encoded_size = (last_index + 1) * sizeof(FIELDTYPE);                       \\",
          "1276:     if (encoded_size < kint32max) {                                            \\",
          "1277:       optimized = true;                                                        \\",
          "1278:       t->mutable_##FIELDTYPE##_val()->Reserve(last_index + 1);                 \\",
          "1279:       const auto* src_ptr = tensor->flat<TYPE>().data();                       \\",
          "1280:       auto* dst_ptr =                                                          \\",
          "1281:           t->mutable_##FIELDTYPE##_val()->AddNAlreadyReserved(last_index + 1); \\",
          "1282:       std::copy(src_ptr, src_ptr + last_index + 1, dst_ptr);                   \\",
          "1283:     }                                                                          \\",
          "1284:   }                                                                            \\",
          "",
          "[Added Lines]",
          "1265: #define POPULATE_TENSOR_PROTO(tensor, t, TYPE, FIELDTYPE)         \\",
          "1266:   {                                                               \\",
          "1267:     const auto* val_ptr = tensor->flat<TYPE>().data();            \\",
          "1268:     auto last = *val_ptr;                                         \\",
          "1269:     int64_t last_index = 0;                                       \\",
          "1270:     for (int64_t i = 0; i < tensor->NumElements(); ++i) {         \\",
          "1271:       TYPE cur = *val_ptr++;                                      \\",
          "1272:       if (PackedValuesNotEqual(cur, last)) {                      \\",
          "1273:         last = cur;                                               \\",
          "1274:         last_index = i;                                           \\",
          "1275:       }                                                           \\",
          "1276:     }                                                             \\",
          "1277:     encoded_size = (last_index + 1) * sizeof(FIELDTYPE);          \\",
          "1278:     if (encoded_size < kint32max) {                               \\",
          "1279:       optimized = true;                                           \\",
          "1280:       t->mutable_##FIELDTYPE##_val()->Reserve(last_index + 1);    \\",
          "1281:       const auto* src_ptr = tensor->flat<TYPE>().data();          \\",
          "1282:       auto* dst_ptr = t->mutable_##FIELDTYPE##_val()              \\",
          "1283:                           -> AddNAlreadyReserved(last_index + 1); \\",
          "1284:       std::copy(src_ptr, src_ptr + last_index + 1, dst_ptr);      \\",
          "1285:     }                                                             \\",
          "1286:   }                                                               \\",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "1325:   node->mutable_attr()->insert({\"value\", attr_tensor});",
          "1327:   if (encoded_size > original_size && encoded_size >= kMaxConstantSize) {",
          "1331:   }",
          "1332:   return OkStatus();",
          "1333: }",
          "",
          "[Removed Lines]",
          "1328:     return errors::InvalidArgument(",
          "1329:         strings::StrCat(\"Can't fold \", name, \", its size would be too large (\",",
          "1330:                         encoded_size, \" >= \", kMaxConstantSize, \" bytes)\"));",
          "",
          "[Added Lines]",
          "1330:     return absl::InvalidArgumentError(",
          "1331:         absl::StrCat(\"Can't fold \", name, \", its size would be too large (\",",
          "1332:                      encoded_size, \" >= \", kMaxConstantSize, \" bytes)\"));",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "1378:                           \" has a dtype of DT_INVALID.\"));",
          "1379:     }",
          "1380:     if (IsRefType(raw_val.dtype())) {",
          "1382:           \"Not allowed to construct a tensor with reference dtype, got \",",
          "1384:     }",
          "1385:     Tensor* value = new Tensor(raw_val.dtype(), raw_val.tensor_shape());",
          "1386:     if (!value->FromProto(raw_val)) {",
          "1387:       delete (value);",
          "1391:     }",
          "1392:     inputs.emplace_back(value);",
          "1393:     total_inputs_size += value->TotalBytes();",
          "",
          "[Removed Lines]",
          "1381:       return errors::InvalidArgument(",
          "1383:           DataTypeString(raw_val.dtype()));",
          "1388:       return errors::InvalidArgument(\"Unable to make Tensor from proto for \",",
          "1389:                                      node.name(), \" with shape \",",
          "1390:                                      raw_val.tensor_shape().DebugString());",
          "",
          "[Added Lines]",
          "1383:       return absl::InvalidArgumentError(absl::StrCat(",
          "1385:           DataTypeString(raw_val.dtype())));",
          "1390:       return absl::InvalidArgumentError(",
          "1391:           absl::StrCat(\"Unable to make Tensor from proto for \", node.name(),",
          "1392:                        \" with shape \", raw_val.tensor_shape().DebugString()));",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "1462:     if (node_map_->GetNode(const_out_name) ||",
          "1463:         node_map_->GetNode(const_index_name)) {",
          "1466:           strings::StrCat(const_out_name, \" or \", const_index_name,",
          "1467:                           \" already present in the graph\"));",
          "1468:     }",
          "",
          "[Removed Lines]",
          "1465:       return errors::AlreadyExists(",
          "",
          "[Added Lines]",
          "1467:       return absl::AlreadyExistsError(",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "1581:     } else {",
          "1582:       if (node_map_->GetNode(const_node->name())) {",
          "1585:             const_node->name(), \" already present in the graph\"));",
          "1586:       }",
          "1587:       NodeDef* added_node = output_graph->add_node();",
          "",
          "[Removed Lines]",
          "1584:         return errors::AlreadyExists(strings::StrCat(",
          "",
          "[Added Lines]",
          "1586:         return absl::AlreadyExistsError(strings::StrCat(",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "1707: Status ConstantFolding::IsSimplifiableReshape(",
          "1708:     const NodeDef& node, const GraphProperties& properties) const {",
          "1709:   if (!IsReshape(node)) {",
          "1711:   }",
          "1712:   if (2 > node.input_size()) {",
          "1716:   }",
          "1717:   const NodeDef* new_shape = node_map_->GetNode(node.input(1));",
          "1718:   if (!IsReallyConstant(*new_shape)) {",
          "1722:   }",
          "1723:   TensorVector outputs;",
          "1724:   auto outputs_cleanup = gtl::MakeCleanup([&outputs] {",
          "",
          "[Removed Lines]",
          "1710:     return errors::Internal(\"Node \", node.name(), \" is not a Reshape node\");",
          "1713:     return errors::Internal(\"Node \", node.name(),",
          "1714:                             \" must have at most 2 inputs but has \",",
          "1715:                             node.input_size());",
          "1719:     return errors::Internal(\"Node \", node.name(), \" has shape \",",
          "1720:                             new_shape->DebugString(),",
          "1721:                             \" which is not a constant\");",
          "",
          "[Added Lines]",
          "1712:     return absl::InternalError(",
          "1713:         absl::StrCat(\"Node \", node.name(), \" is not a Reshape node\"));",
          "1716:     return absl::InternalError(absl::StrCat(",
          "1717:         \"Node \", node.name(), \" must have at most 2 inputs but has \",",
          "1718:         node.input_size()));",
          "1722:     return absl::InternalError(absl::StrCat(\"Node \", node.name(), \" has shape \",",
          "1723:                                             new_shape->DebugString(),",
          "1724:                                             \" which is not a constant\"));",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "1730:   Status s = EvaluateNode(*new_shape, TensorVector(), &outputs);",
          "1731:   if (!s.ok()) {",
          "1733:   }",
          "1734:   if (outputs.size() != 1) {",
          "1738:   }",
          "1740:   const std::vector<OpInfo::TensorProperties>& props =",
          "1741:       properties.GetInputProperties(node.name());",
          "1742:   if (props.empty()) {",
          "1744:   }",
          "1745:   const OpInfo::TensorProperties& prop = props[0];",
          "1746:   if (prop.dtype() == DT_INVALID) {",
          "1749:   }",
          "1750:   const PartialTensorShape shape(prop.shape());",
          "1751:   if (!shape.IsFullyDefined()) {",
          "1755:   }",
          "1757:   PartialTensorShape new_dims;",
          "",
          "[Removed Lines]",
          "1732:     return errors::Internal(\"Could not evaluate node \", node.name());",
          "1735:     return errors::Internal(\"Node \", node.name(),",
          "1736:                             \" must have exactly 1 output but has \",",
          "1737:                             outputs.size());",
          "1743:     return errors::Internal(\"Node \", node.name(), \" has no properties\");",
          "1747:     return errors::Internal(\"Node \", node.name(), \" has property \",",
          "1748:                             prop.DebugString(), \" with invalid dtype\");",
          "1752:     return errors::Internal(\"Node \", node.name(), \" has property \",",
          "1753:                             prop.DebugString(), \" with shape \",",
          "1754:                             shape.DebugString(), \" which is not fully defined\");",
          "",
          "[Added Lines]",
          "1735:     return absl::InternalError(",
          "1736:         absl::StrCat(\"Could not evaluate node \", node.name()));",
          "1739:     return absl::InternalError(",
          "1740:         absl::StrCat(\"Node \", node.name(),",
          "1741:                      \" must have exactly 1 output but has \", outputs.size()));",
          "1747:     return absl::InternalError(",
          "1748:         absl::StrCat(\"Node \", node.name(), \" has no properties\"));",
          "1752:     return absl::InternalError(",
          "1753:         absl::StrCat(\"Node \", node.name(), \" has property \", prop.DebugString(),",
          "1754:                      \" with invalid dtype\"));",
          "1758:     return absl::InternalError(absl::StrCat(",
          "1759:         \"Node \", node.name(), \" has property \", prop.DebugString(),",
          "1760:         \" with shape \", shape.DebugString(), \" which is not fully defined\"));",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "1774:   }",
          "1776:   if (!shape.IsCompatibleWith(new_dims)) {",
          "1779:   }",
          "1781:   return OkStatus();",
          "",
          "[Removed Lines]",
          "1777:     return errors::Internal(\"Expected shape \", shape.DebugString(),",
          "1778:                             \"to be compatible with \", new_dims.DebugString());",
          "",
          "[Added Lines]",
          "1783:     return absl::InternalError(",
          "1784:         absl::StrCat(\"Expected shape \", shape.DebugString(),",
          "1785:                      \"to be compatible with \", new_dims.DebugString()));",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "2992:     const NodeDef* x = node_map_->GetNode(node->input(0));",
          "2993:     const NodeDef* y = node_map_->GetNode(node->input(1));",
          "2994:     if (x == nullptr || y == nullptr) {",
          "2997:     }",
          "2998:     const TensorShapeProto& output_shape =",
          "2999:         properties.GetOutputProperties(node->name())[0].shape();",
          "",
          "[Removed Lines]",
          "2995:       return errors::InvalidArgument(\"Invalid inputs to node: \",",
          "2996:                                      node->DebugString());",
          "",
          "[Added Lines]",
          "3002:       return absl::InvalidArgumentError(",
          "3003:           absl::StrCat(\"Invalid inputs to node: \", node->DebugString()));",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "3984:     TF_RETURN_IF_ERROR(add_quantized_out(min_out_const_name, 1));",
          "3985:     TF_RETURN_IF_ERROR(add_quantized_out(max_out_const_name, 2));",
          "3986:   } else {",
          "3988:         \"Can't create Const for QuantizedMatMul min_out/max_out of \"",
          "3989:         \"node '$0' because of node name conflict\",",
          "3990:         node->name()));",
          "",
          "[Removed Lines]",
          "3987:     return errors::Internal(absl::Substitute(",
          "",
          "[Added Lines]",
          "3994:     return absl::InternalError(absl::Substitute(",
          "",
          "---------------"
        ],
        "tensorflow/core/grappler/optimizers/data/autotune_buffer_sizes.cc||tensorflow/core/grappler/optimizers/data/autotune_buffer_sizes.cc": [
          "File: tensorflow/core/grappler/optimizers/data/autotune_buffer_sizes.cc -> tensorflow/core/grappler/optimizers/data/autotune_buffer_sizes.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "16: #include \"tensorflow/core/grappler/optimizers/data/autotune_buffer_sizes.h\"",
          "18: #include \"tensorflow/core/framework/model.h\"",
          "19: #include \"tensorflow/core/framework/node_def.pb.h\"",
          "20: #include \"tensorflow/core/grappler/clusters/cluster.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: #include \"absl/status/status.h\"",
          "19: #include \"absl/strings/str_cat.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "81:           stats->num_changes++;",
          "82:         }",
          "83:       } else {",
          "85:             \"The autotune_buffer_sizes rewrite does not currently support \"",
          "86:             \"non-constant buffer_size input.\");",
          "87:       }",
          "",
          "[Removed Lines]",
          "84:         return errors::FailedPrecondition(",
          "",
          "[Added Lines]",
          "86:         return absl::FailedPreconditionError(",
          "",
          "---------------"
        ],
        "tensorflow/core/grappler/optimizers/data/autotune_buffer_sizes.h||tensorflow/core/grappler/optimizers/data/autotune_buffer_sizes.h": [
          "File: tensorflow/core/grappler/optimizers/data/autotune_buffer_sizes.h -> tensorflow/core/grappler/optimizers/data/autotune_buffer_sizes.h",
          "--- Hunk 1 ---",
          "[Context before]",
          "16: #ifndef TENSORFLOW_CORE_GRAPPLER_OPTIMIZERS_DATA_AUTOTUNE_BUFFER_SIZES_H_",
          "17: #define TENSORFLOW_CORE_GRAPPLER_OPTIMIZERS_DATA_AUTOTUNE_BUFFER_SIZES_H_",
          "19: #include \"tensorflow/core/framework/attr_value.pb.h\"",
          "20: #include \"tensorflow/core/grappler/optimizers/data/optimizer_base.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19: #include \"absl/status/status.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "52:     } else if (autotune == \"false\") {",
          "53:       autotune_ = false;",
          "54:     } else {",
          "57:     }",
          "58:     return OkStatus();",
          "59:   }",
          "",
          "[Removed Lines]",
          "55:       return errors::InvalidArgument(\"Received an invalid value for parameter \",",
          "56:                                      kAutotune, \": \", autotune);",
          "",
          "[Added Lines]",
          "56:       return absl::InvalidArgumentError(",
          "57:           absl::StrCat(\"Received an invalid value for parameter \", kAutotune,",
          "58:                        \": \", autotune));",
          "",
          "---------------"
        ],
        "tensorflow/core/grappler/optimizers/function_optimizer.cc||tensorflow/core/grappler/optimizers/function_optimizer.cc": [
          "File: tensorflow/core/grappler/optimizers/function_optimizer.cc -> tensorflow/core/grappler/optimizers/function_optimizer.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: #include \"absl/container/flat_hash_map.h\"",
          "22: #include \"absl/container/flat_hash_set.h\"",
          "23: #include \"absl/memory/memory.h\"",
          "24: #include \"absl/strings/str_replace.h\"",
          "25: #include \"absl/strings/substitute.h\"",
          "26: #include \"tensorflow/compiler/jit/defs.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "24: #include \"absl/status/status.h\"",
          "25: #include \"absl/strings/str_cat.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "594:     (*attr)[kFuncAttr].mutable_func()->set_name(specialized_func_name);",
          "596:   } else {",
          "598:   }",
          "600:   return OkStatus();",
          "",
          "[Removed Lines]",
          "597:     return errors::InvalidArgument(\"Unknown function call site\");",
          "",
          "[Added Lines]",
          "599:     return absl::InvalidArgumentError(\"Unknown function call site\");",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "753:   if (flib.Contains(specialized_func_name)) {",
          "757:   }",
          "759:   specialized_func.mutable_signature()->set_name(specialized_func_name);",
          "",
          "[Removed Lines]",
          "756:     return errors::Internal(\"Created duplicate function specialization\");",
          "",
          "[Added Lines]",
          "758:     return absl::InternalError(\"Created duplicate function specialization\");",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "900:         \"Can't guarantee execution of function side-effects after inlining. \"",
          "901:         \"Function call node has no outgoing control edges.\";",
          "902:     if (validate_outgoing_control_edge) {",
          "904:     } else {",
          "905:       VLOG(3) << error_message;",
          "906:     }",
          "",
          "[Removed Lines]",
          "903:       return errors::Internal(error_message);",
          "",
          "[Added Lines]",
          "905:       return absl::InternalError(error_message);",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "935:     if (!will_execute) {",
          "937:           \"Can't guarantee execution of a side-effectful node, that is not \"",
          "938:           \"reachable from function control source. Function body node: \",",
          "940:     }",
          "941:   }",
          "",
          "[Removed Lines]",
          "936:       return errors::Internal(",
          "939:           SummarizeNode(*side_effect));",
          "",
          "[Added Lines]",
          "938:       return absl::InternalError(absl::StrCat(",
          "941:           SummarizeNode(*side_effect)));",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "1001:     if (has_dead_output) {",
          "1003:           \"Can't inline a function with dead outputs. Dead tensor source: \",",
          "1005:     }",
          "1006:   }",
          "",
          "[Removed Lines]",
          "1002:       return errors::Internal(",
          "1004:           SummarizeNode(*dead_tensor_source));",
          "",
          "[Added Lines]",
          "1004:       return absl::InternalError(absl::StrCat(",
          "1006:           SummarizeNode(*dead_tensor_source)));",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "1019:                              const string& name,",
          "1020:                              const FunctionDef** fdef) -> Status {",
          "1021:     if ((*fdef = flib_def.Find(name)) == nullptr) {",
          "1023:           \"Was not able to find a function definition (name=\", name,",
          "1025:     }",
          "1026:     return OkStatus();",
          "1027:   };",
          "",
          "[Removed Lines]",
          "1022:       return errors::Internal(",
          "1024:           \") for a function call: \", SummarizeNode(node));",
          "",
          "[Added Lines]",
          "1024:       return absl::InternalError(absl::StrCat(",
          "1026:           \") for a function call: \", SummarizeNode(node)));",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "1049:       gradient::Creator creator;",
          "1050:       TF_RETURN_IF_ERROR(gradient::GetOpGradientCreator(func.name(), &creator));",
          "1051:       if (creator == nullptr) {",
          "1054:       }",
          "1055:       FunctionDef grad_fdef;",
          "1056:       TF_RETURN_IF_ERROR(creator(AttrSlice(&func.attr()), &grad_fdef));",
          "",
          "[Removed Lines]",
          "1052:         return errors::InvalidArgument(\"No gradient is defined for \",",
          "1053:                                        func.name());",
          "",
          "[Added Lines]",
          "1054:         return absl::InvalidArgumentError(",
          "1055:             absl::StrCat(\"No gradient is defined for \", func.name()));",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "1523:                                    GraphDef* optimized_graph) {",
          "1525:   if (item.graph.library().function_size() == 0) {",
          "1527:   }",
          "1529:   TF_RETURN_IF_ERROR(RunFunctionOptimizerPass(item, optimized_graph));",
          "",
          "[Removed Lines]",
          "1526:     return errors::Aborted(\"Nothing to do.\");",
          "",
          "[Added Lines]",
          "1528:     return absl::AbortedError(\"Nothing to do.\");",
          "",
          "---------------"
        ],
        "tensorflow/core/grappler/optimizers/gpu_swapping_kernels.cc||tensorflow/core/grappler/optimizers/gpu_swapping_kernels.cc": [
          "File: tensorflow/core/grappler/optimizers/gpu_swapping_kernels.cc -> tensorflow/core/grappler/optimizers/gpu_swapping_kernels.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: #include \"tensorflow/core/common_runtime/device.h\"",
          "19: #include \"tensorflow/core/framework/op_kernel.h\"",
          "20: #include \"tensorflow/core/lib/core/status.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: #include \"absl/status/status.h\"",
          "19: #include \"absl/strings/str_cat.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "30:     const Tensor& input = ctx->input(0);",
          "31:     OP_REQUIRES_ASYNC(",
          "32:         ctx, !ctx->input_alloc_attr(0).on_host(),",
          "35:         done);",
          "37:     AllocatorAttributes alloc_attrs;",
          "",
          "[Removed Lines]",
          "33:         errors::Internal(\"The input tensor to the _CopyFromGpuToHost kernel \"",
          "34:                          \"must reside on the device.\"),",
          "",
          "[Added Lines]",
          "35:         absl::InternalError(\"The input tensor to the _CopyFromGpuToHost kernel \"",
          "36:                             \"must reside on the device.\"),",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "63:     const Tensor& input = ctx->input(0);",
          "64:     OP_REQUIRES_ASYNC(",
          "65:         ctx, ctx->input_alloc_attr(0).on_host(),",
          "68:         done);",
          "70:     Tensor* output;",
          "",
          "[Removed Lines]",
          "66:         errors::Internal(\"The input tensor to the _CopyFromHostToGpu kernel \"",
          "67:                          \"must reside on the host.\"),",
          "",
          "[Added Lines]",
          "68:         absl::InternalError(\"The input tensor to the _CopyFromHostToGpu kernel \"",
          "69:                             \"must reside on the host.\"),",
          "",
          "---------------"
        ],
        "tensorflow/core/grappler/optimizers/graph_optimizer.h||tensorflow/core/grappler/optimizers/graph_optimizer.h": [
          "File: tensorflow/core/grappler/optimizers/graph_optimizer.h -> tensorflow/core/grappler/optimizers/graph_optimizer.h",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: #include <string>",
          "21: #include \"tensorflow/core/framework/graph.pb.h\"",
          "22: #include \"tensorflow/core/platform/env.h\"",
          "23: #include \"tensorflow/core/platform/errors.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "21: #include \"absl/status/status.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "78:   uint64 deadline_usec_;",
          "79: };",
          "86:   } while (0)",
          "88: }  // end namespace grappler",
          "",
          "[Removed Lines]",
          "81: #define GRAPPLER_RETURN_IF_DEADLINE_EXCEEDED()                              \\",
          "82:   do {                                                                      \\",
          "83:     if (this->DeadlineExceeded()) {                                         \\",
          "84:       return errors::DeadlineExceeded(this->name(), \" exceeded deadline.\"); \\",
          "85:     }                                                                       \\",
          "",
          "[Added Lines]",
          "82: #define GRAPPLER_RETURN_IF_DEADLINE_EXCEEDED()                \\",
          "83:   do {                                                        \\",
          "84:     if (this->DeadlineExceeded()) {                           \\",
          "85:       return absl::DeadlineExceededError(                     \\",
          "86:           absl::StrCat(this->name(), \" exceeded deadline.\")); \\",
          "87:     }                                                         \\",
          "",
          "---------------"
        ],
        "tensorflow/core/grappler/optimizers/inference/batch_op_rewriter.cc||tensorflow/core/grappler/optimizers/inference/batch_op_rewriter.cc": [
          "File: tensorflow/core/grappler/optimizers/inference/batch_op_rewriter.cc -> tensorflow/core/grappler/optimizers/inference/batch_op_rewriter.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "23: #include \"google/protobuf/repeated_field.h\"",
          "24: #include \"absl/status/status.h\"",
          "25: #include \"absl/strings/escaping.h\"",
          "26: #include \"tensorflow/core/framework/attr_value.pb.h\"",
          "27: #include \"tensorflow/core/framework/function.pb.h\"",
          "28: #include \"tensorflow/core/framework/node_def.pb.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "26: #include \"absl/strings/str_cat.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "140:   if (config->parameter_map().find(kBatchOpRewriteConfigParamKey) ==",
          "141:       config->parameter_map().end()) {",
          "143:         \"batch_op_rewrite_config param must be set in the rewriter config \"",
          "144:         \"with a serialized/encoded BatchOpRewriteConfig.\");",
          "145:   }",
          "",
          "[Removed Lines]",
          "142:     return ::tensorflow::errors::Internal(",
          "",
          "[Added Lines]",
          "143:     return absl::InternalError(",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "154:     return OkStatus();",
          "155:   }",
          "156:   if (!absl::Base64Unescape(params.s(), &unencoded)) {",
          "158:         \"Failed to unencode batch_op_rewrite_config from params.\");",
          "159:   }",
          "160:   if (!config_.ParseFromString(unencoded)) {",
          "162:         \"Failed to parse batch_op_rewrite_config from params.\");",
          "163:   }",
          "164:   VLOG(2) << \"BatchOp Rewrite config is \" << config_.DebugString();",
          "",
          "[Removed Lines]",
          "157:     return ::tensorflow::errors::Internal(",
          "161:     return ::tensorflow::errors::Internal(",
          "",
          "[Added Lines]",
          "158:     return absl::InternalError(",
          "162:     return absl::InternalError(",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "177:         config_proto_.experimental().session_metadata().name();",
          "179:     if (!config_.model_scheduler_options().empty()) {",
          "181:           \"model_scheduler_options is deprecated. Please use the \"",
          "182:           \"adaptive_batch_scheduler_option field in batch_options instead.\");",
          "183:     }",
          "",
          "[Removed Lines]",
          "180:       return ::tensorflow::errors::InvalidArgument(",
          "",
          "[Added Lines]",
          "181:       return absl::InvalidArgumentError(",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "197:         if ((params.min_inflight_batches > params.max_inflight_batches) ||",
          "198:             (params.initial_inflight_batches < params.min_inflight_batches) ||",
          "199:             (params.initial_inflight_batches > params.max_inflight_batches)) {",
          "201:               \"Requires min_inflight_batches <= initial_inflight_batches \"",
          "202:               \"and initial_inflight_batches <= max_inflight_batches; Got \"",
          "203:               \"{min_inflight_batches : \",",
          "204:               params.min_inflight_batches,",
          "205:               \", initial_inflight_batches : \", params.initial_inflight_batches,",
          "207:         }",
          "209:         asbs_overridden = true;",
          "",
          "[Removed Lines]",
          "200:           return errors ::InvalidArgument(",
          "206:               \", max_inflight_batches : \", params.max_inflight_batches, \"}.\");",
          "",
          "[Added Lines]",
          "201:           return absl::InvalidArgumentError(absl::StrCat(",
          "207:               \", max_inflight_batches : \", params.max_inflight_batches, \"}.\"));",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "220:       if (config_.enable_adaptive_shared_batching_thread_pool() &&",
          "221:           !asbs_overridden && batch_options.has_num_batch_threads() &&",
          "222:           batch_options.num_batch_threads() != 0) {",
          "224:             \"Unable to enable adapative shared batching because it requires \"",
          "225:             \"num_batch_threads=0 but the BatchOpRewriteConfig is also trying \"",
          "226:             \"to set num_batch_threads. Set either set \"",
          "",
          "[Removed Lines]",
          "223:         return errors::InvalidArgument(",
          "",
          "[Added Lines]",
          "224:         return absl::InvalidArgumentError(",
          "",
          "---------------"
        ],
        "tensorflow/core/grappler/optimizers/shape_optimizer.cc||tensorflow/core/grappler/optimizers/shape_optimizer.cc": [
          "File: tensorflow/core/grappler/optimizers/shape_optimizer.cc -> tensorflow/core/grappler/optimizers/shape_optimizer.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "16: #include \"tensorflow/core/grappler/optimizers/shape_optimizer.h\"",
          "18: #include \"tensorflow/core/framework/tensor.pb.h\"",
          "19: #include \"tensorflow/core/framework/tensor_shape.pb.h\"",
          "20: #include \"tensorflow/core/framework/types.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: #include \"absl/status/status.h\"",
          "19: #include \"absl/strings/str_cat.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "62:     }",
          "63:   }",
          "64:   if (!can_optimize) {",
          "66:   }",
          "",
          "[Removed Lines]",
          "65:     return errors::Aborted(\"Nothing to do.\");",
          "",
          "[Added Lines]",
          "67:     return absl::AbortedError(\"Nothing to do.\");",
          "",
          "---------------"
        ],
        "tensorflow/core/grappler/optimizers/tfg_optimizer_hook.cc||tensorflow/core/grappler/optimizers/tfg_optimizer_hook.cc": [
          "File: tensorflow/core/grappler/optimizers/tfg_optimizer_hook.cc -> tensorflow/core/grappler/optimizers/tfg_optimizer_hook.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: #include <string>",
          "19: #include <utility>",
          "21: #include \"absl/strings/str_cat.h\"",
          "22: #include \"llvm/Support/ThreadPool.h\"",
          "23: #include \"llvm/Support/Threading.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "21: #include \"absl/status/status.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "134:     LOG(ERROR) << name() << \" failed: \" << status.ToString();",
          "136:   }",
          "137:   metrics.ReportAndStop();",
          "",
          "[Removed Lines]",
          "135:     return tensorflow::errors::Aborted(status.message());",
          "",
          "[Added Lines]",
          "136:     return absl::AbortedError(status.message());",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "147:   if (failed(impl_->RunPipeline(module))) {",
          "149:   }",
          "",
          "[Removed Lines]",
          "148:     return InvalidArgument(\"MLIR Graph Optimizer failed: \");",
          "",
          "[Added Lines]",
          "149:     return absl::InvalidArgumentError(\"MLIR Graph Optimizer failed: \");",
          "",
          "---------------"
        ],
        "tensorflow/core/grappler/utils/functions.cc||tensorflow/core/grappler/utils/functions.cc": [
          "File: tensorflow/core/grappler/utils/functions.cc -> tensorflow/core/grappler/utils/functions.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: #include \"absl/container/flat_hash_map.h\"",
          "18: #include \"absl/container/flat_hash_set.h\"",
          "19: #include \"absl/strings/str_cat.h\"",
          "20: #include \"absl/strings/str_replace.h\"",
          "21: #include \"absl/strings/substitute.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19: #include \"absl/status/status.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "157:     const FunctionDef& func, const AttrSlice& func_instantiation_attr,",
          "158:     absl::flat_hash_map<string, DataType>* type_parameters) {",
          "159:   if (!type_parameters->empty()) {",
          "161:   }",
          "163:   const auto resolve_type_attr = [&](const OpDef::ArgDef& arg) -> Status {",
          "",
          "[Removed Lines]",
          "160:     return errors::InvalidArgument(\"Type parameters output map must be empty\");",
          "",
          "[Added Lines]",
          "161:     return absl::InvalidArgumentError(",
          "162:         \"Type parameters output map must be empty\");",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "193:     const FunctionDef& func, const AttrSlice& func_instantiation_attr,",
          "194:     absl::flat_hash_map<string, AttrValue>* body_parameters) {",
          "195:   if (!body_parameters->empty()) {",
          "197:   }",
          "199:   for (const NodeDef& func_body_node : func.node_def()) {",
          "",
          "[Removed Lines]",
          "196:     return errors::InvalidArgument(\"Body parameters output map must be empty\");",
          "",
          "[Added Lines]",
          "198:     return absl::InvalidArgumentError(",
          "199:         \"Body parameters output map must be empty\");",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "209:       if (placeholder_value) {",
          "210:         body_parameters->insert({placeholder, *placeholder_value});",
          "211:       } else {",
          "214:       }",
          "215:     }",
          "216:   }",
          "",
          "[Removed Lines]",
          "212:         return errors::InvalidArgument(\"Can't resolve placeholder: \",",
          "213:                                        placeholder);",
          "",
          "[Added Lines]",
          "215:         return absl::InvalidArgumentError(",
          "216:             absl::StrCat(\"Can't resolve placeholder: \", placeholder));",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "226:   const OpDef& signature = func.signature();",
          "228:   if (signature.name().empty()) {",
          "230:   }",
          "234:   for (const OpDef::AttrDef& attr : signature.attr()) {",
          "235:     if (attr.type() != \"type\") {",
          "237:           \"Function signature must have only type attributes\");",
          "238:     }",
          "239:   }",
          "",
          "[Removed Lines]",
          "229:     return errors::InvalidArgument(\"Function name must be specified\");",
          "236:       return errors::InvalidArgument(",
          "",
          "[Added Lines]",
          "232:     return absl::InvalidArgumentError(\"Function name must be specified\");",
          "239:       return absl::InvalidArgumentError(",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "292:   std::vector<const FunctionDef::ArgAttrs*> arg_attr(inputs.size(), nullptr);",
          "293:   for (const auto& attr : func.arg_attr()) {",
          "294:     if (attr.first >= inputs.size()) {",
          "298:     }",
          "299:     arg_attr.at(attr.first) = &attr.second;",
          "300:   }",
          "",
          "[Removed Lines]",
          "295:       return errors::InvalidArgument(\"Invalid attribute index, got \",",
          "296:                                      attr.first, \" but expected less than \",",
          "297:                                      inputs.size());",
          "",
          "[Added Lines]",
          "298:       return absl::InvalidArgumentError(",
          "299:           absl::StrCat(\"Invalid attribute index, got \", attr.first,",
          "300:                        \" but expected less than \", inputs.size()));",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "319: Status ReplaceInputWithConst(const NodeDef& input_const, int input_index,",
          "320:                              GrapplerFunctionItem* item) {",
          "321:   if (!IsConstant(input_const)) {",
          "324:   }",
          "325:   const int item_input_size = item->input_size();",
          "326:   if (input_index < 0 || input_index >= item_input_size) {",
          "328:         \"Function input index is out of bound: index=\", input_index,",
          "330:   }",
          "332:   const InputArgInstantiation& input_arg = item->input(input_index);",
          "",
          "[Removed Lines]",
          "322:     return errors::InvalidArgument(\"Input node is not a constant: \",",
          "323:                                    SummarizeNodeDef(input_const));",
          "327:     return errors::InvalidArgument(",
          "329:         \" input_size=\", item->input_size());",
          "",
          "[Added Lines]",
          "325:     return absl::InvalidArgumentError(absl::StrCat(",
          "326:         \"Input node is not a constant: \", SummarizeNodeDef(input_const)));",
          "330:     return absl::InvalidArgumentError(absl::StrCat(",
          "332:         \" input_size=\", item->input_size()));",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "366:   for (int remove_output : remove_outputs) {",
          "367:     const int item_output_size = item->output_size();",
          "368:     if (remove_output < 0 || remove_output >= item_output_size) {",
          "370:           \"Function output index is out of bound: index=\", remove_output,",
          "372:     }",
          "373:   }",
          "",
          "[Removed Lines]",
          "369:       return errors::InvalidArgument(",
          "371:           \" output_size=\", item->output_size());",
          "",
          "[Added Lines]",
          "372:       return absl::InvalidArgumentError(absl::StrCat(",
          "374:           \" output_size=\", item->output_size()));",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "507:     }",
          "508:   }",
          "511: }",
          "513: Status MakeFunctionDefHelper::AsFunctionDefNode(",
          "",
          "[Removed Lines]",
          "510:   return errors::InvalidArgument(\"Unknown graph def input: \", graph_def_input);",
          "",
          "[Added Lines]",
          "513:   return absl::InvalidArgumentError(",
          "514:       absl::StrCat(\"Unknown graph def input: \", graph_def_input));",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "540:   for (const NodeDef& func_body_node : item.function_body().node()) {",
          "541:     if (!helper.IsOutputNode(func_body_node)) continue;",
          "542:     if (func_body_node.input_size() != 1) {",
          "545:     }",
          "546:     output_tensors.emplace(func_body_node.name(), func_body_node.input(0));",
          "547:   }",
          "",
          "[Removed Lines]",
          "543:       return errors::Internal(\"_Retval node must have single input: \",",
          "544:                               SummarizeNodeDef(func_body_node));",
          "",
          "[Added Lines]",
          "547:       return absl::InternalError(",
          "548:           absl::StrCat(\"_Retval node must have single input: \",",
          "549:                        SummarizeNodeDef(func_body_node)));",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "568:     auto it = output_tensors.find(output_arg.node_name);",
          "569:     if (it == output_tensors.end()) {",
          "573:     }",
          "575:     TF_RETURN_IF_ERROR(helper.AsFunctionDefInput(",
          "",
          "[Removed Lines]",
          "570:       return errors::Internal(",
          "571:           \"Can't find an output tensor for the output node: \",",
          "572:           output_arg.node_name);",
          "",
          "[Added Lines]",
          "575:       return absl::InternalError(",
          "576:           absl::StrCat(\"Can't find an output tensor for the output node: \",",
          "577:                        output_arg.node_name));",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "216640f745a91a876759db50eededb881f17c0d1",
      "candidate_info": {
        "commit_hash": "216640f745a91a876759db50eededb881f17c0d1",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/216640f745a91a876759db50eededb881f17c0d1",
        "files": [
          "tensorflow/core/grappler/utils/functions.cc"
        ],
        "message": "Fix OOB write in grappler.\n\nDiscovered via internal fuzzing.\n\nPiperOrigin-RevId: 482097391",
        "before_after_code_files": [
          "tensorflow/core/grappler/utils/functions.cc||tensorflow/core/grappler/utils/functions.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/grappler/utils/functions.cc||tensorflow/core/grappler/utils/functions.cc"
          ],
          "candidate": [
            "tensorflow/core/grappler/utils/functions.cc||tensorflow/core/grappler/utils/functions.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/grappler/utils/functions.cc||tensorflow/core/grappler/utils/functions.cc": [
          "File: tensorflow/core/grappler/utils/functions.cc -> tensorflow/core/grappler/utils/functions.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "292:   std::vector<const FunctionDef::ArgAttrs*> arg_attr(inputs.size(), nullptr);",
          "293:   for (const auto& attr : func.arg_attr()) {",
          "294:     arg_attr.at(attr.first) = &attr.second;",
          "295:   }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "294:     if (attr.first >= inputs.size()) {",
          "295:       return errors::InvalidArgument(\"Invalid attribute index, got \",",
          "296:                                      attr.first, \" but expected less than \",",
          "297:                                      inputs.size());",
          "298:     }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "c1b2cc4bf3be94bc27a6daa29812ff5ed73d14e7",
      "candidate_info": {
        "commit_hash": "c1b2cc4bf3be94bc27a6daa29812ff5ed73d14e7",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/c1b2cc4bf3be94bc27a6daa29812ff5ed73d14e7",
        "files": [
          "tensorflow/core/grappler/utils/functions.cc"
        ],
        "message": "Fix OOB write in grappler.\n\nDiscovered via internal fuzzing.\n\nPiperOrigin-RevId: 482097391",
        "before_after_code_files": [
          "tensorflow/core/grappler/utils/functions.cc||tensorflow/core/grappler/utils/functions.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/grappler/utils/functions.cc||tensorflow/core/grappler/utils/functions.cc"
          ],
          "candidate": [
            "tensorflow/core/grappler/utils/functions.cc||tensorflow/core/grappler/utils/functions.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/grappler/utils/functions.cc||tensorflow/core/grappler/utils/functions.cc": [
          "File: tensorflow/core/grappler/utils/functions.cc -> tensorflow/core/grappler/utils/functions.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "292:   std::vector<const FunctionDef::ArgAttrs*> arg_attr(inputs.size(), nullptr);",
          "293:   for (const auto& attr : func.arg_attr()) {",
          "294:     arg_attr.at(attr.first) = &attr.second;",
          "295:   }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "294:     if (attr.first >= inputs.size()) {",
          "295:       return errors::InvalidArgument(\"Invalid attribute index, got \",",
          "296:                                      attr.first, \" but expected less than \",",
          "297:                                      inputs.size());",
          "298:     }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "4af65448cf66aba5f5de05177a7999c38965d27b",
      "candidate_info": {
        "commit_hash": "4af65448cf66aba5f5de05177a7999c38965d27b",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/4af65448cf66aba5f5de05177a7999c38965d27b",
        "files": [
          "tensorflow/core/grappler/utils/functions.cc"
        ],
        "message": "Fix OOB write in grappler.\n\nDiscovered via internal fuzzing.\n\nPiperOrigin-RevId: 482097391",
        "before_after_code_files": [
          "tensorflow/core/grappler/utils/functions.cc||tensorflow/core/grappler/utils/functions.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/grappler/utils/functions.cc||tensorflow/core/grappler/utils/functions.cc"
          ],
          "candidate": [
            "tensorflow/core/grappler/utils/functions.cc||tensorflow/core/grappler/utils/functions.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/grappler/utils/functions.cc||tensorflow/core/grappler/utils/functions.cc": [
          "File: tensorflow/core/grappler/utils/functions.cc -> tensorflow/core/grappler/utils/functions.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "292:   std::vector<const FunctionDef::ArgAttrs*> arg_attr(inputs.size(), nullptr);",
          "293:   for (const auto& attr : func.arg_attr()) {",
          "294:     arg_attr.at(attr.first) = &attr.second;",
          "295:   }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "294:     if (attr.first >= inputs.size()) {",
          "295:       return errors::InvalidArgument(\"Invalid attribute index, got \",",
          "296:                                      attr.first, \" but expected less than \",",
          "297:                                      inputs.size());",
          "298:     }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "0264a59c2abd465347d755d591f3d0733efa70fc",
      "candidate_info": {
        "commit_hash": "0264a59c2abd465347d755d591f3d0733efa70fc",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/0264a59c2abd465347d755d591f3d0733efa70fc",
        "files": [
          "tensorflow/core/grappler/utils/functions.cc"
        ],
        "message": "Fix OOB write in grappler.\n\nDiscovered via internal fuzzing.\n\nPiperOrigin-RevId: 482097391",
        "before_after_code_files": [
          "tensorflow/core/grappler/utils/functions.cc||tensorflow/core/grappler/utils/functions.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/grappler/utils/functions.cc||tensorflow/core/grappler/utils/functions.cc"
          ],
          "candidate": [
            "tensorflow/core/grappler/utils/functions.cc||tensorflow/core/grappler/utils/functions.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/grappler/utils/functions.cc||tensorflow/core/grappler/utils/functions.cc": [
          "File: tensorflow/core/grappler/utils/functions.cc -> tensorflow/core/grappler/utils/functions.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "292:   std::vector<const FunctionDef::ArgAttrs*> arg_attr(inputs.size(), nullptr);",
          "293:   for (const auto& attr : func.arg_attr()) {",
          "294:     arg_attr.at(attr.first) = &attr.second;",
          "295:   }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "294:     if (attr.first >= inputs.size()) {",
          "295:       return errors::InvalidArgument(\"Invalid attribute index, got \",",
          "296:                                      attr.first, \" but expected less than \",",
          "297:                                      inputs.size());",
          "298:     }",
          "",
          "---------------"
        ]
      }
    }
  ]
}