{
  "cve_id": "CVE-2024-25116",
  "cve_desc": "RedisBloom adds a set of probabilistic data structures to Redis. Starting in version 2.0.0 and prior to version 2.4.7 and 2.6.10, authenticated users can use the `CF.RESERVE` command to trigger a runtime assertion and termination of the Redis server process. The problem is fixed in RedisBloom 2.4.7 and 2.6.10.",
  "repo": "RedisBloom/RedisBloom",
  "patch_hash": "61d980a429050637f1af9fe919a880800a824f2a",
  "patch_info": {
    "commit_hash": "61d980a429050637f1af9fe919a880800a824f2a",
    "repo": "RedisBloom/RedisBloom",
    "commit_url": "https://github.com/RedisBloom/RedisBloom/commit/61d980a429050637f1af9fe919a880800a824f2a",
    "files": [
      "src/rebloom.c",
      "tests/flow/test_cuckoo.py"
    ],
    "message": "MOD-6343 Fix potential crash for cf.reserve (#724)\n\n* Enforce limits for cf.reserve arguments\n\n* comment\n\n* comment-2",
    "before_after_code_files": [
      "src/rebloom.c||src/rebloom.c",
      "tests/flow/test_cuckoo.py||tests/flow/test_cuckoo.py"
    ]
  },
  "patch_diff": {
    "src/rebloom.c||src/rebloom.c": [
      "File: src/rebloom.c -> src/rebloom.c",
      "--- Hunk 1 ---",
      "[Context before]",
      "24: #define REDISBLOOM_GIT_SHA \"unknown\"",
      "25: #endif",
      "28: #define CF_DEFAULT_BUCKETSIZE 2",
      "29: #define CF_DEFAULT_EXPANSION 1",
      "30: #define BF_DEFAULT_EXPANSION 2",
      "",
      "[Removed Lines]",
      "27: #define CF_MAX_ITERATIONS 20",
      "",
      "[Added Lines]",
      "27: #define CF_DEFAULT_MAX_ITERATIONS 20",
      "30: #define CF_MAX_EXPANSION 32768",
      "31: #define CF_MAX_BUCKET_SIZE 255",
      "32: #define CF_MAX_ITERATIONS 65535",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "107:     return sb;",
      "108: }",
      "112:     if (capacity < bucketSize * 2)",
      "113:         return NULL;",
      "",
      "[Removed Lines]",
      "110: static CuckooFilter *cfCreate(RedisModuleKey *key, size_t capacity, size_t bucketSize,",
      "111:                               size_t maxIterations, size_t expansion) {",
      "",
      "[Added Lines]",
      "113: static CuckooFilter *cfCreate(RedisModuleKey *key, size_t capacity, uint16_t bucketSize,",
      "114:                               uint16_t maxIterations, uint16_t expansion) {",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "529:         return RedisModule_ReplyWithError(ctx, \"Bad capacity\");",
      "530:     }",
      "533:     int mi_loc = RMUtil_ArgIndex(\"MAXITERATIONS\", argv, argc);",
      "534:     if (mi_loc != -1) {",
      "535:         if (RedisModule_StringToLongLong(argv[mi_loc + 1], &maxIterations) != REDISMODULE_OK) {",
      "536:             return RedisModule_ReplyWithError(ctx, \"Couldn't parse MAXITERATIONS\");",
      "538:             return RedisModule_ReplyWithError(",
      "540:         }",
      "541:     }",
      "",
      "[Removed Lines]",
      "532:     long long maxIterations = CF_MAX_ITERATIONS;",
      "537:         } else if (maxIterations <= 0) {",
      "539:                 ctx, \"MAXITERATIONS parameter needs to be a positive integer\");",
      "",
      "[Added Lines]",
      "535:     long long maxIterations = CF_DEFAULT_MAX_ITERATIONS;",
      "540:         } else if (maxIterations <= 0 || maxIterations > CF_MAX_ITERATIONS) {",
      "542:                 ctx, \"MAXITERATIONS: value must be an integer between 1 and 65535, inclusive.\");",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "545:     if (bs_loc != -1) {",
      "546:         if (RedisModule_StringToLongLong(argv[bs_loc + 1], &bucketSize) != REDISMODULE_OK) {",
      "547:             return RedisModule_ReplyWithError(ctx, \"Couldn't parse BUCKETSIZE\");",
      "549:             return RedisModule_ReplyWithError(",
      "551:         }",
      "552:     }",
      "",
      "[Removed Lines]",
      "548:         } else if (bucketSize <= 0) {",
      "550:                 ctx, \"BUCKETSIZE parameter needs to be a positive integer\");",
      "",
      "[Added Lines]",
      "551:         } else if (bucketSize <= 0 || bucketSize > CF_MAX_BUCKET_SIZE) {",
      "553:                 ctx, \"BUCKETSIZE: value must be an integer between 1 and 255, inclusive.\");",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "556:     if (ex_loc != -1) {",
      "557:         if (RedisModule_StringToLongLong(argv[ex_loc + 1], &expansion) != REDISMODULE_OK) {",
      "558:             return RedisModule_ReplyWithError(ctx, \"Couldn't parse EXPANSION\");",
      "560:             return RedisModule_ReplyWithError(",
      "562:         }",
      "563:     }",
      "",
      "[Removed Lines]",
      "559:         } else if (expansion < 0) {",
      "561:                 ctx, \"EXPANSION parameter needs to be a non-negative integer\");",
      "",
      "[Added Lines]",
      "562:         } else if (expansion < 0 || expansion > CF_MAX_EXPANSION) {",
      "564:                 ctx, \"EXPANSION: value must be an integer between 0 and 32768, inclusive.\");",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "596:     int status = cfGetFilter(key, &cf);",
      "598:     if (status == SB_EMPTY && options->autocreate) {",
      "600:                            CF_DEFAULT_EXPANSION)) == NULL) {",
      "601:             return RedisModule_ReplyWithError(ctx, \"Could not create filter\"); // LCOV_EXCL_LINE",
      "602:         }",
      "",
      "[Removed Lines]",
      "599:         if ((cf = cfCreate(key, options->capacity, CF_DEFAULT_BUCKETSIZE, CF_MAX_ITERATIONS,",
      "",
      "[Added Lines]",
      "602:         if ((cf = cfCreate(key, options->capacity, CF_DEFAULT_BUCKETSIZE, CF_DEFAULT_MAX_ITERATIONS,",
      "",
      "---------------",
      "--- Hunk 7 ---",
      "[Context before]",
      "1252:     if (encver < CF_MIN_EXPANSION_VERSION) { // CF_ENCODING_VERSION when added",
      "1253:         cf->numDeletes = 0;                  // Didn't exist earlier. bug fix",
      "1254:         cf->bucketSize = CF_DEFAULT_BUCKETSIZE;",
      "1256:         cf->expansion = CF_DEFAULT_EXPANSION;",
      "1257:     } else {",
      "1258:         cf->numDeletes = RedisModule_LoadUnsigned(io);",
      "",
      "[Removed Lines]",
      "1255:         cf->maxIterations = CF_MAX_ITERATIONS;",
      "",
      "[Added Lines]",
      "1258:         cf->maxIterations = CF_DEFAULT_MAX_ITERATIONS;",
      "",
      "---------------"
    ],
    "tests/flow/test_cuckoo.py||tests/flow/test_cuckoo.py": [
      "File: tests/flow/test_cuckoo.py -> tests/flow/test_cuckoo.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "346:         self.assertRaises(ResponseError, self.cmd, 'CF.LOADCHUNK err iterator') # missing data",
      "347:         self.assertRaises(ResponseError, self.cmd, 'CF.SCANDUMP err')",
      "349: class testCuckooNoCodec():",
      "350:     def __init__(self):",
      "351:         self.env = Env(decodeResponses=False)",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "349:     def test_reserve_limits(self):",
      "350:         self.cmd('FLUSHALL')",
      "351:         self.assertRaises(ResponseError, self.cmd, 'CF.RESERVE cf 100 BUCKETSIZE 33554432')",
      "352:         self.assertRaises(ResponseError, self.cmd, 'CF.RESERVE cf 100 MAXITERATIONS 165536')",
      "353:         self.assertRaises(ResponseError, self.cmd, 'CF.RESERVE cf 100 EXPANSION 327695')",
      "354:         self.assertRaises(ResponseError, self.cmd, 'CF.RESERVE CF 67108864 BUCKETSIZE 33554432 MAXITERATIONS 1337 EXPANSION 1337')",
      "356:         self.cmd('CF.RESERVE cf 67108864 BUCKETSIZE 255 MAXITERATIONS 65535 EXPANSION 32768')",
      "357:         info = self.cmd('CF.INFO cf')",
      "358:         self.assertEqual(info[info.index('Bucket size') + 1], 255)",
      "359:         self.assertEqual(info[info.index('Expansion rate') + 1], 32768)",
      "360:         self.assertEqual(info[info.index('Max iterations') + 1], 65535)",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "71eddc8ac617f2b849267da4c2677a46ab054383",
      "candidate_info": {
        "commit_hash": "71eddc8ac617f2b849267da4c2677a46ab054383",
        "repo": "RedisBloom/RedisBloom",
        "commit_url": "https://github.com/RedisBloom/RedisBloom/commit/71eddc8ac617f2b849267da4c2677a46ab054383",
        "files": [
          ".install/mariner2.sh"
        ],
        "message": "fix mariner.sh (#24)\n\n(cherry picked from commit 3a6cdd29c80c098fb78399aa6b9f29bd06638f0f)",
        "before_after_code_files": [
          ".install/mariner2.sh||.install/mariner2.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/RedisBloom/RedisBloom/pull/859"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        ".install/mariner2.sh||.install/mariner2.sh": [
          "File: .install/mariner2.sh -> .install/mariner2.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "6: pip install --upgrade setuptools",
          "7: pip install -r tests/flow/requirements.txt",
          "11: # Install aws-cli for uploading artifacts to s3",
          "12: curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"",
          "",
          "[Removed Lines]",
          "9: install -r .install/build_package_requirements.txt  # required for packing the module (todo: move to pack.sh after refactor)",
          "",
          "[Added Lines]",
          "9: pip install -r .install/build_package_requirements.txt  # required for packing the module (todo: move to pack.sh after refactor)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "e65d76a55b36cbb0b265cc279e53a9fd587600dd",
      "candidate_info": {
        "commit_hash": "e65d76a55b36cbb0b265cc279e53a9fd587600dd",
        "repo": "RedisBloom/RedisBloom",
        "commit_url": "https://github.com/RedisBloom/RedisBloom/commit/e65d76a55b36cbb0b265cc279e53a9fd587600dd",
        "files": [
          "src/version.h"
        ],
        "message": "Bump version 2.6.12",
        "before_after_code_files": [
          "src/version.h||src/version.h"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/RedisBloom/RedisBloom/pull/859"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "src/version.h||src/version.h": [
          "File: src/version.h -> src/version.h",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: #endif",
          "19: #ifndef REBLOOM_VERSION_PATCH",
          "21: #endif",
          "23: #define REBLOOM_MODULE_VERSION                                                                     \\",
          "",
          "[Removed Lines]",
          "20: #define REBLOOM_VERSION_PATCH 11",
          "",
          "[Added Lines]",
          "20: #define REBLOOM_VERSION_PATCH 12",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "dd37a130bf01812b29d1eb19804435d5e3a4fd4d",
      "candidate_info": {
        "commit_hash": "dd37a130bf01812b29d1eb19804435d5e3a4fd4d",
        "repo": "RedisBloom/RedisBloom",
        "commit_url": "https://github.com/RedisBloom/RedisBloom/commit/dd37a130bf01812b29d1eb19804435d5e3a4fd4d",
        "files": [
          "src/cf.c",
          "src/cms.c",
          "src/cuckoo.c",
          "src/cuckoo.h",
          "src/rebloom.c",
          "src/rm_cms.c",
          "src/rm_topk.c",
          "src/topk.c",
          "tests/flow/test_cms.py",
          "tests/flow/test_cuckoo.py",
          "tests/flow/test_overall.py",
          "tests/flow/test_topk.py"
        ],
        "message": "Backport allocation overflow checks (#16)\n\n(cherry picked from commit 2114a6b0872f96bddace8af1c81c82621365e2ed)",
        "before_after_code_files": [
          "src/cf.c||src/cf.c",
          "src/cms.c||src/cms.c",
          "src/cuckoo.c||src/cuckoo.c",
          "src/cuckoo.h||src/cuckoo.h",
          "src/rebloom.c||src/rebloom.c",
          "src/rm_cms.c||src/rm_cms.c",
          "src/rm_topk.c||src/rm_topk.c",
          "src/topk.c||src/topk.c",
          "tests/flow/test_cms.py||tests/flow/test_cms.py",
          "tests/flow/test_cuckoo.py||tests/flow/test_cuckoo.py",
          "tests/flow/test_overall.py||tests/flow/test_overall.py",
          "tests/flow/test_topk.py||tests/flow/test_topk.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "src/rebloom.c||src/rebloom.c",
            "tests/flow/test_cuckoo.py||tests/flow/test_cuckoo.py"
          ],
          "candidate": [
            "src/rebloom.c||src/rebloom.c",
            "tests/flow/test_cuckoo.py||tests/flow/test_cuckoo.py"
          ]
        }
      },
      "candidate_diff": {
        "src/cf.c||src/cf.c": [
          "File: src/cf.c -> src/cf.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "132:         SubCF *cur = filter->filters + ii;",
          "133:         cur->bucketSize = header->bucketSize;",
          "134:         cur->numBuckets = filter->numBuckets * pow(filter->expansion, ii);",
          "135:         cur->data =",
          "136:             RedisModule_Calloc((size_t)cur->numBuckets * filter->bucketSize, sizeof(CuckooBucket));",
          "137:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "136:         if (cur->numBuckets != 0 && filter->bucketSize > SIZE_MAX / cur->numBuckets) {",
          "137:             goto error;",
          "138:         }",
          "",
          "---------------"
        ],
        "src/cms.c||src/cms.c": [
          "File: src/cms.c -> src/cms.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "21:     assert(width > 0);",
          "22:     assert(depth > 0);",
          "24:     CMSketch *cms = CMS_CALLOC(1, sizeof(CMSketch));",
          "26:     cms->width = width;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "24:     if (width > SIZE_MAX / depth || width * depth > SIZE_MAX / sizeof(uint32_t)) {",
          "25:         return NULL;",
          "26:     }",
          "",
          "---------------"
        ],
        "src/cuckoo.c||src/cuckoo.c": [
          "File: src/cuckoo.c -> src/cuckoo.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "56: }",
          "58: void CuckooFilter_Free(CuckooFilter *filter) {",
          "59:     for (uint16_t ii = 0; ii < filter->numFilters; ++ii) {",
          "60:         CUCKOO_FREE(filter->filters[ii].data);",
          "61:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "59:     if (!filter) {",
          "60:         return;",
          "61:     }",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "69:     if (!filtersArray) {",
          "70:         return -1; // LCOV_EXCL_LINE memory failure",
          "71:     }",
          "72:     SubCF *currentFilter = filtersArray + filter->numFilters;",
          "73:     size_t growth = pow(filter->expansion, filter->numFilters);",
          "75:     currentFilter->numBuckets = filter->numBuckets * growth;",
          "76:     currentFilter->data =",
          "77:         CUCKOO_CALLOC((size_t)currentFilter->numBuckets * filter->bucketSize, sizeof(CuckooBucket));",
          "78:     if (!currentFilter->data) {",
          "",
          "[Removed Lines]",
          "74:     currentFilter->bucketSize = filter->bucketSize;",
          "",
          "[Added Lines]",
          "76:     filter->filters = filtersArray;",
          "79:         .bucketSize = filter->bucketSize,",
          "80:         .data = NULL",
          "81:     };",
          "86:     if (filter->numBuckets != 0 && growth > CF_MAX_NUM_BUCKETS / filter->numBuckets) {",
          "87:         return -1;",
          "88:     }",
          "93:     if (currentFilter->numBuckets != 0 && filter->bucketSize > SIZE_MAX / currentFilter->numBuckets) {",
          "94:         return -1;",
          "95:     }",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "80:     }",
          "82:     filter->numFilters++;",
          "84:     return 0;",
          "85: }",
          "",
          "[Removed Lines]",
          "83:     filter->filters = filtersArray;",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "src/cuckoo.h||src/cuckoo.h": [
          "File: src/cuckoo.h -> src/cuckoo.h",
          "--- Hunk 1 ---",
          "[Context before]",
          "71:     CuckooInsert_MemAllocFailed = -2",
          "72: } CuckooInsertStatus;",
          "74: int CuckooFilter_Init(CuckooFilter *filter, uint64_t capacity, uint16_t bucketSize,",
          "75:                       uint16_t maxIterations, uint16_t expansion);",
          "76: void CuckooFilter_Free(CuckooFilter *filter);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "74: enum CuckooRc {",
          "75:     CUCKOO_OK = 0,",
          "76:     CUCKOO_ERR = -1,",
          "77:     CUCKOO_OOM = -2,",
          "78: };",
          "",
          "---------------"
        ],
        "src/rebloom.c||src/rebloom.c": [
          "File: src/rebloom.c -> src/rebloom.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "105: }",
          "107: static CuckooFilter *cfCreate(RedisModuleKey *key, size_t capacity, uint16_t bucketSize,",
          "110:         return NULL;",
          "112:     CuckooFilter *cf = RedisModule_Calloc(1, sizeof(*cf));",
          "113:     if (CuckooFilter_Init(cf, capacity, bucketSize, maxIterations, expansion) != 0) {",
          "116:     }",
          "117:     RedisModule_ModuleTypeSetValue(key, CFType, cf);",
          "118:     return cf;",
          "",
          "[Removed Lines]",
          "108:                               uint16_t maxIterations, uint16_t expansion) {",
          "109:     if (capacity < bucketSize * 2)",
          "114:         RedisModule_Free(cf); // LCOV_EXCL_LINE",
          "115:         cf = NULL;            // LCOV_EXCL_LINE",
          "",
          "[Added Lines]",
          "108:                               uint16_t maxIterations, uint16_t expansion, int *err) {",
          "111:     if (capacity < bucketSize * 2) {",
          "114:     }",
          "118:         CuckooFilter_Free(cf);",
          "119:         RedisModule_Free(cf);",
          "121:         return NULL;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "570:         return RedisModule_ReplyWithError(ctx, statusStrerror(status));",
          "571:     }",
          "574:     if (cf == NULL) {",
          "576:     } else {",
          "577:         RedisModule_ReplicateVerbatim(ctx);",
          "578:         return RedisModule_ReplyWithSimpleString(ctx, \"OK\");",
          "",
          "[Removed Lines]",
          "573:     cf = cfCreate(key, capacity, bucketSize, maxIterations, expansion);",
          "575:         return RedisModule_ReplyWithError(ctx, \"Couldn't create Cuckoo Filter\"); // LCOV_EXCL_LINE",
          "",
          "[Added Lines]",
          "579:     int err = CUCKOO_OK;",
          "580:     cf = cfCreate(key, capacity, bucketSize, maxIterations, expansion, &err);",
          "582:         if (err == CUCKOO_OOM) {",
          "583:             RedisModule_ReplyWithError(ctx, \"ERR Insufficient memory to create filter\");",
          "584:         } else {",
          "585:             RedisModule_ReplyWithError(ctx, \"ERR Could not create filter\");",
          "586:         }",
          "587:         return REDISMODULE_OK;",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "593:     int status = cfGetFilter(key, &cf);",
          "595:     if (status == SB_EMPTY && options->autocreate) {",
          "596:         if ((cf = cfCreate(key, options->capacity, CF_DEFAULT_BUCKETSIZE, CF_DEFAULT_MAX_ITERATIONS,",
          "599:         }",
          "600:     } else if (status != SB_OK) {",
          "601:         return RedisModule_ReplyWithError(ctx, statusStrerror(status));",
          "",
          "[Removed Lines]",
          "597:                            CF_DEFAULT_EXPANSION)) == NULL) {",
          "598:             return RedisModule_ReplyWithError(ctx, \"Could not create filter\"); // LCOV_EXCL_LINE",
          "",
          "[Added Lines]",
          "608:         int err = CUCKOO_OK;",
          "610:                            CF_DEFAULT_EXPANSION, &err)) == NULL) {",
          "611:             if (err == CUCKOO_OOM) {",
          "612:                 RedisModule_ReplyWithError(ctx, \"ERR Insufficient memory to create filter\");",
          "613:             } else {",
          "614:                 RedisModule_ReplyWithError(ctx, \"ERR Could not create filter\");",
          "615:             }",
          "616:             return REDISMODULE_OK;",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "656:             }",
          "657:             break;",
          "658:         case CuckooInsert_MemAllocFailed:",
          "660:             break;",
          "661:         default:",
          "662:             break;",
          "",
          "[Removed Lines]",
          "659:             RedisModule_ReplyWithError(ctx, \"Memory allocation failure\"); // LCOV_EXCL_LINE",
          "",
          "[Added Lines]",
          "677:             if (!options->is_multi) {",
          "678:                 RedisModule_ReplyWithError(ctx, \"Memory allocation failure\"); // LCOV_EXCL_LINE",
          "679:             } else {",
          "680:                 RedisModule_ReplyWithLongLong(ctx, -1);",
          "681:             }",
          "",
          "---------------"
        ],
        "src/rm_cms.c||src/rm_cms.c": [
          "File: src/rm_cms.c -> src/rm_cms.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "91:         return REDISMODULE_OK;",
          "93:     cms = NewCMSketch(width, depth);",
          "94:     RedisModule_ModuleTypeSetValue(key, CMSketchType, cms);",
          "96:     RedisModule_CloseKey(key);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "94:     if (!cms) {",
          "95:         RedisModule_CloseKey(key);",
          "96:         RedisModule_ReplyWithError(ctx, \"CMS: Insufficient memory to create the key\");",
          "97:         return REDISMODULE_OK;",
          "98:     }",
          "",
          "---------------"
        ],
        "src/rm_topk.c||src/rm_topk.c": [
          "File: src/rm_topk.c -> src/rm_topk.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "46:         INNER_ERROR(\"TopK: invalid k\");",
          "47:     }",
          "48:     if (argc == 6) {",
          "50:             INNER_ERROR(\"TopK: invalid width\");",
          "51:         }",
          "53:             INNER_ERROR(\"TopK: invalid depth\");",
          "54:         }",
          "55:         if ((RedisModule_StringToDouble(argv[5], &decay) != REDISMODULE_OK) ||",
          "",
          "[Removed Lines]",
          "49:         if ((RedisModule_StringToLongLong(argv[3], &width) != REDISMODULE_OK) || width < 1) {",
          "52:         if ((RedisModule_StringToLongLong(argv[4], &depth) != REDISMODULE_OK) || depth < 1) {",
          "",
          "[Added Lines]",
          "49:         if ((RedisModule_StringToLongLong(argv[3], &width) != REDISMODULE_OK) || width < 1 ||",
          "50:             width > UINT32_MAX) {",
          "53:         if ((RedisModule_StringToLongLong(argv[4], &depth) != REDISMODULE_OK) || depth < 1 ||",
          "54:             depth > UINT32_MAX) {",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "62:         decay = 0.9;",
          "63:     }",
          "65:     return REDISMODULE_OK;",
          "66: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "67:     if (!(*topk)) {",
          "68:         INNER_ERROR(\"ERR Insufficient memory to create topk data structure\");",
          "69:     }",
          "",
          "---------------"
        ],
        "src/topk.c||src/topk.c": [
          "File: src/topk.c -> src/topk.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "67:     assert(depth > 0);",
          "68:     assert(decay > 0 && decay <= 1);",
          "70:     TopK *topk = (TopK *)TOPK_CALLOC(1, sizeof(TopK));",
          "71:     topk->k = k;",
          "72:     topk->width = width;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "70:     if (depth > SIZE_MAX / width || (size_t)depth * width > SIZE_MAX / sizeof(Bucket)) {",
          "71:         return NULL;",
          "72:     }",
          "",
          "---------------"
        ],
        "tests/flow/test_cms.py||tests/flow/test_cms.py": [
          "File: tests/flow/test_cms.py -> tests/flow/test_cms.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "49:                 ('foo', '0', '0'),",
          "50:                 ('foo', '0', '100'),",
          "51:                 ('foo', '100', '0'),",
          "52:         ):",
          "53:             self.assertRaises(ResponseError, self.cmd, 'cms.initbydim', *args)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "52:                 ('foo', '8589934592', '8589934592'),",
          "53:                 ('foo', '4611686018427388100', '1'),",
          "54:                 ('foo', '2', '2611686018427388100'),",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "66:                 ('foo', '0', '0'),",
          "67:                 ('foo', '1000', '0',),",
          "68:                 ('foo', '0', '100'),",
          "69:         ):",
          "70:             self.assertRaises(ResponseError, self.cmd, 'cms.initbyprob', *args)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "72:                 ('foo', '0.9', '0.9999999999999999'),",
          "73:                 ('foo', '0.0000000000000000001', '0.9'),",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "163:         self.assertRaises(ResponseError, self.cmd, 'cms.merge', 'foo', 'A', 'foo', 'weights', 1)",
          "164:         self.assertRaises(ResponseError, self.cmd, 'cms.merge', 'foo', 3, 'bar', 'baz' 'weights', 1, 'a')",
          "165:         self.assertRaises(ResponseError, self.cmd, 'cms.merge', 'foo', 3, 'bar', 'baz' 'weights', 1)",
          "167:     def test_merge_extensive(self):",
          "168:         self.cmd('FLUSHALL')",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "171:         self.assertRaises(ResponseError, self.cmd, 'cms.merge', 'foo', '0')",
          "172:         self.assertRaises(ResponseError, self.cmd, 'cms.merge', 'foo', '0', 'weights')",
          "173:         self.assertRaises(ResponseError, self.cmd, 'cms.merge', 'foo', '-1')",
          "174:         self.assertRaises(ResponseError, self.cmd, 'cms.merge', 'foo', '-1', 'foo', 'bar')",
          "175:         self.assertRaises(ResponseError, self.cmd, 'cms.merge', 'foo', '-1', 'foo', 'bar', 'weights', 1, 1)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "383:         self.assertEqual(['width', 2, 'depth', 2, 'count', 8], self.cmd('cms.info', 'cms1{t}'))",
          "384:         self.assertEqual([8], self.cmd('cms.query', 'cms1{t}', 'foo'))",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "396:     def test_insufficient_memory(self):",
          "397:         self.cmd('FLUSHALL')",
          "398:         self.env.expect('CMS.INITBYDIM',  'x', '4611686018427388100', '1').error().contains('CMS: Insufficient memory to create the key')",
          "",
          "---------------"
        ],
        "tests/flow/test_cuckoo.py||tests/flow/test_cuckoo.py": [
          "File: tests/flow/test_cuckoo.py -> tests/flow/test_cuckoo.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "634:             except Exception as e:",
          "635:                 if str(e) != \"Couldn't load chunk!\":",
          "636:                     raise e",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "638:     def test_insufficient_memory(self):",
          "639:         self.cmd('FLUSHALL')",
          "640:         self.env.expect('cf.reserve', 'cf', '9223372036854775807').error().contains('Insufficient memory to create filter')",
          "",
          "---------------"
        ],
        "tests/flow/test_overall.py||tests/flow/test_overall.py": [
          "File: tests/flow/test_overall.py -> tests/flow/test_overall.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "756:                 env.cmd('bf.loadchunk', 'bf', random.randint(0, size), bytes(b))",
          "757:             except Exception as e:",
          "758:                 if (str(e) != \"invalid offset - no link found\" and",
          "759:                         str(e) != \"received bad data\"):",
          "760:                     raise e",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "759:                         str(e) != \"invalid chunk - Too big for current filter\" and",
          "",
          "---------------"
        ],
        "tests/flow/test_topk.py||tests/flow/test_topk.py": [
          "File: tests/flow/test_topk.py -> tests/flow/test_topk.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "220:         heapList = self.cmd('topk.list', 'topk', 'WITHCOUNT')",
          "221:         self.assertEqual(['foo', 504, 'bar', 503, 'baz', 502], heapList)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "223:     def test_insufficient_memory(self):",
          "224:         self.cmd('FLUSHALL')",
          "226:         self.env.expect('topk.reserve', 'x', '3', '4294967295', '4294967295', '1').error().contains('Insufficient memory to create topk data structure')",
          "227:         self.env.expect('topk.reserve', 'x', '3', '900000000000', '1', '1').error().contains('TopK: invalid width')",
          "228:         self.env.expect('topk.reserve', 'x', '3', '1', '900000000000', '1').error().contains('TopK: invalid depth')",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "e838ebad94d1af71d961e41e06c411bc5d608ad2",
      "candidate_info": {
        "commit_hash": "e838ebad94d1af71d961e41e06c411bc5d608ad2",
        "repo": "RedisBloom/RedisBloom",
        "commit_url": "https://github.com/RedisBloom/RedisBloom/commit/e838ebad94d1af71d961e41e06c411bc5d608ad2",
        "files": [
          "src/cf.c",
          "src/cms.c",
          "src/cuckoo.c",
          "src/cuckoo.h",
          "src/rebloom.c",
          "src/rm_cms.c",
          "src/rm_topk.c",
          "src/topk.c",
          "tests/flow/test_cms.py",
          "tests/flow/test_cuckoo.py",
          "tests/flow/test_overall.py",
          "tests/flow/test_topk.py"
        ],
        "message": "Backport allocation overflow checks (#16)\n\n(cherry picked from commit 2114a6b0872f96bddace8af1c81c82621365e2ed)",
        "before_after_code_files": [
          "src/cf.c||src/cf.c",
          "src/cms.c||src/cms.c",
          "src/cuckoo.c||src/cuckoo.c",
          "src/cuckoo.h||src/cuckoo.h",
          "src/rebloom.c||src/rebloom.c",
          "src/rm_cms.c||src/rm_cms.c",
          "src/rm_topk.c||src/rm_topk.c",
          "src/topk.c||src/topk.c",
          "tests/flow/test_cms.py||tests/flow/test_cms.py",
          "tests/flow/test_cuckoo.py||tests/flow/test_cuckoo.py",
          "tests/flow/test_overall.py||tests/flow/test_overall.py",
          "tests/flow/test_topk.py||tests/flow/test_topk.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "src/rebloom.c||src/rebloom.c",
            "tests/flow/test_cuckoo.py||tests/flow/test_cuckoo.py"
          ],
          "candidate": [
            "src/rebloom.c||src/rebloom.c",
            "tests/flow/test_cuckoo.py||tests/flow/test_cuckoo.py"
          ]
        }
      },
      "candidate_diff": {
        "src/cf.c||src/cf.c": [
          "File: src/cf.c -> src/cf.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "132:         SubCF *cur = filter->filters + ii;",
          "133:         cur->bucketSize = header->bucketSize;",
          "134:         cur->numBuckets = filter->numBuckets * pow(filter->expansion, ii);",
          "135:         cur->data =",
          "136:             RedisModule_Calloc((size_t)cur->numBuckets * filter->bucketSize, sizeof(CuckooBucket));",
          "137:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "136:         if (cur->numBuckets != 0 && filter->bucketSize > SIZE_MAX / cur->numBuckets) {",
          "137:             goto error;",
          "138:         }",
          "",
          "---------------"
        ],
        "src/cms.c||src/cms.c": [
          "File: src/cms.c -> src/cms.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "21:     assert(width > 0);",
          "22:     assert(depth > 0);",
          "24:     CMSketch *cms = CMS_CALLOC(1, sizeof(CMSketch));",
          "26:     cms->width = width;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "24:     if (width > SIZE_MAX / depth || width * depth > SIZE_MAX / sizeof(uint32_t)) {",
          "25:         return NULL;",
          "26:     }",
          "",
          "---------------"
        ],
        "src/cuckoo.c||src/cuckoo.c": [
          "File: src/cuckoo.c -> src/cuckoo.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "56: }",
          "58: void CuckooFilter_Free(CuckooFilter *filter) {",
          "59:     for (uint16_t ii = 0; ii < filter->numFilters; ++ii) {",
          "60:         CUCKOO_FREE(filter->filters[ii].data);",
          "61:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "59:     if (!filter) {",
          "60:         return;",
          "61:     }",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "69:     if (!filtersArray) {",
          "70:         return -1; // LCOV_EXCL_LINE memory failure",
          "71:     }",
          "72:     SubCF *currentFilter = filtersArray + filter->numFilters;",
          "73:     size_t growth = pow(filter->expansion, filter->numFilters);",
          "75:     currentFilter->numBuckets = filter->numBuckets * growth;",
          "76:     currentFilter->data =",
          "77:         CUCKOO_CALLOC((size_t)currentFilter->numBuckets * filter->bucketSize, sizeof(CuckooBucket));",
          "78:     if (!currentFilter->data) {",
          "",
          "[Removed Lines]",
          "74:     currentFilter->bucketSize = filter->bucketSize;",
          "",
          "[Added Lines]",
          "76:     filter->filters = filtersArray;",
          "79:         .bucketSize = filter->bucketSize,",
          "80:         .data = NULL",
          "81:     };",
          "86:     if (filter->numBuckets != 0 && growth > CF_MAX_NUM_BUCKETS / filter->numBuckets) {",
          "87:         return -1;",
          "88:     }",
          "93:     if (currentFilter->numBuckets != 0 && filter->bucketSize > SIZE_MAX / currentFilter->numBuckets) {",
          "94:         return -1;",
          "95:     }",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "80:     }",
          "82:     filter->numFilters++;",
          "84:     return 0;",
          "85: }",
          "",
          "[Removed Lines]",
          "83:     filter->filters = filtersArray;",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "src/cuckoo.h||src/cuckoo.h": [
          "File: src/cuckoo.h -> src/cuckoo.h",
          "--- Hunk 1 ---",
          "[Context before]",
          "71:     CuckooInsert_MemAllocFailed = -2",
          "72: } CuckooInsertStatus;",
          "74: int CuckooFilter_Init(CuckooFilter *filter, uint64_t capacity, uint16_t bucketSize,",
          "75:                       uint16_t maxIterations, uint16_t expansion);",
          "76: void CuckooFilter_Free(CuckooFilter *filter);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "74: enum CuckooRc {",
          "75:     CUCKOO_OK = 0,",
          "76:     CUCKOO_ERR = -1,",
          "77:     CUCKOO_OOM = -2,",
          "78: };",
          "",
          "---------------"
        ],
        "src/rebloom.c||src/rebloom.c": [
          "File: src/rebloom.c -> src/rebloom.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "105: }",
          "107: static CuckooFilter *cfCreate(RedisModuleKey *key, size_t capacity, uint16_t bucketSize,",
          "110:         return NULL;",
          "112:     CuckooFilter *cf = RedisModule_Calloc(1, sizeof(*cf));",
          "113:     if (CuckooFilter_Init(cf, capacity, bucketSize, maxIterations, expansion) != 0) {",
          "116:     }",
          "117:     RedisModule_ModuleTypeSetValue(key, CFType, cf);",
          "118:     return cf;",
          "",
          "[Removed Lines]",
          "108:                               uint16_t maxIterations, uint16_t expansion) {",
          "109:     if (capacity < bucketSize * 2)",
          "114:         RedisModule_Free(cf); // LCOV_EXCL_LINE",
          "115:         cf = NULL;            // LCOV_EXCL_LINE",
          "",
          "[Added Lines]",
          "108:                               uint16_t maxIterations, uint16_t expansion, int *err) {",
          "111:     if (capacity < bucketSize * 2) {",
          "114:     }",
          "118:         CuckooFilter_Free(cf);",
          "119:         RedisModule_Free(cf);",
          "121:         return NULL;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "570:         return RedisModule_ReplyWithError(ctx, statusStrerror(status));",
          "571:     }",
          "574:     if (cf == NULL) {",
          "576:     } else {",
          "577:         RedisModule_ReplicateVerbatim(ctx);",
          "578:         return RedisModule_ReplyWithSimpleString(ctx, \"OK\");",
          "",
          "[Removed Lines]",
          "573:     cf = cfCreate(key, capacity, bucketSize, maxIterations, expansion);",
          "575:         return RedisModule_ReplyWithError(ctx, \"Couldn't create Cuckoo Filter\"); // LCOV_EXCL_LINE",
          "",
          "[Added Lines]",
          "579:     int err = CUCKOO_OK;",
          "580:     cf = cfCreate(key, capacity, bucketSize, maxIterations, expansion, &err);",
          "582:         if (err == CUCKOO_OOM) {",
          "583:             RedisModule_ReplyWithError(ctx, \"ERR Insufficient memory to create filter\");",
          "584:         } else {",
          "585:             RedisModule_ReplyWithError(ctx, \"ERR Could not create filter\");",
          "586:         }",
          "587:         return REDISMODULE_OK;",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "593:     int status = cfGetFilter(key, &cf);",
          "595:     if (status == SB_EMPTY && options->autocreate) {",
          "596:         if ((cf = cfCreate(key, options->capacity, CF_DEFAULT_BUCKETSIZE, CF_DEFAULT_MAX_ITERATIONS,",
          "599:         }",
          "600:     } else if (status != SB_OK) {",
          "601:         return RedisModule_ReplyWithError(ctx, statusStrerror(status));",
          "",
          "[Removed Lines]",
          "597:                            CF_DEFAULT_EXPANSION)) == NULL) {",
          "598:             return RedisModule_ReplyWithError(ctx, \"Could not create filter\"); // LCOV_EXCL_LINE",
          "",
          "[Added Lines]",
          "608:         int err = CUCKOO_OK;",
          "610:                            CF_DEFAULT_EXPANSION, &err)) == NULL) {",
          "611:             if (err == CUCKOO_OOM) {",
          "612:                 RedisModule_ReplyWithError(ctx, \"ERR Insufficient memory to create filter\");",
          "613:             } else {",
          "614:                 RedisModule_ReplyWithError(ctx, \"ERR Could not create filter\");",
          "615:             }",
          "616:             return REDISMODULE_OK;",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "656:             }",
          "657:             break;",
          "658:         case CuckooInsert_MemAllocFailed:",
          "660:             break;",
          "661:         default:",
          "662:             break;",
          "",
          "[Removed Lines]",
          "659:             RedisModule_ReplyWithError(ctx, \"Memory allocation failure\"); // LCOV_EXCL_LINE",
          "",
          "[Added Lines]",
          "677:             if (!options->is_multi) {",
          "678:                 RedisModule_ReplyWithError(ctx, \"Memory allocation failure\"); // LCOV_EXCL_LINE",
          "679:             } else {",
          "680:                 RedisModule_ReplyWithLongLong(ctx, -1);",
          "681:             }",
          "",
          "---------------"
        ],
        "src/rm_cms.c||src/rm_cms.c": [
          "File: src/rm_cms.c -> src/rm_cms.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "96:         return REDISMODULE_OK;",
          "98:     cms = NewCMSketch(width, depth);",
          "99:     RedisModule_ModuleTypeSetValue(key, CMSketchType, cms);",
          "101:     RedisModule_CloseKey(key);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "99:     if (!cms) {",
          "100:         RedisModule_CloseKey(key);",
          "101:         RedisModule_ReplyWithError(ctx, \"CMS: Insufficient memory to create the key\");",
          "102:         return REDISMODULE_OK;",
          "103:     }",
          "",
          "---------------"
        ],
        "src/rm_topk.c||src/rm_topk.c": [
          "File: src/rm_topk.c -> src/rm_topk.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "46:         INNER_ERROR(\"TopK: invalid k\");",
          "47:     }",
          "48:     if (argc == 6) {",
          "50:             INNER_ERROR(\"TopK: invalid width\");",
          "51:         }",
          "53:             INNER_ERROR(\"TopK: invalid depth\");",
          "54:         }",
          "55:         if ((RedisModule_StringToDouble(argv[5], &decay) != REDISMODULE_OK) ||",
          "",
          "[Removed Lines]",
          "49:         if ((RedisModule_StringToLongLong(argv[3], &width) != REDISMODULE_OK) || width < 1) {",
          "52:         if ((RedisModule_StringToLongLong(argv[4], &depth) != REDISMODULE_OK) || depth < 1) {",
          "",
          "[Added Lines]",
          "49:         if ((RedisModule_StringToLongLong(argv[3], &width) != REDISMODULE_OK) || width < 1 ||",
          "50:             width > UINT32_MAX) {",
          "53:         if ((RedisModule_StringToLongLong(argv[4], &depth) != REDISMODULE_OK) || depth < 1 ||",
          "54:             depth > UINT32_MAX) {",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "62:         decay = 0.9;",
          "63:     }",
          "65:     return REDISMODULE_OK;",
          "66: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "67:     if (!(*topk)) {",
          "68:         INNER_ERROR(\"ERR Insufficient memory to create topk data structure\");",
          "69:     }",
          "",
          "---------------"
        ],
        "src/topk.c||src/topk.c": [
          "File: src/topk.c -> src/topk.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "67:     assert(depth > 0);",
          "68:     assert(decay > 0 && decay <= 1);",
          "70:     TopK *topk = (TopK *)TOPK_CALLOC(1, sizeof(TopK));",
          "71:     topk->k = k;",
          "72:     topk->width = width;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "70:     if (depth > SIZE_MAX / width || (size_t)depth * width > SIZE_MAX / sizeof(Bucket)) {",
          "71:         return NULL;",
          "72:     }",
          "",
          "---------------"
        ],
        "tests/flow/test_cms.py||tests/flow/test_cms.py": [
          "File: tests/flow/test_cms.py -> tests/flow/test_cms.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "50:                 ('foo', '0', '100'),",
          "51:                 ('foo', '100', '0'),",
          "52:                 ('foo', '8589934592', '8589934592'),",
          "53:         ):",
          "54:             self.assertRaises(ResponseError, self.cmd, 'cms.initbydim', *args)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "53:                 ('foo', '4611686018427388100', '1'),",
          "54:                 ('foo', '2', '2611686018427388100'),",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "391:         self.assertEqual(['width', 2, 'depth', 2, 'count', 8], self.cmd('cms.info', 'cms1{t}'))",
          "392:         self.assertEqual([8], self.cmd('cms.query', 'cms1{t}', 'foo'))",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "396:     def test_insufficient_memory(self):",
          "397:         self.cmd('FLUSHALL')",
          "398:         self.env.expect('CMS.INITBYDIM',  'x', '4611686018427388100', '1').error().contains('CMS: Insufficient memory to create the key')",
          "",
          "---------------"
        ],
        "tests/flow/test_cuckoo.py||tests/flow/test_cuckoo.py": [
          "File: tests/flow/test_cuckoo.py -> tests/flow/test_cuckoo.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "634:             except Exception as e:",
          "635:                 if str(e) != \"Couldn't load chunk!\":",
          "636:                     raise e",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "638:     def test_insufficient_memory(self):",
          "639:         self.cmd('FLUSHALL')",
          "640:         self.env.expect('cf.reserve', 'cf', '9223372036854775807').error().contains('Insufficient memory to create filter')",
          "",
          "---------------"
        ],
        "tests/flow/test_overall.py||tests/flow/test_overall.py": [
          "File: tests/flow/test_overall.py -> tests/flow/test_overall.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "756:                 env.cmd('bf.loadchunk', 'bf', random.randint(0, size), bytes(b))",
          "757:             except Exception as e:",
          "758:                 if (str(e) != \"invalid offset - no link found\" and",
          "760:                     raise e",
          "",
          "[Removed Lines]",
          "759:                         str(e) != \"received bad data\" and str(e) != \"invalid chunk - Too big for current filter\"):",
          "",
          "[Added Lines]",
          "759:                         str(e) != \"invalid chunk - Too big for current filter\" and",
          "760:                         str(e) != \"received bad data\"):",
          "",
          "---------------"
        ],
        "tests/flow/test_topk.py||tests/flow/test_topk.py": [
          "File: tests/flow/test_topk.py -> tests/flow/test_topk.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "220:         heapList = self.cmd('topk.list', 'topk', 'WITHCOUNT')",
          "221:         self.assertEqual(['foo', 504, 'bar', 503, 'baz', 502], heapList)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "223:     def test_insufficient_memory(self):",
          "224:         self.cmd('FLUSHALL')",
          "226:         self.env.expect('topk.reserve', 'x', '3', '4294967295', '4294967295', '1').error().contains('Insufficient memory to create topk data structure')",
          "227:         self.env.expect('topk.reserve', 'x', '3', '900000000000', '1', '1').error().contains('TopK: invalid width')",
          "228:         self.env.expect('topk.reserve', 'x', '3', '1', '900000000000', '1').error().contains('TopK: invalid depth')",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "f0868939cc83edfda40ee1dc7456f09985363b01",
      "candidate_info": {
        "commit_hash": "f0868939cc83edfda40ee1dc7456f09985363b01",
        "repo": "RedisBloom/RedisBloom",
        "commit_url": "https://github.com/RedisBloom/RedisBloom/commit/f0868939cc83edfda40ee1dc7456f09985363b01",
        "files": [
          "src/rebloom.c",
          "tests/flow/test_cuckoo.py"
        ],
        "message": "MOD-6343 Fix potential crash for cf.reserve (#724)\n\n* Enforce limits for cf.reserve arguments\n\n* comment\n\n* comment-2",
        "before_after_code_files": [
          "src/rebloom.c||src/rebloom.c",
          "tests/flow/test_cuckoo.py||tests/flow/test_cuckoo.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "src/rebloom.c||src/rebloom.c",
            "tests/flow/test_cuckoo.py||tests/flow/test_cuckoo.py"
          ],
          "candidate": [
            "src/rebloom.c||src/rebloom.c",
            "tests/flow/test_cuckoo.py||tests/flow/test_cuckoo.py"
          ]
        }
      },
      "candidate_diff": {
        "src/rebloom.c||src/rebloom.c": [
          "File: src/rebloom.c -> src/rebloom.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "25: #define REDISBLOOM_GIT_SHA \"unknown\"",
          "26: #endif",
          "29: #define CF_DEFAULT_BUCKETSIZE 2",
          "30: #define CF_DEFAULT_EXPANSION 1",
          "31: #define BF_DEFAULT_EXPANSION 2",
          "",
          "[Removed Lines]",
          "28: #define CF_MAX_ITERATIONS 20",
          "",
          "[Added Lines]",
          "28: #define CF_DEFAULT_MAX_ITERATIONS 20",
          "31: #define CF_MAX_EXPANSION 32768",
          "32: #define CF_MAX_BUCKET_SIZE 255",
          "33: #define CF_MAX_ITERATIONS 65535",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "108:     return sb;",
          "109: }",
          "113:     if (capacity < bucketSize * 2)",
          "114:         return NULL;",
          "",
          "[Removed Lines]",
          "111: static CuckooFilter *cfCreate(RedisModuleKey *key, size_t capacity, size_t bucketSize,",
          "112:                               size_t maxIterations, size_t expansion) {",
          "",
          "[Added Lines]",
          "114: static CuckooFilter *cfCreate(RedisModuleKey *key, size_t capacity, uint16_t bucketSize,",
          "115:                               uint16_t maxIterations, uint16_t expansion) {",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "532:         return RedisModule_ReplyWithError(ctx, \"Bad capacity\");",
          "533:     }",
          "536:     int mi_loc = RMUtil_ArgIndex(\"MAXITERATIONS\", argv, argc);",
          "537:     if (mi_loc != -1) {",
          "538:         if (RedisModule_StringToLongLong(argv[mi_loc + 1], &maxIterations) != REDISMODULE_OK) {",
          "539:             return RedisModule_ReplyWithError(ctx, \"Couldn't parse MAXITERATIONS\");",
          "541:             return RedisModule_ReplyWithError(",
          "543:         }",
          "544:     }",
          "",
          "[Removed Lines]",
          "535:     long long maxIterations = CF_MAX_ITERATIONS;",
          "540:         } else if (maxIterations <= 0) {",
          "542:                 ctx, \"MAXITERATIONS parameter needs to be a positive integer\");",
          "",
          "[Added Lines]",
          "538:     long long maxIterations = CF_DEFAULT_MAX_ITERATIONS;",
          "543:         } else if (maxIterations <= 0 || maxIterations > CF_MAX_ITERATIONS) {",
          "545:                 ctx, \"MAXITERATIONS: value must be an integer between 1 and 65535, inclusive.\");",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "548:     if (bs_loc != -1) {",
          "549:         if (RedisModule_StringToLongLong(argv[bs_loc + 1], &bucketSize) != REDISMODULE_OK) {",
          "550:             return RedisModule_ReplyWithError(ctx, \"Couldn't parse BUCKETSIZE\");",
          "552:             return RedisModule_ReplyWithError(",
          "554:         }",
          "555:     }",
          "",
          "[Removed Lines]",
          "551:         } else if (bucketSize <= 0) {",
          "553:                 ctx, \"BUCKETSIZE parameter needs to be a positive integer\");",
          "",
          "[Added Lines]",
          "554:         } else if (bucketSize <= 0 || bucketSize > CF_MAX_BUCKET_SIZE) {",
          "556:                 ctx, \"BUCKETSIZE: value must be an integer between 1 and 255, inclusive.\");",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "559:     if (ex_loc != -1) {",
          "560:         if (RedisModule_StringToLongLong(argv[ex_loc + 1], &expansion) != REDISMODULE_OK) {",
          "561:             return RedisModule_ReplyWithError(ctx, \"Couldn't parse EXPANSION\");",
          "563:             return RedisModule_ReplyWithError(",
          "565:         }",
          "566:     }",
          "",
          "[Removed Lines]",
          "562:         } else if (expansion < 0) {",
          "564:                 ctx, \"EXPANSION parameter needs to be a non-negative integer\");",
          "",
          "[Added Lines]",
          "565:         } else if (expansion < 0 || expansion > CF_MAX_EXPANSION) {",
          "567:                 ctx, \"EXPANSION: value must be an integer between 0 and 32768, inclusive.\");",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "599:     int status = cfGetFilter(key, &cf);",
          "601:     if (status == SB_EMPTY && options->autocreate) {",
          "603:                            CF_DEFAULT_EXPANSION)) == NULL) {",
          "604:             return RedisModule_ReplyWithError(ctx, \"Could not create filter\"); // LCOV_EXCL_LINE",
          "605:         }",
          "",
          "[Removed Lines]",
          "602:         if ((cf = cfCreate(key, options->capacity, CF_DEFAULT_BUCKETSIZE, CF_MAX_ITERATIONS,",
          "",
          "[Added Lines]",
          "605:         if ((cf = cfCreate(key, options->capacity, CF_DEFAULT_BUCKETSIZE, CF_DEFAULT_MAX_ITERATIONS,",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "1256:     if (encver < CF_MIN_EXPANSION_VERSION) { // CF_ENCODING_VERSION when added",
          "1257:         cf->numDeletes = 0;                  // Didn't exist earlier. bug fix",
          "1258:         cf->bucketSize = CF_DEFAULT_BUCKETSIZE;",
          "1260:         cf->expansion = CF_DEFAULT_EXPANSION;",
          "1261:     } else {",
          "1262:         cf->numDeletes = RedisModule_LoadUnsigned(io);",
          "",
          "[Removed Lines]",
          "1259:         cf->maxIterations = CF_MAX_ITERATIONS;",
          "",
          "[Added Lines]",
          "1262:         cf->maxIterations = CF_DEFAULT_MAX_ITERATIONS;",
          "",
          "---------------"
        ],
        "tests/flow/test_cuckoo.py||tests/flow/test_cuckoo.py": [
          "File: tests/flow/test_cuckoo.py -> tests/flow/test_cuckoo.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "346:         self.assertRaises(ResponseError, self.cmd, 'CF.LOADCHUNK err iterator') # missing data",
          "347:         self.assertRaises(ResponseError, self.cmd, 'CF.SCANDUMP err')",
          "349: class testCuckooNoCodec():",
          "350:     def __init__(self):",
          "351:         self.env = Env(decodeResponses=False)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "349:     def test_reserve_limits(self):",
          "350:         self.cmd('FLUSHALL')",
          "351:         self.assertRaises(ResponseError, self.cmd, 'CF.RESERVE cf 100 BUCKETSIZE 33554432')",
          "352:         self.assertRaises(ResponseError, self.cmd, 'CF.RESERVE cf 100 MAXITERATIONS 165536')",
          "353:         self.assertRaises(ResponseError, self.cmd, 'CF.RESERVE cf 100 EXPANSION 327695')",
          "354:         self.assertRaises(ResponseError, self.cmd, 'CF.RESERVE CF 67108864 BUCKETSIZE 33554432 MAXITERATIONS 1337 EXPANSION 1337')",
          "356:         self.cmd('CF.RESERVE cf 67108864 BUCKETSIZE 255 MAXITERATIONS 65535 EXPANSION 32768')",
          "357:         info = self.cmd('CF.INFO cf')",
          "358:         self.assertEqual(info[info.index('Bucket size') + 1], 255)",
          "359:         self.assertEqual(info[info.index('Expansion rate') + 1], 32768)",
          "360:         self.assertEqual(info[info.index('Max iterations') + 1], 65535)",
          "",
          "---------------"
        ]
      }
    }
  ]
}