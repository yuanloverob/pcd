{
  "cve_id": "CVE-2024-4030",
  "cve_desc": "On Windows a directory returned by tempfile.mkdtemp() would not always have permissions set to restrict reading and writing to the temporary directory by other users, instead usually inheriting the correct permissions from the default location. Alternate configurations or users without a profile directory may not have the intended permissions.\n\nIf you\u2019re not using Windows or haven\u2019t changed the temporary directory location then you aren\u2019t affected by this vulnerability. On other platforms the returned directory is consistently readable and writable only by the current user.\n\nThis issue was caused by Python not supporting Unix permissions on Windows. The fix adds support for Unix \u201c700\u201d for the mkdir function on Windows which is used by mkdtemp() to ensure the newly created directory has the proper permissions.",
  "repo": "python/cpython",
  "patch_hash": "d86b49411753bf2c83291e3a14ae43fefded2f84",
  "patch_info": {
    "commit_hash": "d86b49411753bf2c83291e3a14ae43fefded2f84",
    "repo": "python/cpython",
    "commit_url": "https://github.com/python/cpython/commit/d86b49411753bf2c83291e3a14ae43fefded2f84",
    "files": [
      "Doc/whatsnew/3.13.rst",
      "Misc/NEWS.d/next/Security/2024-05-01-20-57-09.gh-issue-118486.K44KJG.rst"
    ],
    "message": "gh-118486: Update docs for CVE-2024-4030 reference (GH-118737)\n\nUpdate docs for CVE-2024-4030 reference",
    "before_after_code_files": []
  },
  "patch_diff": {},
  "candidates": [
    {
      "candidate_hash": "e04809299fc1a5f0ff0b567173439cb0b6f8e907",
      "candidate_info": {
        "commit_hash": "e04809299fc1a5f0ff0b567173439cb0b6f8e907",
        "repo": "python/cpython",
        "commit_url": "https://github.com/python/cpython/commit/e04809299fc1a5f0ff0b567173439cb0b6f8e907",
        "files": [
          "Modules/_sre/sre.c"
        ],
        "message": "[3.13] gh-120155: Add assertion to sre.c match_getindex() (GH-120402) (#120409)\n\ngh-120155: Add assertion to sre.c match_getindex() (GH-120402)\n\nAdd an assertion to help static analyzers to detect that i*2 cannot\noverflow.\n(cherry picked from commit 42b25dd61ff3593795c4cc2ffe876ab766098b24)\n\nCo-authored-by: Victor Stinner <vstinner@python.org>",
        "before_after_code_files": [
          "Modules/_sre/sre.c||Modules/_sre/sre.c"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/AcreetionOS-Linux/python/pull/2"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "Modules/_sre/sre.c||Modules/_sre/sre.c": [
          "File: Modules/_sre/sre.c -> Modules/_sre/sre.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "2217:         return -1;",
          "2218:     }",
          "2220:     return i;",
          "2221: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "2221:     assert(i <= SRE_MAXGROUPS);",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "7c6b3429b631d80de0348e5ddc2a3a8125e5c00d",
      "candidate_info": {
        "commit_hash": "7c6b3429b631d80de0348e5ddc2a3a8125e5c00d",
        "repo": "python/cpython",
        "commit_url": "https://github.com/python/cpython/commit/7c6b3429b631d80de0348e5ddc2a3a8125e5c00d",
        "files": [
          "Lib/test/test_tokenize.py",
          "Python/Python-tokenize.c"
        ],
        "message": "[3.13] gh-120343: Fix column offsets of multiline tokens in tokenize (GH-120391) (#120427)\n\n(cherry picked from commit 4b5d3e0e721a952f4ac9d17bee331e6dfe543dcd)\n\nCo-authored-by: Lysandros Nikolaou <lisandrosnik@gmail.com>",
        "before_after_code_files": [
          "Lib/test/test_tokenize.py||Lib/test/test_tokenize.py",
          "Python/Python-tokenize.c||Python/Python-tokenize.c"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/AcreetionOS-Linux/python/pull/2"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "Lib/test/test_tokenize.py||Lib/test/test_tokenize.py": [
          "File: Lib/test/test_tokenize.py -> Lib/test/test_tokenize.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1210:     FSTRING_END \"\\'\\'\\'\"         (2, 68) (2, 71)",
          "1211:     \"\"\")",
          "1213: class GenerateTokensTest(TokenizeTest):",
          "1214:     def check_tokenize(self, s, expected):",
          "1215:         # Format the tokens in s in a table format.",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1213:     def test_multiline_non_ascii_fstring_with_expr(self):",
          "1214:         self.check_tokenize(\"\"\"\\",
          "1215: f'''",
          "1216:     \ud83d\udd17 This is a test {test_arg1}\ud83d\udd17",
          "1217: \ud83d\udd17'''\"\"\", \"\"\"\\",
          "1218:     FSTRING_START \"f\\'\\'\\'\"        (1, 0) (1, 4)",
          "1219:     FSTRING_MIDDLE '\\\\n    \ud83d\udd17 This is a test ' (1, 4) (2, 21)",
          "1220:     OP         '{'           (2, 21) (2, 22)",
          "1221:     NAME       'test_arg1'   (2, 22) (2, 31)",
          "1222:     OP         '}'           (2, 31) (2, 32)",
          "1223:     FSTRING_MIDDLE '\ud83d\udd17\\\\n\ud83d\udd17'        (2, 32) (3, 1)",
          "1224:     FSTRING_END \"\\'\\'\\'\"         (3, 1) (3, 4)",
          "1225:     \"\"\")",
          "",
          "---------------"
        ],
        "Python/Python-tokenize.c||Python/Python-tokenize.c": [
          "File: Python/Python-tokenize.c -> Python/Python-tokenize.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "216:     const char *line_start = ISSTRINGLIT(type) ? it->tok->multi_line_start : it->tok->line_start;",
          "217:     PyObject* line = NULL;",
          "218:     if (it->tok->tok_extra_tokens && is_trailing_token) {",
          "219:         line = PyUnicode_FromString(\"\");",
          "220:     } else {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "218:     int line_changed = 1;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "229:             Py_XDECREF(it->last_line);",
          "230:             line = PyUnicode_DecodeUTF8(line_start, size, \"replace\");",
          "231:             it->last_line = line;",
          "235:         } else {",
          "237:             line = it->last_line;",
          "238:         }",
          "239:     }",
          "240:     if (line == NULL) {",
          "",
          "[Removed Lines]",
          "232:             if (it->tok->lineno != it->last_end_lineno) {",
          "233:                 it->byte_col_offset_diff = 0;",
          "234:             }",
          "",
          "[Added Lines]",
          "233:             it->byte_col_offset_diff = 0;",
          "237:             line_changed = 0;",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "252:     Py_ssize_t byte_offset = -1;",
          "253:     if (token.start != NULL && token.start >= line_start) {",
          "254:         byte_offset = token.start - line_start;",
          "256:     }",
          "257:     if (token.end != NULL && token.end >= it->tok->line_start) {",
          "258:         Py_ssize_t end_byte_offset = token.end - it->tok->line_start;",
          "",
          "[Removed Lines]",
          "255:         col_offset = byte_offset - it->byte_col_offset_diff;",
          "",
          "[Added Lines]",
          "255:         if (line_changed) {",
          "256:             col_offset = _PyPegen_byte_offset_to_character_offset_line(line, 0, byte_offset);",
          "257:             it->byte_col_offset_diff = byte_offset - col_offset;",
          "258:         }",
          "259:         else {",
          "260:             col_offset = byte_offset - it->byte_col_offset_diff;",
          "261:         }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "51bcb67405cceee1f18067fb2ae510dec47191bc",
      "candidate_info": {
        "commit_hash": "51bcb67405cceee1f18067fb2ae510dec47191bc",
        "repo": "python/cpython",
        "commit_url": "https://github.com/python/cpython/commit/51bcb67405cceee1f18067fb2ae510dec47191bc",
        "files": [
          "Lib/test/test_tokenize.py",
          "Misc/NEWS.d/next/Library/2024-06-11-16-34-41.gh-issue-120343.hdiXeU.rst",
          "Python/Python-tokenize.c"
        ],
        "message": "[3.13] gh-120343: Do not reset byte_col_offset_diff after multiline tokens (GH-120352) (#120355)\n\n(cherry picked from commit 1b62bcee941e54244b3ce6476aef8913604987c9)\n\nCo-authored-by: Lysandros Nikolaou <lisandrosnik@gmail.com>\nCo-authored-by: blurb-it[bot] <43283697+blurb-it[bot]@users.noreply.github.com>",
        "before_after_code_files": [
          "Lib/test/test_tokenize.py||Lib/test/test_tokenize.py",
          "Python/Python-tokenize.c||Python/Python-tokenize.c"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/AcreetionOS-Linux/python/pull/2"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "Lib/test/test_tokenize.py||Lib/test/test_tokenize.py": [
          "File: Lib/test/test_tokenize.py -> Lib/test/test_tokenize.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1199:     NAME       'x'           (1, 3) (1, 4)",
          "1200:     \"\"\")",
          "1202: class GenerateTokensTest(TokenizeTest):",
          "1203:     def check_tokenize(self, s, expected):",
          "1204:         # Format the tokens in s in a table format.",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1202:     def test_multiline_non_ascii_fstring(self):",
          "1203:         self.check_tokenize(\"\"\"\\",
          "1204: a = f'''",
          "1205:     Autorzy, kt\u00f3rzy t\u0105 jednostk\u0119 maj\u0105 wpisani jako AKTUALNA -- czyli'''\"\"\", \"\"\"\\",
          "1206:     NAME       'a'           (1, 0) (1, 1)",
          "1207:     OP         '='           (1, 2) (1, 3)",
          "1208:     FSTRING_START \"f\\'\\'\\'\"        (1, 4) (1, 8)",
          "1209:     FSTRING_MIDDLE '\\\\n    Autorzy, kt\u00f3rzy t\u0105 jednostk\u0119 maj\u0105 wpisani jako AKTUALNA -- czyli' (1, 8) (2, 68)",
          "1210:     FSTRING_END \"\\'\\'\\'\"         (2, 68) (2, 71)",
          "1211:     \"\"\")",
          "",
          "---------------"
        ],
        "Python/Python-tokenize.c||Python/Python-tokenize.c": [
          "File: Python/Python-tokenize.c -> Python/Python-tokenize.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "37:     PyObject *last_line;",
          "38:     Py_ssize_t last_lineno;",
          "39:     Py_ssize_t byte_col_offset_diff;",
          "40: } tokenizeriterobject;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "39:     Py_ssize_t last_end_lineno;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "77:     self->last_line = NULL;",
          "78:     self->byte_col_offset_diff = 0;",
          "79:     self->last_lineno = 0;",
          "81:     return (PyObject *)self;",
          "82: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "81:     self->last_end_lineno = 0;",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "227:             Py_XDECREF(it->last_line);",
          "228:             line = PyUnicode_DecodeUTF8(line_start, size, \"replace\");",
          "229:             it->last_line = line;",
          "231:         } else {",
          "233:             line = it->last_line;",
          "",
          "[Removed Lines]",
          "230:             it->byte_col_offset_diff = 0;",
          "",
          "[Added Lines]",
          "232:             if (it->tok->lineno != it->last_end_lineno) {",
          "233:                 it->byte_col_offset_diff = 0;",
          "234:             }",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "241:     Py_ssize_t lineno = ISSTRINGLIT(type) ? it->tok->first_lineno : it->tok->lineno;",
          "242:     Py_ssize_t end_lineno = it->tok->lineno;",
          "243:     it->last_lineno = lineno;",
          "245:     Py_ssize_t col_offset = -1;",
          "246:     Py_ssize_t end_col_offset = -1;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "248:     it->last_end_lineno = end_lineno;",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "6ce2810f36829ae89278219ec89f3cc798f19ae6",
      "candidate_info": {
        "commit_hash": "6ce2810f36829ae89278219ec89f3cc798f19ae6",
        "repo": "python/cpython",
        "commit_url": "https://github.com/python/cpython/commit/6ce2810f36829ae89278219ec89f3cc798f19ae6",
        "files": [
          "Lib/test/test_launcher.py"
        ],
        "message": "[3.13] gh-119070: Update test_shebang_executable_extension to always use non-installed version (GH-119846) (#GH-120015)\n\ngh-119070: Update test_shebang_executable_extension to always use non-installed version (GH-119846)\n(cherry picked from commit 5c48eb0cc6c3e84aafda0a734a05ecec14fc0ccf)\n\nCo-authored-by: Steve Dower <steve.dower@python.org>",
        "before_after_code_files": [
          "Lib/test/test_launcher.py||Lib/test/test_launcher.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/AcreetionOS-Linux/python/pull/2"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "Lib/test/test_launcher.py||Lib/test/test_launcher.py": [
          "File: Lib/test/test_launcher.py -> Lib/test/test_launcher.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "766:             self.assertEqual(data[\"stdout\"].strip(), f\"{quote(exe)} arg1 {quote(script)}\")",
          "768:     def test_shebang_executable_extension(self):",
          "772:         actual = [line.strip() for line in data[\"stderr\"].splitlines()",
          "773:                   if line.startswith(\"# Search PATH\")]",
          "774:         self.assertEqual([expect], actual)",
          "",
          "[Removed Lines]",
          "769:         with self.script('#! /usr/bin/env python3.12') as script:",
          "770:             data = self.run_py([script])",
          "771:         expect = \"# Search PATH for python3.12.exe\"",
          "",
          "[Added Lines]",
          "769:         with self.script('#! /usr/bin/env python3.99') as script:",
          "770:             data = self.run_py([script], expect_returncode=103)",
          "771:         expect = \"# Search PATH for python3.99.exe\"",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "8d74eae4d492f23f33757b05f7de2cdbe210760e",
      "candidate_info": {
        "commit_hash": "8d74eae4d492f23f33757b05f7de2cdbe210760e",
        "repo": "python/cpython",
        "commit_url": "https://github.com/python/cpython/commit/8d74eae4d492f23f33757b05f7de2cdbe210760e",
        "files": [
          "Lib/_pyrepl/completing_reader.py",
          "Lib/test/test_pyrepl/support.py",
          "Lib/test/test_pyrepl/test_reader.py"
        ],
        "message": "[3.13] gh-120041: Do not use append_to_screen when completions are visible (GH-120042) (#120051)\n\n* gh-120041: Do not use append_to_screen when completions are visible (GH-120042)\n(cherry picked from commit 8fc7653766b106bdbc4ff6154e0020aea4ab15e6)\n\n* gh-120041: Refactor check for visible completion menu in completing_reader (GH-120055)\n(cherry picked from commit bf8e5e53d0c359a1f9c285d855e7a5e9b6d91375)\n---------\n\nCo-authored-by: Lysandros Nikolaou <lisandrosnik@gmail.com>",
        "before_after_code_files": [
          "Lib/_pyrepl/completing_reader.py||Lib/_pyrepl/completing_reader.py",
          "Lib/test/test_pyrepl/support.py||Lib/test/test_pyrepl/support.py",
          "Lib/test/test_pyrepl/test_reader.py||Lib/test/test_pyrepl/test_reader.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/AcreetionOS-Linux/python/pull/2"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "Lib/_pyrepl/completing_reader.py||Lib/_pyrepl/completing_reader.py": [
          "File: Lib/_pyrepl/completing_reader.py -> Lib/_pyrepl/completing_reader.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "187:             if p:",
          "188:                 r.insert(p)",
          "189:             if last_is_completer:",
          "192:                 r.cmpltn_menu, r.cmpltn_menu_end = build_menu(",
          "193:                     r.console, completions, r.cmpltn_menu_end,",
          "194:                     r.use_brackets, r.sort_in_column)",
          "195:                 r.dirty = True",
          "204: class self_insert(commands.self_insert):",
          "",
          "[Removed Lines]",
          "190:                 if not r.cmpltn_menu_visible:",
          "191:                     r.cmpltn_menu_visible = True",
          "196:             elif stem + p in completions:",
          "197:                 r.msg = \"[ complete but not unique ]\"",
          "198:                 r.dirty = True",
          "199:             else:",
          "200:                 r.msg = \"[ not unique ]\"",
          "201:                 r.dirty = True",
          "",
          "[Added Lines]",
          "190:                 r.cmpltn_menu_visible = True",
          "191:                 r.cmpltn_message_visible = False",
          "196:             elif not r.cmpltn_menu_visible:",
          "197:                 r.cmpltn_message_visible = True",
          "198:                 if stem + p in completions:",
          "199:                     r.msg = \"[ complete but not unique ]\"",
          "200:                     r.dirty = True",
          "201:                 else:",
          "202:                     r.msg = \"[ not unique ]\"",
          "203:                     r.dirty = True",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "209:         commands.self_insert.do(self)",
          "211:         if r.cmpltn_menu_visible:",
          "212:             stem = r.get_stem()",
          "213:             if len(stem) < 1:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "213:         if r.cmpltn_menu_visible or r.cmpltn_message_visible:",
          "214:             r.calc_screen = r.calc_complete_screen",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "236:     ### Instance variables",
          "237:     cmpltn_menu: list[str] = field(init=False)",
          "238:     cmpltn_menu_visible: bool = field(init=False)",
          "239:     cmpltn_menu_end: int = field(init=False)",
          "240:     cmpltn_menu_choices: list[str] = field(init=False)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "244:     cmpltn_message_visible: bool = field(init=False)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "271:     def cmpltn_reset(self) -> None:",
          "272:         self.cmpltn_menu = []",
          "273:         self.cmpltn_menu_visible = False",
          "274:         self.cmpltn_menu_end = 0",
          "275:         self.cmpltn_menu_choices = []",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "280:         self.cmpltn_message_visible = False",
          "",
          "---------------"
        ],
        "Lib/test/test_pyrepl/support.py||Lib/test/test_pyrepl/support.py": [
          "File: Lib/test/test_pyrepl/support.py -> Lib/test/test_pyrepl/support.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "41: def prepare_reader(console: Console, **kwargs):",
          "43:     reader = ReadlineAlikeReader(console=console, config=config)",
          "44:     reader.more_lines = partial(more_lines, namespace=None)",
          "45:     reader.paste_mode = True  # Avoid extra indents",
          "",
          "[Removed Lines]",
          "42:     config = ReadlineConfig(readline_completer=None)",
          "",
          "[Added Lines]",
          "42:     config = ReadlineConfig(readline_completer=kwargs.pop(\"readline_completer\", None))",
          "",
          "---------------"
        ],
        "Lib/test/test_pyrepl/test_reader.py||Lib/test/test_pyrepl/test_reader.py": [
          "File: Lib/test/test_pyrepl/test_reader.py -> Lib/test/test_pyrepl/test_reader.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1: import itertools",
          "2: import functools",
          "3: from unittest import TestCase",
          "5: from .support import handle_all_events, handle_events_narrow_console, code_to_events, prepare_reader",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "3: import rlcompleter",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "10: class TestReader(TestCase):",
          "11:     def assert_screen_equals(self, reader, expected):",
          "13:         expected = expected.split(\"\\n\")",
          "14:         self.assertListEqual(actual, expected)",
          "",
          "[Removed Lines]",
          "12:         actual = reader.calc_screen()",
          "",
          "[Added Lines]",
          "13:         actual = reader.screen",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "208:         prompt, l = Reader.process_prompt(ps1)",
          "209:         self.assertEqual(prompt, \"\\033[0;32m\u6a02>\\033[0m> \")",
          "210:         self.assertEqual(l, 5)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "213:     def test_completions_updated_on_key_press(self):",
          "214:         namespace = {\"itertools\": itertools}",
          "215:         code = \"itertools.\"",
          "216:         events = itertools.chain(code_to_events(code), [",
          "217:             Event(evt='key', data='\\t', raw=bytearray(b'\\t')),  # Two tabs for completion",
          "218:             Event(evt='key', data='\\t', raw=bytearray(b'\\t')),",
          "219:         ], code_to_events(\"a\"))",
          "221:         completing_reader = functools.partial(",
          "222:             prepare_reader,",
          "223:             readline_completer=rlcompleter.Completer(namespace).complete",
          "224:         )",
          "225:         reader, _ = handle_all_events(events, prepare_reader=completing_reader)",
          "227:         actual = reader.screen",
          "228:         self.assertEqual(len(actual), 2)",
          "229:         self.assertEqual(actual[0].rstrip(), \"itertools.accumulate(\")",
          "230:         self.assertEqual(actual[1], f\"{code}a\")",
          "232:     def test_key_press_on_tab_press_once(self):",
          "233:         namespace = {\"itertools\": itertools}",
          "234:         code = \"itertools.\"",
          "235:         events = itertools.chain(code_to_events(code), [",
          "236:             Event(evt='key', data='\\t', raw=bytearray(b'\\t')),",
          "237:         ], code_to_events(\"a\"))",
          "239:         completing_reader = functools.partial(",
          "240:             prepare_reader,",
          "241:             readline_completer=rlcompleter.Completer(namespace).complete",
          "242:         )",
          "243:         reader, _ = handle_all_events(events, prepare_reader=completing_reader)",
          "245:         self.assert_screen_equals(reader, f\"{code}a\")",
          "",
          "---------------"
        ]
      }
    }
  ]
}