{
  "cve_id": "CVE-2023-25658",
  "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.12.0 and 2.11.1, an out of bounds read is in GRUBlockCellGrad. A fix is included in TensorFlow 2.12.0 and 2.11.1.\n",
  "repo": "tensorflow/tensorflow",
  "patch_hash": "ff459137c2716a2a60f7d441b855fcb466d778cb",
  "patch_info": {
    "commit_hash": "ff459137c2716a2a60f7d441b855fcb466d778cb",
    "repo": "tensorflow/tensorflow",
    "commit_url": "https://github.com/tensorflow/tensorflow/commit/ff459137c2716a2a60f7d441b855fcb466d778cb",
    "files": [
      ".bazelrc",
      "tensorflow/compiler/jit/BUILD",
      "tensorflow/compiler/xla/backends/interpreter/BUILD",
      "tensorflow/compiler/xla/backends/interpreter/platform.cc",
      "tensorflow/compiler/xla/hlo/evaluator/hlo_evaluator.cc",
      "tensorflow/compiler/xla/mlir/tools/mlir_replay/BUILD",
      "tensorflow/compiler/xla/service/hlo_graph_dumper.cc",
      "tensorflow/compiler/xla/stream_executor/BUILD",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_platform.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_rng.cc",
      "tensorflow/compiler/xla/stream_executor/host/BUILD",
      "tensorflow/compiler/xla/stream_executor/host/host_gpu_executor.h",
      "tensorflow/compiler/xla/stream_executor/host/host_platform.cc",
      "tensorflow/compiler/xla/stream_executor/lib/BUILD",
      "tensorflow/compiler/xla/stream_executor/lib/error.h",
      "tensorflow/compiler/xla/stream_executor/lib/initialize.h",
      "tensorflow/compiler/xla/stream_executor/multi_platform_manager.cc",
      "tensorflow/compiler/xla/stream_executor/multi_platform_manager.h",
      "tensorflow/compiler/xla/stream_executor/platform.cc",
      "tensorflow/compiler/xla/stream_executor/plugin_registry.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_blas.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_diagnostics.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_dnn.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_driver.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_fft.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_gpu_executor.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_platform.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_rng.cc",
      "tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.cc",
      "tensorflow/compiler/xla/stream_executor/tf_allocator_adapter.cc",
      "tensorflow/core/common_runtime/function.cc",
      "tensorflow/core/data/BUILD",
      "tensorflow/core/data/service/server_lib.cc",
      "tensorflow/core/data/service/server_lib.h",
      "tensorflow/core/data/service/snapshot/BUILD",
      "tensorflow/core/data/service/snapshot/path_utils.cc",
      "tensorflow/core/data/service/snapshot/path_utils.h",
      "tensorflow/core/data/service/snapshot/path_utils_test.cc",
      "tensorflow/core/data/service/snapshot/snapshot_manager.cc",
      "tensorflow/core/data/tfdataz_metrics.cc",
      "tensorflow/core/data/tfdataz_metrics.h",
      "tensorflow/core/data/tfdataz_metrics_test.cc",
      "tensorflow/core/distributed_runtime/eager/remote_mgr.cc",
      "tensorflow/core/distributed_runtime/integration_test/coordination_test_opkernel_registration.cc",
      "tensorflow/core/framework/dataset.h",
      "tensorflow/core/framework/op_requires.h",
      "tensorflow/core/kernels/data/iterator_ops.cc",
      "tensorflow/core/kernels/function_ops.cc",
      "tensorflow/core/kernels/functional_ops.cc",
      "tensorflow/core/kernels/rnn/gru_ops.cc",
      "tensorflow/core/lib/core/status_test.cc",
      "tensorflow/core/platform/error_payloads.cc",
      "tensorflow/core/tpu/kernels/tpu_compile_op_common.cc",
      "tensorflow/core/tpu/kernels/tpu_functional_ops.cc",
      "tensorflow/core/tpu/tpu_embedding_errors.cc",
      "tensorflow/core/tpu/tpu_embedding_errors.h",
      "tensorflow/core/util/zen_util.h",
      "tensorflow/lite/delegates/xnnpack/README.md",
      "tensorflow/python/data/experimental/kernel_tests/service/snapshot_ft_test.py",
      "tensorflow/python/framework/BUILD",
      "tensorflow/python/framework/errors_test_helper.cc",
      "tensorflow/python/tpu/tpu_strategy_util.py",
      "tensorflow/tools/ci_build/release/requirements_common.txt",
      "tensorflow/tools/ci_build/release/requirements_mac.txt",
      "tensorflow/tools/tf_sig_build_dockerfiles/devel.requirements.txt",
      "tensorflow/tsl/c/tsl_status.cc",
      "tensorflow/tsl/c/tsl_status_helper_test.cc",
      "tensorflow/tsl/distributed_runtime/coordination/coordination_service_error_util.h",
      "tensorflow/tsl/distributed_runtime/rpc/grpc_util.h",
      "tensorflow/tsl/distributed_runtime/rpc/grpc_util_test.cc",
      "tensorflow/tsl/platform/errors.h",
      "tensorflow/tsl/platform/test.h",
      "tensorflow/tsl/profiler/lib/BUILD",
      "tensorflow/tsl/profiler/lib/traceme_encode.h",
      "tensorflow/tsl/profiler/lib/traceme_encode_test.cc",
      "third_party/tf_runtime/workspace.bzl"
    ],
    "message": "Merged commit includes the following changes: 504684855  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Remove legacy references from `ops.py`.\n\n    This is done to eventually remove the lazy loads in `indexed_slices.py`.\n\n--\n504682660  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Add missing reference symbol.\n\n--\n504682467  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    #tf-data-service Add a function to parse split file names.\n\n--\n504680829  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Update XNNPACK README to document feature parity for FP16 operators\n\n--\n504677404  by A. Unique TensorFlower<gardener@tensorflow.org>:\n    Automated rollback of changelist 504103068.\n\n504676634  by A. Unique TensorFlower<gardener@tensorflow.org>:\n    Automated rollback of changelist 504656381.\n\n504672100  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Delete compiler/xla/stream_executor/lib/initialize.h, update users to depend on stream_executor/platform/intialize.h directly\n\n--\n504669543  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Refactor transforms to make buildozer object injectable.\n\n--\n504667726  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Update all CI dependencies to non vulnerable versions.\n\n    This MUST land before branch cut.\n\n--\n504661218  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Update TFRT dependency to use revision\n    http://github.com/tensorflow/runtime/commit/c653281a1a23c0c3d41536a983c7d10fcc5b1fbf.\n\n--\n504660212  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Change TraceMeArg to keep a reference to an AlphaNum constructed on the stack rather than constructing it by value.\n\n    The eliminates a lifetime safety bug where AlphaNum uses a default constructed argument as a string buffer that was a dangling reference before.\n\n    Also add a LIFETIME_BOUND attribute to ensure this is used correctly.\n\n--\n504660069  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Add kIsOpenSource to tsl/platform/test.h\n\n--\n504659330  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Update usages of tensorflow::Status::SetPayload.\n\n--\n504656381  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Remove the scrubbing of constants in tpu_cluster_formation.\n\n    Instead, just ignore tf.Const attributes, in CollectAndGroupClusterOps. This\n    is functionally equivalent (for this pass), but a bit more clean since it\n    doesn't leave modified tf.Const ops behind.\n\n--\n504654874  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Add missing dependency for the Mac build.\n\n--\n504653641  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Internal visibility change\n\n--\n504648821  by A. Unique TensorFlower<gardener@tensorflow.org>:\n    Automated rollback of changelist 504006190.\nBEGIN_PUBLIC\nRollback of PR #59418: [aarch64] enable acl linking for cpu xla for mkl_aarch64_threadpool config\nReason: The configuration is still not very well-tested.\nEND_PUBLIC\n\n504645490  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Fix input validation for GRU ops.\n\n--\n504633571  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    [SE] Replace uses of stream_executor::port::error with tsl::error.\n\n    This lets us remove stream_executor/lib/error.h!\n\n    No functional change; these are aliases of one another.\n\n--\n504633188  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Update tf.tpu.experimental.initialize_tpu_system to disable running on eager mode.\n\n--\n504618714  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    [XLA:GPU] Update hlo graph dumper to additionally dump the gemm epilogue from the GemmBackendConfig\n\n--\n504618661  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Fix ODR violation from zen_util.h\n\n--\n504616623  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    [tf.data] Collect the iterator's memory usage metrics for /tfdataz page.\n\n--\n504612989  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Internal change\n\nPiperOrigin-RevId: 504684855",
    "before_after_code_files": [
      "tensorflow/compiler/xla/backends/interpreter/platform.cc||tensorflow/compiler/xla/backends/interpreter/platform.cc",
      "tensorflow/compiler/xla/hlo/evaluator/hlo_evaluator.cc||tensorflow/compiler/xla/hlo/evaluator/hlo_evaluator.cc",
      "tensorflow/compiler/xla/service/hlo_graph_dumper.cc||tensorflow/compiler/xla/service/hlo_graph_dumper.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_platform.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_platform.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_rng.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_rng.cc",
      "tensorflow/compiler/xla/stream_executor/host/host_gpu_executor.h||tensorflow/compiler/xla/stream_executor/host/host_gpu_executor.h",
      "tensorflow/compiler/xla/stream_executor/host/host_platform.cc||tensorflow/compiler/xla/stream_executor/host/host_platform.cc",
      "tensorflow/compiler/xla/stream_executor/lib/error.h||tensorflow/compiler/xla/stream_executor/lib/error.h",
      "tensorflow/compiler/xla/stream_executor/lib/initialize.h||tensorflow/compiler/xla/stream_executor/lib/initialize.h",
      "tensorflow/compiler/xla/stream_executor/multi_platform_manager.cc||tensorflow/compiler/xla/stream_executor/multi_platform_manager.cc",
      "tensorflow/compiler/xla/stream_executor/multi_platform_manager.h||tensorflow/compiler/xla/stream_executor/multi_platform_manager.h",
      "tensorflow/compiler/xla/stream_executor/platform.cc||tensorflow/compiler/xla/stream_executor/platform.cc",
      "tensorflow/compiler/xla/stream_executor/plugin_registry.cc||tensorflow/compiler/xla/stream_executor/plugin_registry.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_blas.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_blas.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_diagnostics.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_diagnostics.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_dnn.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_dnn.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_driver.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_driver.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_fft.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_fft.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_gpu_executor.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_gpu_executor.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_platform.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_platform.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_rng.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_rng.cc",
      "tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.cc||tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.cc",
      "tensorflow/compiler/xla/stream_executor/tf_allocator_adapter.cc||tensorflow/compiler/xla/stream_executor/tf_allocator_adapter.cc",
      "tensorflow/core/common_runtime/function.cc||tensorflow/core/common_runtime/function.cc",
      "tensorflow/core/data/service/server_lib.cc||tensorflow/core/data/service/server_lib.cc",
      "tensorflow/core/data/service/server_lib.h||tensorflow/core/data/service/server_lib.h",
      "tensorflow/core/data/service/snapshot/path_utils.cc||tensorflow/core/data/service/snapshot/path_utils.cc",
      "tensorflow/core/data/service/snapshot/path_utils.h||tensorflow/core/data/service/snapshot/path_utils.h",
      "tensorflow/core/data/service/snapshot/path_utils_test.cc||tensorflow/core/data/service/snapshot/path_utils_test.cc",
      "tensorflow/core/data/service/snapshot/snapshot_manager.cc||tensorflow/core/data/service/snapshot/snapshot_manager.cc",
      "tensorflow/core/data/tfdataz_metrics.cc||tensorflow/core/data/tfdataz_metrics.cc",
      "tensorflow/core/data/tfdataz_metrics.h||tensorflow/core/data/tfdataz_metrics.h",
      "tensorflow/core/data/tfdataz_metrics_test.cc||tensorflow/core/data/tfdataz_metrics_test.cc",
      "tensorflow/core/distributed_runtime/eager/remote_mgr.cc||tensorflow/core/distributed_runtime/eager/remote_mgr.cc",
      "tensorflow/core/distributed_runtime/integration_test/coordination_test_opkernel_registration.cc||tensorflow/core/distributed_runtime/integration_test/coordination_test_opkernel_registration.cc",
      "tensorflow/core/framework/dataset.h||tensorflow/core/framework/dataset.h",
      "tensorflow/core/framework/op_requires.h||tensorflow/core/framework/op_requires.h",
      "tensorflow/core/kernels/data/iterator_ops.cc||tensorflow/core/kernels/data/iterator_ops.cc",
      "tensorflow/core/kernels/function_ops.cc||tensorflow/core/kernels/function_ops.cc",
      "tensorflow/core/kernels/functional_ops.cc||tensorflow/core/kernels/functional_ops.cc",
      "tensorflow/core/kernels/rnn/gru_ops.cc||tensorflow/core/kernels/rnn/gru_ops.cc",
      "tensorflow/core/lib/core/status_test.cc||tensorflow/core/lib/core/status_test.cc",
      "tensorflow/core/platform/error_payloads.cc||tensorflow/core/platform/error_payloads.cc",
      "tensorflow/core/tpu/kernels/tpu_compile_op_common.cc||tensorflow/core/tpu/kernels/tpu_compile_op_common.cc",
      "tensorflow/core/tpu/kernels/tpu_functional_ops.cc||tensorflow/core/tpu/kernels/tpu_functional_ops.cc",
      "tensorflow/core/tpu/tpu_embedding_errors.cc||tensorflow/core/tpu/tpu_embedding_errors.cc",
      "tensorflow/core/tpu/tpu_embedding_errors.h||tensorflow/core/tpu/tpu_embedding_errors.h",
      "tensorflow/core/util/zen_util.h||tensorflow/core/util/zen_util.h",
      "tensorflow/python/data/experimental/kernel_tests/service/snapshot_ft_test.py||tensorflow/python/data/experimental/kernel_tests/service/snapshot_ft_test.py",
      "tensorflow/python/framework/errors_test_helper.cc||tensorflow/python/framework/errors_test_helper.cc",
      "tensorflow/python/tpu/tpu_strategy_util.py||tensorflow/python/tpu/tpu_strategy_util.py",
      "tensorflow/tsl/c/tsl_status.cc||tensorflow/tsl/c/tsl_status.cc",
      "tensorflow/tsl/c/tsl_status_helper_test.cc||tensorflow/tsl/c/tsl_status_helper_test.cc",
      "tensorflow/tsl/distributed_runtime/coordination/coordination_service_error_util.h||tensorflow/tsl/distributed_runtime/coordination/coordination_service_error_util.h",
      "tensorflow/tsl/distributed_runtime/rpc/grpc_util.h||tensorflow/tsl/distributed_runtime/rpc/grpc_util.h",
      "tensorflow/tsl/distributed_runtime/rpc/grpc_util_test.cc||tensorflow/tsl/distributed_runtime/rpc/grpc_util_test.cc",
      "tensorflow/tsl/platform/errors.h||tensorflow/tsl/platform/errors.h",
      "tensorflow/tsl/platform/test.h||tensorflow/tsl/platform/test.h",
      "tensorflow/tsl/profiler/lib/traceme_encode.h||tensorflow/tsl/profiler/lib/traceme_encode.h",
      "tensorflow/tsl/profiler/lib/traceme_encode_test.cc||tensorflow/tsl/profiler/lib/traceme_encode_test.cc",
      "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl"
    ]
  },
  "patch_diff": {
    "tensorflow/compiler/xla/backends/interpreter/platform.cc||tensorflow/compiler/xla/backends/interpreter/platform.cc": [
      "File: tensorflow/compiler/xla/backends/interpreter/platform.cc -> tensorflow/compiler/xla/backends/interpreter/platform.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "21: #include \"absl/strings/str_format.h\"",
      "22: #include \"tensorflow/compiler/xla/backends/interpreter/executor.h\"",
      "23: #include \"tensorflow/compiler/xla/stream_executor/device_options.h\"",
      "25: #include \"tensorflow/compiler/xla/stream_executor/multi_platform_manager.h\"",
      "26: #include \"tensorflow/compiler/xla/stream_executor/platform.h\"",
      "27: #include \"tensorflow/tsl/platform/status.h\"",
      "29: namespace stream_executor {",
      "",
      "[Removed Lines]",
      "24: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "26: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/hlo/evaluator/hlo_evaluator.cc||tensorflow/compiler/xla/hlo/evaluator/hlo_evaluator.cc": [
      "File: tensorflow/compiler/xla/hlo/evaluator/hlo_evaluator.cc -> tensorflow/compiler/xla/hlo/evaluator/hlo_evaluator.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "222:   absl::little_endian::Store32(",
      "223:       const_cast<char*>(error_payload.data()),",
      "224:       static_cast<uint32_t>(EvalErrorDetail::kDynamicValueDependence));",
      "226:   return error;",
      "227: }",
      "",
      "[Removed Lines]",
      "225:   error.SetPayload(kEvalErrorDetailUrl, error_payload);",
      "",
      "[Added Lines]",
      "225:   error.SetPayload(kEvalErrorDetailUrl, absl::Cord(error_payload));",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/service/hlo_graph_dumper.cc||tensorflow/compiler/xla/service/hlo_graph_dumper.cc": [
      "File: tensorflow/compiler/xla/service/hlo_graph_dumper.cc -> tensorflow/compiler/xla/service/hlo_graph_dumper.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "1251:   if (config.algorithm_case() == gpu::GemmBackendConfig::kSelectedAlgorithm) {",
      "1252:     props.emplace_back(\"algorithm\", StrCat(config.selected_algorithm()));",
      "1253:   }",
      "1254:   return props;",
      "1255: }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "1254:   if (config.epilogue() != gpu::GemmBackendConfig::DEFAULT) {",
      "1255:     props.emplace_back(",
      "1256:         \"epilogue\", gpu::GemmBackendConfig::Epilogue_Name(config.epilogue()));",
      "1257:   }",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc": [
      "File: tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc -> tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "63: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_stream.h\"",
      "64: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_timer.h\"",
      "65: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_types.h\"",
      "67: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "68: #include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"",
      "69: #include \"tensorflow/compiler/xla/stream_executor/plugin_registry.h\"",
      "",
      "[Removed Lines]",
      "66: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "66: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc": [
      "File: tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc -> tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "36: #include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_stream.h\"",
      "37: #include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_timer.h\"",
      "38: #include \"tensorflow/compiler/xla/stream_executor/dnn.h\"",
      "41: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "42: #include \"tensorflow/compiler/xla/stream_executor/plugin_registry.h\"",
      "43: #include \"tensorflow/compiler/xla/stream_executor/scratch_allocator.h\"",
      "",
      "[Removed Lines]",
      "39: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "40: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "39: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "85:       std::ostringstream oss;                                           \\",
      "86:       oss << CudnnStatusToString(_status) << \"\\nin \" << __FILE__ << \"(\" \\",
      "87:           << __LINE__ << \"): '\" << #expr << \"'\";                        \\",
      "89:     }                                                                   \\",
      "90:   } while (false)",
      "",
      "[Removed Lines]",
      "88:       return tsl::Status(port::error::UNKNOWN, oss.str());              \\",
      "",
      "[Added Lines]",
      "87:       return tsl::Status(tsl::error::UNKNOWN, oss.str());               \\",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "96:       std::ostringstream oss;                                           \\",
      "97:       oss << CudnnStatusToString(_status) << \"\\nin \" << __FILE__ << \"(\" \\",
      "98:           << __LINE__ << \"): '\" << #expr << \"' \" << (expr).get_error(); \\",
      "100:     }                                                                   \\",
      "101:   } while (false)",
      "",
      "[Removed Lines]",
      "99:       return tsl::Status(port::error::UNKNOWN, oss.str());              \\",
      "",
      "[Added Lines]",
      "98:       return tsl::Status(tsl::error::UNKNOWN, oss.str());               \\",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "417:           \"configuration.\");",
      "418:       LOG(ERROR) << error;",
      "419:       cudnnDestroy(cudnn_handle);",
      "421:     }",
      "423:     cudnn_.reset(new CudnnAccess(cudnn_handle));",
      "",
      "[Removed Lines]",
      "420:       return tsl::Status(port::error::INTERNAL, error);",
      "",
      "[Added Lines]",
      "419:       return tsl::Status(tsl::error::INTERNAL, error);",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "441:     }",
      "442:   }",
      "445:                      absl::StrCat(\"cudnn library could not create a handle: \",",
      "446:                                   CudnnStatusToString(status)));",
      "447: }",
      "",
      "[Removed Lines]",
      "444:   return tsl::Status(port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "443:   return tsl::Status(tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "1299:             ? algorithm_config.algorithm()->tensor_ops_enabled()",
      "1300:             : allow_tensor_ops;",
      "1301:     if (use_tensor_ops && !allow_tensor_ops) {",
      "1303:                          \"Algo requests disallowed tensor op evaluation.\");",
      "1304:     }",
      "",
      "[Removed Lines]",
      "1302:       return tsl::Status(port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "1301:       return tsl::Status(tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 7 ---",
      "[Context before]",
      "1658:       GpuExecutor* parent, int max_seq_length, int batch_size, int data_size,",
      "1659:       cudnnDataType_t data_type) {",
      "1660:     if (max_seq_length <= 0) {",
      "1662:     }",
      "1663:     int dims[] = {batch_size, data_size, 1};",
      "1664:     int strides[] = {dims[1] * dims[2], dims[2], 1};",
      "",
      "[Removed Lines]",
      "1661:       return tsl::Status(port::error::INVALID_ARGUMENT, \"max_seq_length <= 0\");",
      "",
      "[Added Lines]",
      "1660:       return tsl::Status(tsl::error::INVALID_ARGUMENT, \"max_seq_length <= 0\");",
      "",
      "---------------",
      "--- Hunk 8 ---",
      "[Context before]",
      "1677:       const absl::Span<const int>& seq_lengths, bool time_major,",
      "1678:       cudnnDataType_t data_type) {",
      "1679:     if (max_seq_length <= 0) {",
      "1681:     }",
      "1682:     int dims[] = {batch_size, data_size, 1};",
      "1683:     int strides[] = {dims[1] * dims[2], dims[2], 1};",
      "",
      "[Removed Lines]",
      "1680:       return tsl::Status(port::error::INVALID_ARGUMENT, \"max_seq_length <= 0\");",
      "",
      "[Added Lines]",
      "1679:       return tsl::Status(tsl::error::INVALID_ARGUMENT, \"max_seq_length <= 0\");",
      "",
      "---------------",
      "--- Hunk 9 ---",
      "[Context before]",
      "1804:             model_dims.num_layers * model_dims.dir_count &&",
      "1805:         input_h_desc.batch_size() == model_dims.batch_size &&",
      "1806:         input_h_desc.data_size() == model_dims.hidden_size)) {",
      "1808:   }",
      "1811:   if (!(input_h_desc.num_layers() == input_c_desc.num_layers() &&",
      "1812:         input_h_desc.batch_size() == input_c_desc.batch_size() &&",
      "1813:         input_h_desc.data_size() <= input_c_desc.data_size())) {",
      "1815:   }",
      "1816:   if (!(output_desc.max_seq_length() == model_dims.max_seq_length &&",
      "1817:         output_desc.batch_size() == model_dims.batch_size &&",
      "1818:         output_desc.data_size() ==",
      "1819:             model_dims.hidden_size * model_dims.dir_count)) {",
      "1821:   }",
      "1822:   if (!(input_h_desc.num_layers() == output_h_desc.num_layers() &&",
      "1823:         input_h_desc.batch_size() == output_h_desc.batch_size() &&",
      "1824:         input_h_desc.data_size() == output_h_desc.data_size())) {",
      "1826:   }",
      "1827:   if (!(input_h_desc.num_layers() == output_c_desc.num_layers() &&",
      "1828:         input_h_desc.batch_size() == output_c_desc.batch_size() &&",
      "1829:         input_h_desc.data_size() <= output_c_desc.data_size())) {",
      "1831:   }",
      "1833:   return model_dims;",
      "",
      "[Removed Lines]",
      "1807:     return tsl::Status(port::error::INVALID_ARGUMENT, \"Invalid input_h shape\");",
      "1814:     return tsl::Status(port::error::INVALID_ARGUMENT, \"Invalid input_c shape\");",
      "1820:     return tsl::Status(port::error::INVALID_ARGUMENT, \"Invalid output shape\");",
      "1825:     return tsl::Status(port::error::INVALID_ARGUMENT, \"Invalid output_h shape\");",
      "1830:     return tsl::Status(port::error::INVALID_ARGUMENT, \"Invalid output_c shape\");",
      "",
      "[Added Lines]",
      "1806:     return tsl::Status(tsl::error::INVALID_ARGUMENT, \"Invalid input_h shape\");",
      "1813:     return tsl::Status(tsl::error::INVALID_ARGUMENT, \"Invalid input_c shape\");",
      "1819:     return tsl::Status(tsl::error::INVALID_ARGUMENT, \"Invalid output shape\");",
      "1824:     return tsl::Status(tsl::error::INVALID_ARGUMENT, \"Invalid output_h shape\");",
      "1829:     return tsl::Status(tsl::error::INVALID_ARGUMENT, \"Invalid output_c shape\");",
      "",
      "---------------",
      "--- Hunk 10 ---",
      "[Context before]",
      "1849: #endif",
      "1850:   if (static_cast<int64_t>(params_size_in_bytes) !=",
      "1851:       rnn_desc.ParamsSizeInBytes()) {",
      "1853:                        \"Mismatching RNN parameter size\");",
      "1854:   }",
      "1855:   return ::tsl::OkStatus();",
      "",
      "[Removed Lines]",
      "1852:     return tsl::Status(port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "1851:     return tsl::Status(tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 11 ---",
      "[Context before]",
      "1999:       if (!timer->Init() || !timer->Start(AsGpuStream(stream))) {",
      "2001:       }",
      "2002:     }",
      "",
      "[Removed Lines]",
      "2000:         return tsl::Status(port::error::INTERNAL, \"Failed to start timer\");",
      "",
      "[Added Lines]",
      "1999:         return tsl::Status(tsl::error::INTERNAL, \"Failed to start timer\");",
      "",
      "---------------",
      "--- Hunk 12 ---",
      "[Context before]",
      "2021:     if (is_profiling) {",
      "2022:       if (!timer->Stop(AsGpuStream(stream))) {",
      "2024:       }",
      "2025:       auto algo_desc = *rnn_desc.algorithm_config().algorithm();",
      "2026:       output_profile_result->set_algorithm(algo_desc);",
      "",
      "[Removed Lines]",
      "2023:         return tsl::Status(port::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "[Added Lines]",
      "2022:         return tsl::Status(tsl::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "---------------",
      "--- Hunk 13 ---",
      "[Context before]",
      "2060:     if (!timer->Init() || !timer->Start(AsGpuStream(stream))) {",
      "2062:     }",
      "2063:   }",
      "",
      "[Removed Lines]",
      "2061:       return tsl::Status(port::error::INTERNAL, \"Failed to start timer\");",
      "",
      "[Added Lines]",
      "2060:       return tsl::Status(tsl::error::INTERNAL, \"Failed to start timer\");",
      "",
      "---------------",
      "--- Hunk 14 ---",
      "[Context before]",
      "2131:   if (is_profiling) {",
      "2132:     if (!timer->Stop(AsGpuStream(stream))) {",
      "2134:     }",
      "2135:     auto algo_desc = *rnn_desc.algorithm_config().algorithm();",
      "2136:     output_profile_result->set_algorithm(algo_desc);",
      "",
      "[Removed Lines]",
      "2133:       return tsl::Status(port::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "[Added Lines]",
      "2132:       return tsl::Status(tsl::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "---------------",
      "--- Hunk 15 ---",
      "[Context before]",
      "2206:       if (!timer->Init() || !timer->Start(AsGpuStream(stream))) {",
      "2208:       }",
      "2209:     }",
      "",
      "[Removed Lines]",
      "2207:         return tsl::Status(port::error::INTERNAL, \"Failed to start timer\");",
      "",
      "[Added Lines]",
      "2206:         return tsl::Status(tsl::error::INTERNAL, \"Failed to start timer\");",
      "",
      "---------------",
      "--- Hunk 16 ---",
      "[Context before]",
      "2254:     if (is_profiling) {",
      "2255:       if (!timer->Stop(AsGpuStream(stream))) {",
      "2257:       }",
      "2258:       auto algo_desc = *rnn_desc.algorithm_config().algorithm();",
      "2259:       output_profile_result->set_algorithm(algo_desc);",
      "",
      "[Removed Lines]",
      "2256:         return tsl::Status(port::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "[Added Lines]",
      "2255:         return tsl::Status(tsl::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "---------------",
      "--- Hunk 17 ---",
      "[Context before]",
      "2277:     if (!timer->Init() || !timer->Start(AsGpuStream(stream))) {",
      "2279:     }",
      "2280:   }",
      "",
      "[Removed Lines]",
      "2278:       return tsl::Status(port::error::INTERNAL, \"Failed to start timer\");",
      "",
      "[Added Lines]",
      "2277:       return tsl::Status(tsl::error::INTERNAL, \"Failed to start timer\");",
      "",
      "---------------",
      "--- Hunk 18 ---",
      "[Context before]",
      "2363:   if (is_profiling) {",
      "2364:     if (!timer->Stop(AsGpuStream(stream))) {",
      "2366:     }",
      "2367:     auto algo_desc = *rnn_desc.algorithm_config().algorithm();",
      "2368:     output_profile_result->set_algorithm(algo_desc);",
      "",
      "[Removed Lines]",
      "2365:       return tsl::Status(port::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "[Added Lines]",
      "2364:       return tsl::Status(tsl::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "---------------",
      "--- Hunk 19 ---",
      "[Context before]",
      "2406: #else",
      "2408:                      \"No supported cudnnCTCLoss when \"",
      "2409:                      \"CUDNN_VERSION < 7.6.3\");",
      "2410: #endif",
      "",
      "[Removed Lines]",
      "2407:   return tsl::Status(port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "2406:   return tsl::Status(tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 20 ---",
      "[Context before]",
      "2786:       return perf_results[r].algo;",
      "2787:     }",
      "2788:   }",
      "2790:                      \"cudnnGetConvolutionForwardAlgorithm_v7 returned \"",
      "2791:                      \"no suitable algorithms. This could be a cudnn bug.\");",
      "2792: #else",
      "",
      "[Removed Lines]",
      "2789:   return tsl::Status(port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "2788:   return tsl::Status(tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 21 ---",
      "[Context before]",
      "2828:       return perf_results[r].algo;",
      "2829:     }",
      "2830:   }",
      "2832:                      \"cudnnGetConvolutionBackwardDataAlgorithm_v7 returned \"",
      "2833:                      \"no suitable algorithms. This could be a cudnn bug.\");",
      "2834: #else",
      "",
      "[Removed Lines]",
      "2831:   return tsl::Status(port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "2830:   return tsl::Status(tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 22 ---",
      "[Context before]",
      "2870:       return perf_results[r].algo;",
      "2871:     }",
      "2872:   }",
      "2874:                      \"cudnnGetConvolutionBackwardFilterAlgorithm_v7 returned \"",
      "2875:                      \"no suitable algorithms. This could be a cudnn bug.\");",
      "2876: #else",
      "",
      "[Removed Lines]",
      "2873:   return tsl::Status(port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "2872:   return tsl::Status(tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 23 ---",
      "[Context before]",
      "2895:     ScratchAllocator* scratch_allocator) {",
      "2896:   if (IsTensorMathOpSet(conv) != algorithm_desc.tensor_ops_enabled()) {",
      "2897:     return tsl::Status(",
      "2899:         \"Mismatch between cudnn conv and algorithm descriptors.\");",
      "2900:   }",
      "",
      "[Removed Lines]",
      "2898:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "2897:         tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 24 ---",
      "[Context before]",
      "2918:   if (ABSL_PREDICT_FALSE(size_in_bytes_int64_t < 0)) {",
      "2919:     return tsl::Status(",
      "2921:         \"cudnnGetConvolutionForwardWorkspaceSize() returned \"",
      "2922:         \"negative sizeInBytes value. This could be a cudnn bug.\");",
      "2923:   }",
      "",
      "[Removed Lines]",
      "2920:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "2919:         tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 25 ---",
      "[Context before]",
      "2927:   }",
      "2929:   if (ABSL_PREDICT_FALSE(!scratch_allocator)) {",
      "2931:                        \"No scratch allocator provided\");",
      "2932:   }",
      "",
      "[Removed Lines]",
      "2930:     return tsl::Status(port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "2929:     return tsl::Status(tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 26 ---",
      "[Context before]",
      "2944:     ScratchAllocator* scratch_allocator) {",
      "2945:   if (IsTensorMathOpSet(conv) != algorithm_desc.tensor_ops_enabled()) {",
      "2946:     return tsl::Status(",
      "2948:         \"Mismatch between cudnn conv and algorithm descriptors.\");",
      "2949:   }",
      "",
      "[Removed Lines]",
      "2947:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "2946:         tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 27 ---",
      "[Context before]",
      "2968:   if (ABSL_PREDICT_FALSE(size_in_bytes_int64_t < 0)) {",
      "2969:     return tsl::Status(",
      "2971:         \"cudnnGetConvolutionBackwardDataWorkspaceSize() returned \"",
      "2972:         \"negative sizeInBytes value. This could be a cudnn bug.\");",
      "2973:   }",
      "",
      "[Removed Lines]",
      "2970:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "2969:         tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 28 ---",
      "[Context before]",
      "2977:   }",
      "2979:   if (ABSL_PREDICT_FALSE(!scratch_allocator)) {",
      "2981:                        \"No scratch allocator provided\");",
      "2982:   }",
      "",
      "[Removed Lines]",
      "2980:     return tsl::Status(port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "2979:     return tsl::Status(tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 29 ---",
      "[Context before]",
      "2994:     ScratchAllocator* scratch_allocator) {",
      "2995:   if (IsTensorMathOpSet(conv) != algorithm_desc.tensor_ops_enabled()) {",
      "2996:     return tsl::Status(",
      "2998:         \"Mismatch between cudnn conv and algorithm descriptors.\");",
      "2999:   }",
      "",
      "[Removed Lines]",
      "2997:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "2996:         tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 30 ---",
      "[Context before]",
      "3018:   if (ABSL_PREDICT_FALSE(size_in_bytes_int64_t < 0)) {",
      "3019:     return tsl::Status(",
      "3021:         \"cudnnGetConvolutionBackwardFilterWorkspaceSize() returned \"",
      "3022:         \"negative sizeInBytes value. This could be a cudnn bug.\");",
      "3023:   }",
      "",
      "[Removed Lines]",
      "3020:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "3019:         tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 31 ---",
      "[Context before]",
      "3027:   }",
      "3029:   if (ABSL_PREDICT_FALSE(!scratch_allocator)) {",
      "3031:                        \"No scratch allocator provided\");",
      "3032:   }",
      "",
      "[Removed Lines]",
      "3030:     return tsl::Status(port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "3029:     return tsl::Status(tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 32 ---",
      "[Context before]",
      "3040:   if (desc.has_value()) {",
      "3041:     use_tensor_ops = desc->tensor_ops_enabled();",
      "3042:     if (use_tensor_ops && !IsTensorMathEnabled(stream, type)) {",
      "3044:                          \"Algo requests disabled tensor op evaluation.\");",
      "3045:     }",
      "3046:   } else {",
      "",
      "[Removed Lines]",
      "3043:       return tsl::Status(port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "3042:       return tsl::Status(tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 33 ---",
      "[Context before]",
      "3163:   if (!algo_desc.has_value()) {",
      "3164:     return tsl::Status(",
      "3166:         \"The primary convolution algorithm failed memory allocation, \"",
      "3167:         \"while a secondary algorithm is not provided.\");",
      "3168:   }",
      "",
      "[Removed Lines]",
      "3165:         port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "3164:         tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 34 ---",
      "[Context before]",
      "3225:   if (!algo_desc.has_value()) {",
      "3226:     return tsl::Status(",
      "3228:         absl::StrCat(",
      "3229:             \"The primary convolution algorithm failed memory allocation, \"",
      "3230:             \"while a secondary algorithm is not provided. Actual error: \",",
      "",
      "[Removed Lines]",
      "3227:         port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "3226:         tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 35 ---",
      "[Context before]",
      "4256:       if (!timer->Init() || !timer->Start(AsGpuStream(stream))) {",
      "4258:       }",
      "4259:     }",
      "",
      "[Removed Lines]",
      "4257:         return tsl::Status(port::error::INTERNAL, \"Failed to start timer\");",
      "",
      "[Added Lines]",
      "4256:         return tsl::Status(tsl::error::INTERNAL, \"Failed to start timer\");",
      "",
      "---------------",
      "--- Hunk 36 ---",
      "[Context before]",
      "4264:           ToCudnnDataType(input_type_) == CUDNN_DATA_INT8 &&",
      "4265:           ToCudnnDataType(output_type_) == CUDNN_DATA_FLOAT) {",
      "4266:         return tsl::Status(",
      "4268:             \"This configuration potentially produces incorrect results.\");",
      "4269:       }",
      "4270: #else",
      "",
      "[Removed Lines]",
      "4267:             port::error::FAILED_PRECONDITION,",
      "",
      "[Added Lines]",
      "4266:             tsl::error::FAILED_PRECONDITION,",
      "",
      "---------------",
      "--- Hunk 37 ---",
      "[Context before]",
      "4337:     if (is_profiling) {",
      "4338:       if (!timer->Stop(AsGpuStream(stream))) {",
      "4340:       }",
      "4341:       profile_result->set_algorithm(algo);",
      "4342:       profile_result->set_elapsed_time_in_ms(timer->GetElapsedMilliseconds());",
      "",
      "[Removed Lines]",
      "4339:         return tsl::Status(port::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "[Added Lines]",
      "4338:         return tsl::Status(tsl::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "---------------",
      "--- Hunk 38 ---",
      "[Context before]",
      "4633:       if (!timer->Init() || !timer->Start(AsGpuStream(stream))) {",
      "4635:       }",
      "4636:     }",
      "",
      "[Removed Lines]",
      "4634:         return tsl::Status(port::error::INTERNAL, \"Failed to start timer\");",
      "",
      "[Added Lines]",
      "4633:         return tsl::Status(tsl::error::INTERNAL, \"Failed to start timer\");",
      "",
      "---------------",
      "--- Hunk 39 ---",
      "[Context before]",
      "4642:     if (is_profiling) {",
      "4643:       if (!timer->Stop(AsGpuStream(stream))) {",
      "4645:       }",
      "4646:       TF_ASSIGN_OR_RETURN(auto desc, ToAlgorithmDesc());",
      "4647:       profile_result->set_algorithm(desc);",
      "",
      "[Removed Lines]",
      "4644:         return tsl::Status(port::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "[Added Lines]",
      "4643:         return tsl::Status(tsl::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "---------------",
      "--- Hunk 40 ---",
      "[Context before]",
      "4868:     }",
      "4869:     if (!got_algos) {",
      "4870:       return tsl::Status(",
      "4872:           absl::StrFormat(\"Listing algorithms failed for kind %d\", kind));",
      "4873:     }",
      "",
      "[Removed Lines]",
      "4871:           port::error::UNKNOWN,",
      "",
      "[Added Lines]",
      "4870:           tsl::error::UNKNOWN,",
      "",
      "---------------",
      "--- Hunk 41 ---",
      "[Context before]",
      "5039:       if (!timer->Init() || !timer->Start(AsGpuStream(stream))) {",
      "5041:       }",
      "5042:     }",
      "5043:     auto side_input_data_ptr = (side_input_scale_ == 0)",
      "",
      "[Removed Lines]",
      "5040:         return tsl::Status(port::error::INTERNAL, \"Failed to start timer\");",
      "",
      "[Added Lines]",
      "5039:         return tsl::Status(tsl::error::INTERNAL, \"Failed to start timer\");",
      "",
      "---------------",
      "--- Hunk 42 ---",
      "[Context before]",
      "5065:             << \"\\noutput_data.opaque() = \" << output_data.opaque();",
      "5067:     if (IsTensorMathOpSet(conv_) != tensor_ops_enabled_) {",
      "5069:                          \"Tensor op math type in dnn::AlgorithmDesc does not \"",
      "5070:                          \"match that of the CudnnConvolutionDescriptor\");",
      "5071:     }",
      "",
      "[Removed Lines]",
      "5068:       return tsl::Status(port::error::FAILED_PRECONDITION,",
      "",
      "[Added Lines]",
      "5067:       return tsl::Status(tsl::error::FAILED_PRECONDITION,",
      "",
      "---------------",
      "--- Hunk 43 ---",
      "[Context before]",
      "5096:     if (profile_result) {",
      "5097:       if (!timer->Stop(AsGpuStream(stream))) {",
      "5099:       }",
      "5100:       profile_result->set_algorithm(algo);",
      "5101:       profile_result->set_elapsed_time_in_ms(timer->GetElapsedMilliseconds());",
      "",
      "[Removed Lines]",
      "5098:         return tsl::Status(port::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "[Added Lines]",
      "5097:         return tsl::Status(tsl::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "---------------",
      "--- Hunk 44 ---",
      "[Context before]",
      "5308:       activation_mode != dnn::ActivationMode::kElu &&",
      "5309:       activation_mode != dnn::ActivationMode::kLeakyRelu &&",
      "5310:       activation_mode != dnn::ActivationMode::kNone) {",
      "5312:                        \"CuDNN fusion only supports activations of \"",
      "5313:                        \"{Relu, Relu6, Elu, <None>}.\");",
      "5314:   }",
      "",
      "[Removed Lines]",
      "5311:     return tsl::Status(port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "5310:     return tsl::Status(tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 45 ---",
      "[Context before]",
      "5319:     auto cuda_compute_capability = stream->GetCudaComputeCapability();",
      "5320:     if (!GetConvolveAlgorithms(cuda_compute_capability, input_type,",
      "5321:                                &algorithms)) {",
      "5323:                          \"Listing fused convolve algorithms failed.\");",
      "5324:     }",
      "",
      "[Removed Lines]",
      "5322:       return tsl::Status(port::error::UNKNOWN,",
      "",
      "[Added Lines]",
      "5321:       return tsl::Status(tsl::error::UNKNOWN,",
      "",
      "---------------",
      "--- Hunk 46 ---",
      "[Context before]",
      "5354:       leakyrelu_alpha, input_descriptor, filter_descriptor, bias_descriptor,",
      "5355:       output_descriptor, convolution_descriptor, activation_mode, cudnn);",
      "5356:   if (!op_graph_status.status().ok()) {",
      "5358:                        absl::StrCat(\"Cudnn graph failed to build: \",",
      "5359:                                     op_graph_status.status().ToString()));",
      "5360:   }",
      "",
      "[Removed Lines]",
      "5357:     return tsl::Status(port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "5356:     return tsl::Status(tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 47 ---",
      "[Context before]",
      "5391:       input_type, bias_type, output_type, trans_a, trans_b, m, n, k, lda, ldb,",
      "5392:       ldc, activation_mode, cudnn);",
      "5393:   if (!op_graph_status.status().ok()) {",
      "5395:                        absl::StrCat(\"Cudnn graph failed to build: \",",
      "5396:                                     op_graph_status.status().ToString()));",
      "5397:   }",
      "",
      "[Removed Lines]",
      "5394:     return tsl::Status(port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "5393:     return tsl::Status(tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 48 ---",
      "[Context before]",
      "5685:     if (activation_mode != dnn::ActivationMode::kNone ||",
      "5686:         !side_input.is_null()) {",
      "5687:       return tsl::Status(",
      "5689:           absl::StrCat(",
      "5690:               \"Side input and activation are not supported by cuDNN version: \",",
      "5691:               CUDNN_VERSION));",
      "",
      "[Removed Lines]",
      "5688:           port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "5687:           tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 49 ---",
      "[Context before]",
      "5969:   if (activation_mode != dnn::ActivationMode::kRelu &&",
      "5970:       activation_mode != dnn::ActivationMode::kNone) {",
      "5972:                        \"cudnnConvolutionBiasActivationForward() only supports \"",
      "5973:                        \"Relu or None activation.\");",
      "5974:   }",
      "",
      "[Removed Lines]",
      "5971:     return tsl::Status(port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "5970:     return tsl::Status(tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 50 ---",
      "[Context before]",
      "6070:   }",
      "6072: #else",
      "6074:                      \"No supported cudnnGetCTCLossWorkspaceSize when \"",
      "6075:                      \"CUDNN_VERSION < 7.6.3\");",
      "6076: #endif",
      "",
      "[Removed Lines]",
      "6073:   return tsl::Status(port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "6072:   return tsl::Status(tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 51 ---",
      "[Context before]",
      "6100:     int ctc_loss_algo_id) {",
      "6102:   if (CUDNN_VERSION < 7603 || element_type != dnn::DataType::kFloat) {",
      "6104:                        \"CudnnCtcLossDescriptor is supported only when the \"",
      "6105:                        \"CUDNN_VERSION >= 7.6.3 and DataType is float\");",
      "6106:   }",
      "",
      "[Removed Lines]",
      "6103:     return tsl::Status(port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "6102:     return tsl::Status(tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 52 ---",
      "[Context before]",
      "6383:   if (max_batches_per_split == 0) {",
      "6384:     return tsl::Status(",
      "6386:         absl::StrCat(",
      "6387:             \"Tensor has too many elements for int32 indexing: batches=\",",
      "6388:             num_batches, \" elements_per_batch=\", elements_per_batch_input,",
      "",
      "[Removed Lines]",
      "6385:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "6384:         tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 53 ---",
      "[Context before]",
      "6442:   auto splits_or =",
      "6443:       GetTensorSplits(input_dimensions, output_dimensions, element_type);",
      "6444:   if (!splits_or.ok()) {",
      "6446:   }",
      "6447:   auto splits = std::move(splits_or.value());",
      "",
      "[Removed Lines]",
      "6445:     return tsl::Status(port::error::INTERNAL, \"Cudnn pooling failed to split\");",
      "",
      "[Added Lines]",
      "6444:     return tsl::Status(tsl::error::INTERNAL, \"Cudnn pooling failed to split\");",
      "",
      "---------------",
      "--- Hunk 54 ---",
      "[Context before]",
      "6511:   auto splits_or =",
      "6512:       GetTensorSplits(input_dimensions, output_dimensions, element_type);",
      "6513:   if (!splits_or.ok()) {",
      "6515:   }",
      "6516:   auto splits = std::move(splits_or.value());",
      "",
      "[Removed Lines]",
      "6514:     return tsl::Status(port::error::INTERNAL, \"Cudnn pooling failed to split\");",
      "",
      "[Added Lines]",
      "6513:     return tsl::Status(tsl::error::INTERNAL, \"Cudnn pooling failed to split\");",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc": [
      "File: tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc -> tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "35: #include \"absl/synchronization/notification.h\"",
      "36: #include \"third_party/gpus/cuda/include/cuda_runtime_api.h\"",
      "37: #include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.h\"",
      "39: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "40: #include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"",
      "41: #include \"tensorflow/tsl/platform/env.h\"",
      "42: #include \"tensorflow/tsl/platform/stacktrace.h\"",
      "43: #include \"tensorflow/tsl/platform/static_threadlocal.h\"",
      "44: #include \"tensorflow/tsl/platform/threadpool.h\"",
      "",
      "[Removed Lines]",
      "38: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "",
      "[Added Lines]",
      "41: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "267:   }",
      "269:   Diagnostician::LogDiagnosticInformation();",
      "271:                      absl::StrCat(\"failed call to cuInit: \", ToString(res)));",
      "272: }",
      "",
      "[Removed Lines]",
      "270:   return tsl::Status(port::error::ABORTED,",
      "",
      "[Added Lines]",
      "270:   return tsl::Status(tsl::error::ABORTED,",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "400:     }",
      "401:   }",
      "404: }",
      "",
      "[Removed Lines]",
      "403:   return tsl::Status(port::error::INTERNAL, message);",
      "",
      "[Added Lines]",
      "403:   return tsl::Status(tsl::error::INTERNAL, message);",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "673:   }",
      "675:   return tsl::Status(",
      "677:       absl::StrCat(\"failed to get device for context: \", ToString(result)));",
      "678: }",
      "",
      "[Removed Lines]",
      "676:       port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "676:       tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "973:                                                  CUevent* event) {",
      "974:   if (*event == nullptr) {",
      "976:                        \"input event cannot be null\");",
      "977:   }",
      "",
      "[Removed Lines]",
      "975:     return tsl::Status(port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "975:     return tsl::Status(tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "997:   CUresult res = cuEventQuery(event);",
      "998:   if (res != CUDA_SUCCESS && res != CUDA_ERROR_NOT_READY) {",
      "999:     return tsl::Status(",
      "1001:         absl::StrFormat(\"failed to query event: %s\", ToString(res)));",
      "1002:   }",
      "",
      "[Removed Lines]",
      "1000:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "1000:         tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 7 ---",
      "[Context before]",
      "1263:   if (res == CUDA_SUCCESS) {",
      "1264:     return ::tsl::OkStatus();",
      "1265:   } else if (res == CUDA_ERROR_OUT_OF_MEMORY) {",
      "1267:                        \"could not create CUDA event: out of device memory\");",
      "1268:   } else {",
      "1269:     return tsl::Status(",
      "1271:         absl::StrCat(\"could not create CUDA event: \", ToString(res)));",
      "1272:   }",
      "1273: }",
      "",
      "[Removed Lines]",
      "1266:     return tsl::Status(port::error::RESOURCE_EXHAUSTED,",
      "1270:         port::error::FAILED_PRECONDITION,",
      "",
      "[Added Lines]",
      "1266:     return tsl::Status(tsl::error::RESOURCE_EXHAUSTED,",
      "1270:         tsl::error::FAILED_PRECONDITION,",
      "",
      "---------------",
      "--- Hunk 8 ---",
      "[Context before]",
      "1300:     if (context == nullptr) {",
      "1301:       return tsl::Status(",
      "1303:           \"Empty context returned while querying context for device pointer\");",
      "1304:     }",
      "1305:     return context;",
      "1306:   }",
      "1308:   return tsl::Status(",
      "1310:       absl::StrCat(\"failed to query context for device pointer: \",",
      "1311:                    ToString(result)));",
      "1312: }",
      "",
      "[Removed Lines]",
      "1302:           port::error::UNAVAILABLE,",
      "1309:       port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "1302:           tsl::error::UNAVAILABLE,",
      "1309:       tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 9 ---",
      "[Context before]",
      "1324:         return MemorySpace::kHost;",
      "1325:       default:",
      "1326:         return tsl::Status(",
      "1328:             absl::StrCat(\"unknown memory space provided by CUDA API: \", value));",
      "1329:     }",
      "1330:   }",
      "1332:   return tsl::Status(",
      "1334:       absl::StrCat(\"failed to query device pointer for memory space: \",",
      "1335:                    ToString(result)));",
      "1336: }",
      "",
      "[Removed Lines]",
      "1327:             port::error::INTERNAL,",
      "1333:       port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "1327:             tsl::error::INTERNAL,",
      "1333:       tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 10 ---",
      "[Context before]",
      "1348:     return tsl::Status(",
      "1350:         absl::StrFormat(\"not a device pointer %p; %s\",",
      "1351:                         reinterpret_cast<void*>(dptr), ToString(result)));",
      "1352:   }",
      "1354:   return tsl::Status(",
      "1356:       absl::StrFormat(\"failed to get pointer into for device pointer %p; %s\",",
      "1357:                       reinterpret_cast<void*>(dptr), ToString(result)));",
      "1358: }",
      "",
      "[Removed Lines]",
      "1349:         port::error::NOT_FOUND,",
      "1355:       port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "1349:         tsl::error::NOT_FOUND,",
      "1355:       tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 11 ---",
      "[Context before]",
      "1377:       cc_major, CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MAJOR, device);",
      "1378:   if (res != CUDA_SUCCESS) {",
      "1379:     return tsl::Status(",
      "1381:         absl::StrFormat(",
      "1382:             \"failed to get compute capability major for device: %s; %d\",",
      "1383:             ToString(res), device));",
      "",
      "[Removed Lines]",
      "1380:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "1380:         tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 12 ---",
      "[Context before]",
      "1387:       cc_minor, CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MINOR, device);",
      "1388:   if (res != CUDA_SUCCESS) {",
      "1389:     return tsl::Status(",
      "1391:         absl::StrFormat(",
      "1392:             \"failed to get compute capability minor for device: %s; %d\",",
      "1393:             ToString(res), device));",
      "",
      "[Removed Lines]",
      "1390:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "1390:         tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 13 ---",
      "[Context before]",
      "1400:                                                      CUdevice device) {",
      "1401:   return tsl::Status{",
      "1403:       \"Feature not supported on CUDA platform (GetGpuISAVersion)\"};",
      "1404: }",
      "1407:   return tsl::Status{",
      "1409:       \"Feature not supported on CUDA platform (GetGpuGCNArchName)\"};",
      "1410: }",
      "",
      "[Removed Lines]",
      "1402:       port::error::INTERNAL,",
      "1408:       port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "1402:       tsl::error::INTERNAL,",
      "1408:       tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 14 ---",
      "[Context before]",
      "1519:   CUresult res = cuDeviceGetAttribute(&val, attribute, device);",
      "1520:   if (res != CUDA_SUCCESS) {",
      "1521:     return tsl::Status(",
      "1523:         absl::StrFormat(\"failed to get device attribute %d for device %d: %s\",",
      "1524:                         attribute, device, ToString(res)));",
      "1525:   }",
      "",
      "[Removed Lines]",
      "1522:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "1522:         tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 15 ---",
      "[Context before]",
      "1628:   if (result != CUDA_SUCCESS &&",
      "1629:       result != CUDA_ERROR_PEER_ACCESS_ALREADY_ENABLED) {",
      "1630:     return tsl::Status(",
      "1632:         absl::StrFormat(\"failed to enable peer access from %p to %p: %s\", from,",
      "1633:                         to, ToString(result)));",
      "1634:   }",
      "",
      "[Removed Lines]",
      "1631:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "1631:         tsl::error::INTERNAL,",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc": [
      "File: tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc -> tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "26: #include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_platform_id.h\"",
      "27: #include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_stream.h\"",
      "28: #include \"tensorflow/compiler/xla/stream_executor/device_memory.h\"",
      "30: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "31: #include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"",
      "32: #include \"tensorflow/compiler/xla/stream_executor/plugin_registry.h\"",
      "",
      "[Removed Lines]",
      "29: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "29: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc": [
      "File: tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc -> tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "42: #include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_stream.h\"",
      "43: #include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_timer.h\"",
      "44: #include \"tensorflow/compiler/xla/stream_executor/kernel_cache_config.h\"",
      "47: #include \"tensorflow/compiler/xla/stream_executor/platform.h\"",
      "48: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "49: #include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"",
      "50: #include \"tensorflow/compiler/xla/stream_executor/plugin_registry.h\"",
      "",
      "[Removed Lines]",
      "45: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "46: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "46: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "53: #include \"tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.h\"",
      "54: #include \"tensorflow/compiler/xla/stream_executor/timer.h\"",
      "55: #include \"tensorflow/tsl/platform/env.h\"",
      "56: #include \"tensorflow/tsl/platform/numbers.h\"",
      "57: #include \"tensorflow/tsl/platform/statusor.h\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "55: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "745:     return ::tsl::OkStatus();",
      "746:   } else {",
      "747:     return tsl::Status(",
      "749:         absl::StrFormat(\"error recording waiting for CUDA event on stream %p\",",
      "750:                         stream));",
      "751:   }",
      "",
      "[Removed Lines]",
      "748:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "748:         tsl::error::INTERNAL,",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/cuda/cuda_platform.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_platform.cc": [
      "File: tensorflow/compiler/xla/stream_executor/cuda/cuda_platform.cc -> tensorflow/compiler/xla/stream_executor/cuda/cuda_platform.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "23: #include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.h\"",
      "24: #include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.h\"",
      "25: #include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_platform_id.h\"",
      "28: #include \"tensorflow/tsl/platform/status.h\"",
      "30: namespace stream_executor {",
      "",
      "[Removed Lines]",
      "26: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "27: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "26: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "27: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "117:   }",
      "119:   return tsl::Status(",
      "121:       absl::StrFormat(\"Executor for bus %d not found.\", bus_ordinal));",
      "122: }",
      "",
      "[Removed Lines]",
      "120:       port::error::NOT_FOUND,",
      "",
      "[Added Lines]",
      "120:       tsl::error::NOT_FOUND,",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "177:   auto init_status = executor->Init(config.device_options);",
      "178:   if (!init_status.ok()) {",
      "179:     return tsl::Status(",
      "181:         absl::StrFormat(",
      "182:             \"failed initializing StreamExecutor for CUDA device ordinal %d: %s\",",
      "183:             config.ordinal, init_status.ToString()));",
      "",
      "[Removed Lines]",
      "180:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "180:         tsl::error::INTERNAL,",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/cuda/cuda_rng.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_rng.cc": [
      "File: tensorflow/compiler/xla/stream_executor/cuda/cuda_rng.cc -> tensorflow/compiler/xla/stream_executor/cuda/cuda_rng.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "23: #include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_platform_id.h\"",
      "24: #include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_stream.h\"",
      "25: #include \"tensorflow/compiler/xla/stream_executor/device_memory.h\"",
      "27: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "28: #include \"tensorflow/compiler/xla/stream_executor/rng.h\"",
      "29: #include \"tensorflow/tsl/platform/status.h\"",
      "",
      "[Removed Lines]",
      "26: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "26: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/host/host_gpu_executor.h||tensorflow/compiler/xla/stream_executor/host/host_gpu_executor.h": [
      "File: tensorflow/compiler/xla/stream_executor/host/host_gpu_executor.h -> tensorflow/compiler/xla/stream_executor/host/host_gpu_executor.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "25: #include \"tensorflow/compiler/xla/stream_executor/blas.h\"",
      "26: #include \"tensorflow/compiler/xla/stream_executor/host/host_stream.h\"",
      "27: #include \"tensorflow/compiler/xla/stream_executor/host/host_timer.h\"",
      "29: #include \"tensorflow/compiler/xla/stream_executor/rng.h\"",
      "30: #include \"tensorflow/compiler/xla/stream_executor/stream_executor.h\"",
      "31: #include \"tensorflow/compiler/xla/stream_executor/stream_executor_internal.h\"",
      "33: namespace stream_executor {",
      "34: namespace host {",
      "",
      "[Removed Lines]",
      "28: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "",
      "[Added Lines]",
      "31: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/host/host_platform.cc||tensorflow/compiler/xla/stream_executor/host/host_platform.cc": [
      "File: tensorflow/compiler/xla/stream_executor/host/host_platform.cc -> tensorflow/compiler/xla/stream_executor/host/host_platform.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "21: #include \"absl/strings/str_format.h\"",
      "22: #include \"tensorflow/compiler/xla/stream_executor/host/host_gpu_executor.h\"",
      "23: #include \"tensorflow/compiler/xla/stream_executor/host/host_platform_id.h\"",
      "27: namespace stream_executor {",
      "28: namespace host {",
      "",
      "[Removed Lines]",
      "24: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "25: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "24: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "25: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "75:   auto init_status = executor->Init(config.device_options);",
      "76:   if (!init_status.ok()) {",
      "77:     return tsl::Status(",
      "79:         absl::StrFormat(",
      "80:             \"failed initializing StreamExecutor for device ordinal %d: %s\",",
      "81:             config.ordinal, init_status.ToString().c_str()));",
      "",
      "[Removed Lines]",
      "78:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "78:         tsl::error::INTERNAL,",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/lib/error.h||tensorflow/compiler/xla/stream_executor/lib/error.h": [
      "File: tensorflow/compiler/xla/stream_executor/lib/error.h -> tensorflow/compiler/xla/stream_executor/lib/error.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "[No context available]",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/lib/initialize.h||tensorflow/compiler/xla/stream_executor/lib/initialize.h": [
      "File: tensorflow/compiler/xla/stream_executor/lib/initialize.h -> tensorflow/compiler/xla/stream_executor/lib/initialize.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "[No context available]",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/multi_platform_manager.cc||tensorflow/compiler/xla/stream_executor/multi_platform_manager.cc": [
      "File: tensorflow/compiler/xla/stream_executor/multi_platform_manager.cc -> tensorflow/compiler/xla/stream_executor/multi_platform_manager.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "24: #include \"absl/strings/str_join.h\"",
      "25: #include \"absl/strings/string_view.h\"",
      "26: #include \"absl/synchronization/mutex.h\"",
      "29: #include \"tensorflow/tsl/platform/errors.h\"",
      "31: namespace stream_executor {",
      "",
      "[Removed Lines]",
      "27: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "28: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "27: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "96:   std::string key = absl::AsciiStrToLower(platform->Name());",
      "97:   absl::MutexLock lock(&mu_);",
      "98:   if (name_map_.find(key) != name_map_.end()) {",
      "100:                        \"platform is already registered with name: \\\"\" +",
      "101:                            platform->Name() + \"\\\"\");",
      "102:   }",
      "",
      "[Removed Lines]",
      "99:     return tsl::Status(port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "98:     return tsl::Status(tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "156:   TF_ASSIGN_OR_RETURN(Platform * platform, LookupByNameLocked(target));",
      "157:   if (platform->Initialized()) {",
      "158:     return tsl::Status(",
      "160:         absl::StrCat(\"platform \\\"\", target, \"\\\" is already initialized\"));",
      "161:   }",
      "",
      "[Removed Lines]",
      "159:         port::error::FAILED_PRECONDITION,",
      "",
      "[Added Lines]",
      "158:         tsl::error::FAILED_PRECONDITION,",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "172:   TF_ASSIGN_OR_RETURN(Platform * platform, LookupByIdLocked(id));",
      "173:   if (platform->Initialized()) {",
      "174:     return tsl::Status(",
      "176:         absl::StrFormat(\"platform with id %p is already initialized\", id));",
      "177:   }",
      "",
      "[Removed Lines]",
      "175:         port::error::FAILED_PRECONDITION,",
      "",
      "[Added Lines]",
      "174:         tsl::error::FAILED_PRECONDITION,",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "232:   auto it = name_map_.find(absl::AsciiStrToLower(target));",
      "233:   if (it == name_map_.end()) {",
      "234:     return tsl::Status(",
      "236:         absl::StrCat(\"Could not find registered platform with name: \\\"\", target,",
      "237:                      \"\\\". Available platform names are: \",",
      "238:                      absl::StrJoin(InitializedPlatformNamesWithFilter(), \" \")));",
      "",
      "[Removed Lines]",
      "235:         port::error::NOT_FOUND,",
      "",
      "[Added Lines]",
      "234:         tsl::error::NOT_FOUND,",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "245:   auto it = id_map_.find(id);",
      "246:   if (it == id_map_.end()) {",
      "247:     return tsl::Status(",
      "249:         absl::StrFormat(\"could not find registered platform with id: %p\", id));",
      "250:   }",
      "251:   return it->second;",
      "",
      "[Removed Lines]",
      "248:         port::error::NOT_FOUND,",
      "",
      "[Added Lines]",
      "247:         tsl::error::NOT_FOUND,",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/multi_platform_manager.h||tensorflow/compiler/xla/stream_executor/multi_platform_manager.h": [
      "File: tensorflow/compiler/xla/stream_executor/multi_platform_manager.h -> tensorflow/compiler/xla/stream_executor/multi_platform_manager.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "70: #include <vector>",
      "72: #include \"absl/strings/string_view.h\"",
      "74: #include \"tensorflow/compiler/xla/stream_executor/platform.h\"",
      "75: #include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"",
      "76: #include \"tensorflow/tsl/platform/status.h\"",
      "77: #include \"tensorflow/tsl/platform/statusor.h\"",
      "",
      "[Removed Lines]",
      "73: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "74: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/platform.cc||tensorflow/compiler/xla/stream_executor/platform.cc": [
      "File: tensorflow/compiler/xla/stream_executor/platform.cc -> tensorflow/compiler/xla/stream_executor/platform.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "16: #include \"tensorflow/compiler/xla/stream_executor/platform.h\"",
      "18: #include \"absl/strings/str_cat.h\"",
      "20: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "21: #include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"",
      "22: #include \"tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.h\"",
      "24: namespace stream_executor {",
      "",
      "[Removed Lines]",
      "19: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "",
      "[Added Lines]",
      "22: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "92: tsl::Status Platform::Initialize(",
      "93:     const std::map<std::string, std::string> &platform_options) {",
      "94:   if (!platform_options.empty()) {",
      "96:                        \"this platform does not support custom initialization\");",
      "97:   }",
      "98:   return ::tsl::OkStatus();",
      "99: }",
      "101: tsl::Status Platform::ForceExecutorShutdown() {",
      "103:                      \"executor shutdown is not supported on this platform\");",
      "104: }",
      "",
      "[Removed Lines]",
      "95:     return tsl::Status(port::error::UNIMPLEMENTED,",
      "102:   return tsl::Status(port::error::UNIMPLEMENTED,",
      "",
      "[Added Lines]",
      "95:     return tsl::Status(tsl::error::UNIMPLEMENTED,",
      "102:   return tsl::Status(tsl::error::UNIMPLEMENTED,",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/plugin_registry.cc||tensorflow/compiler/xla/stream_executor/plugin_registry.cc": [
      "File: tensorflow/compiler/xla/stream_executor/plugin_registry.cc -> tensorflow/compiler/xla/stream_executor/plugin_registry.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "19: #include \"absl/strings/str_cat.h\"",
      "20: #include \"absl/strings/str_format.h\"",
      "21: #include \"absl/synchronization/mutex.h\"",
      "23: #include \"tensorflow/compiler/xla/stream_executor/multi_platform_manager.h\"",
      "25: namespace stream_executor {",
      "",
      "[Removed Lines]",
      "22: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "",
      "[Added Lines]",
      "23: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "77:   if (factories->find(plugin_id) != factories->end()) {",
      "78:     return tsl::Status(",
      "80:         absl::StrFormat(\"Attempting to register factory for plugin %s when \"",
      "81:                         \"one has already been registered\",",
      "82:                         plugin_name));",
      "",
      "[Removed Lines]",
      "79:         port::error::ALREADY_EXISTS,",
      "",
      "[Added Lines]",
      "79:         tsl::error::ALREADY_EXISTS,",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "96:     iter = generic_factories.find(plugin_id);",
      "97:     if (iter == generic_factories.end()) {",
      "98:       return tsl::Status(",
      "100:           absl::StrFormat(\"Plugin ID %p not registered.\", plugin_id));",
      "101:     }",
      "102:   }",
      "",
      "[Removed Lines]",
      "99:           port::error::NOT_FOUND,",
      "",
      "[Added Lines]",
      "99:           tsl::error::NOT_FOUND,",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "217:                                                                               \\",
      "218:       if (plugin_id == kNullPlugin) {                                         \\",
      "219:         return tsl::Status(                                                   \\",
      "221:             \"No suitable \" PLUGIN_STRING                                      \\",
      "222:             \" plugin registered. Have you linked in a \" PLUGIN_STRING         \\",
      "223:             \"-providing plugin?\");                                            \\",
      "",
      "[Removed Lines]",
      "220:             port::error::FAILED_PRECONDITION,                                 \\",
      "",
      "[Added Lines]",
      "220:             tsl::error::FAILED_PRECONDITION,                                  \\",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "236:       PlatformKind platform_kind, PluginId plugin_id) {                       \\",
      "237:     auto iter = platform_id_by_kind_.find(platform_kind);                     \\",
      "238:     if (iter == platform_id_by_kind_.end()) {                                 \\",
      "240:                          absl::StrFormat(\"Platform kind %d not registered.\",  \\",
      "241:                                          static_cast<int>(platform_kind)));   \\",
      "242:     }                                                                         \\",
      "",
      "[Removed Lines]",
      "239:       return tsl::Status(port::error::FAILED_PRECONDITION,                    \\",
      "",
      "[Added Lines]",
      "239:       return tsl::Status(tsl::error::FAILED_PRECONDITION,                     \\",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/rocm/rocm_blas.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_blas.cc": [
      "File: tensorflow/compiler/xla/stream_executor/rocm/rocm_blas.cc -> tensorflow/compiler/xla/stream_executor/rocm/rocm_blas.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "32: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_helpers.h\"",
      "33: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_stream.h\"",
      "34: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_timer.h\"",
      "36: #include \"tensorflow/compiler/xla/stream_executor/platform/dso_loader.h\"",
      "37: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "38: #include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"",
      "39: #include \"tensorflow/compiler/xla/stream_executor/plugin_registry.h\"",
      "",
      "[Removed Lines]",
      "35: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "36: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/rocm/rocm_diagnostics.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_diagnostics.cc": [
      "File: tensorflow/compiler/xla/stream_executor/rocm/rocm_diagnostics.cc -> tensorflow/compiler/xla/stream_executor/rocm/rocm_diagnostics.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "35: #include \"absl/strings/str_format.h\"",
      "36: #include \"absl/strings/str_split.h\"",
      "37: #include \"absl/strings/strip.h\"",
      "39: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "40: #include \"tensorflow/tsl/platform/host_info.h\"",
      "42: namespace stream_executor {",
      "",
      "[Removed Lines]",
      "38: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "",
      "[Added Lines]",
      "39: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/rocm/rocm_dnn.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_dnn.cc": [
      "File: tensorflow/compiler/xla/stream_executor/rocm/rocm_dnn.cc -> tensorflow/compiler/xla/stream_executor/rocm/rocm_dnn.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "31: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_executor.h\"",
      "32: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_stream.h\"",
      "33: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_timer.h\"",
      "36: #include \"tensorflow/compiler/xla/stream_executor/platform/dso_loader.h\"",
      "37: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "38: #include \"tensorflow/compiler/xla/stream_executor/plugin_registry.h\"",
      "39: #include \"tensorflow/compiler/xla/stream_executor/rocm/rocm_diagnostics.h\"",
      "",
      "[Removed Lines]",
      "34: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "35: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "35: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "42: #include \"tensorflow/compiler/xla/stream_executor/stream.h\"",
      "43: #include \"tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.h\"",
      "44: #include \"tensorflow/tsl/platform/env.h\"",
      "45: #include \"tensorflow/tsl/platform/hash.h\"",
      "46: #include \"tensorflow/tsl/util/determinism.h\"",
      "47: #include \"tensorflow/tsl/util/env_var.h\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "44: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/rocm/rocm_driver.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_driver.cc": [
      "File: tensorflow/compiler/xla/stream_executor/rocm/rocm_driver.cc -> tensorflow/compiler/xla/stream_executor/rocm/rocm_driver.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "28: #include \"absl/synchronization/notification.h\"",
      "29: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_diagnostics.h\"",
      "30: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_driver.h\"",
      "32: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "33: #include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"",
      "34: #include \"tensorflow/compiler/xla/stream_executor/rocm/rocm_driver_wrapper.h\"",
      "35: #include \"tensorflow/tsl/platform/env.h\"",
      "36: #include \"tensorflow/tsl/platform/numbers.h\"",
      "37: #include \"tensorflow/tsl/platform/stacktrace.h\"",
      "38: #include \"tensorflow/tsl/platform/static_threadlocal.h\"",
      "",
      "[Removed Lines]",
      "31: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "",
      "[Added Lines]",
      "35: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/rocm/rocm_fft.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_fft.cc": [
      "File: tensorflow/compiler/xla/stream_executor/rocm/rocm_fft.cc -> tensorflow/compiler/xla/stream_executor/rocm/rocm_fft.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "22: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_executor.h\"",
      "23: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_helpers.h\"",
      "24: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_stream.h\"",
      "26: #include \"tensorflow/compiler/xla/stream_executor/platform/dso_loader.h\"",
      "27: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "28: #include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"",
      "29: #include \"tensorflow/compiler/xla/stream_executor/plugin_registry.h\"",
      "",
      "[Removed Lines]",
      "25: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "26: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/rocm/rocm_gpu_executor.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_gpu_executor.cc": [
      "File: tensorflow/compiler/xla/stream_executor/rocm/rocm_gpu_executor.cc -> tensorflow/compiler/xla/stream_executor/rocm/rocm_gpu_executor.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "28: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_stream.h\"",
      "29: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_timer.h\"",
      "30: #include \"tensorflow/compiler/xla/stream_executor/kernel_cache_config.h\"",
      "33: #include \"tensorflow/compiler/xla/stream_executor/platform.h\"",
      "34: #include \"tensorflow/compiler/xla/stream_executor/platform/dso_loader.h\"",
      "35: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "36: #include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"",
      "37: #include \"tensorflow/compiler/xla/stream_executor/plugin_registry.h\"",
      "",
      "[Removed Lines]",
      "31: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "32: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "33: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "42: #include \"tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.h\"",
      "43: #include \"tensorflow/compiler/xla/stream_executor/timer.h\"",
      "44: #include \"tensorflow/tsl/platform/env.h\"",
      "46: #ifdef PLATFORMS_GPUS_ROCM_DYNAMIC_LIBROCM_DYNAMIC_LIBROCM_H_",
      "47: #error \\",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "44: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/rocm/rocm_platform.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_platform.cc": [
      "File: tensorflow/compiler/xla/stream_executor/rocm/rocm_platform.cc -> tensorflow/compiler/xla/stream_executor/rocm/rocm_platform.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "21: #include \"absl/strings/str_format.h\"",
      "22: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_driver.h\"",
      "23: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_executor.h\"",
      "26: #include \"tensorflow/compiler/xla/stream_executor/rocm/rocm_platform_id.h\"",
      "28: namespace stream_executor {",
      "29: namespace gpu {",
      "",
      "[Removed Lines]",
      "24: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "25: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "24: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "26: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/rocm/rocm_rng.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_rng.cc": [
      "File: tensorflow/compiler/xla/stream_executor/rocm/rocm_rng.cc -> tensorflow/compiler/xla/stream_executor/rocm/rocm_rng.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "20: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_helpers.h\"",
      "21: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_rng.h\"",
      "22: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_stream.h\"",
      "24: #include \"tensorflow/compiler/xla/stream_executor/platform/dso_loader.h\"",
      "25: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "26: #include \"tensorflow/compiler/xla/stream_executor/rng.h\"",
      "27: #include \"tensorflow/compiler/xla/stream_executor/rocm/rocm_platform_id.h\"",
      "",
      "[Removed Lines]",
      "23: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "24: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.cc||tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.cc": [
      "File: tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.cc -> tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "32: #include \"absl/synchronization/notification.h\"",
      "33: #include \"tensorflow/compiler/xla/stream_executor/blas.h\"",
      "34: #include \"tensorflow/compiler/xla/stream_executor/fft.h\"",
      "36: #include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"",
      "37: #include \"tensorflow/compiler/xla/stream_executor/rng.h\"",
      "38: #include \"tensorflow/compiler/xla/stream_executor/stream.h\"",
      "39: #include \"tensorflow/compiler/xla/stream_executor/stream_executor_internal.h\"",
      "40: #include \"tensorflow/tsl/platform/stacktrace.h\"",
      "41: #include \"tensorflow/tsl/platform/statusor.h\"",
      "42: #include \"tensorflow/tsl/platform/threadpool.h\"",
      "",
      "[Removed Lines]",
      "35: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "",
      "[Added Lines]",
      "39: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "405:     bool use_padded_io) {",
      "406:   dnn::DnnSupport* dnn_support = AsDnn();",
      "407:   if (!dnn_support) {",
      "409:                        \"Fail to find the dnn implementation.\");",
      "410:   }",
      "411:   return dnn_support->createRnnDescriptor(",
      "",
      "[Removed Lines]",
      "408:     return tsl::Status(port::error::UNKNOWN,",
      "",
      "[Added Lines]",
      "408:     return tsl::Status(tsl::error::UNKNOWN,",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "420:                                                   dnn::DataType data_type) {",
      "421:   dnn::DnnSupport* dnn_support = AsDnn();",
      "422:   if (!dnn_support) {",
      "424:                        \"Fail to find the dnn implementation.\");",
      "425:   }",
      "426:   return dnn_support->createRnnSequenceTensorDescriptor(",
      "",
      "[Removed Lines]",
      "423:     return tsl::Status(port::error::UNKNOWN,",
      "",
      "[Added Lines]",
      "423:     return tsl::Status(tsl::error::UNKNOWN,",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "434:     dnn::DataType data_type) {",
      "435:   dnn::DnnSupport* dnn_support = AsDnn();",
      "436:   if (!dnn_support) {",
      "438:                        \"Fail to find the dnn implementation.\");",
      "439:   }",
      "440:   return dnn_support->createRnnSequenceTensorDescriptor(",
      "",
      "[Removed Lines]",
      "437:     return tsl::Status(port::error::UNKNOWN,",
      "",
      "[Added Lines]",
      "437:     return tsl::Status(tsl::error::UNKNOWN,",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "448:                                                dnn::DataType data_type) {",
      "449:   dnn::DnnSupport* dnn_support = AsDnn();",
      "450:   if (!dnn_support) {",
      "452:                        \"Fail to find the dnn implementation.\");",
      "453:   }",
      "454:   return dnn_support->createRnnStateTensorDescriptor(num_layer, batch_size,",
      "",
      "[Removed Lines]",
      "451:     return tsl::Status(port::error::UNKNOWN,",
      "",
      "[Added Lines]",
      "451:     return tsl::Status(tsl::error::UNKNOWN,",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "546:   }",
      "548:   return tsl::Status(",
      "550:       absl::StrCat(\"Check if module containing symbol \", symbol_name,",
      "551:                    \" is loaded (module_handle = \",",
      "552:                    reinterpret_cast<uintptr_t>(module_handle.id()), \")\"));",
      "",
      "[Removed Lines]",
      "549:       port::error::NOT_FOUND,",
      "",
      "[Added Lines]",
      "549:       tsl::error::NOT_FOUND,",
      "",
      "---------------",
      "--- Hunk 7 ---",
      "[Context before]",
      "691:   result = implementation_->SynchronousMemcpy(host_dst, device_src, size);",
      "692:   if (!result.ok()) {",
      "693:     result = tsl::Status(",
      "695:         absl::StrFormat(\"failed to synchronously memcpy device-to-host: device \"",
      "696:                         \"%p to host %p size %d: %s\",",
      "697:                         device_src.opaque(), host_dst, size,",
      "",
      "[Removed Lines]",
      "694:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "694:         tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 8 ---",
      "[Context before]",
      "715:   result = implementation_->SynchronousMemcpy(device_dst, host_src, size);",
      "716:   if (!result.ok()) {",
      "717:     result = tsl::Status(",
      "719:         absl::StrFormat(\"failed to synchronously memcpy host-to-device: host \"",
      "720:                         \"%p to device %p size %d: %s\",",
      "721:                         host_src, device_dst->opaque(), size,",
      "",
      "[Removed Lines]",
      "718:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "718:         tsl::error::INTERNAL,",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/tf_allocator_adapter.cc||tensorflow/compiler/xla/stream_executor/tf_allocator_adapter.cc": [
      "File: tensorflow/compiler/xla/stream_executor/tf_allocator_adapter.cc -> tensorflow/compiler/xla/stream_executor/tf_allocator_adapter.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "16: #include \"tensorflow/compiler/xla/stream_executor/tf_allocator_adapter.h\"",
      "18: #include \"absl/synchronization/mutex.h\"",
      "20: #include \"tensorflow/compiler/xla/stream_executor/stream.h\"",
      "21: #include \"tensorflow/compiler/xla/stream_executor/stream_executor.h\"",
      "22: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "[Removed Lines]",
      "19: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------"
    ],
    "tensorflow/core/common_runtime/function.cc||tensorflow/core/common_runtime/function.cc": [
      "File: tensorflow/core/common_runtime/function.cc -> tensorflow/core/common_runtime/function.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "535:     OP_REQUIRES_ASYNC(ctx, lib != nullptr,",
      "536:                       errors::Internal(\"No function library is provided.\"),",
      "537:                       done);",
      "539:     opts.rendezvous = ctx->rendezvous();",
      "540:     opts.cancellation_manager = ctx->cancellation_manager();",
      "541:     opts.step_container = ctx->step_container();",
      "",
      "[Removed Lines]",
      "538:     FunctionLibraryRuntime::Options opts;",
      "",
      "[Added Lines]",
      "538:     FunctionLibraryRuntime::Options opts(ctx->step_id());",
      "",
      "---------------"
    ],
    "tensorflow/core/data/service/server_lib.cc||tensorflow/core/data/service/server_lib.cc": [
      "File: tensorflow/core/data/service/server_lib.cc -> tensorflow/core/data/service/server_lib.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "37: }",
      "39: GrpcDataServerBase::GrpcDataServerBase(",
      "41:     std::vector<std::unique_ptr<::grpc::ServerBuilderOption>> options)",
      "42:     : requested_port_(port),",
      "43:       protocol_(protocol),",
      "",
      "[Removed Lines]",
      "40:     int port, const std::string& protocol, const std::string server_type,",
      "",
      "[Added Lines]",
      "40:     int port, const std::string& protocol, const std::string& server_type,",
      "",
      "---------------"
    ],
    "tensorflow/core/data/service/server_lib.h||tensorflow/core/data/service/server_lib.h": [
      "File: tensorflow/core/data/service/server_lib.h -> tensorflow/core/data/service/server_lib.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "45:   GrpcDataServerBase(",
      "46:       int requested_port, const std::string& protocol,",
      "48:       std::vector<std::unique_ptr<::grpc::ServerBuilderOption>> options = {});",
      "49:   virtual ~GrpcDataServerBase() = default;",
      "",
      "[Removed Lines]",
      "47:       const std::string server_type,",
      "",
      "[Added Lines]",
      "47:       const std::string& server_type,",
      "",
      "---------------"
    ],
    "tensorflow/core/data/service/snapshot/path_utils.cc||tensorflow/core/data/service/snapshot/path_utils.cc": [
      "File: tensorflow/core/data/service/snapshot/path_utils.cc -> tensorflow/core/data/service/snapshot/path_utils.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "15: #include \"tensorflow/core/data/service/snapshot/path_utils.h\"",
      "17: #include <string>",
      "19: #include \"absl/strings/str_cat.h\"",
      "20: #include \"absl/strings/string_view.h\"",
      "21: #include \"tensorflow/tsl/platform/path.h\"",
      "23: namespace tensorflow {",
      "24: namespace data {",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "18: #include <utility>",
      "19: #include <vector>",
      "22: #include \"absl/strings/str_split.h\"",
      "24: #include \"tensorflow/tsl/platform/errors.h\"",
      "26: #include \"tensorflow/tsl/platform/statusor.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "65:       absl::StrCat(\"split_\", local_index, \"_\", global_index));",
      "66: }",
      "68: std::string SnapshotMetadataFilePath(absl::string_view snapshot_path_) {",
      "69:   return tsl::io::JoinPath(snapshot_path_, kSnapshotMetadataFileName);",
      "70: }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "73: tsl::StatusOr<std::pair<int64_t, int64_t>> SplitIndex(",
      "74:     absl::string_view split_path) {",
      "75:   std::vector<std::string> tokens = absl::StrSplit(split_path, '_');",
      "76:   int64_t local_split_index = 0, global_split_index = 0;",
      "77:   if (tokens.size() != 3 || tokens[0] != \"split\" ||",
      "78:       !absl::SimpleAtoi(tokens[1], &local_split_index) ||",
      "79:       local_split_index < 0 ||",
      "80:       !absl::SimpleAtoi(tokens[2], &global_split_index) ||",
      "81:       global_split_index < 0) {",
      "82:     return tsl::errors::InvalidArgument(",
      "83:         \"Invalid split file name: \", split_path,",
      "84:         \". Expected split_<local_split_index>_<global_split_index>.\");",
      "85:   }",
      "86:   if (local_split_index > global_split_index) {",
      "87:     return tsl::errors::InvalidArgument(",
      "88:         \"Invalid split file name: \", split_path, \". The local split index \",",
      "89:         local_split_index, \" exceeds the global split index \",",
      "90:         global_split_index, \".\");",
      "91:   }",
      "92:   return std::make_pair(local_split_index, global_split_index);",
      "93: }",
      "",
      "---------------"
    ],
    "tensorflow/core/data/service/snapshot/path_utils.h||tensorflow/core/data/service/snapshot/path_utils.h": [
      "File: tensorflow/core/data/service/snapshot/path_utils.h -> tensorflow/core/data/service/snapshot/path_utils.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "16: #define TENSORFLOW_CORE_DATA_SERVICE_SNAPSHOT_PATH_UTILS_H_",
      "18: #include <string>",
      "20: #include \"absl/strings/string_view.h\"",
      "22: namespace tensorflow {",
      "23: namespace data {",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "19: #include <utility>",
      "22: #include \"tensorflow/tsl/platform/statusor.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "45:                       int64_t source_id, int64_t local_index,",
      "46:                       int64_t global_index);",
      "49: std::string StreamDoneFilePath(absl::string_view snapshot_path,",
      "50:                                int64_t stream_index);",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "53: tsl::StatusOr<std::pair<int64_t, int64_t>> SplitIndex(",
      "54:     absl::string_view split_path);",
      "",
      "---------------"
    ],
    "tensorflow/core/data/service/snapshot/path_utils_test.cc||tensorflow/core/data/service/snapshot/path_utils_test.cc": [
      "File: tensorflow/core/data/service/snapshot/path_utils_test.cc -> tensorflow/core/data/service/snapshot/path_utils_test.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "15: #include \"tensorflow/core/data/service/snapshot/path_utils.h\"",
      "17: #include \"tensorflow/tsl/platform/test.h\"",
      "19: namespace tensorflow {",
      "20: namespace data {",
      "21: namespace {",
      "23: using ::testing::MatchesRegex;",
      "25: TEST(PathUtilsTest, StreamsDirectory) {",
      "26:   EXPECT_THAT(StreamsDirectory(\"/path/to/snapshot\"),",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "17: #include \"tensorflow/tsl/platform/status_matchers.h\"",
      "19: #include \"tensorflow/tsl/protobuf/error_codes.pb.h\"",
      "25: using ::testing::HasSubstr;",
      "27: using ::testing::Pair;",
      "28: using tsl::testing::IsOkAndHolds;",
      "29: using tsl::testing::StatusIs;",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "51:           \"/path/to/snapshot.streams.stream_0.splits.source_1.split_2_3\"));",
      "52: }",
      "54: TEST(PathUtilsTest, StreamDoneFilePath) {",
      "55:   EXPECT_THAT(StreamDoneFilePath(\"/path/to/snapshot\", /*stream_index=*/0),",
      "56:               MatchesRegex(\"/path/to/snapshot.streams.stream_0.DONE\"));",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "60: TEST(PathUtilsTest, SplitIndex) {",
      "61:   EXPECT_THAT(SplitIndex(\"split_0_1\"), IsOkAndHolds(Pair(0, 1)));",
      "62: }",
      "64: TEST(PathUtilsTest, InvalidSplitFile) {",
      "65:   EXPECT_THAT(",
      "66:       SplitIndex(\"\"),",
      "67:       StatusIs(error::INVALID_ARGUMENT,",
      "68:                HasSubstr(",
      "69:                    \"Expected split_<local_split_index>_<global_split_index>\")));",
      "70:   EXPECT_THAT(",
      "71:       SplitIndex(\"split_123\"),",
      "72:       StatusIs(error::INVALID_ARGUMENT,",
      "73:                HasSubstr(",
      "74:                    \"Expected split_<local_split_index>_<global_split_index>\")));",
      "75:   EXPECT_THAT(",
      "76:       SplitIndex(\"split_-1_(-1)\"),",
      "77:       StatusIs(error::INVALID_ARGUMENT,",
      "78:                HasSubstr(",
      "79:                    \"Expected split_<local_split_index>_<global_split_index>\")));",
      "80:   EXPECT_THAT(",
      "81:       SplitIndex(\"split_5_0\"),",
      "82:       StatusIs(",
      "83:           error::INVALID_ARGUMENT,",
      "84:           HasSubstr(",
      "85:               \"The local split index 5 exceeds the global split index 0\")));",
      "86: }",
      "",
      "---------------"
    ],
    "tensorflow/core/data/service/snapshot/snapshot_manager.cc||tensorflow/core/data/service/snapshot/snapshot_manager.cc": [
      "File: tensorflow/core/data/service/snapshot/snapshot_manager.cc -> tensorflow/core/data/service/snapshot/snapshot_manager.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "205:     if (local_split_index > split_filenames.size() - 1) {",
      "206:       return InvalidArgument(",
      "207:           \"found conflict between the number of splits and name of \",",
      "",
      "[Removed Lines]",
      "190:     std::vector<std::string> tokens = absl::StrSplit(split_filename, '_');",
      "191:     int64_t local_split_index;",
      "192:     int64_t global_split_index;",
      "193:     if (tokens.size() != 3 ||",
      "194:         !absl::SimpleAtoi(tokens[1], &local_split_index) ||",
      "195:         local_split_index < 0 ||",
      "196:         !absl::SimpleAtoi(tokens[2], &global_split_index) ||",
      "197:         global_split_index < 0) {",
      "198:       return InvalidArgument(\"can't parse the name of \", split_path);",
      "199:     }",
      "200:     if (local_split_index > global_split_index) {",
      "201:       return InvalidArgument(",
      "202:           \"found conflict between local split index and global split index in \",",
      "203:           \"name of \", split_path);",
      "204:     }",
      "",
      "[Added Lines]",
      "190:     TF_ASSIGN_OR_RETURN(auto split_index, SplitIndex(split_filename));",
      "191:     auto [local_split_index, global_split_index] = split_index;",
      "",
      "---------------"
    ],
    "tensorflow/core/data/tfdataz_metrics.cc||tensorflow/core/data/tfdataz_metrics.cc": [
      "File: tensorflow/core/data/tfdataz_metrics.cc -> tensorflow/core/data/tfdataz_metrics.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "88:   return absl::Duration(absl::Microseconds(interval_latency)) / interval_count;",
      "89: }",
      "94: void TfDatazMetricsCollector::RecordGetNextLatency(",
      "95:     int64_t get_next_latency_usec) {",
      "",
      "[Removed Lines]",
      "91: TfDatazMetricsCollector::TfDatazMetricsCollector(const Env& env)",
      "92:     : latency_estimator_(env) {}",
      "",
      "[Added Lines]",
      "91: TfDatazMetricsCollector::TfDatazMetricsCollector(const Env& env,",
      "92:                                                  IteratorBase* iterator)",
      "93:     : iterator_(iterator), latency_estimator_(env) {}",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "113:       ApproximateLatencyEstimator::Duration::kSixtyMinutes);",
      "114: }",
      "116: namespace {",
      "117: static mutex* get_tfdataz_metrics_registry_lock() {",
      "118:   static mutex tfdataz_metrics_registry_lock(LINKER_INITIALIZED);",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "117: int64_t TfDatazMetricsCollector::GetIteratorTotalMemoryUsage() {",
      "118:   return iterator_->TotalBufferedBytes();",
      "119: }",
      "",
      "---------------"
    ],
    "tensorflow/core/data/tfdataz_metrics.h||tensorflow/core/data/tfdataz_metrics.h": [
      "File: tensorflow/core/data/tfdataz_metrics.h -> tensorflow/core/data/tfdataz_metrics.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "26: #include \"absl/container/flat_hash_set.h\"",
      "27: #include \"absl/time/time.h\"",
      "28: #include \"tensorflow/core/platform/env.h\"",
      "29: #include \"tensorflow/core/platform/mutex.h\"",
      "30: #include \"tensorflow/core/platform/thread_annotations.h\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "28: #include \"tensorflow/core/framework/dataset.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "101:   void RecordGetNextLatency(int64_t get_next_latency_usec);",
      "",
      "[Removed Lines]",
      "98:   explicit TfDatazMetricsCollector(const Env& env);",
      "",
      "[Added Lines]",
      "99:   TfDatazMetricsCollector(const Env& env, IteratorBase* iterator);",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "110:   absl::Duration GetAverageLatencyForLastSixtyMinutes();",
      "112:  private:",
      "113:   ApproximateLatencyEstimator latency_estimator_;",
      "114: };",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "116:   int64_t GetIteratorTotalMemoryUsage();",
      "119:   IteratorBase* iterator_;  // not owned",
      "",
      "---------------"
    ],
    "tensorflow/core/data/tfdataz_metrics_test.cc||tensorflow/core/data/tfdataz_metrics_test.cc": [
      "File: tensorflow/core/data/tfdataz_metrics_test.cc -> tensorflow/core/data/tfdataz_metrics_test.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "18: #include <utility>",
      "20: #include \"absl/time/time.h\"",
      "22: #include \"tensorflow/core/platform/env.h\"",
      "23: #include \"tensorflow/core/platform/test.h\"",
      "24: #include \"tensorflow/core/util/fake_clock_env.h\"",
      "",
      "[Removed Lines]",
      "21: #include \"tensorflow/core/framework/types.h\"",
      "",
      "[Added Lines]",
      "21: #include \"tensorflow/core/framework/dataset.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "41:  protected:",
      "42:   void SetUp() override {",
      "43:     env_ = std::make_unique<FakeClockEnv>(Env::Default());",
      "45:   }",
      "47:   void TearDown() override {",
      "",
      "[Removed Lines]",
      "44:     tfdataz_metrics_ = std::make_unique<TfDatazMetricsCollector>(*env_);",
      "",
      "[Added Lines]",
      "44:     tfdataz_metrics_ =",
      "45:         std::make_unique<TfDatazMetricsCollector>(*env_, iterator_.get());",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "49:     tfdataz_metrics_.reset();",
      "50:   }",
      "52:   std::unique_ptr<FakeClockEnv> env_;",
      "53:   std::unique_ptr<TfDatazMetricsCollector> tfdataz_metrics_;",
      "54: };",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "53:   std::unique_ptr<IteratorBase> iterator_;",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "184: };",
      "186: TEST(TfDatazMetricsRegistryTest, Register) {",
      "192:   ScopedTfDataMetricsRegistration scoped_registration_one(collector_one);",
      "193:   ScopedTfDataMetricsRegistration scoped_registration_two(collector_two);",
      "",
      "[Removed Lines]",
      "187:   auto collector_one =",
      "188:       std::make_shared<TfDatazMetricsCollector>(*Env::Default());",
      "189:   auto collector_two =",
      "190:       std::make_shared<TfDatazMetricsCollector>(*Env::Default());",
      "",
      "[Added Lines]",
      "189:   std::unique_ptr<IteratorBase> iterator;",
      "190:   auto collector_one = std::make_shared<TfDatazMetricsCollector>(",
      "192:   auto collector_two = std::make_shared<TfDatazMetricsCollector>(",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "196: }",
      "198: TEST(TfDatazMetricsRegistryTest, Deregister) {",
      "205:   ScopedTfDataMetricsRegistration scoped_registration_one(collector_one);",
      "206:   ScopedTfDataMetricsRegistration scoped_registration_two(collector_two);",
      "207:   ScopedTfDataMetricsRegistration scoped_registration_three(collector_three);",
      "",
      "[Removed Lines]",
      "199:   auto collector_one =",
      "200:       std::make_shared<TfDatazMetricsCollector>(*Env::Default());",
      "201:   auto collector_two =",
      "202:       std::make_shared<TfDatazMetricsCollector>(*Env::Default());",
      "203:   auto collector_three =",
      "204:       std::make_shared<TfDatazMetricsCollector>(*Env::Default());",
      "",
      "[Added Lines]",
      "202:   std::unique_ptr<IteratorBase> iterator;",
      "203:   auto collector_one = std::make_shared<TfDatazMetricsCollector>(",
      "205:   auto collector_two = std::make_shared<TfDatazMetricsCollector>(",
      "207:   auto collector_three = std::make_shared<TfDatazMetricsCollector>(",
      "",
      "---------------"
    ],
    "tensorflow/core/distributed_runtime/eager/remote_mgr.cc||tensorflow/core/distributed_runtime/eager/remote_mgr.cc": [
      "File: tensorflow/core/distributed_runtime/eager/remote_mgr.cc -> tensorflow/core/distributed_runtime/eager/remote_mgr.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "33:   error_source_proto.set_error_source(",
      "34:       core::platform::ErrorSourceProto::EAGER_REMOTE_MGR);",
      "35:   error.SetPayload(tensorflow::kErrorSource,",
      "37:   return error;",
      "38: }",
      "39: }  // namespace",
      "",
      "[Removed Lines]",
      "36:                    error_source_proto.SerializeAsString());",
      "",
      "[Added Lines]",
      "36:                    absl::Cord(error_source_proto.SerializeAsString()));",
      "",
      "---------------"
    ],
    "tensorflow/core/distributed_runtime/integration_test/coordination_test_opkernel_registration.cc||tensorflow/core/distributed_runtime/integration_test/coordination_test_opkernel_registration.cc": [
      "File: tensorflow/core/distributed_runtime/integration_test/coordination_test_opkernel_registration.cc -> tensorflow/core/distributed_runtime/integration_test/coordination_test_opkernel_registration.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "149:     }",
      "150:     tensorflow::Status s(static_cast<tensorflow::error::Code>(error_code),",
      "151:                          error_message);",
      "153:     OP_REQUIRES_OK(ctx, coord_agent->ReportError(s));",
      "154:   }",
      "155: };",
      "",
      "[Removed Lines]",
      "152:     s.SetPayload(tsl::CoordinationErrorPayloadKey(), \"testing error payload\");",
      "",
      "[Added Lines]",
      "152:     s.SetPayload(tsl::CoordinationErrorPayloadKey(),",
      "153:                  absl::Cord(\"testing error payload\"));",
      "",
      "---------------"
    ],
    "tensorflow/core/framework/dataset.h||tensorflow/core/framework/dataset.h": [
      "File: tensorflow/core/framework/dataset.h -> tensorflow/core/framework/dataset.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "959:     return OkStatus();",
      "960:   }",
      "962:  protected:",
      "964:   virtual std::shared_ptr<model::Node> CreateNode(",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "964:   int64_t TotalBufferedBytes() const {",
      "965:     if (node_) return node_->TotalBufferedBytes();",
      "966:     return 0;",
      "967:   }",
      "",
      "---------------"
    ],
    "tensorflow/core/framework/op_requires.h||tensorflow/core/framework/op_requires.h": [
      "File: tensorflow/core/framework/op_requires.h -> tensorflow/core/framework/op_requires.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "62:     if (!TF_PREDICT_TRUE(STATUS.ok())) {                                       \\",
      "63:       CheckNotInComputeAsync((CTX), \"OP_REQUIRES_OK_ASYNC\");                   \\",
      "64:       if (!PAYLOAD_VALUE.empty()) {                                            \\",
      "66:       }                                                                        \\",
      "67:       (CTX)->CtxFailureWithWarning(__FILE__, __LINE__, STATUS);                \\",
      "68:       return;                                                                  \\",
      "",
      "[Removed Lines]",
      "65:         STATUS.SetPayload(PAYLOAD_KEY, PAYLOAD_VALUE);                         \\",
      "",
      "[Added Lines]",
      "65:         STATUS.SetPayload(PAYLOAD_KEY, absl::Cord(PAYLOAD_VALUE));             \\",
      "",
      "---------------"
    ],
    "tensorflow/core/kernels/data/iterator_ops.cc||tensorflow/core/kernels/data/iterator_ops.cc": [
      "File: tensorflow/core/kernels/data/iterator_ops.cc -> tensorflow/core/kernels/data/iterator_ops.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "94:       output_dtypes_(output_dtypes),",
      "95:       output_shapes_(output_shapes) {",
      "98:   VLOG(2) << \"creating iterator resource\";",
      "99: }",
      "",
      "[Removed Lines]",
      "96:   tf_dataz_metrics_collector_ = std::make_shared<TfDatazMetricsCollector>(*env);",
      "97:   TfDatazMetricsRegistry::Register(tf_dataz_metrics_collector_);",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "274:   new_state->MergeCheckpoint(iter_ctx.checkpoint());",
      "275:   mutex_lock l(mu_);",
      "276:   std::swap(iterator_state_, new_state);",
      "277:   return OkStatus();",
      "278: }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "275:   tf_dataz_metrics_collector_ =",
      "276:       std::make_shared<TfDatazMetricsCollector>(env_, iterator.get());",
      "277:   TfDatazMetricsRegistry::Register(tf_dataz_metrics_collector_);",
      "",
      "---------------"
    ],
    "tensorflow/core/kernels/function_ops.cc||tensorflow/core/kernels/function_ops.cc": [
      "File: tensorflow/core/kernels/function_ops.cc -> tensorflow/core/kernels/function_ops.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "238:     OP_REQUIRES_OK_ASYNC(",
      "239:         ctx, lib->Instantiate(kGradientOp, AttrSlice(def()), &handle), done);",
      "242:     opts.rendezvous = ctx->rendezvous();",
      "243:     opts.cancellation_manager = ctx->cancellation_manager();",
      "244:     opts.collective_executor = ctx->collective_executor();",
      "",
      "[Removed Lines]",
      "241:     FunctionLibraryRuntime::Options opts;",
      "",
      "[Added Lines]",
      "241:     FunctionLibraryRuntime::Options opts(ctx->step_id());",
      "",
      "---------------"
    ],
    "tensorflow/core/kernels/functional_ops.cc||tensorflow/core/kernels/functional_ops.cc": [
      "File: tensorflow/core/kernels/functional_ops.cc -> tensorflow/core/kernels/functional_ops.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "160:           then_handle_(then_handle),",
      "161:           else_handle_(else_handle),",
      "162:           done_(std::move(done)),",
      "164:       SetRunOptions(ctx_, &opts_, true /* always_collect_stats */);",
      "165:       for (int i = 1; i < ctx_->num_inputs(); ++i) {",
      "166:         args_.push_back(ctx_->input(i));",
      "",
      "[Removed Lines]",
      "163:           lib_(CHECK_NOTNULL(ctx_->function_library())) {",
      "",
      "[Added Lines]",
      "163:           lib_(CHECK_NOTNULL(ctx_->function_library())),",
      "164:           opts_(ctx->step_id()) {",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "286:           branch_(branch),",
      "287:           branch_handles_(branch_handles),",
      "288:           done_(std::move(done)),",
      "290:       SetRunOptions(ctx_, &opts_, true /* always_collect_stats */);",
      "291:       for (int i = 1; i < ctx_->num_inputs(); ++i) {",
      "292:         args_.push_back(ctx_->input(i));",
      "",
      "[Removed Lines]",
      "289:           lib_(CHECK_NOTNULL(ctx_->function_library())) {",
      "",
      "[Added Lines]",
      "290:           lib_(CHECK_NOTNULL(ctx_->function_library())),",
      "291:           opts_(ctx->step_id()) {",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "507:           cond_handle_(cond_handle),",
      "508:           body_handle_(body_handle),",
      "509:           done_(std::move(done)),",
      "511:       SetRunOptions(ctx_, &opts_, false /* always_collect_stats */);",
      "512:       GetArgsFromContext(ctx, &args_, &loop_var_types_);",
      "513:       body_frame_ =",
      "",
      "[Removed Lines]",
      "510:           lib_(CHECK_NOTNULL(ctx_->function_library())) {",
      "",
      "[Added Lines]",
      "512:           lib_(CHECK_NOTNULL(ctx_->function_library())),",
      "513:           opts_(ctx->step_id()) {",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "751:           ctx_(ctx),",
      "752:           done_(std::move(done)),",
      "753:           lib_(CHECK_NOTNULL(ctx_->function_library())),",
      "754:           args_(1 + ctx_->num_inputs() - 3) {",
      "755:       args_[0] = Tensor(DT_INT32, {});",
      "756:       iter_ = &args_[0].scalar<int32>()();",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "757:           opts_(ctx->step_id()),",
      "",
      "---------------"
    ],
    "tensorflow/core/kernels/rnn/gru_ops.cc||tensorflow/core/kernels/rnn/gru_ops.cc": [
      "File: tensorflow/core/kernels/rnn/gru_ops.cc -> tensorflow/core/kernels/rnn/gru_ops.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "49:     const Tensor* b_c_tensor = nullptr;",
      "50:     OP_REQUIRES_OK(ctx, ctx->input(\"b_c\", &b_c_tensor));",
      "52:     const int64_t batch_size = x_tensor->dim_size(0);",
      "53:     const int64_t input_size = x_tensor->dim_size(1);",
      "59:     OP_REQUIRES(ctx, h_prev_tensor->dim_size(0) == batch_size,",
      "60:                 errors::InvalidArgument(\"h_prev.dims(0) != batch_size: \",",
      "61:                                         h_prev_tensor->dim_size(0), \" vs. \",",
      "62:                                         batch_size));",
      "69:     OP_REQUIRES(ctx, w_ru_tensor->dim_size(0) == input_size + cell_size,",
      "70:                 errors::InvalidArgument(",
      "71:                     \"w_ru.dim_size(0) != input_size + cell_size: \",",
      "72:                     w_ru_tensor->dim_size(0), \" vs. \", input_size + cell_size));",
      "74:     OP_REQUIRES(ctx, w_ru_tensor->dim_size(1) == cell_size * 2,",
      "75:                 errors::InvalidArgument(\"w_ru.dim_size(1) != cell_size * 2: \",",
      "76:                                         w_ru_tensor->dim_size(1), \" vs. \",",
      "77:                                         cell_size * 2));",
      "80:     OP_REQUIRES(ctx, w_c_tensor->dim_size(0) == input_size + cell_size,",
      "81:                 errors::InvalidArgument(",
      "82:                     \"w_c.dim_size(0) != input_size + cell_size: \",",
      "83:                     w_c_tensor->dim_size(0), \" vs. \", input_size + cell_size));",
      "85:     OP_REQUIRES(ctx, w_c_tensor->dim_size(1) == cell_size,",
      "86:                 errors::InvalidArgument(",
      "87:                     \"w_c.dim_size(1) != cell_size: \", w_c_tensor->dim_size(1),",
      "88:                     \" vs. \", cell_size));",
      "91:     OP_REQUIRES(ctx, b_ru_tensor->dim_size(0) == cell_size * 2,",
      "92:                 errors::InvalidArgument(\"b_ru.dim_size(0) != cell_size * 2: \",",
      "93:                                         b_ru_tensor->dim_size(0), \" vs. \",",
      "94:                                         cell_size * 2));",
      "100:     OP_REQUIRES(ctx, b_c_tensor->dim_size(0) == cell_size,",
      "101:                 errors::InvalidArgument(",
      "102:                     \"b_c.dim_size(0) != cell_size: \", b_c_tensor->dim_size(0),",
      "103:                     \" vs. \", cell_size));",
      "109:     Tensor* r_tensor = nullptr;",
      "",
      "[Removed Lines]",
      "54:     const int64_t cell_size = h_prev_tensor->dim_size(1);",
      "63:     OP_REQUIRES(ctx, h_prev_tensor->dim_size(1) == cell_size,",
      "64:                 errors::InvalidArgument(",
      "65:                     \"h_prev.dims(1) != cell_size: \", h_prev_tensor->dim_size(1),",
      "66:                     \" vs. \", cell_size));",
      "96:     OP_REQUIRES(ctx, b_ru_tensor->dims() == 1,",
      "97:                 errors::InvalidArgument(\"Rank of b_ru must be 1\",",
      "98:                                         b_ru_tensor->dims(), \" vs. 1\", 1));",
      "104:     OP_REQUIRES(ctx, b_c_tensor->dims() == 1,",
      "105:                 errors::InvalidArgument(\"Rank of b_c must be 1\",",
      "106:                                         b_c_tensor->dims(), \" vs. 1\"));",
      "",
      "[Added Lines]",
      "55:     OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(x_tensor->shape()),",
      "56:                 errors::InvalidArgument(\"Rank of x must be 2\", x_tensor->dims(),",
      "57:                                         \" vs. 2\"));",
      "62:     OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(h_prev_tensor->shape()),",
      "63:                 errors::InvalidArgument(\"Rank of h_prev must be 2, got \",",
      "64:                                         h_prev_tensor->dims()));",
      "69:     const int64_t cell_size = h_prev_tensor->dim_size(1);",
      "72:     OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(w_ru_tensor->shape()),",
      "73:                 errors::InvalidArgument(\"Rank of w_ru_ must be 2, got \",",
      "74:                                         w_ru_tensor->dims()));",
      "85:     OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(w_c_tensor->shape()),",
      "86:                 errors::InvalidArgument(\"Rank of w_c must be 2, got \",",
      "87:                                         w_c_tensor->dims()));",
      "98:     OP_REQUIRES(ctx, TensorShapeUtils::IsVector(b_ru_tensor->shape()),",
      "99:                 errors::InvalidArgument(\"Rank of b_ru must be 1, got \",",
      "100:                                         b_ru_tensor->dims()));",
      "107:     OP_REQUIRES(ctx, TensorShapeUtils::IsVector(b_c_tensor->shape()),",
      "108:                 errors::InvalidArgument(\"Rank of b_c must be 1, got \",",
      "109:                                         b_c_tensor->dims()));",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "204:     const Tensor* d_h_tensor = nullptr;",
      "205:     OP_REQUIRES_OK(ctx, ctx->input(\"d_h\", &d_h_tensor));",
      "207:     const int64_t batch_size = x_tensor->dim_size(0);",
      "208:     const int64_t input_size = x_tensor->dim_size(1);",
      "214:     OP_REQUIRES(ctx, h_prev_tensor->dim_size(0) == batch_size,",
      "215:                 errors::InvalidArgument(\"h_prev.dims(0) != batch_size: \",",
      "216:                                         h_prev_tensor->dim_size(0), \" vs. \",",
      "217:                                         batch_size));",
      "224:     OP_REQUIRES(ctx, w_ru_tensor->dim_size(0) == input_size + cell_size,",
      "225:                 errors::InvalidArgument(",
      "226:                     \"w_ru.dim_size(0) != input_size + cell_size: \",",
      "227:                     w_ru_tensor->dim_size(0), \" vs. \", input_size + cell_size));",
      "229:     OP_REQUIRES(ctx, w_ru_tensor->dim_size(1) == cell_size * 2,",
      "230:                 errors::InvalidArgument(\"w_ru.dim_size(1) != cell_size * 2: \",",
      "231:                                         w_ru_tensor->dim_size(1), \" vs. \",",
      "232:                                         cell_size * 2));",
      "235:     OP_REQUIRES(ctx, w_c_tensor->dim_size(0) == input_size + cell_size,",
      "236:                 errors::InvalidArgument(",
      "237:                     \"w_c.dim_size(0) != input_size + cell_size: \",",
      "238:                     w_c_tensor->dim_size(0), \" vs. \", input_size + cell_size));",
      "240:     OP_REQUIRES(ctx, w_c_tensor->dim_size(1) == cell_size,",
      "241:                 errors::InvalidArgument(",
      "242:                     \"w_c.dim_size(1) != cell_size: \", w_c_tensor->dim_size(1),",
      "243:                     \" vs. \", cell_size));",
      "246:     OP_REQUIRES(ctx, b_ru_tensor->dim_size(0) == cell_size * 2,",
      "247:                 errors::InvalidArgument(\"b_ru.dim_size(0) != cell_size * 2: \",",
      "248:                                         b_ru_tensor->dim_size(0), \" vs. \",",
      "249:                                         cell_size * 2));",
      "256:     OP_REQUIRES(ctx, b_c_tensor->dim_size(0) == cell_size,",
      "257:                 errors::InvalidArgument(",
      "258:                     \"b_c.dim_size(0) != cell_size: \", b_c_tensor->dim_size(0),",
      "259:                     \" vs. \", cell_size));",
      "266:     OP_REQUIRES(ctx, r_tensor->dim_size(0) == batch_size,",
      "267:                 errors::InvalidArgument(",
      "268:                     \"r.dims(0) != batch_size: \", r_tensor->dim_size(0), \" vs. \",",
      "",
      "[Removed Lines]",
      "209:     const int64_t cell_size = h_prev_tensor->dim_size(1);",
      "218:     OP_REQUIRES(ctx, h_prev_tensor->dim_size(1) == cell_size,",
      "219:                 errors::InvalidArgument(",
      "220:                     \"h_prev.dims(1) != cell_size: \", h_prev_tensor->dim_size(1),",
      "221:                     \" vs. \", cell_size));",
      "251:     OP_REQUIRES(ctx, b_ru_tensor->dims() == 1,",
      "252:                 errors::InvalidArgument(\"Rank of b_ru must be 1\",",
      "253:                                         b_ru_tensor->dims(), \" vs. 1\"));",
      "261:     OP_REQUIRES(ctx, b_c_tensor->dims() == 1,",
      "262:                 errors::InvalidArgument(\"Rank of b_c must be 1 \",",
      "263:                                         b_c_tensor->dims(), \" vs. 1\"));",
      "",
      "[Added Lines]",
      "215:     OP_REQUIRES(",
      "216:         ctx, TensorShapeUtils::IsMatrix(x_tensor->shape()),",
      "217:         errors::InvalidArgument(\"Rank of x must be 2, got \", x_tensor->dims()));",
      "222:     OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(h_prev_tensor->shape()),",
      "223:                 errors::InvalidArgument(\"Rank of h_prev must be 2, got \",",
      "224:                                         h_prev_tensor->dims()));",
      "229:     const int64_t cell_size = h_prev_tensor->dim_size(1);",
      "232:     OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(w_ru_tensor->shape()),",
      "233:                 errors::InvalidArgument(\"Rank of w_ru_ must be 2, got \",",
      "234:                                         w_ru_tensor->dims()));",
      "245:     OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(w_c_tensor->shape()),",
      "246:                 errors::InvalidArgument(\"Rank of w_c must be 2, got \",",
      "247:                                         w_c_tensor->dims()));",
      "258:     OP_REQUIRES(ctx, TensorShapeUtils::IsVector(b_ru_tensor->shape()),",
      "259:                 errors::InvalidArgument(\"Rank of b_ru must be 1, got \",",
      "260:                                         b_ru_tensor->dims()));",
      "267:     OP_REQUIRES(ctx, TensorShapeUtils::IsVector(b_c_tensor->shape()),",
      "268:                 errors::InvalidArgument(\"Rank of b_c must be 1, got \",",
      "269:                                         b_c_tensor->dims()));",
      "276:     OP_REQUIRES(",
      "277:         ctx, TensorShapeUtils::IsMatrix(r_tensor->shape()),",
      "278:         errors::InvalidArgument(\"Rank of r must be 2, got \", r_tensor->dims()));",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "273:                     cell_size));",
      "276:     OP_REQUIRES(ctx, u_tensor->dim_size(0) == batch_size,",
      "277:                 errors::InvalidArgument(",
      "278:                     \"u.dims(0) != batch_size: \", u_tensor->dim_size(0), \" vs. \",",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "289:     OP_REQUIRES(",
      "290:         ctx, TensorShapeUtils::IsMatrix(u_tensor->shape()),",
      "291:         errors::InvalidArgument(\"Rank of u must be 2, got \", u_tensor->dims()));",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "283:                     cell_size));",
      "286:     OP_REQUIRES(ctx, c_tensor->dim_size(0) == batch_size,",
      "287:                 errors::InvalidArgument(",
      "288:                     \"c.dims(0) != batch_size: \", c_tensor->dim_size(0), \" vs. \",",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "302:     OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(c_tensor->shape()),",
      "303:                 errors::InvalidArgument(\"Rank of w_c must be 2, got \",",
      "304:                                         c_tensor->dims()));",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "293:                     cell_size));",
      "296:     OP_REQUIRES(ctx, d_h_tensor->dim_size(0) == batch_size,",
      "297:                 errors::InvalidArgument(",
      "298:                     \"d_h.dims(0) != batch_size: \", d_h_tensor->dim_size(0),",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "315:     OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(d_h_tensor->shape()),",
      "316:                 errors::InvalidArgument(\"Rank of d_h must be 2, got \",",
      "317:                                         d_h_tensor->dims()));",
      "",
      "---------------"
    ],
    "tensorflow/core/lib/core/status_test.cc||tensorflow/core/lib/core/status_test.cc": [
      "File: tensorflow/core/lib/core/status_test.cc -> tensorflow/core/lib/core/status_test.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "178: TEST(Status, InvalidPayloadGetsIgnored) {",
      "179:   Status s = Status();",
      "181:   ASSERT_FALSE(s.GetPayload(\"Invalid\").has_value());",
      "182:   bool is_err_erased = s.ErasePayload(\"Invalid\");",
      "183:   ASSERT_EQ(is_err_erased, false);",
      "",
      "[Removed Lines]",
      "180:   s.SetPayload(\"Invalid\", \"Invalid Val\");",
      "",
      "[Added Lines]",
      "180:   s.SetPayload(\"Invalid\", absl::Cord(\"Invalid Val\"));",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "186: TEST(Status, SetPayloadSetsOrUpdatesIt) {",
      "187:   Status s(error::INTERNAL, \"Error message\");",
      "189:   ASSERT_EQ(s.GetPayload(\"Error key\"), absl::Cord(\"Original\"));",
      "191:   ASSERT_EQ(s.GetPayload(\"Error key\"), absl::Cord(\"Updated\"));",
      "192: }",
      "194: TEST(Status, ErasePayloadRemovesIt) {",
      "195:   Status s(error::INTERNAL, \"Error message\");",
      "198:   bool is_err_erased = s.ErasePayload(\"Error key\");",
      "199:   ASSERT_EQ(is_err_erased, true);",
      "",
      "[Removed Lines]",
      "188:   s.SetPayload(\"Error key\", \"Original\");",
      "190:   s.SetPayload(\"Error key\", \"Updated\");",
      "196:   s.SetPayload(\"Error key\", \"Original\");",
      "",
      "[Added Lines]",
      "188:   s.SetPayload(\"Error key\", absl::Cord(\"Original\"));",
      "190:   s.SetPayload(\"Error key\", absl::Cord(\"Updated\"));",
      "196:   s.SetPayload(\"Error key\", absl::Cord(\"Original\"));",
      "",
      "---------------"
    ],
    "tensorflow/core/platform/error_payloads.cc||tensorflow/core/platform/error_payloads.cc": [
      "File: tensorflow/core/platform/error_payloads.cc -> tensorflow/core/platform/error_payloads.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "27:     ErrorSourceProto error_source_proto;",
      "28:     error_source_proto.set_error_source(error_source);",
      "29:     status.SetPayload(tensorflow::kErrorSource,",
      "31:   }",
      "32: }",
      "",
      "[Removed Lines]",
      "30:                       error_source_proto.SerializeAsString());",
      "",
      "[Added Lines]",
      "30:                       absl::Cord(error_source_proto.SerializeAsString()));",
      "",
      "---------------"
    ],
    "tensorflow/core/tpu/kernels/tpu_compile_op_common.cc||tensorflow/core/tpu/kernels/tpu_compile_op_common.cc": [
      "File: tensorflow/core/tpu/kernels/tpu_compile_op_common.cc -> tensorflow/core/tpu/kernels/tpu_compile_op_common.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "408:     SerializeToTString(proto, &output.scalar<tstring>()());",
      "409:     ctx->set_output(0, output);",
      "410:     status.SetPayload(TpuCompileInterface::kTpuCompileErrorPayloadKey,",
      "412:   }",
      "414:   if (status.ok()) {",
      "",
      "[Removed Lines]",
      "411:                       output.scalar<tstring>()());",
      "",
      "[Added Lines]",
      "411:                       absl::Cord(output.scalar<tstring>()()));",
      "",
      "---------------"
    ],
    "tensorflow/core/tpu/kernels/tpu_functional_ops.cc||tensorflow/core/tpu/kernels/tpu_functional_ops.cc": [
      "File: tensorflow/core/tpu/kernels/tpu_functional_ops.cc -> tensorflow/core/tpu/kernels/tpu_functional_ops.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "1410:   TF_RETURN_IF_ERROR(",
      "1411:       InstantiatePartition(*init_graph, fname, device, &fhandle, nullptr));",
      "1414:   opts.step_container = ctx->step_container();",
      "1415:   opts.cancellation_manager = ctx->cancellation_manager();",
      "1416:   opts.stats_collector = ctx->stats_collector();",
      "",
      "[Removed Lines]",
      "1413:   FunctionLibraryRuntime::Options opts;",
      "",
      "[Added Lines]",
      "1413:   FunctionLibraryRuntime::Options opts(ctx->step_id());",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "1569:     functions.push_back(DeviceAndFHandle{.device = target, .handle = handle});",
      "1570:   }",
      "",
      "[Removed Lines]",
      "1572:   FunctionLibraryRuntime::Options opts;",
      "",
      "[Added Lines]",
      "1572:   FunctionLibraryRuntime::Options opts(ctx->step_id());",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "2702:     const std::vector<DeviceAndFHandle>& functions, OpKernelContext* ctx,",
      "2703:     int device_ordinal, int64_t ordinal_selector_req_id, DoneCallback done) {",
      "2704:   profiler::TraceMe trace_me(\"TPUPartitionedCallOp-ExecuteFunctions\");",
      "2706:   opts.step_container = ctx->step_container();",
      "2707:   opts.stats_collector = ctx->stats_collector();",
      "",
      "[Removed Lines]",
      "2705:   FunctionLibraryRuntime::Options opts;",
      "",
      "[Added Lines]",
      "2705:   FunctionLibraryRuntime::Options opts(ctx->step_id());",
      "",
      "---------------"
    ],
    "tensorflow/core/tpu/tpu_embedding_errors.cc||tensorflow/core/tpu/tpu_embedding_errors.cc": [
      "File: tensorflow/core/tpu/tpu_embedding_errors.cc -> tensorflow/core/tpu/tpu_embedding_errors.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "29:         absl::StrCat(kTpuEmbeddingErrorMessage, \". \", obj.error_message());",
      "30:     Status status(obj.code(), error_message);",
      "31:     TPUEmbeddingError error_payload;",
      "33:     return status;",
      "34:   }",
      "35: }",
      "",
      "[Removed Lines]",
      "32:     status.SetPayload(kTpuEmbeddingErrorUrl, error_payload.SerializeAsString());",
      "",
      "[Added Lines]",
      "32:     status.SetPayload(kTpuEmbeddingErrorUrl,",
      "33:                       absl::Cord(error_payload.SerializeAsString()));",
      "",
      "---------------"
    ],
    "tensorflow/core/tpu/tpu_embedding_errors.h||tensorflow/core/tpu/tpu_embedding_errors.h": [
      "File: tensorflow/core/tpu/tpu_embedding_errors.h -> tensorflow/core/tpu/tpu_embedding_errors.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "50:         kTpuEmbeddingErrorMessage, \". \", obj.status().error_message());",
      "51:     Status status(obj.status().code(), error_message);",
      "52:     TPUEmbeddingError error_payload;",
      "54:     return status;",
      "55:   }",
      "56: }",
      "",
      "[Removed Lines]",
      "53:     status.SetPayload(kTpuEmbeddingErrorUrl, error_payload.SerializeAsString());",
      "",
      "[Added Lines]",
      "53:     status.SetPayload(kTpuEmbeddingErrorUrl,",
      "54:                       absl::Cord(error_payload.SerializeAsString()));",
      "",
      "---------------"
    ],
    "tensorflow/core/util/zen_util.h||tensorflow/core/util/zen_util.h": [
      "File: tensorflow/core/util/zen_util.h -> tensorflow/core/util/zen_util.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "24: namespace tensorflow {",
      "27:   static absl::once_flag once;",
      "28:   static int64_t mempool = 1;",
      "29:   absl::call_once(once, [&] {",
      "",
      "[Removed Lines]",
      "26: int64_t GetMempool() {",
      "",
      "[Added Lines]",
      "26: inline int64_t GetMempool() {",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "34:   return mempool;",
      "35: }",
      "38:   static absl::once_flag once;",
      "39:   static bool blocked_format = false;",
      "40:   absl::call_once(once, [&] {",
      "",
      "[Removed Lines]",
      "37: bool IsBlockedFormatEnabled() {",
      "",
      "[Added Lines]",
      "37: inline bool IsBlockedFormatEnabled() {",
      "",
      "---------------"
    ],
    "tensorflow/python/data/experimental/kernel_tests/service/snapshot_ft_test.py||tensorflow/python/data/experimental/kernel_tests/service/snapshot_ft_test.py": [
      "File: tensorflow/python/data/experimental/kernel_tests/service/snapshot_ft_test.py -> tensorflow/python/data/experimental/kernel_tests/service/snapshot_ft_test.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "131:   def testSnapshotRecoveryFailsWithBadSplitNames(self, bad_split_filename):",
      "132:     cluster, _ = self.setup()",
      "133:     write_file(os.path.join(self.source_dir(), bad_split_filename))",
      "135:       cluster.restart_dispatcher()",
      "137:   @combinations.generate(test_base.eager_only_combinations())",
      "138:   def testSnapshotRecoveryFailsWithOutOfOrderSplitName(self):",
      "139:     cluster, _ = self.setup()",
      "140:     write_file(os.path.join(self.source_dir(), \"split_1_0\"))",
      "142:       cluster.restart_dispatcher()",
      "144:   @combinations.generate(test_base.eager_only_combinations())",
      "",
      "[Removed Lines]",
      "134:     with self.assertRaisesRegex(ValueError, \"can't parse\"):",
      "141:     with self.assertRaisesRegex(ValueError, \"found conflict\"):",
      "",
      "[Added Lines]",
      "134:     with self.assertRaisesRegex(",
      "135:         ValueError, \"Expected split_<local_split_index>_<global_split_index>\"):",
      "142:     with self.assertRaisesRegex(",
      "143:         ValueError, \"The local split index 1 exceeds the global split index 0\"):",
      "",
      "---------------"
    ],
    "tensorflow/python/framework/errors_test_helper.cc||tensorflow/python/framework/errors_test_helper.cc": [
      "File: tensorflow/python/framework/errors_test_helper.cc -> tensorflow/python/framework/errors_test_helper.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "21:   m.def(\"TestRaiseFromStatus\", [](int code) {",
      "22:     tensorflow::Status status(static_cast<tensorflow::error::Code>(code),",
      "23:                               \"test message\");",
      "26:     MaybeRaiseRegisteredFromStatus(status);",
      "27:     return 0;",
      "28:   });",
      "",
      "[Removed Lines]",
      "24:     status.SetPayload(\"key1\", \"value1\");",
      "25:     status.SetPayload(\"key2\", \"value2\");",
      "",
      "[Added Lines]",
      "24:     status.SetPayload(\"key1\", absl::Cord(\"value1\"));",
      "25:     status.SetPayload(\"key2\", absl::Cord(\"value2\"));",
      "",
      "---------------"
    ],
    "tensorflow/python/tpu/tpu_strategy_util.py||tensorflow/python/tpu/tpu_strategy_util.py": [
      "File: tensorflow/python/tpu/tpu_strategy_util.py -> tensorflow/python/tpu/tpu_strategy_util.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "22: from tensorflow.python.eager import context",
      "23: from tensorflow.python.eager import monitoring",
      "24: from tensorflow.python.eager.def_function import function",
      "25: from tensorflow.python.framework import device",
      "26: from tensorflow.python.framework import errors",
      "27: from tensorflow.python.framework import ops",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "25: from tensorflow.python.eager.def_function import functions_run_eagerly",
      "26: from tensorflow.python.eager.def_function import run_functions_eagerly",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "111:     # The TPU_SYSTEM device must match the device used in tpu.initialize_system",
      "112:     # exactly, otherwise you can get errors if there are multiple TPU_SYSTEM",
      "113:     # devices available.",
      "114:     try:",
      "115:       with ops.device(tpu._tpu_system_device_name(job)):  # pylint: disable=protected-access",
      "116:         output = _tpu_init_fn()",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "116:     run_eagerly = functions_run_eagerly()",
      "117:     if run_eagerly:",
      "118:       logging.warning(",
      "119:           \"It looks like tf.function behavior was disabled, perhaps using\"",
      "120:           \" tf.config.run_functions_eagerly.\"",
      "121:           \" tf.tpu.experimental.initialize_tpu_system requires tf.function to\"",
      "122:           \" work. This primitive will override the disable.\"",
      "123:       )",
      "124:     run_functions_eagerly(False)",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "120:           None, None,",
      "121:           \"TPUs not found in the cluster. Failed in initialization: \"",
      "122:           + str(e))",
      "124:     # Clear out the eager context caches since the memory is invalid now.",
      "125:     context.context()._initialize_logical_devices()  # pylint: disable=protected-access",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "134:     finally:",
      "135:       if run_eagerly is not None:",
      "136:         run_functions_eagerly(run_eagerly)",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "221:     # The TPU_SYSTEM device must match the device used in tpu.shutdown_system",
      "222:     # exactly, otherwise you can get errors if there are multiple TPU_SYSTEM",
      "223:     # devices available.",
      "227:     # Clear out the eager context caches since the memory is invalid now.",
      "228:     logging.info(\"Clearing out eager caches\")",
      "",
      "[Removed Lines]",
      "224:     with ops.device(tpu._tpu_system_device_name(job)):  # pylint: disable=protected-access",
      "225:       _tpu_shutdown_fn()",
      "",
      "[Added Lines]",
      "237:     run_eagerly = functions_run_eagerly()",
      "238:     if run_eagerly:",
      "239:       logging.warning(",
      "240:           \"It looks like tf.function behavior was disabled, perhaps using\"",
      "241:           \" tf.config.run_functions_eagerly.\"",
      "242:           \" tf.tpu.experimental.shutdown_tpu_system requires tf.function to\"",
      "243:           \" work. This primitive will override the disable.\"",
      "244:       )",
      "245:     run_functions_eagerly(False)",
      "246:     try:",
      "247:       with ops.device(tpu._tpu_system_device_name(job)):  # pylint: disable=protected-access",
      "248:         _tpu_shutdown_fn()",
      "249:     finally:",
      "250:       if run_eagerly is not None:",
      "251:         run_functions_eagerly(run_eagerly)",
      "",
      "---------------"
    ],
    "tensorflow/tsl/c/tsl_status.cc||tensorflow/tsl/c/tsl_status.cc": [
      "File: tensorflow/tsl/c/tsl_status.cc -> tensorflow/tsl/c/tsl_status.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "36: }",
      "38: void TSL_SetPayload(TSL_Status* s, const char* key, const char* value) {",
      "40: }",
      "42: void TSL_SetStatusFromIOError(TSL_Status* s, int error_code,",
      "",
      "[Removed Lines]",
      "39:   s->status.SetPayload(key, value);",
      "",
      "[Added Lines]",
      "39:   s->status.SetPayload(key, absl::Cord(absl::string_view(value)));",
      "",
      "---------------"
    ],
    "tensorflow/tsl/c/tsl_status_helper_test.cc||tensorflow/tsl/c/tsl_status_helper_test.cc": [
      "File: tensorflow/tsl/c/tsl_status_helper_test.cc -> tensorflow/tsl/c/tsl_status_helper_test.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "24: TEST(StatusHelper, TestStatusHelper) {",
      "25:   TSL_Status* s = TSL_NewStatus();",
      "26:   Status cc_status(errors::InvalidArgument(\"some error\"));",
      "29:   Set_TSL_Status_from_Status(s, cc_status);",
      "30:   ASSERT_EQ(TSL_INVALID_ARGUMENT, TSL_GetCode(s));",
      "31:   ASSERT_EQ(std::string(\"some error\"), TSL_Message(s));",
      "",
      "[Removed Lines]",
      "27:   cc_status.SetPayload(\"key1\", \"value1\");",
      "28:   cc_status.SetPayload(\"key2\", \"value2\");",
      "",
      "[Added Lines]",
      "27:   cc_status.SetPayload(\"key1\", absl::Cord(\"value1\"));",
      "28:   cc_status.SetPayload(\"key2\", absl::Cord(\"value2\"));",
      "",
      "---------------"
    ],
    "tensorflow/tsl/distributed_runtime/coordination/coordination_service_error_util.h||tensorflow/tsl/distributed_runtime/coordination/coordination_service_error_util.h": [
      "File: tensorflow/tsl/distributed_runtime/coordination/coordination_service_error_util.h -> tensorflow/tsl/distributed_runtime/coordination/coordination_service_error_util.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "31: inline Status MakeCoordinationError(Status s) {",
      "33:   return s;",
      "34: }",
      "",
      "[Removed Lines]",
      "32:   s.SetPayload(CoordinationErrorPayloadKey(), \"\");",
      "",
      "[Added Lines]",
      "32:   s.SetPayload(CoordinationErrorPayloadKey(), absl::Cord(\"\"));",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "43:   tensorflow::CoordinationServiceError error;",
      "45:   error.set_is_reported_error(is_reported_error);",
      "47:   return s;",
      "48: }",
      "51: inline Status MakeCoordinationError(",
      "52:     Status s, const tensorflow::CoordinationServiceError& payload) {",
      "54:   return s;",
      "55: }",
      "56: }  // namespace tsl",
      "",
      "[Removed Lines]",
      "46:   s.SetPayload(CoordinationErrorPayloadKey(), error.SerializeAsString());",
      "53:   s.SetPayload(CoordinationErrorPayloadKey(), payload.SerializeAsString());",
      "",
      "[Added Lines]",
      "46:   s.SetPayload(CoordinationErrorPayloadKey(),",
      "47:                absl::Cord(error.SerializeAsString()));",
      "54:   s.SetPayload(CoordinationErrorPayloadKey(),",
      "55:                absl::Cord(payload.SerializeAsString()));",
      "",
      "---------------"
    ],
    "tensorflow/tsl/distributed_runtime/rpc/grpc_util.h||tensorflow/tsl/distributed_runtime/rpc/grpc_util.h": [
      "File: tensorflow/tsl/distributed_runtime/rpc/grpc_util.h -> tensorflow/tsl/distributed_runtime/rpc/grpc_util.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "71:   tensorflow::distributed_runtime::GrpcPayloadContainer container;",
      "72:   if (container.ParseFromString(payloads)) {",
      "73:     for (const auto& key_val : container.payloads()) {",
      "75:     }",
      "76:   } else {",
      "77:     s.SetPayload(kGrpcPayloadsLost,",
      "80:   }",
      "81: }",
      "",
      "[Removed Lines]",
      "74:       s.SetPayload(key_val.first, key_val.second);",
      "78:                  tensorflow::distributed_runtime::GrpcPayloadsLost()",
      "79:                      .SerializeAsString());",
      "",
      "[Added Lines]",
      "74:       s.SetPayload(key_val.first, absl::Cord(key_val.second));",
      "78:                  absl::Cord(tensorflow::distributed_runtime::GrpcPayloadsLost()",
      "79:                                 .SerializeAsString()));",
      "",
      "---------------"
    ],
    "tensorflow/tsl/distributed_runtime/rpc/grpc_util_test.cc||tensorflow/tsl/distributed_runtime/rpc/grpc_util_test.cc": [
      "File: tensorflow/tsl/distributed_runtime/rpc/grpc_util_test.cc -> tensorflow/tsl/distributed_runtime/rpc/grpc_util_test.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "72: TEST(PayloadSerialization, PayloadsAreTransmitted) {",
      "73:   Status status = errors::InvalidArgument(\"invalid arg message\");",
      "75:   Status status_recovered = FromGrpcStatus(ToGrpcStatus(status));",
      "77:   ASSERT_TRUE(status_recovered.GetPayload(\"a\").has_value());",
      "",
      "[Removed Lines]",
      "74:   status.SetPayload(\"a\", \"\\\\xFF\\\\x02\\\\x03\");",
      "",
      "[Added Lines]",
      "74:   status.SetPayload(\"a\", absl::Cord(\"\\\\xFF\\\\x02\\\\x03\"));",
      "",
      "---------------"
    ],
    "tensorflow/tsl/platform/errors.h||tensorflow/tsl/platform/errors.h": [
      "File: tensorflow/tsl/platform/errors.h -> tensorflow/tsl/platform/errors.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "21: #include <utility>",
      "23: #include \"absl/base/attributes.h\"",
      "24: #include \"absl/strings/str_join.h\"",
      "25: #include \"tensorflow/tsl/platform/logging.h\"",
      "26: #include \"tensorflow/tsl/platform/macros.h\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "24: #include \"absl/strings/cord.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "102:     ::tsl::Status& status,",
      "103:     const std::unordered_map<std::string, std::string>& payloads) {",
      "104:   for (const auto& payload : payloads) {",
      "106:   }",
      "107: }",
      "",
      "[Removed Lines]",
      "105:     status.SetPayload(payload.first, payload.second);",
      "",
      "[Added Lines]",
      "106:     status.SetPayload(payload.first, absl::Cord(payload.second));",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "111: inline void CopyPayloads(const ::tsl::Status& from, ::tsl::Status& to) {",
      "112:   from.ForEachPayload([&to](tsl::StringPiece key, tsl::StringPiece value) {",
      "114:   });",
      "115: }",
      "",
      "[Removed Lines]",
      "113:     to.SetPayload(key, value);",
      "",
      "[Added Lines]",
      "114:     to.SetPayload(key, absl::Cord(value));",
      "",
      "---------------"
    ],
    "tensorflow/tsl/platform/test.h||tensorflow/tsl/platform/test.h": [
      "File: tensorflow/tsl/platform/test.h -> tensorflow/tsl/platform/test.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "86: int PickUnusedPortOrDie();",
      "88: }  // namespace testing",
      "89: }  // namespace tsl",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "89: #ifdef PLATFORM_GOOGLE",
      "90: inline constexpr bool kIsOpenSource = false;",
      "91: #else",
      "92: inline constexpr bool kIsOpenSource = true;",
      "93: #endif  // PLATFORM_GOOGLE",
      "",
      "---------------"
    ],
    "tensorflow/tsl/profiler/lib/traceme_encode.h||tensorflow/tsl/profiler/lib/traceme_encode.h": [
      "File: tensorflow/tsl/profiler/lib/traceme_encode.h -> tensorflow/tsl/profiler/lib/traceme_encode.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "20: #include <initializer_list>",
      "21: #include <string>",
      "23: #include \"absl/strings/match.h\"",
      "24: #include \"absl/strings/str_cat.h\"",
      "25: #include \"absl/strings/string_view.h\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "23: #include \"absl/base/attributes.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "33: struct TraceMeArg {",
      "38:   TF_DISALLOW_COPY_AND_ASSIGN(TraceMeArg);",
      "40:   absl::string_view key;",
      "42: };",
      "44: namespace traceme_internal {",
      "",
      "[Removed Lines]",
      "35:   template <typename Value>",
      "36:   TraceMeArg(absl::string_view k, Value v) : key(k), value(v) {}",
      "41:   absl::AlphaNum value;",
      "",
      "[Added Lines]",
      "42:   TraceMeArg(absl::string_view k,",
      "43:              const absl::AlphaNum& v ABSL_ATTRIBUTE_LIFETIME_BOUND)",
      "44:       : key(k), value(v.Piece()) {}",
      "49:   absl::string_view value;",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "74:     for (const auto& arg : args) {",
      "75:       out = Append(out, arg.key);",
      "79:     }",
      "",
      "[Removed Lines]",
      "77:       out = Append(out, arg.value.Piece());",
      "",
      "[Added Lines]",
      "85:       out = Append(out, arg.value);",
      "",
      "---------------"
    ],
    "tensorflow/tsl/profiler/lib/traceme_encode_test.cc||tensorflow/tsl/profiler/lib/traceme_encode_test.cc": [
      "File: tensorflow/tsl/profiler/lib/traceme_encode_test.cc -> tensorflow/tsl/profiler/lib/traceme_encode_test.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "17: #include <string>",
      "19: #include \"absl/strings/str_cat.h\"",
      "20: #include \"tensorflow/tsl/platform/platform.h\"",
      "21: #include \"tensorflow/tsl/platform/test.h\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "20: #include \"absl/strings/str_format.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "53: }",
      "54: #endif",
      "56: TEST(TraceMeEncodeTest, NoNameTest) {",
      "57:   EXPECT_EQ(TraceMeEncode({{\"context\", \"World\"}, {\"request_id\", 42}}),",
      "58:             \"#context=World,request_id=42#\");",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "59: #if defined(PLATFORM_GOOGLE)",
      "61: struct Point {",
      "62:   template <typename Sink>",
      "63:   friend void AbslStringify(Sink& sink, const Point& p) {",
      "64:     absl::Format(&sink, \"(%d, %d)\", p.x, p.y);",
      "65:   }",
      "67:   int x;",
      "68:   int y;",
      "69: };",
      "71: TEST(TraceMeEncodeTest, AbslStringifyTest) {",
      "72:   EXPECT_EQ(TraceMeEncode(\"Plot\", {{\"point\", Point{10, 20}}}),",
      "73:             \"Plot#point=(10, 20)#\");",
      "74: }",
      "76: #endif",
      "",
      "---------------"
    ],
    "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl": [
      "File: third_party/tf_runtime/workspace.bzl -> third_party/tf_runtime/workspace.bzl",
      "--- Hunk 1 ---",
      "[Context before]",
      "6:     \"\"\"Imports TFRT.\"\"\"",
      "8:     # Attention: tools parse and update these lines.",
      "12:     tf_http_archive(",
      "13:         name = \"tf_runtime\",",
      "",
      "[Removed Lines]",
      "9:     TFRT_COMMIT = \"c1248a015d23949afa2471bb21f6f52850aead7d\"",
      "10:     TFRT_SHA256 = \"8cdd8ea905478ac4ffd36ffb39cebe288d3b840d71a02d418bc6a8a760f92af8\"",
      "",
      "[Added Lines]",
      "9:     TFRT_COMMIT = \"c653281a1a23c0c3d41536a983c7d10fcc5b1fbf\"",
      "10:     TFRT_SHA256 = \"3d1edd27c4e36d9cfc9493aef7088489babb370d2a7955bab3545acfbb024ccf\"",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "9a0c0322dccc8a84a190a76ce9506eacd4d9c456",
      "candidate_info": {
        "commit_hash": "9a0c0322dccc8a84a190a76ce9506eacd4d9c456",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/9a0c0322dccc8a84a190a76ce9506eacd4d9c456",
        "files": [
          "third_party/tf_runtime/workspace.bzl",
          "third_party/xla/third_party/tf_runtime/workspace.bzl",
          "third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl"
        ],
        "message": "Update TFRT dependency to use revision http://github.com/tensorflow/runtime/commit/cf730a32058241ae24fd12fe0a9a0258faa0ca89.\n\nPiperOrigin-RevId: 568177684",
        "before_after_code_files": [
          "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl",
          "third_party/xla/third_party/tf_runtime/workspace.bzl||third_party/xla/third_party/tf_runtime/workspace.bzl",
          "third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl||third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl"
          ],
          "candidate": [
            "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl"
          ]
        }
      },
      "candidate_diff": {
        "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl": [
          "File: third_party/tf_runtime/workspace.bzl -> third_party/tf_runtime/workspace.bzl",
          "--- Hunk 1 ---",
          "[Context before]",
          "6:     \"\"\"Imports TFRT.\"\"\"",
          "8:     # Attention: tools parse and update these lines.",
          "12:     tf_http_archive(",
          "13:         name = \"tf_runtime\",",
          "",
          "[Removed Lines]",
          "9:     TFRT_COMMIT = \"549bf94d9643e0a1a9ea71949fde9e0a21dd30ea\"",
          "10:     TFRT_SHA256 = \"d8550a2abb57a78bd786947104d71f7735c96ed68b672e9afe2c45f143488ade\"",
          "",
          "[Added Lines]",
          "9:     TFRT_COMMIT = \"cf730a32058241ae24fd12fe0a9a0258faa0ca89\"",
          "10:     TFRT_SHA256 = \"7fcc709032d16aa5f2cf04e0c4cbcdf9e0dbafb8377e141d2c0074f24ede4066\"",
          "",
          "---------------"
        ],
        "third_party/xla/third_party/tf_runtime/workspace.bzl||third_party/xla/third_party/tf_runtime/workspace.bzl": [
          "File: third_party/xla/third_party/tf_runtime/workspace.bzl -> third_party/xla/third_party/tf_runtime/workspace.bzl",
          "--- Hunk 1 ---",
          "[Context before]",
          "6:     \"\"\"Imports TFRT.\"\"\"",
          "8:     # Attention: tools parse and update these lines.",
          "12:     tf_http_archive(",
          "13:         name = \"tf_runtime\",",
          "",
          "[Removed Lines]",
          "9:     TFRT_COMMIT = \"549bf94d9643e0a1a9ea71949fde9e0a21dd30ea\"",
          "10:     TFRT_SHA256 = \"d8550a2abb57a78bd786947104d71f7735c96ed68b672e9afe2c45f143488ade\"",
          "",
          "[Added Lines]",
          "9:     TFRT_COMMIT = \"cf730a32058241ae24fd12fe0a9a0258faa0ca89\"",
          "10:     TFRT_SHA256 = \"7fcc709032d16aa5f2cf04e0c4cbcdf9e0dbafb8377e141d2c0074f24ede4066\"",
          "",
          "---------------"
        ],
        "third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl||third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl": [
          "File: third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl -> third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl",
          "--- Hunk 1 ---",
          "[Context before]",
          "6:     \"\"\"Imports TFRT.\"\"\"",
          "8:     # Attention: tools parse and update these lines.",
          "12:     tf_http_archive(",
          "13:         name = \"tf_runtime\",",
          "",
          "[Removed Lines]",
          "9:     TFRT_COMMIT = \"549bf94d9643e0a1a9ea71949fde9e0a21dd30ea\"",
          "10:     TFRT_SHA256 = \"d8550a2abb57a78bd786947104d71f7735c96ed68b672e9afe2c45f143488ade\"",
          "",
          "[Added Lines]",
          "9:     TFRT_COMMIT = \"cf730a32058241ae24fd12fe0a9a0258faa0ca89\"",
          "10:     TFRT_SHA256 = \"7fcc709032d16aa5f2cf04e0c4cbcdf9e0dbafb8377e141d2c0074f24ede4066\"",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "145d46d913536a131496d7152e49299172fd6c82",
      "candidate_info": {
        "commit_hash": "145d46d913536a131496d7152e49299172fd6c82",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/145d46d913536a131496d7152e49299172fd6c82",
        "files": [
          "third_party/tf_runtime/workspace.bzl",
          "third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl"
        ],
        "message": "Update TFRT dependency to use revision http://github.com/tensorflow/runtime/commit/886cfe0e0fd894ba1beafbb80585c6f32de8a2e4.\n\nPiperOrigin-RevId: 583383656",
        "before_after_code_files": [
          "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl",
          "third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl||third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl"
          ],
          "candidate": [
            "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl"
          ]
        }
      },
      "candidate_diff": {
        "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl": [
          "File: third_party/tf_runtime/workspace.bzl -> third_party/tf_runtime/workspace.bzl",
          "--- Hunk 1 ---",
          "[Context before]",
          "6:     \"\"\"Imports TFRT.\"\"\"",
          "8:     # Attention: tools parse and update these lines.",
          "12:     tf_http_archive(",
          "13:         name = \"tf_runtime\",",
          "",
          "[Removed Lines]",
          "9:     TFRT_COMMIT = \"77cd0fb4225157e8326ddad1006d137ecced0aae\"",
          "10:     TFRT_SHA256 = \"c13c76ddb5a1f4646cfe7f5cb8f0a0b5789f5a2030086ac2796bf922c66eea6c\"",
          "",
          "[Added Lines]",
          "9:     TFRT_COMMIT = \"886cfe0e0fd894ba1beafbb80585c6f32de8a2e4\"",
          "10:     TFRT_SHA256 = \"d391129b09b90a343f4b948f8fda109a260cdfb0e1ea63c978cafcdf528a85e3\"",
          "",
          "---------------"
        ],
        "third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl||third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl": [
          "File: third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl -> third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl",
          "--- Hunk 1 ---",
          "[Context before]",
          "6:     \"\"\"Imports TFRT.\"\"\"",
          "8:     # Attention: tools parse and update these lines.",
          "12:     tf_http_archive(",
          "13:         name = \"tf_runtime\",",
          "",
          "[Removed Lines]",
          "9:     TFRT_COMMIT = \"77cd0fb4225157e8326ddad1006d137ecced0aae\"",
          "10:     TFRT_SHA256 = \"c13c76ddb5a1f4646cfe7f5cb8f0a0b5789f5a2030086ac2796bf922c66eea6c\"",
          "",
          "[Added Lines]",
          "9:     TFRT_COMMIT = \"886cfe0e0fd894ba1beafbb80585c6f32de8a2e4\"",
          "10:     TFRT_SHA256 = \"d391129b09b90a343f4b948f8fda109a260cdfb0e1ea63c978cafcdf528a85e3\"",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "4a06136fe0bc8a308ff319c1a119d1d4d1286dea",
      "candidate_info": {
        "commit_hash": "4a06136fe0bc8a308ff319c1a119d1d4d1286dea",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/4a06136fe0bc8a308ff319c1a119d1d4d1286dea",
        "files": [
          "third_party/tf_runtime/workspace.bzl"
        ],
        "message": "Update TFRT dependency to use revision http://github.com/tensorflow/runtime/commit/2cd837e8a5ed1f448b3d27ac688bc13b656bc5ae.\n\nPiperOrigin-RevId: 554328186",
        "before_after_code_files": [
          "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl"
          ],
          "candidate": [
            "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl"
          ]
        }
      },
      "candidate_diff": {
        "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl": [
          "File: third_party/tf_runtime/workspace.bzl -> third_party/tf_runtime/workspace.bzl",
          "--- Hunk 1 ---",
          "[Context before]",
          "6:     \"\"\"Imports TFRT.\"\"\"",
          "8:     # Attention: tools parse and update these lines.",
          "12:     tf_http_archive(",
          "13:         name = \"tf_runtime\",",
          "",
          "[Removed Lines]",
          "9:     TFRT_COMMIT = \"508f2be0ae7bee6a90c0a0618182af9eb2add9f2\"",
          "10:     TFRT_SHA256 = \"34d80dc20829aac5199e77bbba6a4ff2cedd4c53b7423e700214ad0cabec56ea\"",
          "",
          "[Added Lines]",
          "9:     TFRT_COMMIT = \"2cd837e8a5ed1f448b3d27ac688bc13b656bc5ae\"",
          "10:     TFRT_SHA256 = \"851c7d3945c8a8800efbe33590e2906d8f59a631f567086a56eed6767d2f3cd2\"",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "3ccce977a0c92e3297176162ccedc50724d53c4f",
      "candidate_info": {
        "commit_hash": "3ccce977a0c92e3297176162ccedc50724d53c4f",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/3ccce977a0c92e3297176162ccedc50724d53c4f",
        "files": [
          "third_party/tf_runtime/workspace.bzl"
        ],
        "message": "Update TFRT dependency to use revision http://github.com/tensorflow/runtime/commit/769f5cc9b8732933140b09e8808d13614182b496.\n\nPiperOrigin-RevId: 552780622",
        "before_after_code_files": [
          "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl"
          ],
          "candidate": [
            "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl"
          ]
        }
      },
      "candidate_diff": {
        "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl": [
          "File: third_party/tf_runtime/workspace.bzl -> third_party/tf_runtime/workspace.bzl",
          "--- Hunk 1 ---",
          "[Context before]",
          "6:     \"\"\"Imports TFRT.\"\"\"",
          "8:     # Attention: tools parse and update these lines.",
          "12:     tf_http_archive(",
          "13:         name = \"tf_runtime\",",
          "",
          "[Removed Lines]",
          "9:     TFRT_COMMIT = \"b6afbd700938c3a102cbdb3bf97e71465cd6dbc2\"",
          "10:     TFRT_SHA256 = \"67d8f70590a91d060185f0bde38da48d46b7513daede370be7aa75e76706ccf6\"",
          "",
          "[Added Lines]",
          "9:     TFRT_COMMIT = \"769f5cc9b8732933140b09e8808d13614182b496\"",
          "10:     TFRT_SHA256 = \"778bac534b9fa81f2b2f1d19c05121992f78d3dd8e8a99787be9ef92c62cace7\"",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "9a7d35d3e371e2e9c537bcf47de12a27e016fc73",
      "candidate_info": {
        "commit_hash": "9a7d35d3e371e2e9c537bcf47de12a27e016fc73",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/9a7d35d3e371e2e9c537bcf47de12a27e016fc73",
        "files": [
          "third_party/tf_runtime/workspace.bzl"
        ],
        "message": "Update TFRT dependency to use revision http://github.com/tensorflow/runtime/commit/8e364643893137f19a44a5c344bbfd56efa169d3.\n\nPiperOrigin-RevId: 544482469",
        "before_after_code_files": [
          "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl"
          ],
          "candidate": [
            "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl"
          ]
        }
      },
      "candidate_diff": {
        "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl": [
          "File: third_party/tf_runtime/workspace.bzl -> third_party/tf_runtime/workspace.bzl",
          "--- Hunk 1 ---",
          "[Context before]",
          "6:     \"\"\"Imports TFRT.\"\"\"",
          "8:     # Attention: tools parse and update these lines.",
          "12:     tf_http_archive(",
          "13:         name = \"tf_runtime\",",
          "",
          "[Removed Lines]",
          "9:     TFRT_COMMIT = \"15917cba5048d32973fc94f446c82dc2c070722f\"",
          "10:     TFRT_SHA256 = \"610c6156a0a10b78404aa050ee082a9e462bd57d1a5f50fa33f3e784d5826a4e\"",
          "",
          "[Added Lines]",
          "9:     TFRT_COMMIT = \"8e364643893137f19a44a5c344bbfd56efa169d3\"",
          "10:     TFRT_SHA256 = \"af8fcf40ac4138305c8ca393763f29b5f6b5938d2f31b82d6a4cdb896cea1902\"",
          "",
          "---------------"
        ]
      }
    }
  ]
}