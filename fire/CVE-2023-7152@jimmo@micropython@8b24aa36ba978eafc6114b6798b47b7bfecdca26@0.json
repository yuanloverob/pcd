{
  "cve_id": "CVE-2023-7152",
  "cve_desc": "A vulnerability, which was classified as critical, has been found in MicroPython 1.21.0/1.22.0-preview. Affected by this issue is the function poll_set_add_fd of the file extmod/modselect.c. The manipulation leads to use after free. The exploit has been disclosed to the public and may be used. The patch is identified as 8b24aa36ba978eafc6114b6798b47b7bfecdca26. It is recommended to apply a patch to fix this issue. VDB-249158 is the identifier assigned to this vulnerability.",
  "repo": "jimmo/micropython",
  "patch_hash": "8b24aa36ba978eafc6114b6798b47b7bfecdca26",
  "patch_info": {
    "commit_hash": "8b24aa36ba978eafc6114b6798b47b7bfecdca26",
    "repo": "jimmo/micropython",
    "commit_url": "https://github.com/jimmo/micropython/commit/8b24aa36ba978eafc6114b6798b47b7bfecdca26",
    "files": [
      "extmod/modselect.c",
      "tests/extmod/select_poll_fd.py"
    ],
    "message": "extmod/modselect: Handle growing the pollfds allocation correctly.\n\nThe poll_obj_t instances have their pollfd field point into this\nallocation.  So if re-allocating results in a move, we need to update the\nexisting poll_obj_t's.\n\nUpdate the test to cover this case.\n\nFixes issue #12887.\n\nThis work was funded through GitHub Sponsors.\n\nSigned-off-by: Jim Mussared <jim.mussared@gmail.com>",
    "before_after_code_files": [
      "extmod/modselect.c||extmod/modselect.c",
      "tests/extmod/select_poll_fd.py||tests/extmod/select_poll_fd.py"
    ]
  },
  "patch_diff": {
    "extmod/modselect.c||extmod/modselect.c": [
      "File: extmod/modselect.c -> extmod/modselect.c",
      "--- Hunk 1 ---",
      "[Context before]",
      "42: #if MICROPY_PY_SELECT_POSIX_OPTIMISATIONS",
      "44: #include <poll.h>",
      "46: #if !((MP_STREAM_POLL_RD) == (POLLIN) && \\",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "44: #include <string.h>",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "142:     }",
      "143: }",
      "145: STATIC struct pollfd *poll_set_add_fd(poll_set_t *poll_set, int fd) {",
      "146:     struct pollfd *free_slot = NULL;",
      "148:     if (poll_set->used == poll_set->max_used) {",
      "150:         if (poll_set->max_used >= poll_set->alloc) {",
      "153:         }",
      "154:         free_slot = &poll_set->pollfds[poll_set->max_used++];",
      "155:     } else {",
      "",
      "[Removed Lines]",
      "151:             poll_set->pollfds = m_renew(struct pollfd, poll_set->pollfds, poll_set->alloc, poll_set->alloc + 4);",
      "152:             poll_set->alloc += 4;",
      "",
      "[Added Lines]",
      "147: #define POLL_SET_ALLOC_INCREMENT (4)",
      "155:             size_t new_alloc = poll_set->alloc + POLL_SET_ALLOC_INCREMENT;",
      "157:             struct pollfd *new_fds = m_renew_maybe(struct pollfd, poll_set->pollfds, poll_set->alloc, new_alloc, false);",
      "158:             if (!new_fds) {",
      "160:                 new_fds = m_new(struct pollfd, new_alloc);",
      "161:                 memcpy(new_fds, poll_set->pollfds, sizeof(struct pollfd) * poll_set->alloc);",
      "165:                 for (mp_uint_t i = 0; i < poll_set->map.alloc; ++i) {",
      "166:                     if (!mp_map_slot_is_filled(&poll_set->map, i)) {",
      "167:                         continue;",
      "168:                     }",
      "170:                     poll_obj_t *poll_obj = MP_OBJ_TO_PTR(poll_set->map.table[i].value);",
      "171:                     if (!poll_obj) {",
      "175:                         continue;",
      "176:                     }",
      "178:                     poll_obj->pollfd = new_fds + (poll_obj->pollfd - poll_set->pollfds);",
      "179:                 }",
      "182:                 m_del(struct pollfd, poll_set->pollfds, poll_set->alloc);",
      "183:             }",
      "185:             poll_set->pollfds = new_fds;",
      "186:             poll_set->alloc = new_alloc;",
      "",
      "---------------"
    ],
    "tests/extmod/select_poll_fd.py||tests/extmod/select_poll_fd.py": [
      "File: tests/extmod/select_poll_fd.py -> tests/extmod/select_poll_fd.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "34: # Poll for input, should return an empty list.",
      "35: print(poller.poll(0))",
      "38: poller = select.poll()",
      "39: for fd in range(6000):",
      "40:     poller.register(fd)",
      "41: try:",
      "42:     poller.poll()",
      "43: except OSError as er:",
      "44:     print(er.errno == errno.EINVAL)",
      "",
      "[Removed Lines]",
      "37: # Test registering a very large number of file descriptors.",
      "",
      "[Added Lines]",
      "37: # Test registering a very large number of file descriptors (will trigger",
      "38: # EINVAL due to more than OPEN_MAX fds).",
      "44:     assert False",
      "48: # Register stdout/stderr, plus many extra ones to trigger the fd vector",
      "49: # resizing. Then unregister the excess ones and verify poll still works.",
      "50: poller = select.poll()",
      "51: for fd in range(1, 1000):",
      "52:     poller.register(fd)",
      "53: for i in range(3, 1000):",
      "54:     poller.unregister(i)",
      "55: print(sorted(poller.poll()))",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "a70367e293a2293918a3649dc8c6f875c39543cd",
      "candidate_info": {
        "commit_hash": "a70367e293a2293918a3649dc8c6f875c39543cd",
        "repo": "jimmo/micropython",
        "commit_url": "https://github.com/jimmo/micropython/commit/a70367e293a2293918a3649dc8c6f875c39543cd",
        "files": [
          "ports/nrf/modules/os/microbitfs.c"
        ],
        "message": "nrf/modules/os/microbitfs: Sweep the filesystem if any free chunk found.\n\nIf there are any free chunks found then it's better to sweep the filesystem\nand use the available chunks, rather than error out with ENOSPC when there\nis in fact a bit of space remaining.\n\nSigned-off-by: Damien George <damien@micropython.org>",
        "before_after_code_files": [
          "ports/nrf/modules/os/microbitfs.c||ports/nrf/modules/os/microbitfs.c"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/micropython/micropython/pull/12644"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "ports/nrf/modules/os/microbitfs.c||ports/nrf/modules/os/microbitfs.c": [
          "File: ports/nrf/modules/os/microbitfs.c -> ports/nrf/modules/os/microbitfs.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "81: #define MAX_FILENAME_LENGTH 120",
          "87: #define FILE_NOT_FOUND ((uint8_t)-1)",
          "",
          "[Removed Lines]",
          "85: #define MIN_CHUNKS_FOR_SWEEP (FLASH_PAGESIZE / CHUNK_SIZE)",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "311:         if (index == chunks_in_file_system+1) index = 1;",
          "312:     } while (index != start_index);",
          "313:     DEBUG((\"FILE DEBUG: %lu free chunks\\r\\n\", freed_chunks));",
          "315:         return FILE_NOT_FOUND;",
          "316:     }",
          "",
          "[Removed Lines]",
          "314:     if (freed_chunks < MIN_CHUNKS_FOR_SWEEP) {",
          "",
          "[Added Lines]",
          "310:     if (freed_chunks == 0) {",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "2ecbad4e91192c88f831d8690dbad31ddba72135",
      "candidate_info": {
        "commit_hash": "2ecbad4e91192c88f831d8690dbad31ddba72135",
        "repo": "jimmo/micropython",
        "commit_url": "https://github.com/jimmo/micropython/commit/2ecbad4e91192c88f831d8690dbad31ddba72135",
        "files": [
          "extmod/asyncio/core.py",
          "extmod/asyncio/funcs.py",
          "tests/extmod/asyncio_gather_finished_early.py"
        ],
        "message": "extmod/asyncio: Support gather of tasks that finish early.\n\nAdds support to asyncio.gather() for the case that one or more (or all)\nsub-tasks finish and/or raise an exception before the gather starts.\n\nSigned-off-by: Damien George <damien@micropython.org>",
        "before_after_code_files": [
          "extmod/asyncio/core.py||extmod/asyncio/core.py",
          "extmod/asyncio/funcs.py||extmod/asyncio/funcs.py",
          "tests/extmod/asyncio_gather_finished_early.py||tests/extmod/asyncio_gather_finished_early.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/micropython/micropython/pull/12644"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "extmod/asyncio/core.py||extmod/asyncio/core.py": [
          "File: extmod/asyncio/core.py -> extmod/asyncio/core.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "219:             elif t.state is None:",
          "220:                 # Task is already finished and nothing await'ed on the task,",
          "221:                 # so call the exception handler.",
          "222:                 _exc_context[\"exception\"] = exc",
          "223:                 _exc_context[\"future\"] = t",
          "224:                 Loop.call_exception_handler(_exc_context)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "223:                 # Save exception raised by the coro for later use.",
          "224:                 t.data = exc",
          "226:                 # Create exception context and call the exception handler.",
          "",
          "---------------"
        ],
        "extmod/asyncio/funcs.py||extmod/asyncio/funcs.py": [
          "File: extmod/asyncio/funcs.py -> extmod/asyncio/funcs.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "64: # async",
          "65: def gather(*aws, return_exceptions=False):",
          "69:     def done(t, er):",
          "70:         # Sub-task \"t\" has finished, with exception \"er\".",
          "71:         nonlocal state",
          "",
          "[Removed Lines]",
          "66:     if not aws:",
          "67:         return []",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "86:         # Gather waiting is done, schedule the main gather task.",
          "87:         core._task_queue.push(gather_task)",
          "89:     ts = [core._promote_to_task(aw) for aw in aws]",
          "90:     for i in range(len(ts)):",
          "93:             raise RuntimeError(\"can't gather\")",
          "97:     # Set the state for execution of the gather.",
          "98:     gather_task = core.cur_task",
          "100:     cancel_all = False",
          "110:     # Clean up tasks.",
          "111:     for i in range(len(ts)):",
          "",
          "[Removed Lines]",
          "91:         if ts[i].state is not True:",
          "92:             # Task is not running, gather not currently supported for this case.",
          "94:         # Register the callback to call when the task is done.",
          "95:         ts[i].state = done",
          "99:     state = len(ts)",
          "102:     # Wait for the a sub-task to need attention.",
          "103:     gather_task.data = _Remove",
          "104:     try:",
          "105:         yield",
          "106:     except core.CancelledError as er:",
          "107:         cancel_all = True",
          "108:         state = er",
          "",
          "[Added Lines]",
          "86:     # Prepare the sub-tasks for the gather.",
          "87:     # The `state` variable counts the number of tasks to wait for, and can be negative",
          "88:     # if the gather should not run at all (because a task already had an exception).",
          "90:     state = 0",
          "92:         if ts[i].state is True:",
          "93:             # Task is running, register the callback to call when the task is done.",
          "94:             ts[i].state = done",
          "95:             state += 1",
          "96:         elif not ts[i].state:",
          "97:             # Task finished already.",
          "98:             if not isinstance(ts[i].data, StopIteration):",
          "99:                 # Task finished by raising an exception.",
          "100:                 if not return_exceptions:",
          "101:                     # Do not run this gather at all.",
          "102:                     state = -len(ts)",
          "103:         else:",
          "104:             # Task being waited on, gather not currently supported for this case.",
          "111:     # Wait for a sub-task to need attention (if there are any to wait for).",
          "112:     if state > 0:",
          "113:         gather_task.data = _Remove",
          "114:         try:",
          "115:             yield",
          "116:         except core.CancelledError as er:",
          "117:             cancel_all = True",
          "118:             state = er",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "118:             # Sub-task ran to completion, get its return value.",
          "119:             ts[i] = ts[i].data.value",
          "120:         else:",
          "124:     # Either this gather was cancelled, or one of the sub-tasks raised an exception with",
          "125:     # return_exceptions==False, so reraise the exception here.",
          "",
          "[Removed Lines]",
          "121:             # Sub-task had an exception with return_exceptions==True, so get its exception.",
          "122:             ts[i] = ts[i].data",
          "",
          "[Added Lines]",
          "131:             # Sub-task had an exception.",
          "132:             if return_exceptions:",
          "133:                 # Get the sub-task exception to return in the list of return values.",
          "134:                 ts[i] = ts[i].data",
          "135:             elif isinstance(state, int):",
          "136:                 # Raise the sub-task exception, if there is not already an exception to raise.",
          "137:                 state = ts[i].data",
          "",
          "---------------"
        ],
        "tests/extmod/asyncio_gather_finished_early.py||tests/extmod/asyncio_gather_finished_early.py": [
          "File: tests/extmod/asyncio_gather_finished_early.py -> tests/extmod/asyncio_gather_finished_early.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: # Test asyncio.gather() when a task is already finished before the gather starts.",
          "3: try:",
          "4:     import asyncio",
          "5: except ImportError:",
          "6:     print(\"SKIP\")",
          "7:     raise SystemExit",
          "10: # CPython and MicroPython differ in when they signal (and print) that a task raised an",
          "11: # uncaught exception.  So define an empty custom_handler() to suppress this output.",
          "12: def custom_handler(loop, context):",
          "13:     pass",
          "16: async def task_that_finishes_early(id, event, fail):",
          "17:     print(\"task_that_finishes_early\", id)",
          "18:     event.set()",
          "19:     if fail:",
          "20:         raise ValueError(\"intentional exception\", id)",
          "23: async def task_that_runs():",
          "24:     for i in range(5):",
          "25:         print(\"task_that_runs\", i)",
          "26:         await asyncio.sleep(0)",
          "29: async def main(start_task_that_runs, task_fail, return_exceptions):",
          "30:     print(\"== start\", start_task_that_runs, task_fail, return_exceptions)",
          "32:     # Set exception handler to suppress exception output.",
          "33:     loop = asyncio.get_event_loop()",
          "34:     loop.set_exception_handler(custom_handler)",
          "36:     # Create tasks.",
          "37:     event_a = asyncio.Event()",
          "38:     event_b = asyncio.Event()",
          "39:     tasks = []",
          "40:     if start_task_that_runs:",
          "41:         tasks.append(asyncio.create_task(task_that_runs()))",
          "42:     tasks.append(asyncio.create_task(task_that_finishes_early(\"a\", event_a, task_fail)))",
          "43:     tasks.append(asyncio.create_task(task_that_finishes_early(\"b\", event_b, task_fail)))",
          "45:     # Make sure task_that_finishes_early() are both done, before calling gather().",
          "46:     await event_a.wait()",
          "47:     await event_b.wait()",
          "49:     # Gather the tasks.",
          "50:     try:",
          "51:         result = \"complete\", await asyncio.gather(*tasks, return_exceptions=return_exceptions)",
          "52:     except Exception as er:",
          "53:         result = \"exception\", er, start_task_that_runs and tasks[0].done()",
          "55:     # Wait for the final task to finish (if it was started).",
          "56:     if start_task_that_runs:",
          "57:         await tasks[0]",
          "59:     # Print results.",
          "60:     print(result)",
          "63: # Run the test in the 8 different combinations of its arguments.",
          "64: for i in range(8):",
          "65:     asyncio.run(main(bool(i & 4), bool(i & 2), bool(i & 1)))",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "c64b7107da0ab5b1554f37ff459113b5a9cf6fdc",
      "candidate_info": {
        "commit_hash": "c64b7107da0ab5b1554f37ff459113b5a9cf6fdc",
        "repo": "jimmo/micropython",
        "commit_url": "https://github.com/jimmo/micropython/commit/c64b7107da0ab5b1554f37ff459113b5a9cf6fdc",
        "files": [
          "py/map.c",
          "py/mpconfig.h",
          "py/obj.c",
          "py/runtime.c",
          "py/scheduler.c",
          "py/vm.c"
        ],
        "message": "py/mpconfig.h: Move MICROPY_WRAP macros to place-of-use.\n\nIt's useful to provide a way for a port/board to customise an individual\nfunction, but no point cluttering up mpconfig.h.\n\nThese wrap macros are now defined in terms of stastandardised levels\n(O3+ram, O3+mayberam, O3, maybeO3) which are defined in mpconfig.h. This\nis what most ports/boards should configure instead.\n\nCurrently only level 1 and 2 are used, and the various functions have\nbeen assigned levels to match the way esp32 currently overrides them.\n\nSigned-off-by: Jim Mussared <jim.mussared@gmail.com>",
        "before_after_code_files": [
          "py/map.c||py/map.c",
          "py/mpconfig.h||py/mpconfig.h",
          "py/obj.c||py/obj.c",
          "py/runtime.c||py/runtime.c",
          "py/scheduler.c||py/scheduler.c",
          "py/vm.c||py/vm.c"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/micropython/micropython/pull/12644"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "py/map.c||py/map.c": [
          "File: py/map.c -> py/map.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "147:     m_del(mp_map_elem_t, old_table, old_alloc);",
          "148: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "150: #ifndef MICROPY_WRAP_MP_MAP_LOOKUP",
          "151: #define MICROPY_WRAP_MP_MAP_LOOKUP(f) MICROPY_PERFORMANCE_CRITICAL_LEVEL_1(f)",
          "152: #endif",
          "",
          "---------------"
        ],
        "py/mpconfig.h||py/mpconfig.h": [
          "File: py/mpconfig.h -> py/mpconfig.h",
          "--- Hunk 1 ---",
          "[Context before]",
          "1784: #endif",
          "1791: #endif",
          "1795: #endif",
          "1799: #endif",
          "1827: #endif",
          "",
          "[Removed Lines]",
          "1789: #ifndef MICROPY_WRAP_MP_BINARY_OP",
          "1790: #define MICROPY_WRAP_MP_BINARY_OP(f) f",
          "1793: #ifndef MICROPY_WRAP_MP_EXECUTE_BYTECODE",
          "1794: #define MICROPY_WRAP_MP_EXECUTE_BYTECODE(f) f",
          "1797: #ifndef MICROPY_WRAP_MP_LOAD_GLOBAL",
          "1798: #define MICROPY_WRAP_MP_LOAD_GLOBAL(f) f",
          "1801: #ifndef MICROPY_WRAP_MP_LOAD_NAME",
          "1802: #define MICROPY_WRAP_MP_LOAD_NAME(f) f",
          "1803: #endif",
          "1805: #ifndef MICROPY_WRAP_MP_MAP_LOOKUP",
          "1806: #define MICROPY_WRAP_MP_MAP_LOOKUP(f) f",
          "1807: #endif",
          "1809: #ifndef MICROPY_WRAP_MP_OBJ_GET_TYPE",
          "1810: #define MICROPY_WRAP_MP_OBJ_GET_TYPE(f) f",
          "1811: #endif",
          "1813: #ifndef MICROPY_WRAP_MP_SCHED_EXCEPTION",
          "1814: #define MICROPY_WRAP_MP_SCHED_EXCEPTION(f) f",
          "1815: #endif",
          "1817: #ifndef MICROPY_WRAP_MP_SCHED_KEYBOARD_INTERRUPT",
          "1818: #define MICROPY_WRAP_MP_SCHED_KEYBOARD_INTERRUPT(f) f",
          "1819: #endif",
          "1821: #ifndef MICROPY_WRAP_MP_SCHED_SCHEDULE",
          "1822: #define MICROPY_WRAP_MP_SCHED_SCHEDULE(f) f",
          "1823: #endif",
          "1825: #ifndef MICROPY_WRAP_MP_SCHED_VM_ABORT",
          "1826: #define MICROPY_WRAP_MP_SCHED_VM_ABORT(f) f",
          "",
          "[Added Lines]",
          "1791: #ifndef MICROPY_PERFORMANCE_CRITICAL_LEVEL_1",
          "1792: #define MICROPY_PERFORMANCE_CRITICAL_LEVEL_1(f) f",
          "1797: #ifndef MICROPY_PERFORMANCE_CRITICAL_LEVEL_2",
          "1798: #define MICROPY_PERFORMANCE_CRITICAL_LEVEL_2(f) f",
          "1803: #ifndef MICROPY_PERFORMANCE_CRITICAL_LEVEL_3",
          "1804: #define MICROPY_PERFORMANCE_CRITICAL_LEVEL_3(f) f",
          "1808: #ifndef MICROPY_PERFORMANCE_CRITICAL_LEVEL_4",
          "1809: #define MICROPY_PERFORMANCE_CRITICAL_LEVEL_4(f) f",
          "",
          "---------------"
        ],
        "py/obj.c||py/obj.c": [
          "File: py/obj.c -> py/obj.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "44:     return base;",
          "45: }",
          "47: const mp_obj_type_t *MICROPY_WRAP_MP_OBJ_GET_TYPE(mp_obj_get_type)(mp_const_obj_t o_in) {",
          "48:     #if MICROPY_OBJ_IMMEDIATE_OBJS && MICROPY_OBJ_REPR == MICROPY_OBJ_REPR_A",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "47: #ifndef MICROPY_WRAP_MP_OBJ_GET_TYPE",
          "48: #define MICROPY_WRAP_MP_OBJ_GET_TYPE(f) MICROPY_PERFORMANCE_CRITICAL_LEVEL_1(f)",
          "49: #endif",
          "",
          "---------------"
        ],
        "py/runtime.c||py/runtime.c": [
          "File: py/runtime.c -> py/runtime.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "203:     ctx->func(ctx->arg);",
          "204: }",
          "206: mp_obj_t MICROPY_WRAP_MP_LOAD_NAME(mp_load_name)(qstr qst) {",
          "208:     DEBUG_OP_printf(\"load name %s\\n\", qstr_str(qst));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "206: #ifndef MICROPY_WRAP_MP_LOAD_NAME",
          "207: #define MICROPY_WRAP_MP_LOAD_NAME(f) MICROPY_PERFORMANCE_CRITICAL_LEVEL_1(f)",
          "208: #endif",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "216:     return mp_load_global(qst);",
          "217: }",
          "219: mp_obj_t MICROPY_WRAP_MP_LOAD_GLOBAL(mp_load_global)(qstr qst) {",
          "221:     DEBUG_OP_printf(\"load global %s\\n\", qstr_str(qst));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "223: #ifndef MICROPY_WRAP_MP_LOAD_GLOBAL",
          "224: #define MICROPY_WRAP_MP_LOAD_GLOBAL(f) MICROPY_PERFORMANCE_CRITICAL_LEVEL_1(f)",
          "225: #endif",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "360:     }",
          "361: }",
          "363: mp_obj_t MICROPY_WRAP_MP_BINARY_OP(mp_binary_op)(mp_binary_op_t op, mp_obj_t lhs, mp_obj_t rhs) {",
          "364:     DEBUG_OP_printf(\"binary \" UINT_FMT \" %q %p %p\\n\", op, mp_binary_op_method_name[op], lhs, rhs);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "371: #ifndef MICROPY_WRAP_MP_BINARY_OP",
          "372: #define MICROPY_WRAP_MP_BINARY_OP(f) MICROPY_PERFORMANCE_CRITICAL_LEVEL_2(f)",
          "373: #endif",
          "",
          "---------------"
        ],
        "py/scheduler.c||py/scheduler.c": [
          "File: py/scheduler.c -> py/scheduler.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "29: #include \"py/mphal.h\"",
          "30: #include \"py/runtime.h\"",
          "34: void MICROPY_WRAP_MP_SCHED_EXCEPTION(mp_sched_exception)(mp_obj_t exc) {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "32: #ifndef MICROPY_WRAP_MP_SCHED_EXCEPTION",
          "33: #define MICROPY_WRAP_MP_SCHED_EXCEPTION(f) MICROPY_PERFORMANCE_CRITICAL_LEVEL_1(f)",
          "34: #endif",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "45: }",
          "47: #if MICROPY_KBD_EXCEPTION",
          "49: void MICROPY_WRAP_MP_SCHED_KEYBOARD_INTERRUPT(mp_sched_keyboard_interrupt)(void) {",
          "50:     MP_STATE_VM(mp_kbd_exception).traceback_data = NULL;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "52: #ifndef MICROPY_WRAP_MP_SCHED_KEYBOARD_INTERRUPT",
          "53: #define MICROPY_WRAP_MP_SCHED_KEYBOARD_INTERRUPT(f) MICROPY_PERFORMANCE_CRITICAL_LEVEL_1(f)",
          "54: #endif",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "53: #endif",
          "55: #if MICROPY_ENABLE_VM_ABORT",
          "56: void MICROPY_WRAP_MP_SCHED_VM_ABORT(mp_sched_vm_abort)(void) {",
          "57:     MP_STATE_VM(vm_abort) = true;",
          "58: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "64: #ifndef MICROPY_WRAP_MP_SCHED_VM_ABORT",
          "65: #define MICROPY_WRAP_MP_SCHED_VM_ABORT(f) MICROPY_PERFORMANCE_CRITICAL_LEVEL_1(f)",
          "66: #endif",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "156:     MICROPY_END_ATOMIC_SECTION(atomic_state);",
          "157: }",
          "159: bool MICROPY_WRAP_MP_SCHED_SCHEDULE(mp_sched_schedule)(mp_obj_t function, mp_obj_t arg) {",
          "160:     mp_uint_t atomic_state = MICROPY_BEGIN_ATOMIC_SECTION();",
          "161:     bool ret;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "171: #ifndef MICROPY_WRAP_MP_SCHED_SCHEDULE",
          "172: #define MICROPY_WRAP_MP_SCHED_SCHEDULE(f) MICROPY_PERFORMANCE_CRITICAL_LEVEL_1(f)",
          "173: #endif",
          "",
          "---------------"
        ],
        "py/vm.c||py/vm.c": [
          "File: py/vm.c -> py/vm.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "195: #define TRACE_TICK(current_ip, current_sp, is_exception)",
          "196: #endif // MICROPY_PY_SYS_SETTRACE",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "198: #ifndef MICROPY_WRAP_MP_EXECUTE_BYTECODE",
          "200: #define MICROPY_WRAP_MP_EXECUTE_BYTECODE(f) MICROPY_PERFORMANCE_CRITICAL_LEVEL_1(f)",
          "211: #endif",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "ee226a8b4340111eee0b13e7b840948f4bb70465",
      "candidate_info": {
        "commit_hash": "ee226a8b4340111eee0b13e7b840948f4bb70465",
        "repo": "jimmo/micropython",
        "commit_url": "https://github.com/jimmo/micropython/commit/ee226a8b4340111eee0b13e7b840948f4bb70465",
        "files": [
          "docs/library/bluetooth.rst",
          "docs/library/rp2.StateMachine.rst",
          "docs/reference/constrained.rst",
          "tests/basics/bytearray_byte_operations.py",
          "tests/extmod/vfs_fat_ilistdir_del.py",
          "tests/extmod/vfs_lfs_ilistdir_del.py",
          "tests/extmod/vfs_posix_ilistdir_del.py",
          "tests/import/ext/micropython.py",
          "tests/import/ext/sys.py",
          "tests/import/ext/usys.py"
        ],
        "message": "all: Fix \"reuse\" and \"overridden\" spelling mistakes.\n\nCodespell doesn't pick up \"re-used\" or \"re-uses\", and ignores the tests/\ndirectory, so fix these manually.\n\nSigned-off-by: Damien George <damien@micropython.org>",
        "before_after_code_files": [
          "tests/basics/bytearray_byte_operations.py||tests/basics/bytearray_byte_operations.py",
          "tests/extmod/vfs_fat_ilistdir_del.py||tests/extmod/vfs_fat_ilistdir_del.py",
          "tests/extmod/vfs_lfs_ilistdir_del.py||tests/extmod/vfs_lfs_ilistdir_del.py",
          "tests/extmod/vfs_posix_ilistdir_del.py||tests/extmod/vfs_posix_ilistdir_del.py",
          "tests/import/ext/micropython.py||tests/import/ext/micropython.py",
          "tests/import/ext/sys.py||tests/import/ext/sys.py",
          "tests/import/ext/usys.py||tests/import/ext/usys.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/micropython/micropython/pull/12644"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "tests/basics/bytearray_byte_operations.py||tests/basics/bytearray_byte_operations.py": [
          "File: tests/basics/bytearray_byte_operations.py -> tests/basics/bytearray_byte_operations.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "3: print(bytearray(b\"hello world\").find(b\"ll\"))",
          "4: print(bytearray(b\"hello\\x00world\").rfind(b\"l\"))",
          "",
          "[Removed Lines]",
          "1: # test bytearray with its re-use of byte functions",
          "",
          "[Added Lines]",
          "1: # test bytearray with its reuse of byte functions",
          "",
          "---------------"
        ],
        "tests/extmod/vfs_fat_ilistdir_del.py||tests/extmod/vfs_fat_ilistdir_del.py": [
          "File: tests/extmod/vfs_fat_ilistdir_del.py -> tests/extmod/vfs_fat_ilistdir_del.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "57:             break",
          "58:         vfs.mkdir(dname)",
          "61:         # throws the correct exception.",
          "62:         idir_emptied = vfs.ilistdir(\"/\")",
          "63:         l = list(idir_emptied)",
          "",
          "[Removed Lines]",
          "60:         # Also create a fully drained iterator and ensure trying to re-use it",
          "",
          "[Added Lines]",
          "60:         # Also create a fully drained iterator and ensure trying to reuse it",
          "",
          "---------------"
        ],
        "tests/extmod/vfs_lfs_ilistdir_del.py||tests/extmod/vfs_lfs_ilistdir_del.py": [
          "File: tests/extmod/vfs_lfs_ilistdir_del.py -> tests/extmod/vfs_lfs_ilistdir_del.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "57:             break",
          "58:         vfs.mkdir(dname)",
          "61:         # throws the correct exception.",
          "62:         idir_emptied = vfs.ilistdir(\"/\")",
          "63:         l = list(idir_emptied)",
          "",
          "[Removed Lines]",
          "60:         # Also create a fully drained iterator and ensure trying to re-use it",
          "",
          "[Added Lines]",
          "60:         # Also create a fully drained iterator and ensure trying to reuse it",
          "",
          "---------------"
        ],
        "tests/extmod/vfs_posix_ilistdir_del.py||tests/extmod/vfs_posix_ilistdir_del.py": [
          "File: tests/extmod/vfs_posix_ilistdir_del.py -> tests/extmod/vfs_posix_ilistdir_del.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "37:             break",
          "38:         vfs.mkdir(dname)",
          "41:         # throws the correct exception.",
          "42:         idir_emptied = vfs.ilistdir(\"/\")",
          "43:         l = list(idir_emptied)",
          "",
          "[Removed Lines]",
          "40:         # Also create a fully drained iterator and ensure trying to re-use it",
          "",
          "[Added Lines]",
          "40:         # Also create a fully drained iterator and ensure trying to reuse it",
          "",
          "---------------"
        ],
        "tests/import/ext/micropython.py||tests/import/ext/micropython.py": [
          "File: tests/import/ext/micropython.py -> tests/import/ext/micropython.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "2: print(\"ERROR: micropython from filesystem\")",
          "",
          "[Removed Lines]",
          "1: # micropython is always builtin and cannot be overriden by the filesystem.",
          "",
          "[Added Lines]",
          "1: # micropython is always builtin and cannot be overridden by the filesystem.",
          "",
          "---------------"
        ],
        "tests/import/ext/sys.py||tests/import/ext/sys.py": [
          "File: tests/import/ext/sys.py -> tests/import/ext/sys.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "2: print(\"ERROR: sys from filesystem\")",
          "",
          "[Removed Lines]",
          "1: # sys is always builtin and cannot be overriden by the filesystem.",
          "",
          "[Added Lines]",
          "1: # sys is always builtin and cannot be overridden by the filesystem.",
          "",
          "---------------"
        ],
        "tests/import/ext/usys.py||tests/import/ext/usys.py": [
          "File: tests/import/ext/usys.py -> tests/import/ext/usys.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "2: # filesystem.",
          "3: print(\"ERROR: usys from filesystem\")",
          "",
          "[Removed Lines]",
          "1: # usys (and any u-prefix) is always builtin and cannot be overriden by the",
          "",
          "[Added Lines]",
          "1: # usys (and any u-prefix) is always builtin and cannot be overridden by the",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "7cf1118831e71670dc237b5256a54856f6fdf0c2",
      "candidate_info": {
        "commit_hash": "7cf1118831e71670dc237b5256a54856f6fdf0c2",
        "repo": "jimmo/micropython",
        "commit_url": "https://github.com/jimmo/micropython/commit/7cf1118831e71670dc237b5256a54856f6fdf0c2",
        "files": [
          "ports/stm32/usbd_conf.h",
          "ports/stm32/usbdev/core/src/usbd_ctlreq.c"
        ],
        "message": "stm32/usbdev: Optionally pass through vendor requests to Setup function.\n\nSigned-off-by: Damien George <damien@micropython.org>",
        "before_after_code_files": [
          "ports/stm32/usbd_conf.h||ports/stm32/usbd_conf.h",
          "ports/stm32/usbdev/core/src/usbd_ctlreq.c||ports/stm32/usbdev/core/src/usbd_ctlreq.c"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/micropython/micropython/pull/12644"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "ports/stm32/usbd_conf.h||ports/stm32/usbd_conf.h": [
          "File: ports/stm32/usbd_conf.h -> ports/stm32/usbd_conf.h",
          "--- Hunk 1 ---",
          "[Context before]",
          "49: #endif",
          "50: #define USBD_DEBUG_LEVEL                      0",
          "53: #define USBD_PMA_RESERVE                      (64)",
          "54: #define USBD_PMA_NUM_FIFO                     (16) // Maximum 8 endpoints, 2 FIFOs each",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "53: #ifndef USBD_ENABLE_VENDOR_DEVICE_REQUESTS",
          "54: #define USBD_ENABLE_VENDOR_DEVICE_REQUESTS    (0)",
          "55: #endif",
          "",
          "---------------"
        ],
        "ports/stm32/usbdev/core/src/usbd_ctlreq.c||ports/stm32/usbdev/core/src/usbd_ctlreq.c": [
          "File: ports/stm32/usbdev/core/src/usbd_ctlreq.c -> ports/stm32/usbdev/core/src/usbd_ctlreq.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "120: {",
          "121:   USBD_StatusTypeDef ret = USBD_OK;",
          "123:   switch (req->bRequest)",
          "124:   {",
          "125:   case USB_REQ_GET_DESCRIPTOR:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "123:   #if USBD_ENABLE_VENDOR_DEVICE_REQUESTS",
          "126:   if ((req->bmRequest & 0xe0) == 0xc0) {",
          "127:     return pdev->pClass->Setup (pdev, req);",
          "128:   }",
          "129:   #endif",
          "",
          "---------------"
        ]
      }
    }
  ]
}