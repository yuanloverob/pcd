{
  "cve_id": "CVE-2024-23638",
  "cve_desc": "Squid is a caching proxy for the Web. Due to an expired pointer reference bug, Squid prior to version 6.6 is vulnerable to a Denial of Service attack against Cache Manager error responses. This problem allows a trusted client to perform Denial of Service when generating error pages for Client Manager reports. Squid older than 5.0.5 have not been tested and should be assumed to be vulnerable. All Squid-5.x up to and including 5.9 are vulnerable. All Squid-6.x up to and including 6.5 are vulnerable. This bug is fixed by Squid version 6.6. In addition, patches addressing this problem for the stable releases can be found in Squid's patch archives. As a workaround, prevent access to Cache Manager using Squid's main access control: `http_access deny manager`.",
  "repo": "squid-cache/squid",
  "patch_hash": "290ae202883ac28a48867079c2fb34c40efd382b",
  "patch_info": {
    "commit_hash": "290ae202883ac28a48867079c2fb34c40efd382b",
    "repo": "squid-cache/squid",
    "commit_url": "https://github.com/squid-cache/squid/commit/290ae202883ac28a48867079c2fb34c40efd382b",
    "files": [
      "src/servers/Server.cc"
    ],
    "message": "Just close after a write(2) response sending error (#1582)\n\n    FATAL: assertion failed: Http1Server.cc:322: \"rep\"\n\n2015 commit 21cd322 started to continue ClientStream processing after\nsocket write(2) failures. In most cases, the code still \"worked\". For\nexample, initiateClose() would close the client-Squid connection, and\nconnStateClosed() would be called before Store has a chance to deliver\nresponse body data requested by pullData() in writeComplete().\n\nHowever, that response body data could sometimes reach Server, and\nhandleReply() would assert because startOfOutput() says that we have not\nwritten the headers, but ClientStream state (i.e. a nil `rep` parameter)\nsays that we have. These assertion can be triggered by disabling\ninitiateClose(), and they can probably be triggered by traffic as well.\n\nNow, after a Comm::Write() error, we terminateAll() client transactions\non the failed connection[^1] and do not call afterClientWrite() that is\nnot equipped to handle I/O errors and would continue ClientStream\nprocessing if called.\n\nThis bug was discovered and detailed by Joshua Rogers at\nhttps://megamansec.github.io/Squid-Security-Audit/stream-assert.html\nwhere it was filed as \"Implicit Assertion in Stream Handling\".\n\n[^1]: We terminateAll() instead of potentially postponing closure with\ninitiateClose() because the failed client-Squid connection most likely\ncannot be salvaged for, say, reading the remainder of the request body.",
    "before_after_code_files": [
      "src/servers/Server.cc||src/servers/Server.cc"
    ]
  },
  "patch_diff": {
    "src/servers/Server.cc||src/servers/Server.cc": [
      "File: src/servers/Server.cc -> src/servers/Server.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "205:     Must(io.conn->fd == clientConnection->fd);",
      "210:     afterClientWrite(io.size); // update state",
      "211:     writeSomeData(); // maybe schedules another write",
      "",
      "[Removed Lines]",
      "207:     if (io.flag && pipeline.front())",
      "208:         pipeline.front()->initiateClose(\"write failure\");",
      "",
      "[Added Lines]",
      "207:     if (io.flag) {",
      "208:         debugs(33, 2, \"bailing after a write failure: \" << xstrerr(io.xerrno));",
      "209:         LogTagsErrors lte;",
      "210:         lte.timedout = io.xerrno == ETIMEDOUT;",
      "211:         lte.aborted = !lte.timedout; // intentionally true for zero io.xerrno",
      "212:         terminateAll(Error(ERR_WRITE_ERROR, SysErrorDetail::NewIfAny(io.xerrno)), lte);",
      "213:         return;",
      "214:     }",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "18209199f8c330176401eac7ef2deb06ca4389b9",
      "candidate_info": {
        "commit_hash": "18209199f8c330176401eac7ef2deb06ca4389b9",
        "repo": "squid-cache/squid",
        "commit_url": "https://github.com/squid-cache/squid/commit/18209199f8c330176401eac7ef2deb06ca4389b9",
        "files": [
          "src/peer_digest.cc"
        ],
        "message": "Bug 5318: peer_digest.cc:399: \"fetch->pd && receivedData.data\" (#1584)\n\nRecent commit 122a6e3 removed HTTP response headers from store_client\nresponses. That removal created the possibility of an empty\nStoreIOBuffer at the beginning of the feeding sequence. Pending Bug 5317\nfix will make such buffers even more frequent. Existing store_client\nrecipients have varying requirements with regard to empty response\nbuffers, as documented in store_client::finishCallback(). We missed this\nrequirement conflict in Cache Digest code. This fix adjusts Cache\nDigests code to be compatible with empty StoreIOBuffer representation in\ncurrent store_client code.",
        "before_after_code_files": [
          "src/peer_digest.cc||src/peer_digest.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/squid-cache/squid/pull/1601"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "src/peer_digest.cc||src/peer_digest.cc": [
          "File: src/peer_digest.cc -> src/peer_digest.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "396:         return;",
          "397:     }",
          "406:     fetch->bufofs += receivedData.length;",
          "",
          "[Removed Lines]",
          "399:     assert(fetch->pd && receivedData.data);",
          "403:     assert(fetch->buf + fetch->bufofs == receivedData.data);",
          "",
          "[Added Lines]",
          "399:     assert(fetch->pd);",
          "403:     assert(!receivedData.data || fetch->buf + fetch->bufofs == receivedData.data);",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "682:     }",
          "686:         if (!pd->cd)",
          "687:             reason = \"null digest?!\";",
          "688:         else if (fetch->mask_offset != pd->cd->mask_size)",
          "",
          "[Removed Lines]",
          "685:     if (!reason && !size) {",
          "",
          "[Added Lines]",
          "685:     if (!reason && !size && fetch->state != DIGEST_READ_REPLY) {",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "6c29ec591b1c777fc9a66f810f0ce5bc5076bc40",
      "candidate_info": {
        "commit_hash": "6c29ec591b1c777fc9a66f810f0ce5bc5076bc40",
        "repo": "squid-cache/squid",
        "commit_url": "https://github.com/squid-cache/squid/commit/6c29ec591b1c777fc9a66f810f0ce5bc5076bc40",
        "files": [
          "src/store_client.cc"
        ],
        "message": "Bug 5317: FATAL attempt to read data from memory (#1579)\n\n    FATAL: Squid has attempted to read data ... that is not present.\n\nRecent commit 122a6e3 attempted to deliver in-memory response body bytes\nto a Store-reading client that requested (at least) response headers.\nThat optimization relied on the old canReadFromMemory() logic, but that\nlogic results in false positives when the checked read offset falls into\na gap between stored headers and the first body byte of a Content-Range.\nIn that case, a false positive leads to a readFromMemory() call and a\nFATAL mem_hdr::copy() error.\n\nThis workaround disables the above optimization without fixing\ncanReadFromMemory(). We believe that a readFromMemory() call that comes\nright after response headers are delivered to the Store-reading client\nwill not suffer from the same problem because the client will supply the\nread offset of the first body byte, eliminating the false positive.",
        "before_after_code_files": [
          "src/store_client.cc||src/store_client.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/squid-cache/squid/pull/1601"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "src/store_client.cc||src/store_client.cc": [
          "File: src/store_client.cc -> src/store_client.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "409:             return; // failure",
          "410:     }",
          "414:         readFromMemory();",
          "415:         noteNews(); // will sendHttpHeaders (if needed) as well",
          "416:         flags.store_copying = false;",
          "",
          "[Removed Lines]",
          "413:     if (canReadFromMemory()) {",
          "",
          "[Added Lines]",
          "414:     if (!sendHttpHeaders && canReadFromMemory()) {",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "2f0b06198837c3a4a1215ebcd1aaaa08b6430f62",
      "candidate_info": {
        "commit_hash": "2f0b06198837c3a4a1215ebcd1aaaa08b6430f62",
        "repo": "squid-cache/squid",
        "commit_url": "https://github.com/squid-cache/squid/commit/2f0b06198837c3a4a1215ebcd1aaaa08b6430f62",
        "files": [
          "src/log/DB/log_db_daemon.pl.in"
        ],
        "message": "log_db_daemon: Fix DSN construction (#1570)",
        "before_after_code_files": [
          "src/log/DB/log_db_daemon.pl.in||src/log/DB/log_db_daemon.pl.in"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/squid-cache/squid/pull/1601"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "src/log/DB/log_db_daemon.pl.in||src/log/DB/log_db_daemon.pl.in": [
          "File: src/log/DB/log_db_daemon.pl.in -> src/log/DB/log_db_daemon.pl.in",
          "--- Hunk 1 ---",
          "[Context before]",
          "392:     );",
          "394: # perform db connection",
          "396: my $dbh;",
          "397: my $sth;",
          "398: eval {",
          "",
          "[Removed Lines]",
          "395: my $dsn = \"DBI:mysql:database=$database\" . ($host ne \"localhost\" ? \":$host\" : \"\");",
          "",
          "[Added Lines]",
          "395: my $dsn = \"DBI:mysql:database=$database\" . ($host ne \"localhost\" ? \";host=$host\" : \"\");",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "985d2d55319043d0a2f12c12bfb80d1154295934",
      "candidate_info": {
        "commit_hash": "985d2d55319043d0a2f12c12bfb80d1154295934",
        "repo": "squid-cache/squid",
        "commit_url": "https://github.com/squid-cache/squid/commit/985d2d55319043d0a2f12c12bfb80d1154295934",
        "files": [
          "src/comm.cc",
          "src/ip/Address.cc",
          "src/ip/Intercept.cc"
        ],
        "message": "Bug 5154: Do not open IPv6 sockets when IPv6 is disabled (#1567)\n\n... but allow basic IPv6 manipulations like getSockAddr().\n\n    Address.cc:663 getAddrInfo() assertion failed: false\n\nSquids receives IPv6 addresses from traffic, configuration, or\nhard-coded constants even when ./configured with --disable-ipv6 or when\nIPv6 support was automatically disabled at startup after failing IPv6\ntests. To handle IPv6 correctly, such Squids must support basic IPv6\noperations like recognizing an IPv6 address in a request-target or\nreporting an unsolicited IPv6 DNS record. At least for now, such Squids\nmust also correctly parse configuration-related IPv6 addresses.\n\nAll those activities rely on various low-level operations like filling\naddrinfo structure with IP address information. Since 2012 commit\nc5fbbc7, Ip::Address::getAddrInfo() was failing for IPv6 addresses when\nIp::EnableIpv6 was falsy. That change correctly recognized[^1] the need\nfor such Squids to handle IPv6, but to support basic operations, we need\nto reject IPv6 addresses at a higher level and without asserting.\n\nThat high-level rejection work is ongoing, but initial attempts have\nexposed difficult problems that will take time to address. For now, we\njust avoid the assertion while protecting IPv6-disabled Squid from\nlistening on or opening connections to IPv6 addresses. Since Squid\nalready expects (and usually correctly handles) socket opening failures,\ndisabling those operations is better than failing in low-level IP\nmanipulation code.\n\nThe overall IPv6 posture of IPv6-disabled Squids that lack http_access\nor other rules to deny IPv6 requests will change: This fix exposes more\nof IPv6-disabled Squid code to IPv6 addresses. It is possible that such\nexposure will make some IPv6 resources inside Squid (e.g., a previously\ncached HTTP response) accessible to external requests. Squids will not\nopen or accept IPv6 connections but may forward requests with raw IPv6\ntargets to IPv4 cache_peers. Whether these and similar behavior changes\nare going to be permanent is open for debate, but even if they are\ntemporary, they are arguably better than the corresponding assertions.\n\nThese changes do not effect IPv6-enabled Squids.\n\nThe assertion in IPv6-disabled Squid was reported by Joshua Rogers at\nhttps://megamansec.github.io/Squid-Security-Audit/ipv6-assert.html where\nit was filed as \"Assertion on IPv6 Host Requests with --disable-ipv6\".\n\n[^1]: https://bugs.squid-cache.org/show_bug.cgi?id=3593#c1",
        "before_after_code_files": [
          "src/comm.cc||src/comm.cc",
          "src/ip/Address.cc||src/ip/Address.cc",
          "src/ip/Intercept.cc||src/ip/Intercept.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/squid-cache/squid/pull/1601"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "src/comm.cc||src/comm.cc": [
          "File: src/comm.cc -> src/comm.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "365:     ++ statCounter.syscalls.sock.sockets;",
          "368:     addr.getAddrInfo(AI);",
          "369:     AI->ai_socktype = sock_type;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "367:     if (!Ip::EnableIpv6 && addr.isIPv6()) {",
          "368:         debugs(50, 2, \"refusing to open an IPv6 socket when IPv6 support is disabled: \" << addr);",
          "369:         errno = ENOTSUP;",
          "370:         return -1;",
          "371:     }",
          "",
          "---------------"
        ],
        "src/ip/Address.cc||src/ip/Address.cc": [
          "File: src/ip/Address.cc -> src/ip/Address.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "623:             && dst->ai_protocol == 0)",
          "624:         dst->ai_protocol = IPPROTO_UDP;",
          "627:         dst->ai_addr = (struct sockaddr*)new sockaddr_in6;",
          "629:         memset(dst->ai_addr,0,sizeof(struct sockaddr_in6));",
          "",
          "[Removed Lines]",
          "626:     if (force == AF_INET6 || (force == AF_UNSPEC && Ip::EnableIpv6 && isIPv6()) ) {",
          "",
          "[Added Lines]",
          "626:     if (force == AF_INET6 || (force == AF_UNSPEC && isIPv6()) ) {",
          "",
          "---------------"
        ],
        "src/ip/Intercept.cc||src/ip/Intercept.cc": [
          "File: src/ip/Intercept.cc -> src/ip/Intercept.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "15: #include \"comm/Connection.h\"",
          "16: #include \"fde.h\"",
          "17: #include \"ip/Intercept.h\"",
          "18: #include \"src/tools.h\"",
          "20: #include <cerrno>",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: #include \"ip/tools.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "417:     debugs(3, 3, \"Detect TPROXY support on port \" << test);",
          "419:     int tos = 1;",
          "420:     int tmp_sock = -1;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "420:     if (!Ip::EnableIpv6 && test.isIPv6() && !test.setIPv4()) {",
          "421:         debugs(3, DBG_CRITICAL, \"Cannot use TPROXY for \" << test << \" because IPv6 support is disabled\");",
          "422:         if (doneSuid)",
          "423:             leave_suid();",
          "424:         return false;",
          "425:     }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "7e8eec79880cc207ba61b662eb8b93081101b62c",
      "candidate_info": {
        "commit_hash": "7e8eec79880cc207ba61b662eb8b93081101b62c",
        "repo": "squid-cache/squid",
        "commit_url": "https://github.com/squid-cache/squid/commit/7e8eec79880cc207ba61b662eb8b93081101b62c",
        "files": [
          "src/cache_manager.cc"
        ],
        "message": "Do not update StoreEntry expiration after errorAppendEntry() (#1580)\n\nerrorAppendEntry() is responsible for setting entry expiration times,\nwhich it does by calling StoreEntry::storeErrorResponse() that calls\nStoreEntry::negativeCache().\n\nThis change was triggered by a vulnerability report by Joshua Rogers at\nhttps://megamansec.github.io/Squid-Security-Audit/cache-uaf.html where\nit was filed as \"Use-After-Free in Cache Manager Errors\". The reported\n\"use after free\" vulnerability was unknowingly addressed by 2022 commit\n1fa761a that removed excessively long \"reentrant\" store_client calls\nresponsible for the disappearance of the properly locked StoreEntry in\nthis (and probably other) contexts.",
        "before_after_code_files": [
          "src/cache_manager.cc||src/cache_manager.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/squid-cache/squid/pull/1601"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "src/cache_manager.cc||src/cache_manager.cc": [
          "File: src/cache_manager.cc -> src/cache_manager.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "332:         err->url = xstrdup(entry->url());",
          "333:         err->detailError(new ExceptionErrorDetail(Here().id()));",
          "334:         errorAppendEntry(entry, err);",
          "336:         return;",
          "337:     }",
          "",
          "[Removed Lines]",
          "335:         entry->expires = squid_curtime;",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ]
      }
    }
  ]
}