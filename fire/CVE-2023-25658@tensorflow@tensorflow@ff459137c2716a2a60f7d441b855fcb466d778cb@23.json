{
  "cve_id": "CVE-2023-25658",
  "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.12.0 and 2.11.1, an out of bounds read is in GRUBlockCellGrad. A fix is included in TensorFlow 2.12.0 and 2.11.1.\n",
  "repo": "tensorflow/tensorflow",
  "patch_hash": "ff459137c2716a2a60f7d441b855fcb466d778cb",
  "patch_info": {
    "commit_hash": "ff459137c2716a2a60f7d441b855fcb466d778cb",
    "repo": "tensorflow/tensorflow",
    "commit_url": "https://github.com/tensorflow/tensorflow/commit/ff459137c2716a2a60f7d441b855fcb466d778cb",
    "files": [
      ".bazelrc",
      "tensorflow/compiler/jit/BUILD",
      "tensorflow/compiler/xla/backends/interpreter/BUILD",
      "tensorflow/compiler/xla/backends/interpreter/platform.cc",
      "tensorflow/compiler/xla/hlo/evaluator/hlo_evaluator.cc",
      "tensorflow/compiler/xla/mlir/tools/mlir_replay/BUILD",
      "tensorflow/compiler/xla/service/hlo_graph_dumper.cc",
      "tensorflow/compiler/xla/stream_executor/BUILD",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_platform.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_rng.cc",
      "tensorflow/compiler/xla/stream_executor/host/BUILD",
      "tensorflow/compiler/xla/stream_executor/host/host_gpu_executor.h",
      "tensorflow/compiler/xla/stream_executor/host/host_platform.cc",
      "tensorflow/compiler/xla/stream_executor/lib/BUILD",
      "tensorflow/compiler/xla/stream_executor/lib/error.h",
      "tensorflow/compiler/xla/stream_executor/lib/initialize.h",
      "tensorflow/compiler/xla/stream_executor/multi_platform_manager.cc",
      "tensorflow/compiler/xla/stream_executor/multi_platform_manager.h",
      "tensorflow/compiler/xla/stream_executor/platform.cc",
      "tensorflow/compiler/xla/stream_executor/plugin_registry.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_blas.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_diagnostics.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_dnn.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_driver.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_fft.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_gpu_executor.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_platform.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_rng.cc",
      "tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.cc",
      "tensorflow/compiler/xla/stream_executor/tf_allocator_adapter.cc",
      "tensorflow/core/common_runtime/function.cc",
      "tensorflow/core/data/BUILD",
      "tensorflow/core/data/service/server_lib.cc",
      "tensorflow/core/data/service/server_lib.h",
      "tensorflow/core/data/service/snapshot/BUILD",
      "tensorflow/core/data/service/snapshot/path_utils.cc",
      "tensorflow/core/data/service/snapshot/path_utils.h",
      "tensorflow/core/data/service/snapshot/path_utils_test.cc",
      "tensorflow/core/data/service/snapshot/snapshot_manager.cc",
      "tensorflow/core/data/tfdataz_metrics.cc",
      "tensorflow/core/data/tfdataz_metrics.h",
      "tensorflow/core/data/tfdataz_metrics_test.cc",
      "tensorflow/core/distributed_runtime/eager/remote_mgr.cc",
      "tensorflow/core/distributed_runtime/integration_test/coordination_test_opkernel_registration.cc",
      "tensorflow/core/framework/dataset.h",
      "tensorflow/core/framework/op_requires.h",
      "tensorflow/core/kernels/data/iterator_ops.cc",
      "tensorflow/core/kernels/function_ops.cc",
      "tensorflow/core/kernels/functional_ops.cc",
      "tensorflow/core/kernels/rnn/gru_ops.cc",
      "tensorflow/core/lib/core/status_test.cc",
      "tensorflow/core/platform/error_payloads.cc",
      "tensorflow/core/tpu/kernels/tpu_compile_op_common.cc",
      "tensorflow/core/tpu/kernels/tpu_functional_ops.cc",
      "tensorflow/core/tpu/tpu_embedding_errors.cc",
      "tensorflow/core/tpu/tpu_embedding_errors.h",
      "tensorflow/core/util/zen_util.h",
      "tensorflow/lite/delegates/xnnpack/README.md",
      "tensorflow/python/data/experimental/kernel_tests/service/snapshot_ft_test.py",
      "tensorflow/python/framework/BUILD",
      "tensorflow/python/framework/errors_test_helper.cc",
      "tensorflow/python/tpu/tpu_strategy_util.py",
      "tensorflow/tools/ci_build/release/requirements_common.txt",
      "tensorflow/tools/ci_build/release/requirements_mac.txt",
      "tensorflow/tools/tf_sig_build_dockerfiles/devel.requirements.txt",
      "tensorflow/tsl/c/tsl_status.cc",
      "tensorflow/tsl/c/tsl_status_helper_test.cc",
      "tensorflow/tsl/distributed_runtime/coordination/coordination_service_error_util.h",
      "tensorflow/tsl/distributed_runtime/rpc/grpc_util.h",
      "tensorflow/tsl/distributed_runtime/rpc/grpc_util_test.cc",
      "tensorflow/tsl/platform/errors.h",
      "tensorflow/tsl/platform/test.h",
      "tensorflow/tsl/profiler/lib/BUILD",
      "tensorflow/tsl/profiler/lib/traceme_encode.h",
      "tensorflow/tsl/profiler/lib/traceme_encode_test.cc",
      "third_party/tf_runtime/workspace.bzl"
    ],
    "message": "Merged commit includes the following changes: 504684855  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Remove legacy references from `ops.py`.\n\n    This is done to eventually remove the lazy loads in `indexed_slices.py`.\n\n--\n504682660  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Add missing reference symbol.\n\n--\n504682467  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    #tf-data-service Add a function to parse split file names.\n\n--\n504680829  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Update XNNPACK README to document feature parity for FP16 operators\n\n--\n504677404  by A. Unique TensorFlower<gardener@tensorflow.org>:\n    Automated rollback of changelist 504103068.\n\n504676634  by A. Unique TensorFlower<gardener@tensorflow.org>:\n    Automated rollback of changelist 504656381.\n\n504672100  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Delete compiler/xla/stream_executor/lib/initialize.h, update users to depend on stream_executor/platform/intialize.h directly\n\n--\n504669543  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Refactor transforms to make buildozer object injectable.\n\n--\n504667726  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Update all CI dependencies to non vulnerable versions.\n\n    This MUST land before branch cut.\n\n--\n504661218  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Update TFRT dependency to use revision\n    http://github.com/tensorflow/runtime/commit/c653281a1a23c0c3d41536a983c7d10fcc5b1fbf.\n\n--\n504660212  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Change TraceMeArg to keep a reference to an AlphaNum constructed on the stack rather than constructing it by value.\n\n    The eliminates a lifetime safety bug where AlphaNum uses a default constructed argument as a string buffer that was a dangling reference before.\n\n    Also add a LIFETIME_BOUND attribute to ensure this is used correctly.\n\n--\n504660069  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Add kIsOpenSource to tsl/platform/test.h\n\n--\n504659330  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Update usages of tensorflow::Status::SetPayload.\n\n--\n504656381  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Remove the scrubbing of constants in tpu_cluster_formation.\n\n    Instead, just ignore tf.Const attributes, in CollectAndGroupClusterOps. This\n    is functionally equivalent (for this pass), but a bit more clean since it\n    doesn't leave modified tf.Const ops behind.\n\n--\n504654874  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Add missing dependency for the Mac build.\n\n--\n504653641  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Internal visibility change\n\n--\n504648821  by A. Unique TensorFlower<gardener@tensorflow.org>:\n    Automated rollback of changelist 504006190.\nBEGIN_PUBLIC\nRollback of PR #59418: [aarch64] enable acl linking for cpu xla for mkl_aarch64_threadpool config\nReason: The configuration is still not very well-tested.\nEND_PUBLIC\n\n504645490  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Fix input validation for GRU ops.\n\n--\n504633571  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    [SE] Replace uses of stream_executor::port::error with tsl::error.\n\n    This lets us remove stream_executor/lib/error.h!\n\n    No functional change; these are aliases of one another.\n\n--\n504633188  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Update tf.tpu.experimental.initialize_tpu_system to disable running on eager mode.\n\n--\n504618714  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    [XLA:GPU] Update hlo graph dumper to additionally dump the gemm epilogue from the GemmBackendConfig\n\n--\n504618661  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Fix ODR violation from zen_util.h\n\n--\n504616623  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    [tf.data] Collect the iterator's memory usage metrics for /tfdataz page.\n\n--\n504612989  by A. Unique TensorFlower<gardener@tensorflow.org>:\n\n    Internal change\n\nPiperOrigin-RevId: 504684855",
    "before_after_code_files": [
      "tensorflow/compiler/xla/backends/interpreter/platform.cc||tensorflow/compiler/xla/backends/interpreter/platform.cc",
      "tensorflow/compiler/xla/hlo/evaluator/hlo_evaluator.cc||tensorflow/compiler/xla/hlo/evaluator/hlo_evaluator.cc",
      "tensorflow/compiler/xla/service/hlo_graph_dumper.cc||tensorflow/compiler/xla/service/hlo_graph_dumper.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_platform.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_platform.cc",
      "tensorflow/compiler/xla/stream_executor/cuda/cuda_rng.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_rng.cc",
      "tensorflow/compiler/xla/stream_executor/host/host_gpu_executor.h||tensorflow/compiler/xla/stream_executor/host/host_gpu_executor.h",
      "tensorflow/compiler/xla/stream_executor/host/host_platform.cc||tensorflow/compiler/xla/stream_executor/host/host_platform.cc",
      "tensorflow/compiler/xla/stream_executor/lib/error.h||tensorflow/compiler/xla/stream_executor/lib/error.h",
      "tensorflow/compiler/xla/stream_executor/lib/initialize.h||tensorflow/compiler/xla/stream_executor/lib/initialize.h",
      "tensorflow/compiler/xla/stream_executor/multi_platform_manager.cc||tensorflow/compiler/xla/stream_executor/multi_platform_manager.cc",
      "tensorflow/compiler/xla/stream_executor/multi_platform_manager.h||tensorflow/compiler/xla/stream_executor/multi_platform_manager.h",
      "tensorflow/compiler/xla/stream_executor/platform.cc||tensorflow/compiler/xla/stream_executor/platform.cc",
      "tensorflow/compiler/xla/stream_executor/plugin_registry.cc||tensorflow/compiler/xla/stream_executor/plugin_registry.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_blas.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_blas.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_diagnostics.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_diagnostics.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_dnn.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_dnn.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_driver.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_driver.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_fft.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_fft.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_gpu_executor.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_gpu_executor.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_platform.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_platform.cc",
      "tensorflow/compiler/xla/stream_executor/rocm/rocm_rng.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_rng.cc",
      "tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.cc||tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.cc",
      "tensorflow/compiler/xla/stream_executor/tf_allocator_adapter.cc||tensorflow/compiler/xla/stream_executor/tf_allocator_adapter.cc",
      "tensorflow/core/common_runtime/function.cc||tensorflow/core/common_runtime/function.cc",
      "tensorflow/core/data/service/server_lib.cc||tensorflow/core/data/service/server_lib.cc",
      "tensorflow/core/data/service/server_lib.h||tensorflow/core/data/service/server_lib.h",
      "tensorflow/core/data/service/snapshot/path_utils.cc||tensorflow/core/data/service/snapshot/path_utils.cc",
      "tensorflow/core/data/service/snapshot/path_utils.h||tensorflow/core/data/service/snapshot/path_utils.h",
      "tensorflow/core/data/service/snapshot/path_utils_test.cc||tensorflow/core/data/service/snapshot/path_utils_test.cc",
      "tensorflow/core/data/service/snapshot/snapshot_manager.cc||tensorflow/core/data/service/snapshot/snapshot_manager.cc",
      "tensorflow/core/data/tfdataz_metrics.cc||tensorflow/core/data/tfdataz_metrics.cc",
      "tensorflow/core/data/tfdataz_metrics.h||tensorflow/core/data/tfdataz_metrics.h",
      "tensorflow/core/data/tfdataz_metrics_test.cc||tensorflow/core/data/tfdataz_metrics_test.cc",
      "tensorflow/core/distributed_runtime/eager/remote_mgr.cc||tensorflow/core/distributed_runtime/eager/remote_mgr.cc",
      "tensorflow/core/distributed_runtime/integration_test/coordination_test_opkernel_registration.cc||tensorflow/core/distributed_runtime/integration_test/coordination_test_opkernel_registration.cc",
      "tensorflow/core/framework/dataset.h||tensorflow/core/framework/dataset.h",
      "tensorflow/core/framework/op_requires.h||tensorflow/core/framework/op_requires.h",
      "tensorflow/core/kernels/data/iterator_ops.cc||tensorflow/core/kernels/data/iterator_ops.cc",
      "tensorflow/core/kernels/function_ops.cc||tensorflow/core/kernels/function_ops.cc",
      "tensorflow/core/kernels/functional_ops.cc||tensorflow/core/kernels/functional_ops.cc",
      "tensorflow/core/kernels/rnn/gru_ops.cc||tensorflow/core/kernels/rnn/gru_ops.cc",
      "tensorflow/core/lib/core/status_test.cc||tensorflow/core/lib/core/status_test.cc",
      "tensorflow/core/platform/error_payloads.cc||tensorflow/core/platform/error_payloads.cc",
      "tensorflow/core/tpu/kernels/tpu_compile_op_common.cc||tensorflow/core/tpu/kernels/tpu_compile_op_common.cc",
      "tensorflow/core/tpu/kernels/tpu_functional_ops.cc||tensorflow/core/tpu/kernels/tpu_functional_ops.cc",
      "tensorflow/core/tpu/tpu_embedding_errors.cc||tensorflow/core/tpu/tpu_embedding_errors.cc",
      "tensorflow/core/tpu/tpu_embedding_errors.h||tensorflow/core/tpu/tpu_embedding_errors.h",
      "tensorflow/core/util/zen_util.h||tensorflow/core/util/zen_util.h",
      "tensorflow/python/data/experimental/kernel_tests/service/snapshot_ft_test.py||tensorflow/python/data/experimental/kernel_tests/service/snapshot_ft_test.py",
      "tensorflow/python/framework/errors_test_helper.cc||tensorflow/python/framework/errors_test_helper.cc",
      "tensorflow/python/tpu/tpu_strategy_util.py||tensorflow/python/tpu/tpu_strategy_util.py",
      "tensorflow/tsl/c/tsl_status.cc||tensorflow/tsl/c/tsl_status.cc",
      "tensorflow/tsl/c/tsl_status_helper_test.cc||tensorflow/tsl/c/tsl_status_helper_test.cc",
      "tensorflow/tsl/distributed_runtime/coordination/coordination_service_error_util.h||tensorflow/tsl/distributed_runtime/coordination/coordination_service_error_util.h",
      "tensorflow/tsl/distributed_runtime/rpc/grpc_util.h||tensorflow/tsl/distributed_runtime/rpc/grpc_util.h",
      "tensorflow/tsl/distributed_runtime/rpc/grpc_util_test.cc||tensorflow/tsl/distributed_runtime/rpc/grpc_util_test.cc",
      "tensorflow/tsl/platform/errors.h||tensorflow/tsl/platform/errors.h",
      "tensorflow/tsl/platform/test.h||tensorflow/tsl/platform/test.h",
      "tensorflow/tsl/profiler/lib/traceme_encode.h||tensorflow/tsl/profiler/lib/traceme_encode.h",
      "tensorflow/tsl/profiler/lib/traceme_encode_test.cc||tensorflow/tsl/profiler/lib/traceme_encode_test.cc",
      "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl"
    ]
  },
  "patch_diff": {
    "tensorflow/compiler/xla/backends/interpreter/platform.cc||tensorflow/compiler/xla/backends/interpreter/platform.cc": [
      "File: tensorflow/compiler/xla/backends/interpreter/platform.cc -> tensorflow/compiler/xla/backends/interpreter/platform.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "21: #include \"absl/strings/str_format.h\"",
      "22: #include \"tensorflow/compiler/xla/backends/interpreter/executor.h\"",
      "23: #include \"tensorflow/compiler/xla/stream_executor/device_options.h\"",
      "25: #include \"tensorflow/compiler/xla/stream_executor/multi_platform_manager.h\"",
      "26: #include \"tensorflow/compiler/xla/stream_executor/platform.h\"",
      "27: #include \"tensorflow/tsl/platform/status.h\"",
      "29: namespace stream_executor {",
      "",
      "[Removed Lines]",
      "24: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "26: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/hlo/evaluator/hlo_evaluator.cc||tensorflow/compiler/xla/hlo/evaluator/hlo_evaluator.cc": [
      "File: tensorflow/compiler/xla/hlo/evaluator/hlo_evaluator.cc -> tensorflow/compiler/xla/hlo/evaluator/hlo_evaluator.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "222:   absl::little_endian::Store32(",
      "223:       const_cast<char*>(error_payload.data()),",
      "224:       static_cast<uint32_t>(EvalErrorDetail::kDynamicValueDependence));",
      "226:   return error;",
      "227: }",
      "",
      "[Removed Lines]",
      "225:   error.SetPayload(kEvalErrorDetailUrl, error_payload);",
      "",
      "[Added Lines]",
      "225:   error.SetPayload(kEvalErrorDetailUrl, absl::Cord(error_payload));",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/service/hlo_graph_dumper.cc||tensorflow/compiler/xla/service/hlo_graph_dumper.cc": [
      "File: tensorflow/compiler/xla/service/hlo_graph_dumper.cc -> tensorflow/compiler/xla/service/hlo_graph_dumper.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "1251:   if (config.algorithm_case() == gpu::GemmBackendConfig::kSelectedAlgorithm) {",
      "1252:     props.emplace_back(\"algorithm\", StrCat(config.selected_algorithm()));",
      "1253:   }",
      "1254:   return props;",
      "1255: }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "1254:   if (config.epilogue() != gpu::GemmBackendConfig::DEFAULT) {",
      "1255:     props.emplace_back(",
      "1256:         \"epilogue\", gpu::GemmBackendConfig::Epilogue_Name(config.epilogue()));",
      "1257:   }",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc": [
      "File: tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc -> tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "63: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_stream.h\"",
      "64: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_timer.h\"",
      "65: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_types.h\"",
      "67: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "68: #include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"",
      "69: #include \"tensorflow/compiler/xla/stream_executor/plugin_registry.h\"",
      "",
      "[Removed Lines]",
      "66: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "66: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc": [
      "File: tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc -> tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "36: #include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_stream.h\"",
      "37: #include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_timer.h\"",
      "38: #include \"tensorflow/compiler/xla/stream_executor/dnn.h\"",
      "41: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "42: #include \"tensorflow/compiler/xla/stream_executor/plugin_registry.h\"",
      "43: #include \"tensorflow/compiler/xla/stream_executor/scratch_allocator.h\"",
      "",
      "[Removed Lines]",
      "39: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "40: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "39: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "85:       std::ostringstream oss;                                           \\",
      "86:       oss << CudnnStatusToString(_status) << \"\\nin \" << __FILE__ << \"(\" \\",
      "87:           << __LINE__ << \"): '\" << #expr << \"'\";                        \\",
      "89:     }                                                                   \\",
      "90:   } while (false)",
      "",
      "[Removed Lines]",
      "88:       return tsl::Status(port::error::UNKNOWN, oss.str());              \\",
      "",
      "[Added Lines]",
      "87:       return tsl::Status(tsl::error::UNKNOWN, oss.str());               \\",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "96:       std::ostringstream oss;                                           \\",
      "97:       oss << CudnnStatusToString(_status) << \"\\nin \" << __FILE__ << \"(\" \\",
      "98:           << __LINE__ << \"): '\" << #expr << \"' \" << (expr).get_error(); \\",
      "100:     }                                                                   \\",
      "101:   } while (false)",
      "",
      "[Removed Lines]",
      "99:       return tsl::Status(port::error::UNKNOWN, oss.str());              \\",
      "",
      "[Added Lines]",
      "98:       return tsl::Status(tsl::error::UNKNOWN, oss.str());               \\",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "417:           \"configuration.\");",
      "418:       LOG(ERROR) << error;",
      "419:       cudnnDestroy(cudnn_handle);",
      "421:     }",
      "423:     cudnn_.reset(new CudnnAccess(cudnn_handle));",
      "",
      "[Removed Lines]",
      "420:       return tsl::Status(port::error::INTERNAL, error);",
      "",
      "[Added Lines]",
      "419:       return tsl::Status(tsl::error::INTERNAL, error);",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "441:     }",
      "442:   }",
      "445:                      absl::StrCat(\"cudnn library could not create a handle: \",",
      "446:                                   CudnnStatusToString(status)));",
      "447: }",
      "",
      "[Removed Lines]",
      "444:   return tsl::Status(port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "443:   return tsl::Status(tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "1299:             ? algorithm_config.algorithm()->tensor_ops_enabled()",
      "1300:             : allow_tensor_ops;",
      "1301:     if (use_tensor_ops && !allow_tensor_ops) {",
      "1303:                          \"Algo requests disallowed tensor op evaluation.\");",
      "1304:     }",
      "",
      "[Removed Lines]",
      "1302:       return tsl::Status(port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "1301:       return tsl::Status(tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 7 ---",
      "[Context before]",
      "1658:       GpuExecutor* parent, int max_seq_length, int batch_size, int data_size,",
      "1659:       cudnnDataType_t data_type) {",
      "1660:     if (max_seq_length <= 0) {",
      "1662:     }",
      "1663:     int dims[] = {batch_size, data_size, 1};",
      "1664:     int strides[] = {dims[1] * dims[2], dims[2], 1};",
      "",
      "[Removed Lines]",
      "1661:       return tsl::Status(port::error::INVALID_ARGUMENT, \"max_seq_length <= 0\");",
      "",
      "[Added Lines]",
      "1660:       return tsl::Status(tsl::error::INVALID_ARGUMENT, \"max_seq_length <= 0\");",
      "",
      "---------------",
      "--- Hunk 8 ---",
      "[Context before]",
      "1677:       const absl::Span<const int>& seq_lengths, bool time_major,",
      "1678:       cudnnDataType_t data_type) {",
      "1679:     if (max_seq_length <= 0) {",
      "1681:     }",
      "1682:     int dims[] = {batch_size, data_size, 1};",
      "1683:     int strides[] = {dims[1] * dims[2], dims[2], 1};",
      "",
      "[Removed Lines]",
      "1680:       return tsl::Status(port::error::INVALID_ARGUMENT, \"max_seq_length <= 0\");",
      "",
      "[Added Lines]",
      "1679:       return tsl::Status(tsl::error::INVALID_ARGUMENT, \"max_seq_length <= 0\");",
      "",
      "---------------",
      "--- Hunk 9 ---",
      "[Context before]",
      "1804:             model_dims.num_layers * model_dims.dir_count &&",
      "1805:         input_h_desc.batch_size() == model_dims.batch_size &&",
      "1806:         input_h_desc.data_size() == model_dims.hidden_size)) {",
      "1808:   }",
      "1811:   if (!(input_h_desc.num_layers() == input_c_desc.num_layers() &&",
      "1812:         input_h_desc.batch_size() == input_c_desc.batch_size() &&",
      "1813:         input_h_desc.data_size() <= input_c_desc.data_size())) {",
      "1815:   }",
      "1816:   if (!(output_desc.max_seq_length() == model_dims.max_seq_length &&",
      "1817:         output_desc.batch_size() == model_dims.batch_size &&",
      "1818:         output_desc.data_size() ==",
      "1819:             model_dims.hidden_size * model_dims.dir_count)) {",
      "1821:   }",
      "1822:   if (!(input_h_desc.num_layers() == output_h_desc.num_layers() &&",
      "1823:         input_h_desc.batch_size() == output_h_desc.batch_size() &&",
      "1824:         input_h_desc.data_size() == output_h_desc.data_size())) {",
      "1826:   }",
      "1827:   if (!(input_h_desc.num_layers() == output_c_desc.num_layers() &&",
      "1828:         input_h_desc.batch_size() == output_c_desc.batch_size() &&",
      "1829:         input_h_desc.data_size() <= output_c_desc.data_size())) {",
      "1831:   }",
      "1833:   return model_dims;",
      "",
      "[Removed Lines]",
      "1807:     return tsl::Status(port::error::INVALID_ARGUMENT, \"Invalid input_h shape\");",
      "1814:     return tsl::Status(port::error::INVALID_ARGUMENT, \"Invalid input_c shape\");",
      "1820:     return tsl::Status(port::error::INVALID_ARGUMENT, \"Invalid output shape\");",
      "1825:     return tsl::Status(port::error::INVALID_ARGUMENT, \"Invalid output_h shape\");",
      "1830:     return tsl::Status(port::error::INVALID_ARGUMENT, \"Invalid output_c shape\");",
      "",
      "[Added Lines]",
      "1806:     return tsl::Status(tsl::error::INVALID_ARGUMENT, \"Invalid input_h shape\");",
      "1813:     return tsl::Status(tsl::error::INVALID_ARGUMENT, \"Invalid input_c shape\");",
      "1819:     return tsl::Status(tsl::error::INVALID_ARGUMENT, \"Invalid output shape\");",
      "1824:     return tsl::Status(tsl::error::INVALID_ARGUMENT, \"Invalid output_h shape\");",
      "1829:     return tsl::Status(tsl::error::INVALID_ARGUMENT, \"Invalid output_c shape\");",
      "",
      "---------------",
      "--- Hunk 10 ---",
      "[Context before]",
      "1849: #endif",
      "1850:   if (static_cast<int64_t>(params_size_in_bytes) !=",
      "1851:       rnn_desc.ParamsSizeInBytes()) {",
      "1853:                        \"Mismatching RNN parameter size\");",
      "1854:   }",
      "1855:   return ::tsl::OkStatus();",
      "",
      "[Removed Lines]",
      "1852:     return tsl::Status(port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "1851:     return tsl::Status(tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 11 ---",
      "[Context before]",
      "1999:       if (!timer->Init() || !timer->Start(AsGpuStream(stream))) {",
      "2001:       }",
      "2002:     }",
      "",
      "[Removed Lines]",
      "2000:         return tsl::Status(port::error::INTERNAL, \"Failed to start timer\");",
      "",
      "[Added Lines]",
      "1999:         return tsl::Status(tsl::error::INTERNAL, \"Failed to start timer\");",
      "",
      "---------------",
      "--- Hunk 12 ---",
      "[Context before]",
      "2021:     if (is_profiling) {",
      "2022:       if (!timer->Stop(AsGpuStream(stream))) {",
      "2024:       }",
      "2025:       auto algo_desc = *rnn_desc.algorithm_config().algorithm();",
      "2026:       output_profile_result->set_algorithm(algo_desc);",
      "",
      "[Removed Lines]",
      "2023:         return tsl::Status(port::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "[Added Lines]",
      "2022:         return tsl::Status(tsl::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "---------------",
      "--- Hunk 13 ---",
      "[Context before]",
      "2060:     if (!timer->Init() || !timer->Start(AsGpuStream(stream))) {",
      "2062:     }",
      "2063:   }",
      "",
      "[Removed Lines]",
      "2061:       return tsl::Status(port::error::INTERNAL, \"Failed to start timer\");",
      "",
      "[Added Lines]",
      "2060:       return tsl::Status(tsl::error::INTERNAL, \"Failed to start timer\");",
      "",
      "---------------",
      "--- Hunk 14 ---",
      "[Context before]",
      "2131:   if (is_profiling) {",
      "2132:     if (!timer->Stop(AsGpuStream(stream))) {",
      "2134:     }",
      "2135:     auto algo_desc = *rnn_desc.algorithm_config().algorithm();",
      "2136:     output_profile_result->set_algorithm(algo_desc);",
      "",
      "[Removed Lines]",
      "2133:       return tsl::Status(port::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "[Added Lines]",
      "2132:       return tsl::Status(tsl::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "---------------",
      "--- Hunk 15 ---",
      "[Context before]",
      "2206:       if (!timer->Init() || !timer->Start(AsGpuStream(stream))) {",
      "2208:       }",
      "2209:     }",
      "",
      "[Removed Lines]",
      "2207:         return tsl::Status(port::error::INTERNAL, \"Failed to start timer\");",
      "",
      "[Added Lines]",
      "2206:         return tsl::Status(tsl::error::INTERNAL, \"Failed to start timer\");",
      "",
      "---------------",
      "--- Hunk 16 ---",
      "[Context before]",
      "2254:     if (is_profiling) {",
      "2255:       if (!timer->Stop(AsGpuStream(stream))) {",
      "2257:       }",
      "2258:       auto algo_desc = *rnn_desc.algorithm_config().algorithm();",
      "2259:       output_profile_result->set_algorithm(algo_desc);",
      "",
      "[Removed Lines]",
      "2256:         return tsl::Status(port::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "[Added Lines]",
      "2255:         return tsl::Status(tsl::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "---------------",
      "--- Hunk 17 ---",
      "[Context before]",
      "2277:     if (!timer->Init() || !timer->Start(AsGpuStream(stream))) {",
      "2279:     }",
      "2280:   }",
      "",
      "[Removed Lines]",
      "2278:       return tsl::Status(port::error::INTERNAL, \"Failed to start timer\");",
      "",
      "[Added Lines]",
      "2277:       return tsl::Status(tsl::error::INTERNAL, \"Failed to start timer\");",
      "",
      "---------------",
      "--- Hunk 18 ---",
      "[Context before]",
      "2363:   if (is_profiling) {",
      "2364:     if (!timer->Stop(AsGpuStream(stream))) {",
      "2366:     }",
      "2367:     auto algo_desc = *rnn_desc.algorithm_config().algorithm();",
      "2368:     output_profile_result->set_algorithm(algo_desc);",
      "",
      "[Removed Lines]",
      "2365:       return tsl::Status(port::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "[Added Lines]",
      "2364:       return tsl::Status(tsl::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "---------------",
      "--- Hunk 19 ---",
      "[Context before]",
      "2406: #else",
      "2408:                      \"No supported cudnnCTCLoss when \"",
      "2409:                      \"CUDNN_VERSION < 7.6.3\");",
      "2410: #endif",
      "",
      "[Removed Lines]",
      "2407:   return tsl::Status(port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "2406:   return tsl::Status(tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 20 ---",
      "[Context before]",
      "2786:       return perf_results[r].algo;",
      "2787:     }",
      "2788:   }",
      "2790:                      \"cudnnGetConvolutionForwardAlgorithm_v7 returned \"",
      "2791:                      \"no suitable algorithms. This could be a cudnn bug.\");",
      "2792: #else",
      "",
      "[Removed Lines]",
      "2789:   return tsl::Status(port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "2788:   return tsl::Status(tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 21 ---",
      "[Context before]",
      "2828:       return perf_results[r].algo;",
      "2829:     }",
      "2830:   }",
      "2832:                      \"cudnnGetConvolutionBackwardDataAlgorithm_v7 returned \"",
      "2833:                      \"no suitable algorithms. This could be a cudnn bug.\");",
      "2834: #else",
      "",
      "[Removed Lines]",
      "2831:   return tsl::Status(port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "2830:   return tsl::Status(tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 22 ---",
      "[Context before]",
      "2870:       return perf_results[r].algo;",
      "2871:     }",
      "2872:   }",
      "2874:                      \"cudnnGetConvolutionBackwardFilterAlgorithm_v7 returned \"",
      "2875:                      \"no suitable algorithms. This could be a cudnn bug.\");",
      "2876: #else",
      "",
      "[Removed Lines]",
      "2873:   return tsl::Status(port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "2872:   return tsl::Status(tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 23 ---",
      "[Context before]",
      "2895:     ScratchAllocator* scratch_allocator) {",
      "2896:   if (IsTensorMathOpSet(conv) != algorithm_desc.tensor_ops_enabled()) {",
      "2897:     return tsl::Status(",
      "2899:         \"Mismatch between cudnn conv and algorithm descriptors.\");",
      "2900:   }",
      "",
      "[Removed Lines]",
      "2898:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "2897:         tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 24 ---",
      "[Context before]",
      "2918:   if (ABSL_PREDICT_FALSE(size_in_bytes_int64_t < 0)) {",
      "2919:     return tsl::Status(",
      "2921:         \"cudnnGetConvolutionForwardWorkspaceSize() returned \"",
      "2922:         \"negative sizeInBytes value. This could be a cudnn bug.\");",
      "2923:   }",
      "",
      "[Removed Lines]",
      "2920:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "2919:         tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 25 ---",
      "[Context before]",
      "2927:   }",
      "2929:   if (ABSL_PREDICT_FALSE(!scratch_allocator)) {",
      "2931:                        \"No scratch allocator provided\");",
      "2932:   }",
      "",
      "[Removed Lines]",
      "2930:     return tsl::Status(port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "2929:     return tsl::Status(tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 26 ---",
      "[Context before]",
      "2944:     ScratchAllocator* scratch_allocator) {",
      "2945:   if (IsTensorMathOpSet(conv) != algorithm_desc.tensor_ops_enabled()) {",
      "2946:     return tsl::Status(",
      "2948:         \"Mismatch between cudnn conv and algorithm descriptors.\");",
      "2949:   }",
      "",
      "[Removed Lines]",
      "2947:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "2946:         tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 27 ---",
      "[Context before]",
      "2968:   if (ABSL_PREDICT_FALSE(size_in_bytes_int64_t < 0)) {",
      "2969:     return tsl::Status(",
      "2971:         \"cudnnGetConvolutionBackwardDataWorkspaceSize() returned \"",
      "2972:         \"negative sizeInBytes value. This could be a cudnn bug.\");",
      "2973:   }",
      "",
      "[Removed Lines]",
      "2970:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "2969:         tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 28 ---",
      "[Context before]",
      "2977:   }",
      "2979:   if (ABSL_PREDICT_FALSE(!scratch_allocator)) {",
      "2981:                        \"No scratch allocator provided\");",
      "2982:   }",
      "",
      "[Removed Lines]",
      "2980:     return tsl::Status(port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "2979:     return tsl::Status(tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 29 ---",
      "[Context before]",
      "2994:     ScratchAllocator* scratch_allocator) {",
      "2995:   if (IsTensorMathOpSet(conv) != algorithm_desc.tensor_ops_enabled()) {",
      "2996:     return tsl::Status(",
      "2998:         \"Mismatch between cudnn conv and algorithm descriptors.\");",
      "2999:   }",
      "",
      "[Removed Lines]",
      "2997:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "2996:         tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 30 ---",
      "[Context before]",
      "3018:   if (ABSL_PREDICT_FALSE(size_in_bytes_int64_t < 0)) {",
      "3019:     return tsl::Status(",
      "3021:         \"cudnnGetConvolutionBackwardFilterWorkspaceSize() returned \"",
      "3022:         \"negative sizeInBytes value. This could be a cudnn bug.\");",
      "3023:   }",
      "",
      "[Removed Lines]",
      "3020:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "3019:         tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 31 ---",
      "[Context before]",
      "3027:   }",
      "3029:   if (ABSL_PREDICT_FALSE(!scratch_allocator)) {",
      "3031:                        \"No scratch allocator provided\");",
      "3032:   }",
      "",
      "[Removed Lines]",
      "3030:     return tsl::Status(port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "3029:     return tsl::Status(tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 32 ---",
      "[Context before]",
      "3040:   if (desc.has_value()) {",
      "3041:     use_tensor_ops = desc->tensor_ops_enabled();",
      "3042:     if (use_tensor_ops && !IsTensorMathEnabled(stream, type)) {",
      "3044:                          \"Algo requests disabled tensor op evaluation.\");",
      "3045:     }",
      "3046:   } else {",
      "",
      "[Removed Lines]",
      "3043:       return tsl::Status(port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "3042:       return tsl::Status(tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 33 ---",
      "[Context before]",
      "3163:   if (!algo_desc.has_value()) {",
      "3164:     return tsl::Status(",
      "3166:         \"The primary convolution algorithm failed memory allocation, \"",
      "3167:         \"while a secondary algorithm is not provided.\");",
      "3168:   }",
      "",
      "[Removed Lines]",
      "3165:         port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "3164:         tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 34 ---",
      "[Context before]",
      "3225:   if (!algo_desc.has_value()) {",
      "3226:     return tsl::Status(",
      "3228:         absl::StrCat(",
      "3229:             \"The primary convolution algorithm failed memory allocation, \"",
      "3230:             \"while a secondary algorithm is not provided. Actual error: \",",
      "",
      "[Removed Lines]",
      "3227:         port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "3226:         tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 35 ---",
      "[Context before]",
      "4256:       if (!timer->Init() || !timer->Start(AsGpuStream(stream))) {",
      "4258:       }",
      "4259:     }",
      "",
      "[Removed Lines]",
      "4257:         return tsl::Status(port::error::INTERNAL, \"Failed to start timer\");",
      "",
      "[Added Lines]",
      "4256:         return tsl::Status(tsl::error::INTERNAL, \"Failed to start timer\");",
      "",
      "---------------",
      "--- Hunk 36 ---",
      "[Context before]",
      "4264:           ToCudnnDataType(input_type_) == CUDNN_DATA_INT8 &&",
      "4265:           ToCudnnDataType(output_type_) == CUDNN_DATA_FLOAT) {",
      "4266:         return tsl::Status(",
      "4268:             \"This configuration potentially produces incorrect results.\");",
      "4269:       }",
      "4270: #else",
      "",
      "[Removed Lines]",
      "4267:             port::error::FAILED_PRECONDITION,",
      "",
      "[Added Lines]",
      "4266:             tsl::error::FAILED_PRECONDITION,",
      "",
      "---------------",
      "--- Hunk 37 ---",
      "[Context before]",
      "4337:     if (is_profiling) {",
      "4338:       if (!timer->Stop(AsGpuStream(stream))) {",
      "4340:       }",
      "4341:       profile_result->set_algorithm(algo);",
      "4342:       profile_result->set_elapsed_time_in_ms(timer->GetElapsedMilliseconds());",
      "",
      "[Removed Lines]",
      "4339:         return tsl::Status(port::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "[Added Lines]",
      "4338:         return tsl::Status(tsl::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "---------------",
      "--- Hunk 38 ---",
      "[Context before]",
      "4633:       if (!timer->Init() || !timer->Start(AsGpuStream(stream))) {",
      "4635:       }",
      "4636:     }",
      "",
      "[Removed Lines]",
      "4634:         return tsl::Status(port::error::INTERNAL, \"Failed to start timer\");",
      "",
      "[Added Lines]",
      "4633:         return tsl::Status(tsl::error::INTERNAL, \"Failed to start timer\");",
      "",
      "---------------",
      "--- Hunk 39 ---",
      "[Context before]",
      "4642:     if (is_profiling) {",
      "4643:       if (!timer->Stop(AsGpuStream(stream))) {",
      "4645:       }",
      "4646:       TF_ASSIGN_OR_RETURN(auto desc, ToAlgorithmDesc());",
      "4647:       profile_result->set_algorithm(desc);",
      "",
      "[Removed Lines]",
      "4644:         return tsl::Status(port::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "[Added Lines]",
      "4643:         return tsl::Status(tsl::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "---------------",
      "--- Hunk 40 ---",
      "[Context before]",
      "4868:     }",
      "4869:     if (!got_algos) {",
      "4870:       return tsl::Status(",
      "4872:           absl::StrFormat(\"Listing algorithms failed for kind %d\", kind));",
      "4873:     }",
      "",
      "[Removed Lines]",
      "4871:           port::error::UNKNOWN,",
      "",
      "[Added Lines]",
      "4870:           tsl::error::UNKNOWN,",
      "",
      "---------------",
      "--- Hunk 41 ---",
      "[Context before]",
      "5039:       if (!timer->Init() || !timer->Start(AsGpuStream(stream))) {",
      "5041:       }",
      "5042:     }",
      "5043:     auto side_input_data_ptr = (side_input_scale_ == 0)",
      "",
      "[Removed Lines]",
      "5040:         return tsl::Status(port::error::INTERNAL, \"Failed to start timer\");",
      "",
      "[Added Lines]",
      "5039:         return tsl::Status(tsl::error::INTERNAL, \"Failed to start timer\");",
      "",
      "---------------",
      "--- Hunk 42 ---",
      "[Context before]",
      "5065:             << \"\\noutput_data.opaque() = \" << output_data.opaque();",
      "5067:     if (IsTensorMathOpSet(conv_) != tensor_ops_enabled_) {",
      "5069:                          \"Tensor op math type in dnn::AlgorithmDesc does not \"",
      "5070:                          \"match that of the CudnnConvolutionDescriptor\");",
      "5071:     }",
      "",
      "[Removed Lines]",
      "5068:       return tsl::Status(port::error::FAILED_PRECONDITION,",
      "",
      "[Added Lines]",
      "5067:       return tsl::Status(tsl::error::FAILED_PRECONDITION,",
      "",
      "---------------",
      "--- Hunk 43 ---",
      "[Context before]",
      "5096:     if (profile_result) {",
      "5097:       if (!timer->Stop(AsGpuStream(stream))) {",
      "5099:       }",
      "5100:       profile_result->set_algorithm(algo);",
      "5101:       profile_result->set_elapsed_time_in_ms(timer->GetElapsedMilliseconds());",
      "",
      "[Removed Lines]",
      "5098:         return tsl::Status(port::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "[Added Lines]",
      "5097:         return tsl::Status(tsl::error::INTERNAL, \"Failed to stop timer\");",
      "",
      "---------------",
      "--- Hunk 44 ---",
      "[Context before]",
      "5308:       activation_mode != dnn::ActivationMode::kElu &&",
      "5309:       activation_mode != dnn::ActivationMode::kLeakyRelu &&",
      "5310:       activation_mode != dnn::ActivationMode::kNone) {",
      "5312:                        \"CuDNN fusion only supports activations of \"",
      "5313:                        \"{Relu, Relu6, Elu, <None>}.\");",
      "5314:   }",
      "",
      "[Removed Lines]",
      "5311:     return tsl::Status(port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "5310:     return tsl::Status(tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 45 ---",
      "[Context before]",
      "5319:     auto cuda_compute_capability = stream->GetCudaComputeCapability();",
      "5320:     if (!GetConvolveAlgorithms(cuda_compute_capability, input_type,",
      "5321:                                &algorithms)) {",
      "5323:                          \"Listing fused convolve algorithms failed.\");",
      "5324:     }",
      "",
      "[Removed Lines]",
      "5322:       return tsl::Status(port::error::UNKNOWN,",
      "",
      "[Added Lines]",
      "5321:       return tsl::Status(tsl::error::UNKNOWN,",
      "",
      "---------------",
      "--- Hunk 46 ---",
      "[Context before]",
      "5354:       leakyrelu_alpha, input_descriptor, filter_descriptor, bias_descriptor,",
      "5355:       output_descriptor, convolution_descriptor, activation_mode, cudnn);",
      "5356:   if (!op_graph_status.status().ok()) {",
      "5358:                        absl::StrCat(\"Cudnn graph failed to build: \",",
      "5359:                                     op_graph_status.status().ToString()));",
      "5360:   }",
      "",
      "[Removed Lines]",
      "5357:     return tsl::Status(port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "5356:     return tsl::Status(tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 47 ---",
      "[Context before]",
      "5391:       input_type, bias_type, output_type, trans_a, trans_b, m, n, k, lda, ldb,",
      "5392:       ldc, activation_mode, cudnn);",
      "5393:   if (!op_graph_status.status().ok()) {",
      "5395:                        absl::StrCat(\"Cudnn graph failed to build: \",",
      "5396:                                     op_graph_status.status().ToString()));",
      "5397:   }",
      "",
      "[Removed Lines]",
      "5394:     return tsl::Status(port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "5393:     return tsl::Status(tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 48 ---",
      "[Context before]",
      "5685:     if (activation_mode != dnn::ActivationMode::kNone ||",
      "5686:         !side_input.is_null()) {",
      "5687:       return tsl::Status(",
      "5689:           absl::StrCat(",
      "5690:               \"Side input and activation are not supported by cuDNN version: \",",
      "5691:               CUDNN_VERSION));",
      "",
      "[Removed Lines]",
      "5688:           port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "5687:           tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 49 ---",
      "[Context before]",
      "5969:   if (activation_mode != dnn::ActivationMode::kRelu &&",
      "5970:       activation_mode != dnn::ActivationMode::kNone) {",
      "5972:                        \"cudnnConvolutionBiasActivationForward() only supports \"",
      "5973:                        \"Relu or None activation.\");",
      "5974:   }",
      "",
      "[Removed Lines]",
      "5971:     return tsl::Status(port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "5970:     return tsl::Status(tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 50 ---",
      "[Context before]",
      "6070:   }",
      "6072: #else",
      "6074:                      \"No supported cudnnGetCTCLossWorkspaceSize when \"",
      "6075:                      \"CUDNN_VERSION < 7.6.3\");",
      "6076: #endif",
      "",
      "[Removed Lines]",
      "6073:   return tsl::Status(port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "6072:   return tsl::Status(tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 51 ---",
      "[Context before]",
      "6100:     int ctc_loss_algo_id) {",
      "6102:   if (CUDNN_VERSION < 7603 || element_type != dnn::DataType::kFloat) {",
      "6104:                        \"CudnnCtcLossDescriptor is supported only when the \"",
      "6105:                        \"CUDNN_VERSION >= 7.6.3 and DataType is float\");",
      "6106:   }",
      "",
      "[Removed Lines]",
      "6103:     return tsl::Status(port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "6102:     return tsl::Status(tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 52 ---",
      "[Context before]",
      "6383:   if (max_batches_per_split == 0) {",
      "6384:     return tsl::Status(",
      "6386:         absl::StrCat(",
      "6387:             \"Tensor has too many elements for int32 indexing: batches=\",",
      "6388:             num_batches, \" elements_per_batch=\", elements_per_batch_input,",
      "",
      "[Removed Lines]",
      "6385:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "6384:         tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 53 ---",
      "[Context before]",
      "6442:   auto splits_or =",
      "6443:       GetTensorSplits(input_dimensions, output_dimensions, element_type);",
      "6444:   if (!splits_or.ok()) {",
      "6446:   }",
      "6447:   auto splits = std::move(splits_or.value());",
      "",
      "[Removed Lines]",
      "6445:     return tsl::Status(port::error::INTERNAL, \"Cudnn pooling failed to split\");",
      "",
      "[Added Lines]",
      "6444:     return tsl::Status(tsl::error::INTERNAL, \"Cudnn pooling failed to split\");",
      "",
      "---------------",
      "--- Hunk 54 ---",
      "[Context before]",
      "6511:   auto splits_or =",
      "6512:       GetTensorSplits(input_dimensions, output_dimensions, element_type);",
      "6513:   if (!splits_or.ok()) {",
      "6515:   }",
      "6516:   auto splits = std::move(splits_or.value());",
      "",
      "[Removed Lines]",
      "6514:     return tsl::Status(port::error::INTERNAL, \"Cudnn pooling failed to split\");",
      "",
      "[Added Lines]",
      "6513:     return tsl::Status(tsl::error::INTERNAL, \"Cudnn pooling failed to split\");",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc": [
      "File: tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc -> tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "35: #include \"absl/synchronization/notification.h\"",
      "36: #include \"third_party/gpus/cuda/include/cuda_runtime_api.h\"",
      "37: #include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.h\"",
      "39: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "40: #include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"",
      "41: #include \"tensorflow/tsl/platform/env.h\"",
      "42: #include \"tensorflow/tsl/platform/stacktrace.h\"",
      "43: #include \"tensorflow/tsl/platform/static_threadlocal.h\"",
      "44: #include \"tensorflow/tsl/platform/threadpool.h\"",
      "",
      "[Removed Lines]",
      "38: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "",
      "[Added Lines]",
      "41: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "267:   }",
      "269:   Diagnostician::LogDiagnosticInformation();",
      "271:                      absl::StrCat(\"failed call to cuInit: \", ToString(res)));",
      "272: }",
      "",
      "[Removed Lines]",
      "270:   return tsl::Status(port::error::ABORTED,",
      "",
      "[Added Lines]",
      "270:   return tsl::Status(tsl::error::ABORTED,",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "400:     }",
      "401:   }",
      "404: }",
      "",
      "[Removed Lines]",
      "403:   return tsl::Status(port::error::INTERNAL, message);",
      "",
      "[Added Lines]",
      "403:   return tsl::Status(tsl::error::INTERNAL, message);",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "673:   }",
      "675:   return tsl::Status(",
      "677:       absl::StrCat(\"failed to get device for context: \", ToString(result)));",
      "678: }",
      "",
      "[Removed Lines]",
      "676:       port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "676:       tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "973:                                                  CUevent* event) {",
      "974:   if (*event == nullptr) {",
      "976:                        \"input event cannot be null\");",
      "977:   }",
      "",
      "[Removed Lines]",
      "975:     return tsl::Status(port::error::INVALID_ARGUMENT,",
      "",
      "[Added Lines]",
      "975:     return tsl::Status(tsl::error::INVALID_ARGUMENT,",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "997:   CUresult res = cuEventQuery(event);",
      "998:   if (res != CUDA_SUCCESS && res != CUDA_ERROR_NOT_READY) {",
      "999:     return tsl::Status(",
      "1001:         absl::StrFormat(\"failed to query event: %s\", ToString(res)));",
      "1002:   }",
      "",
      "[Removed Lines]",
      "1000:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "1000:         tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 7 ---",
      "[Context before]",
      "1263:   if (res == CUDA_SUCCESS) {",
      "1264:     return ::tsl::OkStatus();",
      "1265:   } else if (res == CUDA_ERROR_OUT_OF_MEMORY) {",
      "1267:                        \"could not create CUDA event: out of device memory\");",
      "1268:   } else {",
      "1269:     return tsl::Status(",
      "1271:         absl::StrCat(\"could not create CUDA event: \", ToString(res)));",
      "1272:   }",
      "1273: }",
      "",
      "[Removed Lines]",
      "1266:     return tsl::Status(port::error::RESOURCE_EXHAUSTED,",
      "1270:         port::error::FAILED_PRECONDITION,",
      "",
      "[Added Lines]",
      "1266:     return tsl::Status(tsl::error::RESOURCE_EXHAUSTED,",
      "1270:         tsl::error::FAILED_PRECONDITION,",
      "",
      "---------------",
      "--- Hunk 8 ---",
      "[Context before]",
      "1300:     if (context == nullptr) {",
      "1301:       return tsl::Status(",
      "1303:           \"Empty context returned while querying context for device pointer\");",
      "1304:     }",
      "1305:     return context;",
      "1306:   }",
      "1308:   return tsl::Status(",
      "1310:       absl::StrCat(\"failed to query context for device pointer: \",",
      "1311:                    ToString(result)));",
      "1312: }",
      "",
      "[Removed Lines]",
      "1302:           port::error::UNAVAILABLE,",
      "1309:       port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "1302:           tsl::error::UNAVAILABLE,",
      "1309:       tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 9 ---",
      "[Context before]",
      "1324:         return MemorySpace::kHost;",
      "1325:       default:",
      "1326:         return tsl::Status(",
      "1328:             absl::StrCat(\"unknown memory space provided by CUDA API: \", value));",
      "1329:     }",
      "1330:   }",
      "1332:   return tsl::Status(",
      "1334:       absl::StrCat(\"failed to query device pointer for memory space: \",",
      "1335:                    ToString(result)));",
      "1336: }",
      "",
      "[Removed Lines]",
      "1327:             port::error::INTERNAL,",
      "1333:       port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "1327:             tsl::error::INTERNAL,",
      "1333:       tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 10 ---",
      "[Context before]",
      "1348:     return tsl::Status(",
      "1350:         absl::StrFormat(\"not a device pointer %p; %s\",",
      "1351:                         reinterpret_cast<void*>(dptr), ToString(result)));",
      "1352:   }",
      "1354:   return tsl::Status(",
      "1356:       absl::StrFormat(\"failed to get pointer into for device pointer %p; %s\",",
      "1357:                       reinterpret_cast<void*>(dptr), ToString(result)));",
      "1358: }",
      "",
      "[Removed Lines]",
      "1349:         port::error::NOT_FOUND,",
      "1355:       port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "1349:         tsl::error::NOT_FOUND,",
      "1355:       tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 11 ---",
      "[Context before]",
      "1377:       cc_major, CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MAJOR, device);",
      "1378:   if (res != CUDA_SUCCESS) {",
      "1379:     return tsl::Status(",
      "1381:         absl::StrFormat(",
      "1382:             \"failed to get compute capability major for device: %s; %d\",",
      "1383:             ToString(res), device));",
      "",
      "[Removed Lines]",
      "1380:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "1380:         tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 12 ---",
      "[Context before]",
      "1387:       cc_minor, CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MINOR, device);",
      "1388:   if (res != CUDA_SUCCESS) {",
      "1389:     return tsl::Status(",
      "1391:         absl::StrFormat(",
      "1392:             \"failed to get compute capability minor for device: %s; %d\",",
      "1393:             ToString(res), device));",
      "",
      "[Removed Lines]",
      "1390:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "1390:         tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 13 ---",
      "[Context before]",
      "1400:                                                      CUdevice device) {",
      "1401:   return tsl::Status{",
      "1403:       \"Feature not supported on CUDA platform (GetGpuISAVersion)\"};",
      "1404: }",
      "1407:   return tsl::Status{",
      "1409:       \"Feature not supported on CUDA platform (GetGpuGCNArchName)\"};",
      "1410: }",
      "",
      "[Removed Lines]",
      "1402:       port::error::INTERNAL,",
      "1408:       port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "1402:       tsl::error::INTERNAL,",
      "1408:       tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 14 ---",
      "[Context before]",
      "1519:   CUresult res = cuDeviceGetAttribute(&val, attribute, device);",
      "1520:   if (res != CUDA_SUCCESS) {",
      "1521:     return tsl::Status(",
      "1523:         absl::StrFormat(\"failed to get device attribute %d for device %d: %s\",",
      "1524:                         attribute, device, ToString(res)));",
      "1525:   }",
      "",
      "[Removed Lines]",
      "1522:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "1522:         tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 15 ---",
      "[Context before]",
      "1628:   if (result != CUDA_SUCCESS &&",
      "1629:       result != CUDA_ERROR_PEER_ACCESS_ALREADY_ENABLED) {",
      "1630:     return tsl::Status(",
      "1632:         absl::StrFormat(\"failed to enable peer access from %p to %p: %s\", from,",
      "1633:                         to, ToString(result)));",
      "1634:   }",
      "",
      "[Removed Lines]",
      "1631:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "1631:         tsl::error::INTERNAL,",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc": [
      "File: tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc -> tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "26: #include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_platform_id.h\"",
      "27: #include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_stream.h\"",
      "28: #include \"tensorflow/compiler/xla/stream_executor/device_memory.h\"",
      "30: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "31: #include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"",
      "32: #include \"tensorflow/compiler/xla/stream_executor/plugin_registry.h\"",
      "",
      "[Removed Lines]",
      "29: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "29: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc": [
      "File: tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc -> tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "42: #include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_stream.h\"",
      "43: #include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_timer.h\"",
      "44: #include \"tensorflow/compiler/xla/stream_executor/kernel_cache_config.h\"",
      "47: #include \"tensorflow/compiler/xla/stream_executor/platform.h\"",
      "48: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "49: #include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"",
      "50: #include \"tensorflow/compiler/xla/stream_executor/plugin_registry.h\"",
      "",
      "[Removed Lines]",
      "45: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "46: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "46: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "53: #include \"tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.h\"",
      "54: #include \"tensorflow/compiler/xla/stream_executor/timer.h\"",
      "55: #include \"tensorflow/tsl/platform/env.h\"",
      "56: #include \"tensorflow/tsl/platform/numbers.h\"",
      "57: #include \"tensorflow/tsl/platform/statusor.h\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "55: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "745:     return ::tsl::OkStatus();",
      "746:   } else {",
      "747:     return tsl::Status(",
      "749:         absl::StrFormat(\"error recording waiting for CUDA event on stream %p\",",
      "750:                         stream));",
      "751:   }",
      "",
      "[Removed Lines]",
      "748:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "748:         tsl::error::INTERNAL,",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/cuda/cuda_platform.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_platform.cc": [
      "File: tensorflow/compiler/xla/stream_executor/cuda/cuda_platform.cc -> tensorflow/compiler/xla/stream_executor/cuda/cuda_platform.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "23: #include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.h\"",
      "24: #include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.h\"",
      "25: #include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_platform_id.h\"",
      "28: #include \"tensorflow/tsl/platform/status.h\"",
      "30: namespace stream_executor {",
      "",
      "[Removed Lines]",
      "26: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "27: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "26: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "27: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "117:   }",
      "119:   return tsl::Status(",
      "121:       absl::StrFormat(\"Executor for bus %d not found.\", bus_ordinal));",
      "122: }",
      "",
      "[Removed Lines]",
      "120:       port::error::NOT_FOUND,",
      "",
      "[Added Lines]",
      "120:       tsl::error::NOT_FOUND,",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "177:   auto init_status = executor->Init(config.device_options);",
      "178:   if (!init_status.ok()) {",
      "179:     return tsl::Status(",
      "181:         absl::StrFormat(",
      "182:             \"failed initializing StreamExecutor for CUDA device ordinal %d: %s\",",
      "183:             config.ordinal, init_status.ToString()));",
      "",
      "[Removed Lines]",
      "180:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "180:         tsl::error::INTERNAL,",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/cuda/cuda_rng.cc||tensorflow/compiler/xla/stream_executor/cuda/cuda_rng.cc": [
      "File: tensorflow/compiler/xla/stream_executor/cuda/cuda_rng.cc -> tensorflow/compiler/xla/stream_executor/cuda/cuda_rng.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "23: #include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_platform_id.h\"",
      "24: #include \"tensorflow/compiler/xla/stream_executor/cuda/cuda_stream.h\"",
      "25: #include \"tensorflow/compiler/xla/stream_executor/device_memory.h\"",
      "27: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "28: #include \"tensorflow/compiler/xla/stream_executor/rng.h\"",
      "29: #include \"tensorflow/tsl/platform/status.h\"",
      "",
      "[Removed Lines]",
      "26: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "26: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/host/host_gpu_executor.h||tensorflow/compiler/xla/stream_executor/host/host_gpu_executor.h": [
      "File: tensorflow/compiler/xla/stream_executor/host/host_gpu_executor.h -> tensorflow/compiler/xla/stream_executor/host/host_gpu_executor.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "25: #include \"tensorflow/compiler/xla/stream_executor/blas.h\"",
      "26: #include \"tensorflow/compiler/xla/stream_executor/host/host_stream.h\"",
      "27: #include \"tensorflow/compiler/xla/stream_executor/host/host_timer.h\"",
      "29: #include \"tensorflow/compiler/xla/stream_executor/rng.h\"",
      "30: #include \"tensorflow/compiler/xla/stream_executor/stream_executor.h\"",
      "31: #include \"tensorflow/compiler/xla/stream_executor/stream_executor_internal.h\"",
      "33: namespace stream_executor {",
      "34: namespace host {",
      "",
      "[Removed Lines]",
      "28: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "",
      "[Added Lines]",
      "31: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/host/host_platform.cc||tensorflow/compiler/xla/stream_executor/host/host_platform.cc": [
      "File: tensorflow/compiler/xla/stream_executor/host/host_platform.cc -> tensorflow/compiler/xla/stream_executor/host/host_platform.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "21: #include \"absl/strings/str_format.h\"",
      "22: #include \"tensorflow/compiler/xla/stream_executor/host/host_gpu_executor.h\"",
      "23: #include \"tensorflow/compiler/xla/stream_executor/host/host_platform_id.h\"",
      "27: namespace stream_executor {",
      "28: namespace host {",
      "",
      "[Removed Lines]",
      "24: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "25: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "24: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "25: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "75:   auto init_status = executor->Init(config.device_options);",
      "76:   if (!init_status.ok()) {",
      "77:     return tsl::Status(",
      "79:         absl::StrFormat(",
      "80:             \"failed initializing StreamExecutor for device ordinal %d: %s\",",
      "81:             config.ordinal, init_status.ToString().c_str()));",
      "",
      "[Removed Lines]",
      "78:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "78:         tsl::error::INTERNAL,",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/lib/error.h||tensorflow/compiler/xla/stream_executor/lib/error.h": [
      "File: tensorflow/compiler/xla/stream_executor/lib/error.h -> tensorflow/compiler/xla/stream_executor/lib/error.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "[No context available]",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/lib/initialize.h||tensorflow/compiler/xla/stream_executor/lib/initialize.h": [
      "File: tensorflow/compiler/xla/stream_executor/lib/initialize.h -> tensorflow/compiler/xla/stream_executor/lib/initialize.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "[No context available]",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/multi_platform_manager.cc||tensorflow/compiler/xla/stream_executor/multi_platform_manager.cc": [
      "File: tensorflow/compiler/xla/stream_executor/multi_platform_manager.cc -> tensorflow/compiler/xla/stream_executor/multi_platform_manager.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "24: #include \"absl/strings/str_join.h\"",
      "25: #include \"absl/strings/string_view.h\"",
      "26: #include \"absl/synchronization/mutex.h\"",
      "29: #include \"tensorflow/tsl/platform/errors.h\"",
      "31: namespace stream_executor {",
      "",
      "[Removed Lines]",
      "27: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "28: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "27: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "96:   std::string key = absl::AsciiStrToLower(platform->Name());",
      "97:   absl::MutexLock lock(&mu_);",
      "98:   if (name_map_.find(key) != name_map_.end()) {",
      "100:                        \"platform is already registered with name: \\\"\" +",
      "101:                            platform->Name() + \"\\\"\");",
      "102:   }",
      "",
      "[Removed Lines]",
      "99:     return tsl::Status(port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "98:     return tsl::Status(tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "156:   TF_ASSIGN_OR_RETURN(Platform * platform, LookupByNameLocked(target));",
      "157:   if (platform->Initialized()) {",
      "158:     return tsl::Status(",
      "160:         absl::StrCat(\"platform \\\"\", target, \"\\\" is already initialized\"));",
      "161:   }",
      "",
      "[Removed Lines]",
      "159:         port::error::FAILED_PRECONDITION,",
      "",
      "[Added Lines]",
      "158:         tsl::error::FAILED_PRECONDITION,",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "172:   TF_ASSIGN_OR_RETURN(Platform * platform, LookupByIdLocked(id));",
      "173:   if (platform->Initialized()) {",
      "174:     return tsl::Status(",
      "176:         absl::StrFormat(\"platform with id %p is already initialized\", id));",
      "177:   }",
      "",
      "[Removed Lines]",
      "175:         port::error::FAILED_PRECONDITION,",
      "",
      "[Added Lines]",
      "174:         tsl::error::FAILED_PRECONDITION,",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "232:   auto it = name_map_.find(absl::AsciiStrToLower(target));",
      "233:   if (it == name_map_.end()) {",
      "234:     return tsl::Status(",
      "236:         absl::StrCat(\"Could not find registered platform with name: \\\"\", target,",
      "237:                      \"\\\". Available platform names are: \",",
      "238:                      absl::StrJoin(InitializedPlatformNamesWithFilter(), \" \")));",
      "",
      "[Removed Lines]",
      "235:         port::error::NOT_FOUND,",
      "",
      "[Added Lines]",
      "234:         tsl::error::NOT_FOUND,",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "245:   auto it = id_map_.find(id);",
      "246:   if (it == id_map_.end()) {",
      "247:     return tsl::Status(",
      "249:         absl::StrFormat(\"could not find registered platform with id: %p\", id));",
      "250:   }",
      "251:   return it->second;",
      "",
      "[Removed Lines]",
      "248:         port::error::NOT_FOUND,",
      "",
      "[Added Lines]",
      "247:         tsl::error::NOT_FOUND,",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/multi_platform_manager.h||tensorflow/compiler/xla/stream_executor/multi_platform_manager.h": [
      "File: tensorflow/compiler/xla/stream_executor/multi_platform_manager.h -> tensorflow/compiler/xla/stream_executor/multi_platform_manager.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "70: #include <vector>",
      "72: #include \"absl/strings/string_view.h\"",
      "74: #include \"tensorflow/compiler/xla/stream_executor/platform.h\"",
      "75: #include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"",
      "76: #include \"tensorflow/tsl/platform/status.h\"",
      "77: #include \"tensorflow/tsl/platform/statusor.h\"",
      "",
      "[Removed Lines]",
      "73: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "74: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/platform.cc||tensorflow/compiler/xla/stream_executor/platform.cc": [
      "File: tensorflow/compiler/xla/stream_executor/platform.cc -> tensorflow/compiler/xla/stream_executor/platform.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "16: #include \"tensorflow/compiler/xla/stream_executor/platform.h\"",
      "18: #include \"absl/strings/str_cat.h\"",
      "20: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "21: #include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"",
      "22: #include \"tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.h\"",
      "24: namespace stream_executor {",
      "",
      "[Removed Lines]",
      "19: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "",
      "[Added Lines]",
      "22: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "92: tsl::Status Platform::Initialize(",
      "93:     const std::map<std::string, std::string> &platform_options) {",
      "94:   if (!platform_options.empty()) {",
      "96:                        \"this platform does not support custom initialization\");",
      "97:   }",
      "98:   return ::tsl::OkStatus();",
      "99: }",
      "101: tsl::Status Platform::ForceExecutorShutdown() {",
      "103:                      \"executor shutdown is not supported on this platform\");",
      "104: }",
      "",
      "[Removed Lines]",
      "95:     return tsl::Status(port::error::UNIMPLEMENTED,",
      "102:   return tsl::Status(port::error::UNIMPLEMENTED,",
      "",
      "[Added Lines]",
      "95:     return tsl::Status(tsl::error::UNIMPLEMENTED,",
      "102:   return tsl::Status(tsl::error::UNIMPLEMENTED,",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/plugin_registry.cc||tensorflow/compiler/xla/stream_executor/plugin_registry.cc": [
      "File: tensorflow/compiler/xla/stream_executor/plugin_registry.cc -> tensorflow/compiler/xla/stream_executor/plugin_registry.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "19: #include \"absl/strings/str_cat.h\"",
      "20: #include \"absl/strings/str_format.h\"",
      "21: #include \"absl/synchronization/mutex.h\"",
      "23: #include \"tensorflow/compiler/xla/stream_executor/multi_platform_manager.h\"",
      "25: namespace stream_executor {",
      "",
      "[Removed Lines]",
      "22: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "",
      "[Added Lines]",
      "23: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "77:   if (factories->find(plugin_id) != factories->end()) {",
      "78:     return tsl::Status(",
      "80:         absl::StrFormat(\"Attempting to register factory for plugin %s when \"",
      "81:                         \"one has already been registered\",",
      "82:                         plugin_name));",
      "",
      "[Removed Lines]",
      "79:         port::error::ALREADY_EXISTS,",
      "",
      "[Added Lines]",
      "79:         tsl::error::ALREADY_EXISTS,",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "96:     iter = generic_factories.find(plugin_id);",
      "97:     if (iter == generic_factories.end()) {",
      "98:       return tsl::Status(",
      "100:           absl::StrFormat(\"Plugin ID %p not registered.\", plugin_id));",
      "101:     }",
      "102:   }",
      "",
      "[Removed Lines]",
      "99:           port::error::NOT_FOUND,",
      "",
      "[Added Lines]",
      "99:           tsl::error::NOT_FOUND,",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "217:                                                                               \\",
      "218:       if (plugin_id == kNullPlugin) {                                         \\",
      "219:         return tsl::Status(                                                   \\",
      "221:             \"No suitable \" PLUGIN_STRING                                      \\",
      "222:             \" plugin registered. Have you linked in a \" PLUGIN_STRING         \\",
      "223:             \"-providing plugin?\");                                            \\",
      "",
      "[Removed Lines]",
      "220:             port::error::FAILED_PRECONDITION,                                 \\",
      "",
      "[Added Lines]",
      "220:             tsl::error::FAILED_PRECONDITION,                                  \\",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "236:       PlatformKind platform_kind, PluginId plugin_id) {                       \\",
      "237:     auto iter = platform_id_by_kind_.find(platform_kind);                     \\",
      "238:     if (iter == platform_id_by_kind_.end()) {                                 \\",
      "240:                          absl::StrFormat(\"Platform kind %d not registered.\",  \\",
      "241:                                          static_cast<int>(platform_kind)));   \\",
      "242:     }                                                                         \\",
      "",
      "[Removed Lines]",
      "239:       return tsl::Status(port::error::FAILED_PRECONDITION,                    \\",
      "",
      "[Added Lines]",
      "239:       return tsl::Status(tsl::error::FAILED_PRECONDITION,                     \\",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/rocm/rocm_blas.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_blas.cc": [
      "File: tensorflow/compiler/xla/stream_executor/rocm/rocm_blas.cc -> tensorflow/compiler/xla/stream_executor/rocm/rocm_blas.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "32: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_helpers.h\"",
      "33: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_stream.h\"",
      "34: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_timer.h\"",
      "36: #include \"tensorflow/compiler/xla/stream_executor/platform/dso_loader.h\"",
      "37: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "38: #include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"",
      "39: #include \"tensorflow/compiler/xla/stream_executor/plugin_registry.h\"",
      "",
      "[Removed Lines]",
      "35: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "36: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/rocm/rocm_diagnostics.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_diagnostics.cc": [
      "File: tensorflow/compiler/xla/stream_executor/rocm/rocm_diagnostics.cc -> tensorflow/compiler/xla/stream_executor/rocm/rocm_diagnostics.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "35: #include \"absl/strings/str_format.h\"",
      "36: #include \"absl/strings/str_split.h\"",
      "37: #include \"absl/strings/strip.h\"",
      "39: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "40: #include \"tensorflow/tsl/platform/host_info.h\"",
      "42: namespace stream_executor {",
      "",
      "[Removed Lines]",
      "38: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "",
      "[Added Lines]",
      "39: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/rocm/rocm_dnn.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_dnn.cc": [
      "File: tensorflow/compiler/xla/stream_executor/rocm/rocm_dnn.cc -> tensorflow/compiler/xla/stream_executor/rocm/rocm_dnn.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "31: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_executor.h\"",
      "32: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_stream.h\"",
      "33: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_timer.h\"",
      "36: #include \"tensorflow/compiler/xla/stream_executor/platform/dso_loader.h\"",
      "37: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "38: #include \"tensorflow/compiler/xla/stream_executor/plugin_registry.h\"",
      "39: #include \"tensorflow/compiler/xla/stream_executor/rocm/rocm_diagnostics.h\"",
      "",
      "[Removed Lines]",
      "34: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "35: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "35: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "42: #include \"tensorflow/compiler/xla/stream_executor/stream.h\"",
      "43: #include \"tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.h\"",
      "44: #include \"tensorflow/tsl/platform/env.h\"",
      "45: #include \"tensorflow/tsl/platform/hash.h\"",
      "46: #include \"tensorflow/tsl/util/determinism.h\"",
      "47: #include \"tensorflow/tsl/util/env_var.h\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "44: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/rocm/rocm_driver.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_driver.cc": [
      "File: tensorflow/compiler/xla/stream_executor/rocm/rocm_driver.cc -> tensorflow/compiler/xla/stream_executor/rocm/rocm_driver.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "28: #include \"absl/synchronization/notification.h\"",
      "29: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_diagnostics.h\"",
      "30: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_driver.h\"",
      "32: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "33: #include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"",
      "34: #include \"tensorflow/compiler/xla/stream_executor/rocm/rocm_driver_wrapper.h\"",
      "35: #include \"tensorflow/tsl/platform/env.h\"",
      "36: #include \"tensorflow/tsl/platform/numbers.h\"",
      "37: #include \"tensorflow/tsl/platform/stacktrace.h\"",
      "38: #include \"tensorflow/tsl/platform/static_threadlocal.h\"",
      "",
      "[Removed Lines]",
      "31: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "",
      "[Added Lines]",
      "35: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/rocm/rocm_fft.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_fft.cc": [
      "File: tensorflow/compiler/xla/stream_executor/rocm/rocm_fft.cc -> tensorflow/compiler/xla/stream_executor/rocm/rocm_fft.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "22: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_executor.h\"",
      "23: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_helpers.h\"",
      "24: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_stream.h\"",
      "26: #include \"tensorflow/compiler/xla/stream_executor/platform/dso_loader.h\"",
      "27: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "28: #include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"",
      "29: #include \"tensorflow/compiler/xla/stream_executor/plugin_registry.h\"",
      "",
      "[Removed Lines]",
      "25: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "26: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/rocm/rocm_gpu_executor.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_gpu_executor.cc": [
      "File: tensorflow/compiler/xla/stream_executor/rocm/rocm_gpu_executor.cc -> tensorflow/compiler/xla/stream_executor/rocm/rocm_gpu_executor.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "28: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_stream.h\"",
      "29: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_timer.h\"",
      "30: #include \"tensorflow/compiler/xla/stream_executor/kernel_cache_config.h\"",
      "33: #include \"tensorflow/compiler/xla/stream_executor/platform.h\"",
      "34: #include \"tensorflow/compiler/xla/stream_executor/platform/dso_loader.h\"",
      "35: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "36: #include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"",
      "37: #include \"tensorflow/compiler/xla/stream_executor/plugin_registry.h\"",
      "",
      "[Removed Lines]",
      "31: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "32: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "33: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "42: #include \"tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.h\"",
      "43: #include \"tensorflow/compiler/xla/stream_executor/timer.h\"",
      "44: #include \"tensorflow/tsl/platform/env.h\"",
      "46: #ifdef PLATFORMS_GPUS_ROCM_DYNAMIC_LIBROCM_DYNAMIC_LIBROCM_H_",
      "47: #error \\",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "44: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/rocm/rocm_platform.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_platform.cc": [
      "File: tensorflow/compiler/xla/stream_executor/rocm/rocm_platform.cc -> tensorflow/compiler/xla/stream_executor/rocm/rocm_platform.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "21: #include \"absl/strings/str_format.h\"",
      "22: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_driver.h\"",
      "23: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_executor.h\"",
      "26: #include \"tensorflow/compiler/xla/stream_executor/rocm/rocm_platform_id.h\"",
      "28: namespace stream_executor {",
      "29: namespace gpu {",
      "",
      "[Removed Lines]",
      "24: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "25: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "24: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "26: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/rocm/rocm_rng.cc||tensorflow/compiler/xla/stream_executor/rocm/rocm_rng.cc": [
      "File: tensorflow/compiler/xla/stream_executor/rocm/rocm_rng.cc -> tensorflow/compiler/xla/stream_executor/rocm/rocm_rng.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "20: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_helpers.h\"",
      "21: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_rng.h\"",
      "22: #include \"tensorflow/compiler/xla/stream_executor/gpu/gpu_stream.h\"",
      "24: #include \"tensorflow/compiler/xla/stream_executor/platform/dso_loader.h\"",
      "25: #include \"tensorflow/compiler/xla/stream_executor/platform/logging.h\"",
      "26: #include \"tensorflow/compiler/xla/stream_executor/rng.h\"",
      "27: #include \"tensorflow/compiler/xla/stream_executor/rocm/rocm_platform_id.h\"",
      "",
      "[Removed Lines]",
      "23: #include \"tensorflow/compiler/xla/stream_executor/lib/initialize.h\"",
      "",
      "[Added Lines]",
      "24: #include \"tensorflow/compiler/xla/stream_executor/platform/initialize.h\"",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.cc||tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.cc": [
      "File: tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.cc -> tensorflow/compiler/xla/stream_executor/stream_executor_pimpl.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "32: #include \"absl/synchronization/notification.h\"",
      "33: #include \"tensorflow/compiler/xla/stream_executor/blas.h\"",
      "34: #include \"tensorflow/compiler/xla/stream_executor/fft.h\"",
      "36: #include \"tensorflow/compiler/xla/stream_executor/platform/port.h\"",
      "37: #include \"tensorflow/compiler/xla/stream_executor/rng.h\"",
      "38: #include \"tensorflow/compiler/xla/stream_executor/stream.h\"",
      "39: #include \"tensorflow/compiler/xla/stream_executor/stream_executor_internal.h\"",
      "40: #include \"tensorflow/tsl/platform/stacktrace.h\"",
      "41: #include \"tensorflow/tsl/platform/statusor.h\"",
      "42: #include \"tensorflow/tsl/platform/threadpool.h\"",
      "",
      "[Removed Lines]",
      "35: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "",
      "[Added Lines]",
      "39: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "405:     bool use_padded_io) {",
      "406:   dnn::DnnSupport* dnn_support = AsDnn();",
      "407:   if (!dnn_support) {",
      "409:                        \"Fail to find the dnn implementation.\");",
      "410:   }",
      "411:   return dnn_support->createRnnDescriptor(",
      "",
      "[Removed Lines]",
      "408:     return tsl::Status(port::error::UNKNOWN,",
      "",
      "[Added Lines]",
      "408:     return tsl::Status(tsl::error::UNKNOWN,",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "420:                                                   dnn::DataType data_type) {",
      "421:   dnn::DnnSupport* dnn_support = AsDnn();",
      "422:   if (!dnn_support) {",
      "424:                        \"Fail to find the dnn implementation.\");",
      "425:   }",
      "426:   return dnn_support->createRnnSequenceTensorDescriptor(",
      "",
      "[Removed Lines]",
      "423:     return tsl::Status(port::error::UNKNOWN,",
      "",
      "[Added Lines]",
      "423:     return tsl::Status(tsl::error::UNKNOWN,",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "434:     dnn::DataType data_type) {",
      "435:   dnn::DnnSupport* dnn_support = AsDnn();",
      "436:   if (!dnn_support) {",
      "438:                        \"Fail to find the dnn implementation.\");",
      "439:   }",
      "440:   return dnn_support->createRnnSequenceTensorDescriptor(",
      "",
      "[Removed Lines]",
      "437:     return tsl::Status(port::error::UNKNOWN,",
      "",
      "[Added Lines]",
      "437:     return tsl::Status(tsl::error::UNKNOWN,",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "448:                                                dnn::DataType data_type) {",
      "449:   dnn::DnnSupport* dnn_support = AsDnn();",
      "450:   if (!dnn_support) {",
      "452:                        \"Fail to find the dnn implementation.\");",
      "453:   }",
      "454:   return dnn_support->createRnnStateTensorDescriptor(num_layer, batch_size,",
      "",
      "[Removed Lines]",
      "451:     return tsl::Status(port::error::UNKNOWN,",
      "",
      "[Added Lines]",
      "451:     return tsl::Status(tsl::error::UNKNOWN,",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "546:   }",
      "548:   return tsl::Status(",
      "550:       absl::StrCat(\"Check if module containing symbol \", symbol_name,",
      "551:                    \" is loaded (module_handle = \",",
      "552:                    reinterpret_cast<uintptr_t>(module_handle.id()), \")\"));",
      "",
      "[Removed Lines]",
      "549:       port::error::NOT_FOUND,",
      "",
      "[Added Lines]",
      "549:       tsl::error::NOT_FOUND,",
      "",
      "---------------",
      "--- Hunk 7 ---",
      "[Context before]",
      "691:   result = implementation_->SynchronousMemcpy(host_dst, device_src, size);",
      "692:   if (!result.ok()) {",
      "693:     result = tsl::Status(",
      "695:         absl::StrFormat(\"failed to synchronously memcpy device-to-host: device \"",
      "696:                         \"%p to host %p size %d: %s\",",
      "697:                         device_src.opaque(), host_dst, size,",
      "",
      "[Removed Lines]",
      "694:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "694:         tsl::error::INTERNAL,",
      "",
      "---------------",
      "--- Hunk 8 ---",
      "[Context before]",
      "715:   result = implementation_->SynchronousMemcpy(device_dst, host_src, size);",
      "716:   if (!result.ok()) {",
      "717:     result = tsl::Status(",
      "719:         absl::StrFormat(\"failed to synchronously memcpy host-to-device: host \"",
      "720:                         \"%p to device %p size %d: %s\",",
      "721:                         host_src, device_dst->opaque(), size,",
      "",
      "[Removed Lines]",
      "718:         port::error::INTERNAL,",
      "",
      "[Added Lines]",
      "718:         tsl::error::INTERNAL,",
      "",
      "---------------"
    ],
    "tensorflow/compiler/xla/stream_executor/tf_allocator_adapter.cc||tensorflow/compiler/xla/stream_executor/tf_allocator_adapter.cc": [
      "File: tensorflow/compiler/xla/stream_executor/tf_allocator_adapter.cc -> tensorflow/compiler/xla/stream_executor/tf_allocator_adapter.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "16: #include \"tensorflow/compiler/xla/stream_executor/tf_allocator_adapter.h\"",
      "18: #include \"absl/synchronization/mutex.h\"",
      "20: #include \"tensorflow/compiler/xla/stream_executor/stream.h\"",
      "21: #include \"tensorflow/compiler/xla/stream_executor/stream_executor.h\"",
      "22: #include \"tensorflow/tsl/platform/errors.h\"",
      "",
      "[Removed Lines]",
      "19: #include \"tensorflow/compiler/xla/stream_executor/lib/error.h\"",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------"
    ],
    "tensorflow/core/common_runtime/function.cc||tensorflow/core/common_runtime/function.cc": [
      "File: tensorflow/core/common_runtime/function.cc -> tensorflow/core/common_runtime/function.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "535:     OP_REQUIRES_ASYNC(ctx, lib != nullptr,",
      "536:                       errors::Internal(\"No function library is provided.\"),",
      "537:                       done);",
      "539:     opts.rendezvous = ctx->rendezvous();",
      "540:     opts.cancellation_manager = ctx->cancellation_manager();",
      "541:     opts.step_container = ctx->step_container();",
      "",
      "[Removed Lines]",
      "538:     FunctionLibraryRuntime::Options opts;",
      "",
      "[Added Lines]",
      "538:     FunctionLibraryRuntime::Options opts(ctx->step_id());",
      "",
      "---------------"
    ],
    "tensorflow/core/data/service/server_lib.cc||tensorflow/core/data/service/server_lib.cc": [
      "File: tensorflow/core/data/service/server_lib.cc -> tensorflow/core/data/service/server_lib.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "37: }",
      "39: GrpcDataServerBase::GrpcDataServerBase(",
      "41:     std::vector<std::unique_ptr<::grpc::ServerBuilderOption>> options)",
      "42:     : requested_port_(port),",
      "43:       protocol_(protocol),",
      "",
      "[Removed Lines]",
      "40:     int port, const std::string& protocol, const std::string server_type,",
      "",
      "[Added Lines]",
      "40:     int port, const std::string& protocol, const std::string& server_type,",
      "",
      "---------------"
    ],
    "tensorflow/core/data/service/server_lib.h||tensorflow/core/data/service/server_lib.h": [
      "File: tensorflow/core/data/service/server_lib.h -> tensorflow/core/data/service/server_lib.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "45:   GrpcDataServerBase(",
      "46:       int requested_port, const std::string& protocol,",
      "48:       std::vector<std::unique_ptr<::grpc::ServerBuilderOption>> options = {});",
      "49:   virtual ~GrpcDataServerBase() = default;",
      "",
      "[Removed Lines]",
      "47:       const std::string server_type,",
      "",
      "[Added Lines]",
      "47:       const std::string& server_type,",
      "",
      "---------------"
    ],
    "tensorflow/core/data/service/snapshot/path_utils.cc||tensorflow/core/data/service/snapshot/path_utils.cc": [
      "File: tensorflow/core/data/service/snapshot/path_utils.cc -> tensorflow/core/data/service/snapshot/path_utils.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "15: #include \"tensorflow/core/data/service/snapshot/path_utils.h\"",
      "17: #include <string>",
      "19: #include \"absl/strings/str_cat.h\"",
      "20: #include \"absl/strings/string_view.h\"",
      "21: #include \"tensorflow/tsl/platform/path.h\"",
      "23: namespace tensorflow {",
      "24: namespace data {",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "18: #include <utility>",
      "19: #include <vector>",
      "22: #include \"absl/strings/str_split.h\"",
      "24: #include \"tensorflow/tsl/platform/errors.h\"",
      "26: #include \"tensorflow/tsl/platform/statusor.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "65:       absl::StrCat(\"split_\", local_index, \"_\", global_index));",
      "66: }",
      "68: std::string SnapshotMetadataFilePath(absl::string_view snapshot_path_) {",
      "69:   return tsl::io::JoinPath(snapshot_path_, kSnapshotMetadataFileName);",
      "70: }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "73: tsl::StatusOr<std::pair<int64_t, int64_t>> SplitIndex(",
      "74:     absl::string_view split_path) {",
      "75:   std::vector<std::string> tokens = absl::StrSplit(split_path, '_');",
      "76:   int64_t local_split_index = 0, global_split_index = 0;",
      "77:   if (tokens.size() != 3 || tokens[0] != \"split\" ||",
      "78:       !absl::SimpleAtoi(tokens[1], &local_split_index) ||",
      "79:       local_split_index < 0 ||",
      "80:       !absl::SimpleAtoi(tokens[2], &global_split_index) ||",
      "81:       global_split_index < 0) {",
      "82:     return tsl::errors::InvalidArgument(",
      "83:         \"Invalid split file name: \", split_path,",
      "84:         \". Expected split_<local_split_index>_<global_split_index>.\");",
      "85:   }",
      "86:   if (local_split_index > global_split_index) {",
      "87:     return tsl::errors::InvalidArgument(",
      "88:         \"Invalid split file name: \", split_path, \". The local split index \",",
      "89:         local_split_index, \" exceeds the global split index \",",
      "90:         global_split_index, \".\");",
      "91:   }",
      "92:   return std::make_pair(local_split_index, global_split_index);",
      "93: }",
      "",
      "---------------"
    ],
    "tensorflow/core/data/service/snapshot/path_utils.h||tensorflow/core/data/service/snapshot/path_utils.h": [
      "File: tensorflow/core/data/service/snapshot/path_utils.h -> tensorflow/core/data/service/snapshot/path_utils.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "16: #define TENSORFLOW_CORE_DATA_SERVICE_SNAPSHOT_PATH_UTILS_H_",
      "18: #include <string>",
      "20: #include \"absl/strings/string_view.h\"",
      "22: namespace tensorflow {",
      "23: namespace data {",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "19: #include <utility>",
      "22: #include \"tensorflow/tsl/platform/statusor.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "45:                       int64_t source_id, int64_t local_index,",
      "46:                       int64_t global_index);",
      "49: std::string StreamDoneFilePath(absl::string_view snapshot_path,",
      "50:                                int64_t stream_index);",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "53: tsl::StatusOr<std::pair<int64_t, int64_t>> SplitIndex(",
      "54:     absl::string_view split_path);",
      "",
      "---------------"
    ],
    "tensorflow/core/data/service/snapshot/path_utils_test.cc||tensorflow/core/data/service/snapshot/path_utils_test.cc": [
      "File: tensorflow/core/data/service/snapshot/path_utils_test.cc -> tensorflow/core/data/service/snapshot/path_utils_test.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "15: #include \"tensorflow/core/data/service/snapshot/path_utils.h\"",
      "17: #include \"tensorflow/tsl/platform/test.h\"",
      "19: namespace tensorflow {",
      "20: namespace data {",
      "21: namespace {",
      "23: using ::testing::MatchesRegex;",
      "25: TEST(PathUtilsTest, StreamsDirectory) {",
      "26:   EXPECT_THAT(StreamsDirectory(\"/path/to/snapshot\"),",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "17: #include \"tensorflow/tsl/platform/status_matchers.h\"",
      "19: #include \"tensorflow/tsl/protobuf/error_codes.pb.h\"",
      "25: using ::testing::HasSubstr;",
      "27: using ::testing::Pair;",
      "28: using tsl::testing::IsOkAndHolds;",
      "29: using tsl::testing::StatusIs;",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "51:           \"/path/to/snapshot.streams.stream_0.splits.source_1.split_2_3\"));",
      "52: }",
      "54: TEST(PathUtilsTest, StreamDoneFilePath) {",
      "55:   EXPECT_THAT(StreamDoneFilePath(\"/path/to/snapshot\", /*stream_index=*/0),",
      "56:               MatchesRegex(\"/path/to/snapshot.streams.stream_0.DONE\"));",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "60: TEST(PathUtilsTest, SplitIndex) {",
      "61:   EXPECT_THAT(SplitIndex(\"split_0_1\"), IsOkAndHolds(Pair(0, 1)));",
      "62: }",
      "64: TEST(PathUtilsTest, InvalidSplitFile) {",
      "65:   EXPECT_THAT(",
      "66:       SplitIndex(\"\"),",
      "67:       StatusIs(error::INVALID_ARGUMENT,",
      "68:                HasSubstr(",
      "69:                    \"Expected split_<local_split_index>_<global_split_index>\")));",
      "70:   EXPECT_THAT(",
      "71:       SplitIndex(\"split_123\"),",
      "72:       StatusIs(error::INVALID_ARGUMENT,",
      "73:                HasSubstr(",
      "74:                    \"Expected split_<local_split_index>_<global_split_index>\")));",
      "75:   EXPECT_THAT(",
      "76:       SplitIndex(\"split_-1_(-1)\"),",
      "77:       StatusIs(error::INVALID_ARGUMENT,",
      "78:                HasSubstr(",
      "79:                    \"Expected split_<local_split_index>_<global_split_index>\")));",
      "80:   EXPECT_THAT(",
      "81:       SplitIndex(\"split_5_0\"),",
      "82:       StatusIs(",
      "83:           error::INVALID_ARGUMENT,",
      "84:           HasSubstr(",
      "85:               \"The local split index 5 exceeds the global split index 0\")));",
      "86: }",
      "",
      "---------------"
    ],
    "tensorflow/core/data/service/snapshot/snapshot_manager.cc||tensorflow/core/data/service/snapshot/snapshot_manager.cc": [
      "File: tensorflow/core/data/service/snapshot/snapshot_manager.cc -> tensorflow/core/data/service/snapshot/snapshot_manager.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "205:     if (local_split_index > split_filenames.size() - 1) {",
      "206:       return InvalidArgument(",
      "207:           \"found conflict between the number of splits and name of \",",
      "",
      "[Removed Lines]",
      "190:     std::vector<std::string> tokens = absl::StrSplit(split_filename, '_');",
      "191:     int64_t local_split_index;",
      "192:     int64_t global_split_index;",
      "193:     if (tokens.size() != 3 ||",
      "194:         !absl::SimpleAtoi(tokens[1], &local_split_index) ||",
      "195:         local_split_index < 0 ||",
      "196:         !absl::SimpleAtoi(tokens[2], &global_split_index) ||",
      "197:         global_split_index < 0) {",
      "198:       return InvalidArgument(\"can't parse the name of \", split_path);",
      "199:     }",
      "200:     if (local_split_index > global_split_index) {",
      "201:       return InvalidArgument(",
      "202:           \"found conflict between local split index and global split index in \",",
      "203:           \"name of \", split_path);",
      "204:     }",
      "",
      "[Added Lines]",
      "190:     TF_ASSIGN_OR_RETURN(auto split_index, SplitIndex(split_filename));",
      "191:     auto [local_split_index, global_split_index] = split_index;",
      "",
      "---------------"
    ],
    "tensorflow/core/data/tfdataz_metrics.cc||tensorflow/core/data/tfdataz_metrics.cc": [
      "File: tensorflow/core/data/tfdataz_metrics.cc -> tensorflow/core/data/tfdataz_metrics.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "88:   return absl::Duration(absl::Microseconds(interval_latency)) / interval_count;",
      "89: }",
      "94: void TfDatazMetricsCollector::RecordGetNextLatency(",
      "95:     int64_t get_next_latency_usec) {",
      "",
      "[Removed Lines]",
      "91: TfDatazMetricsCollector::TfDatazMetricsCollector(const Env& env)",
      "92:     : latency_estimator_(env) {}",
      "",
      "[Added Lines]",
      "91: TfDatazMetricsCollector::TfDatazMetricsCollector(const Env& env,",
      "92:                                                  IteratorBase* iterator)",
      "93:     : iterator_(iterator), latency_estimator_(env) {}",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "113:       ApproximateLatencyEstimator::Duration::kSixtyMinutes);",
      "114: }",
      "116: namespace {",
      "117: static mutex* get_tfdataz_metrics_registry_lock() {",
      "118:   static mutex tfdataz_metrics_registry_lock(LINKER_INITIALIZED);",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "117: int64_t TfDatazMetricsCollector::GetIteratorTotalMemoryUsage() {",
      "118:   return iterator_->TotalBufferedBytes();",
      "119: }",
      "",
      "---------------"
    ],
    "tensorflow/core/data/tfdataz_metrics.h||tensorflow/core/data/tfdataz_metrics.h": [
      "File: tensorflow/core/data/tfdataz_metrics.h -> tensorflow/core/data/tfdataz_metrics.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "26: #include \"absl/container/flat_hash_set.h\"",
      "27: #include \"absl/time/time.h\"",
      "28: #include \"tensorflow/core/platform/env.h\"",
      "29: #include \"tensorflow/core/platform/mutex.h\"",
      "30: #include \"tensorflow/core/platform/thread_annotations.h\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "28: #include \"tensorflow/core/framework/dataset.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "101:   void RecordGetNextLatency(int64_t get_next_latency_usec);",
      "",
      "[Removed Lines]",
      "98:   explicit TfDatazMetricsCollector(const Env& env);",
      "",
      "[Added Lines]",
      "99:   TfDatazMetricsCollector(const Env& env, IteratorBase* iterator);",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "110:   absl::Duration GetAverageLatencyForLastSixtyMinutes();",
      "112:  private:",
      "113:   ApproximateLatencyEstimator latency_estimator_;",
      "114: };",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "116:   int64_t GetIteratorTotalMemoryUsage();",
      "119:   IteratorBase* iterator_;  // not owned",
      "",
      "---------------"
    ],
    "tensorflow/core/data/tfdataz_metrics_test.cc||tensorflow/core/data/tfdataz_metrics_test.cc": [
      "File: tensorflow/core/data/tfdataz_metrics_test.cc -> tensorflow/core/data/tfdataz_metrics_test.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "18: #include <utility>",
      "20: #include \"absl/time/time.h\"",
      "22: #include \"tensorflow/core/platform/env.h\"",
      "23: #include \"tensorflow/core/platform/test.h\"",
      "24: #include \"tensorflow/core/util/fake_clock_env.h\"",
      "",
      "[Removed Lines]",
      "21: #include \"tensorflow/core/framework/types.h\"",
      "",
      "[Added Lines]",
      "21: #include \"tensorflow/core/framework/dataset.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "41:  protected:",
      "42:   void SetUp() override {",
      "43:     env_ = std::make_unique<FakeClockEnv>(Env::Default());",
      "45:   }",
      "47:   void TearDown() override {",
      "",
      "[Removed Lines]",
      "44:     tfdataz_metrics_ = std::make_unique<TfDatazMetricsCollector>(*env_);",
      "",
      "[Added Lines]",
      "44:     tfdataz_metrics_ =",
      "45:         std::make_unique<TfDatazMetricsCollector>(*env_, iterator_.get());",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "49:     tfdataz_metrics_.reset();",
      "50:   }",
      "52:   std::unique_ptr<FakeClockEnv> env_;",
      "53:   std::unique_ptr<TfDatazMetricsCollector> tfdataz_metrics_;",
      "54: };",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "53:   std::unique_ptr<IteratorBase> iterator_;",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "184: };",
      "186: TEST(TfDatazMetricsRegistryTest, Register) {",
      "192:   ScopedTfDataMetricsRegistration scoped_registration_one(collector_one);",
      "193:   ScopedTfDataMetricsRegistration scoped_registration_two(collector_two);",
      "",
      "[Removed Lines]",
      "187:   auto collector_one =",
      "188:       std::make_shared<TfDatazMetricsCollector>(*Env::Default());",
      "189:   auto collector_two =",
      "190:       std::make_shared<TfDatazMetricsCollector>(*Env::Default());",
      "",
      "[Added Lines]",
      "189:   std::unique_ptr<IteratorBase> iterator;",
      "190:   auto collector_one = std::make_shared<TfDatazMetricsCollector>(",
      "192:   auto collector_two = std::make_shared<TfDatazMetricsCollector>(",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "196: }",
      "198: TEST(TfDatazMetricsRegistryTest, Deregister) {",
      "205:   ScopedTfDataMetricsRegistration scoped_registration_one(collector_one);",
      "206:   ScopedTfDataMetricsRegistration scoped_registration_two(collector_two);",
      "207:   ScopedTfDataMetricsRegistration scoped_registration_three(collector_three);",
      "",
      "[Removed Lines]",
      "199:   auto collector_one =",
      "200:       std::make_shared<TfDatazMetricsCollector>(*Env::Default());",
      "201:   auto collector_two =",
      "202:       std::make_shared<TfDatazMetricsCollector>(*Env::Default());",
      "203:   auto collector_three =",
      "204:       std::make_shared<TfDatazMetricsCollector>(*Env::Default());",
      "",
      "[Added Lines]",
      "202:   std::unique_ptr<IteratorBase> iterator;",
      "203:   auto collector_one = std::make_shared<TfDatazMetricsCollector>(",
      "205:   auto collector_two = std::make_shared<TfDatazMetricsCollector>(",
      "207:   auto collector_three = std::make_shared<TfDatazMetricsCollector>(",
      "",
      "---------------"
    ],
    "tensorflow/core/distributed_runtime/eager/remote_mgr.cc||tensorflow/core/distributed_runtime/eager/remote_mgr.cc": [
      "File: tensorflow/core/distributed_runtime/eager/remote_mgr.cc -> tensorflow/core/distributed_runtime/eager/remote_mgr.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "33:   error_source_proto.set_error_source(",
      "34:       core::platform::ErrorSourceProto::EAGER_REMOTE_MGR);",
      "35:   error.SetPayload(tensorflow::kErrorSource,",
      "37:   return error;",
      "38: }",
      "39: }  // namespace",
      "",
      "[Removed Lines]",
      "36:                    error_source_proto.SerializeAsString());",
      "",
      "[Added Lines]",
      "36:                    absl::Cord(error_source_proto.SerializeAsString()));",
      "",
      "---------------"
    ],
    "tensorflow/core/distributed_runtime/integration_test/coordination_test_opkernel_registration.cc||tensorflow/core/distributed_runtime/integration_test/coordination_test_opkernel_registration.cc": [
      "File: tensorflow/core/distributed_runtime/integration_test/coordination_test_opkernel_registration.cc -> tensorflow/core/distributed_runtime/integration_test/coordination_test_opkernel_registration.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "149:     }",
      "150:     tensorflow::Status s(static_cast<tensorflow::error::Code>(error_code),",
      "151:                          error_message);",
      "153:     OP_REQUIRES_OK(ctx, coord_agent->ReportError(s));",
      "154:   }",
      "155: };",
      "",
      "[Removed Lines]",
      "152:     s.SetPayload(tsl::CoordinationErrorPayloadKey(), \"testing error payload\");",
      "",
      "[Added Lines]",
      "152:     s.SetPayload(tsl::CoordinationErrorPayloadKey(),",
      "153:                  absl::Cord(\"testing error payload\"));",
      "",
      "---------------"
    ],
    "tensorflow/core/framework/dataset.h||tensorflow/core/framework/dataset.h": [
      "File: tensorflow/core/framework/dataset.h -> tensorflow/core/framework/dataset.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "959:     return OkStatus();",
      "960:   }",
      "962:  protected:",
      "964:   virtual std::shared_ptr<model::Node> CreateNode(",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "964:   int64_t TotalBufferedBytes() const {",
      "965:     if (node_) return node_->TotalBufferedBytes();",
      "966:     return 0;",
      "967:   }",
      "",
      "---------------"
    ],
    "tensorflow/core/framework/op_requires.h||tensorflow/core/framework/op_requires.h": [
      "File: tensorflow/core/framework/op_requires.h -> tensorflow/core/framework/op_requires.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "62:     if (!TF_PREDICT_TRUE(STATUS.ok())) {                                       \\",
      "63:       CheckNotInComputeAsync((CTX), \"OP_REQUIRES_OK_ASYNC\");                   \\",
      "64:       if (!PAYLOAD_VALUE.empty()) {                                            \\",
      "66:       }                                                                        \\",
      "67:       (CTX)->CtxFailureWithWarning(__FILE__, __LINE__, STATUS);                \\",
      "68:       return;                                                                  \\",
      "",
      "[Removed Lines]",
      "65:         STATUS.SetPayload(PAYLOAD_KEY, PAYLOAD_VALUE);                         \\",
      "",
      "[Added Lines]",
      "65:         STATUS.SetPayload(PAYLOAD_KEY, absl::Cord(PAYLOAD_VALUE));             \\",
      "",
      "---------------"
    ],
    "tensorflow/core/kernels/data/iterator_ops.cc||tensorflow/core/kernels/data/iterator_ops.cc": [
      "File: tensorflow/core/kernels/data/iterator_ops.cc -> tensorflow/core/kernels/data/iterator_ops.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "94:       output_dtypes_(output_dtypes),",
      "95:       output_shapes_(output_shapes) {",
      "98:   VLOG(2) << \"creating iterator resource\";",
      "99: }",
      "",
      "[Removed Lines]",
      "96:   tf_dataz_metrics_collector_ = std::make_shared<TfDatazMetricsCollector>(*env);",
      "97:   TfDatazMetricsRegistry::Register(tf_dataz_metrics_collector_);",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "274:   new_state->MergeCheckpoint(iter_ctx.checkpoint());",
      "275:   mutex_lock l(mu_);",
      "276:   std::swap(iterator_state_, new_state);",
      "277:   return OkStatus();",
      "278: }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "275:   tf_dataz_metrics_collector_ =",
      "276:       std::make_shared<TfDatazMetricsCollector>(env_, iterator.get());",
      "277:   TfDatazMetricsRegistry::Register(tf_dataz_metrics_collector_);",
      "",
      "---------------"
    ],
    "tensorflow/core/kernels/function_ops.cc||tensorflow/core/kernels/function_ops.cc": [
      "File: tensorflow/core/kernels/function_ops.cc -> tensorflow/core/kernels/function_ops.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "238:     OP_REQUIRES_OK_ASYNC(",
      "239:         ctx, lib->Instantiate(kGradientOp, AttrSlice(def()), &handle), done);",
      "242:     opts.rendezvous = ctx->rendezvous();",
      "243:     opts.cancellation_manager = ctx->cancellation_manager();",
      "244:     opts.collective_executor = ctx->collective_executor();",
      "",
      "[Removed Lines]",
      "241:     FunctionLibraryRuntime::Options opts;",
      "",
      "[Added Lines]",
      "241:     FunctionLibraryRuntime::Options opts(ctx->step_id());",
      "",
      "---------------"
    ],
    "tensorflow/core/kernels/functional_ops.cc||tensorflow/core/kernels/functional_ops.cc": [
      "File: tensorflow/core/kernels/functional_ops.cc -> tensorflow/core/kernels/functional_ops.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "160:           then_handle_(then_handle),",
      "161:           else_handle_(else_handle),",
      "162:           done_(std::move(done)),",
      "164:       SetRunOptions(ctx_, &opts_, true /* always_collect_stats */);",
      "165:       for (int i = 1; i < ctx_->num_inputs(); ++i) {",
      "166:         args_.push_back(ctx_->input(i));",
      "",
      "[Removed Lines]",
      "163:           lib_(CHECK_NOTNULL(ctx_->function_library())) {",
      "",
      "[Added Lines]",
      "163:           lib_(CHECK_NOTNULL(ctx_->function_library())),",
      "164:           opts_(ctx->step_id()) {",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "286:           branch_(branch),",
      "287:           branch_handles_(branch_handles),",
      "288:           done_(std::move(done)),",
      "290:       SetRunOptions(ctx_, &opts_, true /* always_collect_stats */);",
      "291:       for (int i = 1; i < ctx_->num_inputs(); ++i) {",
      "292:         args_.push_back(ctx_->input(i));",
      "",
      "[Removed Lines]",
      "289:           lib_(CHECK_NOTNULL(ctx_->function_library())) {",
      "",
      "[Added Lines]",
      "290:           lib_(CHECK_NOTNULL(ctx_->function_library())),",
      "291:           opts_(ctx->step_id()) {",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "507:           cond_handle_(cond_handle),",
      "508:           body_handle_(body_handle),",
      "509:           done_(std::move(done)),",
      "511:       SetRunOptions(ctx_, &opts_, false /* always_collect_stats */);",
      "512:       GetArgsFromContext(ctx, &args_, &loop_var_types_);",
      "513:       body_frame_ =",
      "",
      "[Removed Lines]",
      "510:           lib_(CHECK_NOTNULL(ctx_->function_library())) {",
      "",
      "[Added Lines]",
      "512:           lib_(CHECK_NOTNULL(ctx_->function_library())),",
      "513:           opts_(ctx->step_id()) {",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "751:           ctx_(ctx),",
      "752:           done_(std::move(done)),",
      "753:           lib_(CHECK_NOTNULL(ctx_->function_library())),",
      "754:           args_(1 + ctx_->num_inputs() - 3) {",
      "755:       args_[0] = Tensor(DT_INT32, {});",
      "756:       iter_ = &args_[0].scalar<int32>()();",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "757:           opts_(ctx->step_id()),",
      "",
      "---------------"
    ],
    "tensorflow/core/kernels/rnn/gru_ops.cc||tensorflow/core/kernels/rnn/gru_ops.cc": [
      "File: tensorflow/core/kernels/rnn/gru_ops.cc -> tensorflow/core/kernels/rnn/gru_ops.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "49:     const Tensor* b_c_tensor = nullptr;",
      "50:     OP_REQUIRES_OK(ctx, ctx->input(\"b_c\", &b_c_tensor));",
      "52:     const int64_t batch_size = x_tensor->dim_size(0);",
      "53:     const int64_t input_size = x_tensor->dim_size(1);",
      "59:     OP_REQUIRES(ctx, h_prev_tensor->dim_size(0) == batch_size,",
      "60:                 errors::InvalidArgument(\"h_prev.dims(0) != batch_size: \",",
      "61:                                         h_prev_tensor->dim_size(0), \" vs. \",",
      "62:                                         batch_size));",
      "69:     OP_REQUIRES(ctx, w_ru_tensor->dim_size(0) == input_size + cell_size,",
      "70:                 errors::InvalidArgument(",
      "71:                     \"w_ru.dim_size(0) != input_size + cell_size: \",",
      "72:                     w_ru_tensor->dim_size(0), \" vs. \", input_size + cell_size));",
      "74:     OP_REQUIRES(ctx, w_ru_tensor->dim_size(1) == cell_size * 2,",
      "75:                 errors::InvalidArgument(\"w_ru.dim_size(1) != cell_size * 2: \",",
      "76:                                         w_ru_tensor->dim_size(1), \" vs. \",",
      "77:                                         cell_size * 2));",
      "80:     OP_REQUIRES(ctx, w_c_tensor->dim_size(0) == input_size + cell_size,",
      "81:                 errors::InvalidArgument(",
      "82:                     \"w_c.dim_size(0) != input_size + cell_size: \",",
      "83:                     w_c_tensor->dim_size(0), \" vs. \", input_size + cell_size));",
      "85:     OP_REQUIRES(ctx, w_c_tensor->dim_size(1) == cell_size,",
      "86:                 errors::InvalidArgument(",
      "87:                     \"w_c.dim_size(1) != cell_size: \", w_c_tensor->dim_size(1),",
      "88:                     \" vs. \", cell_size));",
      "91:     OP_REQUIRES(ctx, b_ru_tensor->dim_size(0) == cell_size * 2,",
      "92:                 errors::InvalidArgument(\"b_ru.dim_size(0) != cell_size * 2: \",",
      "93:                                         b_ru_tensor->dim_size(0), \" vs. \",",
      "94:                                         cell_size * 2));",
      "100:     OP_REQUIRES(ctx, b_c_tensor->dim_size(0) == cell_size,",
      "101:                 errors::InvalidArgument(",
      "102:                     \"b_c.dim_size(0) != cell_size: \", b_c_tensor->dim_size(0),",
      "103:                     \" vs. \", cell_size));",
      "109:     Tensor* r_tensor = nullptr;",
      "",
      "[Removed Lines]",
      "54:     const int64_t cell_size = h_prev_tensor->dim_size(1);",
      "63:     OP_REQUIRES(ctx, h_prev_tensor->dim_size(1) == cell_size,",
      "64:                 errors::InvalidArgument(",
      "65:                     \"h_prev.dims(1) != cell_size: \", h_prev_tensor->dim_size(1),",
      "66:                     \" vs. \", cell_size));",
      "96:     OP_REQUIRES(ctx, b_ru_tensor->dims() == 1,",
      "97:                 errors::InvalidArgument(\"Rank of b_ru must be 1\",",
      "98:                                         b_ru_tensor->dims(), \" vs. 1\", 1));",
      "104:     OP_REQUIRES(ctx, b_c_tensor->dims() == 1,",
      "105:                 errors::InvalidArgument(\"Rank of b_c must be 1\",",
      "106:                                         b_c_tensor->dims(), \" vs. 1\"));",
      "",
      "[Added Lines]",
      "55:     OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(x_tensor->shape()),",
      "56:                 errors::InvalidArgument(\"Rank of x must be 2\", x_tensor->dims(),",
      "57:                                         \" vs. 2\"));",
      "62:     OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(h_prev_tensor->shape()),",
      "63:                 errors::InvalidArgument(\"Rank of h_prev must be 2, got \",",
      "64:                                         h_prev_tensor->dims()));",
      "69:     const int64_t cell_size = h_prev_tensor->dim_size(1);",
      "72:     OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(w_ru_tensor->shape()),",
      "73:                 errors::InvalidArgument(\"Rank of w_ru_ must be 2, got \",",
      "74:                                         w_ru_tensor->dims()));",
      "85:     OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(w_c_tensor->shape()),",
      "86:                 errors::InvalidArgument(\"Rank of w_c must be 2, got \",",
      "87:                                         w_c_tensor->dims()));",
      "98:     OP_REQUIRES(ctx, TensorShapeUtils::IsVector(b_ru_tensor->shape()),",
      "99:                 errors::InvalidArgument(\"Rank of b_ru must be 1, got \",",
      "100:                                         b_ru_tensor->dims()));",
      "107:     OP_REQUIRES(ctx, TensorShapeUtils::IsVector(b_c_tensor->shape()),",
      "108:                 errors::InvalidArgument(\"Rank of b_c must be 1, got \",",
      "109:                                         b_c_tensor->dims()));",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "204:     const Tensor* d_h_tensor = nullptr;",
      "205:     OP_REQUIRES_OK(ctx, ctx->input(\"d_h\", &d_h_tensor));",
      "207:     const int64_t batch_size = x_tensor->dim_size(0);",
      "208:     const int64_t input_size = x_tensor->dim_size(1);",
      "214:     OP_REQUIRES(ctx, h_prev_tensor->dim_size(0) == batch_size,",
      "215:                 errors::InvalidArgument(\"h_prev.dims(0) != batch_size: \",",
      "216:                                         h_prev_tensor->dim_size(0), \" vs. \",",
      "217:                                         batch_size));",
      "224:     OP_REQUIRES(ctx, w_ru_tensor->dim_size(0) == input_size + cell_size,",
      "225:                 errors::InvalidArgument(",
      "226:                     \"w_ru.dim_size(0) != input_size + cell_size: \",",
      "227:                     w_ru_tensor->dim_size(0), \" vs. \", input_size + cell_size));",
      "229:     OP_REQUIRES(ctx, w_ru_tensor->dim_size(1) == cell_size * 2,",
      "230:                 errors::InvalidArgument(\"w_ru.dim_size(1) != cell_size * 2: \",",
      "231:                                         w_ru_tensor->dim_size(1), \" vs. \",",
      "232:                                         cell_size * 2));",
      "235:     OP_REQUIRES(ctx, w_c_tensor->dim_size(0) == input_size + cell_size,",
      "236:                 errors::InvalidArgument(",
      "237:                     \"w_c.dim_size(0) != input_size + cell_size: \",",
      "238:                     w_c_tensor->dim_size(0), \" vs. \", input_size + cell_size));",
      "240:     OP_REQUIRES(ctx, w_c_tensor->dim_size(1) == cell_size,",
      "241:                 errors::InvalidArgument(",
      "242:                     \"w_c.dim_size(1) != cell_size: \", w_c_tensor->dim_size(1),",
      "243:                     \" vs. \", cell_size));",
      "246:     OP_REQUIRES(ctx, b_ru_tensor->dim_size(0) == cell_size * 2,",
      "247:                 errors::InvalidArgument(\"b_ru.dim_size(0) != cell_size * 2: \",",
      "248:                                         b_ru_tensor->dim_size(0), \" vs. \",",
      "249:                                         cell_size * 2));",
      "256:     OP_REQUIRES(ctx, b_c_tensor->dim_size(0) == cell_size,",
      "257:                 errors::InvalidArgument(",
      "258:                     \"b_c.dim_size(0) != cell_size: \", b_c_tensor->dim_size(0),",
      "259:                     \" vs. \", cell_size));",
      "266:     OP_REQUIRES(ctx, r_tensor->dim_size(0) == batch_size,",
      "267:                 errors::InvalidArgument(",
      "268:                     \"r.dims(0) != batch_size: \", r_tensor->dim_size(0), \" vs. \",",
      "",
      "[Removed Lines]",
      "209:     const int64_t cell_size = h_prev_tensor->dim_size(1);",
      "218:     OP_REQUIRES(ctx, h_prev_tensor->dim_size(1) == cell_size,",
      "219:                 errors::InvalidArgument(",
      "220:                     \"h_prev.dims(1) != cell_size: \", h_prev_tensor->dim_size(1),",
      "221:                     \" vs. \", cell_size));",
      "251:     OP_REQUIRES(ctx, b_ru_tensor->dims() == 1,",
      "252:                 errors::InvalidArgument(\"Rank of b_ru must be 1\",",
      "253:                                         b_ru_tensor->dims(), \" vs. 1\"));",
      "261:     OP_REQUIRES(ctx, b_c_tensor->dims() == 1,",
      "262:                 errors::InvalidArgument(\"Rank of b_c must be 1 \",",
      "263:                                         b_c_tensor->dims(), \" vs. 1\"));",
      "",
      "[Added Lines]",
      "215:     OP_REQUIRES(",
      "216:         ctx, TensorShapeUtils::IsMatrix(x_tensor->shape()),",
      "217:         errors::InvalidArgument(\"Rank of x must be 2, got \", x_tensor->dims()));",
      "222:     OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(h_prev_tensor->shape()),",
      "223:                 errors::InvalidArgument(\"Rank of h_prev must be 2, got \",",
      "224:                                         h_prev_tensor->dims()));",
      "229:     const int64_t cell_size = h_prev_tensor->dim_size(1);",
      "232:     OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(w_ru_tensor->shape()),",
      "233:                 errors::InvalidArgument(\"Rank of w_ru_ must be 2, got \",",
      "234:                                         w_ru_tensor->dims()));",
      "245:     OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(w_c_tensor->shape()),",
      "246:                 errors::InvalidArgument(\"Rank of w_c must be 2, got \",",
      "247:                                         w_c_tensor->dims()));",
      "258:     OP_REQUIRES(ctx, TensorShapeUtils::IsVector(b_ru_tensor->shape()),",
      "259:                 errors::InvalidArgument(\"Rank of b_ru must be 1, got \",",
      "260:                                         b_ru_tensor->dims()));",
      "267:     OP_REQUIRES(ctx, TensorShapeUtils::IsVector(b_c_tensor->shape()),",
      "268:                 errors::InvalidArgument(\"Rank of b_c must be 1, got \",",
      "269:                                         b_c_tensor->dims()));",
      "276:     OP_REQUIRES(",
      "277:         ctx, TensorShapeUtils::IsMatrix(r_tensor->shape()),",
      "278:         errors::InvalidArgument(\"Rank of r must be 2, got \", r_tensor->dims()));",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "273:                     cell_size));",
      "276:     OP_REQUIRES(ctx, u_tensor->dim_size(0) == batch_size,",
      "277:                 errors::InvalidArgument(",
      "278:                     \"u.dims(0) != batch_size: \", u_tensor->dim_size(0), \" vs. \",",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "289:     OP_REQUIRES(",
      "290:         ctx, TensorShapeUtils::IsMatrix(u_tensor->shape()),",
      "291:         errors::InvalidArgument(\"Rank of u must be 2, got \", u_tensor->dims()));",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "283:                     cell_size));",
      "286:     OP_REQUIRES(ctx, c_tensor->dim_size(0) == batch_size,",
      "287:                 errors::InvalidArgument(",
      "288:                     \"c.dims(0) != batch_size: \", c_tensor->dim_size(0), \" vs. \",",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "302:     OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(c_tensor->shape()),",
      "303:                 errors::InvalidArgument(\"Rank of w_c must be 2, got \",",
      "304:                                         c_tensor->dims()));",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "293:                     cell_size));",
      "296:     OP_REQUIRES(ctx, d_h_tensor->dim_size(0) == batch_size,",
      "297:                 errors::InvalidArgument(",
      "298:                     \"d_h.dims(0) != batch_size: \", d_h_tensor->dim_size(0),",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "315:     OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(d_h_tensor->shape()),",
      "316:                 errors::InvalidArgument(\"Rank of d_h must be 2, got \",",
      "317:                                         d_h_tensor->dims()));",
      "",
      "---------------"
    ],
    "tensorflow/core/lib/core/status_test.cc||tensorflow/core/lib/core/status_test.cc": [
      "File: tensorflow/core/lib/core/status_test.cc -> tensorflow/core/lib/core/status_test.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "178: TEST(Status, InvalidPayloadGetsIgnored) {",
      "179:   Status s = Status();",
      "181:   ASSERT_FALSE(s.GetPayload(\"Invalid\").has_value());",
      "182:   bool is_err_erased = s.ErasePayload(\"Invalid\");",
      "183:   ASSERT_EQ(is_err_erased, false);",
      "",
      "[Removed Lines]",
      "180:   s.SetPayload(\"Invalid\", \"Invalid Val\");",
      "",
      "[Added Lines]",
      "180:   s.SetPayload(\"Invalid\", absl::Cord(\"Invalid Val\"));",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "186: TEST(Status, SetPayloadSetsOrUpdatesIt) {",
      "187:   Status s(error::INTERNAL, \"Error message\");",
      "189:   ASSERT_EQ(s.GetPayload(\"Error key\"), absl::Cord(\"Original\"));",
      "191:   ASSERT_EQ(s.GetPayload(\"Error key\"), absl::Cord(\"Updated\"));",
      "192: }",
      "194: TEST(Status, ErasePayloadRemovesIt) {",
      "195:   Status s(error::INTERNAL, \"Error message\");",
      "198:   bool is_err_erased = s.ErasePayload(\"Error key\");",
      "199:   ASSERT_EQ(is_err_erased, true);",
      "",
      "[Removed Lines]",
      "188:   s.SetPayload(\"Error key\", \"Original\");",
      "190:   s.SetPayload(\"Error key\", \"Updated\");",
      "196:   s.SetPayload(\"Error key\", \"Original\");",
      "",
      "[Added Lines]",
      "188:   s.SetPayload(\"Error key\", absl::Cord(\"Original\"));",
      "190:   s.SetPayload(\"Error key\", absl::Cord(\"Updated\"));",
      "196:   s.SetPayload(\"Error key\", absl::Cord(\"Original\"));",
      "",
      "---------------"
    ],
    "tensorflow/core/platform/error_payloads.cc||tensorflow/core/platform/error_payloads.cc": [
      "File: tensorflow/core/platform/error_payloads.cc -> tensorflow/core/platform/error_payloads.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "27:     ErrorSourceProto error_source_proto;",
      "28:     error_source_proto.set_error_source(error_source);",
      "29:     status.SetPayload(tensorflow::kErrorSource,",
      "31:   }",
      "32: }",
      "",
      "[Removed Lines]",
      "30:                       error_source_proto.SerializeAsString());",
      "",
      "[Added Lines]",
      "30:                       absl::Cord(error_source_proto.SerializeAsString()));",
      "",
      "---------------"
    ],
    "tensorflow/core/tpu/kernels/tpu_compile_op_common.cc||tensorflow/core/tpu/kernels/tpu_compile_op_common.cc": [
      "File: tensorflow/core/tpu/kernels/tpu_compile_op_common.cc -> tensorflow/core/tpu/kernels/tpu_compile_op_common.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "408:     SerializeToTString(proto, &output.scalar<tstring>()());",
      "409:     ctx->set_output(0, output);",
      "410:     status.SetPayload(TpuCompileInterface::kTpuCompileErrorPayloadKey,",
      "412:   }",
      "414:   if (status.ok()) {",
      "",
      "[Removed Lines]",
      "411:                       output.scalar<tstring>()());",
      "",
      "[Added Lines]",
      "411:                       absl::Cord(output.scalar<tstring>()()));",
      "",
      "---------------"
    ],
    "tensorflow/core/tpu/kernels/tpu_functional_ops.cc||tensorflow/core/tpu/kernels/tpu_functional_ops.cc": [
      "File: tensorflow/core/tpu/kernels/tpu_functional_ops.cc -> tensorflow/core/tpu/kernels/tpu_functional_ops.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "1410:   TF_RETURN_IF_ERROR(",
      "1411:       InstantiatePartition(*init_graph, fname, device, &fhandle, nullptr));",
      "1414:   opts.step_container = ctx->step_container();",
      "1415:   opts.cancellation_manager = ctx->cancellation_manager();",
      "1416:   opts.stats_collector = ctx->stats_collector();",
      "",
      "[Removed Lines]",
      "1413:   FunctionLibraryRuntime::Options opts;",
      "",
      "[Added Lines]",
      "1413:   FunctionLibraryRuntime::Options opts(ctx->step_id());",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "1569:     functions.push_back(DeviceAndFHandle{.device = target, .handle = handle});",
      "1570:   }",
      "",
      "[Removed Lines]",
      "1572:   FunctionLibraryRuntime::Options opts;",
      "",
      "[Added Lines]",
      "1572:   FunctionLibraryRuntime::Options opts(ctx->step_id());",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "2702:     const std::vector<DeviceAndFHandle>& functions, OpKernelContext* ctx,",
      "2703:     int device_ordinal, int64_t ordinal_selector_req_id, DoneCallback done) {",
      "2704:   profiler::TraceMe trace_me(\"TPUPartitionedCallOp-ExecuteFunctions\");",
      "2706:   opts.step_container = ctx->step_container();",
      "2707:   opts.stats_collector = ctx->stats_collector();",
      "",
      "[Removed Lines]",
      "2705:   FunctionLibraryRuntime::Options opts;",
      "",
      "[Added Lines]",
      "2705:   FunctionLibraryRuntime::Options opts(ctx->step_id());",
      "",
      "---------------"
    ],
    "tensorflow/core/tpu/tpu_embedding_errors.cc||tensorflow/core/tpu/tpu_embedding_errors.cc": [
      "File: tensorflow/core/tpu/tpu_embedding_errors.cc -> tensorflow/core/tpu/tpu_embedding_errors.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "29:         absl::StrCat(kTpuEmbeddingErrorMessage, \". \", obj.error_message());",
      "30:     Status status(obj.code(), error_message);",
      "31:     TPUEmbeddingError error_payload;",
      "33:     return status;",
      "34:   }",
      "35: }",
      "",
      "[Removed Lines]",
      "32:     status.SetPayload(kTpuEmbeddingErrorUrl, error_payload.SerializeAsString());",
      "",
      "[Added Lines]",
      "32:     status.SetPayload(kTpuEmbeddingErrorUrl,",
      "33:                       absl::Cord(error_payload.SerializeAsString()));",
      "",
      "---------------"
    ],
    "tensorflow/core/tpu/tpu_embedding_errors.h||tensorflow/core/tpu/tpu_embedding_errors.h": [
      "File: tensorflow/core/tpu/tpu_embedding_errors.h -> tensorflow/core/tpu/tpu_embedding_errors.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "50:         kTpuEmbeddingErrorMessage, \". \", obj.status().error_message());",
      "51:     Status status(obj.status().code(), error_message);",
      "52:     TPUEmbeddingError error_payload;",
      "54:     return status;",
      "55:   }",
      "56: }",
      "",
      "[Removed Lines]",
      "53:     status.SetPayload(kTpuEmbeddingErrorUrl, error_payload.SerializeAsString());",
      "",
      "[Added Lines]",
      "53:     status.SetPayload(kTpuEmbeddingErrorUrl,",
      "54:                       absl::Cord(error_payload.SerializeAsString()));",
      "",
      "---------------"
    ],
    "tensorflow/core/util/zen_util.h||tensorflow/core/util/zen_util.h": [
      "File: tensorflow/core/util/zen_util.h -> tensorflow/core/util/zen_util.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "24: namespace tensorflow {",
      "27:   static absl::once_flag once;",
      "28:   static int64_t mempool = 1;",
      "29:   absl::call_once(once, [&] {",
      "",
      "[Removed Lines]",
      "26: int64_t GetMempool() {",
      "",
      "[Added Lines]",
      "26: inline int64_t GetMempool() {",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "34:   return mempool;",
      "35: }",
      "38:   static absl::once_flag once;",
      "39:   static bool blocked_format = false;",
      "40:   absl::call_once(once, [&] {",
      "",
      "[Removed Lines]",
      "37: bool IsBlockedFormatEnabled() {",
      "",
      "[Added Lines]",
      "37: inline bool IsBlockedFormatEnabled() {",
      "",
      "---------------"
    ],
    "tensorflow/python/data/experimental/kernel_tests/service/snapshot_ft_test.py||tensorflow/python/data/experimental/kernel_tests/service/snapshot_ft_test.py": [
      "File: tensorflow/python/data/experimental/kernel_tests/service/snapshot_ft_test.py -> tensorflow/python/data/experimental/kernel_tests/service/snapshot_ft_test.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "131:   def testSnapshotRecoveryFailsWithBadSplitNames(self, bad_split_filename):",
      "132:     cluster, _ = self.setup()",
      "133:     write_file(os.path.join(self.source_dir(), bad_split_filename))",
      "135:       cluster.restart_dispatcher()",
      "137:   @combinations.generate(test_base.eager_only_combinations())",
      "138:   def testSnapshotRecoveryFailsWithOutOfOrderSplitName(self):",
      "139:     cluster, _ = self.setup()",
      "140:     write_file(os.path.join(self.source_dir(), \"split_1_0\"))",
      "142:       cluster.restart_dispatcher()",
      "144:   @combinations.generate(test_base.eager_only_combinations())",
      "",
      "[Removed Lines]",
      "134:     with self.assertRaisesRegex(ValueError, \"can't parse\"):",
      "141:     with self.assertRaisesRegex(ValueError, \"found conflict\"):",
      "",
      "[Added Lines]",
      "134:     with self.assertRaisesRegex(",
      "135:         ValueError, \"Expected split_<local_split_index>_<global_split_index>\"):",
      "142:     with self.assertRaisesRegex(",
      "143:         ValueError, \"The local split index 1 exceeds the global split index 0\"):",
      "",
      "---------------"
    ],
    "tensorflow/python/framework/errors_test_helper.cc||tensorflow/python/framework/errors_test_helper.cc": [
      "File: tensorflow/python/framework/errors_test_helper.cc -> tensorflow/python/framework/errors_test_helper.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "21:   m.def(\"TestRaiseFromStatus\", [](int code) {",
      "22:     tensorflow::Status status(static_cast<tensorflow::error::Code>(code),",
      "23:                               \"test message\");",
      "26:     MaybeRaiseRegisteredFromStatus(status);",
      "27:     return 0;",
      "28:   });",
      "",
      "[Removed Lines]",
      "24:     status.SetPayload(\"key1\", \"value1\");",
      "25:     status.SetPayload(\"key2\", \"value2\");",
      "",
      "[Added Lines]",
      "24:     status.SetPayload(\"key1\", absl::Cord(\"value1\"));",
      "25:     status.SetPayload(\"key2\", absl::Cord(\"value2\"));",
      "",
      "---------------"
    ],
    "tensorflow/python/tpu/tpu_strategy_util.py||tensorflow/python/tpu/tpu_strategy_util.py": [
      "File: tensorflow/python/tpu/tpu_strategy_util.py -> tensorflow/python/tpu/tpu_strategy_util.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "22: from tensorflow.python.eager import context",
      "23: from tensorflow.python.eager import monitoring",
      "24: from tensorflow.python.eager.def_function import function",
      "25: from tensorflow.python.framework import device",
      "26: from tensorflow.python.framework import errors",
      "27: from tensorflow.python.framework import ops",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "25: from tensorflow.python.eager.def_function import functions_run_eagerly",
      "26: from tensorflow.python.eager.def_function import run_functions_eagerly",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "111:     # The TPU_SYSTEM device must match the device used in tpu.initialize_system",
      "112:     # exactly, otherwise you can get errors if there are multiple TPU_SYSTEM",
      "113:     # devices available.",
      "114:     try:",
      "115:       with ops.device(tpu._tpu_system_device_name(job)):  # pylint: disable=protected-access",
      "116:         output = _tpu_init_fn()",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "116:     run_eagerly = functions_run_eagerly()",
      "117:     if run_eagerly:",
      "118:       logging.warning(",
      "119:           \"It looks like tf.function behavior was disabled, perhaps using\"",
      "120:           \" tf.config.run_functions_eagerly.\"",
      "121:           \" tf.tpu.experimental.initialize_tpu_system requires tf.function to\"",
      "122:           \" work. This primitive will override the disable.\"",
      "123:       )",
      "124:     run_functions_eagerly(False)",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "120:           None, None,",
      "121:           \"TPUs not found in the cluster. Failed in initialization: \"",
      "122:           + str(e))",
      "124:     # Clear out the eager context caches since the memory is invalid now.",
      "125:     context.context()._initialize_logical_devices()  # pylint: disable=protected-access",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "134:     finally:",
      "135:       if run_eagerly is not None:",
      "136:         run_functions_eagerly(run_eagerly)",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "221:     # The TPU_SYSTEM device must match the device used in tpu.shutdown_system",
      "222:     # exactly, otherwise you can get errors if there are multiple TPU_SYSTEM",
      "223:     # devices available.",
      "227:     # Clear out the eager context caches since the memory is invalid now.",
      "228:     logging.info(\"Clearing out eager caches\")",
      "",
      "[Removed Lines]",
      "224:     with ops.device(tpu._tpu_system_device_name(job)):  # pylint: disable=protected-access",
      "225:       _tpu_shutdown_fn()",
      "",
      "[Added Lines]",
      "237:     run_eagerly = functions_run_eagerly()",
      "238:     if run_eagerly:",
      "239:       logging.warning(",
      "240:           \"It looks like tf.function behavior was disabled, perhaps using\"",
      "241:           \" tf.config.run_functions_eagerly.\"",
      "242:           \" tf.tpu.experimental.shutdown_tpu_system requires tf.function to\"",
      "243:           \" work. This primitive will override the disable.\"",
      "244:       )",
      "245:     run_functions_eagerly(False)",
      "246:     try:",
      "247:       with ops.device(tpu._tpu_system_device_name(job)):  # pylint: disable=protected-access",
      "248:         _tpu_shutdown_fn()",
      "249:     finally:",
      "250:       if run_eagerly is not None:",
      "251:         run_functions_eagerly(run_eagerly)",
      "",
      "---------------"
    ],
    "tensorflow/tsl/c/tsl_status.cc||tensorflow/tsl/c/tsl_status.cc": [
      "File: tensorflow/tsl/c/tsl_status.cc -> tensorflow/tsl/c/tsl_status.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "36: }",
      "38: void TSL_SetPayload(TSL_Status* s, const char* key, const char* value) {",
      "40: }",
      "42: void TSL_SetStatusFromIOError(TSL_Status* s, int error_code,",
      "",
      "[Removed Lines]",
      "39:   s->status.SetPayload(key, value);",
      "",
      "[Added Lines]",
      "39:   s->status.SetPayload(key, absl::Cord(absl::string_view(value)));",
      "",
      "---------------"
    ],
    "tensorflow/tsl/c/tsl_status_helper_test.cc||tensorflow/tsl/c/tsl_status_helper_test.cc": [
      "File: tensorflow/tsl/c/tsl_status_helper_test.cc -> tensorflow/tsl/c/tsl_status_helper_test.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "24: TEST(StatusHelper, TestStatusHelper) {",
      "25:   TSL_Status* s = TSL_NewStatus();",
      "26:   Status cc_status(errors::InvalidArgument(\"some error\"));",
      "29:   Set_TSL_Status_from_Status(s, cc_status);",
      "30:   ASSERT_EQ(TSL_INVALID_ARGUMENT, TSL_GetCode(s));",
      "31:   ASSERT_EQ(std::string(\"some error\"), TSL_Message(s));",
      "",
      "[Removed Lines]",
      "27:   cc_status.SetPayload(\"key1\", \"value1\");",
      "28:   cc_status.SetPayload(\"key2\", \"value2\");",
      "",
      "[Added Lines]",
      "27:   cc_status.SetPayload(\"key1\", absl::Cord(\"value1\"));",
      "28:   cc_status.SetPayload(\"key2\", absl::Cord(\"value2\"));",
      "",
      "---------------"
    ],
    "tensorflow/tsl/distributed_runtime/coordination/coordination_service_error_util.h||tensorflow/tsl/distributed_runtime/coordination/coordination_service_error_util.h": [
      "File: tensorflow/tsl/distributed_runtime/coordination/coordination_service_error_util.h -> tensorflow/tsl/distributed_runtime/coordination/coordination_service_error_util.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "31: inline Status MakeCoordinationError(Status s) {",
      "33:   return s;",
      "34: }",
      "",
      "[Removed Lines]",
      "32:   s.SetPayload(CoordinationErrorPayloadKey(), \"\");",
      "",
      "[Added Lines]",
      "32:   s.SetPayload(CoordinationErrorPayloadKey(), absl::Cord(\"\"));",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "43:   tensorflow::CoordinationServiceError error;",
      "45:   error.set_is_reported_error(is_reported_error);",
      "47:   return s;",
      "48: }",
      "51: inline Status MakeCoordinationError(",
      "52:     Status s, const tensorflow::CoordinationServiceError& payload) {",
      "54:   return s;",
      "55: }",
      "56: }  // namespace tsl",
      "",
      "[Removed Lines]",
      "46:   s.SetPayload(CoordinationErrorPayloadKey(), error.SerializeAsString());",
      "53:   s.SetPayload(CoordinationErrorPayloadKey(), payload.SerializeAsString());",
      "",
      "[Added Lines]",
      "46:   s.SetPayload(CoordinationErrorPayloadKey(),",
      "47:                absl::Cord(error.SerializeAsString()));",
      "54:   s.SetPayload(CoordinationErrorPayloadKey(),",
      "55:                absl::Cord(payload.SerializeAsString()));",
      "",
      "---------------"
    ],
    "tensorflow/tsl/distributed_runtime/rpc/grpc_util.h||tensorflow/tsl/distributed_runtime/rpc/grpc_util.h": [
      "File: tensorflow/tsl/distributed_runtime/rpc/grpc_util.h -> tensorflow/tsl/distributed_runtime/rpc/grpc_util.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "71:   tensorflow::distributed_runtime::GrpcPayloadContainer container;",
      "72:   if (container.ParseFromString(payloads)) {",
      "73:     for (const auto& key_val : container.payloads()) {",
      "75:     }",
      "76:   } else {",
      "77:     s.SetPayload(kGrpcPayloadsLost,",
      "80:   }",
      "81: }",
      "",
      "[Removed Lines]",
      "74:       s.SetPayload(key_val.first, key_val.second);",
      "78:                  tensorflow::distributed_runtime::GrpcPayloadsLost()",
      "79:                      .SerializeAsString());",
      "",
      "[Added Lines]",
      "74:       s.SetPayload(key_val.first, absl::Cord(key_val.second));",
      "78:                  absl::Cord(tensorflow::distributed_runtime::GrpcPayloadsLost()",
      "79:                                 .SerializeAsString()));",
      "",
      "---------------"
    ],
    "tensorflow/tsl/distributed_runtime/rpc/grpc_util_test.cc||tensorflow/tsl/distributed_runtime/rpc/grpc_util_test.cc": [
      "File: tensorflow/tsl/distributed_runtime/rpc/grpc_util_test.cc -> tensorflow/tsl/distributed_runtime/rpc/grpc_util_test.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "72: TEST(PayloadSerialization, PayloadsAreTransmitted) {",
      "73:   Status status = errors::InvalidArgument(\"invalid arg message\");",
      "75:   Status status_recovered = FromGrpcStatus(ToGrpcStatus(status));",
      "77:   ASSERT_TRUE(status_recovered.GetPayload(\"a\").has_value());",
      "",
      "[Removed Lines]",
      "74:   status.SetPayload(\"a\", \"\\\\xFF\\\\x02\\\\x03\");",
      "",
      "[Added Lines]",
      "74:   status.SetPayload(\"a\", absl::Cord(\"\\\\xFF\\\\x02\\\\x03\"));",
      "",
      "---------------"
    ],
    "tensorflow/tsl/platform/errors.h||tensorflow/tsl/platform/errors.h": [
      "File: tensorflow/tsl/platform/errors.h -> tensorflow/tsl/platform/errors.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "21: #include <utility>",
      "23: #include \"absl/base/attributes.h\"",
      "24: #include \"absl/strings/str_join.h\"",
      "25: #include \"tensorflow/tsl/platform/logging.h\"",
      "26: #include \"tensorflow/tsl/platform/macros.h\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "24: #include \"absl/strings/cord.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "102:     ::tsl::Status& status,",
      "103:     const std::unordered_map<std::string, std::string>& payloads) {",
      "104:   for (const auto& payload : payloads) {",
      "106:   }",
      "107: }",
      "",
      "[Removed Lines]",
      "105:     status.SetPayload(payload.first, payload.second);",
      "",
      "[Added Lines]",
      "106:     status.SetPayload(payload.first, absl::Cord(payload.second));",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "111: inline void CopyPayloads(const ::tsl::Status& from, ::tsl::Status& to) {",
      "112:   from.ForEachPayload([&to](tsl::StringPiece key, tsl::StringPiece value) {",
      "114:   });",
      "115: }",
      "",
      "[Removed Lines]",
      "113:     to.SetPayload(key, value);",
      "",
      "[Added Lines]",
      "114:     to.SetPayload(key, absl::Cord(value));",
      "",
      "---------------"
    ],
    "tensorflow/tsl/platform/test.h||tensorflow/tsl/platform/test.h": [
      "File: tensorflow/tsl/platform/test.h -> tensorflow/tsl/platform/test.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "86: int PickUnusedPortOrDie();",
      "88: }  // namespace testing",
      "89: }  // namespace tsl",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "89: #ifdef PLATFORM_GOOGLE",
      "90: inline constexpr bool kIsOpenSource = false;",
      "91: #else",
      "92: inline constexpr bool kIsOpenSource = true;",
      "93: #endif  // PLATFORM_GOOGLE",
      "",
      "---------------"
    ],
    "tensorflow/tsl/profiler/lib/traceme_encode.h||tensorflow/tsl/profiler/lib/traceme_encode.h": [
      "File: tensorflow/tsl/profiler/lib/traceme_encode.h -> tensorflow/tsl/profiler/lib/traceme_encode.h",
      "--- Hunk 1 ---",
      "[Context before]",
      "20: #include <initializer_list>",
      "21: #include <string>",
      "23: #include \"absl/strings/match.h\"",
      "24: #include \"absl/strings/str_cat.h\"",
      "25: #include \"absl/strings/string_view.h\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "23: #include \"absl/base/attributes.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "33: struct TraceMeArg {",
      "38:   TF_DISALLOW_COPY_AND_ASSIGN(TraceMeArg);",
      "40:   absl::string_view key;",
      "42: };",
      "44: namespace traceme_internal {",
      "",
      "[Removed Lines]",
      "35:   template <typename Value>",
      "36:   TraceMeArg(absl::string_view k, Value v) : key(k), value(v) {}",
      "41:   absl::AlphaNum value;",
      "",
      "[Added Lines]",
      "42:   TraceMeArg(absl::string_view k,",
      "43:              const absl::AlphaNum& v ABSL_ATTRIBUTE_LIFETIME_BOUND)",
      "44:       : key(k), value(v.Piece()) {}",
      "49:   absl::string_view value;",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "74:     for (const auto& arg : args) {",
      "75:       out = Append(out, arg.key);",
      "79:     }",
      "",
      "[Removed Lines]",
      "77:       out = Append(out, arg.value.Piece());",
      "",
      "[Added Lines]",
      "85:       out = Append(out, arg.value);",
      "",
      "---------------"
    ],
    "tensorflow/tsl/profiler/lib/traceme_encode_test.cc||tensorflow/tsl/profiler/lib/traceme_encode_test.cc": [
      "File: tensorflow/tsl/profiler/lib/traceme_encode_test.cc -> tensorflow/tsl/profiler/lib/traceme_encode_test.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "17: #include <string>",
      "19: #include \"absl/strings/str_cat.h\"",
      "20: #include \"tensorflow/tsl/platform/platform.h\"",
      "21: #include \"tensorflow/tsl/platform/test.h\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "20: #include \"absl/strings/str_format.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "53: }",
      "54: #endif",
      "56: TEST(TraceMeEncodeTest, NoNameTest) {",
      "57:   EXPECT_EQ(TraceMeEncode({{\"context\", \"World\"}, {\"request_id\", 42}}),",
      "58:             \"#context=World,request_id=42#\");",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "59: #if defined(PLATFORM_GOOGLE)",
      "61: struct Point {",
      "62:   template <typename Sink>",
      "63:   friend void AbslStringify(Sink& sink, const Point& p) {",
      "64:     absl::Format(&sink, \"(%d, %d)\", p.x, p.y);",
      "65:   }",
      "67:   int x;",
      "68:   int y;",
      "69: };",
      "71: TEST(TraceMeEncodeTest, AbslStringifyTest) {",
      "72:   EXPECT_EQ(TraceMeEncode(\"Plot\", {{\"point\", Point{10, 20}}}),",
      "73:             \"Plot#point=(10, 20)#\");",
      "74: }",
      "76: #endif",
      "",
      "---------------"
    ],
    "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl": [
      "File: third_party/tf_runtime/workspace.bzl -> third_party/tf_runtime/workspace.bzl",
      "--- Hunk 1 ---",
      "[Context before]",
      "6:     \"\"\"Imports TFRT.\"\"\"",
      "8:     # Attention: tools parse and update these lines.",
      "12:     tf_http_archive(",
      "13:         name = \"tf_runtime\",",
      "",
      "[Removed Lines]",
      "9:     TFRT_COMMIT = \"c1248a015d23949afa2471bb21f6f52850aead7d\"",
      "10:     TFRT_SHA256 = \"8cdd8ea905478ac4ffd36ffb39cebe288d3b840d71a02d418bc6a8a760f92af8\"",
      "",
      "[Added Lines]",
      "9:     TFRT_COMMIT = \"c653281a1a23c0c3d41536a983c7d10fcc5b1fbf\"",
      "10:     TFRT_SHA256 = \"3d1edd27c4e36d9cfc9493aef7088489babb370d2a7955bab3545acfbb024ccf\"",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "eccc765511e08d727be0a15157550f6a330dbea4",
      "candidate_info": {
        "commit_hash": "eccc765511e08d727be0a15157550f6a330dbea4",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/eccc765511e08d727be0a15157550f6a330dbea4",
        "files": [
          "tensorflow/core/data/service/dispatcher.proto",
          "tensorflow/core/data/service/dispatcher_client.cc",
          "tensorflow/core/data/service/dispatcher_client.h",
          "tensorflow/core/data/service/dispatcher_client_test.cc",
          "tensorflow/core/data/service/snapshot/path_utils.cc",
          "tensorflow/core/data/service/snapshot/path_utils.h",
          "tensorflow/core/data/service/snapshot/path_utils_test.cc",
          "tensorflow/core/data/service/snapshot/snapshot_manager.cc",
          "tensorflow/core/data/service/snapshot/snapshot_manager.h",
          "tensorflow/core/data/service/snapshot/snapshot_split_provider.cc",
          "tensorflow/core/data/service/snapshot/snapshot_split_provider.h",
          "tensorflow/core/data/service/snapshot/snapshot_split_provider_test.cc",
          "tensorflow/python/data/experimental/kernel_tests/service/distributed_save_ft_test.py",
          "tensorflow/python/data/experimental/kernel_tests/service/distributed_save_test.py"
        ],
        "message": "#tf-data-service Distributed snapshot supports repetition.\n\nCurrently, when a split provider is exhausted, it's considered\nfinished. This change resets a source if requested. The logic\nis similar to how dynamic sharding handles repetitions.\n\nThe splits directory structure is now\nstreams/stream_i/splits/source_j/repetition_k/split_*_*.\n\nPiperOrigin-RevId: 532571816",
        "before_after_code_files": [
          "tensorflow/core/data/service/dispatcher.proto||tensorflow/core/data/service/dispatcher.proto",
          "tensorflow/core/data/service/dispatcher_client.cc||tensorflow/core/data/service/dispatcher_client.cc",
          "tensorflow/core/data/service/dispatcher_client.h||tensorflow/core/data/service/dispatcher_client.h",
          "tensorflow/core/data/service/dispatcher_client_test.cc||tensorflow/core/data/service/dispatcher_client_test.cc",
          "tensorflow/core/data/service/snapshot/path_utils.cc||tensorflow/core/data/service/snapshot/path_utils.cc",
          "tensorflow/core/data/service/snapshot/path_utils.h||tensorflow/core/data/service/snapshot/path_utils.h",
          "tensorflow/core/data/service/snapshot/path_utils_test.cc||tensorflow/core/data/service/snapshot/path_utils_test.cc",
          "tensorflow/core/data/service/snapshot/snapshot_manager.cc||tensorflow/core/data/service/snapshot/snapshot_manager.cc",
          "tensorflow/core/data/service/snapshot/snapshot_manager.h||tensorflow/core/data/service/snapshot/snapshot_manager.h",
          "tensorflow/core/data/service/snapshot/snapshot_split_provider.cc||tensorflow/core/data/service/snapshot/snapshot_split_provider.cc",
          "tensorflow/core/data/service/snapshot/snapshot_split_provider.h||tensorflow/core/data/service/snapshot/snapshot_split_provider.h",
          "tensorflow/core/data/service/snapshot/snapshot_split_provider_test.cc||tensorflow/core/data/service/snapshot/snapshot_split_provider_test.cc",
          "tensorflow/python/data/experimental/kernel_tests/service/distributed_save_ft_test.py||tensorflow/python/data/experimental/kernel_tests/service/distributed_save_ft_test.py",
          "tensorflow/python/data/experimental/kernel_tests/service/distributed_save_test.py||tensorflow/python/data/experimental/kernel_tests/service/distributed_save_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/data/service/snapshot/path_utils.cc||tensorflow/core/data/service/snapshot/path_utils.cc",
            "tensorflow/core/data/service/snapshot/path_utils.h||tensorflow/core/data/service/snapshot/path_utils.h",
            "tensorflow/core/data/service/snapshot/path_utils_test.cc||tensorflow/core/data/service/snapshot/path_utils_test.cc",
            "tensorflow/core/data/service/snapshot/snapshot_manager.cc||tensorflow/core/data/service/snapshot/snapshot_manager.cc"
          ],
          "candidate": [
            "tensorflow/core/data/service/snapshot/path_utils.cc||tensorflow/core/data/service/snapshot/path_utils.cc",
            "tensorflow/core/data/service/snapshot/path_utils.h||tensorflow/core/data/service/snapshot/path_utils.h",
            "tensorflow/core/data/service/snapshot/path_utils_test.cc||tensorflow/core/data/service/snapshot/path_utils_test.cc",
            "tensorflow/core/data/service/snapshot/snapshot_manager.cc||tensorflow/core/data/service/snapshot/snapshot_manager.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/data/service/dispatcher.proto||tensorflow/core/data/service/dispatcher.proto": [
          "File: tensorflow/core/data/service/dispatcher.proto -> tensorflow/core/data/service/dispatcher.proto",
          "--- Hunk 1 ---",
          "[Context before]",
          "256:   int64 source_index = 3;",
          "257: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "259:   int64 repetition_index = 5;",
          "",
          "---------------"
        ],
        "tensorflow/core/data/service/dispatcher_client.cc||tensorflow/core/data/service/dispatcher_client.cc": [
          "File: tensorflow/core/data/service/dispatcher_client.cc -> tensorflow/core/data/service/dispatcher_client.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "172: Status DataServiceDispatcherClient::GetSnapshotSplit(",
          "173:     const std::string& worker_address, const std::string& base_path,",
          "176:   GetSnapshotSplitRequest req;",
          "177:   req.set_worker_address(worker_address);",
          "178:   req.set_base_path(base_path);",
          "179:   req.set_stream_index(stream_index);",
          "180:   req.set_source_index(source_index);",
          "182:   GetSnapshotSplitResponse resp;",
          "183:   grpc::ClientContext client_ctx;",
          "",
          "[Removed Lines]",
          "174:     int64_t stream_index, int64_t source_index, Tensor& split,",
          "175:     int64_t& local_split_index, bool& end_of_splits) {",
          "",
          "[Added Lines]",
          "174:     int64_t stream_index, int64_t source_index, int64_t repetition_index,",
          "175:     Tensor& split, int64_t& local_split_index, bool& end_of_splits) {",
          "181:   req.set_repetition_index(repetition_index);",
          "",
          "---------------"
        ],
        "tensorflow/core/data/service/dispatcher_client.h||tensorflow/core/data/service/dispatcher_client.h": [
          "File: tensorflow/core/data/service/dispatcher_client.h -> tensorflow/core/data/service/dispatcher_client.h",
          "--- Hunk 1 ---",
          "[Context before]",
          "73:   virtual Status GetSnapshotSplit(const std::string& worker_address,",
          "74:                                   const std::string& base_path,",
          "75:                                   int64_t stream_index, int64_t source_index,",
          "77:                                   bool& end_of_splits);",
          "",
          "[Removed Lines]",
          "76:                                   Tensor& split, int64_t& local_split_index,",
          "",
          "[Added Lines]",
          "76:                                   int64_t repetition_index, Tensor& split,",
          "77:                                   int64_t& local_split_index,",
          "",
          "---------------"
        ],
        "tensorflow/core/data/service/dispatcher_client_test.cc||tensorflow/core/data/service/dispatcher_client_test.cc": [
          "File: tensorflow/core/data/service/dispatcher_client_test.cc -> tensorflow/core/data/service/dispatcher_client_test.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "202:       TF_ASSERT_OK(dispatcher_client_->GetSnapshotSplit(",
          "203:           test_cluster_->WorkerAddress(0), snapshot_task.base_path(),",
          "204:           snapshot_task.stream_index(),",
          "206:       EXPECT_EQ(local_split_index, i);",
          "207:       EXPECT_FALSE(end_of_splits);",
          "208:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "206:           end_of_splits));",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "230:       TF_ASSERT_OK(dispatcher_client_->GetSnapshotSplit(",
          "231:           test_cluster_->WorkerAddress(i), snapshot_task.base_path(),",
          "232:           snapshot_task.stream_index(),",
          "234:       EXPECT_EQ(local_split_index, 0);",
          "235:       EXPECT_FALSE(end_of_splits);",
          "236:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "235:           end_of_splits));",
          "",
          "---------------"
        ],
        "tensorflow/core/data/service/snapshot/path_utils.cc||tensorflow/core/data/service/snapshot/path_utils.cc": [
          "File: tensorflow/core/data/service/snapshot/path_utils.cc -> tensorflow/core/data/service/snapshot/path_utils.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "68:                            absl::StrCat(\"source_\", source_id));",
          "69: }",
          "74:   return tsl::io::JoinPath(",
          "75:       SourceDirectory(snapshot_path, stream_index, source_id),",
          "76:       absl::StrCat(\"split_\", local_index, \"_\", global_index));",
          "77: }",
          "",
          "[Removed Lines]",
          "71: std::string SplitPath(absl::string_view snapshot_path, int64_t stream_index,",
          "72:                       int64_t source_id, int64_t local_index,",
          "73:                       int64_t global_index) {",
          "",
          "[Added Lines]",
          "71: std::string RepetitionDirectory(absl::string_view snapshot_path,",
          "72:                                 int64_t stream_index, int64_t source_id,",
          "73:                                 int64_t repetition_index) {",
          "76:       absl::StrCat(\"repetition_\", repetition_index));",
          "77: }",
          "79: std::string SplitPath(absl::string_view snapshot_path, int64_t stream_index,",
          "80:                       int64_t source_id, int64_t repetition_index,",
          "81:                       int64_t local_index, int64_t global_index) {",
          "82:   return tsl::io::JoinPath(",
          "83:       RepetitionDirectory(snapshot_path, stream_index, source_id,",
          "84:                           repetition_index),",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "92: tsl::StatusOr<std::pair<int64_t, int64_t>> ParseSplitFilename(",
          "93:     absl::string_view split_filename) {",
          "95:   int64_t local_split_index = 0, global_split_index = 0;",
          "96:   if (tokens.size() != 3 || tokens[0] != \"split\" ||",
          "97:       !absl::SimpleAtoi(tokens[1], &local_split_index) ||",
          "",
          "[Removed Lines]",
          "94:   std::vector<std::string> tokens = absl::StrSplit(split_filename, '_');",
          "",
          "[Added Lines]",
          "103:   std::vector<std::string> tokens =",
          "104:       absl::StrSplit(tsl::io::Basename(split_filename), '_');",
          "",
          "---------------"
        ],
        "tensorflow/core/data/service/snapshot/path_utils.h||tensorflow/core/data/service/snapshot/path_utils.h": [
          "File: tensorflow/core/data/service/snapshot/path_utils.h -> tensorflow/core/data/service/snapshot/path_utils.h",
          "--- Hunk 1 ---",
          "[Context before]",
          "43: std::string SourceDirectory(absl::string_view snapshot_path,",
          "44:                             int64_t stream_index, int64_t source_id);",
          "48: std::string SplitPath(absl::string_view snapshot_path, int64_t stream_index,",
          "",
          "[Removed Lines]",
          "49:                       int64_t source_id, int64_t local_index,",
          "50:                       int64_t global_index);",
          "",
          "[Added Lines]",
          "47: std::string RepetitionDirectory(absl::string_view snapshot_path,",
          "48:                                 int64_t stream_index, int64_t source_id,",
          "49:                                 int64_t repetition_index);",
          "54:                       int64_t source_id, int64_t repetition_index,",
          "55:                       int64_t local_index, int64_t global_index);",
          "",
          "---------------"
        ],
        "tensorflow/core/data/service/snapshot/path_utils_test.cc||tensorflow/core/data/service/snapshot/path_utils_test.cc": [
          "File: tensorflow/core/data/service/snapshot/path_utils_test.cc -> tensorflow/core/data/service/snapshot/path_utils_test.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "50:       MatchesRegex(\"/path/to/snapshot.streams.stream_0.splits.source_1\"));",
          "51: }",
          "53: TEST(PathUtilsTest, SplitPath) {",
          "54:   EXPECT_THAT(",
          "55:       SplitPath(\"/path/to/snapshot\", /*stream_index=*/0, /*source_id=*/1,",
          "57:       MatchesRegex(",
          "59: }",
          "61: TEST(PathUtilsTest, ParseStreamDirectoryName) {",
          "",
          "[Removed Lines]",
          "58:           \"/path/to/snapshot.streams.stream_0.splits.source_1.split_2_3\"));",
          "",
          "[Added Lines]",
          "53: TEST(PathUtilsTest, RepetitionDirectory) {",
          "54:   EXPECT_THAT(",
          "55:       RepetitionDirectory(\"/path/to/snapshot\", /*stream_index=*/0,",
          "57:       MatchesRegex(",
          "58:           \"/path/to/snapshot.streams.stream_0.splits.source_1.repetition_2\"));",
          "59: }",
          "66:           \"/path/to/\"",
          "67:           \"snapshot.streams.stream_0.splits.source_1.repetition_2.split_3_4\"));",
          "",
          "---------------"
        ],
        "tensorflow/core/data/service/snapshot/snapshot_manager.cc||tensorflow/core/data/service/snapshot/snapshot_manager.cc": [
          "File: tensorflow/core/data/service/snapshot/snapshot_manager.cc -> tensorflow/core/data/service/snapshot/snapshot_manager.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: #include <memory>",
          "20: #include <optional>",
          "21: #include <string>",
          "22: #include <vector>",
          "24: #include \"absl/algorithm/container.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "22: #include <utility>",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "62:     return InvalidArgument(\"Distributed tf.data snapshot at \", request.path(),",
          "63:                            \" already exists.\");",
          "64:   }",
          "66:   TF_RETURN_IF_ERROR(WriteOnDiskSkeleton());",
          "67:   TF_RETURN_IF_ERROR(WriteOnDiskMetadata(request));",
          "68:   metadata_ = request.metadata();",
          "69:   return OkStatus();",
          "70: }",
          "72: Status SnapshotManager::WriteOnDiskSkeleton() {",
          "73:   TF_RETURN_IF_ERROR(",
          "74:       env_->RecursivelyCreateDir(CommittedChunksDirectory(path_)));",
          "",
          "[Removed Lines]",
          "65:   TF_RETURN_IF_ERROR(CreateSplitProviders(request.dataset(), split_providers_));",
          "",
          "[Added Lines]",
          "66:   TF_ASSIGN_OR_RETURN(sources_, CreateSources(request.dataset()));",
          "73: StatusOr<std::vector<SnapshotManager::Source>> SnapshotManager::CreateSources(",
          "74:     const DatasetDef& dataset_def) const {",
          "75:   std::vector<std::unique_ptr<SplitProvider>> split_providers;",
          "76:   TF_RETURN_IF_ERROR(CreateSplitProviders(dataset_def, split_providers));",
          "77:   std::vector<SnapshotManager::Source> sources;",
          "78:   sources.reserve(split_providers.size());",
          "79:   for (auto& split_provider : split_providers) {",
          "80:     sources.push_back({std::move(split_provider), /*repetition_index=*/0});",
          "81:   }",
          "82:   return sources;",
          "83: }",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "134:   TF_RETURN_IF_ERROR(",
          "135:       ReadBinaryProto(env_, DatasetDefFilePath(path_), &dataset_def));",
          "138:   return OkStatus();",
          "139: }",
          "",
          "[Removed Lines]",
          "137:   TF_RETURN_IF_ERROR(CreateSplitProviders(dataset_def, split_providers_));",
          "",
          "[Added Lines]",
          "150:   TF_ASSIGN_OR_RETURN(sources_, CreateSources(dataset_def));",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "230: Status SnapshotManager::ReadOnDiskSource(",
          "231:     int64_t stream_index, int64_t source_index,",
          "232:     absl::flat_hash_set<int64_t>& global_split_indices) {",
          "251:     }",
          "258:   }",
          "262:   return OkStatus();",
          "263: }",
          "",
          "[Removed Lines]",
          "233:   std::string source_path = SourceDirectory(path_, stream_index, source_index);",
          "234:   TF_ASSIGN_OR_RETURN(std::vector<std::string> split_filenames,",
          "235:                       GetChildren(source_path, env_));",
          "237:   Tensor unused_tensor;",
          "238:   bool unused_end_of_splits;",
          "239:   for (const auto& split_filename : split_filenames) {",
          "240:     std::string split_path = io::JoinPath(source_path, split_filename);",
          "241:     TF_ASSIGN_OR_RETURN(auto split_indices, ParseSplitFilename(split_filename));",
          "242:     auto [local_split_index, global_split_index] = split_indices;",
          "243:     if (local_split_index > split_filenames.size() - 1) {",
          "244:       return InvalidArgument(",
          "245:           \"found conflict between the number of splits and name of \",",
          "246:           split_path);",
          "247:     }",
          "248:     if (global_split_indices.contains(global_split_index)) {",
          "249:       return InvalidArgument(\"found duplicate global split index in name of \",",
          "250:                              split_path);",
          "255:     TF_RETURN_IF_ERROR(split_providers_[source_index]->GetNext(",
          "256:         &unused_tensor, &unused_end_of_splits));",
          "257:     global_split_indices.insert(global_split_index);",
          "260:   streams_[stream_index].num_assigned_splits_per_source[source_index] =",
          "261:       split_filenames.size();",
          "",
          "[Added Lines]",
          "246:   std::string source_directory =",
          "247:       SourceDirectory(path_, stream_index, source_index);",
          "248:   TF_ASSIGN_OR_RETURN(std::vector<std::string> repetition_directories,",
          "249:                       GetChildren(source_directory, env_));",
          "250:   sources_[source_index].repetition_index =",
          "251:       repetition_directories.empty() ? 0 : repetition_directories.size() - 1;",
          "253:   for (const std::string& repetition : repetition_directories) {",
          "254:     std::string repetition_dir =",
          "255:         tsl::io::JoinPath(source_directory, repetition);",
          "256:     TF_ASSIGN_OR_RETURN(std::vector<std::string> split_files,",
          "257:                         GetChildren(repetition_dir, env_));",
          "258:     for (const std::string& split_file : split_files) {",
          "259:       std::string split_path = io::JoinPath(repetition_dir, split_file);",
          "260:       TF_RETURN_IF_ERROR(ReadOnDiskSplit(source_index, split_files, split_path,",
          "261:                                          global_split_indices));",
          "263:     streams_[stream_index].num_assigned_splits_per_source[source_index] +=",
          "264:         split_files.size();",
          "265:   }",
          "266:   return OkStatus();",
          "267: }",
          "269: Status SnapshotManager::ReadOnDiskSplit(",
          "270:     int64_t source_index, const std::vector<std::string>& split_files,",
          "271:     const std::string& split_file,",
          "272:     absl::flat_hash_set<int64_t>& global_split_indices) {",
          "275:   TF_ASSIGN_OR_RETURN(auto split_indices, ParseSplitFilename(split_file));",
          "276:   auto [local_split_index, global_split_index] = split_indices;",
          "277:   if (global_split_indices.contains(global_split_index)) {",
          "278:     return InvalidArgument(\"found duplicate global split index in name of \",",
          "279:                            split_file);",
          "281:   global_split_indices.insert(global_split_index);",
          "285:   return SkipSplit(*sources_[source_index].split_provider);",
          "286: }",
          "288: Status SnapshotManager::SkipSplit(SplitProvider& split_provider) {",
          "289:   Tensor tensor;",
          "290:   bool end_of_splits = false;",
          "291:   TF_RETURN_IF_ERROR(split_provider.GetNext(&tensor, &end_of_splits));",
          "292:   while (end_of_splits) {",
          "293:     TF_RETURN_IF_ERROR(split_provider.Reset());",
          "294:     TF_RETURN_IF_ERROR(split_provider.GetNext(&tensor, &end_of_splits));",
          "295:   }",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "300:     absl::string_view worker_address) {",
          "301:   int64_t new_stream_index = streams_.size();",
          "302:   for (int64_t source_index = 0; source_index < num_sources(); ++source_index) {",
          "305:   }",
          "306:   TF_RETURN_IF_ERROR(AtomicallyWriteStringToFile(",
          "307:       StreamWorkerFilePath(path_, new_stream_index), worker_address, env_));",
          "",
          "[Removed Lines]",
          "303:     TF_RETURN_IF_ERROR(env_->RecursivelyCreateDir(",
          "304:         SourceDirectory(path_, new_stream_index, source_index)));",
          "",
          "[Added Lines]",
          "337:     for (int64_t repetition_index = 0;",
          "338:          repetition_index <= sources_[source_index].repetition_index;",
          "339:          ++repetition_index) {",
          "340:       TF_RETURN_IF_ERROR(env_->RecursivelyCreateDir(RepetitionDirectory(",
          "341:           path_, new_stream_index, source_index, repetition_index)));",
          "342:     }",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "370:       it != request.snapshot_task_progress().end()) {",
          "371:     snapshot_progress = &it->second;",
          "372:   }",
          "373:   TF_ASSIGN_OR_RETURN(std::optional<int64_t> assigned_stream_index,",
          "374:                       MaybeGetOrCreateStreamAssignment(request.worker_address(),",
          "375:                                                        snapshot_progress));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "411:   if (snapshot_progress && snapshot_progress->completed() &&",
          "412:       mode_ == Mode::kActive) {",
          "413:     mode_ = Mode::kWindingDown;",
          "414:   }",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "400:                             \" but it's actually assigned stream \", it->second);",
          "401:   }",
          "408:   Stream& stream = streams_[request.stream_index()];",
          "409:   int64_t local_split_index =",
          "410:       stream.num_assigned_splits_per_source[request.source_index()];",
          "411:   int64_t global_split_index = num_assigned_splits_;",
          "412:   response.set_local_split_index(local_split_index);",
          "417:     response.set_end_of_splits(true);",
          "418:     return OkStatus();",
          "419:   }",
          "424:   TF_RETURN_IF_ERROR(AtomicallyWriteTFRecords(",
          "425:       split_path, {split}, tsl::io::compression::kNone, env_));",
          "426:   split.AsProtoTensorContent(response.mutable_split());",
          "",
          "[Removed Lines]",
          "403:   Tensor split;",
          "404:   bool end_of_splits;",
          "405:   TF_RETURN_IF_ERROR(split_providers_[request.source_index()]->GetNext(",
          "406:       &split, &end_of_splits));",
          "413:   if (end_of_splits) {",
          "414:     if (mode_ == Mode::kActive) {",
          "415:       mode_ = Mode::kWindingDown;",
          "416:     }",
          "421:   std::string split_path =",
          "422:       SplitPath(path_, request.stream_index(), request.source_index(),",
          "423:                 local_split_index, global_split_index);",
          "",
          "[Added Lines]",
          "451:   Source& source = sources_[request.source_index()];",
          "452:   if (request.repetition_index() < source.repetition_index) {",
          "457:   Tensor split;",
          "458:   bool end_of_splits;",
          "459:   TF_RETURN_IF_ERROR(source.split_provider->GetNext(&split, &end_of_splits));",
          "460:   if (end_of_splits) {",
          "461:     response.set_end_of_splits(true);",
          "462:     return ResetSource(source, request.source_index());",
          "463:   }",
          "465:   std::string split_path = SplitPath(",
          "466:       path_, request.stream_index(), request.source_index(),",
          "467:       request.repetition_index(), local_split_index, global_split_index);",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "430:   return OkStatus();",
          "431: }",
          "433: Status SnapshotManager::GetSnapshotStreams(",
          "434:     GetSnapshotStreamsResponse& response) {",
          "435:   for (int64_t i = 0; i < streams_.size(); ++i) {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "477: Status SnapshotManager::ResetSource(Source& source, int64_t source_index) {",
          "478:   TF_RETURN_IF_ERROR(source.split_provider->Reset());",
          "479:   ++source.repetition_index;",
          "480:   for (int64_t i = 0; i < streams_.size(); ++i) {",
          "481:     TF_RETURN_IF_ERROR(env_->RecursivelyCreateDir(RepetitionDirectory(",
          "482:         path_, /*stream_index=*/i, source_index, source.repetition_index)));",
          "483:   }",
          "484:   return OkStatus();",
          "485: }",
          "",
          "---------------"
        ],
        "tensorflow/core/data/service/snapshot/snapshot_manager.h||tensorflow/core/data/service/snapshot/snapshot_manager.h": [
          "File: tensorflow/core/data/service/snapshot/snapshot_manager.h -> tensorflow/core/data/service/snapshot/snapshot_manager.h",
          "--- Hunk 1 ---",
          "[Context before]",
          "103:   tsl::Status ReadOnDiskSource(",
          "104:       int64_t stream_index, int64_t source_index,",
          "105:       absl::flat_hash_set<int64_t>& global_split_indices);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "106:   tsl::Status ReadOnDiskSplit(",
          "107:       int64_t source_index, const std::vector<std::string>& split_files,",
          "108:       const std::string& split_file,",
          "109:       absl::flat_hash_set<int64_t>& global_split_indices);",
          "110:   tsl::Status SkipSplit(SplitProvider& split_provider);",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "134:   absl::flat_hash_set<std::string> dead_workers_;",
          "140:   struct Stream {",
          "141:     explicit Stream(int64_t num_sources)",
          "142:         : num_assigned_splits_per_source(num_sources) {}",
          "",
          "[Removed Lines]",
          "137:   std::vector<std::unique_ptr<SplitProvider>> split_providers_;",
          "138:   int64_t num_sources() const { return split_providers_.size(); }",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "158:     State state = State::kActive;",
          "159:   };",
          "162:   std::vector<Stream> streams_;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "162:   struct Source {",
          "164:     std::unique_ptr<SplitProvider> split_provider;",
          "166:     int64_t repetition_index = 0;",
          "167:   };",
          "169:   std::vector<Source> sources_;",
          "171:   StatusOr<std::vector<Source>> CreateSources(",
          "172:       const DatasetDef& dataset_def) const;",
          "174:   Status ResetSource(Source& source, int64_t source_index);",
          "175:   int64_t num_sources() const { return sources_.size(); }",
          "",
          "---------------"
        ],
        "tensorflow/core/data/service/snapshot/snapshot_split_provider.cc||tensorflow/core/data/service/snapshot/snapshot_split_provider.cc": [
          "File: tensorflow/core/data/service/snapshot/snapshot_split_provider.cc -> tensorflow/core/data/service/snapshot/snapshot_split_provider.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "84:     return OkStatus();",
          "85:   }",
          "88:   TF_RETURN_IF_ERROR(ValidateSplitFiles(split_to_file_map_, next_split_index_,",
          "89:                                         dispatcher_split_index,",
          "",
          "[Removed Lines]",
          "87:   TF_ASSIGN_OR_RETURN(split_to_file_map_, GetSplitsFiles(next_split_index_));",
          "",
          "[Added Lines]",
          "87:   TF_RETURN_IF_ERROR(",
          "88:       GetSplitsFiles(next_split_index_, split_to_file_map_, repetition_index_));",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "119:           TF_EXCLUSIVE_LOCKS_REQUIRED(mu_) {",
          "120:             return dispatcher_->GetSnapshotSplit(",
          "121:                 worker_address_, snapshot_task_.base_path(),",
          "124:           },",
          "125:       \"Get next split for snapshot\",",
          "",
          "[Removed Lines]",
          "122:                 snapshot_task_.stream_index(), source_index_, *split,",
          "123:                 local_split_index, *end_of_splits);",
          "",
          "[Added Lines]",
          "123:                 snapshot_task_.stream_index(), source_index_, repetition_index_,",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "128:   return local_split_index;",
          "129: }",
          "134:   std::string splits_directory = SourceDirectory(",
          "135:       snapshot_task_.base_path(), snapshot_task_.stream_index(), source_index_);",
          "139:                       GetChildren(splits_directory, env_));",
          "146:     }",
          "147:   }",
          "150: }",
          "152: Status SnapshotSplitProvider::ValidateSplitFiles(",
          "",
          "[Removed Lines]",
          "131: StatusOr<absl::btree_map<int64_t, std::string>>",
          "132: SnapshotSplitProvider::GetSplitsFiles(int64_t start_index) const",
          "133:     TF_EXCLUSIVE_LOCKS_REQUIRED(mu_) {",
          "136:   absl::btree_map<int64_t, std::string> splits;",
          "138:   TF_ASSIGN_OR_RETURN(std::vector<std::string> split_files,",
          "140:   for (const std::string& split_file : split_files) {",
          "141:     TF_ASSIGN_OR_RETURN(auto split_indices, ParseSplitFilename(split_file));",
          "142:     auto [local_split_index, global_split_index] = split_indices;",
          "143:     if (local_split_index >= next_split_index_) {",
          "144:       splits[local_split_index] =",
          "145:           tsl::io::JoinPath(splits_directory, split_file);",
          "148:   TF_RETURN_IF_ERROR(ValidateSplitFiles(splits, start_index));",
          "149:   return splits;",
          "",
          "[Added Lines]",
          "132: Status SnapshotSplitProvider::GetSplitsFiles(",
          "133:     int64_t start_index,",
          "134:     absl::btree_map<int64_t, std::string>& split_to_file_map,",
          "135:     int64_t& repetition_index) const TF_EXCLUSIVE_LOCKS_REQUIRED(mu_) {",
          "136:   split_to_file_map.clear();",
          "139:   TF_ASSIGN_OR_RETURN(std::vector<std::string> repetition_directories,",
          "142:   for (const std::string& repetition : repetition_directories) {",
          "143:     std::string repetition_dir = io::JoinPath(splits_directory, repetition);",
          "144:     TF_ASSIGN_OR_RETURN(std::vector<std::string> split_files,",
          "145:                         GetChildren(repetition_dir, env_));",
          "146:     for (const std::string& split_file : split_files) {",
          "147:       TF_ASSIGN_OR_RETURN(auto split_index, ParseSplitFilename(split_file));",
          "148:       auto [local_split_index, global_split_index] = split_index;",
          "149:       if (local_split_index >= start_index) {",
          "150:         split_to_file_map[local_split_index] =",
          "151:             tsl::io::JoinPath(repetition_dir, split_file);",
          "152:       }",
          "156:   TF_RETURN_IF_ERROR(ValidateSplitFiles(split_to_file_map, start_index));",
          "157:   repetition_index =",
          "158:       repetition_directories.empty() ? 0 : repetition_directories.size() - 1;",
          "159:   return OkStatus();",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "198:   return OkStatus();",
          "199: }",
          "203: Status SnapshotSplitProvider::Save(",
          "204:     std::function<std::string(std::string)> full_name,",
          "",
          "[Removed Lines]",
          "201: Status SnapshotSplitProvider::Reset() { return OkStatus(); }",
          "",
          "[Added Lines]",
          "211: Status SnapshotSplitProvider::Reset() {",
          "212:   mutex_lock l(mu_);",
          "213:   ++repetition_index_;",
          "214:   return OkStatus();",
          "215: }",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "217:       reader->ReadScalar(full_name(kNextSplitIndex), &next_split_index));",
          "218:   mutex_lock l(mu_);",
          "219:   next_split_index_ = next_split_index;",
          "221:   return OkStatus();",
          "222: }",
          "",
          "[Removed Lines]",
          "220:   TF_ASSIGN_OR_RETURN(split_to_file_map_, GetSplitsFiles(next_split_index_));",
          "",
          "[Added Lines]",
          "234:   TF_RETURN_IF_ERROR(",
          "235:       GetSplitsFiles(next_split_index_, split_to_file_map_, repetition_index_));",
          "",
          "---------------"
        ],
        "tensorflow/core/data/service/snapshot/snapshot_split_provider.h||tensorflow/core/data/service/snapshot/snapshot_split_provider.h": [
          "File: tensorflow/core/data/service/snapshot/snapshot_split_provider.h -> tensorflow/core/data/service/snapshot/snapshot_split_provider.h",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: #include <functional>",
          "20: #include <memory>",
          "21: #include <string>",
          "23: #include \"absl/container/btree_map.h\"",
          "24: #include \"absl/time/time.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "22: #include <utility>",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "72:   StatusOr<absl::btree_map<int64_t, std::string>> GetSplitsFiles(",
          "73:       int64_t start_index) const;",
          "",
          "[Added Lines]",
          "73:   Status GetSplitsFiles(",
          "74:       int64_t start_index,",
          "75:       absl::btree_map<int64_t, std::string>& split_to_file_map,",
          "76:       int64_t& repetition_index) const;",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "91:   int64_t next_split_index_ TF_GUARDED_BY(mu_) = 0;",
          "94:   absl::btree_map<int64_t, std::string> split_to_file_map_ TF_GUARDED_BY(mu_);",
          "95: };",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "97:   int64_t repetition_index_ TF_GUARDED_BY(mu_) = 0;",
          "",
          "---------------"
        ],
        "tensorflow/core/data/service/snapshot/snapshot_split_provider_test.cc||tensorflow/core/data/service/snapshot/snapshot_split_provider_test.cc": [
          "File: tensorflow/core/data/service/snapshot/snapshot_split_provider_test.cc -> tensorflow/core/data/service/snapshot/snapshot_split_provider_test.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "60:   MOCK_METHOD(Status, GetSnapshotSplit,",
          "61:               (const std::string& worker_address, const std::string& base_path,",
          "63:                int64_t& local_split_index, bool& end_of_splits),",
          "64:               (override));",
          "65: };",
          "",
          "[Removed Lines]",
          "62:                int64_t stream_index, int64_t source_index, Tensor& split,",
          "",
          "[Added Lines]",
          "62:                int64_t stream_index, int64_t source_index,",
          "63:                int64_t repetition_index, Tensor& split,",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "74: }",
          "76: Status WriteSplits(const SnapshotTaskDef& snapshot_task, int64_t num_splits) {",
          "79:   TF_RETURN_IF_ERROR(Env::Default()->RecursivelyCreateDir(source_dir));",
          "80:   for (int64_t i = 0; i < num_splits; ++i) {",
          "81:     std::string split_filename = absl::StrCat(\"split_\", i, \"_\", i);",
          "",
          "[Removed Lines]",
          "77:   std::string source_dir = SourceDirectory(",
          "78:       snapshot_task.base_path(), snapshot_task.stream_index(), /*source_id=*/0);",
          "",
          "[Added Lines]",
          "78:   std::string source_dir = RepetitionDirectory(",
          "79:       snapshot_task.base_path(), snapshot_task.stream_index(), /*source_id=*/0,",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "93:   auto mock_dispatcher_ptr = std::make_unique<MockDispatcherClient>();",
          "94:   MockDispatcherClient* mock_dispatcher = mock_dispatcher_ptr.get();",
          "100:                       Return(OkStatus())));",
          "102:   Tensor result;",
          "",
          "[Removed Lines]",
          "96:   EXPECT_CALL(*mock_dispatcher, GetSnapshotSplit(_, _, _, _, _, _, _))",
          "97:       .WillOnce(DoAll(SetArgReferee<4>(split),",
          "98:                       SetArgReferee<5>(0),      // local_split_index",
          "99:                       SetArgReferee<6>(false),  // end_of_splits",
          "",
          "[Added Lines]",
          "98:   EXPECT_CALL(*mock_dispatcher, GetSnapshotSplit(_, _, _, _, _, _, _, _))",
          "99:       .WillOnce(DoAll(SetArgReferee<5>(split),",
          "100:                       SetArgReferee<6>(0),      // local_split_index",
          "101:                       SetArgReferee<7>(false),  // end_of_splits",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "117:   MockDispatcherClient* mock_dispatcher = mock_dispatcher_ptr.get();",
          "124:                       Return(OkStatus())));",
          "125:   TF_ASSERT_OK(WriteSplits(snapshot_task, /*num_splits=*/10));",
          "",
          "[Removed Lines]",
          "120:   EXPECT_CALL(*mock_dispatcher, GetSnapshotSplit(_, _, _, _, _, _, _))",
          "121:       .WillOnce(DoAll(SetArgReferee<4>(split),",
          "122:                       SetArgReferee<5>(9),      // local_split_index",
          "123:                       SetArgReferee<6>(false),  // end_of_splits",
          "",
          "[Added Lines]",
          "122:   EXPECT_CALL(*mock_dispatcher, GetSnapshotSplit(_, _, _, _, _, _, _, _))",
          "123:       .WillOnce(DoAll(SetArgReferee<5>(split),",
          "124:                       SetArgReferee<6>(9),      // local_split_index",
          "125:                       SetArgReferee<7>(false),  // end_of_splits",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "143:   auto mock_dispatcher_ptr = std::make_unique<MockDispatcherClient>();",
          "144:   MockDispatcherClient* mock_dispatcher = mock_dispatcher_ptr.get();",
          "149:                       Return(OkStatus())));",
          "151:   SnapshotSplitProvider split_provider(",
          "",
          "[Removed Lines]",
          "146:   EXPECT_CALL(*mock_dispatcher, GetSnapshotSplit(_, _, _, _, _, _, _))",
          "147:       .WillOnce(DoAll(SetArgReferee<5>(0),     // local_split_index",
          "148:                       SetArgReferee<6>(true),  // end_of_splits",
          "",
          "[Added Lines]",
          "148:   EXPECT_CALL(*mock_dispatcher, GetSnapshotSplit(_, _, _, _, _, _, _, _))",
          "149:       .WillOnce(DoAll(SetArgReferee<6>(0),     // local_split_index",
          "150:                       SetArgReferee<7>(true),  // end_of_splits",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "164:   auto mock_dispatcher_ptr = std::make_unique<MockDispatcherClient>();",
          "165:   MockDispatcherClient* mock_dispatcher = mock_dispatcher_ptr.get();",
          "171:                       Return(OkStatus())));",
          "172:   TF_ASSERT_OK(WriteSplits(snapshot_task, /*num_splits=*/0));",
          "",
          "[Removed Lines]",
          "167:   EXPECT_CALL(*mock_dispatcher, GetSnapshotSplit(_, _, _, _, _, _, _))",
          "168:       .WillOnce(DoAll(SetArgReferee<4>(split),",
          "169:                       SetArgReferee<5>(10),     // local_split_index",
          "170:                       SetArgReferee<6>(false),  // end_of_splits",
          "",
          "[Added Lines]",
          "169:   EXPECT_CALL(*mock_dispatcher, GetSnapshotSplit(_, _, _, _, _, _, _, _))",
          "170:       .WillOnce(DoAll(SetArgReferee<5>(split),",
          "171:                       SetArgReferee<6>(10),     // local_split_index",
          "172:                       SetArgReferee<7>(false),  // end_of_splits",
          "",
          "---------------"
        ],
        "tensorflow/python/data/experimental/kernel_tests/service/distributed_save_ft_test.py||tensorflow/python/data/experimental/kernel_tests/service/distributed_save_ft_test.py": [
          "File: tensorflow/python/data/experimental/kernel_tests/service/distributed_save_ft_test.py -> tensorflow/python/data/experimental/kernel_tests/service/distributed_save_ft_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "59: class SnapshotFtTest(data_service_test_base.TestBase, parameterized.TestCase):",
          "61:   def setUp(self):",
          "62:     super().setUp()",
          "63:     self._path = os.path.join(",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "61:   maxDiff = None",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "94:     return os.path.join(",
          "95:         self.splits_dir(stream_idx, worker=worker),",
          "96:         f\"source_{source_idx}\",",
          "97:     )",
          "99:   def _make_stream_dir(self, stream_name, worker=0):",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "99:         \"repetition_0\",",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "182:         ValueError, \"The local split index 1 exceeds the global split index 0\"):",
          "183:       cluster.restart_dispatcher()",
          "192:   @combinations.generate(test_base.eager_only_combinations())",
          "193:   def testSnapshotRecoveryFailsWithMissingGlobalIndexInSplitNames(self):",
          "194:     cluster, _ = self.setup(num_workers=0)",
          "",
          "[Removed Lines]",
          "185:   @combinations.generate(test_base.eager_only_combinations())",
          "186:   def testSnapshotRecoveryFailsWithOutOfBoundsSplitName(self):",
          "187:     cluster, _ = self.setup(num_workers=0)",
          "188:     write_file(os.path.join(self.source_dir(), \"split_1_1\"))",
          "189:     with self.assertRaisesRegex(ValueError, \"found conflict\"):",
          "190:       cluster.restart_dispatcher()",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "232:   def testLargeMultiSourceSnapshotRecoversAndCompletes(self):",
          "233:     n = 5",
          "234:     cluster, _ = self.setup(num_workers=n, ds_size=1000, num_sources=3)",
          "236:     cluster.stop_worker(0)",
          "237:     cluster.restart_dispatcher()",
          "238:     cluster.restart_worker(0)",
          "239:     self._wait_for_snapshot()",
          "240:     self.assertTrue(self._snapshot_is_done())",
          "242:   def _snapshot_is_done(self):",
          "243:     return os.path.exists(os.path.join(self._path, \"DONE\"))",
          "",
          "[Removed Lines]",
          "235:     get_stream_assignments(cluster, n)  # Block until all workers have streams.",
          "",
          "[Added Lines]",
          "231:     get_stream_assignments(cluster, n)  # Blocks until all workers have streams.",
          "232:     cluster.stop_worker(0)",
          "233:     cluster.restart_dispatcher()",
          "234:     cluster.restart_worker(0)",
          "235:     self._wait_for_snapshot()",
          "236:     self.assertTrue(self._snapshot_is_done())",
          "237:     # TODO(b/250921378): Verify the number of elements.",
          "239:   @combinations.generate(test_base.eager_only_combinations())",
          "240:   def testRepeatedDatasetRecoversAndCompletes(self):",
          "241:     cluster = data_service_test_base.TestCluster(num_workers=3)",
          "242:     ds = dataset_ops.Dataset.range(100)",
          "243:     ds = ds.repeat(10)",
          "244:     distributed_save_op.distributed_save(",
          "245:         ds, self._path, cluster.dispatcher_address()",
          "246:     )",
          "248:     get_stream_assignments(cluster, 3)  # Blocks until all workers have streams.",
          "254:     # TODO(b/250921378): Verify the number of elements.",
          "",
          "---------------"
        ],
        "tensorflow/python/data/experimental/kernel_tests/service/distributed_save_test.py||tensorflow/python/data/experimental/kernel_tests/service/distributed_save_test.py": [
          "File: tensorflow/python/data/experimental/kernel_tests/service/distributed_save_test.py -> tensorflow/python/data/experimental/kernel_tests/service/distributed_save_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "103:     dataset = dataset_ops.Dataset.load(self._test_dir)",
          "104:     self.assertDatasetProduces(dataset, list(range(10)))",
          "106:   @combinations.generate(test_base.default_test_combinations())",
          "107:   def testChooseFromDatasets(self):",
          "108:     cluster = data_service_test_base.TestCluster(num_workers=1)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "106:   @combinations.generate(test_base.default_test_combinations())",
          "107:   def testRepeatedDataset(self):",
          "108:     cluster = data_service_test_base.TestCluster(num_workers=1)",
          "109:     dataset = dataset_ops.Dataset.range(10)",
          "110:     dataset = dataset.repeat(3)",
          "111:     self.evaluate(distributed_save_op.distributed_save(",
          "112:         dataset,",
          "113:         self._test_dir,",
          "114:         cluster.dispatcher_address(),",
          "115:     ))",
          "116:     _wait_for_snapshot(self._test_dir)",
          "118:     dataset = dataset_ops.Dataset.load(self._test_dir)",
          "119:     self.assertDatasetProduces(dataset, list(range(10)) * 3)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "121:     dataset = dataset_ops.Dataset.load(self._test_dir)",
          "122:     self.assertDatasetProduces(dataset, [\"a\", \"b\", \"c\"] * 5)",
          "124:   @combinations.generate(test_base.default_test_combinations())",
          "125:   def testLoadWithCustomReaderFunc(self):",
          "126:     # TODO(b/250921378): Currently, all the unit tests only write one chunk",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "139:   @combinations.generate(test_base.default_test_combinations())",
          "140:   def testChooseFromRepeatedDatasets(self):",
          "141:     cluster = data_service_test_base.TestCluster(num_workers=1)",
          "142:     datasets = [",
          "143:         dataset_ops.Dataset.from_tensors(\"a\").repeat(5),",
          "144:         dataset_ops.Dataset.from_tensors(\"b\").repeat(5),",
          "145:         dataset_ops.Dataset.from_tensors(\"c\").repeat(5),",
          "146:     ]",
          "147:     choice_dataset = dataset_ops.Dataset.range(3).repeat()",
          "148:     dataset = dataset_ops.Dataset.choose_from_datasets(datasets, choice_dataset)",
          "149:     self.evaluate(distributed_save_op.distributed_save(",
          "150:         dataset, self._test_dir, cluster.dispatcher_address()",
          "151:     ))",
          "152:     _wait_for_snapshot(self._test_dir)",
          "154:     dataset = dataset_ops.Dataset.load(self._test_dir)",
          "155:     self.assertDatasetProduces(dataset, [\"a\", \"b\", \"c\"] * 5)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "6088a22ddb8fc299d18a34596b91ccf077b86b17",
      "candidate_info": {
        "commit_hash": "6088a22ddb8fc299d18a34596b91ccf077b86b17",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/6088a22ddb8fc299d18a34596b91ccf077b86b17",
        "files": [
          "tensorflow/compiler/tests/BUILD",
          "tensorflow/compiler/tests/giant_const_op_test.py",
          "tensorflow/python/distribute/BUILD",
          "tensorflow/python/distribute/cluster_resolver/tpu/BUILD",
          "tensorflow/python/distribute/cluster_resolver/tpu/tpu_cluster_resolver.py",
          "tensorflow/python/distribute/cluster_resolver/tpu_cluster_resolver.py",
          "tensorflow/python/distribute/collective_all_reduce_strategy.py",
          "tensorflow/python/distribute/collective_all_reduce_strategy_test.py",
          "tensorflow/python/distribute/parallel_device/BUILD",
          "tensorflow/python/distribute/parallel_device/parallel_device_test.py",
          "tensorflow/python/distribute/strategy_combinations.py",
          "tensorflow/python/distribute/tpu_strategy.py",
          "tensorflow/python/distribute/tpu_strategy_compilation_test.py",
          "tensorflow/python/distribute/tpu_strategy_model_parallelism_test.py",
          "tensorflow/python/distribute/tpu_strategy_test.py",
          "tensorflow/python/distribute/vars_test.py",
          "tensorflow/python/eager/BUILD",
          "tensorflow/python/eager/remote.py",
          "tensorflow/python/eager/remote_cloud_tpu_test.py",
          "tensorflow/python/ops/memory_tests/BUILD",
          "tensorflow/python/ops/memory_tests/custom_gradient_memory_test.py",
          "tensorflow/python/tpu/BUILD",
          "tensorflow/python/tpu/tests/BUILD",
          "tensorflow/python/tpu/tests/tpu_embedding_base_test.py",
          "tensorflow/python/tpu/tests/tpu_embedding_v2_checkpoint_test.py",
          "tensorflow/python/tpu/tests/tpu_initialization_test.py",
          "tensorflow/python/tpu/tpu_outside_compilation_test.py",
          "tensorflow/python/tpu/tpu_strategy_util.py"
        ],
        "message": "Break the interdependency between tpu/tpu_strategy_util.py,  distribute/cluster_resolver/tpu/tpu_cluster_resolver.py, and eager/remote.py.\n\nMake exported wrappers for initialize_tpu_system and shutdown_tpu_system in tpu_cluster_resolver.py, and make implementation functions for them in tpu_strategy_util.py that they pass a reference of TPUClusterResolver to. Add a test for this.\n\nReplace an isinstance check of TPUClusterResolver in remote.py with an isinstance check of ClusterResolver and a hasattr check.\n\nMake all inline imports regular imports and add all missing BUILD deps. Update references to the new location of initialize_tpu_system.\n\nPiperOrigin-RevId: 537905952",
        "before_after_code_files": [
          "tensorflow/compiler/tests/giant_const_op_test.py||tensorflow/compiler/tests/giant_const_op_test.py",
          "tensorflow/python/distribute/cluster_resolver/tpu/tpu_cluster_resolver.py||tensorflow/python/distribute/cluster_resolver/tpu/tpu_cluster_resolver.py",
          "tensorflow/python/distribute/cluster_resolver/tpu_cluster_resolver.py||tensorflow/python/distribute/cluster_resolver/tpu_cluster_resolver.py",
          "tensorflow/python/distribute/collective_all_reduce_strategy.py||tensorflow/python/distribute/collective_all_reduce_strategy.py",
          "tensorflow/python/distribute/collective_all_reduce_strategy_test.py||tensorflow/python/distribute/collective_all_reduce_strategy_test.py",
          "tensorflow/python/distribute/parallel_device/parallel_device_test.py||tensorflow/python/distribute/parallel_device/parallel_device_test.py",
          "tensorflow/python/distribute/strategy_combinations.py||tensorflow/python/distribute/strategy_combinations.py",
          "tensorflow/python/distribute/tpu_strategy.py||tensorflow/python/distribute/tpu_strategy.py",
          "tensorflow/python/distribute/tpu_strategy_compilation_test.py||tensorflow/python/distribute/tpu_strategy_compilation_test.py",
          "tensorflow/python/distribute/tpu_strategy_model_parallelism_test.py||tensorflow/python/distribute/tpu_strategy_model_parallelism_test.py",
          "tensorflow/python/distribute/tpu_strategy_test.py||tensorflow/python/distribute/tpu_strategy_test.py",
          "tensorflow/python/distribute/vars_test.py||tensorflow/python/distribute/vars_test.py",
          "tensorflow/python/eager/remote.py||tensorflow/python/eager/remote.py",
          "tensorflow/python/eager/remote_cloud_tpu_test.py||tensorflow/python/eager/remote_cloud_tpu_test.py",
          "tensorflow/python/ops/memory_tests/custom_gradient_memory_test.py||tensorflow/python/ops/memory_tests/custom_gradient_memory_test.py",
          "tensorflow/python/tpu/tests/tpu_embedding_base_test.py||tensorflow/python/tpu/tests/tpu_embedding_base_test.py",
          "tensorflow/python/tpu/tests/tpu_embedding_v2_checkpoint_test.py||tensorflow/python/tpu/tests/tpu_embedding_v2_checkpoint_test.py",
          "tensorflow/python/tpu/tests/tpu_initialization_test.py||tensorflow/python/tpu/tests/tpu_initialization_test.py",
          "tensorflow/python/tpu/tpu_outside_compilation_test.py||tensorflow/python/tpu/tpu_outside_compilation_test.py",
          "tensorflow/python/tpu/tpu_strategy_util.py||tensorflow/python/tpu/tpu_strategy_util.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/python/tpu/tpu_strategy_util.py||tensorflow/python/tpu/tpu_strategy_util.py"
          ],
          "candidate": [
            "tensorflow/python/tpu/tpu_strategy_util.py||tensorflow/python/tpu/tpu_strategy_util.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/compiler/tests/giant_const_op_test.py||tensorflow/compiler/tests/giant_const_op_test.py": [
          "File: tensorflow/compiler/tests/giant_const_op_test.py -> tensorflow/compiler/tests/giant_const_op_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "25: from tensorflow.python.framework import constant_op",
          "26: from tensorflow.python.framework import dtypes",
          "27: from tensorflow.python.platform import flags",
          "30: FLAGS = flags.FLAGS",
          "31: flags.DEFINE_string(\"tpu\", \"\", \"Name of TPU to connect to.\")",
          "",
          "[Removed Lines]",
          "28: from tensorflow.python.tpu import tpu_strategy_util",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "45: def get_tpu_strategy():",
          "46:   resolver = get_tpu_cluster_resolver()",
          "47:   remote.connect_to_cluster(resolver)",
          "49:   return tpu_lib.TPUStrategyV2(resolver)",
          "",
          "[Removed Lines]",
          "48:   tpu_strategy_util.initialize_tpu_system(resolver)",
          "",
          "[Added Lines]",
          "47:   tpu_cluster_resolver.initialize_tpu_system(resolver)",
          "",
          "---------------"
        ],
        "tensorflow/python/distribute/cluster_resolver/tpu/tpu_cluster_resolver.py||tensorflow/python/distribute/cluster_resolver/tpu/tpu_cluster_resolver.py": [
          "File: tensorflow/python/distribute/cluster_resolver/tpu/tpu_cluster_resolver.py -> tensorflow/python/distribute/cluster_resolver/tpu/tpu_cluster_resolver.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: import re",
          "20: from tensorflow.core.protobuf.tpu import topology_pb2",
          "22: from tensorflow.python.framework import config as framework_config",
          "23: from tensorflow.python.framework import errors",
          "24: from tensorflow.python.platform import tf_logging as logging",
          "25: from tensorflow.python.tpu import tpu_system_metadata as tpu_system_metadata_lib",
          "26: from tensorflow.python.training import server_lib",
          "27: from tensorflow.python.util import compat",
          "",
          "[Removed Lines]",
          "21: from tensorflow.python.distribute.cluster_resolver import cluster_resolver",
          "",
          "[Added Lines]",
          "21: from tensorflow.python.distribute.cluster_resolver import cluster_resolver as cluster_resolver_lib",
          "22: from tensorflow.python.eager import remote",
          "26: from tensorflow.python.tpu import tpu_strategy_util",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "53:     'DeviceDetails', ['device_map', 'total_cores'])",
          "57:   \"\"\"Cluster Resolver for Google Cloud TPUs.",
          "59:   This is an implementation of cluster resolvers for the Google Cloud TPU",
          "",
          "[Removed Lines]",
          "56: class TPUClusterResolver(cluster_resolver.ClusterResolver):",
          "",
          "[Added Lines]",
          "58: def initialize_tpu_system(cluster_resolver=None):",
          "59:   \"\"\"Initialize the TPU devices.",
          "61:   Args:",
          "62:     cluster_resolver: A tf.distribute.cluster_resolver.TPUClusterResolver,",
          "63:         which provides information about the TPU cluster.",
          "64:   Returns:",
          "65:     The tf.tpu.Topology object for the topology of the TPU cluster. If called",
          "66:     inside tf.function, it returns the serialized topology object instead.",
          "68:   Raises:",
          "69:     RuntimeError: If running inside a tf.function.",
          "70:     NotFoundError: If no TPU devices found in eager mode.",
          "71:   \"\"\"",
          "72:   return tpu_strategy_util.initialize_tpu_system_impl(",
          "73:       cluster_resolver, TPUClusterResolver)",
          "76: def shutdown_tpu_system(cluster_resolver=None):",
          "77:   \"\"\"Shuts down the TPU devices.",
          "79:   This will clear all caches, even those that are maintained through sequential",
          "80:   calls to tf.tpu.experimental.initialize_tpu_system, such as the compilation",
          "81:   cache.",
          "83:   Args:",
          "84:     cluster_resolver: A tf.distribute.cluster_resolver.TPUClusterResolver,",
          "85:         which provides information about the TPU cluster.",
          "87:   Raises:",
          "88:     RuntimeError: If no TPU devices found for eager execution or if run in a",
          "89:         tf.function.",
          "90:   \"\"\"",
          "91:   tpu_strategy_util.shutdown_tpu_system_impl(",
          "92:       cluster_resolver, TPUClusterResolver)",
          "95: class TPUClusterResolver(cluster_resolver_lib.ClusterResolver):",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "104:       NotFoundError: If no TPU devices found in eager mode.",
          "105:     \"\"\"",
          "106:     resolver = TPUClusterResolver(tpu, zone, project)",
          "108:     remote.connect_to_cluster(resolver)",
          "111:     return resolver",
          "113:   @staticmethod",
          "",
          "[Removed Lines]",
          "107:     from tensorflow.python.eager import remote  # pylint: disable=g-import-not-at-top",
          "109:     from tensorflow.python.tpu import tpu_strategy_util  # pylint: disable=g-import-not-at-top",
          "110:     tpu_strategy_util.initialize_tpu_system(resolver)",
          "",
          "[Added Lines]",
          "147:     tpu_strategy_util.initialize_tpu_system_impl(resolver)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "266:         if not job_tasks:",
          "267:           raise ValueError('No TPUs with the specified names exist.')",
          "268:         master = job_tasks[0]",
          "270:     else:",
          "271:       return ''",
          "",
          "[Removed Lines]",
          "269:       return cluster_resolver.format_master_url(master, 'grpc')",
          "",
          "[Added Lines]",
          "306:       return cluster_resolver_lib.format_master_url(master, 'grpc')",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "384:     while True:",
          "385:       try:",
          "386:         device_details = TPUClusterResolver._get_device_dict_and_cores(",
          "388:                 self.master(), config_proto=config_proto))",
          "389:         break",
          "390:       except errors.DeadlineExceededError:",
          "",
          "[Removed Lines]",
          "387:             cluster_resolver.get_accelerator_devices(",
          "",
          "[Added Lines]",
          "424:             cluster_resolver_lib.get_accelerator_devices(",
          "",
          "---------------"
        ],
        "tensorflow/python/distribute/cluster_resolver/tpu_cluster_resolver.py||tensorflow/python/distribute/cluster_resolver/tpu_cluster_resolver.py": [
          "File: tensorflow/python/distribute/cluster_resolver/tpu_cluster_resolver.py -> tensorflow/python/distribute/cluster_resolver/tpu_cluster_resolver.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "15: \"\"\"Shim so that direct imports of tpu_cluster_resolver get correct symbols.",
          "16: \"\"\"",
          "18: from tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver import is_running_in_gce  # pylint: disable=unused-import",
          "19: from tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver import TPUClusterResolver",
          "20: from tensorflow.python.util.tf_export import tf_export",
          "22: tf_export('distribute.cluster_resolver.TPUClusterResolver')(TPUClusterResolver)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: from tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver import initialize_tpu_system",
          "20: from tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver import shutdown_tpu_system",
          "25: tf_export('tpu.experimental.initialize_tpu_system')(initialize_tpu_system)",
          "26: tf_export('tpu.experimental.shutdown_tpu_system')(shutdown_tpu_system)",
          "",
          "---------------"
        ],
        "tensorflow/python/distribute/collective_all_reduce_strategy.py||tensorflow/python/distribute/collective_all_reduce_strategy.py": [
          "File: tensorflow/python/distribute/collective_all_reduce_strategy.py -> tensorflow/python/distribute/collective_all_reduce_strategy.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "36: from tensorflow.python.distribute import values",
          "37: from tensorflow.python.distribute.cluster_resolver import cluster_resolver as cluster_resolver_lib",
          "38: from tensorflow.python.distribute.cluster_resolver import tfconfig_cluster_resolver",
          "39: from tensorflow.python.distribute.v1 import input_lib as input_lib_v1",
          "40: from tensorflow.python.eager import context",
          "41: from tensorflow.python.framework import device as tf_device",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "39: from tensorflow.python.distribute.cluster_resolver import tpu_cluster_resolver",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "45: from tensorflow.python.ops import collective_ops",
          "46: from tensorflow.python.ops import control_flow_util",
          "47: from tensorflow.python.platform import tf_logging as logging",
          "49: from tensorflow.python.trackable import base",
          "50: from tensorflow.python.util import deprecation",
          "51: from tensorflow.python.util.tf_export import tf_export",
          "",
          "[Removed Lines]",
          "48: from tensorflow.python.tpu import tpu_strategy_util",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "540:     local_devices, local_device_type = self._initialize_local_devices(",
          "541:         cluster_resolver, self._worker_device)",
          "542:     if local_device_type == \"TPU\":",
          "545:     self._collective_keys = cross_device_utils.CollectiveKeys(",
          "546:         group_key_start=1 + self._collective_key_base)",
          "",
          "[Removed Lines]",
          "543:       tpu_strategy_util.initialize_tpu_system()",
          "",
          "[Added Lines]",
          "543:       tpu_cluster_resolver.initialize_tpu_system()",
          "",
          "---------------"
        ],
        "tensorflow/python/distribute/collective_all_reduce_strategy_test.py||tensorflow/python/distribute/collective_all_reduce_strategy_test.py": [
          "File: tensorflow/python/distribute/collective_all_reduce_strategy_test.py -> tensorflow/python/distribute/collective_all_reduce_strategy_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "35: from tensorflow.python.distribute import strategy_test_lib",
          "36: from tensorflow.python.distribute import test_util",
          "37: from tensorflow.python.distribute.cluster_resolver import cluster_resolver as cluster_resolver_lib",
          "38: from tensorflow.python.distribute.v1 import input_lib as input_lib_v1",
          "39: from tensorflow.python.eager import context",
          "40: from tensorflow.python.framework import config as tf_config",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "38: from tensorflow.python.distribute.cluster_resolver import tpu_cluster_resolver",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "52: from tensorflow.python.ops import variable_scope",
          "53: from tensorflow.python.ops import variables",
          "54: from tensorflow.python.platform import test",
          "56: from tensorflow.python.training import server_lib",
          "",
          "[Removed Lines]",
          "55: from tensorflow.python.tpu import tpu_strategy_util",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "76:   if num_tpus is None:",
          "77:     num_tpus = context.context().list_physical_devices('TPU')",
          "78:   if num_tpus:",
          "81:   if cluster_spec and task_type and task_id is not None:",
          "82:     cluster_resolver = cluster_resolver_lib.SimpleClusterResolver(",
          "",
          "[Removed Lines]",
          "79:     tpu_strategy_util.initialize_tpu_system()",
          "",
          "[Added Lines]",
          "79:     tpu_cluster_resolver.initialize_tpu_system()",
          "",
          "---------------"
        ],
        "tensorflow/python/distribute/parallel_device/parallel_device_test.py||tensorflow/python/distribute/parallel_device/parallel_device_test.py": [
          "File: tensorflow/python/distribute/parallel_device/parallel_device_test.py -> tensorflow/python/distribute/parallel_device/parallel_device_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: from tensorflow.python.checkpoint import checkpoint as tracking",
          "21: from tensorflow.python.checkpoint import checkpoint_management",
          "22: from tensorflow.python.data.ops import dataset_ops",
          "23: from tensorflow.python.distribute.parallel_device import parallel_device",
          "24: from tensorflow.python.eager import backprop",
          "25: from tensorflow.python.eager import context",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "23: from tensorflow.python.distribute.cluster_resolver import tpu_cluster_resolver",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "39: from tensorflow.python.platform import test",
          "40: from tensorflow.python.saved_model import load",
          "41: from tensorflow.python.saved_model import save",
          "43: from tensorflow.python.util import nest",
          "45: # When running collectives asynchronously, we need to give each parallel device",
          "",
          "[Removed Lines]",
          "42: from tensorflow.python.tpu import tpu_strategy_util",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "97:     ctx = context.context()",
          "98:     if ctx.list_physical_devices(\"TPU\"):",
          "99:       self.device_type = \"TPU\"",
          "101:     elif ctx.list_physical_devices(\"GPU\"):",
          "102:       self.device_type = \"GPU\"",
          "103:       gpus = ctx.list_physical_devices(self.device_type)",
          "",
          "[Removed Lines]",
          "100:       tpu_strategy_util.initialize_tpu_system()",
          "",
          "[Added Lines]",
          "100:       tpu_cluster_resolver.initialize_tpu_system()",
          "",
          "---------------"
        ],
        "tensorflow/python/distribute/strategy_combinations.py||tensorflow/python/distribute/strategy_combinations.py": [
          "File: tensorflow/python/distribute/strategy_combinations.py -> tensorflow/python/distribute/strategy_combinations.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "39: from tensorflow.python.framework import test_util as framework_test_util",
          "40: from tensorflow.python.platform import flags",
          "41: from tensorflow.python.tpu import device_assignment as device_assignment_lib",
          "43: from tensorflow.python.training import server_lib",
          "44: from tensorflow.python.util.tf_export import tf_export",
          "",
          "[Removed Lines]",
          "42: from tensorflow.python.tpu import tpu_strategy_util",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "105:       if getattr(FLAGS, \"tpu\", \"\") or did_automatically_resolve:",
          "106:         remote.connect_to_cluster(resolver)",
          "107:         _did_connect_to_cluster = True",
          "110:     device_assignment = None",
          "111:     if use_single_core:",
          "",
          "[Removed Lines]",
          "108:       _topology = tpu_strategy_util.initialize_tpu_system(resolver)",
          "",
          "[Added Lines]",
          "107:       _topology = tpu_cluster_resolver.initialize_tpu_system(resolver)",
          "",
          "---------------"
        ],
        "tensorflow/python/distribute/tpu_strategy.py||tensorflow/python/distribute/tpu_strategy.py": [
          "File: tensorflow/python/distribute/tpu_strategy.py -> tensorflow/python/distribute/tpu_strategy.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "62: from tensorflow.python.tpu import device_assignment as device_assignment_lib  # pylint: disable=unused-import",
          "63: from tensorflow.python.tpu import tpu",
          "64: from tensorflow.python.tpu import tpu_hardware_feature",
          "66: from tensorflow.python.tpu import training_loop",
          "67: from tensorflow.python.tpu.ops import tpu_ops",
          "68: from tensorflow.python.util import deprecation",
          "",
          "[Removed Lines]",
          "65: from tensorflow.python.tpu import tpu_strategy_util",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1239:     This is a private method only to be used by Estimator. Other frameworks",
          "1240:     should directly be calling `tf.tpu.experimental.initialize_tpu_system`",
          "1241:     \"\"\"",
          "1244:   def _create_variable(self, next_creator, **kwargs):",
          "1245:     \"\"\"Create a TPUMirroredVariable. See `DistributionStrategy.scope`.\"\"\"",
          "",
          "[Removed Lines]",
          "1242:     tpu_strategy_util.initialize_tpu_system(self._tpu_cluster_resolver)",
          "",
          "[Added Lines]",
          "1241:     tpu_cluster_resolver_lib.initialize_tpu_system(self._tpu_cluster_resolver)",
          "",
          "---------------"
        ],
        "tensorflow/python/distribute/tpu_strategy_compilation_test.py||tensorflow/python/distribute/tpu_strategy_compilation_test.py": [
          "File: tensorflow/python/distribute/tpu_strategy_compilation_test.py -> tensorflow/python/distribute/tpu_strategy_compilation_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: from tensorflow.python.eager import test",
          "22: from tensorflow.python.framework import constant_op",
          "23: from tensorflow.python.platform import flags",
          "26: FLAGS = flags.FLAGS",
          "27: flags.DEFINE_string(\"tpu\", \"\", \"Name of TPU to connect to.\")",
          "",
          "[Removed Lines]",
          "24: from tensorflow.python.tpu import tpu_strategy_util",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "41: def get_tpu_strategy():",
          "42:   resolver = get_tpu_cluster_resolver()",
          "43:   remote.connect_to_cluster(resolver)",
          "45:   strategy = tpu_lib.TPUStrategyV2(resolver)",
          "46:   return strategy",
          "",
          "[Removed Lines]",
          "44:   tpu_strategy_util.initialize_tpu_system(resolver)",
          "",
          "[Added Lines]",
          "43:   tpu_cluster_resolver.initialize_tpu_system(resolver)",
          "",
          "---------------"
        ],
        "tensorflow/python/distribute/tpu_strategy_model_parallelism_test.py||tensorflow/python/distribute/tpu_strategy_model_parallelism_test.py": [
          "File: tensorflow/python/distribute/tpu_strategy_model_parallelism_test.py -> tensorflow/python/distribute/tpu_strategy_model_parallelism_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "47: from tensorflow.python.platform import flags",
          "48: from tensorflow.python.tpu import device_assignment as device_assignment_lib",
          "49: from tensorflow.python.tpu import tpu_replication",
          "52: FLAGS = flags.FLAGS",
          "53: flags.DEFINE_string(\"tpu\", \"\", \"Name of TPU to connect to.\")",
          "",
          "[Removed Lines]",
          "50: from tensorflow.python.tpu import tpu_strategy_util",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "67: def get_tpu_strategy(enable_spmd=False):",
          "68:   resolver = get_tpu_cluster_resolver()",
          "69:   remote.connect_to_cluster(resolver)",
          "71:   num_replicas = resolver.get_tpu_system_metadata().num_cores // 2",
          "72:   device_assignment = device_assignment_lib.DeviceAssignment.build(",
          "73:       topology, num_replicas=num_replicas, computation_shape=[1, 1, 1, 2])",
          "",
          "[Removed Lines]",
          "70:   topology = tpu_strategy_util.initialize_tpu_system(resolver)",
          "",
          "[Added Lines]",
          "69:   topology = tpu_cluster_resolver.initialize_tpu_system(resolver)",
          "",
          "---------------"
        ],
        "tensorflow/python/distribute/tpu_strategy_test.py||tensorflow/python/distribute/tpu_strategy_test.py": [
          "File: tensorflow/python/distribute/tpu_strategy_test.py -> tensorflow/python/distribute/tpu_strategy_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "79: def get_tpu_strategy(enable_packed_var=False):",
          "80:   resolver = get_tpu_cluster_resolver()",
          "81:   remote.connect_to_cluster(resolver)",
          "83:   strategy = tpu_lib.TPUStrategyV2(resolver)",
          "84:   strategy._enable_packed_variable_in_eager_mode = enable_packed_var",
          "85:   return strategy",
          "",
          "[Removed Lines]",
          "82:   tpu_strategy_util.initialize_tpu_system(resolver)",
          "",
          "[Added Lines]",
          "82:   tpu_cluster_resolver.initialize_tpu_system(resolver)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "176:   def test_multiple_initialize_system(self):",
          "177:     resolver = get_tpu_cluster_resolver()",
          "178:     remote.connect_to_cluster(resolver)",
          "181:     with test.mock.patch.object(logging, \"warning\") as mock_log:",
          "183:       self.assertRegex(str(mock_log.call_args), \"already been initialized\")",
          "185:   def test_tpu_tf_function_same_device(self):",
          "186:     with ops.device(\"/device:TPU:0\"):",
          "187:       a = variables.Variable(1)",
          "",
          "[Removed Lines]",
          "179:     tpu_strategy_util.initialize_tpu_system(resolver)",
          "182:       tpu_strategy_util.initialize_tpu_system(resolver)",
          "",
          "[Added Lines]",
          "179:     tpu_cluster_resolver.initialize_tpu_system(resolver)",
          "182:       tpu_cluster_resolver.initialize_tpu_system(resolver)",
          "185:   def test_initialize_tpu_system_impl_input(self):",
          "186:     resolver = get_tpu_cluster_resolver()",
          "187:     with self.assertRaisesRegex(",
          "188:         TypeError,",
          "189:         r\"tpu_cluster_resolver_cls is not\"",
          "190:         r\" tf.distribute.cluster_resolver.TPUClusterResolver.\"):",
          "191:       tpu_strategy_util.initialize_tpu_system_impl(",
          "192:           resolver, tpu_cluster_resolver_cls=None)",
          "194:   def test_shutdown_tpu_system_impl_input(self):",
          "195:     resolver = get_tpu_cluster_resolver()",
          "196:     with self.assertRaisesRegex(",
          "197:         TypeError,",
          "198:         r\"tpu_cluster_resolver_cls is not\"",
          "199:         r\" tf.distribute.cluster_resolver.TPUClusterResolver.\"):",
          "200:       tpu_strategy_util.shutdown_tpu_system_impl(",
          "201:           resolver, tpu_cluster_resolver_cls=None)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "332:   def test_sequential_runs(self, enable_packed_var):",
          "333:     resolver = get_tpu_cluster_resolver()",
          "334:     remote.connect_to_cluster(resolver)",
          "336:     # Computation replicated to all cores.",
          "337:     device_assignment = device_assignment_lib.DeviceAssignment.build(",
          "338:         topology, num_replicas=2)",
          "",
          "[Removed Lines]",
          "335:     topology = tpu_strategy_util.initialize_tpu_system(resolver)",
          "",
          "[Added Lines]",
          "353:     topology = tpu_cluster_resolver.initialize_tpu_system(resolver)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "443:   def test_computation_on_subset_cores(self, enable_packed_var):",
          "444:     resolver = get_tpu_cluster_resolver()",
          "445:     remote.connect_to_cluster(resolver)",
          "447:     all_core_strategy = tpu_lib.TPUStrategyV2(resolver)",
          "448:     all_core_strategy._enable_packed_variable_in_eager_mode = enable_packed_var",
          "",
          "[Removed Lines]",
          "446:     topology = tpu_strategy_util.initialize_tpu_system(resolver)",
          "",
          "[Added Lines]",
          "464:     topology = tpu_cluster_resolver.initialize_tpu_system(resolver)",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "484:   def test_worker_devices_on_subset_cores(self, enable_packed_var):",
          "485:     resolver = get_tpu_cluster_resolver()",
          "486:     remote.connect_to_cluster(resolver)",
          "489:     # Strategy for the 1st core.",
          "490:     device_assignment = device_assignment_lib.DeviceAssignment.build(",
          "",
          "[Removed Lines]",
          "487:     topology = tpu_strategy_util.initialize_tpu_system(resolver)",
          "",
          "[Added Lines]",
          "505:     topology = tpu_cluster_resolver.initialize_tpu_system(resolver)",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "1181:     resolver = get_tpu_cluster_resolver()",
          "1182:     remote.connect_to_cluster(resolver)",
          "1184:     device_assignment = device_assignment_lib.DeviceAssignment(",
          "1185:         topology, core_assignment=[[[0, 0, 0, 1]], [[0, 0, 0, 0]]]",
          "1186:     )",
          "",
          "[Removed Lines]",
          "1183:     topology = tpu_strategy_util.initialize_tpu_system(resolver)",
          "",
          "[Added Lines]",
          "1201:     topology = tpu_cluster_resolver.initialize_tpu_system(resolver)",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "1317:   def test_update_config_proto(self):",
          "1318:     resolver = get_tpu_cluster_resolver()",
          "1319:     remote.connect_to_cluster(resolver)",
          "1321:     strategy = tpu_lib.TPUStrategyV2(resolver)",
          "1323:     config_proto = config_pb2.ConfigProto()",
          "",
          "[Removed Lines]",
          "1320:     tpu_strategy_util.initialize_tpu_system(resolver)",
          "",
          "[Added Lines]",
          "1338:     tpu_cluster_resolver.initialize_tpu_system(resolver)",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "1449:   def test_core_assignment(self):",
          "1450:     resolver = get_tpu_cluster_resolver()",
          "1451:     remote.connect_to_cluster(resolver)",
          "1453:     device_assignment = device_assignment_lib.DeviceAssignment(",
          "1454:         topology, core_assignment=[[[0, 0, 0, 0]]])",
          "1455:     self.assertAllEqual([[[0, 0, 0, 0]]], device_assignment.core_assignment)",
          "",
          "[Removed Lines]",
          "1452:     topology = tpu_strategy_util.initialize_tpu_system(resolver)",
          "",
          "[Added Lines]",
          "1470:     topology = tpu_cluster_resolver.initialize_tpu_system(resolver)",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "1461:   def test_device_assignment_strategy_properties(self):",
          "1462:     resolver = get_tpu_cluster_resolver()",
          "1463:     remote.connect_to_cluster(resolver)",
          "1465:     device_assignment = device_assignment_lib.DeviceAssignment(",
          "1466:         topology, core_assignment=[[[0, 0, 0, 0]]])",
          "1467:     strategy = tpu_lib.TPUStrategyV2(",
          "",
          "[Removed Lines]",
          "1464:     topology = tpu_strategy_util.initialize_tpu_system(resolver)",
          "",
          "[Added Lines]",
          "1482:     topology = tpu_cluster_resolver.initialize_tpu_system(resolver)",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "1474:   def test_device_assignment_constants(self):",
          "1475:     resolver = get_tpu_cluster_resolver()",
          "1476:     remote.connect_to_cluster(resolver)",
          "1478:     device_assignment = device_assignment_lib.DeviceAssignment(",
          "1479:         topology,",
          "1480:         core_assignment=device_assignment_lib.SINGLE_CORE_ASSIGNMENT)",
          "",
          "[Removed Lines]",
          "1477:     topology = tpu_strategy_util.initialize_tpu_system(resolver)",
          "",
          "[Added Lines]",
          "1495:     topology = tpu_cluster_resolver.initialize_tpu_system(resolver)",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "1487:   def test_variables_mismatched_device_assignment(self):",
          "1488:     resolver = get_tpu_cluster_resolver()",
          "1489:     remote.connect_to_cluster(resolver)",
          "1492:     strategy0 = tpu_lib.TPUStrategyV2(resolver)",
          "1493:     self.assertEqual(",
          "",
          "[Removed Lines]",
          "1490:     topology = tpu_strategy_util.initialize_tpu_system(resolver)",
          "",
          "[Added Lines]",
          "1508:     topology = tpu_cluster_resolver.initialize_tpu_system(resolver)",
          "",
          "---------------"
        ],
        "tensorflow/python/distribute/vars_test.py||tensorflow/python/distribute/vars_test.py": [
          "File: tensorflow/python/distribute/vars_test.py -> tensorflow/python/distribute/vars_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "42: from tensorflow.python.ops import variable_scope",
          "43: from tensorflow.python.ops import variable_v1",
          "44: from tensorflow.python.ops import variables as variables_lib",
          "46: from tensorflow.python.util import variable_utils",
          "",
          "[Removed Lines]",
          "45: from tensorflow.python.tpu import tpu_strategy_util",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "971:     for aggregation in aggregations:",
          "972:       if strategy_test_lib.is_tpu_strategy(distribution):",
          "973:         resolver = tpu_cluster_resolver.TPUClusterResolver(\"\")",
          "975:       with distribution.scope():",
          "976:         v = variable_v1.VariableV1(",
          "977:             0.,",
          "",
          "[Removed Lines]",
          "974:         tpu_strategy_util.initialize_tpu_system(resolver)",
          "",
          "[Added Lines]",
          "973:         tpu_cluster_resolver.initialize_tpu_system(resolver)",
          "",
          "---------------"
        ],
        "tensorflow/python/eager/remote.py||tensorflow/python/eager/remote.py": [
          "File: tensorflow/python/eager/remote.py -> tensorflow/python/eager/remote.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: from tensorflow.python import pywrap_tfe",
          "23: from tensorflow.python.distribute import device_util",
          "24: from tensorflow.python.distribute.cluster_resolver import cluster_resolver",
          "26: from tensorflow.python.eager import context",
          "27: from tensorflow.python.framework import ops",
          "28: from tensorflow.python.platform import remote_utils",
          "",
          "[Removed Lines]",
          "25: from tensorflow.python.distribute.cluster_resolver.tpu import tpu_cluster_resolver",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "184:     service_leader = \"\"",
          "185:     # Maybe enable coordination service for the communication protocol",
          "186:     # TODO(b/243839559): Fix UPTC + Coordination service crashing",
          "189:       is_uptc_sess = \".uptc-worker.\" in cluster_spec_or_resolver.master()",
          "190:       service_type = remote_utils.coordination_service_type(",
          "191:           protocol, is_uptc_sess)",
          "",
          "[Removed Lines]",
          "187:     if isinstance(cluster_spec_or_resolver,",
          "188:                   tpu_cluster_resolver.TPUClusterResolver):",
          "",
          "[Added Lines]",
          "186:     # Check if cluster_spec_or_resolver is an instance of",
          "187:     #    tpu_cluster_resolver.TPUClusterResolver",
          "188:     if (isinstance(cluster_spec_or_resolver, cluster_resolver.ClusterResolver)",
          "189:         and hasattr(cluster_spec_or_resolver, \"tpu_hardware_feature\")):",
          "",
          "---------------"
        ],
        "tensorflow/python/eager/remote_cloud_tpu_test.py||tensorflow/python/eager/remote_cloud_tpu_test.py": [
          "File: tensorflow/python/eager/remote_cloud_tpu_test.py -> tensorflow/python/eager/remote_cloud_tpu_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: from tensorflow.python.distribute.cluster_resolver import tpu_cluster_resolver",
          "21: from tensorflow.python.eager import remote",
          "22: from tensorflow.python.framework import config",
          "25: FLAGS = flags.FLAGS",
          "26: flags.DEFINE_string('tpu', '', 'Name of TPU to connect to.')",
          "",
          "[Removed Lines]",
          "23: from tensorflow.python.tpu import tpu_strategy_util",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "75:         expected_devices,",
          "76:         [device.name for device in config.list_logical_devices()])",
          "80: if __name__ == '__main__':",
          "81:   absltest.main()",
          "",
          "[Removed Lines]",
          "78:     tpu_strategy_util.initialize_tpu_system(resolver)",
          "",
          "[Added Lines]",
          "77:     tpu_cluster_resolver.initialize_tpu_system(resolver)",
          "",
          "---------------"
        ],
        "tensorflow/python/ops/memory_tests/custom_gradient_memory_test.py||tensorflow/python/ops/memory_tests/custom_gradient_memory_test.py": [
          "File: tensorflow/python/ops/memory_tests/custom_gradient_memory_test.py -> tensorflow/python/ops/memory_tests/custom_gradient_memory_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: from absl.testing import parameterized",
          "20: from tensorflow.compiler.xla.service import hlo_pb2",
          "21: from tensorflow.python.eager import backprop",
          "22: from tensorflow.python.eager import def_function",
          "23: from tensorflow.python.framework import config",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "21: from tensorflow.python.distribute.cluster_resolver import tpu_cluster_resolver",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "29: from tensorflow.python.ops import math_ops",
          "30: from tensorflow.python.platform import googletest",
          "31: from tensorflow.python.platform import test",
          "35: class RecomputeGradMemoryTest(test.TestCase, parameterized.TestCase):",
          "",
          "[Removed Lines]",
          "32: from tensorflow.python.tpu import tpu_strategy_util",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "116:     device_name = f\"{device_type}:0\"",
          "117:     # Necessary for TFRT tests.",
          "118:     if device_type == \"TPU\":",
          "121:     n = 500",
          "122:     with ops.device(device_name):",
          "",
          "[Removed Lines]",
          "119:       tpu_strategy_util.initialize_tpu_system()",
          "",
          "[Added Lines]",
          "119:       tpu_cluster_resolver.initialize_tpu_system()",
          "",
          "---------------"
        ],
        "tensorflow/python/tpu/tests/tpu_embedding_base_test.py||tensorflow/python/tpu/tests/tpu_embedding_base_test.py": [
          "File: tensorflow/python/tpu/tests/tpu_embedding_base_test.py -> tensorflow/python/tpu/tests/tpu_embedding_base_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "35: from tensorflow.python.platform import test",
          "36: from tensorflow.python.tpu import tpu_embedding_v2",
          "37: from tensorflow.python.tpu import tpu_embedding_v2_utils",
          "39: from tensorflow.python.util import nest",
          "41: FLAGS = flags.FLAGS",
          "",
          "[Removed Lines]",
          "38: from tensorflow.python.tpu import tpu_strategy_util",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "154:       self.resolver._cloud_tpu_client.configure_tpu_version(",
          "155:           version='nightly', restart_type='always')",
          "156:     remote.connect_to_cluster(self.resolver)",
          "158:     return tpu_strategy.TPUStrategy(self.resolver)",
          "160:   def _create_mid_level(self, optimizer=None):",
          "",
          "[Removed Lines]",
          "157:     tpu_strategy_util.initialize_tpu_system(self.resolver)",
          "",
          "[Added Lines]",
          "156:     tpu_cluster_resolver.initialize_tpu_system(self.resolver)",
          "",
          "---------------"
        ],
        "tensorflow/python/tpu/tests/tpu_embedding_v2_checkpoint_test.py||tensorflow/python/tpu/tests/tpu_embedding_v2_checkpoint_test.py": [
          "File: tensorflow/python/tpu/tests/tpu_embedding_v2_checkpoint_test.py -> tensorflow/python/tpu/tests/tpu_embedding_v2_checkpoint_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: import numpy as np",
          "19: from tensorflow.python.checkpoint import checkpoint as util",
          "20: from tensorflow.python.compat import v2_compat",
          "21: from tensorflow.python.eager import def_function",
          "22: from tensorflow.python.framework import constant_op",
          "23: from tensorflow.python.framework import dtypes",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "21: from tensorflow.python.distribute.cluster_resolver import tpu_cluster_resolver",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "31: from tensorflow.python.tpu import tpu_embedding_for_serving",
          "32: from tensorflow.python.tpu import tpu_embedding_v2",
          "33: from tensorflow.python.tpu import tpu_embedding_v2_utils",
          "35: from tensorflow.python.tpu.tests import tpu_embedding_base_test",
          "36: from tensorflow.python.training import checkpoint_utils",
          "",
          "[Removed Lines]",
          "34: from tensorflow.python.tpu import tpu_strategy_util",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "86:         msg='Checkpoint should contain values from the first api object.')",
          "88:     # Reinitialize the tpu.",
          "91:     with strategy.scope():",
          "92:       second_mid_level_contents = np.ones((num_rows, 4)) * 2",
          "",
          "[Removed Lines]",
          "89:     tpu_strategy_util.initialize_tpu_system(self.resolver)",
          "",
          "[Added Lines]",
          "89:     tpu_cluster_resolver.initialize_tpu_system(self.resolver)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "148:     first_checkpoint = util.Checkpoint(model=first_mid_level)",
          "149:     first_checkpoint.save(self._get_tmpdir('restore', 'save'))",
          "153:     with strategy.scope():",
          "154:       second_mid_level_contents = np.ones((num_rows, 4)) * 2",
          "",
          "[Removed Lines]",
          "151:     tpu_strategy_util.initialize_tpu_system(self.resolver)",
          "",
          "[Added Lines]",
          "151:     tpu_cluster_resolver.initialize_tpu_system(self.resolver)",
          "",
          "---------------"
        ],
        "tensorflow/python/tpu/tests/tpu_initialization_test.py||tensorflow/python/tpu/tests/tpu_initialization_test.py": [
          "File: tensorflow/python/tpu/tests/tpu_initialization_test.py -> tensorflow/python/tpu/tests/tpu_initialization_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: from tensorflow.python.compat import v2_compat",
          "20: from tensorflow.python.distribute.cluster_resolver import tpu_cluster_resolver",
          "21: from tensorflow.python.platform import test",
          "25: class TPUInitializationTest(parameterized.TestCase, test.TestCase):",
          "27:   def test_tpu_initialization(self):",
          "28:     resolver = tpu_cluster_resolver.TPUClusterResolver('')",
          "32: if __name__ == '__main__':",
          "",
          "[Removed Lines]",
          "22: from tensorflow.python.tpu import tpu_strategy_util",
          "29:     tpu_strategy_util.initialize_tpu_system(resolver)",
          "",
          "[Added Lines]",
          "28:     tpu_cluster_resolver.initialize_tpu_system(resolver)",
          "",
          "---------------"
        ],
        "tensorflow/python/tpu/tpu_outside_compilation_test.py||tensorflow/python/tpu/tpu_outside_compilation_test.py": [
          "File: tensorflow/python/tpu/tpu_outside_compilation_test.py -> tensorflow/python/tpu/tpu_outside_compilation_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "51: from tensorflow.python.tpu import functional as tpu_functional",
          "52: from tensorflow.python.tpu import tpu",
          "53: from tensorflow.python.tpu import tpu_replication",
          "55: from tensorflow.python.tpu.ops import tpu_ops",
          "57: FLAGS = flags.FLAGS",
          "",
          "[Removed Lines]",
          "54: from tensorflow.python.tpu import tpu_strategy_util",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "72: def get_tpu_strategy():",
          "73:   resolver = get_tpu_cluster_resolver()",
          "74:   remote.connect_to_cluster(resolver)",
          "76:   return tpu_lib.TPUStrategyV2(resolver)",
          "",
          "[Removed Lines]",
          "75:   tpu_strategy_util.initialize_tpu_system(resolver)",
          "",
          "[Added Lines]",
          "74:   tpu_cluster_resolver.initialize_tpu_system(resolver)",
          "",
          "---------------"
        ],
        "tensorflow/python/tpu/tpu_strategy_util.py||tensorflow/python/tpu/tpu_strategy_util.py": [
          "File: tensorflow/python/tpu/tpu_strategy_util.py -> tensorflow/python/tpu/tpu_strategy_util.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: from tensorflow.core.protobuf import config_pb2",
          "20: from tensorflow.python.client import session as session_lib",
          "22: from tensorflow.python.eager import context",
          "23: from tensorflow.python.eager import monitoring",
          "27: from tensorflow.python.framework import device",
          "28: from tensorflow.python.framework import errors",
          "29: from tensorflow.python.framework import ops",
          "",
          "[Removed Lines]",
          "21: from tensorflow.python.distribute.cluster_resolver.tpu import tpu_cluster_resolver",
          "24: from tensorflow.python.eager.def_function import function",
          "25: from tensorflow.python.eager.def_function import functions_run_eagerly",
          "26: from tensorflow.python.eager.def_function import run_functions_eagerly",
          "",
          "[Added Lines]",
          "21: from tensorflow.python.distribute.cluster_resolver import cluster_resolver as cluster_resolver_lib",
          "23: from tensorflow.python.eager import def_function",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "31: from tensorflow.python.tpu import topology",
          "32: from tensorflow.python.tpu import tpu",
          "33: from tensorflow.python.util import compat",
          "37: _INITIALIZED_TPU_SYSTEMS = {}",
          "",
          "[Removed Lines]",
          "34: from tensorflow.python.util.tf_export import tf_export",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "43:     \"The worker address that the coordinator/client connects to.\", \"address\")",
          "50:   Args:",
          "51:     cluster_resolver: A tf.distribute.cluster_resolver.TPUClusterResolver,",
          "52:         which provides information about the TPU cluster.",
          "53:   Returns:",
          "54:     The tf.tpu.Topology object for the topology of the TPU cluster. If called",
          "55:     inside tf.function, it returns the serialized topology object instead.",
          "",
          "[Removed Lines]",
          "46: @tf_export(\"tpu.experimental.initialize_tpu_system\")",
          "47: def initialize_tpu_system(cluster_resolver=None):",
          "48:   \"\"\"Initialize the TPU devices.",
          "",
          "[Added Lines]",
          "43: def initialize_tpu_system_impl(cluster_resolver, tpu_cluster_resolver_cls):",
          "44:   \"\"\"Implementation for tpu.experimental.initialize_tpu_system.",
          "46:   Kept separate to avoid tpu_oss code duplication.",
          "48:   Initialize the TPU devices.",
          "53:     tpu_cluster_resolver_cls: a reference to",
          "54:         tf.distribute.cluster_resolver.TPUClusterResolver so that an instance",
          "55:         of it can be initialized if cluster_resolver is None.",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "57:   Raises:",
          "58:     RuntimeError: If running inside a tf.function.",
          "59:     NotFoundError: If no TPU devices found in eager mode.",
          "60:   \"\"\"",
          "62:   # Deallocate all TPU buffers by clearing out eager context caches and",
          "63:   # triggering garbage collection to avoid keeping invalid tpu buffer around",
          "64:   # after reinitialized tpu system.",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "63:     TypeError: If tpu_cluster_resolver_cls is",
          "64:         not tf.distribute.cluster_resolver.TPUClusterResolver.",
          "66:   # check that tpu_cluster_resolver_cls is a",
          "67:   # tf.distribute.cluster_resolver.TPUClusterResolver",
          "68:   if tpu_cluster_resolver_cls is None or not issubclass(",
          "69:       tpu_cluster_resolver_cls, cluster_resolver_lib.ClusterResolver",
          "70:   ) or not hasattr(tpu_cluster_resolver_cls, \"tpu_hardware_feature\"):",
          "71:     raise TypeError(",
          "72:         \"tpu_cluster_resolver_cls is not\"",
          "73:         \" tf.distribute.cluster_resolver.TPUClusterResolver.\")",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "76:       if curr_device.job is not None:",
          "77:         job = \"{}/replica:0/task:0\".format(curr_device.job)",
          "82:   tpu_name = compat.as_text(cluster_resolver._tpu)  # pylint: disable=protected-access",
          "83:   if tpu_name in _INITIALIZED_TPU_SYSTEMS:",
          "",
          "[Removed Lines]",
          "79:     cluster_resolver = tpu_cluster_resolver.TPUClusterResolver(\"\")",
          "80:   assert isinstance(cluster_resolver, tpu_cluster_resolver.TPUClusterResolver)",
          "",
          "[Added Lines]",
          "91:     cluster_resolver = tpu_cluster_resolver_cls(\"\")",
          "92:   assert isinstance(cluster_resolver, tpu_cluster_resolver_cls)",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "99:     job = \"{}/replica:0/task:0\".format(cluster_resolver.get_job_name())",
          "101:   if context.executing_eagerly():",
          "103:     def _tpu_init_fn():",
          "104:       # In TF1, we usually close chips when compilation fails to clear the data",
          "105:       # in infeed. In TF2, we don't need to do this because infeed is no longer",
          "",
          "[Removed Lines]",
          "102:     @function(autograph=False)",
          "",
          "[Added Lines]",
          "114:     @def_function.function(autograph=False)",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "113:     # The TPU_SYSTEM device must match the device used in tpu.initialize_system",
          "114:     # exactly, otherwise you can get errors if there are multiple TPU_SYSTEM",
          "115:     # devices available.",
          "117:     if run_eagerly:",
          "118:       logging.warning(",
          "119:           \"It looks like tf.function behavior was disabled, perhaps using\"",
          "",
          "[Removed Lines]",
          "116:     run_eagerly = functions_run_eagerly()",
          "",
          "[Added Lines]",
          "128:     run_eagerly = def_function.functions_run_eagerly()",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "121:           \" tf.tpu.experimental.initialize_tpu_system requires tf.function to\"",
          "122:           \" work. This primitive will override the disable.\"",
          "123:       )",
          "125:     try:",
          "126:       with ops.device(tpu._tpu_system_device_name(job)):  # pylint: disable=protected-access",
          "127:         output = _tpu_init_fn()",
          "",
          "[Removed Lines]",
          "124:       run_functions_eagerly(False)",
          "",
          "[Added Lines]",
          "136:       def_function.run_functions_eagerly(False)",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "133:           + str(e))",
          "134:     finally:",
          "135:       if run_eagerly is not None:",
          "137:     # Clear out the eager context caches since the memory is invalid now.",
          "138:     context.context()._initialize_logical_devices()  # pylint: disable=protected-access",
          "",
          "[Removed Lines]",
          "136:         run_functions_eagerly(run_eagerly)",
          "",
          "[Added Lines]",
          "148:         def_function.run_functions_eagerly(run_eagerly)",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "181:   return _INITIALIZED_TPU_SYSTEMS.copy()",
          "188:   This will clear all caches, even those that are maintained through sequential",
          "189:   calls to tf.tpu.experimental.initialize_tpu_system, such as the compilation",
          "",
          "[Removed Lines]",
          "184: @tf_export(\"tpu.experimental.shutdown_tpu_system\")",
          "185: def shutdown_tpu_system(cluster_resolver=None):",
          "186:   \"\"\"Shuts down the TPU devices.",
          "",
          "[Added Lines]",
          "196: def shutdown_tpu_system_impl(cluster_resolver, tpu_cluster_resolver_cls):",
          "197:   \"\"\"Implementation for tpu.experimental.shutdown_tpu_system.",
          "199:   Kept separate to avoid tpu_oss code duplication.",
          "201:   Shuts down the TPU devices.",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "192:   Args:",
          "193:     cluster_resolver: A tf.distribute.cluster_resolver.TPUClusterResolver,",
          "194:         which provides information about the TPU cluster.",
          "196:   Raises:",
          "197:     RuntimeError: If no TPU devices found for eager execution or if run in a",
          "198:         tf.function.",
          "199:   \"\"\"",
          "200:   job = None",
          "201:   if cluster_resolver is None:",
          "202:     # If no cluster resolver is specified, and running eagerly, execute the init",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "210:     tpu_cluster_resolver_cls: a reference to",
          "211:         tf.distribute.cluster_resolver.TPUClusterResolver so that an instance",
          "212:         of it can be initialized if cluster_resolver is None.",
          "217:     TypeError: If tpu_cluster_resolver_cls is",
          "218:         not tf.distribute.cluster_resolver.TPUClusterResolver.",
          "220:   # check that tpu_cluster_resolver_cls is a",
          "221:   # tf.distribute.cluster_resolver.TPUClusterResolver",
          "222:   if tpu_cluster_resolver_cls is None or not issubclass(",
          "223:       tpu_cluster_resolver_cls, cluster_resolver_lib.ClusterResolver",
          "224:   ) or not hasattr(tpu_cluster_resolver_cls, \"tpu_hardware_feature\"):",
          "225:     raise TypeError(",
          "226:         \"tpu_cluster_resolver_cls is not\"",
          "227:         \" tf.distribute.cluster_resolver.TPUClusterResolver.\")",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "206:       if curr_device.job is not None:",
          "207:         job = \"{}/replica:0/task:0\".format(curr_device.job)",
          "212:   tpu_name = compat.as_text(cluster_resolver._tpu)  # pylint: disable=protected-access",
          "213:   if tpu_name not in _INITIALIZED_TPU_SYSTEMS:",
          "",
          "[Removed Lines]",
          "209:     cluster_resolver = tpu_cluster_resolver.TPUClusterResolver(\"\")",
          "210:   assert isinstance(cluster_resolver, tpu_cluster_resolver.TPUClusterResolver)",
          "",
          "[Added Lines]",
          "238:     cluster_resolver = tpu_cluster_resolver_cls(\"\")",
          "239:   assert isinstance(cluster_resolver, tpu_cluster_resolver_cls)",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "227:       # avoid the output node match multiple devices error.",
          "228:       job = \"{}/replica:0/task:0\".format(cluster_resolver.get_job_name())",
          "231:     def _tpu_shutdown_fn():",
          "232:       tpu.shutdown_system(job=job)",
          "234:     # The TPU_SYSTEM device must match the device used in tpu.shutdown_system",
          "235:     # exactly, otherwise you can get errors if there are multiple TPU_SYSTEM",
          "236:     # devices available.",
          "238:     if run_eagerly:",
          "239:       logging.warning(",
          "240:           \"It looks like tf.function behavior was disabled, perhaps using\"",
          "",
          "[Removed Lines]",
          "230:     @function(autograph=False)",
          "237:     run_eagerly = functions_run_eagerly()",
          "",
          "[Added Lines]",
          "259:     @def_function.function(autograph=False)",
          "266:     run_eagerly = def_function.functions_run_eagerly()",
          "",
          "---------------",
          "--- Hunk 14 ---",
          "[Context before]",
          "242:           \" tf.tpu.experimental.shutdown_tpu_system requires tf.function to\"",
          "243:           \" work. This primitive will override the disable.\"",
          "244:       )",
          "246:     try:",
          "247:       with ops.device(tpu._tpu_system_device_name(job)):  # pylint: disable=protected-access",
          "248:         _tpu_shutdown_fn()",
          "249:     finally:",
          "250:       if run_eagerly is not None:",
          "253:     # Clear out the eager context caches since the memory is invalid now.",
          "254:     logging.info(\"Clearing out eager caches\")",
          "",
          "[Removed Lines]",
          "245:       run_functions_eagerly(False)",
          "251:         run_functions_eagerly(run_eagerly)",
          "",
          "[Added Lines]",
          "274:       def_function.run_functions_eagerly(False)",
          "280:         def_function.run_functions_eagerly(run_eagerly)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "f04ab1f59e6adc2c32efd739a2d9bd0bb51feb78",
      "candidate_info": {
        "commit_hash": "f04ab1f59e6adc2c32efd739a2d9bd0bb51feb78",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/f04ab1f59e6adc2c32efd739a2d9bd0bb51feb78",
        "files": [
          "third_party/tf_runtime/workspace.bzl",
          "third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl"
        ],
        "message": "Update TFRT dependency to use revision http://github.com/tensorflow/runtime/commit/926cadbbf571d364512bd90806b3049a312dcf84.\n\nPiperOrigin-RevId: 591122477",
        "before_after_code_files": [
          "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl",
          "third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl||third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl"
          ],
          "candidate": [
            "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl"
          ]
        }
      },
      "candidate_diff": {
        "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl": [
          "File: third_party/tf_runtime/workspace.bzl -> third_party/tf_runtime/workspace.bzl",
          "--- Hunk 1 ---",
          "[Context before]",
          "6:     \"\"\"Imports TFRT.\"\"\"",
          "8:     # Attention: tools parse and update these lines.",
          "12:     tf_http_archive(",
          "13:         name = \"tf_runtime\",",
          "",
          "[Removed Lines]",
          "9:     TFRT_COMMIT = \"dc27fed599a9c25a47a4ccc9048601faac7aa5f3\"",
          "10:     TFRT_SHA256 = \"589c994a6ebcfbca84e1e745fb2f20165d712bb76089e72f8862ed4866aa888b\"",
          "",
          "[Added Lines]",
          "9:     TFRT_COMMIT = \"926cadbbf571d364512bd90806b3049a312dcf84\"",
          "10:     TFRT_SHA256 = \"6093a5b169004f92ee395adca058b5d9f9218609fb5176888c0725b8f889fcdd\"",
          "",
          "---------------"
        ],
        "third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl||third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl": [
          "File: third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl -> third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl",
          "--- Hunk 1 ---",
          "[Context before]",
          "6:     \"\"\"Imports TFRT.\"\"\"",
          "8:     # Attention: tools parse and update these lines.",
          "12:     tf_http_archive(",
          "13:         name = \"tf_runtime\",",
          "",
          "[Removed Lines]",
          "9:     TFRT_COMMIT = \"dc27fed599a9c25a47a4ccc9048601faac7aa5f3\"",
          "10:     TFRT_SHA256 = \"589c994a6ebcfbca84e1e745fb2f20165d712bb76089e72f8862ed4866aa888b\"",
          "",
          "[Added Lines]",
          "9:     TFRT_COMMIT = \"926cadbbf571d364512bd90806b3049a312dcf84\"",
          "10:     TFRT_SHA256 = \"6093a5b169004f92ee395adca058b5d9f9218609fb5176888c0725b8f889fcdd\"",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "74835a3bea4b869564c0e07849c05f8e8523c2a4",
      "candidate_info": {
        "commit_hash": "74835a3bea4b869564c0e07849c05f8e8523c2a4",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/74835a3bea4b869564c0e07849c05f8e8523c2a4",
        "files": [
          "third_party/tf_runtime/workspace.bzl"
        ],
        "message": "Update TFRT dependency to use revision http://github.com/tensorflow/runtime/commit/2a140a18fe10879d3c93cd7e32b0b6991d5bf27b.\n\nPiperOrigin-RevId: 508176170",
        "before_after_code_files": [
          "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl"
          ],
          "candidate": [
            "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl"
          ]
        }
      },
      "candidate_diff": {
        "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl": [
          "File: third_party/tf_runtime/workspace.bzl -> third_party/tf_runtime/workspace.bzl",
          "--- Hunk 1 ---",
          "[Context before]",
          "6:     \"\"\"Imports TFRT.\"\"\"",
          "8:     # Attention: tools parse and update these lines.",
          "12:     tf_http_archive(",
          "13:         name = \"tf_runtime\",",
          "",
          "[Removed Lines]",
          "9:     TFRT_COMMIT = \"af4bc12b47591e963158cb5474d3b417d4e64170\"",
          "10:     TFRT_SHA256 = \"dabc7e58e115c463302c7f08ce4889caf7632c6e1f3f2f614e8670a7d2ccd3ad\"",
          "",
          "[Added Lines]",
          "9:     TFRT_COMMIT = \"2a140a18fe10879d3c93cd7e32b0b6991d5bf27b\"",
          "10:     TFRT_SHA256 = \"4d3a244f0432088e59af9538ce04cae7bea38a5d2625aa863a25d5208e8a5ebd\"",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "c57315017a07a1750193b8dbe510efdc75dc9a28",
      "candidate_info": {
        "commit_hash": "c57315017a07a1750193b8dbe510efdc75dc9a28",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/c57315017a07a1750193b8dbe510efdc75dc9a28",
        "files": [
          "third_party/tf_runtime/workspace.bzl",
          "third_party/xla/third_party/tf_runtime/workspace.bzl",
          "third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl"
        ],
        "message": "Update TFRT dependency to use revision http://github.com/tensorflow/runtime/commit/9d58a7aefd3b0b184bfc30be383bdbe17c5233ae.\n\nPiperOrigin-RevId: 568866604",
        "before_after_code_files": [
          "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl",
          "third_party/xla/third_party/tf_runtime/workspace.bzl||third_party/xla/third_party/tf_runtime/workspace.bzl",
          "third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl||third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl"
          ],
          "candidate": [
            "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl"
          ]
        }
      },
      "candidate_diff": {
        "third_party/tf_runtime/workspace.bzl||third_party/tf_runtime/workspace.bzl": [
          "File: third_party/tf_runtime/workspace.bzl -> third_party/tf_runtime/workspace.bzl",
          "--- Hunk 1 ---",
          "[Context before]",
          "6:     \"\"\"Imports TFRT.\"\"\"",
          "8:     # Attention: tools parse and update these lines.",
          "12:     tf_http_archive(",
          "13:         name = \"tf_runtime\",",
          "",
          "[Removed Lines]",
          "9:     TFRT_COMMIT = \"ad4ba135f9a5ca24862daf7c93e4a3b6e53c69c8\"",
          "10:     TFRT_SHA256 = \"f523256aa10d35e9c2f8c2d7e5674e8496aef7fd2a6547942696462d0d0497f6\"",
          "",
          "[Added Lines]",
          "9:     TFRT_COMMIT = \"9d58a7aefd3b0b184bfc30be383bdbe17c5233ae\"",
          "10:     TFRT_SHA256 = \"f0bd547a2a36e4866af3101c9f3c7da39e66fe77ead83bf8b2fdc1c9b5674ce0\"",
          "",
          "---------------"
        ],
        "third_party/xla/third_party/tf_runtime/workspace.bzl||third_party/xla/third_party/tf_runtime/workspace.bzl": [
          "File: third_party/xla/third_party/tf_runtime/workspace.bzl -> third_party/xla/third_party/tf_runtime/workspace.bzl",
          "--- Hunk 1 ---",
          "[Context before]",
          "6:     \"\"\"Imports TFRT.\"\"\"",
          "8:     # Attention: tools parse and update these lines.",
          "12:     tf_http_archive(",
          "13:         name = \"tf_runtime\",",
          "",
          "[Removed Lines]",
          "9:     TFRT_COMMIT = \"ad4ba135f9a5ca24862daf7c93e4a3b6e53c69c8\"",
          "10:     TFRT_SHA256 = \"f523256aa10d35e9c2f8c2d7e5674e8496aef7fd2a6547942696462d0d0497f6\"",
          "",
          "[Added Lines]",
          "9:     TFRT_COMMIT = \"9d58a7aefd3b0b184bfc30be383bdbe17c5233ae\"",
          "10:     TFRT_SHA256 = \"f0bd547a2a36e4866af3101c9f3c7da39e66fe77ead83bf8b2fdc1c9b5674ce0\"",
          "",
          "---------------"
        ],
        "third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl||third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl": [
          "File: third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl -> third_party/xla/third_party/tsl/third_party/tf_runtime/workspace.bzl",
          "--- Hunk 1 ---",
          "[Context before]",
          "6:     \"\"\"Imports TFRT.\"\"\"",
          "8:     # Attention: tools parse and update these lines.",
          "12:     tf_http_archive(",
          "13:         name = \"tf_runtime\",",
          "",
          "[Removed Lines]",
          "9:     TFRT_COMMIT = \"ad4ba135f9a5ca24862daf7c93e4a3b6e53c69c8\"",
          "10:     TFRT_SHA256 = \"f523256aa10d35e9c2f8c2d7e5674e8496aef7fd2a6547942696462d0d0497f6\"",
          "",
          "[Added Lines]",
          "9:     TFRT_COMMIT = \"9d58a7aefd3b0b184bfc30be383bdbe17c5233ae\"",
          "10:     TFRT_SHA256 = \"f0bd547a2a36e4866af3101c9f3c7da39e66fe77ead83bf8b2fdc1c9b5674ce0\"",
          "",
          "---------------"
        ]
      }
    }
  ]
}