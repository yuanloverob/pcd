{
  "cve_id": "CVE-2022-35967",
  "cve_desc": "TensorFlow is an open source platform for machine learning. If `QuantizedAdd` is given `min_input` or `max_input` tensors of a nonzero rank, it results in a segfault that can be used to trigger a denial of service attack. We have patched the issue in GitHub commit 49b3824d83af706df0ad07e4e677d88659756d89. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
  "repo": "tensorflow/tensorflow",
  "patch_hash": "49b3824d83af706df0ad07e4e677d88659756d89",
  "patch_info": {
    "commit_hash": "49b3824d83af706df0ad07e4e677d88659756d89",
    "repo": "tensorflow/tensorflow",
    "commit_url": "https://github.com/tensorflow/tensorflow/commit/49b3824d83af706df0ad07e4e677d88659756d89",
    "files": [
      "tensorflow/core/kernels/quantized_activation_ops.cc",
      "tensorflow/core/kernels/quantized_activation_ops_test.cc",
      "tensorflow/core/kernels/quantized_add_op.cc",
      "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
    ],
    "message": "Add IsScalar (rank == 0) check to min/max input tensors for QuantizedAdd/Relu/Relu6 op.\n\nPiperOrigin-RevId: 461902847",
    "before_after_code_files": [
      "tensorflow/core/kernels/quantized_activation_ops.cc||tensorflow/core/kernels/quantized_activation_ops.cc",
      "tensorflow/core/kernels/quantized_activation_ops_test.cc||tensorflow/core/kernels/quantized_activation_ops_test.cc",
      "tensorflow/core/kernels/quantized_add_op.cc||tensorflow/core/kernels/quantized_add_op.cc",
      "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
    ]
  },
  "patch_diff": {
    "tensorflow/core/kernels/quantized_activation_ops.cc||tensorflow/core/kernels/quantized_activation_ops.cc": [
      "File: tensorflow/core/kernels/quantized_activation_ops.cc -> tensorflow/core/kernels/quantized_activation_ops.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "33:   void Compute(OpKernelContext* context) override {",
      "34:     const Tensor& input = context->input(0);",
      "37:     Tensor* output = nullptr;",
      "38:     OP_REQUIRES_OK(context,",
      "39:                    context->allocate_output(0, input.shape(), &output));",
      "",
      "[Removed Lines]",
      "35:     const float min_input = context->input(1).flat<float>()(0);",
      "36:     const float max_input = context->input(2).flat<float>()(0);",
      "",
      "[Added Lines]",
      "35:     const Tensor& min_input_tensor = context->input(1);",
      "36:     const Tensor& max_input_tensor = context->input(2);",
      "38:     OP_REQUIRES(",
      "39:         context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),",
      "40:         errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",",
      "41:                                 min_input_tensor.dims()));",
      "42:     OP_REQUIRES(",
      "43:         context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),",
      "44:         errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",",
      "45:                                 max_input_tensor.dims()));",
      "47:     const float min_input = min_input_tensor.scalar<float>()();",
      "48:     const float max_input = max_input_tensor.scalar<float>()();",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "66:   void Compute(OpKernelContext* context) override {",
      "67:     const Tensor& input = context->input(0);",
      "70:     Tensor* output = nullptr;",
      "71:     OP_REQUIRES_OK(context,",
      "72:                    context->allocate_output(0, input.shape(), &output));",
      "",
      "[Removed Lines]",
      "68:     const float min_input = context->input(1).flat<float>()(0);",
      "69:     const float max_input = context->input(2).flat<float>()(0);",
      "",
      "[Added Lines]",
      "81:     const Tensor& min_input_tensor = context->input(1);",
      "82:     const Tensor& max_input_tensor = context->input(2);",
      "84:     OP_REQUIRES(",
      "85:         context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),",
      "86:         errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",",
      "87:                                 min_input_tensor.dims()));",
      "88:     OP_REQUIRES(",
      "89:         context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),",
      "90:         errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",",
      "91:                                 max_input_tensor.dims()));",
      "93:     const float min_input = min_input_tensor.scalar<float>()();",
      "94:     const float max_input = max_input_tensor.scalar<float>()();",
      "",
      "---------------"
    ],
    "tensorflow/core/kernels/quantized_activation_ops_test.cc||tensorflow/core/kernels/quantized_activation_ops_test.cc": [
      "File: tensorflow/core/kernels/quantized_activation_ops_test.cc -> tensorflow/core/kernels/quantized_activation_ops_test.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "56:   AddInputFromArray<quint8>(input_quantized.shape(),",
      "57:                             input_quantized.flat<quint8>());",
      "60:   TF_ASSERT_OK(RunOpKernel());",
      "61:   const Tensor& output_quantized = *GetOutput(0);",
      "62:   const float output_min = GetOutput(1)->flat<float>()(0);",
      "",
      "[Removed Lines]",
      "58:   AddInputFromArray<float>(TensorShape({1}), {input_min});",
      "59:   AddInputFromArray<float>(TensorShape({1}), {input_max});",
      "",
      "[Added Lines]",
      "58:   AddInputFromArray<float>(TensorShape({}), {input_min});",
      "59:   AddInputFromArray<float>(TensorShape({}), {input_max});",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "87:   AddInputFromArray<quint8>(input_quantized.shape(),",
      "88:                             input_quantized.flat<quint8>());",
      "91:   TF_ASSERT_OK(RunOpKernel());",
      "92:   const Tensor& output_quantized = *GetOutput(0);",
      "93:   const float output_min = GetOutput(1)->flat<float>()(0);",
      "",
      "[Removed Lines]",
      "89:   AddInputFromArray<float>(TensorShape({1}), {input_min});",
      "90:   AddInputFromArray<float>(TensorShape({1}), {input_max});",
      "",
      "[Added Lines]",
      "89:   AddInputFromArray<float>(TensorShape({}), {input_min});",
      "90:   AddInputFromArray<float>(TensorShape({}), {input_max});",
      "",
      "---------------"
    ],
    "tensorflow/core/kernels/quantized_add_op.cc||tensorflow/core/kernels/quantized_add_op.cc": [
      "File: tensorflow/core/kernels/quantized_add_op.cc -> tensorflow/core/kernels/quantized_add_op.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "26: #include \"tensorflow/core/framework/op_kernel.h\"",
      "27: #include \"tensorflow/core/framework/tensor.h\"",
      "28: #include \"tensorflow/core/kernels/meta_support.h\"",
      "29: #include \"tensorflow/core/kernels/quantization_utils.h\"",
      "30: #include \"tensorflow/core/lib/core/errors.h\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "28: #include \"tensorflow/core/framework/tensor_shape.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "457:   void Compute(OpKernelContext* context) override {",
      "458:     const Tensor& x = context->input(0);",
      "459:     const Tensor& y = context->input(1);",
      "465:     BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));",
      "466:     if (!bcast.IsValid()) {",
      "",
      "[Removed Lines]",
      "460:     const float min_x = context->input(2).flat<float>()(0);",
      "461:     const float max_x = context->input(3).flat<float>()(0);",
      "462:     const float min_y = context->input(4).flat<float>()(0);",
      "463:     const float max_y = context->input(5).flat<float>()(0);",
      "",
      "[Added Lines]",
      "461:     const Tensor& min_x_tensor = context->input(2);",
      "462:     const Tensor& max_x_tensor = context->input(3);",
      "463:     const Tensor& min_y_tensor = context->input(4);",
      "464:     const Tensor& max_y_tensor = context->input(5);",
      "466:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_x_tensor.shape()),",
      "467:                 errors::InvalidArgument(\"`min_x` must be rank 0 but is rank \",",
      "468:                                         min_x_tensor.dims()));",
      "469:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_x_tensor.shape()),",
      "470:                 errors::InvalidArgument(\"`max_x` must be rank 0 but is rank \",",
      "471:                                         max_x_tensor.dims()));",
      "472:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_y_tensor.shape()),",
      "473:                 errors::InvalidArgument(\"`min_y` must be rank 0 but is rank \",",
      "474:                                         min_y_tensor.dims()));",
      "475:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_y_tensor.shape()),",
      "476:                 errors::InvalidArgument(\"`max_y` must be rank 0 but is rank \",",
      "477:                                         max_y_tensor.dims()));",
      "479:     const float min_x = min_x_tensor.scalar<float>()();",
      "480:     const float max_x = max_x_tensor.scalar<float>()();",
      "481:     const float min_y = min_y_tensor.scalar<float>()();",
      "482:     const float max_y = max_y_tensor.scalar<float>()();",
      "",
      "---------------"
    ],
    "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py": [
      "File: tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py -> tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "206:               out_type=dtypes.qint8))",
      "209: if __name__ == \"__main__\":",
      "210:   googletest.main()",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "209: class QuantizedAddOpTest(test_util.TensorFlowTestCase):",
      "211:   @test_util.run_in_graph_and_eager_modes",
      "212:   def test_invalid_inputs(self):",
      "213:     x = constant_op.constant(",
      "214:         np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)",
      "215:     y = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.quint8)",
      "217:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
      "218:                                 \"must be rank 0\"):",
      "219:       self.evaluate(",
      "220:           math_ops.quantized_add(",
      "221:               x=x,",
      "222:               y=y,",
      "223:               min_x=[],",
      "224:               max_x=1.0,",
      "225:               min_y=0.0,",
      "226:               max_y=1.0,",
      "227:               Toutput=dtypes.qint32))",
      "230: class QuantizedReluOpTest(test_util.TensorFlowTestCase):",
      "232:   @test_util.run_in_graph_and_eager_modes",
      "233:   def test_invalid_inputs(self):",
      "234:     inputs = constant_op.constant(",
      "235:         np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)",
      "237:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
      "238:                                 \"must be rank 0\"):",
      "239:       self.evaluate(",
      "240:           nn_ops.quantized_relu(",
      "241:               features=inputs,",
      "242:               min_features=[],",
      "243:               max_features=127.0,",
      "244:               out_type=dtypes.quint8))",
      "247: class QuantizedRelu6OpTest(test_util.TensorFlowTestCase):",
      "249:   @test_util.run_in_graph_and_eager_modes",
      "250:   def test_invalid_inputs(self):",
      "251:     inputs = constant_op.constant(",
      "252:         np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)",
      "254:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
      "255:                                 \"must be rank 0\"):",
      "256:       self.evaluate(",
      "257:           nn_ops.quantized_relu6(",
      "258:               features=inputs,",
      "259:               min_features=[],",
      "260:               max_features=127.0,",
      "261:               out_type=dtypes.quint8))",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "f99e392807ad40d5901b4fb28beeb469f18ee92c",
      "candidate_info": {
        "commit_hash": "f99e392807ad40d5901b4fb28beeb469f18ee92c",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/f99e392807ad40d5901b4fb28beeb469f18ee92c",
        "files": [
          "tensorflow/core/kernels/quantized_activation_ops.cc",
          "tensorflow/core/kernels/quantized_activation_ops_test.cc",
          "tensorflow/core/kernels/quantized_add_op.cc",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ],
        "message": "Add IsScalar (rank == 0) check to min/max input tensors for QuantizedAdd/Relu/Relu6 op.\n\nPiperOrigin-RevId: 461902847",
        "before_after_code_files": [
          "tensorflow/core/kernels/quantized_activation_ops.cc||tensorflow/core/kernels/quantized_activation_ops.cc",
          "tensorflow/core/kernels/quantized_activation_ops_test.cc||tensorflow/core/kernels/quantized_activation_ops_test.cc",
          "tensorflow/core/kernels/quantized_add_op.cc||tensorflow/core/kernels/quantized_add_op.cc",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/quantized_activation_ops.cc||tensorflow/core/kernels/quantized_activation_ops.cc",
            "tensorflow/core/kernels/quantized_activation_ops_test.cc||tensorflow/core/kernels/quantized_activation_ops_test.cc",
            "tensorflow/core/kernels/quantized_add_op.cc||tensorflow/core/kernels/quantized_add_op.cc",
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ],
          "candidate": [
            "tensorflow/core/kernels/quantized_activation_ops.cc||tensorflow/core/kernels/quantized_activation_ops.cc",
            "tensorflow/core/kernels/quantized_activation_ops_test.cc||tensorflow/core/kernels/quantized_activation_ops_test.cc",
            "tensorflow/core/kernels/quantized_add_op.cc||tensorflow/core/kernels/quantized_add_op.cc",
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/quantized_activation_ops.cc||tensorflow/core/kernels/quantized_activation_ops.cc": [
          "File: tensorflow/core/kernels/quantized_activation_ops.cc -> tensorflow/core/kernels/quantized_activation_ops.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "33:   void Compute(OpKernelContext* context) override {",
          "34:     const Tensor& input = context->input(0);",
          "37:     Tensor* output = nullptr;",
          "38:     OP_REQUIRES_OK(context,",
          "39:                    context->allocate_output(0, input.shape(), &output));",
          "",
          "[Removed Lines]",
          "35:     const float min_input = context->input(1).flat<float>()(0);",
          "36:     const float max_input = context->input(2).flat<float>()(0);",
          "",
          "[Added Lines]",
          "35:     const Tensor& min_input_tensor = context->input(1);",
          "36:     const Tensor& max_input_tensor = context->input(2);",
          "38:     OP_REQUIRES(",
          "39:         context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),",
          "40:         errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",",
          "41:                                 min_input_tensor.dims()));",
          "42:     OP_REQUIRES(",
          "43:         context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),",
          "44:         errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",",
          "45:                                 max_input_tensor.dims()));",
          "47:     const float min_input = min_input_tensor.scalar<float>()();",
          "48:     const float max_input = max_input_tensor.scalar<float>()();",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "66:   void Compute(OpKernelContext* context) override {",
          "67:     const Tensor& input = context->input(0);",
          "70:     Tensor* output = nullptr;",
          "71:     OP_REQUIRES_OK(context,",
          "72:                    context->allocate_output(0, input.shape(), &output));",
          "",
          "[Removed Lines]",
          "68:     const float min_input = context->input(1).flat<float>()(0);",
          "69:     const float max_input = context->input(2).flat<float>()(0);",
          "",
          "[Added Lines]",
          "81:     const Tensor& min_input_tensor = context->input(1);",
          "82:     const Tensor& max_input_tensor = context->input(2);",
          "84:     OP_REQUIRES(",
          "85:         context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),",
          "86:         errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",",
          "87:                                 min_input_tensor.dims()));",
          "88:     OP_REQUIRES(",
          "89:         context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),",
          "90:         errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",",
          "91:                                 max_input_tensor.dims()));",
          "93:     const float min_input = min_input_tensor.scalar<float>()();",
          "94:     const float max_input = max_input_tensor.scalar<float>()();",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/quantized_activation_ops_test.cc||tensorflow/core/kernels/quantized_activation_ops_test.cc": [
          "File: tensorflow/core/kernels/quantized_activation_ops_test.cc -> tensorflow/core/kernels/quantized_activation_ops_test.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "56:   AddInputFromArray<quint8>(input_quantized.shape(),",
          "57:                             input_quantized.flat<quint8>());",
          "60:   TF_ASSERT_OK(RunOpKernel());",
          "61:   const Tensor& output_quantized = *GetOutput(0);",
          "62:   const float output_min = GetOutput(1)->flat<float>()(0);",
          "",
          "[Removed Lines]",
          "58:   AddInputFromArray<float>(TensorShape({1}), {input_min});",
          "59:   AddInputFromArray<float>(TensorShape({1}), {input_max});",
          "",
          "[Added Lines]",
          "58:   AddInputFromArray<float>(TensorShape({}), {input_min});",
          "59:   AddInputFromArray<float>(TensorShape({}), {input_max});",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "87:   AddInputFromArray<quint8>(input_quantized.shape(),",
          "88:                             input_quantized.flat<quint8>());",
          "91:   TF_ASSERT_OK(RunOpKernel());",
          "92:   const Tensor& output_quantized = *GetOutput(0);",
          "93:   const float output_min = GetOutput(1)->flat<float>()(0);",
          "",
          "[Removed Lines]",
          "89:   AddInputFromArray<float>(TensorShape({1}), {input_min});",
          "90:   AddInputFromArray<float>(TensorShape({1}), {input_max});",
          "",
          "[Added Lines]",
          "89:   AddInputFromArray<float>(TensorShape({}), {input_min});",
          "90:   AddInputFromArray<float>(TensorShape({}), {input_max});",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/quantized_add_op.cc||tensorflow/core/kernels/quantized_add_op.cc": [
          "File: tensorflow/core/kernels/quantized_add_op.cc -> tensorflow/core/kernels/quantized_add_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "26: #include \"tensorflow/core/framework/op_kernel.h\"",
          "27: #include \"tensorflow/core/framework/tensor.h\"",
          "28: #include \"tensorflow/core/kernels/meta_support.h\"",
          "29: #include \"tensorflow/core/kernels/quantization_utils.h\"",
          "30: #include \"tensorflow/core/lib/core/errors.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "28: #include \"tensorflow/core/framework/tensor_shape.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "457:   void Compute(OpKernelContext* context) override {",
          "458:     const Tensor& x = context->input(0);",
          "459:     const Tensor& y = context->input(1);",
          "465:     BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));",
          "466:     if (!bcast.IsValid()) {",
          "",
          "[Removed Lines]",
          "460:     const float min_x = context->input(2).flat<float>()(0);",
          "461:     const float max_x = context->input(3).flat<float>()(0);",
          "462:     const float min_y = context->input(4).flat<float>()(0);",
          "463:     const float max_y = context->input(5).flat<float>()(0);",
          "",
          "[Added Lines]",
          "461:     const Tensor& min_x_tensor = context->input(2);",
          "462:     const Tensor& max_x_tensor = context->input(3);",
          "463:     const Tensor& min_y_tensor = context->input(4);",
          "464:     const Tensor& max_y_tensor = context->input(5);",
          "466:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_x_tensor.shape()),",
          "467:                 errors::InvalidArgument(\"`min_x` must be rank 0 but is rank \",",
          "468:                                         min_x_tensor.dims()));",
          "469:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_x_tensor.shape()),",
          "470:                 errors::InvalidArgument(\"`max_x` must be rank 0 but is rank \",",
          "471:                                         max_x_tensor.dims()));",
          "472:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_y_tensor.shape()),",
          "473:                 errors::InvalidArgument(\"`min_y` must be rank 0 but is rank \",",
          "474:                                         min_y_tensor.dims()));",
          "475:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_y_tensor.shape()),",
          "476:                 errors::InvalidArgument(\"`max_y` must be rank 0 but is rank \",",
          "477:                                         max_y_tensor.dims()));",
          "479:     const float min_x = min_x_tensor.scalar<float>()();",
          "480:     const float max_x = max_x_tensor.scalar<float>()();",
          "481:     const float min_y = min_y_tensor.scalar<float>()();",
          "482:     const float max_y = max_y_tensor.scalar<float>()();",
          "",
          "---------------"
        ],
        "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py": [
          "File: tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py -> tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "206:               out_type=dtypes.qint8))",
          "209: if __name__ == \"__main__\":",
          "210:   googletest.main()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "209: class QuantizedAddOpTest(test_util.TensorFlowTestCase):",
          "211:   @test_util.run_in_graph_and_eager_modes",
          "212:   def test_invalid_inputs(self):",
          "213:     x = constant_op.constant(",
          "214:         np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)",
          "215:     y = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.quint8)",
          "217:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "218:                                 \"must be rank 0\"):",
          "219:       self.evaluate(",
          "220:           math_ops.quantized_add(",
          "221:               x=x,",
          "222:               y=y,",
          "223:               min_x=[],",
          "224:               max_x=1.0,",
          "225:               min_y=0.0,",
          "226:               max_y=1.0,",
          "227:               Toutput=dtypes.qint32))",
          "230: class QuantizedReluOpTest(test_util.TensorFlowTestCase):",
          "232:   @test_util.run_in_graph_and_eager_modes",
          "233:   def test_invalid_inputs(self):",
          "234:     inputs = constant_op.constant(",
          "235:         np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)",
          "237:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "238:                                 \"must be rank 0\"):",
          "239:       self.evaluate(",
          "240:           nn_ops.quantized_relu(",
          "241:               features=inputs,",
          "242:               min_features=[],",
          "243:               max_features=127.0,",
          "244:               out_type=dtypes.quint8))",
          "247: class QuantizedRelu6OpTest(test_util.TensorFlowTestCase):",
          "249:   @test_util.run_in_graph_and_eager_modes",
          "250:   def test_invalid_inputs(self):",
          "251:     inputs = constant_op.constant(",
          "252:         np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)",
          "254:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "255:                                 \"must be rank 0\"):",
          "256:       self.evaluate(",
          "257:           nn_ops.quantized_relu6(",
          "258:               features=inputs,",
          "259:               min_features=[],",
          "260:               max_features=127.0,",
          "261:               out_type=dtypes.quint8))",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "9814beb2ae38986d69495068dda1bcccdb6e68d2",
      "candidate_info": {
        "commit_hash": "9814beb2ae38986d69495068dda1bcccdb6e68d2",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/9814beb2ae38986d69495068dda1bcccdb6e68d2",
        "files": [
          "tensorflow/core/kernels/quantized_activation_ops.cc",
          "tensorflow/core/kernels/quantized_activation_ops_test.cc",
          "tensorflow/core/kernels/quantized_add_op.cc",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ],
        "message": "Add IsScalar (rank == 0) check to min/max input tensors for QuantizedAdd/Relu/Relu6 op.\n\nPiperOrigin-RevId: 461902847",
        "before_after_code_files": [
          "tensorflow/core/kernels/quantized_activation_ops.cc||tensorflow/core/kernels/quantized_activation_ops.cc",
          "tensorflow/core/kernels/quantized_activation_ops_test.cc||tensorflow/core/kernels/quantized_activation_ops_test.cc",
          "tensorflow/core/kernels/quantized_add_op.cc||tensorflow/core/kernels/quantized_add_op.cc",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/quantized_activation_ops.cc||tensorflow/core/kernels/quantized_activation_ops.cc",
            "tensorflow/core/kernels/quantized_activation_ops_test.cc||tensorflow/core/kernels/quantized_activation_ops_test.cc",
            "tensorflow/core/kernels/quantized_add_op.cc||tensorflow/core/kernels/quantized_add_op.cc",
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ],
          "candidate": [
            "tensorflow/core/kernels/quantized_activation_ops.cc||tensorflow/core/kernels/quantized_activation_ops.cc",
            "tensorflow/core/kernels/quantized_activation_ops_test.cc||tensorflow/core/kernels/quantized_activation_ops_test.cc",
            "tensorflow/core/kernels/quantized_add_op.cc||tensorflow/core/kernels/quantized_add_op.cc",
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/quantized_activation_ops.cc||tensorflow/core/kernels/quantized_activation_ops.cc": [
          "File: tensorflow/core/kernels/quantized_activation_ops.cc -> tensorflow/core/kernels/quantized_activation_ops.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "33:   void Compute(OpKernelContext* context) override {",
          "34:     const Tensor& input = context->input(0);",
          "37:     Tensor* output = nullptr;",
          "38:     OP_REQUIRES_OK(context,",
          "39:                    context->allocate_output(0, input.shape(), &output));",
          "",
          "[Removed Lines]",
          "35:     const float min_input = context->input(1).flat<float>()(0);",
          "36:     const float max_input = context->input(2).flat<float>()(0);",
          "",
          "[Added Lines]",
          "35:     const Tensor& min_input_tensor = context->input(1);",
          "36:     const Tensor& max_input_tensor = context->input(2);",
          "38:     OP_REQUIRES(",
          "39:         context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),",
          "40:         errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",",
          "41:                                 min_input_tensor.dims()));",
          "42:     OP_REQUIRES(",
          "43:         context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),",
          "44:         errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",",
          "45:                                 max_input_tensor.dims()));",
          "47:     const float min_input = min_input_tensor.scalar<float>()();",
          "48:     const float max_input = max_input_tensor.scalar<float>()();",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "66:   void Compute(OpKernelContext* context) override {",
          "67:     const Tensor& input = context->input(0);",
          "70:     Tensor* output = nullptr;",
          "71:     OP_REQUIRES_OK(context,",
          "72:                    context->allocate_output(0, input.shape(), &output));",
          "",
          "[Removed Lines]",
          "68:     const float min_input = context->input(1).flat<float>()(0);",
          "69:     const float max_input = context->input(2).flat<float>()(0);",
          "",
          "[Added Lines]",
          "81:     const Tensor& min_input_tensor = context->input(1);",
          "82:     const Tensor& max_input_tensor = context->input(2);",
          "84:     OP_REQUIRES(",
          "85:         context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),",
          "86:         errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",",
          "87:                                 min_input_tensor.dims()));",
          "88:     OP_REQUIRES(",
          "89:         context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),",
          "90:         errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",",
          "91:                                 max_input_tensor.dims()));",
          "93:     const float min_input = min_input_tensor.scalar<float>()();",
          "94:     const float max_input = max_input_tensor.scalar<float>()();",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/quantized_activation_ops_test.cc||tensorflow/core/kernels/quantized_activation_ops_test.cc": [
          "File: tensorflow/core/kernels/quantized_activation_ops_test.cc -> tensorflow/core/kernels/quantized_activation_ops_test.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "56:   AddInputFromArray<quint8>(input_quantized.shape(),",
          "57:                             input_quantized.flat<quint8>());",
          "60:   TF_ASSERT_OK(RunOpKernel());",
          "61:   const Tensor& output_quantized = *GetOutput(0);",
          "62:   const float output_min = GetOutput(1)->flat<float>()(0);",
          "",
          "[Removed Lines]",
          "58:   AddInputFromArray<float>(TensorShape({1}), {input_min});",
          "59:   AddInputFromArray<float>(TensorShape({1}), {input_max});",
          "",
          "[Added Lines]",
          "58:   AddInputFromArray<float>(TensorShape({}), {input_min});",
          "59:   AddInputFromArray<float>(TensorShape({}), {input_max});",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "87:   AddInputFromArray<quint8>(input_quantized.shape(),",
          "88:                             input_quantized.flat<quint8>());",
          "91:   TF_ASSERT_OK(RunOpKernel());",
          "92:   const Tensor& output_quantized = *GetOutput(0);",
          "93:   const float output_min = GetOutput(1)->flat<float>()(0);",
          "",
          "[Removed Lines]",
          "89:   AddInputFromArray<float>(TensorShape({1}), {input_min});",
          "90:   AddInputFromArray<float>(TensorShape({1}), {input_max});",
          "",
          "[Added Lines]",
          "89:   AddInputFromArray<float>(TensorShape({}), {input_min});",
          "90:   AddInputFromArray<float>(TensorShape({}), {input_max});",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/quantized_add_op.cc||tensorflow/core/kernels/quantized_add_op.cc": [
          "File: tensorflow/core/kernels/quantized_add_op.cc -> tensorflow/core/kernels/quantized_add_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "26: #include \"tensorflow/core/framework/op_kernel.h\"",
          "27: #include \"tensorflow/core/framework/tensor.h\"",
          "28: #include \"tensorflow/core/kernels/meta_support.h\"",
          "29: #include \"tensorflow/core/kernels/quantization_utils.h\"",
          "30: #include \"tensorflow/core/lib/core/errors.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "28: #include \"tensorflow/core/framework/tensor_shape.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "457:   void Compute(OpKernelContext* context) override {",
          "458:     const Tensor& x = context->input(0);",
          "459:     const Tensor& y = context->input(1);",
          "465:     BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));",
          "466:     if (!bcast.IsValid()) {",
          "",
          "[Removed Lines]",
          "460:     const float min_x = context->input(2).flat<float>()(0);",
          "461:     const float max_x = context->input(3).flat<float>()(0);",
          "462:     const float min_y = context->input(4).flat<float>()(0);",
          "463:     const float max_y = context->input(5).flat<float>()(0);",
          "",
          "[Added Lines]",
          "461:     const Tensor& min_x_tensor = context->input(2);",
          "462:     const Tensor& max_x_tensor = context->input(3);",
          "463:     const Tensor& min_y_tensor = context->input(4);",
          "464:     const Tensor& max_y_tensor = context->input(5);",
          "466:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_x_tensor.shape()),",
          "467:                 errors::InvalidArgument(\"`min_x` must be rank 0 but is rank \",",
          "468:                                         min_x_tensor.dims()));",
          "469:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_x_tensor.shape()),",
          "470:                 errors::InvalidArgument(\"`max_x` must be rank 0 but is rank \",",
          "471:                                         max_x_tensor.dims()));",
          "472:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_y_tensor.shape()),",
          "473:                 errors::InvalidArgument(\"`min_y` must be rank 0 but is rank \",",
          "474:                                         min_y_tensor.dims()));",
          "475:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_y_tensor.shape()),",
          "476:                 errors::InvalidArgument(\"`max_y` must be rank 0 but is rank \",",
          "477:                                         max_y_tensor.dims()));",
          "479:     const float min_x = min_x_tensor.scalar<float>()();",
          "480:     const float max_x = max_x_tensor.scalar<float>()();",
          "481:     const float min_y = min_y_tensor.scalar<float>()();",
          "482:     const float max_y = max_y_tensor.scalar<float>()();",
          "",
          "---------------"
        ],
        "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py": [
          "File: tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py -> tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "206:               out_type=dtypes.qint8))",
          "209: if __name__ == \"__main__\":",
          "210:   googletest.main()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "209: class QuantizedAddOpTest(test_util.TensorFlowTestCase):",
          "211:   @test_util.run_in_graph_and_eager_modes",
          "212:   def test_invalid_inputs(self):",
          "213:     x = constant_op.constant(",
          "214:         np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)",
          "215:     y = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.quint8)",
          "217:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "218:                                 \"must be rank 0\"):",
          "219:       self.evaluate(",
          "220:           math_ops.quantized_add(",
          "221:               x=x,",
          "222:               y=y,",
          "223:               min_x=[],",
          "224:               max_x=1.0,",
          "225:               min_y=0.0,",
          "226:               max_y=1.0,",
          "227:               Toutput=dtypes.qint32))",
          "230: class QuantizedReluOpTest(test_util.TensorFlowTestCase):",
          "232:   @test_util.run_in_graph_and_eager_modes",
          "233:   def test_invalid_inputs(self):",
          "234:     inputs = constant_op.constant(",
          "235:         np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)",
          "237:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "238:                                 \"must be rank 0\"):",
          "239:       self.evaluate(",
          "240:           nn_ops.quantized_relu(",
          "241:               features=inputs,",
          "242:               min_features=[],",
          "243:               max_features=127.0,",
          "244:               out_type=dtypes.quint8))",
          "247: class QuantizedRelu6OpTest(test_util.TensorFlowTestCase):",
          "249:   @test_util.run_in_graph_and_eager_modes",
          "250:   def test_invalid_inputs(self):",
          "251:     inputs = constant_op.constant(",
          "252:         np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)",
          "254:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "255:                                 \"must be rank 0\"):",
          "256:       self.evaluate(",
          "257:           nn_ops.quantized_relu6(",
          "258:               features=inputs,",
          "259:               min_features=[],",
          "260:               max_features=127.0,",
          "261:               out_type=dtypes.quint8))",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "89104e563d186a5ef836bbebcc332892ba42c9c7",
      "candidate_info": {
        "commit_hash": "89104e563d186a5ef836bbebcc332892ba42c9c7",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/89104e563d186a5ef836bbebcc332892ba42c9c7",
        "files": [
          "tensorflow/core/kernels/quantized_activation_ops.cc",
          "tensorflow/core/kernels/quantized_activation_ops_test.cc",
          "tensorflow/core/kernels/quantized_add_op.cc",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ],
        "message": "Add IsScalar (rank == 0) check to min/max input tensors for QuantizedAdd/Relu/Relu6 op.\n\nPiperOrigin-RevId: 461902847",
        "before_after_code_files": [
          "tensorflow/core/kernels/quantized_activation_ops.cc||tensorflow/core/kernels/quantized_activation_ops.cc",
          "tensorflow/core/kernels/quantized_activation_ops_test.cc||tensorflow/core/kernels/quantized_activation_ops_test.cc",
          "tensorflow/core/kernels/quantized_add_op.cc||tensorflow/core/kernels/quantized_add_op.cc",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/quantized_activation_ops.cc||tensorflow/core/kernels/quantized_activation_ops.cc",
            "tensorflow/core/kernels/quantized_activation_ops_test.cc||tensorflow/core/kernels/quantized_activation_ops_test.cc",
            "tensorflow/core/kernels/quantized_add_op.cc||tensorflow/core/kernels/quantized_add_op.cc",
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ],
          "candidate": [
            "tensorflow/core/kernels/quantized_activation_ops.cc||tensorflow/core/kernels/quantized_activation_ops.cc",
            "tensorflow/core/kernels/quantized_activation_ops_test.cc||tensorflow/core/kernels/quantized_activation_ops_test.cc",
            "tensorflow/core/kernels/quantized_add_op.cc||tensorflow/core/kernels/quantized_add_op.cc",
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/quantized_activation_ops.cc||tensorflow/core/kernels/quantized_activation_ops.cc": [
          "File: tensorflow/core/kernels/quantized_activation_ops.cc -> tensorflow/core/kernels/quantized_activation_ops.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "33:   void Compute(OpKernelContext* context) override {",
          "34:     const Tensor& input = context->input(0);",
          "37:     Tensor* output = nullptr;",
          "38:     OP_REQUIRES_OK(context,",
          "39:                    context->allocate_output(0, input.shape(), &output));",
          "",
          "[Removed Lines]",
          "35:     const float min_input = context->input(1).flat<float>()(0);",
          "36:     const float max_input = context->input(2).flat<float>()(0);",
          "",
          "[Added Lines]",
          "35:     const Tensor& min_input_tensor = context->input(1);",
          "36:     const Tensor& max_input_tensor = context->input(2);",
          "38:     OP_REQUIRES(",
          "39:         context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),",
          "40:         errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",",
          "41:                                 min_input_tensor.dims()));",
          "42:     OP_REQUIRES(",
          "43:         context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),",
          "44:         errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",",
          "45:                                 max_input_tensor.dims()));",
          "47:     const float min_input = min_input_tensor.scalar<float>()();",
          "48:     const float max_input = max_input_tensor.scalar<float>()();",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "66:   void Compute(OpKernelContext* context) override {",
          "67:     const Tensor& input = context->input(0);",
          "70:     Tensor* output = nullptr;",
          "71:     OP_REQUIRES_OK(context,",
          "72:                    context->allocate_output(0, input.shape(), &output));",
          "",
          "[Removed Lines]",
          "68:     const float min_input = context->input(1).flat<float>()(0);",
          "69:     const float max_input = context->input(2).flat<float>()(0);",
          "",
          "[Added Lines]",
          "81:     const Tensor& min_input_tensor = context->input(1);",
          "82:     const Tensor& max_input_tensor = context->input(2);",
          "84:     OP_REQUIRES(",
          "85:         context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),",
          "86:         errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",",
          "87:                                 min_input_tensor.dims()));",
          "88:     OP_REQUIRES(",
          "89:         context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),",
          "90:         errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",",
          "91:                                 max_input_tensor.dims()));",
          "93:     const float min_input = min_input_tensor.scalar<float>()();",
          "94:     const float max_input = max_input_tensor.scalar<float>()();",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/quantized_activation_ops_test.cc||tensorflow/core/kernels/quantized_activation_ops_test.cc": [
          "File: tensorflow/core/kernels/quantized_activation_ops_test.cc -> tensorflow/core/kernels/quantized_activation_ops_test.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "56:   AddInputFromArray<quint8>(input_quantized.shape(),",
          "57:                             input_quantized.flat<quint8>());",
          "60:   TF_ASSERT_OK(RunOpKernel());",
          "61:   const Tensor& output_quantized = *GetOutput(0);",
          "62:   const float output_min = GetOutput(1)->flat<float>()(0);",
          "",
          "[Removed Lines]",
          "58:   AddInputFromArray<float>(TensorShape({1}), {input_min});",
          "59:   AddInputFromArray<float>(TensorShape({1}), {input_max});",
          "",
          "[Added Lines]",
          "58:   AddInputFromArray<float>(TensorShape({}), {input_min});",
          "59:   AddInputFromArray<float>(TensorShape({}), {input_max});",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "87:   AddInputFromArray<quint8>(input_quantized.shape(),",
          "88:                             input_quantized.flat<quint8>());",
          "91:   TF_ASSERT_OK(RunOpKernel());",
          "92:   const Tensor& output_quantized = *GetOutput(0);",
          "93:   const float output_min = GetOutput(1)->flat<float>()(0);",
          "",
          "[Removed Lines]",
          "89:   AddInputFromArray<float>(TensorShape({1}), {input_min});",
          "90:   AddInputFromArray<float>(TensorShape({1}), {input_max});",
          "",
          "[Added Lines]",
          "89:   AddInputFromArray<float>(TensorShape({}), {input_min});",
          "90:   AddInputFromArray<float>(TensorShape({}), {input_max});",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/quantized_add_op.cc||tensorflow/core/kernels/quantized_add_op.cc": [
          "File: tensorflow/core/kernels/quantized_add_op.cc -> tensorflow/core/kernels/quantized_add_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "26: #include \"tensorflow/core/framework/op_kernel.h\"",
          "27: #include \"tensorflow/core/framework/tensor.h\"",
          "28: #include \"tensorflow/core/kernels/meta_support.h\"",
          "29: #include \"tensorflow/core/kernels/quantization_utils.h\"",
          "30: #include \"tensorflow/core/lib/core/errors.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "28: #include \"tensorflow/core/framework/tensor_shape.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "457:   void Compute(OpKernelContext* context) override {",
          "458:     const Tensor& x = context->input(0);",
          "459:     const Tensor& y = context->input(1);",
          "465:     BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));",
          "466:     if (!bcast.IsValid()) {",
          "",
          "[Removed Lines]",
          "460:     const float min_x = context->input(2).flat<float>()(0);",
          "461:     const float max_x = context->input(3).flat<float>()(0);",
          "462:     const float min_y = context->input(4).flat<float>()(0);",
          "463:     const float max_y = context->input(5).flat<float>()(0);",
          "",
          "[Added Lines]",
          "461:     const Tensor& min_x_tensor = context->input(2);",
          "462:     const Tensor& max_x_tensor = context->input(3);",
          "463:     const Tensor& min_y_tensor = context->input(4);",
          "464:     const Tensor& max_y_tensor = context->input(5);",
          "466:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_x_tensor.shape()),",
          "467:                 errors::InvalidArgument(\"`min_x` must be rank 0 but is rank \",",
          "468:                                         min_x_tensor.dims()));",
          "469:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_x_tensor.shape()),",
          "470:                 errors::InvalidArgument(\"`max_x` must be rank 0 but is rank \",",
          "471:                                         max_x_tensor.dims()));",
          "472:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_y_tensor.shape()),",
          "473:                 errors::InvalidArgument(\"`min_y` must be rank 0 but is rank \",",
          "474:                                         min_y_tensor.dims()));",
          "475:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_y_tensor.shape()),",
          "476:                 errors::InvalidArgument(\"`max_y` must be rank 0 but is rank \",",
          "477:                                         max_y_tensor.dims()));",
          "479:     const float min_x = min_x_tensor.scalar<float>()();",
          "480:     const float max_x = max_x_tensor.scalar<float>()();",
          "481:     const float min_y = min_y_tensor.scalar<float>()();",
          "482:     const float max_y = max_y_tensor.scalar<float>()();",
          "",
          "---------------"
        ],
        "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py": [
          "File: tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py -> tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "206:               out_type=dtypes.qint8))",
          "209: if __name__ == \"__main__\":",
          "210:   googletest.main()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "209: class QuantizedAddOpTest(test_util.TensorFlowTestCase):",
          "211:   @test_util.run_in_graph_and_eager_modes",
          "212:   def test_invalid_inputs(self):",
          "213:     x = constant_op.constant(",
          "214:         np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)",
          "215:     y = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.quint8)",
          "217:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "218:                                 \"must be rank 0\"):",
          "219:       self.evaluate(",
          "220:           math_ops.quantized_add(",
          "221:               x=x,",
          "222:               y=y,",
          "223:               min_x=[],",
          "224:               max_x=1.0,",
          "225:               min_y=0.0,",
          "226:               max_y=1.0,",
          "227:               Toutput=dtypes.qint32))",
          "230: class QuantizedReluOpTest(test_util.TensorFlowTestCase):",
          "232:   @test_util.run_in_graph_and_eager_modes",
          "233:   def test_invalid_inputs(self):",
          "234:     inputs = constant_op.constant(",
          "235:         np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)",
          "237:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "238:                                 \"must be rank 0\"):",
          "239:       self.evaluate(",
          "240:           nn_ops.quantized_relu(",
          "241:               features=inputs,",
          "242:               min_features=[],",
          "243:               max_features=127.0,",
          "244:               out_type=dtypes.quint8))",
          "247: class QuantizedRelu6OpTest(test_util.TensorFlowTestCase):",
          "249:   @test_util.run_in_graph_and_eager_modes",
          "250:   def test_invalid_inputs(self):",
          "251:     inputs = constant_op.constant(",
          "252:         np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)",
          "254:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "255:                                 \"must be rank 0\"):",
          "256:       self.evaluate(",
          "257:           nn_ops.quantized_relu6(",
          "258:               features=inputs,",
          "259:               min_features=[],",
          "260:               max_features=127.0,",
          "261:               out_type=dtypes.quint8))",
          "",
          "---------------"
        ]
      }
    }
  ]
}