{
  "cve_id": "CVE-2021-37642",
  "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions the implementation of `tf.raw_ops.ResourceScatterDiv` is vulnerable to a division by 0 error. The [implementation](https://github.com/tensorflow/tensorflow/blob/8d72537c6abf5a44103b57b9c2e22c14f5f49698/tensorflow/core/kernels/resource_variable_ops.cc#L865) uses a common class for all binary operations but fails to treat the division by 0 case separately. We have patched the issue in GitHub commit 4aacb30888638da75023e6601149415b39763d76. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
  "repo": "tensorflow/tensorflow",
  "patch_hash": "4aacb30888638da75023e6601149415b39763d76",
  "patch_info": {
    "commit_hash": "4aacb30888638da75023e6601149415b39763d76",
    "repo": "tensorflow/tensorflow",
    "commit_url": "https://github.com/tensorflow/tensorflow/commit/4aacb30888638da75023e6601149415b39763d76",
    "files": [
      "tensorflow/core/kernels/resource_variable_ops.cc",
      "tensorflow/python/distribute/sharded_variable_test.py"
    ],
    "message": "Disallow division by zero FPE in `tf.raw_ops.ResourceScatterDiv`\n\nHad to update a test that was broken.\n\nPiperOrigin-RevId: 388516976\nChange-Id: Ic358e6bf0559e011539974d453fc7aa18b427e9c",
    "before_after_code_files": [
      "tensorflow/core/kernels/resource_variable_ops.cc||tensorflow/core/kernels/resource_variable_ops.cc",
      "tensorflow/python/distribute/sharded_variable_test.py||tensorflow/python/distribute/sharded_variable_test.py"
    ]
  },
  "patch_diff": {
    "tensorflow/core/kernels/resource_variable_ops.cc||tensorflow/core/kernels/resource_variable_ops.cc": [
      "File: tensorflow/core/kernels/resource_variable_ops.cc -> tensorflow/core/kernels/resource_variable_ops.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "873: #undef REGISTER_GATHER_ND_ALL_INDICES",
      "874: #undef REGISTER_GATHER_ND_FULL",
      "876: template <typename Device, typename T, typename Index, scatter_op::UpdateOp op>",
      "877: class ResourceScatterUpdateOp : public OpKernel {",
      "878:  public:",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "876: namespace {",
      "878: template <typename Device>",
      "879: bool isCPUDevice() {",
      "880:   return false;",
      "881: }",
      "883: template <>",
      "884: bool isCPUDevice<CPUDevice>() {",
      "885:   return true;",
      "886: }",
      "888: template <typename T>",
      "889: bool ValidateInput(const Tensor& updates) {",
      "890:   const auto updates_flat = updates.flat<T>();",
      "891:   const T zero(0);",
      "892:   for (int i = 0; i < updates.NumElements(); i++) {",
      "893:     if (updates_flat(i) == zero) return false;",
      "894:   }",
      "895:   return true;",
      "896: }",
      "898: template <>",
      "899: bool ValidateInput<Variant>(const Tensor& updates) {",
      "900:   return true;",
      "901: }",
      "903: }  // namespace",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "939:                                 \" indexing: \", params->dim_size(0), \" > \",",
      "940:                                 std::numeric_limits<Index>::max()));",
      "942:     if (N > 0) {",
      "943:       auto indices_flat = indices.flat<Index>();",
      "944:       auto params_flat = params->flat_outer_dims<T>();",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "972:     if (isCPUDevice<Device>() && op == tensorflow::scatter_op::UpdateOp::DIV) {",
      "973:       OP_REQUIRES(c, ValidateInput<T>(updates),",
      "974:                   errors::InvalidArgument(\"updates must not contain 0\"));",
      "975:     }",
      "",
      "---------------"
    ],
    "tensorflow/python/distribute/sharded_variable_test.py||tensorflow/python/distribute/sharded_variable_test.py": [
      "File: tensorflow/python/distribute/sharded_variable_test.py -> tensorflow/python/distribute/sharded_variable_test.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "175:                             'scatter_update')",
      "176:   def test_scatter_ops_even_partition(self, op):",
      "177:     v = variables_lib.Variable(array_ops.zeros((30, 1)))",
      "178:     sparse_delta = ops.IndexedSlices(",
      "180:         indices=constant_op.constant([0, 10, 12, 21, 22]))",
      "182:     v0 = variables_lib.Variable(array_ops.zeros((10, 1)))",
      "",
      "[Removed Lines]",
      "179:         values=constant_op.constant([[0.], [1.], [2.], [3.], [4.]]),",
      "",
      "[Added Lines]",
      "178:     # Make sure values does not contain 0 due to testing `scatter_div`!",
      "180:         values=constant_op.constant([[1.], [2.], [3.], [4.], [5.]]),",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "ca51a9b21b942067c984f39adb18ccc41e9aa8ae",
      "candidate_info": {
        "commit_hash": "ca51a9b21b942067c984f39adb18ccc41e9aa8ae",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/ca51a9b21b942067c984f39adb18ccc41e9aa8ae",
        "files": [
          "tensorflow/core/kernels/resource_variable_ops.cc"
        ],
        "message": "Don't use 0 to initialize a tensorflow::tstring\n\nPiperOrigin-RevId: 436507055",
        "before_after_code_files": [
          "tensorflow/core/kernels/resource_variable_ops.cc||tensorflow/core/kernels/resource_variable_ops.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/resource_variable_ops.cc||tensorflow/core/kernels/resource_variable_ops.cc"
          ],
          "candidate": [
            "tensorflow/core/kernels/resource_variable_ops.cc||tensorflow/core/kernels/resource_variable_ops.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/resource_variable_ops.cc||tensorflow/core/kernels/resource_variable_ops.cc": [
          "File: tensorflow/core/kernels/resource_variable_ops.cc -> tensorflow/core/kernels/resource_variable_ops.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "890: template <typename T>",
          "891: bool ValidateInput(const Tensor& updates) {",
          "892:   const auto updates_flat = updates.flat<T>();",
          "896:   }",
          "897:   return true;",
          "898: }",
          "",
          "[Removed Lines]",
          "893:   const T zero(0);",
          "894:   for (int i = 0; i < updates.NumElements(); i++) {",
          "895:     if (updates_flat(i) == zero) return false;",
          "",
          "[Added Lines]",
          "893:   for (int i = 0; i < updates.NumElements(); ++i) {",
          "894:     if (updates_flat(i) == T{}) return false;",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "37f7b2853a48ee5f49b111667ad80360bec04a3e",
      "candidate_info": {
        "commit_hash": "37f7b2853a48ee5f49b111667ad80360bec04a3e",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/37f7b2853a48ee5f49b111667ad80360bec04a3e",
        "files": [
          "tensorflow/python/distribute/BUILD",
          "tensorflow/python/distribute/sharded_variable.py",
          "tensorflow/python/distribute/sharded_variable_test.py"
        ],
        "message": "Add \"scatter_xxx\" ops implementation to ShardedVariable.\n\nPiperOrigin-RevId: 385809361\nChange-Id: I0964b6a5c57d56c30e37022e504af93f744e5d5a",
        "before_after_code_files": [
          "tensorflow/python/distribute/sharded_variable.py||tensorflow/python/distribute/sharded_variable.py",
          "tensorflow/python/distribute/sharded_variable_test.py||tensorflow/python/distribute/sharded_variable_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/python/distribute/sharded_variable_test.py||tensorflow/python/distribute/sharded_variable_test.py"
          ],
          "candidate": [
            "tensorflow/python/distribute/sharded_variable_test.py||tensorflow/python/distribute/sharded_variable_test.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/python/distribute/sharded_variable.py||tensorflow/python/distribute/sharded_variable.py": [
          "File: tensorflow/python/distribute/sharded_variable.py -> tensorflow/python/distribute/sharded_variable.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "28: from tensorflow.python.framework import tensor_shape",
          "29: from tensorflow.python.framework import type_spec",
          "30: from tensorflow.python.ops import array_ops",
          "31: from tensorflow.python.ops import embedding_ops",
          "32: from tensorflow.python.ops import partitioned_variables",
          "33: from tensorflow.python.ops import resource_variable_ops",
          "34: from tensorflow.python.ops import variables as variables_lib",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "31: from tensorflow.python.ops import data_flow_ops",
          "33: from tensorflow.python.ops import math_ops",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "537:           array_ops.slice(delta, self._var_offsets[i], v.shape.as_list()))",
          "538:     return self",
          "540:   def _gather_saveables_for_checkpoint(self):",
          "541:     \"\"\"Return a `Saveable` for each shard. See `Trackable`.\"\"\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "542:   def _decompose_indices(self, indices):",
          "543:     \"\"\"Decompose a global 1D indices into a list of per-variable indices.\"\"\"",
          "544:     if indices.shape.rank != 1:",
          "545:       raise ValueError(",
          "546:           'ShardedVariable: indices must be 1D Tensor for sparse operations, '",
          "547:           'got: %d' % indices.shape.rank)",
          "549:     base = self._shape[0] // len(self._variables)",
          "550:     extra = self._shape[0] % len(self._variables)",
          "552:     # Assert that sharding conforms to \"div\" sharding",
          "553:     expect_first_dim = [base] * len(self._variables)",
          "554:     for i in range(extra):",
          "555:       expect_first_dim[i] = expect_first_dim[i] + 1",
          "556:     actual_first_dim = [v.shape.as_list()[0] for v in self._variables]",
          "557:     if expect_first_dim != actual_first_dim:",
          "558:       raise NotImplementedError(",
          "559:           'scater_xxx ops are not supported in ShardedVariale that does not '",
          "560:           'conform to \"div\" sharding')",
          "562:     # For index that falls into the partition that has extra 1, assignment is",
          "563:     # `index // (base + 1)` (no less than `(indices - extra) // base`)",
          "564:     # For index that falls into the partition that doesn't has extra 1,",
          "565:     # assignment is `(indices - extra) // base` (no less than",
          "566:     # `indices // (base + 1)`)",
          "567:     #",
          "568:     # Example:",
          "569:     #   base = 10, extra = 2, partitions: [0, 11), [11, 22), [22, 32)",
          "570:     #   index = 10 -> partition_assigment = 0",
          "571:     #   index = 22 -> partition_assiment = 2",
          "572:     partition_assignments = math_ops.maximum(indices // (base + 1),",
          "573:                                              (indices - extra) // base)",
          "574:     local_indices = array_ops.where(partition_assignments < extra,",
          "575:                                     indices % (base + 1),",
          "576:                                     (indices - extra) % base)",
          "577:     # For whatever reason `dynamic_partition` only supports int32",
          "578:     partition_assignments = math_ops.cast(partition_assignments, dtypes.int32)",
          "579:     per_var_indices = data_flow_ops.dynamic_partition(local_indices,",
          "580:                                                       partition_assignments,",
          "581:                                                       len(self._variables))",
          "583:     return per_var_indices, partition_assignments",
          "585:   def _decompose_indexed_slices(self, indexed_slices):",
          "586:     \"\"\"Decompose a global `IndexedSlices` into a list of per-variable ones.\"\"\"",
          "587:     per_var_indices, partition_assignments = self._decompose_indices(",
          "588:         indexed_slices.indices)",
          "589:     per_var_values = data_flow_ops.dynamic_partition(indexed_slices.values,",
          "590:                                                      partition_assignments,",
          "591:                                                      len(self._variables))",
          "593:     return [",
          "594:         ops.IndexedSlices(values=per_var_values[i], indices=per_var_indices[i])",
          "595:         for i in range(len(self._variables))",
          "596:     ]",
          "598:   # ==================== scatter ops implementations ======================== #",
          "600:   def scatter_add(self, sparse_delta, use_locking=False, name=None):",
          "601:     \"\"\"Implements tf.Variable.scatter_add.\"\"\"",
          "602:     per_var_sparse_delta = self._decompose_indexed_slices(sparse_delta)",
          "603:     for i, v in enumerate(self._variables):",
          "604:       new_name = None",
          "605:       if name is not None:",
          "606:         new_name = '{}/part_{}'.format(name, i)",
          "607:       v.scatter_add(per_var_sparse_delta[i], name=new_name)",
          "608:     return self",
          "610:   def scatter_div(self, sparse_delta, use_locking=False, name=None):",
          "611:     \"\"\"Implements tf.Variable.scatter_div.\"\"\"",
          "612:     per_var_sparse_delta = self._decompose_indexed_slices(sparse_delta)",
          "613:     for i, v in enumerate(self._variables):",
          "614:       new_name = None",
          "615:       if name is not None:",
          "616:         new_name = '{}/part_{}'.format(name, i)",
          "617:       v.scatter_div(per_var_sparse_delta[i], name=new_name)",
          "618:     return self",
          "620:   def scatter_max(self, sparse_delta, use_locking=False, name=None):",
          "621:     \"\"\"Implements tf.Variable.scatter_max.\"\"\"",
          "622:     per_var_sparse_delta = self._decompose_indexed_slices(sparse_delta)",
          "623:     for i, v in enumerate(self._variables):",
          "624:       new_name = None",
          "625:       if name is not None:",
          "626:         new_name = '{}/part_{}'.format(name, i)",
          "627:       v.scatter_max(per_var_sparse_delta[i], name=new_name)",
          "628:     return self",
          "630:   def scatter_min(self, sparse_delta, use_locking=False, name=None):",
          "631:     \"\"\"Implements tf.Variable.scatter_min.\"\"\"",
          "632:     per_var_sparse_delta = self._decompose_indexed_slices(sparse_delta)",
          "633:     for i, v in enumerate(self._variables):",
          "634:       new_name = None",
          "635:       if name is not None:",
          "636:         new_name = '{}/part_{}'.format(name, i)",
          "637:       v.scatter_min(per_var_sparse_delta[i], name=new_name)",
          "638:     return self",
          "640:   def scatter_mul(self, sparse_delta, use_locking=False, name=None):",
          "641:     \"\"\"Implements tf.Variable.scatter_mul.\"\"\"",
          "642:     per_var_sparse_delta = self._decompose_indexed_slices(sparse_delta)",
          "643:     for i, v in enumerate(self._variables):",
          "644:       new_name = None",
          "645:       if name is not None:",
          "646:         new_name = '{}/part_{}'.format(name, i)",
          "647:       v.scatter_mul(per_var_sparse_delta[i], name=new_name)",
          "648:     return self",
          "650:   def scatter_sub(self, sparse_delta, use_locking=False, name=None):",
          "651:     \"\"\"Implements tf.Variable.scatter_sub.\"\"\"",
          "652:     per_var_sparse_delta = self._decompose_indexed_slices(sparse_delta)",
          "653:     for i, v in enumerate(self._variables):",
          "654:       new_name = None",
          "655:       if name is not None:",
          "656:         new_name = '{}/part_{}'.format(name, i)",
          "657:       v.scatter_sub(per_var_sparse_delta[i], name=new_name)",
          "658:     return self",
          "660:   def scatter_update(self, sparse_delta, use_locking=False, name=None):",
          "661:     \"\"\"Implements tf.Variable.scatter_update.\"\"\"",
          "662:     per_var_sparse_delta = self._decompose_indexed_slices(sparse_delta)",
          "663:     for i, v in enumerate(self._variables):",
          "664:       new_name = None",
          "665:       if name is not None:",
          "666:         new_name = '{}/part_{}'.format(name, i)",
          "667:       v.scatter_update(per_var_sparse_delta[i], name=new_name)",
          "668:     return self",
          "670:   def batch_scatter_update(self, sparse_delta, use_locking=False, name=None):",
          "671:     \"\"\"Implements tf.Variable.batch_scatter_update.\"\"\"",
          "672:     per_var_sparse_delta = self._decompose_indexed_slices(sparse_delta)",
          "673:     for i, v in enumerate(self._variables):",
          "674:       new_name = None",
          "675:       if name is not None:",
          "676:         new_name = '{}/part_{}'.format(name, i)",
          "677:       v.batch_scatter_update(per_var_sparse_delta[i], name=new_name)",
          "678:     return self",
          "680:   # ================== scatter ops implementations END ====================== #",
          "682:   def sparse_read(self, indices, name=None):",
          "683:     \"\"\"Implements tf.Variable.sparse_read.\"\"\"",
          "684:     per_var_indices, _ = self._decompose_indices(indices)",
          "685:     result = []",
          "686:     for i, v in enumerate(self._variables):",
          "687:       new_name = None",
          "688:       if name is not None:",
          "689:         new_name = '{}/part_{}'.format(name, i)",
          "690:       result.append(v.sparse_read(per_var_indices[i], name=new_name))",
          "691:     return array_ops.concat(result, axis=0)",
          "",
          "---------------"
        ],
        "tensorflow/python/distribute/sharded_variable_test.py||tensorflow/python/distribute/sharded_variable_test.py": [
          "File: tensorflow/python/distribute/sharded_variable_test.py -> tensorflow/python/distribute/sharded_variable_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: import os",
          "23: from tensorflow.python.client import session as session_lib",
          "24: from tensorflow.python.compat import v2_compat",
          "25: from tensorflow.python.distribute import sharded_variable",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "23: from absl.testing import parameterized",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "100:     self.assertAllEqual(got, [1, 1])",
          "105:   def test_sharded_variable_simple(self):",
          "106:     v0 = variables_lib.Variable([0])",
          "",
          "[Removed Lines]",
          "103: class ShardedVariableTest(test.TestCase):",
          "",
          "[Added Lines]",
          "105: class ShardedVariableTest(test.TestCase, parameterized.TestCase):",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "145:     self.assertAllEqual(self.evaluate(s.variables[2]), [[0, 0]])",
          "146:     self.assertIs(ret, s)",
          "148:   def test_control_dep_on_assign(self):",
          "149:     v0 = variables_lib.Variable([[0, 0]])",
          "150:     v1 = variables_lib.Variable([[1, 1], [2, 2]])",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "150:   def test_scatter_add_uneven_partition(self):",
          "151:     v = variables_lib.Variable(array_ops.zeros((32, 1)))",
          "152:     sparse_delta = ops.IndexedSlices(",
          "153:         values=constant_op.constant([[0.], [1.], [2.], [3.], [4.], [5.]]),",
          "154:         indices=constant_op.constant([0, 10, 11, 12, 30, 31]))",
          "156:     v0 = variables_lib.Variable(array_ops.zeros((11, 1)))",
          "157:     v1 = variables_lib.Variable(array_ops.zeros((11, 1)))",
          "158:     v2 = variables_lib.Variable(array_ops.zeros((10, 1)))",
          "159:     sv = sharded_variable.ShardedVariable([v0, v1, v2])",
          "161:     v.scatter_add(sparse_delta)",
          "162:     sv.scatter_add(sparse_delta)",
          "163:     self.assertAllEqual(v, ops.convert_to_tensor(sv))",
          "165:     @def_function.function",
          "166:     def func():",
          "167:       v.scatter_add(sparse_delta)",
          "168:       sv.scatter_add(sparse_delta)",
          "170:     func()",
          "171:     self.assertAllEqual(v, ops.convert_to_tensor(sv))",
          "173:   @parameterized.parameters('scatter_add', 'scatter_div', 'scatter_max',",
          "174:                             'scatter_min', 'scatter_mul', 'scatter_sub',",
          "175:                             'scatter_update')",
          "176:   def test_scatter_ops_even_partition(self, op):",
          "177:     v = variables_lib.Variable(array_ops.zeros((30, 1)))",
          "178:     sparse_delta = ops.IndexedSlices(",
          "179:         values=constant_op.constant([[0.], [1.], [2.], [3.], [4.]]),",
          "180:         indices=constant_op.constant([0, 10, 12, 21, 22]))",
          "182:     v0 = variables_lib.Variable(array_ops.zeros((10, 1)))",
          "183:     v1 = variables_lib.Variable(array_ops.zeros((10, 1)))",
          "184:     v2 = variables_lib.Variable(array_ops.zeros((10, 1)))",
          "185:     sv = sharded_variable.ShardedVariable([v0, v1, v2])",
          "187:     getattr(v, op)(sparse_delta, name='scatter_v')",
          "188:     getattr(sv, op)(sparse_delta, name='scatter_sv')",
          "189:     self.assertAllEqual(v, ops.convert_to_tensor(sv))",
          "191:     @def_function.function",
          "192:     def func():",
          "193:       getattr(v, op)(sparse_delta, name='scatter_v')",
          "194:       getattr(sv, op)(sparse_delta, name='scatter_sv')",
          "196:     func()",
          "197:     self.assertAllEqual(v, ops.convert_to_tensor(sv))",
          "199:   def test_batch_scatter_update(self):",
          "200:     v = variables_lib.Variable(array_ops.zeros((32, 1)))",
          "201:     sparse_delta = ops.IndexedSlices(",
          "202:         values=constant_op.constant([[0.], [1.], [2.], [3.], [4.], [5.]]),",
          "203:         indices=constant_op.constant([10, 11, 12, 13, 14, 15]))",
          "205:     v0 = variables_lib.Variable(array_ops.zeros((11, 1)))",
          "206:     v1 = variables_lib.Variable(array_ops.zeros((11, 1)))",
          "207:     v2 = variables_lib.Variable(array_ops.zeros((10, 1)))",
          "208:     sv = sharded_variable.ShardedVariable([v0, v1, v2])",
          "210:     v.batch_scatter_update(sparse_delta)",
          "211:     sv.batch_scatter_update(sparse_delta)",
          "212:     self.assertAllEqual(v, ops.convert_to_tensor(sv))",
          "214:     @def_function.function",
          "215:     def func():",
          "216:       v.batch_scatter_update(sparse_delta)",
          "217:       sv.batch_scatter_update(sparse_delta)",
          "219:     func()",
          "220:     self.assertAllEqual(v, ops.convert_to_tensor(sv))",
          "222:   def test_sparse_read(self):",
          "223:     v = variables_lib.Variable(array_ops.zeros((30, 1)))",
          "224:     indices = constant_op.constant([0, 10, 12, 21, 22])",
          "226:     v0 = variables_lib.Variable(array_ops.zeros((10, 1)))",
          "227:     v1 = variables_lib.Variable(array_ops.zeros((10, 1)))",
          "228:     v2 = variables_lib.Variable(array_ops.zeros((10, 1)))",
          "229:     sv = sharded_variable.ShardedVariable([v0, v1, v2])",
          "231:     self.assertAllEqual(v.sparse_read(indices), sv.sparse_read(indices))",
          "233:     @def_function.function",
          "234:     def func():",
          "235:       return v.sparse_read(indices), sv.sparse_read(indices)",
          "237:     got, expect = func()",
          "238:     self.assertAllEqual(got, expect)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "b19244176b6f613801b718900e8fe05ef26a51e6",
      "candidate_info": {
        "commit_hash": "b19244176b6f613801b718900e8fe05ef26a51e6",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/b19244176b6f613801b718900e8fe05ef26a51e6",
        "files": [
          "tensorflow/core/kernels/resource_variable_ops.cc"
        ],
        "message": "Disallow division by zero FPE in `tf.raw_ops.ResourceScatterDiv`\n\nHad to update a test that was broken.\n\nPiperOrigin-RevId: 388516976\nChange-Id: Ic358e6bf0559e011539974d453fc7aa18b427e9c",
        "before_after_code_files": [
          "tensorflow/core/kernels/resource_variable_ops.cc||tensorflow/core/kernels/resource_variable_ops.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/resource_variable_ops.cc||tensorflow/core/kernels/resource_variable_ops.cc"
          ],
          "candidate": [
            "tensorflow/core/kernels/resource_variable_ops.cc||tensorflow/core/kernels/resource_variable_ops.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/resource_variable_ops.cc||tensorflow/core/kernels/resource_variable_ops.cc": [
          "File: tensorflow/core/kernels/resource_variable_ops.cc -> tensorflow/core/kernels/resource_variable_ops.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "843: #undef REGISTER_GATHER_ND_ALL_INDICES",
          "844: #undef REGISTER_GATHER_ND_FULL",
          "846: template <typename Device, typename T, typename Index, scatter_op::UpdateOp op>",
          "847: class ResourceScatterUpdateOp : public OpKernel {",
          "848:  public:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "846: namespace {",
          "848: template <typename Device>",
          "849: bool isCPUDevice() {",
          "850:   return false;",
          "851: }",
          "853: template <>",
          "854: bool isCPUDevice<CPUDevice>() {",
          "855:   return true;",
          "856: }",
          "858: template <typename T>",
          "859: bool ValidateInput(const Tensor& updates) {",
          "860:   const auto updates_flat = updates.flat<T>();",
          "861:   const T zero(0);",
          "862:   for (int i = 0; i < updates.NumElements(); i++) {",
          "863:     if (updates_flat(i) == zero) return false;",
          "864:   }",
          "865:   return true;",
          "866: }",
          "868: template <>",
          "869: bool ValidateInput<Variant>(const Tensor& updates) {",
          "870:   return true;",
          "871: }",
          "873: }  // namespace",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "909:                                 \" indexing: \", params->dim_size(0), \" > \",",
          "910:                                 std::numeric_limits<Index>::max()));",
          "912:     if (N > 0) {",
          "913:       auto indices_flat = indices.flat<Index>();",
          "914:       auto params_flat = params->flat_outer_dims<T>();",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "942:     if (isCPUDevice<Device>() && op == tensorflow::scatter_op::UpdateOp::DIV) {",
          "943:       OP_REQUIRES(c, ValidateInput<T>(updates),",
          "944:                   errors::InvalidArgument(\"updates must not contain 0\"));",
          "945:     }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "6852ffb411d8940a3b39a9714def22b2f4230667",
      "candidate_info": {
        "commit_hash": "6852ffb411d8940a3b39a9714def22b2f4230667",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/6852ffb411d8940a3b39a9714def22b2f4230667",
        "files": [
          "tensorflow/core/kernels/resource_variable_ops.cc"
        ],
        "message": "Disallow division by zero FPE in `tf.raw_ops.ResourceScatterDiv`\n\nHad to update a test that was broken.\n\nPiperOrigin-RevId: 388516976\nChange-Id: Ic358e6bf0559e011539974d453fc7aa18b427e9c",
        "before_after_code_files": [
          "tensorflow/core/kernels/resource_variable_ops.cc||tensorflow/core/kernels/resource_variable_ops.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/resource_variable_ops.cc||tensorflow/core/kernels/resource_variable_ops.cc"
          ],
          "candidate": [
            "tensorflow/core/kernels/resource_variable_ops.cc||tensorflow/core/kernels/resource_variable_ops.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/resource_variable_ops.cc||tensorflow/core/kernels/resource_variable_ops.cc": [
          "File: tensorflow/core/kernels/resource_variable_ops.cc -> tensorflow/core/kernels/resource_variable_ops.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "873: #undef REGISTER_GATHER_ND_ALL_INDICES",
          "874: #undef REGISTER_GATHER_ND_FULL",
          "876: template <typename Device, typename T, typename Index, scatter_op::UpdateOp op>",
          "877: class ResourceScatterUpdateOp : public OpKernel {",
          "878:  public:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "876: namespace {",
          "878: template <typename Device>",
          "879: bool isCPUDevice() {",
          "880:   return false;",
          "881: }",
          "883: template <>",
          "884: bool isCPUDevice<CPUDevice>() {",
          "885:   return true;",
          "886: }",
          "888: template <typename T>",
          "889: bool ValidateInput(const Tensor& updates) {",
          "890:   const auto updates_flat = updates.flat<T>();",
          "891:   const T zero(0);",
          "892:   for (int i = 0; i < updates.NumElements(); i++) {",
          "893:     if (updates_flat(i) == zero) return false;",
          "894:   }",
          "895:   return true;",
          "896: }",
          "898: template <>",
          "899: bool ValidateInput<Variant>(const Tensor& updates) {",
          "900:   return true;",
          "901: }",
          "903: }  // namespace",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "939:                                 \" indexing: \", params->dim_size(0), \" > \",",
          "940:                                 std::numeric_limits<Index>::max()));",
          "942:     if (N > 0) {",
          "943:       auto indices_flat = indices.flat<Index>();",
          "944:       auto params_flat = params->flat_outer_dims<T>();",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "972:     if (isCPUDevice<Device>() && op == tensorflow::scatter_op::UpdateOp::DIV) {",
          "973:       OP_REQUIRES(c, ValidateInput<T>(updates),",
          "974:                   errors::InvalidArgument(\"updates must not contain 0\"));",
          "975:     }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "7abc3c9e7d7e8f073f145cd5e1ff2fda1aebe27b",
      "candidate_info": {
        "commit_hash": "7abc3c9e7d7e8f073f145cd5e1ff2fda1aebe27b",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/7abc3c9e7d7e8f073f145cd5e1ff2fda1aebe27b",
        "files": [
          "tensorflow/core/kernels/resource_variable_ops.cc"
        ],
        "message": "Disallow division by zero FPE in `tf.raw_ops.ResourceScatterDiv`\n\nHad to update a test that was broken.\n\nPiperOrigin-RevId: 388516976\nChange-Id: Ic358e6bf0559e011539974d453fc7aa18b427e9c",
        "before_after_code_files": [
          "tensorflow/core/kernels/resource_variable_ops.cc||tensorflow/core/kernels/resource_variable_ops.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/resource_variable_ops.cc||tensorflow/core/kernels/resource_variable_ops.cc"
          ],
          "candidate": [
            "tensorflow/core/kernels/resource_variable_ops.cc||tensorflow/core/kernels/resource_variable_ops.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/resource_variable_ops.cc||tensorflow/core/kernels/resource_variable_ops.cc": [
          "File: tensorflow/core/kernels/resource_variable_ops.cc -> tensorflow/core/kernels/resource_variable_ops.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "844: #undef REGISTER_GATHER_ND_ALL_INDICES",
          "845: #undef REGISTER_GATHER_ND_FULL",
          "847: template <typename Device, typename T, typename Index, scatter_op::UpdateOp op>",
          "848: class ResourceScatterUpdateOp : public OpKernel {",
          "849:  public:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "847: namespace {",
          "849: template <typename Device>",
          "850: bool isCPUDevice() {",
          "851:   return false;",
          "852: }",
          "854: template <>",
          "855: bool isCPUDevice<CPUDevice>() {",
          "856:   return true;",
          "857: }",
          "859: template <typename T>",
          "860: bool ValidateInput(const Tensor& updates) {",
          "861:   const auto updates_flat = updates.flat<T>();",
          "862:   const T zero(0);",
          "863:   for (int i = 0; i < updates.NumElements(); i++) {",
          "864:     if (updates_flat(i) == zero) return false;",
          "865:   }",
          "866:   return true;",
          "867: }",
          "869: template <>",
          "870: bool ValidateInput<Variant>(const Tensor& updates) {",
          "871:   return true;",
          "872: }",
          "874: }  // namespace",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "910:                                 \" indexing: \", params->dim_size(0), \" > \",",
          "911:                                 std::numeric_limits<Index>::max()));",
          "913:     if (N > 0) {",
          "914:       auto indices_flat = indices.flat<Index>();",
          "915:       auto params_flat = params->flat_outer_dims<T>();",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "943:     if (isCPUDevice<Device>() && op == tensorflow::scatter_op::UpdateOp::DIV) {",
          "944:       OP_REQUIRES(c, ValidateInput<T>(updates),",
          "945:                   errors::InvalidArgument(\"updates must not contain 0\"));",
          "946:     }",
          "",
          "---------------"
        ]
      }
    }
  ]
}