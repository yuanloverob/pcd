{
  "cve_id": "CVE-2021-37682",
  "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions all TFLite operations that use quantization can be made to use unitialized values. [For example](https://github.com/tensorflow/tensorflow/blob/460e000de3a83278fb00b61a16d161b1964f15f4/tensorflow/lite/kernels/depthwise_conv.cc#L198-L200). The issue stems from the fact that `quantization.params` is only valid if `quantization.type` is different that `kTfLiteNoQuantization`. However, these checks are missing in large parts of the code. We have patched the issue in GitHub commits 537bc7c723439b9194a358f64d871dd326c18887, 4a91f2069f7145aab6ba2d8cfe41be8a110c18a5 and 8933b8a21280696ab119b63263babdb54c298538. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.",
  "repo": "tensorflow/tensorflow",
  "patch_hash": "8933b8a21280696ab119b63263babdb54c298538",
  "patch_info": {
    "commit_hash": "8933b8a21280696ab119b63263babdb54c298538",
    "repo": "tensorflow/tensorflow",
    "commit_url": "https://github.com/tensorflow/tensorflow/commit/8933b8a21280696ab119b63263babdb54c298538",
    "files": [
      "tensorflow/lite/kernels/depthwise_conv.cc"
    ],
    "message": "Fix a null pointer exception caused by branching on uninitialized data.\n\nThis is due to not checking that the params for the quantization exists. If there is no quantization, we should not access the `.params` field.\n\nPiperOrigin-RevId: 385173491\nChange-Id: I8fc476c4b274fdb21ba741caa0fbc6d1b8840663",
    "before_after_code_files": [
      "tensorflow/lite/kernels/depthwise_conv.cc||tensorflow/lite/kernels/depthwise_conv.cc"
    ]
  },
  "patch_diff": {
    "tensorflow/lite/kernels/depthwise_conv.cc||tensorflow/lite/kernels/depthwise_conv.cc": [
      "File: tensorflow/lite/kernels/depthwise_conv.cc -> tensorflow/lite/kernels/depthwise_conv.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "176:   if (data_type != kTfLiteFloat32) {",
      "177:     TF_LITE_ENSURE_EQ(context, filter->quantization.type,",
      "178:                       kTfLiteAffineQuantization);",
      "179:     const auto* affine_quantization =",
      "180:         reinterpret_cast<TfLiteAffineQuantization*>(",
      "181:             filter->quantization.params);",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "179:     TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "195:   }",
      "197:   if (is_hybrid) {",
      "198:     const auto* affine_quantization =",
      "199:         reinterpret_cast<TfLiteAffineQuantization*>(",
      "200:             filter->quantization.params);",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "199:     TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "495:   op_params.weights_offset = 0;",
      "496:   op_params.float_activation_min = output_activation_min;",
      "497:   op_params.float_activation_max = output_activation_max;",
      "498:   const auto* affine_quantization =",
      "499:       reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params);",
      "500:   if (kernel_type == kReference) {",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "500:   TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "18fc10f9e34b04473feba9f11a390fb2a970c0b6",
      "candidate_info": {
        "commit_hash": "18fc10f9e34b04473feba9f11a390fb2a970c0b6",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/18fc10f9e34b04473feba9f11a390fb2a970c0b6",
        "files": [
          "tensorflow/lite/kernels/depthwise_conv.cc"
        ],
        "message": "Fix a null pointer exception caused by branching on uninitialized data.\n\nThis is due to not checking that the params for the quantization exists. If there is no quantization, we should not access the `.params` field.\n\nPiperOrigin-RevId: 385173491\nChange-Id: I8fc476c4b274fdb21ba741caa0fbc6d1b8840663",
        "before_after_code_files": [
          "tensorflow/lite/kernels/depthwise_conv.cc||tensorflow/lite/kernels/depthwise_conv.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/lite/kernels/depthwise_conv.cc||tensorflow/lite/kernels/depthwise_conv.cc"
          ],
          "candidate": [
            "tensorflow/lite/kernels/depthwise_conv.cc||tensorflow/lite/kernels/depthwise_conv.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/lite/kernels/depthwise_conv.cc||tensorflow/lite/kernels/depthwise_conv.cc": [
          "File: tensorflow/lite/kernels/depthwise_conv.cc -> tensorflow/lite/kernels/depthwise_conv.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "176:   if (data_type != kTfLiteFloat32) {",
          "177:     TF_LITE_ENSURE_EQ(context, filter->quantization.type,",
          "178:                       kTfLiteAffineQuantization);",
          "179:     const auto* affine_quantization =",
          "180:         reinterpret_cast<TfLiteAffineQuantization*>(",
          "181:             filter->quantization.params);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "179:     TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "195:   }",
          "197:   if (is_hybrid) {",
          "198:     const auto* affine_quantization =",
          "199:         reinterpret_cast<TfLiteAffineQuantization*>(",
          "200:             filter->quantization.params);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "199:     TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "495:   op_params.weights_offset = 0;",
          "496:   op_params.float_activation_min = output_activation_min;",
          "497:   op_params.float_activation_max = output_activation_max;",
          "498:   const auto* affine_quantization =",
          "499:       reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params);",
          "500:   if (kernel_type == kReference) {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "500:   TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "cb688771c53708aaea985f2aa8b087b7c011c595",
      "candidate_info": {
        "commit_hash": "cb688771c53708aaea985f2aa8b087b7c011c595",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/cb688771c53708aaea985f2aa8b087b7c011c595",
        "files": [
          "tensorflow/lite/kernels/depthwise_conv.cc"
        ],
        "message": "Fix a null pointer exception caused by branching on uninitialized data.\n\nThis is due to not checking that the params for the quantization exists. If there is no quantization, we should not access the `.params` field.\n\nPiperOrigin-RevId: 385173491\nChange-Id: I8fc476c4b274fdb21ba741caa0fbc6d1b8840663",
        "before_after_code_files": [
          "tensorflow/lite/kernels/depthwise_conv.cc||tensorflow/lite/kernels/depthwise_conv.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/lite/kernels/depthwise_conv.cc||tensorflow/lite/kernels/depthwise_conv.cc"
          ],
          "candidate": [
            "tensorflow/lite/kernels/depthwise_conv.cc||tensorflow/lite/kernels/depthwise_conv.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/lite/kernels/depthwise_conv.cc||tensorflow/lite/kernels/depthwise_conv.cc": [
          "File: tensorflow/lite/kernels/depthwise_conv.cc -> tensorflow/lite/kernels/depthwise_conv.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "176:   if (data_type != kTfLiteFloat32) {",
          "177:     TF_LITE_ENSURE_EQ(context, filter->quantization.type,",
          "178:                       kTfLiteAffineQuantization);",
          "179:     const auto* affine_quantization =",
          "180:         reinterpret_cast<TfLiteAffineQuantization*>(",
          "181:             filter->quantization.params);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "179:     TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "195:   }",
          "197:   if (is_hybrid) {",
          "198:     const auto* affine_quantization =",
          "199:         reinterpret_cast<TfLiteAffineQuantization*>(",
          "200:             filter->quantization.params);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "199:     TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "495:   op_params.weights_offset = 0;",
          "496:   op_params.float_activation_min = output_activation_min;",
          "497:   op_params.float_activation_max = output_activation_max;",
          "498:   const auto* affine_quantization =",
          "499:       reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params);",
          "500:   if (kernel_type == kReference) {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "500:   TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "6aae5ea9041ac49ecbf3e9f4087beee76bcb6219",
      "candidate_info": {
        "commit_hash": "6aae5ea9041ac49ecbf3e9f4087beee76bcb6219",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/6aae5ea9041ac49ecbf3e9f4087beee76bcb6219",
        "files": [
          "tensorflow/lite/kernels/depthwise_conv.cc"
        ],
        "message": "Fix a null pointer exception caused by branching on uninitialized data.\n\nThis is due to not checking that the params for the quantization exists. If there is no quantization, we should not access the `.params` field.\n\nPiperOrigin-RevId: 385173491\nChange-Id: I8fc476c4b274fdb21ba741caa0fbc6d1b8840663",
        "before_after_code_files": [
          "tensorflow/lite/kernels/depthwise_conv.cc||tensorflow/lite/kernels/depthwise_conv.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/lite/kernels/depthwise_conv.cc||tensorflow/lite/kernels/depthwise_conv.cc"
          ],
          "candidate": [
            "tensorflow/lite/kernels/depthwise_conv.cc||tensorflow/lite/kernels/depthwise_conv.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/lite/kernels/depthwise_conv.cc||tensorflow/lite/kernels/depthwise_conv.cc": [
          "File: tensorflow/lite/kernels/depthwise_conv.cc -> tensorflow/lite/kernels/depthwise_conv.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "176:   if (data_type != kTfLiteFloat32) {",
          "177:     TF_LITE_ENSURE_EQ(context, filter->quantization.type,",
          "178:                       kTfLiteAffineQuantization);",
          "179:     const auto* affine_quantization =",
          "180:         reinterpret_cast<TfLiteAffineQuantization*>(",
          "181:             filter->quantization.params);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "179:     TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "195:   }",
          "197:   if (is_hybrid) {",
          "198:     const auto* affine_quantization =",
          "199:         reinterpret_cast<TfLiteAffineQuantization*>(",
          "200:             filter->quantization.params);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "199:     TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "495:   op_params.weights_offset = 0;",
          "496:   op_params.float_activation_min = output_activation_min;",
          "497:   op_params.float_activation_max = output_activation_max;",
          "498:   const auto* affine_quantization =",
          "499:       reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params);",
          "500:   if (kernel_type == kReference) {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "500:   TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "da2e2d8af295990fe036e65902de79729b4678f7",
      "candidate_info": {
        "commit_hash": "da2e2d8af295990fe036e65902de79729b4678f7",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/da2e2d8af295990fe036e65902de79729b4678f7",
        "files": [
          "tensorflow/lite/kernels/depthwise_conv.cc"
        ],
        "message": "Fix a null pointer exception caused by branching on uninitialized data.\n\nThis is due to not checking that the params for the quantization exists. If there is no quantization, we should not access the `.params` field.\n\nPiperOrigin-RevId: 385173491\nChange-Id: I8fc476c4b274fdb21ba741caa0fbc6d1b8840663",
        "before_after_code_files": [
          "tensorflow/lite/kernels/depthwise_conv.cc||tensorflow/lite/kernels/depthwise_conv.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/lite/kernels/depthwise_conv.cc||tensorflow/lite/kernels/depthwise_conv.cc"
          ],
          "candidate": [
            "tensorflow/lite/kernels/depthwise_conv.cc||tensorflow/lite/kernels/depthwise_conv.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/lite/kernels/depthwise_conv.cc||tensorflow/lite/kernels/depthwise_conv.cc": [
          "File: tensorflow/lite/kernels/depthwise_conv.cc -> tensorflow/lite/kernels/depthwise_conv.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "171:   if (data_type != kTfLiteFloat32) {",
          "172:     TF_LITE_ENSURE_EQ(context, filter->quantization.type,",
          "173:                       kTfLiteAffineQuantization);",
          "174:     const auto* affine_quantization =",
          "175:         reinterpret_cast<TfLiteAffineQuantization*>(",
          "176:             filter->quantization.params);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "174:     TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "190:   }",
          "192:   if (is_hybrid) {",
          "193:     const auto* affine_quantization =",
          "194:         reinterpret_cast<TfLiteAffineQuantization*>(",
          "195:             filter->quantization.params);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "194:     TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "476:   op_params.weights_offset = 0;",
          "477:   op_params.float_activation_min = output_activation_min;",
          "478:   op_params.float_activation_max = output_activation_max;",
          "479:   const auto* affine_quantization =",
          "480:       reinterpret_cast<TfLiteAffineQuantization*>(filter->quantization.params);",
          "481:   if (kernel_type == kReference) {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "481:   TF_LITE_ENSURE(context, filter->quantization.type != kTfLiteNoQuantization);",
          "",
          "---------------"
        ]
      }
    }
  ]
}