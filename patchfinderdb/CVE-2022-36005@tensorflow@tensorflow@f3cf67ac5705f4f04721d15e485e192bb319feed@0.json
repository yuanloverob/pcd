{
  "cve_id": "CVE-2022-36005",
  "cve_desc": "TensorFlow is an open source platform for machine learning. When `tf.quantization.fake_quant_with_min_max_vars_gradient` receives input `min` or `max` that is nonscalar, it gives a `CHECK` fail that can trigger a denial of service attack. We have patched the issue in GitHub commit f3cf67ac5705f4f04721d15e485e192bb319feed. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
  "repo": "tensorflow/tensorflow",
  "patch_hash": "f3cf67ac5705f4f04721d15e485e192bb319feed",
  "patch_info": {
    "commit_hash": "f3cf67ac5705f4f04721d15e485e192bb319feed",
    "repo": "tensorflow/tensorflow",
    "commit_url": "https://github.com/tensorflow/tensorflow/commit/f3cf67ac5705f4f04721d15e485e192bb319feed",
    "files": [
      "tensorflow/core/kernels/fake_quant_ops.cc",
      "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
    ],
    "message": "Add IsScalar / IsVector (rank) checks to input min/max tensors for FakeQuantWithMinMaxVarsPerChannelGradientOp and FakeQuantWithMinMaxVarsGradientOp.\n\nPiperOrigin-RevId: 462542629",
    "before_after_code_files": [
      "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc",
      "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
    ]
  },
  "patch_diff": {
    "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc": [
      "File: tensorflow/core/kernels/fake_quant_ops.cc -> tensorflow/core/kernels/fake_quant_ops.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "261:                 InvalidArgument(\"gradient and input must be the same size\"));",
      "262:     const Tensor& min = context->input(2);",
      "263:     const Tensor& max = context->input(3);",
      "265:     Tensor* grad_wrt_input;",
      "266:     OP_REQUIRES_OK(context,",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "264:     OP_REQUIRES(",
      "265:         context, TensorShapeUtils::IsScalar(min.shape()),",
      "266:         InvalidArgument(\"`min` must be rank 0 but is rank \", min.dims()));",
      "267:     OP_REQUIRES(",
      "268:         context, TensorShapeUtils::IsScalar(max.shape()),",
      "269:         InvalidArgument(\"`max` must be rank 0 but is rank \", max.dims()));",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "414:                 InvalidArgument(\"gradient and input must be the same size\"));",
      "415:     const int depth = input.dim_size(input.dims() - 1);  // last dimension size.",
      "416:     const Tensor& min = context->input(2);",
      "417:     OP_REQUIRES(context, min.dim_size(0) == depth,",
      "418:                 InvalidArgument(\"min has incorrect size, expected \", depth,",
      "419:                                 \" was \", min.dim_size(0)));",
      "420:     const Tensor& max = context->input(3);",
      "421:     OP_REQUIRES(context, max.dim_size(0) == depth,",
      "422:                 InvalidArgument(\"max has incorrect size, expected \", depth,",
      "423:                                 \" was \", max.dim_size(0)));",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "423:     OP_REQUIRES(",
      "424:         context, TensorShapeUtils::IsVector(min.shape()),",
      "425:         InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));",
      "430:     OP_REQUIRES(",
      "431:         context, TensorShapeUtils::IsVector(max.shape()),",
      "432:         InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));",
      "",
      "---------------"
    ],
    "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py": [
      "File: tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py -> tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "77:               inputs=inputs, min=[0.0], max=[1.0, 1.1]))",
      "80: class QuantizedBiasedAddTest(test_util.TensorFlowTestCase):",
      "82:   @test_util.run_in_graph_and_eager_modes",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "80: class FakeQuantWithMinMaxVarsGradientOpTest(test_util.TensorFlowTestCase):",
      "82:   @test_util.run_in_graph_and_eager_modes",
      "83:   def test_invalid_inputs(self):",
      "84:     gradients = constant_op.constant(",
      "85:         value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
      "86:     inputs = constant_op.constant(",
      "87:         value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
      "89:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
      "90:                                 \"must be equal rank|must be rank 0\"):",
      "91:       self.evaluate(",
      "92:           array_ops.fake_quant_with_min_max_vars_gradient(",
      "93:               gradients=gradients,",
      "94:               inputs=inputs,",
      "95:               min=0.0,",
      "96:               max=[[1.0], [2.0], [4.0]]))",
      "98:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
      "99:                                 \"must be rank 0\"):",
      "100:       self.evaluate(",
      "101:           array_ops.fake_quant_with_min_max_vars_gradient(",
      "102:               gradients=gradients,",
      "103:               inputs=inputs,",
      "104:               min=[[1.0], [2.0], [4.0]],",
      "105:               max=[[1.0], [2.0], [4.0]]))",
      "108: class FakeQuantWithMinMaxVarsPerChannelGradientOpTest(",
      "109:     test_util.TensorFlowTestCase):",
      "111:   @test_util.run_in_graph_and_eager_modes",
      "112:   def test_invalid_inputs(self):",
      "113:     gradients = constant_op.constant(",
      "114:         value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
      "115:     inputs = constant_op.constant(",
      "116:         value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
      "118:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
      "119:                                 \"Shapes must be equal rank|must be rank 1\"):",
      "120:       self.evaluate(",
      "121:           array_ops.fake_quant_with_min_max_vars_per_channel_gradient(",
      "122:               gradients=gradients, inputs=inputs, min=[[0.0]], max=[1.0]))",
      "124:     with self.assertRaisesRegex(",
      "125:         (ValueError, errors.InvalidArgumentError),",
      "126:         \"Dimension 0 in both shapes must be equal|incorrect size\"):",
      "127:       self.evaluate(",
      "128:           array_ops.fake_quant_with_min_max_vars_per_channel_gradient(",
      "129:               gradients=gradients, inputs=inputs, min=[0.0, 0.1], max=[1.0]))",
      "131:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
      "132:                                 \"Shapes must be equal rank|must be rank 1\"):",
      "133:       self.evaluate(",
      "134:           array_ops.fake_quant_with_min_max_vars_per_channel_gradient(",
      "135:               gradients=gradients, inputs=inputs, min=[1.0], max=[[1.0]]))",
      "137:     with self.assertRaisesRegex(",
      "138:         (ValueError, errors.InvalidArgumentError),",
      "139:         \"Dimension 0 in both shapes must be equal|incorrect size\"):",
      "140:       self.evaluate(",
      "141:           array_ops.fake_quant_with_min_max_vars_per_channel_gradient(",
      "142:               gradients=gradients, inputs=inputs, min=[0.0], max=[1.0, 1.1]))",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "337:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
      "338:                                 \"must be rank 0\"):",
      "339:       self.evaluate(",
      "346: if __name__ == \"__main__\":",
      "",
      "[Removed Lines]",
      "340:           math_ops.quantize_down_and_shrink_range(input=inputs,",
      "341:                                                   input_min=[],",
      "342:                                                   input_max=4.0,",
      "343:                                                   out_type=dtypes.quint8))",
      "",
      "[Added Lines]",
      "405:           math_ops.quantize_down_and_shrink_range(",
      "406:               input=inputs, input_min=[], input_max=4.0,",
      "407:               out_type=dtypes.quint8))",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "49b3824d83af706df0ad07e4e677d88659756d89",
      "candidate_info": {
        "commit_hash": "49b3824d83af706df0ad07e4e677d88659756d89",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/49b3824d83af706df0ad07e4e677d88659756d89",
        "files": [
          "tensorflow/core/kernels/quantized_activation_ops.cc",
          "tensorflow/core/kernels/quantized_activation_ops_test.cc",
          "tensorflow/core/kernels/quantized_add_op.cc",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ],
        "message": "Add IsScalar (rank == 0) check to min/max input tensors for QuantizedAdd/Relu/Relu6 op.\n\nPiperOrigin-RevId: 461902847",
        "before_after_code_files": [
          "tensorflow/core/kernels/quantized_activation_ops.cc||tensorflow/core/kernels/quantized_activation_ops.cc",
          "tensorflow/core/kernels/quantized_activation_ops_test.cc||tensorflow/core/kernels/quantized_activation_ops_test.cc",
          "tensorflow/core/kernels/quantized_add_op.cc||tensorflow/core/kernels/quantized_add_op.cc",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ],
          "candidate": [
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/quantized_activation_ops.cc||tensorflow/core/kernels/quantized_activation_ops.cc": [
          "File: tensorflow/core/kernels/quantized_activation_ops.cc -> tensorflow/core/kernels/quantized_activation_ops.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "33:   void Compute(OpKernelContext* context) override {",
          "34:     const Tensor& input = context->input(0);",
          "37:     Tensor* output = nullptr;",
          "38:     OP_REQUIRES_OK(context,",
          "39:                    context->allocate_output(0, input.shape(), &output));",
          "",
          "[Removed Lines]",
          "35:     const float min_input = context->input(1).flat<float>()(0);",
          "36:     const float max_input = context->input(2).flat<float>()(0);",
          "",
          "[Added Lines]",
          "35:     const Tensor& min_input_tensor = context->input(1);",
          "36:     const Tensor& max_input_tensor = context->input(2);",
          "38:     OP_REQUIRES(",
          "39:         context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),",
          "40:         errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",",
          "41:                                 min_input_tensor.dims()));",
          "42:     OP_REQUIRES(",
          "43:         context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),",
          "44:         errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",",
          "45:                                 max_input_tensor.dims()));",
          "47:     const float min_input = min_input_tensor.scalar<float>()();",
          "48:     const float max_input = max_input_tensor.scalar<float>()();",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "66:   void Compute(OpKernelContext* context) override {",
          "67:     const Tensor& input = context->input(0);",
          "70:     Tensor* output = nullptr;",
          "71:     OP_REQUIRES_OK(context,",
          "72:                    context->allocate_output(0, input.shape(), &output));",
          "",
          "[Removed Lines]",
          "68:     const float min_input = context->input(1).flat<float>()(0);",
          "69:     const float max_input = context->input(2).flat<float>()(0);",
          "",
          "[Added Lines]",
          "81:     const Tensor& min_input_tensor = context->input(1);",
          "82:     const Tensor& max_input_tensor = context->input(2);",
          "84:     OP_REQUIRES(",
          "85:         context, TensorShapeUtils::IsScalar(min_input_tensor.shape()),",
          "86:         errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",",
          "87:                                 min_input_tensor.dims()));",
          "88:     OP_REQUIRES(",
          "89:         context, TensorShapeUtils::IsScalar(max_input_tensor.shape()),",
          "90:         errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",",
          "91:                                 max_input_tensor.dims()));",
          "93:     const float min_input = min_input_tensor.scalar<float>()();",
          "94:     const float max_input = max_input_tensor.scalar<float>()();",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/quantized_activation_ops_test.cc||tensorflow/core/kernels/quantized_activation_ops_test.cc": [
          "File: tensorflow/core/kernels/quantized_activation_ops_test.cc -> tensorflow/core/kernels/quantized_activation_ops_test.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "56:   AddInputFromArray<quint8>(input_quantized.shape(),",
          "57:                             input_quantized.flat<quint8>());",
          "60:   TF_ASSERT_OK(RunOpKernel());",
          "61:   const Tensor& output_quantized = *GetOutput(0);",
          "62:   const float output_min = GetOutput(1)->flat<float>()(0);",
          "",
          "[Removed Lines]",
          "58:   AddInputFromArray<float>(TensorShape({1}), {input_min});",
          "59:   AddInputFromArray<float>(TensorShape({1}), {input_max});",
          "",
          "[Added Lines]",
          "58:   AddInputFromArray<float>(TensorShape({}), {input_min});",
          "59:   AddInputFromArray<float>(TensorShape({}), {input_max});",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "87:   AddInputFromArray<quint8>(input_quantized.shape(),",
          "88:                             input_quantized.flat<quint8>());",
          "91:   TF_ASSERT_OK(RunOpKernel());",
          "92:   const Tensor& output_quantized = *GetOutput(0);",
          "93:   const float output_min = GetOutput(1)->flat<float>()(0);",
          "",
          "[Removed Lines]",
          "89:   AddInputFromArray<float>(TensorShape({1}), {input_min});",
          "90:   AddInputFromArray<float>(TensorShape({1}), {input_max});",
          "",
          "[Added Lines]",
          "89:   AddInputFromArray<float>(TensorShape({}), {input_min});",
          "90:   AddInputFromArray<float>(TensorShape({}), {input_max});",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/quantized_add_op.cc||tensorflow/core/kernels/quantized_add_op.cc": [
          "File: tensorflow/core/kernels/quantized_add_op.cc -> tensorflow/core/kernels/quantized_add_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "26: #include \"tensorflow/core/framework/op_kernel.h\"",
          "27: #include \"tensorflow/core/framework/tensor.h\"",
          "28: #include \"tensorflow/core/kernels/meta_support.h\"",
          "29: #include \"tensorflow/core/kernels/quantization_utils.h\"",
          "30: #include \"tensorflow/core/lib/core/errors.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "28: #include \"tensorflow/core/framework/tensor_shape.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "457:   void Compute(OpKernelContext* context) override {",
          "458:     const Tensor& x = context->input(0);",
          "459:     const Tensor& y = context->input(1);",
          "465:     BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));",
          "466:     if (!bcast.IsValid()) {",
          "",
          "[Removed Lines]",
          "460:     const float min_x = context->input(2).flat<float>()(0);",
          "461:     const float max_x = context->input(3).flat<float>()(0);",
          "462:     const float min_y = context->input(4).flat<float>()(0);",
          "463:     const float max_y = context->input(5).flat<float>()(0);",
          "",
          "[Added Lines]",
          "461:     const Tensor& min_x_tensor = context->input(2);",
          "462:     const Tensor& max_x_tensor = context->input(3);",
          "463:     const Tensor& min_y_tensor = context->input(4);",
          "464:     const Tensor& max_y_tensor = context->input(5);",
          "466:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_x_tensor.shape()),",
          "467:                 errors::InvalidArgument(\"`min_x` must be rank 0 but is rank \",",
          "468:                                         min_x_tensor.dims()));",
          "469:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_x_tensor.shape()),",
          "470:                 errors::InvalidArgument(\"`max_x` must be rank 0 but is rank \",",
          "471:                                         max_x_tensor.dims()));",
          "472:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_y_tensor.shape()),",
          "473:                 errors::InvalidArgument(\"`min_y` must be rank 0 but is rank \",",
          "474:                                         min_y_tensor.dims()));",
          "475:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_y_tensor.shape()),",
          "476:                 errors::InvalidArgument(\"`max_y` must be rank 0 but is rank \",",
          "477:                                         max_y_tensor.dims()));",
          "479:     const float min_x = min_x_tensor.scalar<float>()();",
          "480:     const float max_x = max_x_tensor.scalar<float>()();",
          "481:     const float min_y = min_y_tensor.scalar<float>()();",
          "482:     const float max_y = max_y_tensor.scalar<float>()();",
          "",
          "---------------"
        ],
        "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py": [
          "File: tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py -> tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "206:               out_type=dtypes.qint8))",
          "209: if __name__ == \"__main__\":",
          "210:   googletest.main()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "209: class QuantizedAddOpTest(test_util.TensorFlowTestCase):",
          "211:   @test_util.run_in_graph_and_eager_modes",
          "212:   def test_invalid_inputs(self):",
          "213:     x = constant_op.constant(",
          "214:         np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)",
          "215:     y = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.quint8)",
          "217:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "218:                                 \"must be rank 0\"):",
          "219:       self.evaluate(",
          "220:           math_ops.quantized_add(",
          "221:               x=x,",
          "222:               y=y,",
          "223:               min_x=[],",
          "224:               max_x=1.0,",
          "225:               min_y=0.0,",
          "226:               max_y=1.0,",
          "227:               Toutput=dtypes.qint32))",
          "230: class QuantizedReluOpTest(test_util.TensorFlowTestCase):",
          "232:   @test_util.run_in_graph_and_eager_modes",
          "233:   def test_invalid_inputs(self):",
          "234:     inputs = constant_op.constant(",
          "235:         np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)",
          "237:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "238:                                 \"must be rank 0\"):",
          "239:       self.evaluate(",
          "240:           nn_ops.quantized_relu(",
          "241:               features=inputs,",
          "242:               min_features=[],",
          "243:               max_features=127.0,",
          "244:               out_type=dtypes.quint8))",
          "247: class QuantizedRelu6OpTest(test_util.TensorFlowTestCase):",
          "249:   @test_util.run_in_graph_and_eager_modes",
          "250:   def test_invalid_inputs(self):",
          "251:     inputs = constant_op.constant(",
          "252:         np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)",
          "254:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "255:                                 \"must be rank 0\"):",
          "256:       self.evaluate(",
          "257:           nn_ops.quantized_relu6(",
          "258:               features=inputs,",
          "259:               min_features=[],",
          "260:               max_features=127.0,",
          "261:               out_type=dtypes.quint8))",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "400e6c57efafa3a8beebb4559d94fd6089c02815",
      "candidate_info": {
        "commit_hash": "400e6c57efafa3a8beebb4559d94fd6089c02815",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/400e6c57efafa3a8beebb4559d94fd6089c02815",
        "files": [
          "tensorflow/core/kernels/fake_quant_ops.cc",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ],
        "message": "Add IsScalar / IsVector (rank) checks to input min/max tensors for FakeQuantWithMinMaxVarsPerChannelGradientOp and FakeQuantWithMinMaxVarsGradientOp.\n\nPiperOrigin-RevId: 462542629",
        "before_after_code_files": [
          "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc",
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ],
          "candidate": [
            "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc",
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc": [
          "File: tensorflow/core/kernels/fake_quant_ops.cc -> tensorflow/core/kernels/fake_quant_ops.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "253:                 InvalidArgument(\"gradient and input must be the same size\"));",
          "254:     const Tensor& min = context->input(2);",
          "255:     const Tensor& max = context->input(3);",
          "257:     Tensor* grad_wrt_input;",
          "258:     OP_REQUIRES_OK(context,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "256:     OP_REQUIRES(",
          "257:         context, TensorShapeUtils::IsScalar(min.shape()),",
          "258:         InvalidArgument(\"`min` must be rank 0 but is rank \", min.dims()));",
          "259:     OP_REQUIRES(",
          "260:         context, TensorShapeUtils::IsScalar(max.shape()),",
          "261:         InvalidArgument(\"`max` must be rank 0 but is rank \", max.dims()));",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "399:                 InvalidArgument(\"gradient and input must be the same size\"));",
          "400:     const int depth = input.dim_size(input.dims() - 1);  // last dimension size.",
          "401:     const Tensor& min = context->input(2);",
          "402:     OP_REQUIRES(context, min.dim_size(0) == depth,",
          "403:                 InvalidArgument(\"min has incorrect size, expected \", depth,",
          "404:                                 \" was \", min.dim_size(0)));",
          "405:     const Tensor& max = context->input(3);",
          "406:     OP_REQUIRES(context, max.dim_size(0) == depth,",
          "407:                 InvalidArgument(\"max has incorrect size, expected \", depth,",
          "408:                                 \" was \", max.dim_size(0)));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "408:     OP_REQUIRES(",
          "409:         context, TensorShapeUtils::IsVector(min.shape()),",
          "410:         InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));",
          "415:     OP_REQUIRES(",
          "416:         context, TensorShapeUtils::IsVector(max.shape()),",
          "417:         InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));",
          "",
          "---------------"
        ],
        "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py": [
          "File: tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py -> tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "79:               inputs=inputs, min=[0.0], max=[1.0, 1.1]))",
          "82: class QuantizedBiasedAddTest(test_util.TensorFlowTestCase):",
          "84:   @test_util.run_in_graph_and_eager_modes",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "82: class FakeQuantWithMinMaxVarsGradientOpTest(test_util.TensorFlowTestCase):",
          "84:   @test_util.run_in_graph_and_eager_modes",
          "85:   def test_invalid_inputs(self):",
          "86:     gradients = constant_op.constant(",
          "87:         value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
          "88:     inputs = constant_op.constant(",
          "89:         value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
          "91:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "92:                                 \"must be equal rank|must be rank 0\"):",
          "93:       self.evaluate(",
          "94:           array_ops.fake_quant_with_min_max_vars_gradient(",
          "95:               gradients=gradients,",
          "96:               inputs=inputs,",
          "97:               min=0.0,",
          "98:               max=[[1.0], [2.0], [4.0]]))",
          "100:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "101:                                 \"must be rank 0\"):",
          "102:       self.evaluate(",
          "103:           array_ops.fake_quant_with_min_max_vars_gradient(",
          "104:               gradients=gradients,",
          "105:               inputs=inputs,",
          "106:               min=[[1.0], [2.0], [4.0]],",
          "107:               max=[[1.0], [2.0], [4.0]]))",
          "110: class FakeQuantWithMinMaxVarsPerChannelGradientOpTest(",
          "111:     test_util.TensorFlowTestCase):",
          "113:   @test_util.run_in_graph_and_eager_modes",
          "114:   def test_invalid_inputs(self):",
          "115:     gradients = constant_op.constant(",
          "116:         value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
          "117:     inputs = constant_op.constant(",
          "118:         value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
          "120:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "121:                                 \"Shapes must be equal rank|must be rank 1\"):",
          "122:       self.evaluate(",
          "123:           array_ops.fake_quant_with_min_max_vars_per_channel_gradient(",
          "124:               gradients=gradients, inputs=inputs, min=[[0.0]], max=[1.0]))",
          "126:     with self.assertRaisesRegex(",
          "127:         (ValueError, errors.InvalidArgumentError),",
          "128:         \"Dimension 0 in both shapes must be equal|incorrect size\"):",
          "129:       self.evaluate(",
          "130:           array_ops.fake_quant_with_min_max_vars_per_channel_gradient(",
          "131:               gradients=gradients, inputs=inputs, min=[0.0, 0.1], max=[1.0]))",
          "133:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "134:                                 \"Shapes must be equal rank|must be rank 1\"):",
          "135:       self.evaluate(",
          "136:           array_ops.fake_quant_with_min_max_vars_per_channel_gradient(",
          "137:               gradients=gradients, inputs=inputs, min=[1.0], max=[[1.0]]))",
          "139:     with self.assertRaisesRegex(",
          "140:         (ValueError, errors.InvalidArgumentError),",
          "141:         \"Dimension 0 in both shapes must be equal|incorrect size\"):",
          "142:       self.evaluate(",
          "143:           array_ops.fake_quant_with_min_max_vars_per_channel_gradient(",
          "144:               gradients=gradients, inputs=inputs, min=[0.0], max=[1.0, 1.1]))",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "0f4ac97e2bfabd4068c9f61dd5a7fc3c70746da5",
      "candidate_info": {
        "commit_hash": "0f4ac97e2bfabd4068c9f61dd5a7fc3c70746da5",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/0f4ac97e2bfabd4068c9f61dd5a7fc3c70746da5",
        "files": [
          "tensorflow/core/kernels/fake_quant_ops.cc",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ],
        "message": "Add IsScalar / IsVector (rank) checks to input min/max tensors for FakeQuantWithMinMaxVarsPerChannelGradientOp and FakeQuantWithMinMaxVarsGradientOp.\n\nPiperOrigin-RevId: 462542629",
        "before_after_code_files": [
          "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc",
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ],
          "candidate": [
            "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc",
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc": [
          "File: tensorflow/core/kernels/fake_quant_ops.cc -> tensorflow/core/kernels/fake_quant_ops.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "261:                 InvalidArgument(\"gradient and input must be the same size\"));",
          "262:     const Tensor& min = context->input(2);",
          "263:     const Tensor& max = context->input(3);",
          "265:     Tensor* grad_wrt_input;",
          "266:     OP_REQUIRES_OK(context,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "264:     OP_REQUIRES(",
          "265:         context, TensorShapeUtils::IsScalar(min.shape()),",
          "266:         InvalidArgument(\"`min` must be rank 0 but is rank \", min.dims()));",
          "267:     OP_REQUIRES(",
          "268:         context, TensorShapeUtils::IsScalar(max.shape()),",
          "269:         InvalidArgument(\"`max` must be rank 0 but is rank \", max.dims()));",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "414:                 InvalidArgument(\"gradient and input must be the same size\"));",
          "415:     const int depth = input.dim_size(input.dims() - 1);  // last dimension size.",
          "416:     const Tensor& min = context->input(2);",
          "417:     OP_REQUIRES(context, min.dim_size(0) == depth,",
          "418:                 InvalidArgument(\"min has incorrect size, expected \", depth,",
          "419:                                 \" was \", min.dim_size(0)));",
          "420:     const Tensor& max = context->input(3);",
          "421:     OP_REQUIRES(context, max.dim_size(0) == depth,",
          "422:                 InvalidArgument(\"max has incorrect size, expected \", depth,",
          "423:                                 \" was \", max.dim_size(0)));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "423:     OP_REQUIRES(",
          "424:         context, TensorShapeUtils::IsVector(min.shape()),",
          "425:         InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));",
          "430:     OP_REQUIRES(",
          "431:         context, TensorShapeUtils::IsVector(max.shape()),",
          "432:         InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));",
          "",
          "---------------"
        ],
        "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py": [
          "File: tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py -> tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "79:               inputs=inputs, min=[0.0], max=[1.0, 1.1]))",
          "82: class QuantizedBiasedAddTest(test_util.TensorFlowTestCase):",
          "84:   @test_util.run_in_graph_and_eager_modes",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "82: class FakeQuantWithMinMaxVarsGradientOpTest(test_util.TensorFlowTestCase):",
          "84:   @test_util.run_in_graph_and_eager_modes",
          "85:   def test_invalid_inputs(self):",
          "86:     gradients = constant_op.constant(",
          "87:         value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
          "88:     inputs = constant_op.constant(",
          "89:         value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
          "91:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "92:                                 \"must be equal rank|must be rank 0\"):",
          "93:       self.evaluate(",
          "94:           array_ops.fake_quant_with_min_max_vars_gradient(",
          "95:               gradients=gradients,",
          "96:               inputs=inputs,",
          "97:               min=0.0,",
          "98:               max=[[1.0], [2.0], [4.0]]))",
          "100:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "101:                                 \"must be rank 0\"):",
          "102:       self.evaluate(",
          "103:           array_ops.fake_quant_with_min_max_vars_gradient(",
          "104:               gradients=gradients,",
          "105:               inputs=inputs,",
          "106:               min=[[1.0], [2.0], [4.0]],",
          "107:               max=[[1.0], [2.0], [4.0]]))",
          "110: class FakeQuantWithMinMaxVarsPerChannelGradientOpTest(",
          "111:     test_util.TensorFlowTestCase):",
          "113:   @test_util.run_in_graph_and_eager_modes",
          "114:   def test_invalid_inputs(self):",
          "115:     gradients = constant_op.constant(",
          "116:         value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
          "117:     inputs = constant_op.constant(",
          "118:         value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
          "120:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "121:                                 \"Shapes must be equal rank|must be rank 1\"):",
          "122:       self.evaluate(",
          "123:           array_ops.fake_quant_with_min_max_vars_per_channel_gradient(",
          "124:               gradients=gradients, inputs=inputs, min=[[0.0]], max=[1.0]))",
          "126:     with self.assertRaisesRegex(",
          "127:         (ValueError, errors.InvalidArgumentError),",
          "128:         \"Dimension 0 in both shapes must be equal|incorrect size\"):",
          "129:       self.evaluate(",
          "130:           array_ops.fake_quant_with_min_max_vars_per_channel_gradient(",
          "131:               gradients=gradients, inputs=inputs, min=[0.0, 0.1], max=[1.0]))",
          "133:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "134:                                 \"Shapes must be equal rank|must be rank 1\"):",
          "135:       self.evaluate(",
          "136:           array_ops.fake_quant_with_min_max_vars_per_channel_gradient(",
          "137:               gradients=gradients, inputs=inputs, min=[1.0], max=[[1.0]]))",
          "139:     with self.assertRaisesRegex(",
          "140:         (ValueError, errors.InvalidArgumentError),",
          "141:         \"Dimension 0 in both shapes must be equal|incorrect size\"):",
          "142:       self.evaluate(",
          "143:           array_ops.fake_quant_with_min_max_vars_per_channel_gradient(",
          "144:               gradients=gradients, inputs=inputs, min=[0.0], max=[1.0, 1.1]))",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "354:   @test_util.run_in_graph_and_eager_modes",
          "355:   def test_invalid_inputs(self):",
          "364:     # Test that running the op raises error. It raises different errors",
          "365:     # depending on whether the shape inference is run first or the op's",
          "",
          "[Removed Lines]",
          "356:     input_value = constant_op.constant([-0.8, -0.5, 0, 0.3, 0.8, -2.0],",
          "357:                                        shape=(6,),",
          "358:                                        dtype=dtypes.float32),",
          "359:     input_min = constant_op.constant(-127, shape=(), dtype=dtypes.float32)",
          "360:     input_max = constant_op.constant(127, shape=(), dtype=dtypes.float32)",
          "361:     # Tensor with invalid shape and invalid number of elements.",
          "362:     num_bits = constant_op.constant([], shape=(0,), dtype=dtypes.int32)",
          "",
          "[Added Lines]",
          "421:     inputs = constant_op.constant(",
          "422:         np.int32(0), shape=[3, 3, 3, 3], dtype=dtypes.qint32)",
          "424:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "425:                                 \"must be rank 0\"):",
          "426:       self.evaluate(",
          "427:           math_ops.quantize_down_and_shrink_range(",
          "428:               input=inputs, input_min=[], input_max=4.0,",
          "429:               out_type=dtypes.quint8))",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "392e9d69dd4fdf290240ad10e18ba341901687dc",
      "candidate_info": {
        "commit_hash": "392e9d69dd4fdf290240ad10e18ba341901687dc",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/392e9d69dd4fdf290240ad10e18ba341901687dc",
        "files": [
          "tensorflow/core/kernels/fake_quant_ops.cc",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ],
        "message": "Add IsScalar / IsVector (rank) checks to input min/max tensors for FakeQuantWithMinMaxVarsPerChannelGradientOp and FakeQuantWithMinMaxVarsGradientOp.\n\nPiperOrigin-RevId: 462542629",
        "before_after_code_files": [
          "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc",
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ],
          "candidate": [
            "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc",
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc": [
          "File: tensorflow/core/kernels/fake_quant_ops.cc -> tensorflow/core/kernels/fake_quant_ops.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "261:                 InvalidArgument(\"gradient and input must be the same size\"));",
          "262:     const Tensor& min = context->input(2);",
          "263:     const Tensor& max = context->input(3);",
          "265:     Tensor* grad_wrt_input;",
          "266:     OP_REQUIRES_OK(context,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "264:     OP_REQUIRES(",
          "265:         context, TensorShapeUtils::IsScalar(min.shape()),",
          "266:         InvalidArgument(\"`min` must be rank 0 but is rank \", min.dims()));",
          "267:     OP_REQUIRES(",
          "268:         context, TensorShapeUtils::IsScalar(max.shape()),",
          "269:         InvalidArgument(\"`max` must be rank 0 but is rank \", max.dims()));",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "414:                 InvalidArgument(\"gradient and input must be the same size\"));",
          "415:     const int depth = input.dim_size(input.dims() - 1);  // last dimension size.",
          "416:     const Tensor& min = context->input(2);",
          "417:     OP_REQUIRES(context, min.dim_size(0) == depth,",
          "418:                 InvalidArgument(\"min has incorrect size, expected \", depth,",
          "419:                                 \" was \", min.dim_size(0)));",
          "420:     const Tensor& max = context->input(3);",
          "421:     OP_REQUIRES(context, max.dim_size(0) == depth,",
          "422:                 InvalidArgument(\"max has incorrect size, expected \", depth,",
          "423:                                 \" was \", max.dim_size(0)));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "423:     OP_REQUIRES(",
          "424:         context, TensorShapeUtils::IsVector(min.shape()),",
          "425:         InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));",
          "430:     OP_REQUIRES(",
          "431:         context, TensorShapeUtils::IsVector(max.shape()),",
          "432:         InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));",
          "",
          "---------------"
        ],
        "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py": [
          "File: tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py -> tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "79:               inputs=inputs, min=[0.0], max=[1.0, 1.1]))",
          "82: class QuantizedBiasedAddTest(test_util.TensorFlowTestCase):",
          "84:   @test_util.run_in_graph_and_eager_modes",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "82: class FakeQuantWithMinMaxVarsGradientOpTest(test_util.TensorFlowTestCase):",
          "84:   @test_util.run_in_graph_and_eager_modes",
          "85:   def test_invalid_inputs(self):",
          "86:     gradients = constant_op.constant(",
          "87:         value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
          "88:     inputs = constant_op.constant(",
          "89:         value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
          "91:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "92:                                 \"must be equal rank|must be rank 0\"):",
          "93:       self.evaluate(",
          "94:           array_ops.fake_quant_with_min_max_vars_gradient(",
          "95:               gradients=gradients,",
          "96:               inputs=inputs,",
          "97:               min=0.0,",
          "98:               max=[[1.0], [2.0], [4.0]]))",
          "100:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "101:                                 \"must be rank 0\"):",
          "102:       self.evaluate(",
          "103:           array_ops.fake_quant_with_min_max_vars_gradient(",
          "104:               gradients=gradients,",
          "105:               inputs=inputs,",
          "106:               min=[[1.0], [2.0], [4.0]],",
          "107:               max=[[1.0], [2.0], [4.0]]))",
          "110: class FakeQuantWithMinMaxVarsPerChannelGradientOpTest(",
          "111:     test_util.TensorFlowTestCase):",
          "113:   @test_util.run_in_graph_and_eager_modes",
          "114:   def test_invalid_inputs(self):",
          "115:     gradients = constant_op.constant(",
          "116:         value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
          "117:     inputs = constant_op.constant(",
          "118:         value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
          "120:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "121:                                 \"Shapes must be equal rank|must be rank 1\"):",
          "122:       self.evaluate(",
          "123:           array_ops.fake_quant_with_min_max_vars_per_channel_gradient(",
          "124:               gradients=gradients, inputs=inputs, min=[[0.0]], max=[1.0]))",
          "126:     with self.assertRaisesRegex(",
          "127:         (ValueError, errors.InvalidArgumentError),",
          "128:         \"Dimension 0 in both shapes must be equal|incorrect size\"):",
          "129:       self.evaluate(",
          "130:           array_ops.fake_quant_with_min_max_vars_per_channel_gradient(",
          "131:               gradients=gradients, inputs=inputs, min=[0.0, 0.1], max=[1.0]))",
          "133:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "134:                                 \"Shapes must be equal rank|must be rank 1\"):",
          "135:       self.evaluate(",
          "136:           array_ops.fake_quant_with_min_max_vars_per_channel_gradient(",
          "137:               gradients=gradients, inputs=inputs, min=[1.0], max=[[1.0]]))",
          "139:     with self.assertRaisesRegex(",
          "140:         (ValueError, errors.InvalidArgumentError),",
          "141:         \"Dimension 0 in both shapes must be equal|incorrect size\"):",
          "142:       self.evaluate(",
          "143:           array_ops.fake_quant_with_min_max_vars_per_channel_gradient(",
          "144:               gradients=gradients, inputs=inputs, min=[0.0], max=[1.0, 1.1]))",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "381:       self.fail(",
          "382:           \"Did not raise an exception where it is expected to raise either \"",
          "383:           \"a ValueError or errors.InvalidArgumentError.\")",
          "386: if __name__ == \"__main__\":",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "449: class QuantizeDownAndShrinkRangeOpTest(test_util.TensorFlowTestCase):",
          "451:   @test_util.run_in_graph_and_eager_modes",
          "452:   def test_invalid_inputs(self):",
          "453:     inputs = constant_op.constant(",
          "454:         np.int32(0), shape=[3, 3, 3, 3], dtype=dtypes.qint32)",
          "456:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "457:                                 \"must be rank 0\"):",
          "458:       self.evaluate(",
          "459:           math_ops.quantize_down_and_shrink_range(",
          "460:               input=inputs, input_min=[], input_max=4.0,",
          "461:               out_type=dtypes.quint8))",
          "",
          "---------------"
        ]
      }
    }
  ]
}