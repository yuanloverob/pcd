{
  "cve_id": "CVE-2022-29195",
  "cve_desc": "TensorFlow is an open source platform for machine learning. Prior to versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4, the implementation of `tf.raw_ops.StagePeek` does not fully validate the input arguments. This results in a `CHECK`-failure which can be used to trigger a denial of service attack. The code assumes `index` is a scalar but there is no validation for this before accessing its value. Versions 2.9.0, 2.8.1, 2.7.2, and 2.6.4 contain a patch for this issue.",
  "repo": "tensorflow/tensorflow",
  "patch_hash": "cebe3c45d76357d201c65bdbbf0dbe6e8a63bbdb",
  "patch_info": {
    "commit_hash": "cebe3c45d76357d201c65bdbbf0dbe6e8a63bbdb",
    "repo": "tensorflow/tensorflow",
    "commit_url": "https://github.com/tensorflow/tensorflow/commit/cebe3c45d76357d201c65bdbbf0dbe6e8a63bbdb",
    "files": [
      "tensorflow/core/kernels/stage_op.cc",
      "tensorflow/python/kernel_tests/data_structures/stage_op_test.py",
      "tensorflow/python/ops/data_flow_ops.py"
    ],
    "message": "Fix tf.raw_ops.StagePeek vulnerability with invalid `index`.\n\nCheck that input is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445524908",
    "before_after_code_files": [
      "tensorflow/core/kernels/stage_op.cc||tensorflow/core/kernels/stage_op.cc",
      "tensorflow/python/kernel_tests/data_structures/stage_op_test.py||tensorflow/python/kernel_tests/data_structures/stage_op_test.py",
      "tensorflow/python/ops/data_flow_ops.py||tensorflow/python/ops/data_flow_ops.py"
    ]
  },
  "patch_diff": {
    "tensorflow/core/kernels/stage_op.cc||tensorflow/core/kernels/stage_op.cc": [
      "File: tensorflow/core/kernels/stage_op.cc -> tensorflow/core/kernels/stage_op.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "258:     core::ScopedUnref scope(buf);",
      "259:     Buffer::Tuple tuple;",
      "261:     std::size_t index = ctx->input(0).scalar<int>()();",
      "263:     OP_REQUIRES_OK(ctx, buf->Peek(index, &tuple));",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "261:     OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(ctx->input(0).shape()),",
      "262:                 errors::InvalidArgument(\"index must be scalar\"));",
      "",
      "---------------"
    ],
    "tensorflow/python/kernel_tests/data_structures/stage_op_test.py||tensorflow/python/kernel_tests/data_structures/stage_op_test.py": [
      "File: tensorflow/python/kernel_tests/data_structures/stage_op_test.py -> tensorflow/python/kernel_tests/data_structures/stage_op_test.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "13: # limitations under the License.",
      "14: # ==============================================================================",
      "15: from tensorflow.python.framework import dtypes",
      "16: from tensorflow.python.framework import ops",
      "17: from tensorflow.python.framework import test_util",
      "18: from tensorflow.python.ops import array_ops",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "16: from tensorflow.python.framework import errors",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "134:       for i in range(10):",
      "135:         self.assertTrue(sess.run(peek, feed_dict={p: i}) == [i])",
      "137:   @test_util.run_deprecated_v1",
      "138:   def testSizeAndClear(self):",
      "139:     with ops.Graph().as_default() as G:",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "138:   def testPeekBadIndex(self):",
      "139:     stager = data_flow_ops.StagingArea([",
      "140:         dtypes.int32,",
      "141:     ], shapes=[[10]])",
      "142:     stager.put([array_ops.zeros([10], dtype=dtypes.int32)])",
      "144:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
      "145:                                 'must be scalar'):",
      "146:       self.evaluate(stager.peek([]))",
      "",
      "---------------"
    ],
    "tensorflow/python/ops/data_flow_ops.py||tensorflow/python/ops/data_flow_ops.py": [
      "File: tensorflow/python/ops/data_flow_ops.py -> tensorflow/python/ops/data_flow_ops.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "1738:     # Sanity check number of values",
      "1739:     if not len(vals) <= len(self._dtypes):",
      "1741:                        f\"{len(self._dtypes)}\")",
      "1743:     tensors = []",
      "",
      "[Removed Lines]",
      "1740:       raise ValueError(f\"Unexpected number of inputs {len(vals)} vs\"",
      "",
      "[Added Lines]",
      "1740:       raise ValueError(f\"Unexpected number of inputs {len(vals)} vs \"",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "eba4b598cb9be3503d22b8e5124ebd3e9aef925c",
      "candidate_info": {
        "commit_hash": "eba4b598cb9be3503d22b8e5124ebd3e9aef925c",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/eba4b598cb9be3503d22b8e5124ebd3e9aef925c",
        "files": [
          "tensorflow/python/kernel_tests/map_fn_test.py",
          "tensorflow/python/ops/control_flow_grad.py",
          "tensorflow/python/ops/data_flow_ops.py",
          "tensorflow/python/ops/embedding_ops.py",
          "tensorflow/python/ops/linalg_ops.py",
          "tensorflow/python/ops/map_fn.py",
          "tensorflow/python/ops/partitioned_variables.py"
        ],
        "message": "bucket 29 error message fixes for TF Errors Fixit.\n\nPiperOrigin-RevId: 390223410\nChange-Id: Ie943e67692188fe196e84690fbb3a2342ca9efbc",
        "before_after_code_files": [
          "tensorflow/python/kernel_tests/map_fn_test.py||tensorflow/python/kernel_tests/map_fn_test.py",
          "tensorflow/python/ops/control_flow_grad.py||tensorflow/python/ops/control_flow_grad.py",
          "tensorflow/python/ops/data_flow_ops.py||tensorflow/python/ops/data_flow_ops.py",
          "tensorflow/python/ops/embedding_ops.py||tensorflow/python/ops/embedding_ops.py",
          "tensorflow/python/ops/linalg_ops.py||tensorflow/python/ops/linalg_ops.py",
          "tensorflow/python/ops/map_fn.py||tensorflow/python/ops/map_fn.py",
          "tensorflow/python/ops/partitioned_variables.py||tensorflow/python/ops/partitioned_variables.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/python/ops/data_flow_ops.py||tensorflow/python/ops/data_flow_ops.py"
          ],
          "candidate": [
            "tensorflow/python/ops/data_flow_ops.py||tensorflow/python/ops/data_flow_ops.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/python/kernel_tests/map_fn_test.py||tensorflow/python/kernel_tests/map_fn_test.py": [
          "File: tensorflow/python/kernel_tests/map_fn_test.py -> tensorflow/python/kernel_tests/map_fn_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "12: # See the License for the specific language governing permissions and",
          "13: # limitations under the License.",
          "14: # ==============================================================================",
          "15: \"\"\"Tests for tensorflow.kernels.functional_ops.\"\"\"",
          "17: from __future__ import absolute_import",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "15: # pylint: disable=anomalous-backslash-in-string",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "95:   @test_util.run_in_graph_and_eager_modes",
          "96:   def testMapOverScalarErrors(self):",
          "98:       map_fn.map_fn(lambda x: x, [1, 2])",
          "100:       map_fn.map_fn(lambda x: x, 1)",
          "102:   @test_util.run_deprecated_v1",
          "",
          "[Removed Lines]",
          "97:     with self.assertRaisesRegex(ValueError, \"not scalars\"):",
          "99:     with self.assertRaisesRegex(ValueError, \"not a scalar\"):",
          "",
          "[Added Lines]",
          "99:     with self.assertRaisesRegex(ValueError, \"must be .* Tensor.* not scalar\"):",
          "101:     with self.assertRaisesRegex(ValueError, \"must be .* Tensor.* not scalar\"):",
          "",
          "---------------"
        ],
        "tensorflow/python/ops/control_flow_grad.py||tensorflow/python/ops/control_flow_grad.py": [
          "File: tensorflow/python/ops/control_flow_grad.py -> tensorflow/python/ops/control_flow_grad.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "164:     grad_ctxt.AddName(grad.name)",
          "165:   else:",
          "166:     if not isinstance(grad, (ops.IndexedSlices, sparse_tensor.SparseTensor)):",
          "168:     grad_ctxt.AddName(grad.values.name)",
          "169:     grad_ctxt.AddName(grad.indices.name)",
          "170:     dense_shape = grad.dense_shape",
          "",
          "[Removed Lines]",
          "167:       raise TypeError(\"Type %s not supported\" % type(grad))",
          "",
          "[Added Lines]",
          "167:       raise TypeError(f\"Type {type(grad)} not supported, must be either\"",
          "168:                       \"`ops.IndexedSlices` or `SparseTensor`.\")",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "226:       result = grad_ctxt.AddBackpropIndexedSlicesAccumulator(op, grad)",
          "227:     else:",
          "228:       # TODO(yuanbyu, lukasr): Add support for SparseTensor.",
          "230:   else:",
          "231:     result = exit(grad)",
          "232:     grad_ctxt.loop_exits.append(result)",
          "",
          "[Removed Lines]",
          "229:       raise TypeError(\"Type %s not supported\" % type(grad))",
          "",
          "[Added Lines]",
          "230:       raise TypeError(f\"Type {type(grad)} not supported,\"",
          "231:                       \"must be Tensor or Indexed Slices\")",
          "",
          "---------------"
        ],
        "tensorflow/python/ops/data_flow_ops.py||tensorflow/python/ops/data_flow_ops.py": [
          "File: tensorflow/python/ops/data_flow_ops.py -> tensorflow/python/ops/data_flow_ops.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "73:     shapes = [shapes]",
          "74:   if not isinstance(shapes, (tuple, list)):",
          "75:     raise TypeError(",
          "77:   if all(shape is None or isinstance(shape, int) for shape in shapes):",
          "78:     # We have a single shape.",
          "79:     shapes = [shapes]",
          "80:   shapes = [tensor_shape.as_shape(shape) for shape in shapes]",
          "81:   if not unknown_dim_allowed:",
          "82:     if any(not shape.is_fully_defined() for shape in shapes):",
          "84:   if not unknown_rank_allowed:",
          "85:     if any(shape.dims is None for shape in shapes):",
          "88:   return shapes",
          "",
          "[Removed Lines]",
          "76:         \"shapes must be a TensorShape or a list or tuple of TensorShapes.\")",
          "83:       raise ValueError(\"All shapes must be fully defined: %s\" % shapes)",
          "86:       raise ValueError(\"All shapes must have a defined rank: %s\" % shapes)",
          "",
          "[Added Lines]",
          "76:         \"Shapes must be a TensorShape or a list or tuple of TensorShapes, \"",
          "77:         f\"got {type(shapes)} instead.\")",
          "84:       raise ValueError(f\"All shapes must be fully defined: {shapes}\")",
          "87:       raise ValueError(f\"All shapes must have a defined rank: {shapes}\")",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "95:     names = [names]",
          "96:   if len(names) != len(dtypes):",
          "97:     raise ValueError(\"List of names must have the same length as the list \"",
          "99:   return list(names)",
          "",
          "[Removed Lines]",
          "98:                      \"of dtypes\")",
          "",
          "[Added Lines]",
          "99:                      f\"of dtypes, received len(names)={len(names)},\"",
          "100:                      f\"len(dtypes)={len(dtypes)}\")",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "160:     self._dtypes = dtypes",
          "161:     if shapes is not None:",
          "162:       if len(shapes) != len(dtypes):",
          "164:       self._shapes = [tensor_shape.TensorShape(s) for s in shapes]",
          "165:     else:",
          "166:       self._shapes = [tensor_shape.unknown_shape() for _ in self._dtypes]",
          "167:     if names is not None:",
          "168:       if len(names) != len(dtypes):",
          "170:       self._names = names",
          "171:     else:",
          "172:       self._names = None",
          "",
          "[Removed Lines]",
          "163:         raise ValueError(\"Queue shapes must have the same length as dtypes\")",
          "169:         raise ValueError(\"Queue names must have the same length as dtypes\")",
          "",
          "[Added Lines]",
          "165:         raise ValueError(\"Queue shapes must have the same length as dtypes, \"",
          "166:                          f\"received len(shapes)={len(shapes)}, \"",
          "167:                          f\"len(dtypes)={len(dtypes)}\")",
          "173:         raise ValueError(\"Queue names must have the same length as dtypes,\"",
          "174:                          f\"received len(names)={len(names)},\"",
          "175:                          f\"len {len(dtypes)}\")",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "274:         raise ValueError(\"Queue must have names to enqueue a dictionary\")",
          "275:       if sorted(self._names, key=str) != sorted(vals.keys(), key=str):",
          "276:         raise ValueError(\"Keys in dictionary to enqueue do not match \"",
          "279:       # The order of values in `self._names` indicates the order in which the",
          "280:       # tensors in the dictionary `vals` must be listed.",
          "281:       vals = [vals[k] for k in self._names]",
          "",
          "[Removed Lines]",
          "277:                          \"names of Queue.  Dictionary: (%s), Queue: (%s)\" %",
          "278:                          (sorted(vals.keys()), sorted(self._names)))",
          "",
          "[Added Lines]",
          "283:                          f\"names of Queue.  Dictionary: {sorted(vals.keys())},\"",
          "284:                          f\"Queue: {sorted(self._names)}\")",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "906:     names = _as_name_list(names, dtypes)",
          "907:     if len(dtypes) != len(shapes):",
          "908:       raise ValueError(\"Shapes must be provided for all components, \"",
          "912:     queue_ref = gen_data_flow_ops.padding_fifo_queue_v2(",
          "913:         component_types=dtypes,",
          "914:         shapes=shapes,",
          "",
          "[Removed Lines]",
          "909:                        \"but received %d dtypes and %d shapes.\" % (len(dtypes),",
          "910:                                                                   len(shapes)))",
          "",
          "[Added Lines]",
          "915:                        f\"but received {len(dtypes)} dtypes and \"",
          "916:                        f\"{len(shapes)} shapes.\")",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "1060:       for i, shape in enumerate(self._shapes):",
          "1061:         if shape.num_elements() == 0:",
          "1062:           raise ValueError(\"Empty tensors are not supported, but received \"",
          "1064:     else:",
          "1065:       self._shapes = [tensor_shape.unknown_shape() for _ in self._types]",
          "",
          "[Removed Lines]",
          "1063:                            \"shape '%s' at index %d\" % (shape, i))",
          "",
          "[Added Lines]",
          "1068:                            f\"shape '{shape}' at index {i}\")",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "1621:     elif isinstance(shared_name, six.string_types):",
          "1622:       self._name = shared_name",
          "1623:     else:",
          "1626:     self._dtypes = dtypes",
          "",
          "[Removed Lines]",
          "1624:       raise ValueError(\"shared_name must be a string\")",
          "",
          "[Added Lines]",
          "1629:       raise ValueError(f\"shared_name must be a string, got {shared_name}\")",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "1710:             \"Staging areas must have names to enqueue a dictionary\")",
          "1711:       if not set(vals.keys()).issubset(self._names):",
          "1712:         raise ValueError(\"Keys in dictionary to put do not match names \"",
          "1715:       # The order of values in `self._names` indicates the order in which the",
          "1716:       # tensors in the dictionary `vals` must be listed.",
          "1717:       vals, indices, _ = zip(*[(vals[k], i, k)",
          "",
          "[Removed Lines]",
          "1713:                          \"of staging area. Dictionary: (%s), Queue: (%s)\" %",
          "1714:                          (sorted(vals.keys()), sorted(self._names)))",
          "",
          "[Added Lines]",
          "1718:                          f\"of staging area. Dictionary: {sorted(vals.keys())}\"",
          "1719:                          f\"Queue: {sorted(self._names)}\")",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "1727:                          \"of tensors\")",
          "1729:       if len(indices) != len(vals):",
          "1733:       if not isinstance(vals, (list, tuple)):",
          "1734:         vals = [vals]",
          "",
          "[Removed Lines]",
          "1730:         raise ValueError(\"Number of indices '%s' doesn't match \"",
          "1731:                          \"number of values '%s'\")",
          "",
          "[Added Lines]",
          "1735:         raise ValueError(f\"Number of indices {len(indices)} doesn't match \"",
          "1736:                          f\"number of values {len(vals)}\")",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "1737:     # Sanity check number of values",
          "1738:     if not len(vals) <= len(self._dtypes):",
          "1742:     tensors = []",
          "",
          "[Removed Lines]",
          "1739:       raise ValueError(\"Unexpected number of inputs '%s' vs '%s'\" %",
          "1740:                        (len(vals), len(self._dtypes)))",
          "",
          "[Added Lines]",
          "1744:       raise ValueError(f\"Unexpected number of inputs {len(vals)} vs\"",
          "1745:                        f\"{len(self._dtypes)}\")",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "1745:       dtype, shape = self._dtypes[i], self._shapes[i]",
          "1746:       # Check dtype",
          "1747:       if val.dtype != dtype:",
          "1751:       # Check shape",
          "1752:       val.get_shape().assert_is_compatible_with(shape)",
          "",
          "[Removed Lines]",
          "1748:         raise ValueError(\"Datatypes do not match. '%s' != '%s'\" %",
          "1749:                          (str(val.dtype), str(dtype)))",
          "",
          "[Added Lines]",
          "1753:         raise ValueError(f\"Datatypes do not match. \"",
          "1754:                          f\"Received val.dtype {str(val.dtype)} and \"",
          "1755:                          f\"dtype {str(dtype)}\")",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "2209:       indices = list(six.moves.range(len(self._dtypes)))",
          "2211:     if not isinstance(indices, (tuple, list)):",
          "2214:     if len(indices) == 0:",
          "2215:       raise ValueError(\"Empty indices\")",
          "2217:     if all(isinstance(i, str) for i in indices):",
          "2218:       if self._names is None:",
          "2222:       try:",
          "2223:         indices = [self._names.index(n) for n in indices]",
          "2224:       except ValueError:",
          "2227:     elif all(isinstance(i, int) for i in indices):",
          "2228:       pass",
          "2229:     else:",
          "2233:     dtypes = [self._dtypes[i] for i in indices]",
          "",
          "[Removed Lines]",
          "2212:       raise TypeError(\"Invalid indices type '%s'\" % type(indices))",
          "2219:         raise ValueError(\"String indices provided '%s', but this Staging Area \"",
          "2220:                          \"was not created with names.\" % indices)",
          "2225:         raise ValueError(\"Named index '%s' not in \"",
          "2226:                          \"Staging Area names '%s'\" % (n, self._names))",
          "2230:       raise TypeError(\"Mixed types in indices '%s'. \"",
          "2231:                       \"May only be str or int\" % indices)",
          "",
          "[Added Lines]",
          "2217:       raise TypeError(f\"Invalid indices type {type(indices)}\")",
          "2224:         raise ValueError(f\"String indices provided {indices}, but \"",
          "2225:                          \"this Staging Area was not created with names.\")",
          "2230:         raise ValueError(f\"Named index not in \"",
          "2231:                          f\"Staging Area names {self._names}\")",
          "2235:       raise TypeError(f\"Mixed types in indices {indices}. \"",
          "2236:                       \"May only be str or int\")",
          "",
          "---------------"
        ],
        "tensorflow/python/ops/embedding_ops.py||tensorflow/python/ops/embedding_ops.py": [
          "File: tensorflow/python/ops/embedding_ops.py -> tensorflow/python/ops/embedding_ops.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "128:   if params is None:",
          "129:     raise ValueError(\"params must be specified\")",
          "130:   if isinstance(params, (list, tuple)) and not params:",
          "132:   if isinstance(params, variables.PartitionedVariable):",
          "133:     params = list(params)  # Iterate to get the underlying Variables.",
          "134:   if not isinstance(params, list):",
          "",
          "[Removed Lines]",
          "131:     raise ValueError(\"Need at least one param\")",
          "",
          "[Added Lines]",
          "131:     raise ValueError(\"Length of params is currently 0. \"",
          "132:                      \"Need at least one param.\")",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "199:                                   flat_ids % (ids_per_partition + 1),",
          "200:                                   (flat_ids - extras) % ids_per_partition)",
          "201:       else:",
          "205:       # Cast partition assignments to int32 for use in dynamic_partition.",
          "206:       # There really should not be more than 2^32 partitions.",
          "",
          "[Removed Lines]",
          "202:         raise ValueError(\"Unrecognized partition strategy: \" +",
          "203:                          partition_strategy)",
          "",
          "[Added Lines]",
          "203:         raise ValueError(",
          "204:             f\"Unrecognized partition strategy: {partition_strategy}.\"",
          "205:             \"Must be one of either `mod` or `div`.\")",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "492:   if combiner is None:",
          "493:     combiner = \"mean\"",
          "494:   if combiner not in (\"mean\", \"sqrtn\", \"sum\"):",
          "496:   if isinstance(params, variables.PartitionedVariable):",
          "497:     params = list(params)  # Iterate to get the underlying Variables.",
          "498:   if not isinstance(params, list):",
          "499:     params = [params]",
          "500:   if not isinstance(sp_ids, sparse_tensor.SparseTensor):",
          "502:   ignore_weights = sp_weights is None",
          "503:   if not ignore_weights:",
          "504:     if not isinstance(sp_weights, sparse_tensor.SparseTensor):",
          "506:     sp_ids.values.get_shape().assert_is_compatible_with(",
          "507:         sp_weights.values.get_shape())",
          "508:     sp_ids.indices.get_shape().assert_is_compatible_with(",
          "",
          "[Removed Lines]",
          "495:     raise ValueError(\"combiner must be one of 'mean', 'sqrtn' or 'sum'\")",
          "501:     raise TypeError(\"sp_ids must be SparseTensor\")",
          "505:       raise TypeError(\"sp_weights must be either None or SparseTensor\")",
          "",
          "[Added Lines]",
          "497:     raise ValueError(",
          "498:         f\"combiner must be one of 'mean', 'sqrtn' or 'sum', got {combiner}\")",
          "504:     raise TypeError(f\"sp_ids must be SparseTensor, got {type(sp_ids)}\")",
          "508:       raise TypeError(f\"sp_weights must be either None or SparseTensor,\"",
          "509:                       f\"got {type(sp_weights)}\")",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "870:     ValueError: if `embedding_weights` is empty.",
          "871:   \"\"\"",
          "872:   if embedding_weights is None:",
          "874:   if isinstance(embedding_weights, variables.PartitionedVariable):",
          "875:     embedding_weights = list(embedding_weights)  # get underlying Variables.",
          "876:   if not isinstance(embedding_weights, list):",
          "877:     embedding_weights = [embedding_weights]",
          "878:   if len(embedding_weights) < 1:",
          "881:   dtype = sparse_weights.dtype if sparse_weights is not None else None",
          "882:   embedding_weights = [",
          "",
          "[Removed Lines]",
          "873:     raise ValueError(\"Missing embedding_weights %s.\" % embedding_weights)",
          "879:     raise ValueError(\"Missing embedding_weights %s.\" % embedding_weights)",
          "",
          "[Added Lines]",
          "877:     raise ValueError(f\"Missing embedding_weights {embedding_weights}.\")",
          "883:     raise ValueError(f\"Missing embedding_weights {embedding_weights}.\")",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "982:   if isinstance(embedding_weights, (list, tuple)) and not embedding_weights:",
          "983:     raise ValueError(\"The embedding weights should not be empty.\")",
          "984:   if ragged_ids.dtype != dtypes.int32 and ragged_ids.dtype != dtypes.int64:",
          "987:                      \" and cannot be processed. All values\"",
          "988:                      \" should be indices, either of type `in32` or `int64`.\")",
          "",
          "[Removed Lines]",
          "985:     raise ValueError(\"The values contained by the inputs have type \" +",
          "986:                      str(ragged_ids.dtype) +",
          "",
          "[Added Lines]",
          "989:     raise ValueError(\"The values contained by the inputs have type \"",
          "990:                      f\"{str(ragged_ids.dtype)}\"",
          "",
          "---------------"
        ],
        "tensorflow/python/ops/linalg_ops.py||tensorflow/python/ops/linalg_ops.py": [
          "File: tensorflow/python/ops/linalg_ops.py -> tensorflow/python/ops/linalg_ops.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "709:     if (not isinstance(axis[0], int) or not isinstance(axis[1], int) or",
          "710:         axis[0] == axis[1]):",
          "711:       raise ValueError(",
          "713:     supported_matrix_norms = ['euclidean', 'fro', 1, 2, np.inf]",
          "714:     if ord not in supported_matrix_norms:",
          "717:   else:",
          "718:     if not (isinstance(axis, int) or axis is None):",
          "719:       raise ValueError(",
          "722:     supported_vector_norms = ['euclidean', 1, 2, np.inf]",
          "723:     if (not np.isreal(ord) or ord <= 0) and ord not in supported_vector_norms:",
          "725:     if axis is not None:",
          "726:       axis = (axis,)",
          "",
          "[Removed Lines]",
          "712:           \"'axis' must be None, an integer, or a tuple of 2 unique integers\")",
          "715:       raise ValueError(\"'ord' must be a supported matrix norm in %s, got %s\" %",
          "716:                        (supported_matrix_norms, ord))",
          "720:           \"'axis' must be None, an integer, or a tuple of 2 unique integers\")",
          "724:       raise ValueError(\"'ord' must be a supported vector norm, got %s\" % ord)",
          "",
          "[Added Lines]",
          "712:           \"'axis' must be None, an integer, or a tuple of 2 \"",
          "713:           f\"unique integers, got {axis}\")",
          "716:       raise ValueError(f\"'ord' must be a supported matrix norm in \"",
          "717:                        f\"{supported_matrix_norms}, got {ord}\")",
          "721:           \"'axis' must be None, an integer, or a \"",
          "722:           f\"tuple of 2 unique integers, got {axis}\")",
          "726:       raise ValueError(f\"'ord' must be a supported vector norm, got {ord}\")",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "732:       if is_matrix_norm and ord in [2, 2.0]:",
          "733:         rank = array_ops.rank(tensor)",
          "734:         positive_axis = map_fn.map_fn(",
          "737:         axes = math_ops.range(rank)",
          "738:         perm_before = array_ops.concat([",
          "739:             gen_array_ops.list_diff(axes, positive_axis, dtypes.int32)[0],",
          "",
          "[Removed Lines]",
          "735:             lambda i: control_flow_ops.cond(i >= 0, lambda: i, lambda: i + rank),",
          "736:             ops.convert_to_tensor(axis))",
          "",
          "[Added Lines]",
          "737:             lambda i: control_flow_ops.cond(i >= 0, lambda: i, lambda: i + rank",
          "738:                                            ), ops.convert_to_tensor(axis))",
          "",
          "---------------"
        ],
        "tensorflow/python/ops/map_fn.py||tensorflow/python/ops/map_fn.py": [
          "File: tensorflow/python/ops/map_fn.py -> tensorflow/python/ops/map_fn.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "357:     fn_output_signature = dtype",
          "359:   if not callable(fn):",
          "362:   in_graph_mode = not context.executing_eagerly()",
          "363:   # Set the default number of parallel_iterations depending on graph/eager mode.",
          "",
          "[Removed Lines]",
          "360:     raise TypeError(\"fn must be callable.\")",
          "",
          "[Added Lines]",
          "360:     raise TypeError(f\"The provided function {fn.__name__} is not callable.\"",
          "361:                     \"fn must be callable.\")",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "422:     first_elem = elems_flat[0]",
          "423:     elems_static_shape = first_elem.shape",
          "424:     if elems_static_shape.ndims is not None and elems_static_shape.ndims < 1:",
          "432:     # Box any composite tensors into tensor lists.",
          "433:     elems_batchable = _elems_flat_to_batchable(elems_flat)",
          "",
          "[Removed Lines]",
          "425:       if len(elems_flat) == 1:",
          "426:         raise ValueError(\"elems must be a 1+ dimensional Tensor, not a scalar\")",
          "427:       else:",
          "428:         raise ValueError(",
          "429:             \"elements in elems must be 1+ dimensional Tensors, not scalars\"",
          "430:         )",
          "",
          "[Added Lines]",
          "426:       raise ValueError(",
          "427:           \"Elements in elems must be 1+ dimensional Tensors, not scalars\")",
          "",
          "---------------"
        ],
        "tensorflow/python/ops/partitioned_variables.py||tensorflow/python/ops/partitioned_variables.py": [
          "File: tensorflow/python/ops/partitioned_variables.py -> tensorflow/python/ops/partitioned_variables.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "103:   \"\"\"",
          "104:   if max_shard_bytes < 1 or bytes_per_string_element < 1:",
          "105:     raise ValueError(",
          "107:   if max_shards and max_shards < 1:",
          "108:     raise ValueError(",
          "109:         \"max_shards must be positive.\")",
          "",
          "[Removed Lines]",
          "106:         \"Both max_shard_bytes and bytes_per_string_element must be positive.\")",
          "",
          "[Added Lines]",
          "106:         \"Both max_shard_bytes and bytes_per_string_element must be positive. \"",
          "107:         f\"Currently, max_shard_bytes is {max_shard_bytes} and\"",
          "108:         f\"bytes_per_string_element is {bytes_per_string_element}\")",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "123:         a `DType`.",
          "124:     \"\"\"",
          "125:     if not isinstance(shape, tensor_shape.TensorShape):",
          "127:     if not shape.is_fully_defined():",
          "129:     if not isinstance(dtype, dtypes.DType):",
          "132:     if dtype.base_dtype == dtypes.string:",
          "133:       element_size = bytes_per_string_element",
          "",
          "[Removed Lines]",
          "126:       raise ValueError(\"shape is not a TensorShape: %s\" % shape)",
          "128:       raise ValueError(\"shape is not fully defined: %s\" % shape)",
          "130:       raise ValueError(\"dtype is not a DType: %s\" % dtype)",
          "",
          "[Added Lines]",
          "128:       raise ValueError(f\"shape is not a TensorShape: {shape}\")",
          "130:       raise ValueError(f\"shape is not fully defined: {shape}\")",
          "132:       raise ValueError(f\"dtype is not a DType: {dtype}\")",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "200:       ValueError: If axis to partition along does not exist for the variable.",
          "201:     \"\"\"",
          "202:     if axis >= len(shape):",
          "205:     if dtype.base_dtype == dtypes.string:",
          "206:       bytes_per_element = bytes_per_string_element",
          "207:     else:",
          "",
          "[Removed Lines]",
          "203:       raise ValueError(\"Can not partition variable along axis %d when shape is \"",
          "204:                        \"only %s\" % (axis, shape))",
          "",
          "[Added Lines]",
          "205:       raise ValueError(",
          "206:           f\"Cannot partition variable along axis {axis} when shape is \"",
          "207:           f\"only {shape}\")",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "286:     ValueError: If any of the arguments is malformed.",
          "287:   \"\"\"",
          "288:   if len(shape) != len(slicing):",
          "292:   if len(shape) < 1:",
          "293:     raise ValueError(\"A partitioned Variable must have rank at least 1: \"",
          "296:   # Legacy: we are provided the slicing directly, so just pass it to",
          "297:   # the partitioner.",
          "",
          "[Removed Lines]",
          "289:     raise ValueError(\"The 'shape' and 'slicing' of a partitioned Variable \"",
          "290:                      \"must have the length: shape: %s, slicing: %s\" %",
          "291:                      (shape, slicing))",
          "294:                      \"shape: %s\" % shape)",
          "",
          "[Added Lines]",
          "292:     raise ValueError(",
          "293:         \"The 'shape' and 'slicing' of a partitioned Variable \"",
          "294:         f\"must have the length: shape: {shape}, slicing: {slicing}\")",
          "297:                      f\"shape: {shape}\")",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "51d867296a46a60954affec46b6dbfac73181269",
      "candidate_info": {
        "commit_hash": "51d867296a46a60954affec46b6dbfac73181269",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/51d867296a46a60954affec46b6dbfac73181269",
        "files": [
          "tensorflow/core/kernels/stage_op.cc",
          "tensorflow/python/kernel_tests/stage_op_test.py",
          "tensorflow/python/ops/data_flow_ops.py"
        ],
        "message": "Fix tf.raw_ops.StagePeek vulnerability with invalid `index`.\n\nCheck that input is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445524908",
        "before_after_code_files": [
          "tensorflow/core/kernels/stage_op.cc||tensorflow/core/kernels/stage_op.cc",
          "tensorflow/python/kernel_tests/stage_op_test.py||tensorflow/python/kernel_tests/stage_op_test.py",
          "tensorflow/python/ops/data_flow_ops.py||tensorflow/python/ops/data_flow_ops.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/stage_op.cc||tensorflow/core/kernels/stage_op.cc",
            "tensorflow/python/ops/data_flow_ops.py||tensorflow/python/ops/data_flow_ops.py"
          ],
          "candidate": [
            "tensorflow/core/kernels/stage_op.cc||tensorflow/core/kernels/stage_op.cc",
            "tensorflow/python/ops/data_flow_ops.py||tensorflow/python/ops/data_flow_ops.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/stage_op.cc||tensorflow/core/kernels/stage_op.cc": [
          "File: tensorflow/core/kernels/stage_op.cc -> tensorflow/core/kernels/stage_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "258:     core::ScopedUnref scope(buf);",
          "259:     Buffer::Tuple tuple;",
          "261:     std::size_t index = ctx->input(0).scalar<int>()();",
          "263:     OP_REQUIRES_OK(ctx, buf->Peek(index, &tuple));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "261:     OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(ctx->input(0).shape()),",
          "262:                 errors::InvalidArgument(\"index must be scalar\"));",
          "",
          "---------------"
        ],
        "tensorflow/python/kernel_tests/stage_op_test.py||tensorflow/python/kernel_tests/stage_op_test.py": [
          "File: tensorflow/python/kernel_tests/stage_op_test.py -> tensorflow/python/kernel_tests/stage_op_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: from __future__ import print_function",
          "19: from tensorflow.python.framework import dtypes",
          "20: from tensorflow.python.framework import ops",
          "21: from tensorflow.python.framework import test_util",
          "22: from tensorflow.python.ops import array_ops",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "20: from tensorflow.python.framework import errors",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "138:       for i in range(10):",
          "139:         self.assertTrue(sess.run(peek, feed_dict={p: i}) == [i])",
          "141:   @test_util.run_deprecated_v1",
          "142:   def testSizeAndClear(self):",
          "143:     with ops.Graph().as_default() as G:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "142:   def testPeekBadIndex(self):",
          "143:     stager = data_flow_ops.StagingArea([",
          "144:         dtypes.int32,",
          "145:     ], shapes=[[10]])",
          "146:     stager.put([array_ops.zeros([10], dtype=dtypes.int32)])",
          "148:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "149:                                 'must be scalar'):",
          "150:       self.evaluate(stager.peek([]))",
          "",
          "---------------"
        ],
        "tensorflow/python/ops/data_flow_ops.py||tensorflow/python/ops/data_flow_ops.py": [
          "File: tensorflow/python/ops/data_flow_ops.py -> tensorflow/python/ops/data_flow_ops.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1742:     # Sanity check number of values",
          "1743:     if not len(vals) <= len(self._dtypes):",
          "1745:                        f\"{len(self._dtypes)}\")",
          "1747:     tensors = []",
          "",
          "[Removed Lines]",
          "1744:       raise ValueError(f\"Unexpected number of inputs {len(vals)} vs\"",
          "",
          "[Added Lines]",
          "1744:       raise ValueError(f\"Unexpected number of inputs {len(vals)} vs \"",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "c12187aedadf9346134be70f5eb99c1afc8934ab",
      "candidate_info": {
        "commit_hash": "c12187aedadf9346134be70f5eb99c1afc8934ab",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/c12187aedadf9346134be70f5eb99c1afc8934ab",
        "files": [
          "tensorflow/core/kernels/stage_op.cc",
          "tensorflow/python/kernel_tests/stage_op_test.py"
        ],
        "message": "Fix tf.raw_ops.StagePeek vulnerability with invalid `index`.\n\nCheck that input is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445524908",
        "before_after_code_files": [
          "tensorflow/core/kernels/stage_op.cc||tensorflow/core/kernels/stage_op.cc",
          "tensorflow/python/kernel_tests/stage_op_test.py||tensorflow/python/kernel_tests/stage_op_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/stage_op.cc||tensorflow/core/kernels/stage_op.cc"
          ],
          "candidate": [
            "tensorflow/core/kernels/stage_op.cc||tensorflow/core/kernels/stage_op.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/stage_op.cc||tensorflow/core/kernels/stage_op.cc": [
          "File: tensorflow/core/kernels/stage_op.cc -> tensorflow/core/kernels/stage_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "264:     core::ScopedUnref scope(buf);",
          "265:     Buffer::Tuple tuple;",
          "267:     std::size_t index = ctx->input(0).scalar<int>()();",
          "269:     OP_REQUIRES_OK(ctx, buf->Peek(index, &tuple));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "267:     OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(ctx->input(0).shape()),",
          "268:                 errors::InvalidArgument(\"index must be scalar\"));",
          "",
          "---------------"
        ],
        "tensorflow/python/kernel_tests/stage_op_test.py||tensorflow/python/kernel_tests/stage_op_test.py": [
          "File: tensorflow/python/kernel_tests/stage_op_test.py -> tensorflow/python/kernel_tests/stage_op_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: from __future__ import print_function",
          "19: from tensorflow.python.framework import dtypes",
          "20: from tensorflow.python.framework import ops",
          "21: from tensorflow.python.framework import test_util",
          "22: from tensorflow.python.ops import array_ops",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "20: from tensorflow.python.framework import errors",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "138:       for i in range(10):",
          "139:         self.assertTrue(sess.run(peek, feed_dict={p: i}) == [i])",
          "141:   @test_util.run_deprecated_v1",
          "142:   def testSizeAndClear(self):",
          "143:     with ops.Graph().as_default() as G:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "142:   def testPeekBadIndex(self):",
          "143:     stager = data_flow_ops.StagingArea([",
          "144:         dtypes.int32,",
          "145:     ], shapes=[[10]])",
          "146:     stager.put([array_ops.zeros([10], dtype=dtypes.int32)])",
          "148:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "149:                                 'must be scalar'):",
          "150:       self.evaluate(stager.peek([]))",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "bdac05929ec6f21ef9cdc4b9f7ce7a16ef029bd0",
      "candidate_info": {
        "commit_hash": "bdac05929ec6f21ef9cdc4b9f7ce7a16ef029bd0",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/bdac05929ec6f21ef9cdc4b9f7ce7a16ef029bd0",
        "files": [
          "tensorflow/core/kernels/stage_op.cc",
          "tensorflow/python/kernel_tests/data_structures/stage_op_test.py",
          "tensorflow/python/ops/data_flow_ops.py"
        ],
        "message": "Fix tf.raw_ops.StagePeek vulnerability with invalid `index`.\n\nCheck that input is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445524908",
        "before_after_code_files": [
          "tensorflow/core/kernels/stage_op.cc||tensorflow/core/kernels/stage_op.cc",
          "tensorflow/python/kernel_tests/data_structures/stage_op_test.py||tensorflow/python/kernel_tests/data_structures/stage_op_test.py",
          "tensorflow/python/ops/data_flow_ops.py||tensorflow/python/ops/data_flow_ops.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/stage_op.cc||tensorflow/core/kernels/stage_op.cc",
            "tensorflow/python/kernel_tests/data_structures/stage_op_test.py||tensorflow/python/kernel_tests/data_structures/stage_op_test.py",
            "tensorflow/python/ops/data_flow_ops.py||tensorflow/python/ops/data_flow_ops.py"
          ],
          "candidate": [
            "tensorflow/core/kernels/stage_op.cc||tensorflow/core/kernels/stage_op.cc",
            "tensorflow/python/kernel_tests/data_structures/stage_op_test.py||tensorflow/python/kernel_tests/data_structures/stage_op_test.py",
            "tensorflow/python/ops/data_flow_ops.py||tensorflow/python/ops/data_flow_ops.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/stage_op.cc||tensorflow/core/kernels/stage_op.cc": [
          "File: tensorflow/core/kernels/stage_op.cc -> tensorflow/core/kernels/stage_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "258:     core::ScopedUnref scope(buf);",
          "259:     Buffer::Tuple tuple;",
          "261:     std::size_t index = ctx->input(0).scalar<int>()();",
          "263:     OP_REQUIRES_OK(ctx, buf->Peek(index, &tuple));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "261:     OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(ctx->input(0).shape()),",
          "262:                 errors::InvalidArgument(\"index must be scalar\"));",
          "",
          "---------------"
        ],
        "tensorflow/python/kernel_tests/data_structures/stage_op_test.py||tensorflow/python/kernel_tests/data_structures/stage_op_test.py": [
          "File: tensorflow/python/kernel_tests/data_structures/stage_op_test.py -> tensorflow/python/kernel_tests/data_structures/stage_op_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "13: # limitations under the License.",
          "14: # ==============================================================================",
          "15: from tensorflow.python.framework import dtypes",
          "16: from tensorflow.python.framework import ops",
          "17: from tensorflow.python.framework import test_util",
          "18: from tensorflow.python.ops import array_ops",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "16: from tensorflow.python.framework import errors",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "134:       for i in range(10):",
          "135:         self.assertTrue(sess.run(peek, feed_dict={p: i}) == [i])",
          "137:   @test_util.run_deprecated_v1",
          "138:   def testSizeAndClear(self):",
          "139:     with ops.Graph().as_default() as G:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "138:   def testPeekBadIndex(self):",
          "139:     stager = data_flow_ops.StagingArea([",
          "140:         dtypes.int32,",
          "141:     ], shapes=[[10]])",
          "142:     stager.put([array_ops.zeros([10], dtype=dtypes.int32)])",
          "144:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "145:                                 'must be scalar'):",
          "146:       self.evaluate(stager.peek([]))",
          "",
          "---------------"
        ],
        "tensorflow/python/ops/data_flow_ops.py||tensorflow/python/ops/data_flow_ops.py": [
          "File: tensorflow/python/ops/data_flow_ops.py -> tensorflow/python/ops/data_flow_ops.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1739:     # Sanity check number of values",
          "1740:     if not len(vals) <= len(self._dtypes):",
          "1742:                        f\"{len(self._dtypes)}\")",
          "1744:     tensors = []",
          "",
          "[Removed Lines]",
          "1741:       raise ValueError(f\"Unexpected number of inputs {len(vals)} vs\"",
          "",
          "[Added Lines]",
          "1741:       raise ValueError(f\"Unexpected number of inputs {len(vals)} vs \"",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "f778d0bc68c5638243f55739e9c6b8cd519b46b0",
      "candidate_info": {
        "commit_hash": "f778d0bc68c5638243f55739e9c6b8cd519b46b0",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/f778d0bc68c5638243f55739e9c6b8cd519b46b0",
        "files": [
          "tensorflow/core/kernels/stage_op.cc",
          "tensorflow/python/kernel_tests/data_structures/stage_op_test.py",
          "tensorflow/python/ops/data_flow_ops.py"
        ],
        "message": "Fix tf.raw_ops.StagePeek vulnerability with invalid `index`.\n\nCheck that input is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445524908",
        "before_after_code_files": [
          "tensorflow/core/kernels/stage_op.cc||tensorflow/core/kernels/stage_op.cc",
          "tensorflow/python/kernel_tests/data_structures/stage_op_test.py||tensorflow/python/kernel_tests/data_structures/stage_op_test.py",
          "tensorflow/python/ops/data_flow_ops.py||tensorflow/python/ops/data_flow_ops.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/stage_op.cc||tensorflow/core/kernels/stage_op.cc",
            "tensorflow/python/kernel_tests/data_structures/stage_op_test.py||tensorflow/python/kernel_tests/data_structures/stage_op_test.py",
            "tensorflow/python/ops/data_flow_ops.py||tensorflow/python/ops/data_flow_ops.py"
          ],
          "candidate": [
            "tensorflow/core/kernels/stage_op.cc||tensorflow/core/kernels/stage_op.cc",
            "tensorflow/python/kernel_tests/data_structures/stage_op_test.py||tensorflow/python/kernel_tests/data_structures/stage_op_test.py",
            "tensorflow/python/ops/data_flow_ops.py||tensorflow/python/ops/data_flow_ops.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/stage_op.cc||tensorflow/core/kernels/stage_op.cc": [
          "File: tensorflow/core/kernels/stage_op.cc -> tensorflow/core/kernels/stage_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "258:     core::ScopedUnref scope(buf);",
          "259:     Buffer::Tuple tuple;",
          "261:     std::size_t index = ctx->input(0).scalar<int>()();",
          "263:     OP_REQUIRES_OK(ctx, buf->Peek(index, &tuple));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "261:     OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(ctx->input(0).shape()),",
          "262:                 errors::InvalidArgument(\"index must be scalar\"));",
          "",
          "---------------"
        ],
        "tensorflow/python/kernel_tests/data_structures/stage_op_test.py||tensorflow/python/kernel_tests/data_structures/stage_op_test.py": [
          "File: tensorflow/python/kernel_tests/data_structures/stage_op_test.py -> tensorflow/python/kernel_tests/data_structures/stage_op_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "13: # limitations under the License.",
          "14: # ==============================================================================",
          "15: from tensorflow.python.framework import dtypes",
          "16: from tensorflow.python.framework import ops",
          "17: from tensorflow.python.framework import test_util",
          "18: from tensorflow.python.ops import array_ops",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "16: from tensorflow.python.framework import errors",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "134:       for i in range(10):",
          "135:         self.assertTrue(sess.run(peek, feed_dict={p: i}) == [i])",
          "137:   @test_util.run_deprecated_v1",
          "138:   def testSizeAndClear(self):",
          "139:     with ops.Graph().as_default() as G:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "138:   def testPeekBadIndex(self):",
          "139:     stager = data_flow_ops.StagingArea([",
          "140:         dtypes.int32,",
          "141:     ], shapes=[[10]])",
          "142:     stager.put([array_ops.zeros([10], dtype=dtypes.int32)])",
          "144:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "145:                                 'must be scalar'):",
          "146:       self.evaluate(stager.peek([]))",
          "",
          "---------------"
        ],
        "tensorflow/python/ops/data_flow_ops.py||tensorflow/python/ops/data_flow_ops.py": [
          "File: tensorflow/python/ops/data_flow_ops.py -> tensorflow/python/ops/data_flow_ops.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1738:     # Sanity check number of values",
          "1739:     if not len(vals) <= len(self._dtypes):",
          "1741:                        f\"{len(self._dtypes)}\")",
          "1743:     tensors = []",
          "",
          "[Removed Lines]",
          "1740:       raise ValueError(f\"Unexpected number of inputs {len(vals)} vs\"",
          "",
          "[Added Lines]",
          "1740:       raise ValueError(f\"Unexpected number of inputs {len(vals)} vs \"",
          "",
          "---------------"
        ]
      }
    }
  ]
}