{
  "cve_id": "CVE-2021-29582",
  "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. Due to lack of validation in `tf.raw_ops.Dequantize`, an attacker can trigger a read from outside of bounds of heap allocated data. The implementation(https://github.com/tensorflow/tensorflow/blob/26003593aa94b1742f34dc22ce88a1e17776a67d/tensorflow/core/kernels/dequantize_op.cc#L106-L131) accesses the `min_range` and `max_range` tensors in parallel but fails to check that they have the same shape. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
  "repo": "tensorflow/tensorflow",
  "patch_hash": "5899741d0421391ca878da47907b1452f06aaf1b",
  "patch_info": {
    "commit_hash": "5899741d0421391ca878da47907b1452f06aaf1b",
    "repo": "tensorflow/tensorflow",
    "commit_url": "https://github.com/tensorflow/tensorflow/commit/5899741d0421391ca878da47907b1452f06aaf1b",
    "files": [
      "tensorflow/core/kernels/dequantize_op.cc"
    ],
    "message": "Fix heap OOB read in dequantize op.\n\nAlso fixes SEGV in same op\n\nPiperOrigin-RevId: 372437896\nChange-Id: I135e94d360c2a1ce374c10f7e0fed1af603dbc02",
    "before_after_code_files": [
      "tensorflow/core/kernels/dequantize_op.cc||tensorflow/core/kernels/dequantize_op.cc"
    ]
  },
  "patch_diff": {
    "tensorflow/core/kernels/dequantize_op.cc||tensorflow/core/kernels/dequantize_op.cc": [
      "File: tensorflow/core/kernels/dequantize_op.cc -> tensorflow/core/kernels/dequantize_op.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "98:     if (axis_ > -1) {",
      "99:       num_slices = input.dim_size(axis_);",
      "100:     }",
      "102:     Tensor* output = nullptr;",
      "103:     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "101:     OP_REQUIRES(ctx, input_min_tensor.NumElements() == num_slices,",
      "102:                 errors::InvalidArgument(",
      "103:                     \"input_min_tensor must have as many elements as input on \"",
      "104:                     \"the dequantization axis (\",",
      "105:                     axis_, \"), got \", input_min_tensor.NumElements(),",
      "106:                     \", expected \", num_slices));",
      "107:     OP_REQUIRES(ctx, input_max_tensor.NumElements() == num_slices,",
      "108:                 errors::InvalidArgument(",
      "109:                     \"input_max_tensor must have as many elements as input on \"",
      "110:                     \"the dequantization axis (\",",
      "111:                     axis_, \"), got \", input_max_tensor.NumElements(),",
      "112:                     \", expected \", num_slices));",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "3aab9305d3c3908e7f4bf4ca619c47117af4fb62",
      "candidate_info": {
        "commit_hash": "3aab9305d3c3908e7f4bf4ca619c47117af4fb62",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/3aab9305d3c3908e7f4bf4ca619c47117af4fb62",
        "files": [
          "tensorflow/core/kernels/dequantize_op.cc"
        ],
        "message": "Fix heap OOB read in dequantize op.\n\nAlso fixes SEGV in same op\n\nPiperOrigin-RevId: 372437896\nChange-Id: I135e94d360c2a1ce374c10f7e0fed1af603dbc02",
        "before_after_code_files": [
          "tensorflow/core/kernels/dequantize_op.cc||tensorflow/core/kernels/dequantize_op.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/dequantize_op.cc||tensorflow/core/kernels/dequantize_op.cc"
          ],
          "candidate": [
            "tensorflow/core/kernels/dequantize_op.cc||tensorflow/core/kernels/dequantize_op.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/dequantize_op.cc||tensorflow/core/kernels/dequantize_op.cc": [
          "File: tensorflow/core/kernels/dequantize_op.cc -> tensorflow/core/kernels/dequantize_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "96:     if (axis_ > -1) {",
          "97:       num_slices = input.dim_size(axis_);",
          "98:     }",
          "100:     Tensor* output = nullptr;",
          "101:     Tensor float_output = tensorflow::Tensor(DT_FLOAT, input.shape());",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "99:     OP_REQUIRES(ctx, input_min_tensor.NumElements() == num_slices,",
          "100:                 errors::InvalidArgument(",
          "101:                     \"input_min_tensor must have as many elements as input on \"",
          "102:                     \"the dequantization axis (\",",
          "103:                     axis_, \"), got \", input_min_tensor.NumElements(),",
          "104:                     \", expected \", num_slices));",
          "105:     OP_REQUIRES(ctx, input_max_tensor.NumElements() == num_slices,",
          "106:                 errors::InvalidArgument(",
          "107:                     \"input_max_tensor must have as many elements as input on \"",
          "108:                     \"the dequantization axis (\",",
          "109:                     axis_, \"), got \", input_max_tensor.NumElements(),",
          "110:                     \", expected \", num_slices));",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "38bd82842630c5c23d0e5f0832eee8154108fab8",
      "candidate_info": {
        "commit_hash": "38bd82842630c5c23d0e5f0832eee8154108fab8",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/38bd82842630c5c23d0e5f0832eee8154108fab8",
        "files": [
          "tensorflow/core/kernels/dequantize_op.cc"
        ],
        "message": "Fix heap OOB read in dequantize op.\n\nAlso fixes SEGV in same op\n\nPiperOrigin-RevId: 372437896\nChange-Id: I135e94d360c2a1ce374c10f7e0fed1af603dbc02",
        "before_after_code_files": [
          "tensorflow/core/kernels/dequantize_op.cc||tensorflow/core/kernels/dequantize_op.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/dequantize_op.cc||tensorflow/core/kernels/dequantize_op.cc"
          ],
          "candidate": [
            "tensorflow/core/kernels/dequantize_op.cc||tensorflow/core/kernels/dequantize_op.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/dequantize_op.cc||tensorflow/core/kernels/dequantize_op.cc": [
          "File: tensorflow/core/kernels/dequantize_op.cc -> tensorflow/core/kernels/dequantize_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "98:     if (axis_ > -1) {",
          "99:       num_slices = input.dim_size(axis_);",
          "100:     }",
          "102:     Tensor* output = nullptr;",
          "103:     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "101:     OP_REQUIRES(ctx, input_min_tensor.NumElements() == num_slices,",
          "102:                 errors::InvalidArgument(",
          "103:                     \"input_min_tensor must have as many elements as input on \"",
          "104:                     \"the dequantization axis (\",",
          "105:                     axis_, \"), got \", input_min_tensor.NumElements(),",
          "106:                     \", expected \", num_slices));",
          "107:     OP_REQUIRES(ctx, input_max_tensor.NumElements() == num_slices,",
          "108:                 errors::InvalidArgument(",
          "109:                     \"input_max_tensor must have as many elements as input on \"",
          "110:                     \"the dequantization axis (\",",
          "111:                     axis_, \"), got \", input_max_tensor.NumElements(),",
          "112:                     \", expected \", num_slices));",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "48083ad391775a008d40d7dfee007b98406bb0a2",
      "candidate_info": {
        "commit_hash": "48083ad391775a008d40d7dfee007b98406bb0a2",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/48083ad391775a008d40d7dfee007b98406bb0a2",
        "files": [
          "tensorflow/core/kernels/dequantize_op.cc"
        ],
        "message": "Fix heap OOB read in dequantize op.\n\nAlso fixes SEGV in same op\n\nPiperOrigin-RevId: 372437896\nChange-Id: I135e94d360c2a1ce374c10f7e0fed1af603dbc02",
        "before_after_code_files": [
          "tensorflow/core/kernels/dequantize_op.cc||tensorflow/core/kernels/dequantize_op.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/dequantize_op.cc||tensorflow/core/kernels/dequantize_op.cc"
          ],
          "candidate": [
            "tensorflow/core/kernels/dequantize_op.cc||tensorflow/core/kernels/dequantize_op.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/dequantize_op.cc||tensorflow/core/kernels/dequantize_op.cc": [
          "File: tensorflow/core/kernels/dequantize_op.cc -> tensorflow/core/kernels/dequantize_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "98:     if (axis_ > -1) {",
          "99:       num_slices = input.dim_size(axis_);",
          "100:     }",
          "102:     Tensor* output = nullptr;",
          "103:     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "101:     OP_REQUIRES(ctx, input_min_tensor.NumElements() == num_slices,",
          "102:                 errors::InvalidArgument(",
          "103:                     \"input_min_tensor must have as many elements as input on \"",
          "104:                     \"the dequantization axis (\",",
          "105:                     axis_, \"), got \", input_min_tensor.NumElements(),",
          "106:                     \", expected \", num_slices));",
          "107:     OP_REQUIRES(ctx, input_max_tensor.NumElements() == num_slices,",
          "108:                 errors::InvalidArgument(",
          "109:                     \"input_max_tensor must have as many elements as input on \"",
          "110:                     \"the dequantization axis (\",",
          "111:                     axis_, \"), got \", input_max_tensor.NumElements(),",
          "112:                     \", expected \", num_slices));",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "c0998257ea4a5b3f497407f5f8dabcd2c70f53ca",
      "candidate_info": {
        "commit_hash": "c0998257ea4a5b3f497407f5f8dabcd2c70f53ca",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/c0998257ea4a5b3f497407f5f8dabcd2c70f53ca",
        "files": [
          "tensorflow/core/kernels/dequantize_op.cc"
        ],
        "message": "Fix heap OOB read in dequantize op.\n\nAlso fixes SEGV in same op\n\nPiperOrigin-RevId: 372437896\nChange-Id: I135e94d360c2a1ce374c10f7e0fed1af603dbc02",
        "before_after_code_files": [
          "tensorflow/core/kernels/dequantize_op.cc||tensorflow/core/kernels/dequantize_op.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/dequantize_op.cc||tensorflow/core/kernels/dequantize_op.cc"
          ],
          "candidate": [
            "tensorflow/core/kernels/dequantize_op.cc||tensorflow/core/kernels/dequantize_op.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/dequantize_op.cc||tensorflow/core/kernels/dequantize_op.cc": [
          "File: tensorflow/core/kernels/dequantize_op.cc -> tensorflow/core/kernels/dequantize_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "98:     if (axis_ > -1) {",
          "99:       num_slices = input.dim_size(axis_);",
          "100:     }",
          "102:     Tensor* output = nullptr;",
          "103:     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "101:     OP_REQUIRES(ctx, input_min_tensor.NumElements() == num_slices,",
          "102:                 errors::InvalidArgument(",
          "103:                     \"input_min_tensor must have as many elements as input on \"",
          "104:                     \"the dequantization axis (\",",
          "105:                     axis_, \"), got \", input_min_tensor.NumElements(),",
          "106:                     \", expected \", num_slices));",
          "107:     OP_REQUIRES(ctx, input_max_tensor.NumElements() == num_slices,",
          "108:                 errors::InvalidArgument(",
          "109:                     \"input_max_tensor must have as many elements as input on \"",
          "110:                     \"the dequantization axis (\",",
          "111:                     axis_, \"), got \", input_max_tensor.NumElements(),",
          "112:                     \", expected \", num_slices));",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "55993172172f6eb42a89590c4ba9626e1599410e",
      "candidate_info": {
        "commit_hash": "55993172172f6eb42a89590c4ba9626e1599410e",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/55993172172f6eb42a89590c4ba9626e1599410e",
        "files": [
          "tensorflow/core/kernels/dequantize_op.cc"
        ],
        "message": "Fix heap OOB read in dequantize op.\n\nAlso fixes SEGV in same op\n\nPiperOrigin-RevId: 372437896\nChange-Id: I135e94d360c2a1ce374c10f7e0fed1af603dbc02",
        "before_after_code_files": [
          "tensorflow/core/kernels/dequantize_op.cc||tensorflow/core/kernels/dequantize_op.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/dequantize_op.cc||tensorflow/core/kernels/dequantize_op.cc"
          ],
          "candidate": [
            "tensorflow/core/kernels/dequantize_op.cc||tensorflow/core/kernels/dequantize_op.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/dequantize_op.cc||tensorflow/core/kernels/dequantize_op.cc": [
          "File: tensorflow/core/kernels/dequantize_op.cc -> tensorflow/core/kernels/dequantize_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "69:     if (axis_ > -1) {",
          "70:       num_slices = input.dim_size(axis_);",
          "71:     }",
          "73:     Tensor* output = nullptr;",
          "74:     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "72:     OP_REQUIRES(ctx, input_min_tensor.NumElements() == num_slices,",
          "73:                 errors::InvalidArgument(",
          "74:                     \"input_min_tensor must have as many elements as input on \"",
          "75:                     \"the dequantization axis (\",",
          "76:                     axis_, \"), got \", input_min_tensor.NumElements(),",
          "77:                     \", expected \", num_slices));",
          "78:     OP_REQUIRES(ctx, input_max_tensor.NumElements() == num_slices,",
          "79:                 errors::InvalidArgument(",
          "80:                     \"input_max_tensor must have as many elements as input on \"",
          "81:                     \"the dequantization axis (\",",
          "82:                     axis_, \"), got \", input_max_tensor.NumElements(),",
          "83:                     \", expected \", num_slices));",
          "",
          "---------------"
        ]
      }
    }
  ]
}