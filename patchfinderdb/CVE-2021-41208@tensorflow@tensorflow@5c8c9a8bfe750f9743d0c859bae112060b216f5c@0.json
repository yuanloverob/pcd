{
  "cve_id": "CVE-2021-41208",
  "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions the code for boosted trees in TensorFlow is still missing validation. As a result, attackers can trigger denial of service (via dereferencing `nullptr`s or via `CHECK`-failures) as well as abuse undefined behavior (binding references to `nullptr`s). An attacker can also read and write from heap buffers, depending on the API that gets used and the arguments that are passed to the call. Given that the boosted trees implementation in TensorFlow is unmaintained, it is recommend to no longer use these APIs. We will deprecate TensorFlow's boosted trees APIs in subsequent releases. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
  "repo": "tensorflow/tensorflow",
  "patch_hash": "5c8c9a8bfe750f9743d0c859bae112060b216f5c",
  "patch_info": {
    "commit_hash": "5c8c9a8bfe750f9743d0c859bae112060b216f5c",
    "repo": "tensorflow/tensorflow",
    "commit_url": "https://github.com/tensorflow/tensorflow/commit/5c8c9a8bfe750f9743d0c859bae112060b216f5c",
    "files": [
      "tensorflow/core/kernels/boosted_trees/stats_ops.cc",
      "tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py"
    ],
    "message": "Fixing security fixes in boosted trees ops\n\nPiperOrigin-RevId: 405669548\nChange-Id: Iae224d240d1779bcc02405c2fff99785644fbd0d",
    "before_after_code_files": [
      "tensorflow/core/kernels/boosted_trees/stats_ops.cc||tensorflow/core/kernels/boosted_trees/stats_ops.cc",
      "tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py||tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py"
    ]
  },
  "patch_diff": {
    "tensorflow/core/kernels/boosted_trees/stats_ops.cc||tensorflow/core/kernels/boosted_trees/stats_ops.cc": [
      "File: tensorflow/core/kernels/boosted_trees/stats_ops.cc -> tensorflow/core/kernels/boosted_trees/stats_ops.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "72:                                                 &stats_summary_list));",
      "73:     const int64_t num_buckets = stats_summary_list[0].dim_size(1);",
      "76:     std::vector<TTypes<float, 3>::ConstTensor> stats_summary;",
      "77:     stats_summary.reserve(stats_summary_list.size());",
      "78:     for (const auto& tensor : stats_summary_list) {",
      "",
      "[Removed Lines]",
      "75:     DCHECK_EQ(stats_summary_list[0].dim_size(2), 2);",
      "",
      "[Added Lines]",
      "75:     OP_REQUIRES(context, stats_summary_list[0].dim_size(2) == 2,",
      "76:                 errors::InvalidArgument(\"stats_summary_list[0] must have \"",
      "77:                                         \"exactly 2 dimensions, obtained: \",",
      "78:                                         stats_summary_list[0].dim_size(2)));",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "275:     const int32_t num_buckets = stats_summary_t->dim_size(2) - 1;",
      "276:     const int32_t logits_dim = logits_dim_;",
      "277:     const int32_t hessian_dim = stats_summary_t->dim_size(3) - logits_dim;",
      "281:     const Tensor* l1_t;",
      "282:     OP_REQUIRES_OK(context, context->input(\"l1\", &l1_t));",
      "",
      "[Removed Lines]",
      "278:     DCHECK_GT(hessian_dim, 0);",
      "279:     DCHECK_LE(hessian_dim, logits_dim * logits_dim);",
      "",
      "[Added Lines]",
      "281:     OP_REQUIRES(context, hessian_dim > 0,",
      "282:                 errors::InvalidArgument(\"hessian dim should be < 0, got \",",
      "283:                                         hessian_dim));",
      "284:     OP_REQUIRES(context, hessian_dim <= logits_dim * logits_dim,",
      "285:                 errors::InvalidArgument(",
      "286:                     \"hessian dim should be <= \", logits_dim * logits_dim,",
      "287:                     \" but got: \", hessian_dim));",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "624:     const int32_t logits_dim = logits_dim_;",
      "625:     const int32_t hessian_dim =",
      "626:         stats_summaries_list[0].dim_size(3) - logits_dim;",
      "",
      "[Removed Lines]",
      "627:     DCHECK_GT(hessian_dim, 0);",
      "628:     DCHECK_LE(hessian_dim, logits_dim * logits_dim);",
      "",
      "[Added Lines]",
      "635:     OP_REQUIRES(context, hessian_dim > 0,",
      "636:                 errors::InvalidArgument(\"hessian dim should be < 0, got \",",
      "637:                                         hessian_dim));",
      "638:     OP_REQUIRES(context, hessian_dim <= logits_dim * logits_dim,",
      "639:                 errors::InvalidArgument(",
      "640:                     \"hessian dim should be <= \", logits_dim * logits_dim,",
      "641:                     \" but got: \", hessian_dim));",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "1002:     const Tensor* node_id_range_t;",
      "1003:     OP_REQUIRES_OK(context, context->input(\"node_id_range\", &node_id_range_t));",
      "1004:     const auto node_id_range = node_id_range_t->vec<int32>();",
      "1005:     const int32_t node_id_first = node_id_range(0);  // inclusive",
      "1006:     const int32_t node_id_last = node_id_range(1);   // exclusive",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "1018:     OP_REQUIRES(",
      "1019:         context, node_id_range.size() == 2,",
      "1020:         errors::InvalidArgument(\"node_id_range should have 2 entries, got: \",",
      "1021:                                 node_id_range.size()));",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "1075:                       \"dims, the last value in stats_summary_shape, which was \",",
      "1076:                       stats_dims, \". At index (\", idx,",
      "1077:                       \", 4), stats_summary_indices contains value \", stat_dim));",
      "1078:       std::pair<FeatureMapIterator, bool> const& f_insert_result = f_map.insert(",
      "1079:           FeatureMapIterator::value_type(feature_dim, BucketMap()));",
      "1080:       auto& b_map = f_insert_result.first->second;",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "1095:       OP_REQUIRES(context, stat_dim >= 0,",
      "1096:                   errors::InvalidArgument(",
      "1097:                       \"Stat dim, the sum of logits dim and hessian dim in \"",
      "1098:                       \"stats_summary_indices, should be >= 0, which was \",",
      "1099:                       stat_dim, \" at index \", idx));",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "1307:     const Tensor* gradients_t;",
      "1308:     OP_REQUIRES_OK(context, context->input(\"gradients\", &gradients_t));",
      "1309:     const auto gradients = gradients_t->matrix<float>();",
      "1311:     const Tensor* hessians_t;",
      "1312:     OP_REQUIRES_OK(context, context->input(\"hessians\", &hessians_t));",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "1332:     OP_REQUIRES(",
      "1333:         context, node_ids.size() == gradients.dimension(0),",
      "1334:         errors::InvalidArgument(",
      "1335:             \"node_ids size should match 0th dim of gradients. node ids \"",
      "1336:             \"size: \",",
      "1337:             node_ids.size(), \", gradients dim0: \", gradients.dimension(0)));",
      "",
      "---------------",
      "--- Hunk 7 ---",
      "[Context before]",
      "1376:     OP_REQUIRES_OK(context, context->input(\"gradients\", &gradients_t));",
      "1377:     const auto gradients = gradients_t->matrix<float>();",
      "1380:     const Tensor* hessians_t;",
      "1381:     OP_REQUIRES_OK(context, context->input(\"hessians\", &hessians_t));",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "1407:     OP_REQUIRES(",
      "1408:         context, node_ids.size() == gradients.dimension(0),",
      "1409:         errors::InvalidArgument(",
      "1410:             \"node_ids size should match 0th dim of gradients. node ids \"",
      "1411:             \"size: \",",
      "1412:             node_ids.size(), \", gradients dim0: \", gradients.dimension(0)));",
      "",
      "---------------",
      "--- Hunk 8 ---",
      "[Context before]",
      "1407:     for (int i = 0; i < batch_size; ++i) {",
      "1408:       const int32_t node = node_ids(i);",
      "1409:       for (int feature_dim = 0; feature_dim < feature_dims; ++feature_dim) {",
      "1410:         const int32_t feature_value = feature(i, feature_dim);",
      "1411:         const int32_t bucket =",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "1444:       OP_REQUIRES(context, node >= 0,",
      "1445:                   errors::InvalidArgument(",
      "1446:                       \"node_ids \", i, \"th entry should be >=0, got: \", node));",
      "",
      "---------------",
      "--- Hunk 9 ---",
      "[Context before]",
      "1612:     const int64_t stats_dims = logits_dims + hessians_dims;",
      "1613:     const int64_t num_sparse_entries = feature_indices_t->dim_size(0);",
      "1614:     const int32_t feature_dims = feature_shape(1);",
      "1618:     StatsPartitionMap stats_map;",
      "",
      "[Removed Lines]",
      "1615:     DCHECK_LE(num_sparse_entries, batch_size * feature_dims);",
      "",
      "[Added Lines]",
      "1653:     OP_REQUIRES(context, num_sparse_entries <= batch_size * feature_dims,",
      "1654:                 errors::InvalidArgument(",
      "1655:                     \"feature_indices dim0 should be <= gradients dim0 * \"",
      "1656:                     \"feature_shape[1]. features_indices dim0: \",",
      "1657:                     num_sparse_entries, \" gradients dim0: \", batch_size,",
      "1658:                     \", feature_shape[1]: \", feature_dims));",
      "",
      "---------------"
    ],
    "tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py||tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py": [
      "File: tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py -> tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "18: from tensorflow.python.framework import constant_op",
      "19: from tensorflow.python.framework import dtypes",
      "20: from tensorflow.python.framework import test_util",
      "21: from tensorflow.python.ops import array_ops",
      "22: from tensorflow.python.ops import boosted_trees_ops",
      "23: from tensorflow.python.ops import sparse_ops",
      "24: from tensorflow.python.platform import googletest",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "20: from tensorflow.python.framework import errors",
      "24: from tensorflow.python.ops import gen_boosted_trees_ops",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "1665:     \"\"\"Tests numeric precision.\"\"\"",
      "1666:     self._verify_precision(length=50000000)",
      "1669: class BestMultiDimFeatureSplitMultiClassV2Op(StatsOpsTest):",
      "1670:   \"\"\"Tests multi-class/multi-regression for best splits using V2 op.\"\"\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "1670:   def testBoostedTreesCalculateBestGainsPerFeatureSecurity(self):",
      "1671:     node_id_range = [1, 2]",
      "1672:     stats_summary_list = [[[[]]]]",
      "1673:     l1 = [1.0]",
      "1674:     l2 = [1.0]",
      "1675:     tree_complexity = [1.0]",
      "1676:     min_node_weight = [1.17]",
      "1677:     max_splits = 1",
      "1678:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
      "1679:       gen_boosted_trees_ops.boosted_trees_calculate_best_gains_per_feature(",
      "1680:           node_id_range=node_id_range,",
      "1681:           stats_summary_list=stats_summary_list,",
      "1682:           l1=l1,",
      "1683:           l2=l2,",
      "1684:           tree_complexity=tree_complexity,",
      "1685:           min_node_weight=min_node_weight,",
      "1686:           max_splits=max_splits)",
      "1688:   def testBoostedTreesCalculateBestFeatureSplitSecurity(self):",
      "1689:     node_id_range = [1, 2]",
      "1690:     stats_summary = [[[[]]]]",
      "1691:     split_type = 'equality'",
      "1692:     l1 = [1.0]",
      "1693:     l2 = [1.0]",
      "1694:     tree_complexity = [1.0]",
      "1695:     min_node_weight = [1.17]",
      "1696:     logits_dimension = 5",
      "1697:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
      "1698:       gen_boosted_trees_ops.boosted_trees_calculate_best_feature_split(",
      "1699:           node_id_range=node_id_range,",
      "1700:           stats_summary=stats_summary,",
      "1701:           l1=l1,",
      "1702:           l2=l2,",
      "1703:           tree_complexity=tree_complexity,",
      "1704:           min_node_weight=min_node_weight,",
      "1705:           logits_dimension=logits_dimension,",
      "1706:           split_type=split_type)",
      "1708:   def testBoostedTreesCalculateBestFeatureSplitSecurity2(self):",
      "1709:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
      "1710:       gen_boosted_trees_ops.boosted_trees_calculate_best_feature_split(",
      "1711:           node_id_range=[0, 8],",
      "1712:           stats_summary=[[[[1.0], [2.0], [3.0]]]],",
      "1713:           l1=[0.5],",
      "1714:           l2=[0.5],",
      "1715:           tree_complexity=[0.1],",
      "1716:           min_node_weight=[1.0],",
      "1717:           logits_dimension=8)",
      "1719:   def testBoostedTreesCalculateBestFeatureSplitV2Security(self):",
      "1720:     node_id_range = [1, 2]",
      "1721:     stats_summaries_list = [[[[[]]]]]",
      "1722:     split_types = ['inequality']",
      "1723:     candidate_feature_ids = [1, 2, 3, 4]",
      "1724:     l1 = [1.0]",
      "1725:     l2 = [1.0]",
      "1726:     tree_complexity = [1.0]",
      "1727:     min_node_weight = [1.17]",
      "1728:     logits_dimension = 5",
      "1729:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
      "1730:       gen_boosted_trees_ops.boosted_trees_calculate_best_feature_split_v2(",
      "1731:           node_id_range=node_id_range,",
      "1732:           stats_summaries_list=stats_summaries_list,",
      "1733:           split_types=split_types,",
      "1734:           candidate_feature_ids=candidate_feature_ids,",
      "1735:           l1=l1,",
      "1736:           l2=l2,",
      "1737:           tree_complexity=tree_complexity,",
      "1738:           min_node_weight=min_node_weight,",
      "1739:           logits_dimension=logits_dimension)",
      "1741:   def testBoostedTreesSparseCalculateBestFeatureSplitSecurity(self):",
      "1742:     node_id_range = []",
      "1743:     stats_summary_indices = [[]]",
      "1744:     stats_summary_values = [1.0]",
      "1745:     stats_summary_shape = [1, 1, 1, 1]",
      "1746:     l1 = [1.0]",
      "1747:     l2 = [1.0]",
      "1748:     tree_complexity = [0.5]",
      "1749:     min_node_weight = [1.0]",
      "1750:     logits_dimension = 3",
      "1751:     split_type = 'inequality'",
      "1752:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
      "1753:       gen_boosted_trees_ops.boosted_trees_sparse_calculate_best_feature_split(",
      "1754:           node_id_range=node_id_range,",
      "1755:           stats_summary_indices=stats_summary_indices,",
      "1756:           stats_summary_values=stats_summary_values,",
      "1757:           stats_summary_shape=stats_summary_shape,",
      "1758:           l1=l1,",
      "1759:           l2=l2,",
      "1760:           tree_complexity=tree_complexity,",
      "1761:           min_node_weight=min_node_weight,",
      "1762:           logits_dimension=logits_dimension,",
      "1763:           split_type=split_type)",
      "1765:   def testBoostedTreesSparseCalculateBestFeatureSplitSecurity2(self):",
      "1766:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
      "1767:       gen_boosted_trees_ops.boosted_trees_sparse_calculate_best_feature_split(",
      "1768:           node_id_range=[0, 1],",
      "1769:           stats_summary_indices=[[0, -1, -1, -1], [1, 0, -1, 0], [1, 0, 0, -1]],",
      "1770:           stats_summary_values=[0.1, 0.2, 0.3],",
      "1771:           stats_summary_shape=[1, 1, 1, 1],",
      "1772:           l1=[0.5],",
      "1773:           l2=[0.5],",
      "1774:           tree_complexity=[0.1],",
      "1775:           min_node_weight=[1.0],",
      "1776:           logits_dimension=1)",
      "1778:   def testBoostedTreesMakeStatsSummarySecurity(self):",
      "1779:     node_ids = [1, 2]",
      "1780:     gradients = [[]]",
      "1781:     hessians = [[0.2], [0.1]]",
      "1782:     bucketized_features_list = [[1], [2]]",
      "1783:     max_splits = 3",
      "1784:     num_buckets = 3",
      "1785:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
      "1786:       gen_boosted_trees_ops.boosted_trees_make_stats_summary(",
      "1787:           node_ids=node_ids,",
      "1788:           gradients=gradients,",
      "1789:           hessians=hessians,",
      "1790:           bucketized_features_list=bucketized_features_list,",
      "1791:           max_splits=max_splits,",
      "1792:           num_buckets=num_buckets)",
      "1794:   def testBoostedTreesMakeStatsSummarySecurity2(self):",
      "1795:     node_ids = [1, 2, 3]",
      "1796:     gradients = [[0.1], [0.2]]",
      "1797:     hessians = [[0.2], [0.1]]",
      "1798:     bucketized_features_list = [[1], [2]]",
      "1799:     max_splits = 3",
      "1800:     num_buckets = 3",
      "1801:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
      "1802:       gen_boosted_trees_ops.boosted_trees_make_stats_summary(",
      "1803:           node_ids=node_ids,",
      "1804:           gradients=gradients,",
      "1805:           hessians=hessians,",
      "1806:           bucketized_features_list=bucketized_features_list,",
      "1807:           max_splits=max_splits,",
      "1808:           num_buckets=num_buckets)",
      "1810:   def testBoostedTreesAggregateStatsSecurity(self):",
      "1811:     node_ids = [1, 2]",
      "1812:     gradients = [[]]",
      "1813:     hessians = [[100.0]]",
      "1814:     feature = [[0, 0, 0]]",
      "1815:     max_splits = 100",
      "1816:     num_buckets = 100",
      "1817:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
      "1818:       gen_boosted_trees_ops.boosted_trees_aggregate_stats(",
      "1819:           node_ids=node_ids,",
      "1820:           gradients=gradients,",
      "1821:           hessians=hessians,",
      "1822:           feature=feature,",
      "1823:           max_splits=max_splits,",
      "1824:           num_buckets=num_buckets)",
      "1826:   def testBoostedTreesAggregateStatsSecurity2(self):",
      "1827:     node_ids = [-10]",
      "1828:     gradients = [[0.0, 0.0]]",
      "1829:     hessians = [[100.0]]",
      "1830:     feature = [[0, 0, 0]]",
      "1831:     max_splits = 100",
      "1832:     num_buckets = 100",
      "1833:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
      "1834:       self.evaluate(",
      "1835:           gen_boosted_trees_ops.boosted_trees_aggregate_stats(",
      "1836:               node_ids=node_ids,",
      "1837:               gradients=gradients,",
      "1838:               hessians=hessians,",
      "1839:               feature=feature,",
      "1840:               max_splits=max_splits,",
      "1841:               num_buckets=num_buckets))",
      "1843:   def testBoostedTreesSparseAggregateStatsSecurity(self):",
      "1844:     node_ids = []",
      "1845:     gradients = [[1.0]]",
      "1846:     hessians = [[100.0]]",
      "1847:     feature_indices = [[0, 0, 0]]",
      "1848:     feature_values = [0, 0, 0]",
      "1849:     feature_shape = [0, 0, 0]",
      "1850:     max_splits = 100",
      "1851:     num_buckets = 100",
      "1852:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
      "1853:       gen_boosted_trees_ops.boosted_trees_sparse_aggregate_stats(",
      "1854:           node_ids=node_ids,",
      "1855:           gradients=gradients,",
      "1856:           hessians=hessians,",
      "1857:           feature_indices=feature_indices,",
      "1858:           feature_values=feature_values,",
      "1859:           feature_shape=feature_shape,",
      "1860:           max_splits=max_splits,",
      "1861:           num_buckets=num_buckets)",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "94b0a6571353b2a2008527a94ea3f1346e6dd420",
      "candidate_info": {
        "commit_hash": "94b0a6571353b2a2008527a94ea3f1346e6dd420",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/94b0a6571353b2a2008527a94ea3f1346e6dd420",
        "files": [
          "tensorflow/core/kernels/boosted_trees/stats_ops.cc",
          "tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py"
        ],
        "message": "Fixing security fixes in boosted trees ops\n\nPiperOrigin-RevId: 405669548\nChange-Id: Iae224d240d1779bcc02405c2fff99785644fbd0d",
        "before_after_code_files": [
          "tensorflow/core/kernels/boosted_trees/stats_ops.cc||tensorflow/core/kernels/boosted_trees/stats_ops.cc",
          "tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py||tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/boosted_trees/stats_ops.cc||tensorflow/core/kernels/boosted_trees/stats_ops.cc",
            "tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py||tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py"
          ],
          "candidate": [
            "tensorflow/core/kernels/boosted_trees/stats_ops.cc||tensorflow/core/kernels/boosted_trees/stats_ops.cc",
            "tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py||tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/boosted_trees/stats_ops.cc||tensorflow/core/kernels/boosted_trees/stats_ops.cc": [
          "File: tensorflow/core/kernels/boosted_trees/stats_ops.cc -> tensorflow/core/kernels/boosted_trees/stats_ops.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "72:                                                 &stats_summary_list));",
          "73:     const int64 num_buckets = stats_summary_list[0].dim_size(1);",
          "76:     std::vector<TTypes<float, 3>::ConstTensor> stats_summary;",
          "77:     stats_summary.reserve(stats_summary_list.size());",
          "78:     for (const auto& tensor : stats_summary_list) {",
          "",
          "[Removed Lines]",
          "75:     DCHECK_EQ(stats_summary_list[0].dim_size(2), 2);",
          "",
          "[Added Lines]",
          "75:     OP_REQUIRES(context, stats_summary_list[0].dim_size(2) == 2,",
          "76:                 errors::InvalidArgument(\"stats_summary_list[0] must have \"",
          "77:                                         \"exactly 2 dimensions, obtained: \",",
          "78:                                         stats_summary_list[0].dim_size(2)));",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "275:     const int32 num_buckets = stats_summary_t->dim_size(2) - 1;",
          "276:     const int32 logits_dim = logits_dim_;",
          "277:     const int32 hessian_dim = stats_summary_t->dim_size(3) - logits_dim;",
          "281:     const Tensor* l1_t;",
          "282:     OP_REQUIRES_OK(context, context->input(\"l1\", &l1_t));",
          "",
          "[Removed Lines]",
          "278:     DCHECK_GT(hessian_dim, 0);",
          "279:     DCHECK_LE(hessian_dim, logits_dim * logits_dim);",
          "",
          "[Added Lines]",
          "281:     const int32_t hessian_dim = stats_summary_t->dim_size(3) - logits_dim;",
          "282:     OP_REQUIRES(context, hessian_dim > 0,",
          "283:                 errors::InvalidArgument(\"hessian dim should be < 0, got \",",
          "284:                                         hessian_dim));",
          "285:     OP_REQUIRES(context, hessian_dim <= logits_dim * logits_dim,",
          "286:                 errors::InvalidArgument(",
          "287:                     \"hessian dim should be <= \", logits_dim * logits_dim,",
          "288:                     \" but got: \", hessian_dim));",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "621:     const int32 num_buckets = stats_summaries_list[0].dim_size(2) - 1;",
          "622:     const int32 logits_dim = logits_dim_;",
          "623:     const int32 hessian_dim = stats_summaries_list[0].dim_size(3) - logits_dim;",
          "",
          "[Removed Lines]",
          "624:     DCHECK_GT(hessian_dim, 0);",
          "625:     DCHECK_LE(hessian_dim, logits_dim * logits_dim);",
          "",
          "[Added Lines]",
          "633:    OP_REQUIRES(context, hessian_dim > 0,",
          "634:                 errors::InvalidArgument(\"hessian dim should be < 0, got \",",
          "635:                                         hessian_dim));",
          "636:     OP_REQUIRES(context, hessian_dim <= logits_dim * logits_dim,",
          "637:                 errors::InvalidArgument(",
          "638:                     \"hessian dim should be <= \", logits_dim * logits_dim,",
          "639:                     \" but got: \", hessian_dim));",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "997:     const Tensor* node_id_range_t;",
          "998:     OP_REQUIRES_OK(context, context->input(\"node_id_range\", &node_id_range_t));",
          "999:     const auto node_id_range = node_id_range_t->vec<int32>();",
          "1000:     const int32 node_id_first = node_id_range(0);  // inclusive",
          "1001:     const int32 node_id_last = node_id_range(1);   // exclusive",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1014:     OP_REQUIRES(",
          "1015:         context, node_id_range.size() == 2,",
          "1016:         errors::InvalidArgument(\"node_id_range should have 2 entries, got: \",",
          "1017:                                 node_id_range.size()));",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "1070:                       \"dims, the last value in stats_summary_shape, which was \",",
          "1071:                       stats_dims, \". At index (\", idx,",
          "1072:                       \", 4), stats_summary_indices contains value \", stat_dim));",
          "1073:       std::pair<FeatureMapIterator, bool> const& f_insert_result = f_map.insert(",
          "1074:           FeatureMapIterator::value_type(feature_dim, BucketMap()));",
          "1075:       auto& b_map = f_insert_result.first->second;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1091:       OP_REQUIRES(context, stat_dim >= 0,",
          "1092:                   errors::InvalidArgument(",
          "1093:                       \"Stat dim, the sum of logits dim and hessian dim in \"",
          "1094:                       \"stats_summary_indices, should be >= 0, which was \",",
          "1095:                       stat_dim, \" at index \", idx));",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "1302:     const Tensor* gradients_t;",
          "1303:     OP_REQUIRES_OK(context, context->input(\"gradients\", &gradients_t));",
          "1304:     const auto gradients = gradients_t->matrix<float>();",
          "1306:     const Tensor* hessians_t;",
          "1307:     OP_REQUIRES_OK(context, context->input(\"hessians\", &hessians_t));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1328:     OP_REQUIRES(",
          "1329:         context, node_ids.size() == gradients.dimension(0),",
          "1330:         errors::InvalidArgument(",
          "1331:             \"node_ids size should match 0th dim of gradients. node ids \"",
          "1332:             \"size: \",",
          "1333:             node_ids.size(), \", gradients dim0: \", gradients.dimension(0)));",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "1371:     OP_REQUIRES_OK(context, context->input(\"gradients\", &gradients_t));",
          "1372:     const auto gradients = gradients_t->matrix<float>();",
          "1375:     const Tensor* hessians_t;",
          "1376:     OP_REQUIRES_OK(context, context->input(\"hessians\", &hessians_t));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1403:     OP_REQUIRES(",
          "1404:         context, node_ids.size() == gradients.dimension(0),",
          "1405:         errors::InvalidArgument(",
          "1406:             \"node_ids size should match 0th dim of gradients. node ids \"",
          "1407:             \"size: \",",
          "1408:             node_ids.size(), \", gradients dim0: \", gradients.dimension(0)));",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "1402:     for (int i = 0; i < batch_size; ++i) {",
          "1403:       const int32 node = node_ids(i);",
          "1404:       for (int feature_dim = 0; feature_dim < feature_dims; ++feature_dim) {",
          "1405:         const int32 feature_value = feature(i, feature_dim);",
          "1406:         const int32 bucket =",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1440:       OP_REQUIRES(context, node >= 0,",
          "1441:                   errors::InvalidArgument(",
          "1442:                       \"node_ids \", i, \"th entry should be >=0, got: \", node));",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "1608:     const int64 stats_dims = logits_dims + hessians_dims;",
          "1609:     const int64 num_sparse_entries = feature_indices_t->dim_size(0);",
          "1610:     const int32 feature_dims = feature_shape(1);",
          "1614:     StatsPartitionMap stats_map;",
          "",
          "[Removed Lines]",
          "1611:     DCHECK_LE(num_sparse_entries, batch_size * feature_dims);",
          "",
          "[Added Lines]",
          "1650:     OP_REQUIRES(context, num_sparse_entries <= batch_size * feature_dims,",
          "1651:                 errors::InvalidArgument(",
          "1652:                     \"feature_indices dim0 should be <= gradients dim0 * \"",
          "1653:                     \"feature_shape[1]. features_indices dim0: \",",
          "1654:                     num_sparse_entries, \" gradients dim0: \", batch_size,",
          "1655:                     \", feature_shape[1]: \", feature_dims));",
          "",
          "---------------"
        ],
        "tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py||tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py": [
          "File: tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py -> tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: from tensorflow.python.framework import constant_op",
          "23: from tensorflow.python.framework import dtypes",
          "24: from tensorflow.python.framework import test_util",
          "25: from tensorflow.python.ops import array_ops",
          "26: from tensorflow.python.ops import boosted_trees_ops",
          "27: from tensorflow.python.ops import sparse_ops",
          "28: from tensorflow.python.platform import googletest",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "24: from tensorflow.python.framework import errors",
          "28: from tensorflow.python.ops import gen_boosted_trees_ops",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1669:     \"\"\"Tests numeric precision.\"\"\"",
          "1670:     self._verify_precision(length=50000000)",
          "1673: class BestMultiDimFeatureSplitMultiClassV2Op(StatsOpsTest):",
          "1674:   \"\"\"Tests multi-class/multi-regression for best splits using V2 op.\"\"\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1674:   def testBoostedTreesCalculateBestGainsPerFeatureSecurity(self):",
          "1675:     node_id_range = [1, 2]",
          "1676:     stats_summary_list = [[[[]]]]",
          "1677:     l1 = [1.0]",
          "1678:     l2 = [1.0]",
          "1679:     tree_complexity = [1.0]",
          "1680:     min_node_weight = [1.17]",
          "1681:     max_splits = 1",
          "1682:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1683:       gen_boosted_trees_ops.boosted_trees_calculate_best_gains_per_feature(",
          "1684:           node_id_range=node_id_range,",
          "1685:           stats_summary_list=stats_summary_list,",
          "1686:           l1=l1,",
          "1687:           l2=l2,",
          "1688:           tree_complexity=tree_complexity,",
          "1689:           min_node_weight=min_node_weight,",
          "1690:           max_splits=max_splits)",
          "1692:   def testBoostedTreesCalculateBestFeatureSplitSecurity(self):",
          "1693:     node_id_range = [1, 2]",
          "1694:     stats_summary = [[[[]]]]",
          "1695:     split_type = 'equality'",
          "1696:     l1 = [1.0]",
          "1697:     l2 = [1.0]",
          "1698:     tree_complexity = [1.0]",
          "1699:     min_node_weight = [1.17]",
          "1700:     logits_dimension = 5",
          "1701:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1702:       gen_boosted_trees_ops.boosted_trees_calculate_best_feature_split(",
          "1703:           node_id_range=node_id_range,",
          "1704:           stats_summary=stats_summary,",
          "1705:           l1=l1,",
          "1706:           l2=l2,",
          "1707:           tree_complexity=tree_complexity,",
          "1708:           min_node_weight=min_node_weight,",
          "1709:           logits_dimension=logits_dimension,",
          "1710:           split_type=split_type)",
          "1712:   def testBoostedTreesCalculateBestFeatureSplitSecurity2(self):",
          "1713:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1714:       gen_boosted_trees_ops.boosted_trees_calculate_best_feature_split(",
          "1715:           node_id_range=[0, 8],",
          "1716:           stats_summary=[[[[1.0], [2.0], [3.0]]]],",
          "1717:           l1=[0.5],",
          "1718:           l2=[0.5],",
          "1719:           tree_complexity=[0.1],",
          "1720:           min_node_weight=[1.0],",
          "1721:           logits_dimension=8)",
          "1723:   def testBoostedTreesCalculateBestFeatureSplitV2Security(self):",
          "1724:     node_id_range = [1, 2]",
          "1725:     stats_summaries_list = [[[[[]]]]]",
          "1726:     split_types = ['inequality']",
          "1727:     candidate_feature_ids = [1, 2, 3, 4]",
          "1728:     l1 = [1.0]",
          "1729:     l2 = [1.0]",
          "1730:     tree_complexity = [1.0]",
          "1731:     min_node_weight = [1.17]",
          "1732:     logits_dimension = 5",
          "1733:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1734:       gen_boosted_trees_ops.boosted_trees_calculate_best_feature_split_v2(",
          "1735:           node_id_range=node_id_range,",
          "1736:           stats_summaries_list=stats_summaries_list,",
          "1737:           split_types=split_types,",
          "1738:           candidate_feature_ids=candidate_feature_ids,",
          "1739:           l1=l1,",
          "1740:           l2=l2,",
          "1741:           tree_complexity=tree_complexity,",
          "1742:           min_node_weight=min_node_weight,",
          "1743:           logits_dimension=logits_dimension)",
          "1745:   def testBoostedTreesSparseCalculateBestFeatureSplitSecurity(self):",
          "1746:     node_id_range = []",
          "1747:     stats_summary_indices = [[]]",
          "1748:     stats_summary_values = [1.0]",
          "1749:     stats_summary_shape = [1, 1, 1, 1]",
          "1750:     l1 = [1.0]",
          "1751:     l2 = [1.0]",
          "1752:     tree_complexity = [0.5]",
          "1753:     min_node_weight = [1.0]",
          "1754:     logits_dimension = 3",
          "1755:     split_type = 'inequality'",
          "1756:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1757:       gen_boosted_trees_ops.boosted_trees_sparse_calculate_best_feature_split(",
          "1758:           node_id_range=node_id_range,",
          "1759:           stats_summary_indices=stats_summary_indices,",
          "1760:           stats_summary_values=stats_summary_values,",
          "1761:           stats_summary_shape=stats_summary_shape,",
          "1762:           l1=l1,",
          "1763:           l2=l2,",
          "1764:           tree_complexity=tree_complexity,",
          "1765:           min_node_weight=min_node_weight,",
          "1766:           logits_dimension=logits_dimension,",
          "1767:           split_type=split_type)",
          "1769:   def testBoostedTreesSparseCalculateBestFeatureSplitSecurity2(self):",
          "1770:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1771:       gen_boosted_trees_ops.boosted_trees_sparse_calculate_best_feature_split(",
          "1772:           node_id_range=[0, 1],",
          "1773:           stats_summary_indices=[[0, -1, -1, -1], [1, 0, -1, 0], [1, 0, 0, -1]],",
          "1774:           stats_summary_values=[0.1, 0.2, 0.3],",
          "1775:           stats_summary_shape=[1, 1, 1, 1],",
          "1776:           l1=[0.5],",
          "1777:           l2=[0.5],",
          "1778:           tree_complexity=[0.1],",
          "1779:           min_node_weight=[1.0],",
          "1780:           logits_dimension=1)",
          "1782:   def testBoostedTreesMakeStatsSummarySecurity(self):",
          "1783:     node_ids = [1, 2]",
          "1784:     gradients = [[]]",
          "1785:     hessians = [[0.2], [0.1]]",
          "1786:     bucketized_features_list = [[1], [2]]",
          "1787:     max_splits = 3",
          "1788:     num_buckets = 3",
          "1789:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1790:       gen_boosted_trees_ops.boosted_trees_make_stats_summary(",
          "1791:           node_ids=node_ids,",
          "1792:           gradients=gradients,",
          "1793:           hessians=hessians,",
          "1794:           bucketized_features_list=bucketized_features_list,",
          "1795:           max_splits=max_splits,",
          "1796:           num_buckets=num_buckets)",
          "1798:   def testBoostedTreesMakeStatsSummarySecurity2(self):",
          "1799:     node_ids = [1, 2, 3]",
          "1800:     gradients = [[0.1], [0.2]]",
          "1801:     hessians = [[0.2], [0.1]]",
          "1802:     bucketized_features_list = [[1], [2]]",
          "1803:     max_splits = 3",
          "1804:     num_buckets = 3",
          "1805:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1806:       gen_boosted_trees_ops.boosted_trees_make_stats_summary(",
          "1807:           node_ids=node_ids,",
          "1808:           gradients=gradients,",
          "1809:           hessians=hessians,",
          "1810:           bucketized_features_list=bucketized_features_list,",
          "1811:           max_splits=max_splits,",
          "1812:           num_buckets=num_buckets)",
          "1814:   def testBoostedTreesAggregateStatsSecurity(self):",
          "1815:     node_ids = [1, 2]",
          "1816:     gradients = [[]]",
          "1817:     hessians = [[100.0]]",
          "1818:     feature = [[0, 0, 0]]",
          "1819:     max_splits = 100",
          "1820:     num_buckets = 100",
          "1821:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1822:       gen_boosted_trees_ops.boosted_trees_aggregate_stats(",
          "1823:           node_ids=node_ids,",
          "1824:           gradients=gradients,",
          "1825:           hessians=hessians,",
          "1826:           feature=feature,",
          "1827:           max_splits=max_splits,",
          "1828:           num_buckets=num_buckets)",
          "1830:   def testBoostedTreesAggregateStatsSecurity2(self):",
          "1831:     node_ids = [-10]",
          "1832:     gradients = [[0.0, 0.0]]",
          "1833:     hessians = [[100.0]]",
          "1834:     feature = [[0, 0, 0]]",
          "1835:     max_splits = 100",
          "1836:     num_buckets = 100",
          "1837:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1838:       self.evaluate(",
          "1839:           gen_boosted_trees_ops.boosted_trees_aggregate_stats(",
          "1840:               node_ids=node_ids,",
          "1841:               gradients=gradients,",
          "1842:               hessians=hessians,",
          "1843:               feature=feature,",
          "1844:               max_splits=max_splits,",
          "1845:               num_buckets=num_buckets))",
          "1847:   def testBoostedTreesSparseAggregateStatsSecurity(self):",
          "1848:     node_ids = []",
          "1849:     gradients = [[1.0]]",
          "1850:     hessians = [[100.0]]",
          "1851:     feature_indices = [[0, 0, 0]]",
          "1852:     feature_values = [0, 0, 0]",
          "1853:     feature_shape = [0, 0, 0]",
          "1854:     max_splits = 100",
          "1855:     num_buckets = 100",
          "1856:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1857:       gen_boosted_trees_ops.boosted_trees_sparse_aggregate_stats(",
          "1858:           node_ids=node_ids,",
          "1859:           gradients=gradients,",
          "1860:           hessians=hessians,",
          "1861:           feature_indices=feature_indices,",
          "1862:           feature_values=feature_values,",
          "1863:           feature_shape=feature_shape,",
          "1864:           max_splits=max_splits,",
          "1865:           num_buckets=num_buckets)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "884fcd91c792c95e28a4b0c4a4f0f930699746e7",
      "candidate_info": {
        "commit_hash": "884fcd91c792c95e28a4b0c4a4f0f930699746e7",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/884fcd91c792c95e28a4b0c4a4f0f930699746e7",
        "files": [
          "tensorflow/core/kernels/boosted_trees/stats_ops.cc",
          "tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py"
        ],
        "message": "Fixing security fixes in boosted trees ops\n\nPiperOrigin-RevId: 405669548\nChange-Id: Iae224d240d1779bcc02405c2fff99785644fbd0d",
        "before_after_code_files": [
          "tensorflow/core/kernels/boosted_trees/stats_ops.cc||tensorflow/core/kernels/boosted_trees/stats_ops.cc",
          "tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py||tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/boosted_trees/stats_ops.cc||tensorflow/core/kernels/boosted_trees/stats_ops.cc",
            "tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py||tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py"
          ],
          "candidate": [
            "tensorflow/core/kernels/boosted_trees/stats_ops.cc||tensorflow/core/kernels/boosted_trees/stats_ops.cc",
            "tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py||tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/boosted_trees/stats_ops.cc||tensorflow/core/kernels/boosted_trees/stats_ops.cc": [
          "File: tensorflow/core/kernels/boosted_trees/stats_ops.cc -> tensorflow/core/kernels/boosted_trees/stats_ops.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "72:                                                 &stats_summary_list));",
          "73:     const int64_t num_buckets = stats_summary_list[0].dim_size(1);",
          "76:     std::vector<TTypes<float, 3>::ConstTensor> stats_summary;",
          "77:     stats_summary.reserve(stats_summary_list.size());",
          "78:     for (const auto& tensor : stats_summary_list) {",
          "",
          "[Removed Lines]",
          "75:     DCHECK_EQ(stats_summary_list[0].dim_size(2), 2);",
          "",
          "[Added Lines]",
          "75:     OP_REQUIRES(context, stats_summary_list[0].dim_size(2) == 2,",
          "76:                 errors::InvalidArgument(\"stats_summary_list[0] must have \"",
          "77:                                         \"exactly 2 dimensions, obtained: \",",
          "78:                                         stats_summary_list[0].dim_size(2)));",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "275:     const int32_t num_buckets = stats_summary_t->dim_size(2) - 1;",
          "276:     const int32_t logits_dim = logits_dim_;",
          "277:     const int32_t hessian_dim = stats_summary_t->dim_size(3) - logits_dim;",
          "281:     const Tensor* l1_t;",
          "282:     OP_REQUIRES_OK(context, context->input(\"l1\", &l1_t));",
          "",
          "[Removed Lines]",
          "278:     DCHECK_GT(hessian_dim, 0);",
          "279:     DCHECK_LE(hessian_dim, logits_dim * logits_dim);",
          "",
          "[Added Lines]",
          "281:     OP_REQUIRES(context, hessian_dim > 0,",
          "282:                 errors::InvalidArgument(\"hessian dim should be < 0, got \",",
          "283:                                         hessian_dim));",
          "284:     OP_REQUIRES(context, hessian_dim <= logits_dim * logits_dim,",
          "285:                 errors::InvalidArgument(",
          "286:                     \"hessian dim should be <= \", logits_dim * logits_dim,",
          "287:                     \" but got: \", hessian_dim));",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "624:     const int32_t logits_dim = logits_dim_;",
          "625:     const int32_t hessian_dim =",
          "626:         stats_summaries_list[0].dim_size(3) - logits_dim;",
          "",
          "[Removed Lines]",
          "627:     DCHECK_GT(hessian_dim, 0);",
          "628:     DCHECK_LE(hessian_dim, logits_dim * logits_dim);",
          "",
          "[Added Lines]",
          "635:     OP_REQUIRES(context, hessian_dim > 0,",
          "636:                 errors::InvalidArgument(\"hessian dim should be < 0, got \",",
          "637:                                         hessian_dim));",
          "638:     OP_REQUIRES(context, hessian_dim <= logits_dim * logits_dim,",
          "639:                 errors::InvalidArgument(",
          "640:                     \"hessian dim should be <= \", logits_dim * logits_dim,",
          "641:                     \" but got: \", hessian_dim));",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "1002:     const Tensor* node_id_range_t;",
          "1003:     OP_REQUIRES_OK(context, context->input(\"node_id_range\", &node_id_range_t));",
          "1004:     const auto node_id_range = node_id_range_t->vec<int32>();",
          "1005:     const int32_t node_id_first = node_id_range(0);  // inclusive",
          "1006:     const int32_t node_id_last = node_id_range(1);   // exclusive",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1018:     OP_REQUIRES(",
          "1019:         context, node_id_range.size() == 2,",
          "1020:         errors::InvalidArgument(\"node_id_range should have 2 entries, got: \",",
          "1021:                                 node_id_range.size()));",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "1075:                       \"dims, the last value in stats_summary_shape, which was \",",
          "1076:                       stats_dims, \". At index (\", idx,",
          "1077:                       \", 4), stats_summary_indices contains value \", stat_dim));",
          "1078:       std::pair<FeatureMapIterator, bool> const& f_insert_result = f_map.insert(",
          "1079:           FeatureMapIterator::value_type(feature_dim, BucketMap()));",
          "1080:       auto& b_map = f_insert_result.first->second;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1095:       OP_REQUIRES(context, stat_dim >= 0,",
          "1096:                   errors::InvalidArgument(",
          "1097:                       \"Stat dim, the sum of logits dim and hessian dim in \"",
          "1098:                       \"stats_summary_indices, should be >= 0, which was \",",
          "1099:                       stat_dim, \" at index \", idx));",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "1307:     const Tensor* gradients_t;",
          "1308:     OP_REQUIRES_OK(context, context->input(\"gradients\", &gradients_t));",
          "1309:     const auto gradients = gradients_t->matrix<float>();",
          "1311:     const Tensor* hessians_t;",
          "1312:     OP_REQUIRES_OK(context, context->input(\"hessians\", &hessians_t));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1332:     OP_REQUIRES(",
          "1333:         context, node_ids.size() == gradients.dimension(0),",
          "1334:         errors::InvalidArgument(",
          "1335:             \"node_ids size should match 0th dim of gradients. node ids \"",
          "1336:             \"size: \",",
          "1337:             node_ids.size(), \", gradients dim0: \", gradients.dimension(0)));",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "1376:     OP_REQUIRES_OK(context, context->input(\"gradients\", &gradients_t));",
          "1377:     const auto gradients = gradients_t->matrix<float>();",
          "1380:     const Tensor* hessians_t;",
          "1381:     OP_REQUIRES_OK(context, context->input(\"hessians\", &hessians_t));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1407:     OP_REQUIRES(",
          "1408:         context, node_ids.size() == gradients.dimension(0),",
          "1409:         errors::InvalidArgument(",
          "1410:             \"node_ids size should match 0th dim of gradients. node ids \"",
          "1411:             \"size: \",",
          "1412:             node_ids.size(), \", gradients dim0: \", gradients.dimension(0)));",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "1407:     for (int i = 0; i < batch_size; ++i) {",
          "1408:       const int32_t node = node_ids(i);",
          "1409:       for (int feature_dim = 0; feature_dim < feature_dims; ++feature_dim) {",
          "1410:         const int32_t feature_value = feature(i, feature_dim);",
          "1411:         const int32_t bucket =",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1444:       OP_REQUIRES(context, node >= 0,",
          "1445:                   errors::InvalidArgument(",
          "1446:                       \"node_ids \", i, \"th entry should be >=0, got: \", node));",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "1612:     const int64_t stats_dims = logits_dims + hessians_dims;",
          "1613:     const int64_t num_sparse_entries = feature_indices_t->dim_size(0);",
          "1614:     const int32_t feature_dims = feature_shape(1);",
          "1618:     StatsPartitionMap stats_map;",
          "",
          "[Removed Lines]",
          "1615:     DCHECK_LE(num_sparse_entries, batch_size * feature_dims);",
          "",
          "[Added Lines]",
          "1653:     OP_REQUIRES(context, num_sparse_entries <= batch_size * feature_dims,",
          "1654:                 errors::InvalidArgument(",
          "1655:                     \"feature_indices dim0 should be <= gradients dim0 * \"",
          "1656:                     \"feature_shape[1]. features_indices dim0: \",",
          "1657:                     num_sparse_entries, \" gradients dim0: \", batch_size,",
          "1658:                     \", feature_shape[1]: \", feature_dims));",
          "",
          "---------------"
        ],
        "tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py||tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py": [
          "File: tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py -> tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: from tensorflow.python.framework import constant_op",
          "23: from tensorflow.python.framework import dtypes",
          "24: from tensorflow.python.framework import test_util",
          "25: from tensorflow.python.ops import array_ops",
          "26: from tensorflow.python.ops import boosted_trees_ops",
          "27: from tensorflow.python.ops import sparse_ops",
          "28: from tensorflow.python.platform import googletest",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "24: from tensorflow.python.framework import errors",
          "28: from tensorflow.python.ops import gen_boosted_trees_ops",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1669:     \"\"\"Tests numeric precision.\"\"\"",
          "1670:     self._verify_precision(length=50000000)",
          "1673: class BestMultiDimFeatureSplitMultiClassV2Op(StatsOpsTest):",
          "1674:   \"\"\"Tests multi-class/multi-regression for best splits using V2 op.\"\"\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1674:   def testBoostedTreesCalculateBestGainsPerFeatureSecurity(self):",
          "1675:     node_id_range = [1, 2]",
          "1676:     stats_summary_list = [[[[]]]]",
          "1677:     l1 = [1.0]",
          "1678:     l2 = [1.0]",
          "1679:     tree_complexity = [1.0]",
          "1680:     min_node_weight = [1.17]",
          "1681:     max_splits = 1",
          "1682:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1683:       gen_boosted_trees_ops.boosted_trees_calculate_best_gains_per_feature(",
          "1684:           node_id_range=node_id_range,",
          "1685:           stats_summary_list=stats_summary_list,",
          "1686:           l1=l1,",
          "1687:           l2=l2,",
          "1688:           tree_complexity=tree_complexity,",
          "1689:           min_node_weight=min_node_weight,",
          "1690:           max_splits=max_splits)",
          "1692:   def testBoostedTreesCalculateBestFeatureSplitSecurity(self):",
          "1693:     node_id_range = [1, 2]",
          "1694:     stats_summary = [[[[]]]]",
          "1695:     split_type = 'equality'",
          "1696:     l1 = [1.0]",
          "1697:     l2 = [1.0]",
          "1698:     tree_complexity = [1.0]",
          "1699:     min_node_weight = [1.17]",
          "1700:     logits_dimension = 5",
          "1701:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1702:       gen_boosted_trees_ops.boosted_trees_calculate_best_feature_split(",
          "1703:           node_id_range=node_id_range,",
          "1704:           stats_summary=stats_summary,",
          "1705:           l1=l1,",
          "1706:           l2=l2,",
          "1707:           tree_complexity=tree_complexity,",
          "1708:           min_node_weight=min_node_weight,",
          "1709:           logits_dimension=logits_dimension,",
          "1710:           split_type=split_type)",
          "1712:   def testBoostedTreesCalculateBestFeatureSplitSecurity2(self):",
          "1713:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1714:       gen_boosted_trees_ops.boosted_trees_calculate_best_feature_split(",
          "1715:           node_id_range=[0, 8],",
          "1716:           stats_summary=[[[[1.0], [2.0], [3.0]]]],",
          "1717:           l1=[0.5],",
          "1718:           l2=[0.5],",
          "1719:           tree_complexity=[0.1],",
          "1720:           min_node_weight=[1.0],",
          "1721:           logits_dimension=8)",
          "1723:   def testBoostedTreesCalculateBestFeatureSplitV2Security(self):",
          "1724:     node_id_range = [1, 2]",
          "1725:     stats_summaries_list = [[[[[]]]]]",
          "1726:     split_types = ['inequality']",
          "1727:     candidate_feature_ids = [1, 2, 3, 4]",
          "1728:     l1 = [1.0]",
          "1729:     l2 = [1.0]",
          "1730:     tree_complexity = [1.0]",
          "1731:     min_node_weight = [1.17]",
          "1732:     logits_dimension = 5",
          "1733:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1734:       gen_boosted_trees_ops.boosted_trees_calculate_best_feature_split_v2(",
          "1735:           node_id_range=node_id_range,",
          "1736:           stats_summaries_list=stats_summaries_list,",
          "1737:           split_types=split_types,",
          "1738:           candidate_feature_ids=candidate_feature_ids,",
          "1739:           l1=l1,",
          "1740:           l2=l2,",
          "1741:           tree_complexity=tree_complexity,",
          "1742:           min_node_weight=min_node_weight,",
          "1743:           logits_dimension=logits_dimension)",
          "1745:   def testBoostedTreesSparseCalculateBestFeatureSplitSecurity(self):",
          "1746:     node_id_range = []",
          "1747:     stats_summary_indices = [[]]",
          "1748:     stats_summary_values = [1.0]",
          "1749:     stats_summary_shape = [1, 1, 1, 1]",
          "1750:     l1 = [1.0]",
          "1751:     l2 = [1.0]",
          "1752:     tree_complexity = [0.5]",
          "1753:     min_node_weight = [1.0]",
          "1754:     logits_dimension = 3",
          "1755:     split_type = 'inequality'",
          "1756:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1757:       gen_boosted_trees_ops.boosted_trees_sparse_calculate_best_feature_split(",
          "1758:           node_id_range=node_id_range,",
          "1759:           stats_summary_indices=stats_summary_indices,",
          "1760:           stats_summary_values=stats_summary_values,",
          "1761:           stats_summary_shape=stats_summary_shape,",
          "1762:           l1=l1,",
          "1763:           l2=l2,",
          "1764:           tree_complexity=tree_complexity,",
          "1765:           min_node_weight=min_node_weight,",
          "1766:           logits_dimension=logits_dimension,",
          "1767:           split_type=split_type)",
          "1769:   def testBoostedTreesSparseCalculateBestFeatureSplitSecurity2(self):",
          "1770:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1771:       gen_boosted_trees_ops.boosted_trees_sparse_calculate_best_feature_split(",
          "1772:           node_id_range=[0, 1],",
          "1773:           stats_summary_indices=[[0, -1, -1, -1], [1, 0, -1, 0], [1, 0, 0, -1]],",
          "1774:           stats_summary_values=[0.1, 0.2, 0.3],",
          "1775:           stats_summary_shape=[1, 1, 1, 1],",
          "1776:           l1=[0.5],",
          "1777:           l2=[0.5],",
          "1778:           tree_complexity=[0.1],",
          "1779:           min_node_weight=[1.0],",
          "1780:           logits_dimension=1)",
          "1782:   def testBoostedTreesMakeStatsSummarySecurity(self):",
          "1783:     node_ids = [1, 2]",
          "1784:     gradients = [[]]",
          "1785:     hessians = [[0.2], [0.1]]",
          "1786:     bucketized_features_list = [[1], [2]]",
          "1787:     max_splits = 3",
          "1788:     num_buckets = 3",
          "1789:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1790:       gen_boosted_trees_ops.boosted_trees_make_stats_summary(",
          "1791:           node_ids=node_ids,",
          "1792:           gradients=gradients,",
          "1793:           hessians=hessians,",
          "1794:           bucketized_features_list=bucketized_features_list,",
          "1795:           max_splits=max_splits,",
          "1796:           num_buckets=num_buckets)",
          "1798:   def testBoostedTreesMakeStatsSummarySecurity2(self):",
          "1799:     node_ids = [1, 2, 3]",
          "1800:     gradients = [[0.1], [0.2]]",
          "1801:     hessians = [[0.2], [0.1]]",
          "1802:     bucketized_features_list = [[1], [2]]",
          "1803:     max_splits = 3",
          "1804:     num_buckets = 3",
          "1805:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1806:       gen_boosted_trees_ops.boosted_trees_make_stats_summary(",
          "1807:           node_ids=node_ids,",
          "1808:           gradients=gradients,",
          "1809:           hessians=hessians,",
          "1810:           bucketized_features_list=bucketized_features_list,",
          "1811:           max_splits=max_splits,",
          "1812:           num_buckets=num_buckets)",
          "1814:   def testBoostedTreesAggregateStatsSecurity(self):",
          "1815:     node_ids = [1, 2]",
          "1816:     gradients = [[]]",
          "1817:     hessians = [[100.0]]",
          "1818:     feature = [[0, 0, 0]]",
          "1819:     max_splits = 100",
          "1820:     num_buckets = 100",
          "1821:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1822:       gen_boosted_trees_ops.boosted_trees_aggregate_stats(",
          "1823:           node_ids=node_ids,",
          "1824:           gradients=gradients,",
          "1825:           hessians=hessians,",
          "1826:           feature=feature,",
          "1827:           max_splits=max_splits,",
          "1828:           num_buckets=num_buckets)",
          "1830:   def testBoostedTreesAggregateStatsSecurity2(self):",
          "1831:     node_ids = [-10]",
          "1832:     gradients = [[0.0, 0.0]]",
          "1833:     hessians = [[100.0]]",
          "1834:     feature = [[0, 0, 0]]",
          "1835:     max_splits = 100",
          "1836:     num_buckets = 100",
          "1837:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1838:       self.evaluate(",
          "1839:           gen_boosted_trees_ops.boosted_trees_aggregate_stats(",
          "1840:               node_ids=node_ids,",
          "1841:               gradients=gradients,",
          "1842:               hessians=hessians,",
          "1843:               feature=feature,",
          "1844:               max_splits=max_splits,",
          "1845:               num_buckets=num_buckets))",
          "1847:   def testBoostedTreesSparseAggregateStatsSecurity(self):",
          "1848:     node_ids = []",
          "1849:     gradients = [[1.0]]",
          "1850:     hessians = [[100.0]]",
          "1851:     feature_indices = [[0, 0, 0]]",
          "1852:     feature_values = [0, 0, 0]",
          "1853:     feature_shape = [0, 0, 0]",
          "1854:     max_splits = 100",
          "1855:     num_buckets = 100",
          "1856:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1857:       gen_boosted_trees_ops.boosted_trees_sparse_aggregate_stats(",
          "1858:           node_ids=node_ids,",
          "1859:           gradients=gradients,",
          "1860:           hessians=hessians,",
          "1861:           feature_indices=feature_indices,",
          "1862:           feature_values=feature_values,",
          "1863:           feature_shape=feature_shape,",
          "1864:           max_splits=max_splits,",
          "1865:           num_buckets=num_buckets)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "4448c20e81334769c20576223ce6badfba9ca01e",
      "candidate_info": {
        "commit_hash": "4448c20e81334769c20576223ce6badfba9ca01e",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/4448c20e81334769c20576223ce6badfba9ca01e",
        "files": [
          "tensorflow/core/kernels/boosted_trees/stats_ops.cc",
          "tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py"
        ],
        "message": "Fixing security fixes in boosted trees ops\n\nPiperOrigin-RevId: 405669548\nChange-Id: Iae224d240d1779bcc02405c2fff99785644fbd0d",
        "before_after_code_files": [
          "tensorflow/core/kernels/boosted_trees/stats_ops.cc||tensorflow/core/kernels/boosted_trees/stats_ops.cc",
          "tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py||tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/boosted_trees/stats_ops.cc||tensorflow/core/kernels/boosted_trees/stats_ops.cc",
            "tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py||tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py"
          ],
          "candidate": [
            "tensorflow/core/kernels/boosted_trees/stats_ops.cc||tensorflow/core/kernels/boosted_trees/stats_ops.cc",
            "tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py||tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/boosted_trees/stats_ops.cc||tensorflow/core/kernels/boosted_trees/stats_ops.cc": [
          "File: tensorflow/core/kernels/boosted_trees/stats_ops.cc -> tensorflow/core/kernels/boosted_trees/stats_ops.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "72:                                                 &stats_summary_list));",
          "73:     const int64 num_buckets = stats_summary_list[0].dim_size(1);",
          "76:     std::vector<TTypes<float, 3>::ConstTensor> stats_summary;",
          "77:     stats_summary.reserve(stats_summary_list.size());",
          "78:     for (const auto& tensor : stats_summary_list) {",
          "",
          "[Removed Lines]",
          "75:     DCHECK_EQ(stats_summary_list[0].dim_size(2), 2);",
          "",
          "[Added Lines]",
          "75:     OP_REQUIRES(context, stats_summary_list[0].dim_size(2) == 2,",
          "76:                 errors::InvalidArgument(\"stats_summary_list[0] must have \"",
          "77:                                         \"exactly 2 dimensions, obtained: \",",
          "78:                                         stats_summary_list[0].dim_size(2)));",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "275:     const int32 num_buckets = stats_summary_t->dim_size(2) - 1;",
          "276:     const int32 logits_dim = logits_dim_;",
          "277:     const int32 hessian_dim = stats_summary_t->dim_size(3) - logits_dim;",
          "281:     const Tensor* l1_t;",
          "282:     OP_REQUIRES_OK(context, context->input(\"l1\", &l1_t));",
          "",
          "[Removed Lines]",
          "278:     DCHECK_GT(hessian_dim, 0);",
          "279:     DCHECK_LE(hessian_dim, logits_dim * logits_dim);",
          "",
          "[Added Lines]",
          "281:     const int32_t hessian_dim = stats_summary_t->dim_size(3) - logits_dim;",
          "282:     OP_REQUIRES(context, hessian_dim > 0,",
          "283:                 errors::InvalidArgument(\"hessian dim should be < 0, got \",",
          "284:                                         hessian_dim));",
          "285:     OP_REQUIRES(context, hessian_dim <= logits_dim * logits_dim,",
          "286:                 errors::InvalidArgument(",
          "287:                     \"hessian dim should be <= \", logits_dim * logits_dim,",
          "288:                     \" but got: \", hessian_dim));",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "621:     const int32 num_buckets = stats_summaries_list[0].dim_size(2) - 1;",
          "622:     const int32 logits_dim = logits_dim_;",
          "623:     const int32 hessian_dim = stats_summaries_list[0].dim_size(3) - logits_dim;",
          "",
          "[Removed Lines]",
          "624:     DCHECK_GT(hessian_dim, 0);",
          "625:     DCHECK_LE(hessian_dim, logits_dim * logits_dim);",
          "",
          "[Added Lines]",
          "633:    OP_REQUIRES(context, hessian_dim > 0,",
          "634:                 errors::InvalidArgument(\"hessian dim should be < 0, got \",",
          "635:                                         hessian_dim));",
          "636:     OP_REQUIRES(context, hessian_dim <= logits_dim * logits_dim,",
          "637:                 errors::InvalidArgument(",
          "638:                     \"hessian dim should be <= \", logits_dim * logits_dim,",
          "639:                     \" but got: \", hessian_dim));",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "997:     const Tensor* node_id_range_t;",
          "998:     OP_REQUIRES_OK(context, context->input(\"node_id_range\", &node_id_range_t));",
          "999:     const auto node_id_range = node_id_range_t->vec<int32>();",
          "1000:     const int32 node_id_first = node_id_range(0);  // inclusive",
          "1001:     const int32 node_id_last = node_id_range(1);   // exclusive",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1014:     OP_REQUIRES(",
          "1015:         context, node_id_range.size() == 2,",
          "1016:         errors::InvalidArgument(\"node_id_range should have 2 entries, got: \",",
          "1017:                                 node_id_range.size()));",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "1070:                       \"dims, the last value in stats_summary_shape, which was \",",
          "1071:                       stats_dims, \". At index (\", idx,",
          "1072:                       \", 4), stats_summary_indices contains value \", stat_dim));",
          "1073:       std::pair<FeatureMapIterator, bool> const& f_insert_result = f_map.insert(",
          "1074:           FeatureMapIterator::value_type(feature_dim, BucketMap()));",
          "1075:       auto& b_map = f_insert_result.first->second;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1091:       OP_REQUIRES(context, stat_dim >= 0,",
          "1092:                   errors::InvalidArgument(",
          "1093:                       \"Stat dim, the sum of logits dim and hessian dim in \"",
          "1094:                       \"stats_summary_indices, should be >= 0, which was \",",
          "1095:                       stat_dim, \" at index \", idx));",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "1302:     const Tensor* gradients_t;",
          "1303:     OP_REQUIRES_OK(context, context->input(\"gradients\", &gradients_t));",
          "1304:     const auto gradients = gradients_t->matrix<float>();",
          "1306:     const Tensor* hessians_t;",
          "1307:     OP_REQUIRES_OK(context, context->input(\"hessians\", &hessians_t));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1328:     OP_REQUIRES(",
          "1329:         context, node_ids.size() == gradients.dimension(0),",
          "1330:         errors::InvalidArgument(",
          "1331:             \"node_ids size should match 0th dim of gradients. node ids \"",
          "1332:             \"size: \",",
          "1333:             node_ids.size(), \", gradients dim0: \", gradients.dimension(0)));",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "1371:     OP_REQUIRES_OK(context, context->input(\"gradients\", &gradients_t));",
          "1372:     const auto gradients = gradients_t->matrix<float>();",
          "1375:     const Tensor* hessians_t;",
          "1376:     OP_REQUIRES_OK(context, context->input(\"hessians\", &hessians_t));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1403:     OP_REQUIRES(",
          "1404:         context, node_ids.size() == gradients.dimension(0),",
          "1405:         errors::InvalidArgument(",
          "1406:             \"node_ids size should match 0th dim of gradients. node ids \"",
          "1407:             \"size: \",",
          "1408:             node_ids.size(), \", gradients dim0: \", gradients.dimension(0)));",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "1402:     for (int i = 0; i < batch_size; ++i) {",
          "1403:       const int32 node = node_ids(i);",
          "1404:       for (int feature_dim = 0; feature_dim < feature_dims; ++feature_dim) {",
          "1405:         const int32 feature_value = feature(i, feature_dim);",
          "1406:         const int32 bucket =",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1440:       OP_REQUIRES(context, node >= 0,",
          "1441:                   errors::InvalidArgument(",
          "1442:                       \"node_ids \", i, \"th entry should be >=0, got: \", node));",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "1608:     const int64 stats_dims = logits_dims + hessians_dims;",
          "1609:     const int64 num_sparse_entries = feature_indices_t->dim_size(0);",
          "1610:     const int32 feature_dims = feature_shape(1);",
          "1614:     StatsPartitionMap stats_map;",
          "",
          "[Removed Lines]",
          "1611:     DCHECK_LE(num_sparse_entries, batch_size * feature_dims);",
          "",
          "[Added Lines]",
          "1650:     OP_REQUIRES(context, num_sparse_entries <= batch_size * feature_dims,",
          "1651:                 errors::InvalidArgument(",
          "1652:                     \"feature_indices dim0 should be <= gradients dim0 * \"",
          "1653:                     \"feature_shape[1]. features_indices dim0: \",",
          "1654:                     num_sparse_entries, \" gradients dim0: \", batch_size,",
          "1655:                     \", feature_shape[1]: \", feature_dims));",
          "",
          "---------------"
        ],
        "tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py||tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py": [
          "File: tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py -> tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: from tensorflow.python.framework import constant_op",
          "23: from tensorflow.python.framework import dtypes",
          "24: from tensorflow.python.framework import test_util",
          "25: from tensorflow.python.ops import array_ops",
          "26: from tensorflow.python.ops import boosted_trees_ops",
          "27: from tensorflow.python.ops import sparse_ops",
          "28: from tensorflow.python.platform import googletest",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "24: from tensorflow.python.framework import errors",
          "28: from tensorflow.python.ops import gen_boosted_trees_ops",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1669:     \"\"\"Tests numeric precision.\"\"\"",
          "1670:     self._verify_precision(length=50000000)",
          "1673: class BestMultiDimFeatureSplitMultiClassV2Op(StatsOpsTest):",
          "1674:   \"\"\"Tests multi-class/multi-regression for best splits using V2 op.\"\"\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1674:   def testBoostedTreesCalculateBestGainsPerFeatureSecurity(self):",
          "1675:     node_id_range = [1, 2]",
          "1676:     stats_summary_list = [[[[]]]]",
          "1677:     l1 = [1.0]",
          "1678:     l2 = [1.0]",
          "1679:     tree_complexity = [1.0]",
          "1680:     min_node_weight = [1.17]",
          "1681:     max_splits = 1",
          "1682:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1683:       gen_boosted_trees_ops.boosted_trees_calculate_best_gains_per_feature(",
          "1684:           node_id_range=node_id_range,",
          "1685:           stats_summary_list=stats_summary_list,",
          "1686:           l1=l1,",
          "1687:           l2=l2,",
          "1688:           tree_complexity=tree_complexity,",
          "1689:           min_node_weight=min_node_weight,",
          "1690:           max_splits=max_splits)",
          "1692:   def testBoostedTreesCalculateBestFeatureSplitSecurity(self):",
          "1693:     node_id_range = [1, 2]",
          "1694:     stats_summary = [[[[]]]]",
          "1695:     split_type = 'equality'",
          "1696:     l1 = [1.0]",
          "1697:     l2 = [1.0]",
          "1698:     tree_complexity = [1.0]",
          "1699:     min_node_weight = [1.17]",
          "1700:     logits_dimension = 5",
          "1701:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1702:       gen_boosted_trees_ops.boosted_trees_calculate_best_feature_split(",
          "1703:           node_id_range=node_id_range,",
          "1704:           stats_summary=stats_summary,",
          "1705:           l1=l1,",
          "1706:           l2=l2,",
          "1707:           tree_complexity=tree_complexity,",
          "1708:           min_node_weight=min_node_weight,",
          "1709:           logits_dimension=logits_dimension,",
          "1710:           split_type=split_type)",
          "1712:   def testBoostedTreesCalculateBestFeatureSplitSecurity2(self):",
          "1713:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1714:       gen_boosted_trees_ops.boosted_trees_calculate_best_feature_split(",
          "1715:           node_id_range=[0, 8],",
          "1716:           stats_summary=[[[[1.0], [2.0], [3.0]]]],",
          "1717:           l1=[0.5],",
          "1718:           l2=[0.5],",
          "1719:           tree_complexity=[0.1],",
          "1720:           min_node_weight=[1.0],",
          "1721:           logits_dimension=8)",
          "1723:   def testBoostedTreesCalculateBestFeatureSplitV2Security(self):",
          "1724:     node_id_range = [1, 2]",
          "1725:     stats_summaries_list = [[[[[]]]]]",
          "1726:     split_types = ['inequality']",
          "1727:     candidate_feature_ids = [1, 2, 3, 4]",
          "1728:     l1 = [1.0]",
          "1729:     l2 = [1.0]",
          "1730:     tree_complexity = [1.0]",
          "1731:     min_node_weight = [1.17]",
          "1732:     logits_dimension = 5",
          "1733:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1734:       gen_boosted_trees_ops.boosted_trees_calculate_best_feature_split_v2(",
          "1735:           node_id_range=node_id_range,",
          "1736:           stats_summaries_list=stats_summaries_list,",
          "1737:           split_types=split_types,",
          "1738:           candidate_feature_ids=candidate_feature_ids,",
          "1739:           l1=l1,",
          "1740:           l2=l2,",
          "1741:           tree_complexity=tree_complexity,",
          "1742:           min_node_weight=min_node_weight,",
          "1743:           logits_dimension=logits_dimension)",
          "1745:   def testBoostedTreesSparseCalculateBestFeatureSplitSecurity(self):",
          "1746:     node_id_range = []",
          "1747:     stats_summary_indices = [[]]",
          "1748:     stats_summary_values = [1.0]",
          "1749:     stats_summary_shape = [1, 1, 1, 1]",
          "1750:     l1 = [1.0]",
          "1751:     l2 = [1.0]",
          "1752:     tree_complexity = [0.5]",
          "1753:     min_node_weight = [1.0]",
          "1754:     logits_dimension = 3",
          "1755:     split_type = 'inequality'",
          "1756:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1757:       gen_boosted_trees_ops.boosted_trees_sparse_calculate_best_feature_split(",
          "1758:           node_id_range=node_id_range,",
          "1759:           stats_summary_indices=stats_summary_indices,",
          "1760:           stats_summary_values=stats_summary_values,",
          "1761:           stats_summary_shape=stats_summary_shape,",
          "1762:           l1=l1,",
          "1763:           l2=l2,",
          "1764:           tree_complexity=tree_complexity,",
          "1765:           min_node_weight=min_node_weight,",
          "1766:           logits_dimension=logits_dimension,",
          "1767:           split_type=split_type)",
          "1769:   def testBoostedTreesSparseCalculateBestFeatureSplitSecurity2(self):",
          "1770:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1771:       gen_boosted_trees_ops.boosted_trees_sparse_calculate_best_feature_split(",
          "1772:           node_id_range=[0, 1],",
          "1773:           stats_summary_indices=[[0, -1, -1, -1], [1, 0, -1, 0], [1, 0, 0, -1]],",
          "1774:           stats_summary_values=[0.1, 0.2, 0.3],",
          "1775:           stats_summary_shape=[1, 1, 1, 1],",
          "1776:           l1=[0.5],",
          "1777:           l2=[0.5],",
          "1778:           tree_complexity=[0.1],",
          "1779:           min_node_weight=[1.0],",
          "1780:           logits_dimension=1)",
          "1782:   def testBoostedTreesMakeStatsSummarySecurity(self):",
          "1783:     node_ids = [1, 2]",
          "1784:     gradients = [[]]",
          "1785:     hessians = [[0.2], [0.1]]",
          "1786:     bucketized_features_list = [[1], [2]]",
          "1787:     max_splits = 3",
          "1788:     num_buckets = 3",
          "1789:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1790:       gen_boosted_trees_ops.boosted_trees_make_stats_summary(",
          "1791:           node_ids=node_ids,",
          "1792:           gradients=gradients,",
          "1793:           hessians=hessians,",
          "1794:           bucketized_features_list=bucketized_features_list,",
          "1795:           max_splits=max_splits,",
          "1796:           num_buckets=num_buckets)",
          "1798:   def testBoostedTreesMakeStatsSummarySecurity2(self):",
          "1799:     node_ids = [1, 2, 3]",
          "1800:     gradients = [[0.1], [0.2]]",
          "1801:     hessians = [[0.2], [0.1]]",
          "1802:     bucketized_features_list = [[1], [2]]",
          "1803:     max_splits = 3",
          "1804:     num_buckets = 3",
          "1805:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1806:       gen_boosted_trees_ops.boosted_trees_make_stats_summary(",
          "1807:           node_ids=node_ids,",
          "1808:           gradients=gradients,",
          "1809:           hessians=hessians,",
          "1810:           bucketized_features_list=bucketized_features_list,",
          "1811:           max_splits=max_splits,",
          "1812:           num_buckets=num_buckets)",
          "1814:   def testBoostedTreesAggregateStatsSecurity(self):",
          "1815:     node_ids = [1, 2]",
          "1816:     gradients = [[]]",
          "1817:     hessians = [[100.0]]",
          "1818:     feature = [[0, 0, 0]]",
          "1819:     max_splits = 100",
          "1820:     num_buckets = 100",
          "1821:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1822:       gen_boosted_trees_ops.boosted_trees_aggregate_stats(",
          "1823:           node_ids=node_ids,",
          "1824:           gradients=gradients,",
          "1825:           hessians=hessians,",
          "1826:           feature=feature,",
          "1827:           max_splits=max_splits,",
          "1828:           num_buckets=num_buckets)",
          "1830:   def testBoostedTreesAggregateStatsSecurity2(self):",
          "1831:     node_ids = [-10]",
          "1832:     gradients = [[0.0, 0.0]]",
          "1833:     hessians = [[100.0]]",
          "1834:     feature = [[0, 0, 0]]",
          "1835:     max_splits = 100",
          "1836:     num_buckets = 100",
          "1837:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1838:       self.evaluate(",
          "1839:           gen_boosted_trees_ops.boosted_trees_aggregate_stats(",
          "1840:               node_ids=node_ids,",
          "1841:               gradients=gradients,",
          "1842:               hessians=hessians,",
          "1843:               feature=feature,",
          "1844:               max_splits=max_splits,",
          "1845:               num_buckets=num_buckets))",
          "1847:   def testBoostedTreesSparseAggregateStatsSecurity(self):",
          "1848:     node_ids = []",
          "1849:     gradients = [[1.0]]",
          "1850:     hessians = [[100.0]]",
          "1851:     feature_indices = [[0, 0, 0]]",
          "1852:     feature_values = [0, 0, 0]",
          "1853:     feature_shape = [0, 0, 0]",
          "1854:     max_splits = 100",
          "1855:     num_buckets = 100",
          "1856:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1857:       gen_boosted_trees_ops.boosted_trees_sparse_aggregate_stats(",
          "1858:           node_ids=node_ids,",
          "1859:           gradients=gradients,",
          "1860:           hessians=hessians,",
          "1861:           feature_indices=feature_indices,",
          "1862:           feature_values=feature_values,",
          "1863:           feature_shape=feature_shape,",
          "1864:           max_splits=max_splits,",
          "1865:           num_buckets=num_buckets)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "09be88037ff0d9883086cbad9f121255c18eed08",
      "candidate_info": {
        "commit_hash": "09be88037ff0d9883086cbad9f121255c18eed08",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/09be88037ff0d9883086cbad9f121255c18eed08",
        "files": [
          "tensorflow/core/kernels/boosted_trees/stats_ops.cc",
          "tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py"
        ],
        "message": "Fixing security fixes in boosted trees ops\n\nPiperOrigin-RevId: 405669548\nChange-Id: Iae224d240d1779bcc02405c2fff99785644fbd0d",
        "before_after_code_files": [
          "tensorflow/core/kernels/boosted_trees/stats_ops.cc||tensorflow/core/kernels/boosted_trees/stats_ops.cc",
          "tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py||tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/boosted_trees/stats_ops.cc||tensorflow/core/kernels/boosted_trees/stats_ops.cc",
            "tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py||tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py"
          ],
          "candidate": [
            "tensorflow/core/kernels/boosted_trees/stats_ops.cc||tensorflow/core/kernels/boosted_trees/stats_ops.cc",
            "tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py||tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/boosted_trees/stats_ops.cc||tensorflow/core/kernels/boosted_trees/stats_ops.cc": [
          "File: tensorflow/core/kernels/boosted_trees/stats_ops.cc -> tensorflow/core/kernels/boosted_trees/stats_ops.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "72:                                                 &stats_summary_list));",
          "73:     const int64 num_buckets = stats_summary_list[0].dim_size(1);",
          "76:     std::vector<TTypes<float, 3>::ConstTensor> stats_summary;",
          "77:     stats_summary.reserve(stats_summary_list.size());",
          "78:     for (const auto& tensor : stats_summary_list) {",
          "",
          "[Removed Lines]",
          "75:     DCHECK_EQ(stats_summary_list[0].dim_size(2), 2);",
          "",
          "[Added Lines]",
          "75:     OP_REQUIRES(context, stats_summary_list[0].dim_size(2) == 2,",
          "76:                 errors::InvalidArgument(\"stats_summary_list[0] must have \"",
          "77:                                         \"exactly 2 dimensions, obtained: \",",
          "78:                                         stats_summary_list[0].dim_size(2)));",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "275:     const int32 num_buckets = stats_summary_t->dim_size(2) - 1;",
          "276:     const int32 logits_dim = logits_dim_;",
          "277:     const int32 hessian_dim = stats_summary_t->dim_size(3) - logits_dim;",
          "281:     const Tensor* l1_t;",
          "282:     OP_REQUIRES_OK(context, context->input(\"l1\", &l1_t));",
          "",
          "[Removed Lines]",
          "278:     DCHECK_GT(hessian_dim, 0);",
          "279:     DCHECK_LE(hessian_dim, logits_dim * logits_dim);",
          "",
          "[Added Lines]",
          "281:     const int32_t hessian_dim = stats_summary_t->dim_size(3) - logits_dim;",
          "282:     OP_REQUIRES(context, hessian_dim > 0,",
          "283:                 errors::InvalidArgument(\"hessian dim should be < 0, got \",",
          "284:                                         hessian_dim));",
          "285:     OP_REQUIRES(context, hessian_dim <= logits_dim * logits_dim,",
          "286:                 errors::InvalidArgument(",
          "287:                     \"hessian dim should be <= \", logits_dim * logits_dim,",
          "288:                     \" but got: \", hessian_dim));",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "621:     const int32 num_buckets = stats_summaries_list[0].dim_size(2) - 1;",
          "622:     const int32 logits_dim = logits_dim_;",
          "623:     const int32 hessian_dim = stats_summaries_list[0].dim_size(3) - logits_dim;",
          "",
          "[Removed Lines]",
          "624:     DCHECK_GT(hessian_dim, 0);",
          "625:     DCHECK_LE(hessian_dim, logits_dim * logits_dim);",
          "",
          "[Added Lines]",
          "633:    OP_REQUIRES(context, hessian_dim > 0,",
          "634:                 errors::InvalidArgument(\"hessian dim should be < 0, got \",",
          "635:                                         hessian_dim));",
          "636:     OP_REQUIRES(context, hessian_dim <= logits_dim * logits_dim,",
          "637:                 errors::InvalidArgument(",
          "638:                     \"hessian dim should be <= \", logits_dim * logits_dim,",
          "639:                     \" but got: \", hessian_dim));",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "997:     const Tensor* node_id_range_t;",
          "998:     OP_REQUIRES_OK(context, context->input(\"node_id_range\", &node_id_range_t));",
          "999:     const auto node_id_range = node_id_range_t->vec<int32>();",
          "1000:     const int32 node_id_first = node_id_range(0);  // inclusive",
          "1001:     const int32 node_id_last = node_id_range(1);   // exclusive",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1014:     OP_REQUIRES(",
          "1015:         context, node_id_range.size() == 2,",
          "1016:         errors::InvalidArgument(\"node_id_range should have 2 entries, got: \",",
          "1017:                                 node_id_range.size()));",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "1070:                       \"dims, the last value in stats_summary_shape, which was \",",
          "1071:                       stats_dims, \". At index (\", idx,",
          "1072:                       \", 4), stats_summary_indices contains value \", stat_dim));",
          "1073:       std::pair<FeatureMapIterator, bool> const& f_insert_result = f_map.insert(",
          "1074:           FeatureMapIterator::value_type(feature_dim, BucketMap()));",
          "1075:       auto& b_map = f_insert_result.first->second;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1091:       OP_REQUIRES(context, stat_dim >= 0,",
          "1092:                   errors::InvalidArgument(",
          "1093:                       \"Stat dim, the sum of logits dim and hessian dim in \"",
          "1094:                       \"stats_summary_indices, should be >= 0, which was \",",
          "1095:                       stat_dim, \" at index \", idx));",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "1302:     const Tensor* gradients_t;",
          "1303:     OP_REQUIRES_OK(context, context->input(\"gradients\", &gradients_t));",
          "1304:     const auto gradients = gradients_t->matrix<float>();",
          "1306:     const Tensor* hessians_t;",
          "1307:     OP_REQUIRES_OK(context, context->input(\"hessians\", &hessians_t));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1328:     OP_REQUIRES(",
          "1329:         context, node_ids.size() == gradients.dimension(0),",
          "1330:         errors::InvalidArgument(",
          "1331:             \"node_ids size should match 0th dim of gradients. node ids \"",
          "1332:             \"size: \",",
          "1333:             node_ids.size(), \", gradients dim0: \", gradients.dimension(0)));",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "1371:     OP_REQUIRES_OK(context, context->input(\"gradients\", &gradients_t));",
          "1372:     const auto gradients = gradients_t->matrix<float>();",
          "1375:     const Tensor* hessians_t;",
          "1376:     OP_REQUIRES_OK(context, context->input(\"hessians\", &hessians_t));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1403:     OP_REQUIRES(",
          "1404:         context, node_ids.size() == gradients.dimension(0),",
          "1405:         errors::InvalidArgument(",
          "1406:             \"node_ids size should match 0th dim of gradients. node ids \"",
          "1407:             \"size: \",",
          "1408:             node_ids.size(), \", gradients dim0: \", gradients.dimension(0)));",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "1402:     for (int i = 0; i < batch_size; ++i) {",
          "1403:       const int32 node = node_ids(i);",
          "1404:       for (int feature_dim = 0; feature_dim < feature_dims; ++feature_dim) {",
          "1405:         const int32 feature_value = feature(i, feature_dim);",
          "1406:         const int32 bucket =",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1440:       OP_REQUIRES(context, node >= 0,",
          "1441:                   errors::InvalidArgument(",
          "1442:                       \"node_ids \", i, \"th entry should be >=0, got: \", node));",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "1608:     const int64 stats_dims = logits_dims + hessians_dims;",
          "1609:     const int64 num_sparse_entries = feature_indices_t->dim_size(0);",
          "1610:     const int32 feature_dims = feature_shape(1);",
          "1614:     StatsPartitionMap stats_map;",
          "",
          "[Removed Lines]",
          "1611:     DCHECK_LE(num_sparse_entries, batch_size * feature_dims);",
          "",
          "[Added Lines]",
          "1650:     OP_REQUIRES(context, num_sparse_entries <= batch_size * feature_dims,",
          "1651:                 errors::InvalidArgument(",
          "1652:                     \"feature_indices dim0 should be <= gradients dim0 * \"",
          "1653:                     \"feature_shape[1]. features_indices dim0: \",",
          "1654:                     num_sparse_entries, \" gradients dim0: \", batch_size,",
          "1655:                     \", feature_shape[1]: \", feature_dims));",
          "",
          "---------------"
        ],
        "tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py||tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py": [
          "File: tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py -> tensorflow/python/kernel_tests/boosted_trees/stats_ops_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: from tensorflow.python.framework import constant_op",
          "23: from tensorflow.python.framework import dtypes",
          "24: from tensorflow.python.framework import test_util",
          "25: from tensorflow.python.ops import array_ops",
          "26: from tensorflow.python.ops import boosted_trees_ops",
          "27: from tensorflow.python.ops import sparse_ops",
          "28: from tensorflow.python.platform import googletest",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "24: from tensorflow.python.framework import errors",
          "28: from tensorflow.python.ops import gen_boosted_trees_ops",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1669:     \"\"\"Tests numeric precision.\"\"\"",
          "1670:     self._verify_precision(length=50000000)",
          "1673: class BestMultiDimFeatureSplitMultiClassV2Op(StatsOpsTest):",
          "1674:   \"\"\"Tests multi-class/multi-regression for best splits using V2 op.\"\"\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1674:   def testBoostedTreesCalculateBestGainsPerFeatureSecurity(self):",
          "1675:     node_id_range = [1, 2]",
          "1676:     stats_summary_list = [[[[]]]]",
          "1677:     l1 = [1.0]",
          "1678:     l2 = [1.0]",
          "1679:     tree_complexity = [1.0]",
          "1680:     min_node_weight = [1.17]",
          "1681:     max_splits = 1",
          "1682:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1683:       gen_boosted_trees_ops.boosted_trees_calculate_best_gains_per_feature(",
          "1684:           node_id_range=node_id_range,",
          "1685:           stats_summary_list=stats_summary_list,",
          "1686:           l1=l1,",
          "1687:           l2=l2,",
          "1688:           tree_complexity=tree_complexity,",
          "1689:           min_node_weight=min_node_weight,",
          "1690:           max_splits=max_splits)",
          "1692:   def testBoostedTreesCalculateBestFeatureSplitSecurity(self):",
          "1693:     node_id_range = [1, 2]",
          "1694:     stats_summary = [[[[]]]]",
          "1695:     split_type = 'equality'",
          "1696:     l1 = [1.0]",
          "1697:     l2 = [1.0]",
          "1698:     tree_complexity = [1.0]",
          "1699:     min_node_weight = [1.17]",
          "1700:     logits_dimension = 5",
          "1701:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1702:       gen_boosted_trees_ops.boosted_trees_calculate_best_feature_split(",
          "1703:           node_id_range=node_id_range,",
          "1704:           stats_summary=stats_summary,",
          "1705:           l1=l1,",
          "1706:           l2=l2,",
          "1707:           tree_complexity=tree_complexity,",
          "1708:           min_node_weight=min_node_weight,",
          "1709:           logits_dimension=logits_dimension,",
          "1710:           split_type=split_type)",
          "1712:   def testBoostedTreesCalculateBestFeatureSplitSecurity2(self):",
          "1713:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1714:       gen_boosted_trees_ops.boosted_trees_calculate_best_feature_split(",
          "1715:           node_id_range=[0, 8],",
          "1716:           stats_summary=[[[[1.0], [2.0], [3.0]]]],",
          "1717:           l1=[0.5],",
          "1718:           l2=[0.5],",
          "1719:           tree_complexity=[0.1],",
          "1720:           min_node_weight=[1.0],",
          "1721:           logits_dimension=8)",
          "1723:   def testBoostedTreesCalculateBestFeatureSplitV2Security(self):",
          "1724:     node_id_range = [1, 2]",
          "1725:     stats_summaries_list = [[[[[]]]]]",
          "1726:     split_types = ['inequality']",
          "1727:     candidate_feature_ids = [1, 2, 3, 4]",
          "1728:     l1 = [1.0]",
          "1729:     l2 = [1.0]",
          "1730:     tree_complexity = [1.0]",
          "1731:     min_node_weight = [1.17]",
          "1732:     logits_dimension = 5",
          "1733:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1734:       gen_boosted_trees_ops.boosted_trees_calculate_best_feature_split_v2(",
          "1735:           node_id_range=node_id_range,",
          "1736:           stats_summaries_list=stats_summaries_list,",
          "1737:           split_types=split_types,",
          "1738:           candidate_feature_ids=candidate_feature_ids,",
          "1739:           l1=l1,",
          "1740:           l2=l2,",
          "1741:           tree_complexity=tree_complexity,",
          "1742:           min_node_weight=min_node_weight,",
          "1743:           logits_dimension=logits_dimension)",
          "1745:   def testBoostedTreesSparseCalculateBestFeatureSplitSecurity(self):",
          "1746:     node_id_range = []",
          "1747:     stats_summary_indices = [[]]",
          "1748:     stats_summary_values = [1.0]",
          "1749:     stats_summary_shape = [1, 1, 1, 1]",
          "1750:     l1 = [1.0]",
          "1751:     l2 = [1.0]",
          "1752:     tree_complexity = [0.5]",
          "1753:     min_node_weight = [1.0]",
          "1754:     logits_dimension = 3",
          "1755:     split_type = 'inequality'",
          "1756:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1757:       gen_boosted_trees_ops.boosted_trees_sparse_calculate_best_feature_split(",
          "1758:           node_id_range=node_id_range,",
          "1759:           stats_summary_indices=stats_summary_indices,",
          "1760:           stats_summary_values=stats_summary_values,",
          "1761:           stats_summary_shape=stats_summary_shape,",
          "1762:           l1=l1,",
          "1763:           l2=l2,",
          "1764:           tree_complexity=tree_complexity,",
          "1765:           min_node_weight=min_node_weight,",
          "1766:           logits_dimension=logits_dimension,",
          "1767:           split_type=split_type)",
          "1769:   def testBoostedTreesSparseCalculateBestFeatureSplitSecurity2(self):",
          "1770:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1771:       gen_boosted_trees_ops.boosted_trees_sparse_calculate_best_feature_split(",
          "1772:           node_id_range=[0, 1],",
          "1773:           stats_summary_indices=[[0, -1, -1, -1], [1, 0, -1, 0], [1, 0, 0, -1]],",
          "1774:           stats_summary_values=[0.1, 0.2, 0.3],",
          "1775:           stats_summary_shape=[1, 1, 1, 1],",
          "1776:           l1=[0.5],",
          "1777:           l2=[0.5],",
          "1778:           tree_complexity=[0.1],",
          "1779:           min_node_weight=[1.0],",
          "1780:           logits_dimension=1)",
          "1782:   def testBoostedTreesMakeStatsSummarySecurity(self):",
          "1783:     node_ids = [1, 2]",
          "1784:     gradients = [[]]",
          "1785:     hessians = [[0.2], [0.1]]",
          "1786:     bucketized_features_list = [[1], [2]]",
          "1787:     max_splits = 3",
          "1788:     num_buckets = 3",
          "1789:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1790:       gen_boosted_trees_ops.boosted_trees_make_stats_summary(",
          "1791:           node_ids=node_ids,",
          "1792:           gradients=gradients,",
          "1793:           hessians=hessians,",
          "1794:           bucketized_features_list=bucketized_features_list,",
          "1795:           max_splits=max_splits,",
          "1796:           num_buckets=num_buckets)",
          "1798:   def testBoostedTreesMakeStatsSummarySecurity2(self):",
          "1799:     node_ids = [1, 2, 3]",
          "1800:     gradients = [[0.1], [0.2]]",
          "1801:     hessians = [[0.2], [0.1]]",
          "1802:     bucketized_features_list = [[1], [2]]",
          "1803:     max_splits = 3",
          "1804:     num_buckets = 3",
          "1805:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1806:       gen_boosted_trees_ops.boosted_trees_make_stats_summary(",
          "1807:           node_ids=node_ids,",
          "1808:           gradients=gradients,",
          "1809:           hessians=hessians,",
          "1810:           bucketized_features_list=bucketized_features_list,",
          "1811:           max_splits=max_splits,",
          "1812:           num_buckets=num_buckets)",
          "1814:   def testBoostedTreesAggregateStatsSecurity(self):",
          "1815:     node_ids = [1, 2]",
          "1816:     gradients = [[]]",
          "1817:     hessians = [[100.0]]",
          "1818:     feature = [[0, 0, 0]]",
          "1819:     max_splits = 100",
          "1820:     num_buckets = 100",
          "1821:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1822:       gen_boosted_trees_ops.boosted_trees_aggregate_stats(",
          "1823:           node_ids=node_ids,",
          "1824:           gradients=gradients,",
          "1825:           hessians=hessians,",
          "1826:           feature=feature,",
          "1827:           max_splits=max_splits,",
          "1828:           num_buckets=num_buckets)",
          "1830:   def testBoostedTreesAggregateStatsSecurity2(self):",
          "1831:     node_ids = [-10]",
          "1832:     gradients = [[0.0, 0.0]]",
          "1833:     hessians = [[100.0]]",
          "1834:     feature = [[0, 0, 0]]",
          "1835:     max_splits = 100",
          "1836:     num_buckets = 100",
          "1837:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1838:       self.evaluate(",
          "1839:           gen_boosted_trees_ops.boosted_trees_aggregate_stats(",
          "1840:               node_ids=node_ids,",
          "1841:               gradients=gradients,",
          "1842:               hessians=hessians,",
          "1843:               feature=feature,",
          "1844:               max_splits=max_splits,",
          "1845:               num_buckets=num_buckets))",
          "1847:   def testBoostedTreesSparseAggregateStatsSecurity(self):",
          "1848:     node_ids = []",
          "1849:     gradients = [[1.0]]",
          "1850:     hessians = [[100.0]]",
          "1851:     feature_indices = [[0, 0, 0]]",
          "1852:     feature_values = [0, 0, 0]",
          "1853:     feature_shape = [0, 0, 0]",
          "1854:     max_splits = 100",
          "1855:     num_buckets = 100",
          "1856:     with self.assertRaises((errors.InvalidArgumentError, ValueError)):",
          "1857:       gen_boosted_trees_ops.boosted_trees_sparse_aggregate_stats(",
          "1858:           node_ids=node_ids,",
          "1859:           gradients=gradients,",
          "1860:           hessians=hessians,",
          "1861:           feature_indices=feature_indices,",
          "1862:           feature_values=feature_values,",
          "1863:           feature_shape=feature_shape,",
          "1864:           max_splits=max_splits,",
          "1865:           num_buckets=num_buckets)",
          "",
          "---------------"
        ]
      }
    }
  ]
}