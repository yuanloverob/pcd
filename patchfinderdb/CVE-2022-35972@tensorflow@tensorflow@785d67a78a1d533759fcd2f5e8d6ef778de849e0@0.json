{
  "cve_id": "CVE-2022-35972",
  "cve_desc": "TensorFlow is an open source platform for machine learning. If `QuantizedBiasAdd` is given `min_input`, `max_input`, `min_bias`, `max_bias` tensors of a nonzero rank, it results in a segfault that can be used to trigger a denial of service attack. We have patched the issue in GitHub commit 785d67a78a1d533759fcd2f5e8d6ef778de849e0. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
  "repo": "tensorflow/tensorflow",
  "patch_hash": "785d67a78a1d533759fcd2f5e8d6ef778de849e0",
  "patch_info": {
    "commit_hash": "785d67a78a1d533759fcd2f5e8d6ef778de849e0",
    "repo": "tensorflow/tensorflow",
    "commit_url": "https://github.com/tensorflow/tensorflow/commit/785d67a78a1d533759fcd2f5e8d6ef778de849e0",
    "files": [
      "tensorflow/core/kernels/fake_quant_ops.cc",
      "tensorflow/core/kernels/quantized_bias_add_op.cc",
      "tensorflow/core/kernels/quantized_bias_add_op_test.cc",
      "tensorflow/core/kernels/quantized_instance_norm.cc",
      "tensorflow/core/kernels/requantize.cc",
      "tensorflow/core/kernels/requantize_op_test.cc",
      "tensorflow/python/kernel_tests/quantization_ops/BUILD",
      "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
    ],
    "message": "Fix quantize ops input validation issues.\n\nThe majority of these are just missing checks on min/max.\n\nPiperOrigin-RevId: 461800665",
    "before_after_code_files": [
      "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc",
      "tensorflow/core/kernels/quantized_bias_add_op.cc||tensorflow/core/kernels/quantized_bias_add_op.cc",
      "tensorflow/core/kernels/quantized_bias_add_op_test.cc||tensorflow/core/kernels/quantized_bias_add_op_test.cc",
      "tensorflow/core/kernels/quantized_instance_norm.cc||tensorflow/core/kernels/quantized_instance_norm.cc",
      "tensorflow/core/kernels/requantize.cc||tensorflow/core/kernels/requantize.cc",
      "tensorflow/core/kernels/requantize_op_test.cc||tensorflow/core/kernels/requantize_op_test.cc",
      "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
    ]
  },
  "patch_diff": {
    "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc": [
      "File: tensorflow/core/kernels/fake_quant_ops.cc -> tensorflow/core/kernels/fake_quant_ops.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "25: #include \"tensorflow/core/framework/numeric_op.h\"",
      "26: #include \"tensorflow/core/framework/tensor.h\"",
      "27: #include \"tensorflow/core/lib/core/errors.h\"",
      "28: #include \"tensorflow/core/lib/monitoring/gauge.h\"",
      "29: #include \"tensorflow/core/platform/protobuf.h\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "27: #include \"tensorflow/core/framework/tensor_shape.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "205:     const Tensor& min = context->input(1);",
      "206:     const Tensor& max = context->input(2);",
      "208:     Tensor* output;",
      "209:     OP_REQUIRES_OK(context,",
      "210:                    context->allocate_output(0, input.shape(), &output));",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "209:     OP_REQUIRES(",
      "210:         context, TensorShapeUtils::IsScalar(min.shape()),",
      "211:         InvalidArgument(\"`min` must be rank 0 but is rank \", min.dims()));",
      "212:     OP_REQUIRES(",
      "213:         context, TensorShapeUtils::IsScalar(max.shape()),",
      "214:         InvalidArgument(\"`max` must be rank 0 but is rank \", max.dims()));",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "342:     const Tensor& input = context->input(0);",
      "343:     const int depth = input.dim_size(input.dims() - 1);  // last dimension size.",
      "344:     const Tensor& min = context->input(1);",
      "345:     OP_REQUIRES(context, min.dim_size(0) == depth,",
      "346:                 InvalidArgument(\"min has incorrect size, expected \", depth,",
      "347:                                 \" was \", min.dim_size(0)));",
      "349:     OP_REQUIRES(context, max.dim_size(0) == depth,",
      "350:                 InvalidArgument(\"max has incorrect size, expected \", depth,",
      "351:                                 \" was \", max.dim_size(0)));",
      "",
      "[Removed Lines]",
      "348:     const Tensor& max = context->input(2);",
      "",
      "[Added Lines]",
      "353:     const Tensor& max = context->input(2);",
      "355:     OP_REQUIRES(",
      "356:         context, TensorShapeUtils::IsVector(min.shape()),",
      "357:         InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));",
      "361:     OP_REQUIRES(",
      "362:         context, TensorShapeUtils::IsVector(max.shape()),",
      "363:         InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));",
      "",
      "---------------"
    ],
    "tensorflow/core/kernels/quantized_bias_add_op.cc||tensorflow/core/kernels/quantized_bias_add_op.cc": [
      "File: tensorflow/core/kernels/quantized_bias_add_op.cc -> tensorflow/core/kernels/quantized_bias_add_op.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "20: #include \"tensorflow/core/framework/numeric_op.h\"",
      "21: #include \"tensorflow/core/framework/op_kernel.h\"",
      "22: #include \"tensorflow/core/framework/tensor.h\"",
      "23: #include \"tensorflow/core/kernels/meta_support.h\"",
      "24: #include \"tensorflow/core/kernels/ops_util.h\"",
      "25: #include \"tensorflow/core/kernels/quantization_utils.h\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "23: #include \"tensorflow/core/framework/tensor_shape.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "38:   void Compute(OpKernelContext* context) override {",
      "39:     const Tensor& input = context->input(0);",
      "40:     const Tensor& bias = context->input(1);",
      "46:     OP_REQUIRES(context, TensorShapeUtils::IsMatrixOrHigher(input.shape()),",
      "47:                 errors::InvalidArgument(\"Input tensor must be at least 2D: \",",
      "",
      "[Removed Lines]",
      "41:     const float input_min = context->input(2).flat<float>()(0);",
      "42:     const float input_max = context->input(3).flat<float>()(0);",
      "43:     const float bias_min = context->input(4).flat<float>()(0);",
      "44:     const float bias_max = context->input(5).flat<float>()(0);",
      "",
      "[Added Lines]",
      "43:     const Tensor& min_input = context->input(2);",
      "44:     const Tensor& max_input = context->input(3);",
      "45:     const Tensor& min_bias = context->input(4);",
      "46:     const Tensor& max_bias = context->input(5);",
      "47:     OP_REQUIRES(",
      "48:         context, TensorShapeUtils::IsScalar(min_input.shape()),",
      "49:         errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",",
      "50:                                 min_input.dims()));",
      "51:     OP_REQUIRES(",
      "52:         context, TensorShapeUtils::IsScalar(max_input.shape()),",
      "53:         errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",",
      "54:                                 max_input.dims()));",
      "55:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_bias.shape()),",
      "56:                 errors::InvalidArgument(",
      "57:                     \"`min_bias` must be rank 0 but is rank \", min_bias.dims()));",
      "58:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_bias.shape()),",
      "59:                 errors::InvalidArgument(",
      "60:                     \"`max_bias` must be rank 0 but is rank \", max_bias.dims()));",
      "62:     const float input_min = min_input.flat<float>()(0);",
      "63:     const float input_max = max_input.flat<float>()(0);",
      "64:     const float bias_min = min_bias.flat<float>()(0);",
      "65:     const float bias_max = max_bias.flat<float>()(0);",
      "",
      "---------------"
    ],
    "tensorflow/core/kernels/quantized_bias_add_op_test.cc||tensorflow/core/kernels/quantized_bias_add_op_test.cc": [
      "File: tensorflow/core/kernels/quantized_bias_add_op_test.cc -> tensorflow/core/kernels/quantized_bias_add_op_test.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "74:                             input_quantized.flat<quint8>());",
      "75:   AddInputFromArray<quint8>(bias_quantized.shape(),",
      "76:                             bias_quantized.flat<quint8>());",
      "81:   TF_ASSERT_OK(RunOpKernel());",
      "82:   const Tensor& output_quantized = *GetOutput(0);",
      "83:   const float output_min = GetOutput(1)->flat<float>()(0);",
      "",
      "[Removed Lines]",
      "77:   AddInputFromArray<float>(TensorShape({1}), {input_min});",
      "78:   AddInputFromArray<float>(TensorShape({1}), {input_max});",
      "79:   AddInputFromArray<float>(TensorShape({1}), {bias_min});",
      "80:   AddInputFromArray<float>(TensorShape({1}), {bias_max});",
      "",
      "[Added Lines]",
      "77:   AddInputFromArray<float>(TensorShape({}), {input_min});",
      "78:   AddInputFromArray<float>(TensorShape({}), {input_max});",
      "79:   AddInputFromArray<float>(TensorShape({}), {bias_min});",
      "80:   AddInputFromArray<float>(TensorShape({}), {bias_max});",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "156:                             input_quantized.flat<quint8>());",
      "157:   AddInputFromArray<quint8>(bias_quantized.shape(),",
      "158:                             bias_quantized.flat<quint8>());",
      "163:   TF_ASSERT_OK(RunOpKernel());",
      "164:   const Tensor& output_quantized = *GetOutput(0);",
      "165:   const float output_min = GetOutput(1)->flat<float>()(0);",
      "",
      "[Removed Lines]",
      "159:   AddInputFromArray<float>(TensorShape({1}), {input_min});",
      "160:   AddInputFromArray<float>(TensorShape({1}), {input_max});",
      "161:   AddInputFromArray<float>(TensorShape({1}), {bias_min});",
      "162:   AddInputFromArray<float>(TensorShape({1}), {bias_max});",
      "",
      "[Added Lines]",
      "159:   AddInputFromArray<float>(TensorShape({}), {input_min});",
      "160:   AddInputFromArray<float>(TensorShape({}), {input_max});",
      "161:   AddInputFromArray<float>(TensorShape({}), {bias_min});",
      "162:   AddInputFromArray<float>(TensorShape({}), {bias_max});",
      "",
      "---------------"
    ],
    "tensorflow/core/kernels/quantized_instance_norm.cc||tensorflow/core/kernels/quantized_instance_norm.cc": [
      "File: tensorflow/core/kernels/quantized_instance_norm.cc -> tensorflow/core/kernels/quantized_instance_norm.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "25: #include \"tensorflow/core/framework/op_kernel.h\"",
      "26: #include \"tensorflow/core/framework/register_types.h\"",
      "27: #include \"tensorflow/core/framework/tensor.h\"",
      "29: #include \"tensorflow/core/kernels/quantization_utils.h\"",
      "31: #ifdef USE_NEON",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "28: #include \"tensorflow/core/framework/tensor_shape.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "274:   void Compute(OpKernelContext* context) override {",
      "275:     const Tensor& input = context->input(0);",
      "279:     float input_scale = (input_max - input_min) / 255.0f;",
      "281:     OP_REQUIRES(context, input_min < input_max,",
      "",
      "[Removed Lines]",
      "277:     float input_min = context->input(1).flat<float>()(0);",
      "278:     float input_max = context->input(2).flat<float>()(0);",
      "",
      "[Added Lines]",
      "277:     const Tensor& x_min = context->input(1);",
      "278:     const Tensor& x_max = context->input(2);",
      "279:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(x_min.shape()),",
      "280:                 errors::InvalidArgument(\"`x_min` must be rank 0 but is rank \",",
      "281:                                         x_min.dims()));",
      "282:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(x_max.shape()),",
      "283:                 errors::InvalidArgument(\"`x_max` must be rank 0 but is rank \",",
      "284:                                         x_max.dims()));",
      "285:     float input_min = x_min.scalar<float>()();",
      "286:     float input_max = x_max.scalar<float>()();",
      "",
      "---------------"
    ],
    "tensorflow/core/kernels/requantize.cc||tensorflow/core/kernels/requantize.cc": [
      "File: tensorflow/core/kernels/requantize.cc -> tensorflow/core/kernels/requantize.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "18: #define EIGEN_USE_THREADS",
      "20: #include <math.h>",
      "22: #include \"tensorflow/core/framework/op.h\"",
      "23: #include \"tensorflow/core/framework/op_kernel.h\"",
      "24: #include \"tensorflow/core/framework/type_traits.h\"",
      "25: #include \"tensorflow/core/framework/types.h\"",
      "26: #include \"tensorflow/core/kernels/meta_support.h\"",
      "",
      "[Removed Lines]",
      "21: #include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"",
      "",
      "[Added Lines]",
      "24: #include \"tensorflow/core/framework/tensor.h\"",
      "25: #include \"tensorflow/core/framework/tensor_shape.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "39:   void Compute(OpKernelContext* ctx) override {",
      "40:     const Tensor& input = ctx->input(0);",
      "46:     Tensor* output = nullptr;",
      "47:     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
      "",
      "[Removed Lines]",
      "41:     const float input_min_float = ctx->input(1).flat<float>()(0);",
      "42:     const float input_max_float = ctx->input(2).flat<float>()(0);",
      "43:     const float requested_output_min_float = ctx->input(3).flat<float>()(0);",
      "44:     const float requested_output_max_float = ctx->input(4).flat<float>()(0);",
      "",
      "[Added Lines]",
      "44:     const Tensor& input_min = ctx->input(1);",
      "45:     const Tensor& input_max = ctx->input(2);",
      "46:     const Tensor& requested_output_min = ctx->input(3);",
      "47:     const Tensor& requested_output_max = ctx->input(4);",
      "48:     OP_REQUIRES(",
      "49:         ctx, TensorShapeUtils::IsScalar(input_min.shape()),",
      "50:         errors::InvalidArgument(\"`input_min` must be rank 0 but is rank \",",
      "51:                                 input_min.dims()));",
      "52:     OP_REQUIRES(",
      "53:         ctx, TensorShapeUtils::IsScalar(input_max.shape()),",
      "54:         errors::InvalidArgument(\"`input_max` must be rank 0 but is rank \",",
      "55:                                 input_max.dims()));",
      "56:     OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_min.shape()),",
      "57:                 errors::InvalidArgument(",
      "58:                     \"`requested_output_min` must be rank 0 but is rank \",",
      "59:                     requested_output_min.dims()));",
      "60:     OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_max.shape()),",
      "61:                 errors::InvalidArgument(",
      "62:                     \"`requested_output_max` must be rank 0 but is rank \",",
      "63:                     requested_output_max.dims()));",
      "65:     const float input_min_float = input_min.flat<float>()(0);",
      "66:     const float input_max_float = input_max.flat<float>()(0);",
      "67:     const float requested_output_min_float =",
      "68:         requested_output_min.flat<float>()(0);",
      "69:     const float requested_output_max_float =",
      "70:         requested_output_max.flat<float>()(0);",
      "",
      "---------------"
    ],
    "tensorflow/core/kernels/requantize_op_test.cc||tensorflow/core/kernels/requantize_op_test.cc": [
      "File: tensorflow/core/kernels/requantize_op_test.cc -> tensorflow/core/kernels/requantize_op_test.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "54:   AddInputFromArray<qint32>(TensorShape({value_count}),",
      "55:                             {-(1 << 23), 0, (1 << 23)});",
      "60:   TF_ASSERT_OK(RunOpKernel());",
      "61:   Tensor expected(allocator(), DT_QUINT8, TensorShape({value_count}));",
      "62:   test::FillValues<quint8>(&expected, {0, 128, 255});",
      "",
      "[Removed Lines]",
      "56:   AddInputFromArray<float>(TensorShape({1}), {-256.0f});",
      "57:   AddInputFromArray<float>(TensorShape({1}), {256.0f});",
      "58:   AddInputFromArray<float>(TensorShape({1}), {-1.0f});",
      "59:   AddInputFromArray<float>(TensorShape({1}), {1.0f});",
      "",
      "[Added Lines]",
      "56:   AddInputFromArray<float>(TensorShape({}), {-256.0f});",
      "57:   AddInputFromArray<float>(TensorShape({}), {256.0f});",
      "58:   AddInputFromArray<float>(TensorShape({}), {-1.0f});",
      "59:   AddInputFromArray<float>(TensorShape({}), {1.0f});",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "72:   AddInputFromArray<qint32>(TensorShape({value_count}),",
      "73:                             {-(1 << 23), 0, (1 << 23)});",
      "78:   EXPECT_EQ(\"requested_output_min must be <= 0, but got 0.01\",",
      "79:             RunOpKernel().error_message());",
      "80: }",
      "",
      "[Removed Lines]",
      "74:   AddInputFromArray<float>(TensorShape({1}), {-256.0f});",
      "75:   AddInputFromArray<float>(TensorShape({1}), {256.0f});",
      "76:   AddInputFromArray<float>(TensorShape({1}), {0.01f});",
      "77:   AddInputFromArray<float>(TensorShape({1}), {1.0f});",
      "",
      "[Added Lines]",
      "74:   AddInputFromArray<float>(TensorShape({}), {-256.0f});",
      "75:   AddInputFromArray<float>(TensorShape({}), {256.0f});",
      "76:   AddInputFromArray<float>(TensorShape({}), {0.01f});",
      "77:   AddInputFromArray<float>(TensorShape({}), {1.0f});",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "86:   AddInputFromArray<qint32>(TensorShape({value_count}),",
      "87:                             {-(1 << 23), 0, (1 << 23)});",
      "92:   EXPECT_EQ(",
      "93:       \"requested_output_max must be >= requested_output_min, but got -11 and \"",
      "94:       \"-10\",",
      "",
      "[Removed Lines]",
      "88:   AddInputFromArray<float>(TensorShape({1}), {-256.0f});",
      "89:   AddInputFromArray<float>(TensorShape({1}), {256.0f});",
      "90:   AddInputFromArray<float>(TensorShape({1}), {-10.0f});",
      "91:   AddInputFromArray<float>(TensorShape({1}), {-11.0f});",
      "",
      "[Added Lines]",
      "88:   AddInputFromArray<float>(TensorShape({}), {-256.0f});",
      "89:   AddInputFromArray<float>(TensorShape({}), {256.0f});",
      "90:   AddInputFromArray<float>(TensorShape({}), {-10.0f});",
      "91:   AddInputFromArray<float>(TensorShape({}), {-11.0f});",
      "",
      "---------------"
    ],
    "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py": [
      "File: tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py -> tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "[No context available]",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "1: # Copyright 2015 The TensorFlow Authors. All Rights Reserved.",
      "2: #",
      "3: # Licensed under the Apache License, Version 2.0 (the \"License\");",
      "4: # you may not use this file except in compliance with the License.",
      "5: # You may obtain a copy of the License at",
      "6: #",
      "7: #     http://www.apache.org/licenses/LICENSE-2.0",
      "8: #",
      "9: # Unless required by applicable law or agreed to in writing, software",
      "10: # distributed under the License is distributed on an \"AS IS\" BASIS,",
      "11: # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
      "12: # See the License for the specific language governing permissions and",
      "13: # limitations under the License.",
      "14: # ==============================================================================",
      "15: \"\"\"Tests for tf.quantize ops.\"\"\"",
      "16: import numpy as np",
      "18: from tensorflow.python.framework import constant_op",
      "19: from tensorflow.python.framework import dtypes",
      "20: from tensorflow.python.framework import errors",
      "21: from tensorflow.python.framework import test_util",
      "22: from tensorflow.python.ops import array_ops",
      "23: from tensorflow.python.ops import math_ops",
      "24: from tensorflow.python.ops import nn_ops",
      "25: from tensorflow.python.platform import googletest",
      "28: class FakeQuantWithMinMaxVarsOpTest(test_util.TensorFlowTestCase):",
      "30:   @test_util.run_in_graph_and_eager_modes",
      "31:   def test_invalid_inputs(self):",
      "32:     inputs = constant_op.constant(",
      "33:         value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
      "35:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
      "36:                                 \"must be rank 0\"):",
      "37:       self.evaluate(",
      "38:           array_ops.fake_quant_with_min_max_vars(",
      "39:               inputs=inputs, min=0.0, max=[[1.0], [2.0], [4.0]]))",
      "41:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
      "42:                                 \"must be rank 0\"):",
      "43:       self.evaluate(",
      "44:           array_ops.fake_quant_with_min_max_vars(",
      "45:               inputs=inputs, min=[[1.0], [2.0], [4.0]], max=1.0))",
      "48: class FakeQuantWithMinMaxVarsPerChannelOpTest(test_util.TensorFlowTestCase):",
      "50:   @test_util.run_in_graph_and_eager_modes",
      "51:   def test_invalid_inputs(self):",
      "52:     inputs = constant_op.constant(",
      "53:         value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
      "55:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
      "56:                                 \"must be rank 1\"):",
      "57:       self.evaluate(",
      "58:           array_ops.fake_quant_with_min_max_vars_per_channel(",
      "59:               inputs=inputs, min=[[0.0]], max=[1.0]))",
      "61:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
      "62:                                 \"Dimensions must be equal|incorrect size\"):",
      "63:       self.evaluate(",
      "64:           array_ops.fake_quant_with_min_max_vars_per_channel(",
      "65:               inputs=inputs, min=[0.0, 0.1], max=[1.0]))",
      "67:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
      "68:                                 \"must be rank 1\"):",
      "69:       self.evaluate(",
      "70:           array_ops.fake_quant_with_min_max_vars_per_channel(",
      "71:               inputs=inputs, min=[1.0], max=[[1.0]]))",
      "73:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
      "74:                                 \"Dimensions must be equal|incorrect size\"):",
      "75:       self.evaluate(",
      "76:           array_ops.fake_quant_with_min_max_vars_per_channel(",
      "77:               inputs=inputs, min=[0.0], max=[1.0, 1.1]))",
      "80: class QuantizedBiasedAddTest(test_util.TensorFlowTestCase):",
      "82:   @test_util.run_in_graph_and_eager_modes",
      "83:   def test_invalid_inputs(self):",
      "84:     inputs = constant_op.constant(",
      "85:         np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.qint8)",
      "86:     bias = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.qint8)",
      "88:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
      "89:                                 \"must be rank 0\"):",
      "90:       self.evaluate(",
      "91:           nn_ops.quantized_bias_add(",
      "92:               input=inputs,",
      "93:               bias=bias,",
      "94:               min_input=[],",
      "95:               max_input=1.0,",
      "96:               min_bias=0.0,",
      "97:               max_bias=1.0,",
      "98:               out_type=dtypes.qint32))",
      "100:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
      "101:                                 \"must be rank 0\"):",
      "102:       self.evaluate(",
      "103:           nn_ops.quantized_bias_add(",
      "104:               input=inputs,",
      "105:               bias=bias,",
      "106:               min_input=0.0,",
      "107:               max_input=[],",
      "108:               min_bias=0.0,",
      "109:               max_bias=1.0,",
      "110:               out_type=dtypes.qint32))",
      "112:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
      "113:                                 \"must be rank 0\"):",
      "114:       self.evaluate(",
      "115:           nn_ops.quantized_bias_add(",
      "116:               input=inputs,",
      "117:               bias=bias,",
      "118:               min_input=0.0,",
      "119:               max_input=1.0,",
      "120:               min_bias=[],",
      "121:               max_bias=1.0,",
      "122:               out_type=dtypes.qint32))",
      "124:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
      "125:                                 \"must be rank 0\"):",
      "126:       self.evaluate(",
      "127:           nn_ops.quantized_bias_add(",
      "128:               input=inputs,",
      "129:               bias=bias,",
      "130:               min_input=0.0,",
      "131:               max_input=1.0,",
      "132:               min_bias=0.0,",
      "133:               max_bias=[],",
      "134:               out_type=dtypes.qint32))",
      "137: class QuantizedInstanceNormOpTest(test_util.TensorFlowTestCase):",
      "139:   @test_util.run_in_graph_and_eager_modes",
      "140:   def test_invalid_inputs(self):",
      "141:     inputs = constant_op.constant(",
      "142:         np.uint8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)",
      "144:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
      "145:                                 \"must be rank 0\"):",
      "146:       self.evaluate(",
      "147:           array_ops.quantized_instance_norm(",
      "148:               x=inputs, x_min=0.0, x_max=[[1.0], [2.0], [4.0]]))",
      "150:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
      "151:                                 \"must be rank 0\"):",
      "152:       self.evaluate(",
      "153:           array_ops.quantized_instance_norm(",
      "154:               x=inputs, x_min=[[1.0], [2.0], [4.0]], x_max=1.0))",
      "157: class RequantizeOpTest(test_util.TensorFlowTestCase):",
      "159:   @test_util.run_in_graph_and_eager_modes",
      "160:   def test_invalid_inputs(self):",
      "161:     inputs = constant_op.constant(",
      "162:         np.int32(0), shape=[3, 3, 3, 3], dtype=dtypes.qint32)",
      "164:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
      "165:                                 \"must be rank 0\"):",
      "166:       self.evaluate(",
      "167:           math_ops.requantize(",
      "168:               input=inputs,",
      "169:               input_min=[],",
      "170:               input_max=1.0,",
      "171:               requested_output_min=0.0,",
      "172:               requested_output_max=1.0,",
      "173:               out_type=dtypes.qint8))",
      "175:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
      "176:                                 \"must be rank 0\"):",
      "177:       self.evaluate(",
      "178:           math_ops.requantize(",
      "179:               input=inputs,",
      "180:               input_min=0.0,",
      "181:               input_max=[],",
      "182:               requested_output_min=0.0,",
      "183:               requested_output_max=1.0,",
      "184:               out_type=dtypes.qint8))",
      "186:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
      "187:                                 \"must be rank 0\"):",
      "188:       self.evaluate(",
      "189:           math_ops.requantize(",
      "190:               input=inputs,",
      "191:               input_min=0.0,",
      "192:               input_max=1.0,",
      "193:               requested_output_min=[],",
      "194:               requested_output_max=1.0,",
      "195:               out_type=dtypes.qint8))",
      "197:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
      "198:                                 \"must be rank 0\"):",
      "199:       self.evaluate(",
      "200:           math_ops.requantize(",
      "201:               input=inputs,",
      "202:               input_min=0.0,",
      "203:               input_max=1.0,",
      "204:               requested_output_min=0.0,",
      "205:               requested_output_max=[],",
      "206:               out_type=dtypes.qint8))",
      "209: if __name__ == \"__main__\":",
      "210:   googletest.main()",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "ea48fdb5267bc82ea6756c1b81bde7e5efac8cfe",
      "candidate_info": {
        "commit_hash": "ea48fdb5267bc82ea6756c1b81bde7e5efac8cfe",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/ea48fdb5267bc82ea6756c1b81bde7e5efac8cfe",
        "files": [
          "tensorflow/core/kernels/fake_quant_ops.cc",
          "tensorflow/core/kernels/quantized_bias_add_op.cc",
          "tensorflow/core/kernels/quantized_bias_add_op_test.cc",
          "tensorflow/core/kernels/quantized_instance_norm.cc",
          "tensorflow/core/kernels/requantize.cc",
          "tensorflow/core/kernels/requantize_op_test.cc",
          "tensorflow/python/kernel_tests/quantization_ops/BUILD",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ],
        "message": "Fix quantize ops input validation issues.\n\nThe majority of these are just missing checks on min/max.\n\nPiperOrigin-RevId: 461800665",
        "before_after_code_files": [
          "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc",
          "tensorflow/core/kernels/quantized_bias_add_op.cc||tensorflow/core/kernels/quantized_bias_add_op.cc",
          "tensorflow/core/kernels/quantized_bias_add_op_test.cc||tensorflow/core/kernels/quantized_bias_add_op_test.cc",
          "tensorflow/core/kernels/quantized_instance_norm.cc||tensorflow/core/kernels/quantized_instance_norm.cc",
          "tensorflow/core/kernels/requantize.cc||tensorflow/core/kernels/requantize.cc",
          "tensorflow/core/kernels/requantize_op_test.cc||tensorflow/core/kernels/requantize_op_test.cc",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc",
            "tensorflow/core/kernels/quantized_bias_add_op.cc||tensorflow/core/kernels/quantized_bias_add_op.cc",
            "tensorflow/core/kernels/quantized_bias_add_op_test.cc||tensorflow/core/kernels/quantized_bias_add_op_test.cc",
            "tensorflow/core/kernels/quantized_instance_norm.cc||tensorflow/core/kernels/quantized_instance_norm.cc",
            "tensorflow/core/kernels/requantize.cc||tensorflow/core/kernels/requantize.cc",
            "tensorflow/core/kernels/requantize_op_test.cc||tensorflow/core/kernels/requantize_op_test.cc",
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ],
          "candidate": [
            "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc",
            "tensorflow/core/kernels/quantized_bias_add_op.cc||tensorflow/core/kernels/quantized_bias_add_op.cc",
            "tensorflow/core/kernels/quantized_bias_add_op_test.cc||tensorflow/core/kernels/quantized_bias_add_op_test.cc",
            "tensorflow/core/kernels/quantized_instance_norm.cc||tensorflow/core/kernels/quantized_instance_norm.cc",
            "tensorflow/core/kernels/requantize.cc||tensorflow/core/kernels/requantize.cc",
            "tensorflow/core/kernels/requantize_op_test.cc||tensorflow/core/kernels/requantize_op_test.cc",
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc": [
          "File: tensorflow/core/kernels/fake_quant_ops.cc -> tensorflow/core/kernels/fake_quant_ops.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "25: #include \"tensorflow/core/framework/numeric_op.h\"",
          "26: #include \"tensorflow/core/framework/tensor.h\"",
          "27: #include \"tensorflow/core/lib/core/errors.h\"",
          "28: #include \"tensorflow/core/lib/monitoring/gauge.h\"",
          "29: #include \"tensorflow/core/platform/protobuf.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "27: #include \"tensorflow/core/framework/tensor_shape.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "205:     const Tensor& min = context->input(1);",
          "206:     const Tensor& max = context->input(2);",
          "208:     Tensor* output;",
          "209:     OP_REQUIRES_OK(context,",
          "210:                    context->allocate_output(0, input.shape(), &output));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "209:     OP_REQUIRES(",
          "210:         context, TensorShapeUtils::IsScalar(min.shape()),",
          "211:         InvalidArgument(\"`min` must be rank 0 but is rank \", min.dims()));",
          "212:     OP_REQUIRES(",
          "213:         context, TensorShapeUtils::IsScalar(max.shape()),",
          "214:         InvalidArgument(\"`max` must be rank 0 but is rank \", max.dims()));",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "342:     const Tensor& input = context->input(0);",
          "343:     const int depth = input.dim_size(input.dims() - 1);  // last dimension size.",
          "344:     const Tensor& min = context->input(1);",
          "345:     OP_REQUIRES(context, min.dim_size(0) == depth,",
          "346:                 InvalidArgument(\"min has incorrect size, expected \", depth,",
          "347:                                 \" was \", min.dim_size(0)));",
          "349:     OP_REQUIRES(context, max.dim_size(0) == depth,",
          "350:                 InvalidArgument(\"max has incorrect size, expected \", depth,",
          "351:                                 \" was \", max.dim_size(0)));",
          "",
          "[Removed Lines]",
          "348:     const Tensor& max = context->input(2);",
          "",
          "[Added Lines]",
          "353:     const Tensor& max = context->input(2);",
          "355:     OP_REQUIRES(",
          "356:         context, TensorShapeUtils::IsVector(min.shape()),",
          "357:         InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));",
          "361:     OP_REQUIRES(",
          "362:         context, TensorShapeUtils::IsVector(max.shape()),",
          "363:         InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/quantized_bias_add_op.cc||tensorflow/core/kernels/quantized_bias_add_op.cc": [
          "File: tensorflow/core/kernels/quantized_bias_add_op.cc -> tensorflow/core/kernels/quantized_bias_add_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: #include \"tensorflow/core/framework/numeric_op.h\"",
          "21: #include \"tensorflow/core/framework/op_kernel.h\"",
          "22: #include \"tensorflow/core/framework/tensor.h\"",
          "23: #include \"tensorflow/core/kernels/meta_support.h\"",
          "24: #include \"tensorflow/core/kernels/ops_util.h\"",
          "25: #include \"tensorflow/core/kernels/quantization_utils.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "23: #include \"tensorflow/core/framework/tensor_shape.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "38:   void Compute(OpKernelContext* context) override {",
          "39:     const Tensor& input = context->input(0);",
          "40:     const Tensor& bias = context->input(1);",
          "46:     OP_REQUIRES(context, TensorShapeUtils::IsMatrixOrHigher(input.shape()),",
          "47:                 errors::InvalidArgument(\"Input tensor must be at least 2D: \",",
          "",
          "[Removed Lines]",
          "41:     const float input_min = context->input(2).flat<float>()(0);",
          "42:     const float input_max = context->input(3).flat<float>()(0);",
          "43:     const float bias_min = context->input(4).flat<float>()(0);",
          "44:     const float bias_max = context->input(5).flat<float>()(0);",
          "",
          "[Added Lines]",
          "43:     const Tensor& min_input = context->input(2);",
          "44:     const Tensor& max_input = context->input(3);",
          "45:     const Tensor& min_bias = context->input(4);",
          "46:     const Tensor& max_bias = context->input(5);",
          "47:     OP_REQUIRES(",
          "48:         context, TensorShapeUtils::IsScalar(min_input.shape()),",
          "49:         errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",",
          "50:                                 min_input.dims()));",
          "51:     OP_REQUIRES(",
          "52:         context, TensorShapeUtils::IsScalar(max_input.shape()),",
          "53:         errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",",
          "54:                                 max_input.dims()));",
          "55:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_bias.shape()),",
          "56:                 errors::InvalidArgument(",
          "57:                     \"`min_bias` must be rank 0 but is rank \", min_bias.dims()));",
          "58:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_bias.shape()),",
          "59:                 errors::InvalidArgument(",
          "60:                     \"`max_bias` must be rank 0 but is rank \", max_bias.dims()));",
          "62:     const float input_min = min_input.flat<float>()(0);",
          "63:     const float input_max = max_input.flat<float>()(0);",
          "64:     const float bias_min = min_bias.flat<float>()(0);",
          "65:     const float bias_max = max_bias.flat<float>()(0);",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/quantized_bias_add_op_test.cc||tensorflow/core/kernels/quantized_bias_add_op_test.cc": [
          "File: tensorflow/core/kernels/quantized_bias_add_op_test.cc -> tensorflow/core/kernels/quantized_bias_add_op_test.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "74:                             input_quantized.flat<quint8>());",
          "75:   AddInputFromArray<quint8>(bias_quantized.shape(),",
          "76:                             bias_quantized.flat<quint8>());",
          "81:   TF_ASSERT_OK(RunOpKernel());",
          "82:   const Tensor& output_quantized = *GetOutput(0);",
          "83:   const float output_min = GetOutput(1)->flat<float>()(0);",
          "",
          "[Removed Lines]",
          "77:   AddInputFromArray<float>(TensorShape({1}), {input_min});",
          "78:   AddInputFromArray<float>(TensorShape({1}), {input_max});",
          "79:   AddInputFromArray<float>(TensorShape({1}), {bias_min});",
          "80:   AddInputFromArray<float>(TensorShape({1}), {bias_max});",
          "",
          "[Added Lines]",
          "77:   AddInputFromArray<float>(TensorShape({}), {input_min});",
          "78:   AddInputFromArray<float>(TensorShape({}), {input_max});",
          "79:   AddInputFromArray<float>(TensorShape({}), {bias_min});",
          "80:   AddInputFromArray<float>(TensorShape({}), {bias_max});",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "156:                             input_quantized.flat<quint8>());",
          "157:   AddInputFromArray<quint8>(bias_quantized.shape(),",
          "158:                             bias_quantized.flat<quint8>());",
          "163:   TF_ASSERT_OK(RunOpKernel());",
          "164:   const Tensor& output_quantized = *GetOutput(0);",
          "165:   const float output_min = GetOutput(1)->flat<float>()(0);",
          "",
          "[Removed Lines]",
          "159:   AddInputFromArray<float>(TensorShape({1}), {input_min});",
          "160:   AddInputFromArray<float>(TensorShape({1}), {input_max});",
          "161:   AddInputFromArray<float>(TensorShape({1}), {bias_min});",
          "162:   AddInputFromArray<float>(TensorShape({1}), {bias_max});",
          "",
          "[Added Lines]",
          "159:   AddInputFromArray<float>(TensorShape({}), {input_min});",
          "160:   AddInputFromArray<float>(TensorShape({}), {input_max});",
          "161:   AddInputFromArray<float>(TensorShape({}), {bias_min});",
          "162:   AddInputFromArray<float>(TensorShape({}), {bias_max});",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/quantized_instance_norm.cc||tensorflow/core/kernels/quantized_instance_norm.cc": [
          "File: tensorflow/core/kernels/quantized_instance_norm.cc -> tensorflow/core/kernels/quantized_instance_norm.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "25: #include \"tensorflow/core/framework/op_kernel.h\"",
          "26: #include \"tensorflow/core/framework/register_types.h\"",
          "27: #include \"tensorflow/core/framework/tensor.h\"",
          "29: #include \"tensorflow/core/kernels/quantization_utils.h\"",
          "31: #ifdef USE_NEON",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "28: #include \"tensorflow/core/framework/tensor_shape.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "274:   void Compute(OpKernelContext* context) override {",
          "275:     const Tensor& input = context->input(0);",
          "279:     float input_scale = (input_max - input_min) / 255.0f;",
          "281:     OP_REQUIRES(context, input_min < input_max,",
          "",
          "[Removed Lines]",
          "277:     float input_min = context->input(1).flat<float>()(0);",
          "278:     float input_max = context->input(2).flat<float>()(0);",
          "",
          "[Added Lines]",
          "277:     const Tensor& x_min = context->input(1);",
          "278:     const Tensor& x_max = context->input(2);",
          "279:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(x_min.shape()),",
          "280:                 errors::InvalidArgument(\"`x_min` must be rank 0 but is rank \",",
          "281:                                         x_min.dims()));",
          "282:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(x_max.shape()),",
          "283:                 errors::InvalidArgument(\"`x_max` must be rank 0 but is rank \",",
          "284:                                         x_max.dims()));",
          "285:     float input_min = x_min.scalar<float>()();",
          "286:     float input_max = x_max.scalar<float>()();",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/requantize.cc||tensorflow/core/kernels/requantize.cc": [
          "File: tensorflow/core/kernels/requantize.cc -> tensorflow/core/kernels/requantize.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: #define EIGEN_USE_THREADS",
          "20: #include <math.h>",
          "22: #include \"tensorflow/core/framework/op.h\"",
          "23: #include \"tensorflow/core/framework/op_kernel.h\"",
          "24: #include \"tensorflow/core/framework/type_traits.h\"",
          "25: #include \"tensorflow/core/framework/types.h\"",
          "26: #include \"tensorflow/core/kernels/meta_support.h\"",
          "",
          "[Removed Lines]",
          "21: #include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"",
          "",
          "[Added Lines]",
          "24: #include \"tensorflow/core/framework/tensor.h\"",
          "25: #include \"tensorflow/core/framework/tensor_shape.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "39:   void Compute(OpKernelContext* ctx) override {",
          "40:     const Tensor& input = ctx->input(0);",
          "46:     Tensor* output = nullptr;",
          "47:     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
          "",
          "[Removed Lines]",
          "41:     const float input_min_float = ctx->input(1).flat<float>()(0);",
          "42:     const float input_max_float = ctx->input(2).flat<float>()(0);",
          "43:     const float requested_output_min_float = ctx->input(3).flat<float>()(0);",
          "44:     const float requested_output_max_float = ctx->input(4).flat<float>()(0);",
          "",
          "[Added Lines]",
          "44:     const Tensor& input_min = ctx->input(1);",
          "45:     const Tensor& input_max = ctx->input(2);",
          "46:     const Tensor& requested_output_min = ctx->input(3);",
          "47:     const Tensor& requested_output_max = ctx->input(4);",
          "48:     OP_REQUIRES(",
          "49:         ctx, TensorShapeUtils::IsScalar(input_min.shape()),",
          "50:         errors::InvalidArgument(\"`input_min` must be rank 0 but is rank \",",
          "51:                                 input_min.dims()));",
          "52:     OP_REQUIRES(",
          "53:         ctx, TensorShapeUtils::IsScalar(input_max.shape()),",
          "54:         errors::InvalidArgument(\"`input_max` must be rank 0 but is rank \",",
          "55:                                 input_max.dims()));",
          "56:     OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_min.shape()),",
          "57:                 errors::InvalidArgument(",
          "58:                     \"`requested_output_min` must be rank 0 but is rank \",",
          "59:                     requested_output_min.dims()));",
          "60:     OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_max.shape()),",
          "61:                 errors::InvalidArgument(",
          "62:                     \"`requested_output_max` must be rank 0 but is rank \",",
          "63:                     requested_output_max.dims()));",
          "65:     const float input_min_float = input_min.flat<float>()(0);",
          "66:     const float input_max_float = input_max.flat<float>()(0);",
          "67:     const float requested_output_min_float =",
          "68:         requested_output_min.flat<float>()(0);",
          "69:     const float requested_output_max_float =",
          "70:         requested_output_max.flat<float>()(0);",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/requantize_op_test.cc||tensorflow/core/kernels/requantize_op_test.cc": [
          "File: tensorflow/core/kernels/requantize_op_test.cc -> tensorflow/core/kernels/requantize_op_test.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "54:   AddInputFromArray<qint32>(TensorShape({value_count}),",
          "55:                             {-(1 << 23), 0, (1 << 23)});",
          "60:   TF_ASSERT_OK(RunOpKernel());",
          "61:   Tensor expected(allocator(), DT_QUINT8, TensorShape({value_count}));",
          "62:   test::FillValues<quint8>(&expected, {0, 128, 255});",
          "",
          "[Removed Lines]",
          "56:   AddInputFromArray<float>(TensorShape({1}), {-256.0f});",
          "57:   AddInputFromArray<float>(TensorShape({1}), {256.0f});",
          "58:   AddInputFromArray<float>(TensorShape({1}), {-1.0f});",
          "59:   AddInputFromArray<float>(TensorShape({1}), {1.0f});",
          "",
          "[Added Lines]",
          "56:   AddInputFromArray<float>(TensorShape({}), {-256.0f});",
          "57:   AddInputFromArray<float>(TensorShape({}), {256.0f});",
          "58:   AddInputFromArray<float>(TensorShape({}), {-1.0f});",
          "59:   AddInputFromArray<float>(TensorShape({}), {1.0f});",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "72:   AddInputFromArray<qint32>(TensorShape({value_count}),",
          "73:                             {-(1 << 23), 0, (1 << 23)});",
          "78:   EXPECT_EQ(\"requested_output_min must be <= 0, but got 0.01\",",
          "79:             RunOpKernel().error_message());",
          "80: }",
          "",
          "[Removed Lines]",
          "74:   AddInputFromArray<float>(TensorShape({1}), {-256.0f});",
          "75:   AddInputFromArray<float>(TensorShape({1}), {256.0f});",
          "76:   AddInputFromArray<float>(TensorShape({1}), {0.01f});",
          "77:   AddInputFromArray<float>(TensorShape({1}), {1.0f});",
          "",
          "[Added Lines]",
          "74:   AddInputFromArray<float>(TensorShape({}), {-256.0f});",
          "75:   AddInputFromArray<float>(TensorShape({}), {256.0f});",
          "76:   AddInputFromArray<float>(TensorShape({}), {0.01f});",
          "77:   AddInputFromArray<float>(TensorShape({}), {1.0f});",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "86:   AddInputFromArray<qint32>(TensorShape({value_count}),",
          "87:                             {-(1 << 23), 0, (1 << 23)});",
          "92:   EXPECT_EQ(",
          "93:       \"requested_output_max must be >= requested_output_min, but got -11 and \"",
          "94:       \"-10\",",
          "",
          "[Removed Lines]",
          "88:   AddInputFromArray<float>(TensorShape({1}), {-256.0f});",
          "89:   AddInputFromArray<float>(TensorShape({1}), {256.0f});",
          "90:   AddInputFromArray<float>(TensorShape({1}), {-10.0f});",
          "91:   AddInputFromArray<float>(TensorShape({1}), {-11.0f});",
          "",
          "[Added Lines]",
          "88:   AddInputFromArray<float>(TensorShape({}), {-256.0f});",
          "89:   AddInputFromArray<float>(TensorShape({}), {256.0f});",
          "90:   AddInputFromArray<float>(TensorShape({}), {-10.0f});",
          "91:   AddInputFromArray<float>(TensorShape({}), {-11.0f});",
          "",
          "---------------"
        ],
        "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py": [
          "File: tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py -> tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: # Copyright 2015 The TensorFlow Authors. All Rights Reserved.",
          "2: #",
          "3: # Licensed under the Apache License, Version 2.0 (the \"License\");",
          "4: # you may not use this file except in compliance with the License.",
          "5: # You may obtain a copy of the License at",
          "6: #",
          "7: #     http://www.apache.org/licenses/LICENSE-2.0",
          "8: #",
          "9: # Unless required by applicable law or agreed to in writing, software",
          "10: # distributed under the License is distributed on an \"AS IS\" BASIS,",
          "11: # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
          "12: # See the License for the specific language governing permissions and",
          "13: # limitations under the License.",
          "14: # ==============================================================================",
          "15: \"\"\"Tests for tf.quantize ops.\"\"\"",
          "16: import numpy as np",
          "18: from tensorflow.python.framework import constant_op",
          "19: from tensorflow.python.framework import dtypes",
          "20: from tensorflow.python.framework import errors",
          "21: from tensorflow.python.framework import test_util",
          "22: from tensorflow.python.ops import array_ops",
          "23: from tensorflow.python.ops import math_ops",
          "24: from tensorflow.python.ops import nn_ops",
          "25: from tensorflow.python.platform import googletest",
          "28: class FakeQuantWithMinMaxVarsOpTest(test_util.TensorFlowTestCase):",
          "30:   @test_util.run_in_graph_and_eager_modes",
          "31:   def test_invalid_inputs(self):",
          "32:     inputs = constant_op.constant(",
          "33:         value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
          "35:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "36:                                 \"must be rank 0\"):",
          "37:       self.evaluate(",
          "38:           array_ops.fake_quant_with_min_max_vars(",
          "39:               inputs=inputs, min=0.0, max=[[1.0], [2.0], [4.0]]))",
          "41:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "42:                                 \"must be rank 0\"):",
          "43:       self.evaluate(",
          "44:           array_ops.fake_quant_with_min_max_vars(",
          "45:               inputs=inputs, min=[[1.0], [2.0], [4.0]], max=1.0))",
          "48: class FakeQuantWithMinMaxVarsPerChannelOpTest(test_util.TensorFlowTestCase):",
          "50:   @test_util.run_in_graph_and_eager_modes",
          "51:   def test_invalid_inputs(self):",
          "52:     inputs = constant_op.constant(",
          "53:         value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
          "55:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "56:                                 \"must be rank 1\"):",
          "57:       self.evaluate(",
          "58:           array_ops.fake_quant_with_min_max_vars_per_channel(",
          "59:               inputs=inputs, min=[[0.0]], max=[1.0]))",
          "61:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "62:                                 \"Dimensions must be equal|incorrect size\"):",
          "63:       self.evaluate(",
          "64:           array_ops.fake_quant_with_min_max_vars_per_channel(",
          "65:               inputs=inputs, min=[0.0, 0.1], max=[1.0]))",
          "67:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "68:                                 \"must be rank 1\"):",
          "69:       self.evaluate(",
          "70:           array_ops.fake_quant_with_min_max_vars_per_channel(",
          "71:               inputs=inputs, min=[1.0], max=[[1.0]]))",
          "73:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "74:                                 \"Dimensions must be equal|incorrect size\"):",
          "75:       self.evaluate(",
          "76:           array_ops.fake_quant_with_min_max_vars_per_channel(",
          "77:               inputs=inputs, min=[0.0], max=[1.0, 1.1]))",
          "80: class QuantizedBiasedAddTest(test_util.TensorFlowTestCase):",
          "82:   @test_util.run_in_graph_and_eager_modes",
          "83:   def test_invalid_inputs(self):",
          "84:     inputs = constant_op.constant(",
          "85:         np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.qint8)",
          "86:     bias = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.qint8)",
          "88:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "89:                                 \"must be rank 0\"):",
          "90:       self.evaluate(",
          "91:           nn_ops.quantized_bias_add(",
          "92:               input=inputs,",
          "93:               bias=bias,",
          "94:               min_input=[],",
          "95:               max_input=1.0,",
          "96:               min_bias=0.0,",
          "97:               max_bias=1.0,",
          "98:               out_type=dtypes.qint32))",
          "100:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "101:                                 \"must be rank 0\"):",
          "102:       self.evaluate(",
          "103:           nn_ops.quantized_bias_add(",
          "104:               input=inputs,",
          "105:               bias=bias,",
          "106:               min_input=0.0,",
          "107:               max_input=[],",
          "108:               min_bias=0.0,",
          "109:               max_bias=1.0,",
          "110:               out_type=dtypes.qint32))",
          "112:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "113:                                 \"must be rank 0\"):",
          "114:       self.evaluate(",
          "115:           nn_ops.quantized_bias_add(",
          "116:               input=inputs,",
          "117:               bias=bias,",
          "118:               min_input=0.0,",
          "119:               max_input=1.0,",
          "120:               min_bias=[],",
          "121:               max_bias=1.0,",
          "122:               out_type=dtypes.qint32))",
          "124:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "125:                                 \"must be rank 0\"):",
          "126:       self.evaluate(",
          "127:           nn_ops.quantized_bias_add(",
          "128:               input=inputs,",
          "129:               bias=bias,",
          "130:               min_input=0.0,",
          "131:               max_input=1.0,",
          "132:               min_bias=0.0,",
          "133:               max_bias=[],",
          "134:               out_type=dtypes.qint32))",
          "137: class QuantizedInstanceNormOpTest(test_util.TensorFlowTestCase):",
          "139:   @test_util.run_in_graph_and_eager_modes",
          "140:   def test_invalid_inputs(self):",
          "141:     inputs = constant_op.constant(",
          "142:         np.uint8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)",
          "144:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "145:                                 \"must be rank 0\"):",
          "146:       self.evaluate(",
          "147:           array_ops.quantized_instance_norm(",
          "148:               x=inputs, x_min=0.0, x_max=[[1.0], [2.0], [4.0]]))",
          "150:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "151:                                 \"must be rank 0\"):",
          "152:       self.evaluate(",
          "153:           array_ops.quantized_instance_norm(",
          "154:               x=inputs, x_min=[[1.0], [2.0], [4.0]], x_max=1.0))",
          "157: class RequantizeOpTest(test_util.TensorFlowTestCase):",
          "159:   @test_util.run_in_graph_and_eager_modes",
          "160:   def test_invalid_inputs(self):",
          "161:     inputs = constant_op.constant(",
          "162:         np.int32(0), shape=[3, 3, 3, 3], dtype=dtypes.qint32)",
          "164:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "165:                                 \"must be rank 0\"):",
          "166:       self.evaluate(",
          "167:           math_ops.requantize(",
          "168:               input=inputs,",
          "169:               input_min=[],",
          "170:               input_max=1.0,",
          "171:               requested_output_min=0.0,",
          "172:               requested_output_max=1.0,",
          "173:               out_type=dtypes.qint8))",
          "175:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "176:                                 \"must be rank 0\"):",
          "177:       self.evaluate(",
          "178:           math_ops.requantize(",
          "179:               input=inputs,",
          "180:               input_min=0.0,",
          "181:               input_max=[],",
          "182:               requested_output_min=0.0,",
          "183:               requested_output_max=1.0,",
          "184:               out_type=dtypes.qint8))",
          "186:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "187:                                 \"must be rank 0\"):",
          "188:       self.evaluate(",
          "189:           math_ops.requantize(",
          "190:               input=inputs,",
          "191:               input_min=0.0,",
          "192:               input_max=1.0,",
          "193:               requested_output_min=[],",
          "194:               requested_output_max=1.0,",
          "195:               out_type=dtypes.qint8))",
          "197:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "198:                                 \"must be rank 0\"):",
          "199:       self.evaluate(",
          "200:           math_ops.requantize(",
          "201:               input=inputs,",
          "202:               input_min=0.0,",
          "203:               input_max=1.0,",
          "204:               requested_output_min=0.0,",
          "205:               requested_output_max=[],",
          "206:               out_type=dtypes.qint8))",
          "209: if __name__ == \"__main__\":",
          "210:   googletest.main()",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "4b4f8c9f33e8216331233e30cd27bc72b803ff1a",
      "candidate_info": {
        "commit_hash": "4b4f8c9f33e8216331233e30cd27bc72b803ff1a",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/4b4f8c9f33e8216331233e30cd27bc72b803ff1a",
        "files": [
          "tensorflow/core/kernels/fake_quant_ops.cc",
          "tensorflow/core/kernels/quantized_bias_add_op.cc",
          "tensorflow/core/kernels/quantized_bias_add_op_test.cc",
          "tensorflow/core/kernels/quantized_instance_norm.cc",
          "tensorflow/core/kernels/requantize.cc",
          "tensorflow/core/kernels/requantize_op_test.cc",
          "tensorflow/python/kernel_tests/quantization_ops/BUILD",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ],
        "message": "Fix quantize ops input validation issues.\n\nThe majority of these are just missing checks on min/max.\n\nPiperOrigin-RevId: 461800665",
        "before_after_code_files": [
          "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc",
          "tensorflow/core/kernels/quantized_bias_add_op.cc||tensorflow/core/kernels/quantized_bias_add_op.cc",
          "tensorflow/core/kernels/quantized_bias_add_op_test.cc||tensorflow/core/kernels/quantized_bias_add_op_test.cc",
          "tensorflow/core/kernels/quantized_instance_norm.cc||tensorflow/core/kernels/quantized_instance_norm.cc",
          "tensorflow/core/kernels/requantize.cc||tensorflow/core/kernels/requantize.cc",
          "tensorflow/core/kernels/requantize_op_test.cc||tensorflow/core/kernels/requantize_op_test.cc",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc",
            "tensorflow/core/kernels/quantized_bias_add_op.cc||tensorflow/core/kernels/quantized_bias_add_op.cc",
            "tensorflow/core/kernels/quantized_bias_add_op_test.cc||tensorflow/core/kernels/quantized_bias_add_op_test.cc",
            "tensorflow/core/kernels/quantized_instance_norm.cc||tensorflow/core/kernels/quantized_instance_norm.cc",
            "tensorflow/core/kernels/requantize.cc||tensorflow/core/kernels/requantize.cc",
            "tensorflow/core/kernels/requantize_op_test.cc||tensorflow/core/kernels/requantize_op_test.cc",
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ],
          "candidate": [
            "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc",
            "tensorflow/core/kernels/quantized_bias_add_op.cc||tensorflow/core/kernels/quantized_bias_add_op.cc",
            "tensorflow/core/kernels/quantized_bias_add_op_test.cc||tensorflow/core/kernels/quantized_bias_add_op_test.cc",
            "tensorflow/core/kernels/quantized_instance_norm.cc||tensorflow/core/kernels/quantized_instance_norm.cc",
            "tensorflow/core/kernels/requantize.cc||tensorflow/core/kernels/requantize.cc",
            "tensorflow/core/kernels/requantize_op_test.cc||tensorflow/core/kernels/requantize_op_test.cc",
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc": [
          "File: tensorflow/core/kernels/fake_quant_ops.cc -> tensorflow/core/kernels/fake_quant_ops.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "25: #include \"tensorflow/core/framework/numeric_op.h\"",
          "26: #include \"tensorflow/core/framework/tensor.h\"",
          "27: #include \"tensorflow/core/lib/core/errors.h\"",
          "28: #include \"tensorflow/core/lib/monitoring/gauge.h\"",
          "29: #include \"tensorflow/core/platform/protobuf.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "27: #include \"tensorflow/core/framework/tensor_shape.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "204:     const Tensor& min = context->input(1);",
          "205:     const Tensor& max = context->input(2);",
          "207:     Tensor* output;",
          "208:     OP_REQUIRES_OK(context,",
          "209:                    context->allocate_output(0, input.shape(), &output));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "208:     OP_REQUIRES(",
          "209:         context, TensorShapeUtils::IsScalar(min.shape()),",
          "210:         InvalidArgument(\"`min` must be rank 0 but is rank \", min.dims()));",
          "211:     OP_REQUIRES(",
          "212:         context, TensorShapeUtils::IsScalar(max.shape()),",
          "213:         InvalidArgument(\"`max` must be rank 0 but is rank \", max.dims()));",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "334:     const Tensor& input = context->input(0);",
          "335:     const int depth = input.dim_size(input.dims() - 1);  // last dimension size.",
          "336:     const Tensor& min = context->input(1);",
          "337:     OP_REQUIRES(context, min.dim_size(0) == depth,",
          "338:                 InvalidArgument(\"min has incorrect size, expected \", depth,",
          "339:                                 \" was \", min.dim_size(0)));",
          "341:     OP_REQUIRES(context, max.dim_size(0) == depth,",
          "342:                 InvalidArgument(\"max has incorrect size, expected \", depth,",
          "343:                                 \" was \", max.dim_size(0)));",
          "",
          "[Removed Lines]",
          "340:     const Tensor& max = context->input(2);",
          "",
          "[Added Lines]",
          "345:     const Tensor& max = context->input(2);",
          "347:     OP_REQUIRES(",
          "348:         context, TensorShapeUtils::IsVector(min.shape()),",
          "349:         InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));",
          "353:     OP_REQUIRES(",
          "354:         context, TensorShapeUtils::IsVector(max.shape()),",
          "355:         InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/quantized_bias_add_op.cc||tensorflow/core/kernels/quantized_bias_add_op.cc": [
          "File: tensorflow/core/kernels/quantized_bias_add_op.cc -> tensorflow/core/kernels/quantized_bias_add_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: #include \"tensorflow/core/framework/numeric_op.h\"",
          "21: #include \"tensorflow/core/framework/op_kernel.h\"",
          "22: #include \"tensorflow/core/framework/tensor.h\"",
          "23: #include \"tensorflow/core/kernels/meta_support.h\"",
          "24: #include \"tensorflow/core/kernels/ops_util.h\"",
          "25: #include \"tensorflow/core/kernels/quantization_utils.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "23: #include \"tensorflow/core/framework/tensor_shape.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "38:   void Compute(OpKernelContext* context) override {",
          "39:     const Tensor& input = context->input(0);",
          "40:     const Tensor& bias = context->input(1);",
          "46:     OP_REQUIRES(context, TensorShapeUtils::IsMatrixOrHigher(input.shape()),",
          "47:                 errors::InvalidArgument(\"Input tensor must be at least 2D: \",",
          "",
          "[Removed Lines]",
          "41:     const float input_min = context->input(2).flat<float>()(0);",
          "42:     const float input_max = context->input(3).flat<float>()(0);",
          "43:     const float bias_min = context->input(4).flat<float>()(0);",
          "44:     const float bias_max = context->input(5).flat<float>()(0);",
          "",
          "[Added Lines]",
          "43:     const Tensor& min_input = context->input(2);",
          "44:     const Tensor& max_input = context->input(3);",
          "45:     const Tensor& min_bias = context->input(4);",
          "46:     const Tensor& max_bias = context->input(5);",
          "47:     OP_REQUIRES(",
          "48:         context, TensorShapeUtils::IsScalar(min_input.shape()),",
          "49:         errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",",
          "50:                                 min_input.dims()));",
          "51:     OP_REQUIRES(",
          "52:         context, TensorShapeUtils::IsScalar(max_input.shape()),",
          "53:         errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",",
          "54:                                 max_input.dims()));",
          "55:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_bias.shape()),",
          "56:                 errors::InvalidArgument(",
          "57:                     \"`min_bias` must be rank 0 but is rank \", min_bias.dims()));",
          "58:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_bias.shape()),",
          "59:                 errors::InvalidArgument(",
          "60:                     \"`max_bias` must be rank 0 but is rank \", max_bias.dims()));",
          "62:     const float input_min = min_input.flat<float>()(0);",
          "63:     const float input_max = max_input.flat<float>()(0);",
          "64:     const float bias_min = min_bias.flat<float>()(0);",
          "65:     const float bias_max = max_bias.flat<float>()(0);",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/quantized_bias_add_op_test.cc||tensorflow/core/kernels/quantized_bias_add_op_test.cc": [
          "File: tensorflow/core/kernels/quantized_bias_add_op_test.cc -> tensorflow/core/kernels/quantized_bias_add_op_test.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "74:                             input_quantized.flat<quint8>());",
          "75:   AddInputFromArray<quint8>(bias_quantized.shape(),",
          "76:                             bias_quantized.flat<quint8>());",
          "81:   TF_ASSERT_OK(RunOpKernel());",
          "82:   const Tensor& output_quantized = *GetOutput(0);",
          "83:   const float output_min = GetOutput(1)->flat<float>()(0);",
          "",
          "[Removed Lines]",
          "77:   AddInputFromArray<float>(TensorShape({1}), {input_min});",
          "78:   AddInputFromArray<float>(TensorShape({1}), {input_max});",
          "79:   AddInputFromArray<float>(TensorShape({1}), {bias_min});",
          "80:   AddInputFromArray<float>(TensorShape({1}), {bias_max});",
          "",
          "[Added Lines]",
          "77:   AddInputFromArray<float>(TensorShape({}), {input_min});",
          "78:   AddInputFromArray<float>(TensorShape({}), {input_max});",
          "79:   AddInputFromArray<float>(TensorShape({}), {bias_min});",
          "80:   AddInputFromArray<float>(TensorShape({}), {bias_max});",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "156:                             input_quantized.flat<quint8>());",
          "157:   AddInputFromArray<quint8>(bias_quantized.shape(),",
          "158:                             bias_quantized.flat<quint8>());",
          "163:   TF_ASSERT_OK(RunOpKernel());",
          "164:   const Tensor& output_quantized = *GetOutput(0);",
          "165:   const float output_min = GetOutput(1)->flat<float>()(0);",
          "",
          "[Removed Lines]",
          "159:   AddInputFromArray<float>(TensorShape({1}), {input_min});",
          "160:   AddInputFromArray<float>(TensorShape({1}), {input_max});",
          "161:   AddInputFromArray<float>(TensorShape({1}), {bias_min});",
          "162:   AddInputFromArray<float>(TensorShape({1}), {bias_max});",
          "",
          "[Added Lines]",
          "159:   AddInputFromArray<float>(TensorShape({}), {input_min});",
          "160:   AddInputFromArray<float>(TensorShape({}), {input_max});",
          "161:   AddInputFromArray<float>(TensorShape({}), {bias_min});",
          "162:   AddInputFromArray<float>(TensorShape({}), {bias_max});",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/quantized_instance_norm.cc||tensorflow/core/kernels/quantized_instance_norm.cc": [
          "File: tensorflow/core/kernels/quantized_instance_norm.cc -> tensorflow/core/kernels/quantized_instance_norm.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "25: #include \"tensorflow/core/framework/op_kernel.h\"",
          "26: #include \"tensorflow/core/framework/register_types.h\"",
          "27: #include \"tensorflow/core/framework/tensor.h\"",
          "29: #include \"tensorflow/core/kernels/quantization_utils.h\"",
          "31: #ifdef USE_NEON",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "28: #include \"tensorflow/core/framework/tensor_shape.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "274:   void Compute(OpKernelContext* context) override {",
          "275:     const Tensor& input = context->input(0);",
          "279:     float input_scale = (input_max - input_min) / 255.0f;",
          "281:     OP_REQUIRES(context, input_min < input_max,",
          "",
          "[Removed Lines]",
          "277:     float input_min = context->input(1).flat<float>()(0);",
          "278:     float input_max = context->input(2).flat<float>()(0);",
          "",
          "[Added Lines]",
          "277:     const Tensor& x_min = context->input(1);",
          "278:     const Tensor& x_max = context->input(2);",
          "279:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(x_min.shape()),",
          "280:                 errors::InvalidArgument(\"`x_min` must be rank 0 but is rank \",",
          "281:                                         x_min.dims()));",
          "282:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(x_max.shape()),",
          "283:                 errors::InvalidArgument(\"`x_max` must be rank 0 but is rank \",",
          "284:                                         x_max.dims()));",
          "285:     float input_min = x_min.scalar<float>()();",
          "286:     float input_max = x_max.scalar<float>()();",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/requantize.cc||tensorflow/core/kernels/requantize.cc": [
          "File: tensorflow/core/kernels/requantize.cc -> tensorflow/core/kernels/requantize.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: #define EIGEN_USE_THREADS",
          "20: #include <math.h>",
          "22: #include \"tensorflow/core/framework/op.h\"",
          "23: #include \"tensorflow/core/framework/op_kernel.h\"",
          "24: #include \"tensorflow/core/framework/type_traits.h\"",
          "25: #include \"tensorflow/core/framework/types.h\"",
          "26: #include \"tensorflow/core/kernels/meta_support.h\"",
          "",
          "[Removed Lines]",
          "21: #include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"",
          "",
          "[Added Lines]",
          "24: #include \"tensorflow/core/framework/tensor.h\"",
          "25: #include \"tensorflow/core/framework/tensor_shape.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "39:   void Compute(OpKernelContext* ctx) override {",
          "40:     const Tensor& input = ctx->input(0);",
          "46:     Tensor* output = nullptr;",
          "47:     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
          "",
          "[Removed Lines]",
          "41:     const float input_min_float = ctx->input(1).flat<float>()(0);",
          "42:     const float input_max_float = ctx->input(2).flat<float>()(0);",
          "43:     const float requested_output_min_float = ctx->input(3).flat<float>()(0);",
          "44:     const float requested_output_max_float = ctx->input(4).flat<float>()(0);",
          "",
          "[Added Lines]",
          "44:     const Tensor& input_min = ctx->input(1);",
          "45:     const Tensor& input_max = ctx->input(2);",
          "46:     const Tensor& requested_output_min = ctx->input(3);",
          "47:     const Tensor& requested_output_max = ctx->input(4);",
          "48:     OP_REQUIRES(",
          "49:         ctx, TensorShapeUtils::IsScalar(input_min.shape()),",
          "50:         errors::InvalidArgument(\"`input_min` must be rank 0 but is rank \",",
          "51:                                 input_min.dims()));",
          "52:     OP_REQUIRES(",
          "53:         ctx, TensorShapeUtils::IsScalar(input_max.shape()),",
          "54:         errors::InvalidArgument(\"`input_max` must be rank 0 but is rank \",",
          "55:                                 input_max.dims()));",
          "56:     OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_min.shape()),",
          "57:                 errors::InvalidArgument(",
          "58:                     \"`requested_output_min` must be rank 0 but is rank \",",
          "59:                     requested_output_min.dims()));",
          "60:     OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_max.shape()),",
          "61:                 errors::InvalidArgument(",
          "62:                     \"`requested_output_max` must be rank 0 but is rank \",",
          "63:                     requested_output_max.dims()));",
          "65:     const float input_min_float = input_min.flat<float>()(0);",
          "66:     const float input_max_float = input_max.flat<float>()(0);",
          "67:     const float requested_output_min_float =",
          "68:         requested_output_min.flat<float>()(0);",
          "69:     const float requested_output_max_float =",
          "70:         requested_output_max.flat<float>()(0);",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/requantize_op_test.cc||tensorflow/core/kernels/requantize_op_test.cc": [
          "File: tensorflow/core/kernels/requantize_op_test.cc -> tensorflow/core/kernels/requantize_op_test.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "54:   AddInputFromArray<qint32>(TensorShape({value_count}),",
          "55:                             {-(1 << 23), 0, (1 << 23)});",
          "60:   TF_ASSERT_OK(RunOpKernel());",
          "61:   Tensor expected(allocator(), DT_QUINT8, TensorShape({value_count}));",
          "62:   test::FillValues<quint8>(&expected, {0, 128, 255});",
          "",
          "[Removed Lines]",
          "56:   AddInputFromArray<float>(TensorShape({1}), {-256.0f});",
          "57:   AddInputFromArray<float>(TensorShape({1}), {256.0f});",
          "58:   AddInputFromArray<float>(TensorShape({1}), {-1.0f});",
          "59:   AddInputFromArray<float>(TensorShape({1}), {1.0f});",
          "",
          "[Added Lines]",
          "56:   AddInputFromArray<float>(TensorShape({}), {-256.0f});",
          "57:   AddInputFromArray<float>(TensorShape({}), {256.0f});",
          "58:   AddInputFromArray<float>(TensorShape({}), {-1.0f});",
          "59:   AddInputFromArray<float>(TensorShape({}), {1.0f});",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "72:   AddInputFromArray<qint32>(TensorShape({value_count}),",
          "73:                             {-(1 << 23), 0, (1 << 23)});",
          "78:   EXPECT_EQ(\"requested_output_min must be <= 0, but got 0.01\",",
          "79:             RunOpKernel().error_message());",
          "80: }",
          "",
          "[Removed Lines]",
          "74:   AddInputFromArray<float>(TensorShape({1}), {-256.0f});",
          "75:   AddInputFromArray<float>(TensorShape({1}), {256.0f});",
          "76:   AddInputFromArray<float>(TensorShape({1}), {0.01f});",
          "77:   AddInputFromArray<float>(TensorShape({1}), {1.0f});",
          "",
          "[Added Lines]",
          "74:   AddInputFromArray<float>(TensorShape({}), {-256.0f});",
          "75:   AddInputFromArray<float>(TensorShape({}), {256.0f});",
          "76:   AddInputFromArray<float>(TensorShape({}), {0.01f});",
          "77:   AddInputFromArray<float>(TensorShape({}), {1.0f});",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "86:   AddInputFromArray<qint32>(TensorShape({value_count}),",
          "87:                             {-(1 << 23), 0, (1 << 23)});",
          "92:   EXPECT_EQ(",
          "93:       \"requested_output_max must be >= requested_output_min, but got -11 and \"",
          "94:       \"-10\",",
          "",
          "[Removed Lines]",
          "88:   AddInputFromArray<float>(TensorShape({1}), {-256.0f});",
          "89:   AddInputFromArray<float>(TensorShape({1}), {256.0f});",
          "90:   AddInputFromArray<float>(TensorShape({1}), {-10.0f});",
          "91:   AddInputFromArray<float>(TensorShape({1}), {-11.0f});",
          "",
          "[Added Lines]",
          "88:   AddInputFromArray<float>(TensorShape({}), {-256.0f});",
          "89:   AddInputFromArray<float>(TensorShape({}), {256.0f});",
          "90:   AddInputFromArray<float>(TensorShape({}), {-10.0f});",
          "91:   AddInputFromArray<float>(TensorShape({}), {-11.0f});",
          "",
          "---------------"
        ],
        "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py": [
          "File: tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py -> tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: # Copyright 2015 The TensorFlow Authors. All Rights Reserved.",
          "2: #",
          "3: # Licensed under the Apache License, Version 2.0 (the \"License\");",
          "4: # you may not use this file except in compliance with the License.",
          "5: # You may obtain a copy of the License at",
          "6: #",
          "7: #     http://www.apache.org/licenses/LICENSE-2.0",
          "8: #",
          "9: # Unless required by applicable law or agreed to in writing, software",
          "10: # distributed under the License is distributed on an \"AS IS\" BASIS,",
          "11: # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
          "12: # See the License for the specific language governing permissions and",
          "13: # limitations under the License.",
          "14: # ==============================================================================",
          "15: \"\"\"Tests for tf.quantize ops.\"\"\"",
          "16: import numpy as np",
          "18: from tensorflow.python.framework import constant_op",
          "19: from tensorflow.python.framework import dtypes",
          "20: from tensorflow.python.framework import errors",
          "21: from tensorflow.python.framework import test_util",
          "22: from tensorflow.python.ops import array_ops",
          "23: from tensorflow.python.ops import math_ops",
          "24: from tensorflow.python.ops import nn_ops",
          "25: from tensorflow.python.platform import googletest",
          "28: class FakeQuantWithMinMaxVarsOpTest(test_util.TensorFlowTestCase):",
          "30:   @test_util.run_in_graph_and_eager_modes",
          "31:   def test_invalid_inputs(self):",
          "32:     inputs = constant_op.constant(",
          "33:         value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
          "35:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "36:                                 \"must be rank 0\"):",
          "37:       self.evaluate(",
          "38:           array_ops.fake_quant_with_min_max_vars(",
          "39:               inputs=inputs, min=0.0, max=[[1.0], [2.0], [4.0]]))",
          "41:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "42:                                 \"must be rank 0\"):",
          "43:       self.evaluate(",
          "44:           array_ops.fake_quant_with_min_max_vars(",
          "45:               inputs=inputs, min=[[1.0], [2.0], [4.0]], max=1.0))",
          "48: class FakeQuantWithMinMaxVarsPerChannelOpTest(test_util.TensorFlowTestCase):",
          "50:   @test_util.run_in_graph_and_eager_modes",
          "51:   def test_invalid_inputs(self):",
          "52:     inputs = constant_op.constant(",
          "53:         value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
          "55:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "56:                                 \"must be rank 1\"):",
          "57:       self.evaluate(",
          "58:           array_ops.fake_quant_with_min_max_vars_per_channel(",
          "59:               inputs=inputs, min=[[0.0]], max=[1.0]))",
          "61:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "62:                                 \"Dimensions must be equal|incorrect size\"):",
          "63:       self.evaluate(",
          "64:           array_ops.fake_quant_with_min_max_vars_per_channel(",
          "65:               inputs=inputs, min=[0.0, 0.1], max=[1.0]))",
          "67:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "68:                                 \"must be rank 1\"):",
          "69:       self.evaluate(",
          "70:           array_ops.fake_quant_with_min_max_vars_per_channel(",
          "71:               inputs=inputs, min=[1.0], max=[[1.0]]))",
          "73:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "74:                                 \"Dimensions must be equal|incorrect size\"):",
          "75:       self.evaluate(",
          "76:           array_ops.fake_quant_with_min_max_vars_per_channel(",
          "77:               inputs=inputs, min=[0.0], max=[1.0, 1.1]))",
          "80: class QuantizedBiasedAddTest(test_util.TensorFlowTestCase):",
          "82:   @test_util.run_in_graph_and_eager_modes",
          "83:   def test_invalid_inputs(self):",
          "84:     inputs = constant_op.constant(",
          "85:         np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.qint8)",
          "86:     bias = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.qint8)",
          "88:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "89:                                 \"must be rank 0\"):",
          "90:       self.evaluate(",
          "91:           nn_ops.quantized_bias_add(",
          "92:               input=inputs,",
          "93:               bias=bias,",
          "94:               min_input=[],",
          "95:               max_input=1.0,",
          "96:               min_bias=0.0,",
          "97:               max_bias=1.0,",
          "98:               out_type=dtypes.qint32))",
          "100:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "101:                                 \"must be rank 0\"):",
          "102:       self.evaluate(",
          "103:           nn_ops.quantized_bias_add(",
          "104:               input=inputs,",
          "105:               bias=bias,",
          "106:               min_input=0.0,",
          "107:               max_input=[],",
          "108:               min_bias=0.0,",
          "109:               max_bias=1.0,",
          "110:               out_type=dtypes.qint32))",
          "112:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "113:                                 \"must be rank 0\"):",
          "114:       self.evaluate(",
          "115:           nn_ops.quantized_bias_add(",
          "116:               input=inputs,",
          "117:               bias=bias,",
          "118:               min_input=0.0,",
          "119:               max_input=1.0,",
          "120:               min_bias=[],",
          "121:               max_bias=1.0,",
          "122:               out_type=dtypes.qint32))",
          "124:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "125:                                 \"must be rank 0\"):",
          "126:       self.evaluate(",
          "127:           nn_ops.quantized_bias_add(",
          "128:               input=inputs,",
          "129:               bias=bias,",
          "130:               min_input=0.0,",
          "131:               max_input=1.0,",
          "132:               min_bias=0.0,",
          "133:               max_bias=[],",
          "134:               out_type=dtypes.qint32))",
          "137: class QuantizedInstanceNormOpTest(test_util.TensorFlowTestCase):",
          "139:   @test_util.run_in_graph_and_eager_modes",
          "140:   def test_invalid_inputs(self):",
          "141:     inputs = constant_op.constant(",
          "142:         np.uint8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)",
          "144:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "145:                                 \"must be rank 0\"):",
          "146:       self.evaluate(",
          "147:           array_ops.quantized_instance_norm(",
          "148:               x=inputs, x_min=0.0, x_max=[[1.0], [2.0], [4.0]]))",
          "150:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "151:                                 \"must be rank 0\"):",
          "152:       self.evaluate(",
          "153:           array_ops.quantized_instance_norm(",
          "154:               x=inputs, x_min=[[1.0], [2.0], [4.0]], x_max=1.0))",
          "157: class RequantizeOpTest(test_util.TensorFlowTestCase):",
          "159:   @test_util.run_in_graph_and_eager_modes",
          "160:   def test_invalid_inputs(self):",
          "161:     inputs = constant_op.constant(",
          "162:         np.int32(0), shape=[3, 3, 3, 3], dtype=dtypes.qint32)",
          "164:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "165:                                 \"must be rank 0\"):",
          "166:       self.evaluate(",
          "167:           math_ops.requantize(",
          "168:               input=inputs,",
          "169:               input_min=[],",
          "170:               input_max=1.0,",
          "171:               requested_output_min=0.0,",
          "172:               requested_output_max=1.0,",
          "173:               out_type=dtypes.qint8))",
          "175:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "176:                                 \"must be rank 0\"):",
          "177:       self.evaluate(",
          "178:           math_ops.requantize(",
          "179:               input=inputs,",
          "180:               input_min=0.0,",
          "181:               input_max=[],",
          "182:               requested_output_min=0.0,",
          "183:               requested_output_max=1.0,",
          "184:               out_type=dtypes.qint8))",
          "186:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "187:                                 \"must be rank 0\"):",
          "188:       self.evaluate(",
          "189:           math_ops.requantize(",
          "190:               input=inputs,",
          "191:               input_min=0.0,",
          "192:               input_max=1.0,",
          "193:               requested_output_min=[],",
          "194:               requested_output_max=1.0,",
          "195:               out_type=dtypes.qint8))",
          "197:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "198:                                 \"must be rank 0\"):",
          "199:       self.evaluate(",
          "200:           math_ops.requantize(",
          "201:               input=inputs,",
          "202:               input_min=0.0,",
          "203:               input_max=1.0,",
          "204:               requested_output_min=0.0,",
          "205:               requested_output_max=[],",
          "206:               out_type=dtypes.qint8))",
          "209: if __name__ == \"__main__\":",
          "210:   googletest.main()",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "6840ef99b35ee1d44de559002d3f86813ca9b8d4",
      "candidate_info": {
        "commit_hash": "6840ef99b35ee1d44de559002d3f86813ca9b8d4",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/6840ef99b35ee1d44de559002d3f86813ca9b8d4",
        "files": [
          "tensorflow/core/kernels/fake_quant_ops.cc",
          "tensorflow/core/kernels/quantized_bias_add_op.cc",
          "tensorflow/core/kernels/quantized_bias_add_op_test.cc",
          "tensorflow/core/kernels/quantized_instance_norm.cc",
          "tensorflow/core/kernels/requantize.cc",
          "tensorflow/core/kernels/requantize_op_test.cc",
          "tensorflow/python/kernel_tests/quantization_ops/BUILD",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ],
        "message": "Fix quantize ops input validation issues.\n\nThe majority of these are just missing checks on min/max.\n\nPiperOrigin-RevId: 461800665",
        "before_after_code_files": [
          "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc",
          "tensorflow/core/kernels/quantized_bias_add_op.cc||tensorflow/core/kernels/quantized_bias_add_op.cc",
          "tensorflow/core/kernels/quantized_bias_add_op_test.cc||tensorflow/core/kernels/quantized_bias_add_op_test.cc",
          "tensorflow/core/kernels/quantized_instance_norm.cc||tensorflow/core/kernels/quantized_instance_norm.cc",
          "tensorflow/core/kernels/requantize.cc||tensorflow/core/kernels/requantize.cc",
          "tensorflow/core/kernels/requantize_op_test.cc||tensorflow/core/kernels/requantize_op_test.cc",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc",
            "tensorflow/core/kernels/quantized_bias_add_op.cc||tensorflow/core/kernels/quantized_bias_add_op.cc",
            "tensorflow/core/kernels/quantized_bias_add_op_test.cc||tensorflow/core/kernels/quantized_bias_add_op_test.cc",
            "tensorflow/core/kernels/quantized_instance_norm.cc||tensorflow/core/kernels/quantized_instance_norm.cc",
            "tensorflow/core/kernels/requantize.cc||tensorflow/core/kernels/requantize.cc",
            "tensorflow/core/kernels/requantize_op_test.cc||tensorflow/core/kernels/requantize_op_test.cc",
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ],
          "candidate": [
            "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc",
            "tensorflow/core/kernels/quantized_bias_add_op.cc||tensorflow/core/kernels/quantized_bias_add_op.cc",
            "tensorflow/core/kernels/quantized_bias_add_op_test.cc||tensorflow/core/kernels/quantized_bias_add_op_test.cc",
            "tensorflow/core/kernels/quantized_instance_norm.cc||tensorflow/core/kernels/quantized_instance_norm.cc",
            "tensorflow/core/kernels/requantize.cc||tensorflow/core/kernels/requantize.cc",
            "tensorflow/core/kernels/requantize_op_test.cc||tensorflow/core/kernels/requantize_op_test.cc",
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/fake_quant_ops.cc||tensorflow/core/kernels/fake_quant_ops.cc": [
          "File: tensorflow/core/kernels/fake_quant_ops.cc -> tensorflow/core/kernels/fake_quant_ops.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "25: #include \"tensorflow/core/framework/numeric_op.h\"",
          "26: #include \"tensorflow/core/framework/tensor.h\"",
          "27: #include \"tensorflow/core/lib/core/errors.h\"",
          "28: #include \"tensorflow/core/lib/monitoring/gauge.h\"",
          "29: #include \"tensorflow/core/platform/protobuf.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "27: #include \"tensorflow/core/framework/tensor_shape.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "205:     const Tensor& min = context->input(1);",
          "206:     const Tensor& max = context->input(2);",
          "208:     Tensor* output;",
          "209:     OP_REQUIRES_OK(context,",
          "210:                    context->allocate_output(0, input.shape(), &output));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "209:     OP_REQUIRES(",
          "210:         context, TensorShapeUtils::IsScalar(min.shape()),",
          "211:         InvalidArgument(\"`min` must be rank 0 but is rank \", min.dims()));",
          "212:     OP_REQUIRES(",
          "213:         context, TensorShapeUtils::IsScalar(max.shape()),",
          "214:         InvalidArgument(\"`max` must be rank 0 but is rank \", max.dims()));",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "342:     const Tensor& input = context->input(0);",
          "343:     const int depth = input.dim_size(input.dims() - 1);  // last dimension size.",
          "344:     const Tensor& min = context->input(1);",
          "345:     OP_REQUIRES(context, min.dim_size(0) == depth,",
          "346:                 InvalidArgument(\"min has incorrect size, expected \", depth,",
          "347:                                 \" was \", min.dim_size(0)));",
          "349:     OP_REQUIRES(context, max.dim_size(0) == depth,",
          "350:                 InvalidArgument(\"max has incorrect size, expected \", depth,",
          "351:                                 \" was \", max.dim_size(0)));",
          "",
          "[Removed Lines]",
          "348:     const Tensor& max = context->input(2);",
          "",
          "[Added Lines]",
          "353:     const Tensor& max = context->input(2);",
          "355:     OP_REQUIRES(",
          "356:         context, TensorShapeUtils::IsVector(min.shape()),",
          "357:         InvalidArgument(\"`min` must be rank 1 but is rank \", min.dims()));",
          "361:     OP_REQUIRES(",
          "362:         context, TensorShapeUtils::IsVector(max.shape()),",
          "363:         InvalidArgument(\"`max` must be rank 1 but is rank \", max.dims()));",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/quantized_bias_add_op.cc||tensorflow/core/kernels/quantized_bias_add_op.cc": [
          "File: tensorflow/core/kernels/quantized_bias_add_op.cc -> tensorflow/core/kernels/quantized_bias_add_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: #include \"tensorflow/core/framework/numeric_op.h\"",
          "21: #include \"tensorflow/core/framework/op_kernel.h\"",
          "22: #include \"tensorflow/core/framework/tensor.h\"",
          "23: #include \"tensorflow/core/kernels/meta_support.h\"",
          "24: #include \"tensorflow/core/kernels/ops_util.h\"",
          "25: #include \"tensorflow/core/kernels/quantization_utils.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "23: #include \"tensorflow/core/framework/tensor_shape.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "38:   void Compute(OpKernelContext* context) override {",
          "39:     const Tensor& input = context->input(0);",
          "40:     const Tensor& bias = context->input(1);",
          "46:     OP_REQUIRES(context, TensorShapeUtils::IsMatrixOrHigher(input.shape()),",
          "47:                 errors::InvalidArgument(\"Input tensor must be at least 2D: \",",
          "",
          "[Removed Lines]",
          "41:     const float input_min = context->input(2).flat<float>()(0);",
          "42:     const float input_max = context->input(3).flat<float>()(0);",
          "43:     const float bias_min = context->input(4).flat<float>()(0);",
          "44:     const float bias_max = context->input(5).flat<float>()(0);",
          "",
          "[Added Lines]",
          "43:     const Tensor& min_input = context->input(2);",
          "44:     const Tensor& max_input = context->input(3);",
          "45:     const Tensor& min_bias = context->input(4);",
          "46:     const Tensor& max_bias = context->input(5);",
          "47:     OP_REQUIRES(",
          "48:         context, TensorShapeUtils::IsScalar(min_input.shape()),",
          "49:         errors::InvalidArgument(\"`min_input` must be rank 0 but is rank \",",
          "50:                                 min_input.dims()));",
          "51:     OP_REQUIRES(",
          "52:         context, TensorShapeUtils::IsScalar(max_input.shape()),",
          "53:         errors::InvalidArgument(\"`max_input` must be rank 0 but is rank \",",
          "54:                                 max_input.dims()));",
          "55:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(min_bias.shape()),",
          "56:                 errors::InvalidArgument(",
          "57:                     \"`min_bias` must be rank 0 but is rank \", min_bias.dims()));",
          "58:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(max_bias.shape()),",
          "59:                 errors::InvalidArgument(",
          "60:                     \"`max_bias` must be rank 0 but is rank \", max_bias.dims()));",
          "62:     const float input_min = min_input.flat<float>()(0);",
          "63:     const float input_max = max_input.flat<float>()(0);",
          "64:     const float bias_min = min_bias.flat<float>()(0);",
          "65:     const float bias_max = max_bias.flat<float>()(0);",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/quantized_bias_add_op_test.cc||tensorflow/core/kernels/quantized_bias_add_op_test.cc": [
          "File: tensorflow/core/kernels/quantized_bias_add_op_test.cc -> tensorflow/core/kernels/quantized_bias_add_op_test.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "74:                             input_quantized.flat<quint8>());",
          "75:   AddInputFromArray<quint8>(bias_quantized.shape(),",
          "76:                             bias_quantized.flat<quint8>());",
          "81:   TF_ASSERT_OK(RunOpKernel());",
          "82:   const Tensor& output_quantized = *GetOutput(0);",
          "83:   const float output_min = GetOutput(1)->flat<float>()(0);",
          "",
          "[Removed Lines]",
          "77:   AddInputFromArray<float>(TensorShape({1}), {input_min});",
          "78:   AddInputFromArray<float>(TensorShape({1}), {input_max});",
          "79:   AddInputFromArray<float>(TensorShape({1}), {bias_min});",
          "80:   AddInputFromArray<float>(TensorShape({1}), {bias_max});",
          "",
          "[Added Lines]",
          "77:   AddInputFromArray<float>(TensorShape({}), {input_min});",
          "78:   AddInputFromArray<float>(TensorShape({}), {input_max});",
          "79:   AddInputFromArray<float>(TensorShape({}), {bias_min});",
          "80:   AddInputFromArray<float>(TensorShape({}), {bias_max});",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "156:                             input_quantized.flat<quint8>());",
          "157:   AddInputFromArray<quint8>(bias_quantized.shape(),",
          "158:                             bias_quantized.flat<quint8>());",
          "163:   TF_ASSERT_OK(RunOpKernel());",
          "164:   const Tensor& output_quantized = *GetOutput(0);",
          "165:   const float output_min = GetOutput(1)->flat<float>()(0);",
          "",
          "[Removed Lines]",
          "159:   AddInputFromArray<float>(TensorShape({1}), {input_min});",
          "160:   AddInputFromArray<float>(TensorShape({1}), {input_max});",
          "161:   AddInputFromArray<float>(TensorShape({1}), {bias_min});",
          "162:   AddInputFromArray<float>(TensorShape({1}), {bias_max});",
          "",
          "[Added Lines]",
          "159:   AddInputFromArray<float>(TensorShape({}), {input_min});",
          "160:   AddInputFromArray<float>(TensorShape({}), {input_max});",
          "161:   AddInputFromArray<float>(TensorShape({}), {bias_min});",
          "162:   AddInputFromArray<float>(TensorShape({}), {bias_max});",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/quantized_instance_norm.cc||tensorflow/core/kernels/quantized_instance_norm.cc": [
          "File: tensorflow/core/kernels/quantized_instance_norm.cc -> tensorflow/core/kernels/quantized_instance_norm.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "25: #include \"tensorflow/core/framework/op_kernel.h\"",
          "26: #include \"tensorflow/core/framework/register_types.h\"",
          "27: #include \"tensorflow/core/framework/tensor.h\"",
          "29: #include \"tensorflow/core/kernels/quantization_utils.h\"",
          "31: #ifdef USE_NEON",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "28: #include \"tensorflow/core/framework/tensor_shape.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "274:   void Compute(OpKernelContext* context) override {",
          "275:     const Tensor& input = context->input(0);",
          "279:     float input_scale = (input_max - input_min) / 255.0f;",
          "281:     OP_REQUIRES(context, input_min < input_max,",
          "",
          "[Removed Lines]",
          "277:     float input_min = context->input(1).flat<float>()(0);",
          "278:     float input_max = context->input(2).flat<float>()(0);",
          "",
          "[Added Lines]",
          "277:     const Tensor& x_min = context->input(1);",
          "278:     const Tensor& x_max = context->input(2);",
          "279:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(x_min.shape()),",
          "280:                 errors::InvalidArgument(\"`x_min` must be rank 0 but is rank \",",
          "281:                                         x_min.dims()));",
          "282:     OP_REQUIRES(context, TensorShapeUtils::IsScalar(x_max.shape()),",
          "283:                 errors::InvalidArgument(\"`x_max` must be rank 0 but is rank \",",
          "284:                                         x_max.dims()));",
          "285:     float input_min = x_min.scalar<float>()();",
          "286:     float input_max = x_max.scalar<float>()();",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/requantize.cc||tensorflow/core/kernels/requantize.cc": [
          "File: tensorflow/core/kernels/requantize.cc -> tensorflow/core/kernels/requantize.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: #define EIGEN_USE_THREADS",
          "20: #include <math.h>",
          "22: #include \"tensorflow/core/framework/op.h\"",
          "23: #include \"tensorflow/core/framework/op_kernel.h\"",
          "24: #include \"tensorflow/core/framework/type_traits.h\"",
          "25: #include \"tensorflow/core/framework/types.h\"",
          "26: #include \"tensorflow/core/kernels/meta_support.h\"",
          "",
          "[Removed Lines]",
          "21: #include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"",
          "",
          "[Added Lines]",
          "24: #include \"tensorflow/core/framework/tensor.h\"",
          "25: #include \"tensorflow/core/framework/tensor_shape.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "39:   void Compute(OpKernelContext* ctx) override {",
          "40:     const Tensor& input = ctx->input(0);",
          "46:     Tensor* output = nullptr;",
          "47:     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
          "",
          "[Removed Lines]",
          "41:     const float input_min_float = ctx->input(1).flat<float>()(0);",
          "42:     const float input_max_float = ctx->input(2).flat<float>()(0);",
          "43:     const float requested_output_min_float = ctx->input(3).flat<float>()(0);",
          "44:     const float requested_output_max_float = ctx->input(4).flat<float>()(0);",
          "",
          "[Added Lines]",
          "44:     const Tensor& input_min = ctx->input(1);",
          "45:     const Tensor& input_max = ctx->input(2);",
          "46:     const Tensor& requested_output_min = ctx->input(3);",
          "47:     const Tensor& requested_output_max = ctx->input(4);",
          "48:     OP_REQUIRES(",
          "49:         ctx, TensorShapeUtils::IsScalar(input_min.shape()),",
          "50:         errors::InvalidArgument(\"`input_min` must be rank 0 but is rank \",",
          "51:                                 input_min.dims()));",
          "52:     OP_REQUIRES(",
          "53:         ctx, TensorShapeUtils::IsScalar(input_max.shape()),",
          "54:         errors::InvalidArgument(\"`input_max` must be rank 0 but is rank \",",
          "55:                                 input_max.dims()));",
          "56:     OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_min.shape()),",
          "57:                 errors::InvalidArgument(",
          "58:                     \"`requested_output_min` must be rank 0 but is rank \",",
          "59:                     requested_output_min.dims()));",
          "60:     OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(requested_output_max.shape()),",
          "61:                 errors::InvalidArgument(",
          "62:                     \"`requested_output_max` must be rank 0 but is rank \",",
          "63:                     requested_output_max.dims()));",
          "65:     const float input_min_float = input_min.flat<float>()(0);",
          "66:     const float input_max_float = input_max.flat<float>()(0);",
          "67:     const float requested_output_min_float =",
          "68:         requested_output_min.flat<float>()(0);",
          "69:     const float requested_output_max_float =",
          "70:         requested_output_max.flat<float>()(0);",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/requantize_op_test.cc||tensorflow/core/kernels/requantize_op_test.cc": [
          "File: tensorflow/core/kernels/requantize_op_test.cc -> tensorflow/core/kernels/requantize_op_test.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "54:   AddInputFromArray<qint32>(TensorShape({value_count}),",
          "55:                             {-(1 << 23), 0, (1 << 23)});",
          "60:   TF_ASSERT_OK(RunOpKernel());",
          "61:   Tensor expected(allocator(), DT_QUINT8, TensorShape({value_count}));",
          "62:   test::FillValues<quint8>(&expected, {0, 128, 255});",
          "",
          "[Removed Lines]",
          "56:   AddInputFromArray<float>(TensorShape({1}), {-256.0f});",
          "57:   AddInputFromArray<float>(TensorShape({1}), {256.0f});",
          "58:   AddInputFromArray<float>(TensorShape({1}), {-1.0f});",
          "59:   AddInputFromArray<float>(TensorShape({1}), {1.0f});",
          "",
          "[Added Lines]",
          "56:   AddInputFromArray<float>(TensorShape({}), {-256.0f});",
          "57:   AddInputFromArray<float>(TensorShape({}), {256.0f});",
          "58:   AddInputFromArray<float>(TensorShape({}), {-1.0f});",
          "59:   AddInputFromArray<float>(TensorShape({}), {1.0f});",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "72:   AddInputFromArray<qint32>(TensorShape({value_count}),",
          "73:                             {-(1 << 23), 0, (1 << 23)});",
          "78:   EXPECT_EQ(\"requested_output_min must be <= 0, but got 0.01\",",
          "79:             RunOpKernel().error_message());",
          "80: }",
          "",
          "[Removed Lines]",
          "74:   AddInputFromArray<float>(TensorShape({1}), {-256.0f});",
          "75:   AddInputFromArray<float>(TensorShape({1}), {256.0f});",
          "76:   AddInputFromArray<float>(TensorShape({1}), {0.01f});",
          "77:   AddInputFromArray<float>(TensorShape({1}), {1.0f});",
          "",
          "[Added Lines]",
          "74:   AddInputFromArray<float>(TensorShape({}), {-256.0f});",
          "75:   AddInputFromArray<float>(TensorShape({}), {256.0f});",
          "76:   AddInputFromArray<float>(TensorShape({}), {0.01f});",
          "77:   AddInputFromArray<float>(TensorShape({}), {1.0f});",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "86:   AddInputFromArray<qint32>(TensorShape({value_count}),",
          "87:                             {-(1 << 23), 0, (1 << 23)});",
          "92:   EXPECT_EQ(",
          "93:       \"requested_output_max must be >= requested_output_min, but got -11 and \"",
          "94:       \"-10\",",
          "",
          "[Removed Lines]",
          "88:   AddInputFromArray<float>(TensorShape({1}), {-256.0f});",
          "89:   AddInputFromArray<float>(TensorShape({1}), {256.0f});",
          "90:   AddInputFromArray<float>(TensorShape({1}), {-10.0f});",
          "91:   AddInputFromArray<float>(TensorShape({1}), {-11.0f});",
          "",
          "[Added Lines]",
          "88:   AddInputFromArray<float>(TensorShape({}), {-256.0f});",
          "89:   AddInputFromArray<float>(TensorShape({}), {256.0f});",
          "90:   AddInputFromArray<float>(TensorShape({}), {-10.0f});",
          "91:   AddInputFromArray<float>(TensorShape({}), {-11.0f});",
          "",
          "---------------"
        ],
        "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py": [
          "File: tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py -> tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: # Copyright 2015 The TensorFlow Authors. All Rights Reserved.",
          "2: #",
          "3: # Licensed under the Apache License, Version 2.0 (the \"License\");",
          "4: # you may not use this file except in compliance with the License.",
          "5: # You may obtain a copy of the License at",
          "6: #",
          "7: #     http://www.apache.org/licenses/LICENSE-2.0",
          "8: #",
          "9: # Unless required by applicable law or agreed to in writing, software",
          "10: # distributed under the License is distributed on an \"AS IS\" BASIS,",
          "11: # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
          "12: # See the License for the specific language governing permissions and",
          "13: # limitations under the License.",
          "14: # ==============================================================================",
          "15: \"\"\"Tests for tf.quantize ops.\"\"\"",
          "16: import numpy as np",
          "18: from tensorflow.python.framework import constant_op",
          "19: from tensorflow.python.framework import dtypes",
          "20: from tensorflow.python.framework import errors",
          "21: from tensorflow.python.framework import test_util",
          "22: from tensorflow.python.ops import array_ops",
          "23: from tensorflow.python.ops import math_ops",
          "24: from tensorflow.python.ops import nn_ops",
          "25: from tensorflow.python.platform import googletest",
          "28: class FakeQuantWithMinMaxVarsOpTest(test_util.TensorFlowTestCase):",
          "30:   @test_util.run_in_graph_and_eager_modes",
          "31:   def test_invalid_inputs(self):",
          "32:     inputs = constant_op.constant(",
          "33:         value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
          "35:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "36:                                 \"must be rank 0\"):",
          "37:       self.evaluate(",
          "38:           array_ops.fake_quant_with_min_max_vars(",
          "39:               inputs=inputs, min=0.0, max=[[1.0], [2.0], [4.0]]))",
          "41:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "42:                                 \"must be rank 0\"):",
          "43:       self.evaluate(",
          "44:           array_ops.fake_quant_with_min_max_vars(",
          "45:               inputs=inputs, min=[[1.0], [2.0], [4.0]], max=1.0))",
          "48: class FakeQuantWithMinMaxVarsPerChannelOpTest(test_util.TensorFlowTestCase):",
          "50:   @test_util.run_in_graph_and_eager_modes",
          "51:   def test_invalid_inputs(self):",
          "52:     inputs = constant_op.constant(",
          "53:         value=[[1.0], [2.0], [4.0]], dtype=dtypes.float32)",
          "55:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "56:                                 \"must be rank 1\"):",
          "57:       self.evaluate(",
          "58:           array_ops.fake_quant_with_min_max_vars_per_channel(",
          "59:               inputs=inputs, min=[[0.0]], max=[1.0]))",
          "61:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "62:                                 \"Dimensions must be equal|incorrect size\"):",
          "63:       self.evaluate(",
          "64:           array_ops.fake_quant_with_min_max_vars_per_channel(",
          "65:               inputs=inputs, min=[0.0, 0.1], max=[1.0]))",
          "67:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "68:                                 \"must be rank 1\"):",
          "69:       self.evaluate(",
          "70:           array_ops.fake_quant_with_min_max_vars_per_channel(",
          "71:               inputs=inputs, min=[1.0], max=[[1.0]]))",
          "73:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "74:                                 \"Dimensions must be equal|incorrect size\"):",
          "75:       self.evaluate(",
          "76:           array_ops.fake_quant_with_min_max_vars_per_channel(",
          "77:               inputs=inputs, min=[0.0], max=[1.0, 1.1]))",
          "80: class QuantizedBiasedAddTest(test_util.TensorFlowTestCase):",
          "82:   @test_util.run_in_graph_and_eager_modes",
          "83:   def test_invalid_inputs(self):",
          "84:     inputs = constant_op.constant(",
          "85:         np.int8(0), shape=[3, 3, 3, 3], dtype=dtypes.qint8)",
          "86:     bias = constant_op.constant(np.int8(0), shape=[3], dtype=dtypes.qint8)",
          "88:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "89:                                 \"must be rank 0\"):",
          "90:       self.evaluate(",
          "91:           nn_ops.quantized_bias_add(",
          "92:               input=inputs,",
          "93:               bias=bias,",
          "94:               min_input=[],",
          "95:               max_input=1.0,",
          "96:               min_bias=0.0,",
          "97:               max_bias=1.0,",
          "98:               out_type=dtypes.qint32))",
          "100:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "101:                                 \"must be rank 0\"):",
          "102:       self.evaluate(",
          "103:           nn_ops.quantized_bias_add(",
          "104:               input=inputs,",
          "105:               bias=bias,",
          "106:               min_input=0.0,",
          "107:               max_input=[],",
          "108:               min_bias=0.0,",
          "109:               max_bias=1.0,",
          "110:               out_type=dtypes.qint32))",
          "112:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "113:                                 \"must be rank 0\"):",
          "114:       self.evaluate(",
          "115:           nn_ops.quantized_bias_add(",
          "116:               input=inputs,",
          "117:               bias=bias,",
          "118:               min_input=0.0,",
          "119:               max_input=1.0,",
          "120:               min_bias=[],",
          "121:               max_bias=1.0,",
          "122:               out_type=dtypes.qint32))",
          "124:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "125:                                 \"must be rank 0\"):",
          "126:       self.evaluate(",
          "127:           nn_ops.quantized_bias_add(",
          "128:               input=inputs,",
          "129:               bias=bias,",
          "130:               min_input=0.0,",
          "131:               max_input=1.0,",
          "132:               min_bias=0.0,",
          "133:               max_bias=[],",
          "134:               out_type=dtypes.qint32))",
          "137: class QuantizedInstanceNormOpTest(test_util.TensorFlowTestCase):",
          "139:   @test_util.run_in_graph_and_eager_modes",
          "140:   def test_invalid_inputs(self):",
          "141:     inputs = constant_op.constant(",
          "142:         np.uint8(0), shape=[3, 3, 3, 3], dtype=dtypes.quint8)",
          "144:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "145:                                 \"must be rank 0\"):",
          "146:       self.evaluate(",
          "147:           array_ops.quantized_instance_norm(",
          "148:               x=inputs, x_min=0.0, x_max=[[1.0], [2.0], [4.0]]))",
          "150:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "151:                                 \"must be rank 0\"):",
          "152:       self.evaluate(",
          "153:           array_ops.quantized_instance_norm(",
          "154:               x=inputs, x_min=[[1.0], [2.0], [4.0]], x_max=1.0))",
          "157: class RequantizeOpTest(test_util.TensorFlowTestCase):",
          "159:   @test_util.run_in_graph_and_eager_modes",
          "160:   def test_invalid_inputs(self):",
          "161:     inputs = constant_op.constant(",
          "162:         np.int32(0), shape=[3, 3, 3, 3], dtype=dtypes.qint32)",
          "164:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "165:                                 \"must be rank 0\"):",
          "166:       self.evaluate(",
          "167:           math_ops.requantize(",
          "168:               input=inputs,",
          "169:               input_min=[],",
          "170:               input_max=1.0,",
          "171:               requested_output_min=0.0,",
          "172:               requested_output_max=1.0,",
          "173:               out_type=dtypes.qint8))",
          "175:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "176:                                 \"must be rank 0\"):",
          "177:       self.evaluate(",
          "178:           math_ops.requantize(",
          "179:               input=inputs,",
          "180:               input_min=0.0,",
          "181:               input_max=[],",
          "182:               requested_output_min=0.0,",
          "183:               requested_output_max=1.0,",
          "184:               out_type=dtypes.qint8))",
          "186:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "187:                                 \"must be rank 0\"):",
          "188:       self.evaluate(",
          "189:           math_ops.requantize(",
          "190:               input=inputs,",
          "191:               input_min=0.0,",
          "192:               input_max=1.0,",
          "193:               requested_output_min=[],",
          "194:               requested_output_max=1.0,",
          "195:               out_type=dtypes.qint8))",
          "197:     with self.assertRaisesRegex((ValueError, errors.InvalidArgumentError),",
          "198:                                 \"must be rank 0\"):",
          "199:       self.evaluate(",
          "200:           math_ops.requantize(",
          "201:               input=inputs,",
          "202:               input_min=0.0,",
          "203:               input_max=1.0,",
          "204:               requested_output_min=0.0,",
          "205:               requested_output_max=[],",
          "206:               out_type=dtypes.qint8))",
          "209: if __name__ == \"__main__\":",
          "210:   googletest.main()",
          "",
          "---------------"
        ]
      }
    }
  ]
}