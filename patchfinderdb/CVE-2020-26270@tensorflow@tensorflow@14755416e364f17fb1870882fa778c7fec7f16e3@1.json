{
  "cve_id": "CVE-2020-26270",
  "cve_desc": "In affected versions of TensorFlow running an LSTM/GRU model where the LSTM/GRU layer receives an input with zero-length results in a CHECK failure when using the CUDA backend. This can result in a query-of-death vulnerability, via denial of service, if users can control the input to the layer. This is fixed in versions 1.15.5, 2.0.4, 2.1.3, 2.2.2, 2.3.2, and 2.4.0.",
  "repo": "tensorflow/tensorflow",
  "patch_hash": "14755416e364f17fb1870882fa778c7fec7f16e3",
  "patch_info": {
    "commit_hash": "14755416e364f17fb1870882fa778c7fec7f16e3",
    "repo": "tensorflow/tensorflow",
    "commit_url": "https://github.com/tensorflow/tensorflow/commit/14755416e364f17fb1870882fa778c7fec7f16e3",
    "files": [
      "tensorflow/stream_executor/cuda/cuda_dnn.cc"
    ],
    "message": "Prevent CHECK-fail in LSTM/GRU with zero-length input.\n\nPiperOrigin-RevId: 346239181\nChange-Id: I5f233dbc076aab7bb4e31ba24f5abd4eaf99ea4f",
    "before_after_code_files": [
      "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc"
    ]
  },
  "patch_diff": {
    "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc": [
      "File: tensorflow/stream_executor/cuda/cuda_dnn.cc -> tensorflow/stream_executor/cuda/cuda_dnn.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "1468:   static port::StatusOr<CudnnRnnSequenceTensorDescriptor> Create(",
      "1469:       GpuExecutor* parent, int max_seq_length, int batch_size, int data_size,",
      "1470:       cudnnDataType_t data_type) {",
      "1472:     int dims[] = {batch_size, data_size, 1};",
      "1473:     int strides[] = {dims[1] * dims[2], dims[2], 1};",
      "1474:     TensorDescriptor tensor_desc = CreateTensorDescriptor();",
      "",
      "[Removed Lines]",
      "1471:     CHECK_GT(max_seq_length, 0);",
      "",
      "[Added Lines]",
      "1471:     if (max_seq_length <= 0) {",
      "1472:       return port::Status(port::error::INVALID_ARGUMENT, \"max_seq_length <= 0\");",
      "1473:     }",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "1486:       GpuExecutor* parent, int max_seq_length, int batch_size, int data_size,",
      "1487:       const absl::Span<const int>& seq_lengths, bool time_major,",
      "1488:       cudnnDataType_t data_type) {",
      "1490:     int dims[] = {batch_size, data_size, 1};",
      "1491:     int strides[] = {dims[1] * dims[2], dims[2], 1};",
      "1492:     TensorDescriptor tensor_desc = CreateTensorDescriptor();",
      "",
      "[Removed Lines]",
      "1489:     CHECK_GT(max_seq_length, 0);",
      "",
      "[Added Lines]",
      "1491:     if (max_seq_length <= 0) {",
      "1492:       return port::Status(port::error::INVALID_ARGUMENT, \"max_seq_length <= 0\");",
      "1493:     }",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "ec544f8099981be897463a6b39b8a7a1d6f0f62d",
      "candidate_info": {
        "commit_hash": "ec544f8099981be897463a6b39b8a7a1d6f0f62d",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/ec544f8099981be897463a6b39b8a7a1d6f0f62d",
        "files": [
          "tensorflow/stream_executor/cuda/cuda_dnn.cc"
        ],
        "message": "Prevent CHECK-fail in LSTM/GRU with zero-length input.\n\nPiperOrigin-RevId: 346239181\nChange-Id: I5f233dbc076aab7bb4e31ba24f5abd4eaf99ea4f",
        "before_after_code_files": [
          "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc"
          ],
          "candidate": [
            "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc": [
          "File: tensorflow/stream_executor/cuda/cuda_dnn.cc -> tensorflow/stream_executor/cuda/cuda_dnn.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "1383:   static port::StatusOr<CudnnRnnSequenceTensorDescriptor> Create(",
          "1384:       GpuExecutor* parent, int max_seq_length, int batch_size, int data_size,",
          "1385:       cudnnDataType_t data_type) {",
          "1387:     int dims[] = {batch_size, data_size, 1};",
          "1388:     int strides[] = {dims[1] * dims[2], dims[2], 1};",
          "1389:     TensorDescriptor tensor_desc = CreateTensorDescriptor();",
          "",
          "[Removed Lines]",
          "1386:     CHECK_GT(max_seq_length, 0);",
          "",
          "[Added Lines]",
          "1386:     if (max_seq_length <= 0) {",
          "1387:       return port::Status(port::error::INVALID_ARGUMENT, \"max_seq_length <= 0\");",
          "1388:     }",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1404:       const absl::Span<const int>& seq_lengths, bool time_major,",
          "1405:       cudnnDataType_t data_type) {",
          "1406: #if CUDNN_VERSION >= 7201",
          "1408:     int dims[] = {batch_size, data_size, 1};",
          "1409:     int strides[] = {dims[1] * dims[2], dims[2], 1};",
          "1410:     TensorDescriptor tensor_desc = CreateTensorDescriptor();",
          "",
          "[Removed Lines]",
          "1407:     CHECK_GT(max_seq_length, 0);",
          "",
          "[Added Lines]",
          "1409:     if (max_seq_length <= 0) {",
          "1410:       return port::Status(port::error::INVALID_ARGUMENT, \"max_seq_length <= 0\");",
          "1411:     }",
          "",
          "---------------"
        ]
      }
    }
  ]
}