{
  "cve_id": "CVE-2020-10757",
  "cve_desc": "A flaw was found in the Linux Kernel in versions after 4.5-rc1 in the way mremap handled DAX Huge Pages. This flaw allows a local attacker with access to a DAX enabled storage to escalate their privileges on the system.",
  "repo": "torvalds/linux",
  "patch_hash": "5bfea2d9b17f1034a68147a8b03b9789af5700f9",
  "patch_info": {
    "commit_hash": "5bfea2d9b17f1034a68147a8b03b9789af5700f9",
    "repo": "torvalds/linux",
    "commit_url": "https://github.com/torvalds/linux/commit/5bfea2d9b17f1034a68147a8b03b9789af5700f9",
    "files": [
      "arch/x86/include/asm/pgtable.h",
      "mm/mremap.c"
    ],
    "message": "mm: Fix mremap not considering huge pmd devmap\n\nThe original code in mm/mremap.c checks huge pmd by:\n\n\t\tif (is_swap_pmd(*old_pmd) || pmd_trans_huge(*old_pmd)) {\n\nHowever, a DAX mapped nvdimm is mapped as huge page (by default) but it\nis not transparent huge page (_PAGE_PSE | PAGE_DEVMAP).  This commit\nchanges the condition to include the case.\n\nThis addresses CVE-2020-10757.\n\nFixes: 5c7fb56e5e3f (\"mm, dax: dax-pmd vs thp-pmd vs hugetlbfs-pmd\")\nCc: <stable@vger.kernel.org>\nReported-by: Fan Yang <Fan_Yang@sjtu.edu.cn>\nSigned-off-by: Fan Yang <Fan_Yang@sjtu.edu.cn>\nTested-by: Fan Yang <Fan_Yang@sjtu.edu.cn>\nTested-by: Dan Williams <dan.j.williams@intel.com>\nReviewed-by: Dan Williams <dan.j.williams@intel.com>\nAcked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
    "before_after_code_files": [
      "arch/x86/include/asm/pgtable.h||arch/x86/include/asm/pgtable.h",
      "mm/mremap.c||mm/mremap.c"
    ]
  },
  "patch_diff": {
    "arch/x86/include/asm/pgtable.h||arch/x86/include/asm/pgtable.h": [
      "File: arch/x86/include/asm/pgtable.h -> arch/x86/include/asm/pgtable.h"
    ],
    "mm/mremap.c||mm/mremap.c": [
      "File: mm/mremap.c -> mm/mremap.c",
      "--- Hunk 1 ---",
      "[Context before]",
      "266:   new_pmd = alloc_new_pmd(vma->vm_mm, vma, new_addr);",
      "267:   if (!new_pmd)",
      "268:    break;",
      "270:    if (extent == HPAGE_PMD_SIZE) {",
      "271:     bool moved;",
      "",
      "[Removed Lines]",
      "269:   if (is_swap_pmd(*old_pmd) || pmd_trans_huge(*old_pmd)) {",
      "",
      "[Added Lines]",
      "269:   if (is_swap_pmd(*old_pmd) || pmd_trans_huge(*old_pmd) || pmd_devmap(*old_pmd)) {",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "c49dd340180260c6239e453263a9a244da9a7c85",
      "candidate_info": {
        "commit_hash": "c49dd340180260c6239e453263a9a244da9a7c85",
        "repo": "torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/c49dd340180260c6239e453263a9a244da9a7c85",
        "files": [
          "arch/Kconfig",
          "mm/mremap.c"
        ],
        "message": "mm: speedup mremap on 1GB or larger regions\n\nAndroid needs to move large memory regions for garbage collection.  The GC\nrequires moving physical pages of multi-gigabyte heap using mremap.\nDuring this move, the application threads have to be paused for\ncorrectness.  It is critical to keep this pause as short as possible to\navoid jitters during user interaction.\n\nOptimize mremap for >= 1GB-sized regions by moving at the PUD/PGD level if\nthe source and destination addresses are PUD-aligned.  For\nCONFIG_PGTABLE_LEVELS == 3, moving at the PUD level in effect moves PGD\nentries, since the PUD entry is \u201cfolded back\u201d onto the PGD entry.  Add\nHAVE_MOVE_PUD so that architectures where moving at the PUD level isn't\nsupported/tested can turn this off by not selecting the config.\n\nLink: https://lkml.kernel.org/r/20201014005320.2233162-4-kaleshsingh@google.com\nSigned-off-by: Kalesh Singh <kaleshsingh@google.com>\nAcked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>\nReported-by: kernel test robot <lkp@intel.com>\nCc: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>\nCc: Anshuman Khandual <anshuman.khandual@arm.com>\nCc: Arnd Bergmann <arnd@arndb.de>\nCc: Borislav Petkov <bp@alien8.de>\nCc: Brian Geffon <bgeffon@google.com>\nCc: Catalin Marinas <catalin.marinas@arm.com>\nCc: Christian Brauner <christian.brauner@ubuntu.com>\nCc: Dave Hansen <dave.hansen@intel.com>\nCc: Frederic Weisbecker <frederic@kernel.org>\nCc: Gavin Shan <gshan@redhat.com>\nCc: Hassan Naveed <hnaveed@wavecomp.com>\nCc: \"H. Peter Anvin\" <hpa@zytor.com>\nCc: Ingo Molnar <mingo@redhat.com>\nCc: Jia He <justin.he@arm.com>\nCc: John Hubbard <jhubbard@nvidia.com>\nCc: Kees Cook <keescook@chromium.org>\nCc: Krzysztof Kozlowski <krzk@kernel.org>\nCc: Lokesh Gidra <lokeshgidra@google.com>\nCc: Mark Rutland <mark.rutland@arm.com>\nCc: Masahiro Yamada <masahiroy@kernel.org>\nCc: Masami Hiramatsu <mhiramat@kernel.org>\nCc: Mike Rapoport <rppt@kernel.org>\nCc: Mina Almasry <almasrymina@google.com>\nCc: Minchan Kim <minchan@google.com>\nCc: Peter Zijlstra (Intel) <peterz@infradead.org>\nCc: Ralph Campbell <rcampbell@nvidia.com>\nCc: Ram Pai <linuxram@us.ibm.com>\nCc: Sami Tolvanen <samitolvanen@google.com>\nCc: Sandipan Das <sandipan@linux.ibm.com>\nCc: SeongJae Park <sjpark@amazon.de>\nCc: Shuah Khan <shuah@kernel.org>\nCc: Steven Price <steven.price@arm.com>\nCc: Suren Baghdasaryan <surenb@google.com>\nCc: Thomas Gleixner <tglx@linutronix.de>\nCc: Will Deacon <will@kernel.org>\nCc: Zi Yan <ziy@nvidia.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "before_after_code_files": [
          "mm/mremap.c||mm/mremap.c"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "mm/mremap.c||mm/mremap.c"
          ],
          "candidate": [
            "mm/mremap.c||mm/mremap.c"
          ]
        }
      },
      "candidate_diff": {
        "mm/mremap.c||mm/mremap.c": [
          "File: mm/mremap.c -> mm/mremap.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "31: #include \"internal.h\"",
          "34: {",
          "35:  pgd_t *pgd;",
          "36:  p4d_t *p4d;",
          "37:  pud_t *pud;",
          "40:  pgd = pgd_offset(mm, addr);",
          "41:  if (pgd_none_or_clear_bad(pgd))",
          "",
          "[Removed Lines]",
          "33: static pmd_t *get_old_pmd(struct mm_struct *mm, unsigned long addr)",
          "38:  pmd_t *pmd;",
          "",
          "[Added Lines]",
          "33: static pud_t *get_old_pud(struct mm_struct *mm, unsigned long addr)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "49:  if (pud_none_or_clear_bad(pud))",
          "50:   return NULL;",
          "52:  pmd = pmd_offset(pud, addr);",
          "53:  if (pmd_none(*pmd))",
          "54:   return NULL;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "51:  return pud;",
          "52: }",
          "54: static pmd_t *get_old_pmd(struct mm_struct *mm, unsigned long addr)",
          "55: {",
          "56:  pud_t *pud;",
          "57:  pmd_t *pmd;",
          "59:  pud = get_old_pud(mm, addr);",
          "60:  if (!pud)",
          "61:   return NULL;",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "56:  return pmd;",
          "57: }",
          "60:        unsigned long addr)",
          "61: {",
          "62:  pgd_t *pgd;",
          "63:  p4d_t *p4d;",
          "67:  pgd = pgd_offset(mm, addr);",
          "68:  p4d = p4d_alloc(mm, pgd, addr);",
          "69:  if (!p4d)",
          "70:   return NULL;",
          "72:  if (!pud)",
          "73:   return NULL;",
          "",
          "[Removed Lines]",
          "59: static pmd_t *alloc_new_pmd(struct mm_struct *mm, struct vm_area_struct *vma,",
          "64:  pud_t *pud;",
          "65:  pmd_t *pmd;",
          "71:  pud = pud_alloc(mm, p4d, addr);",
          "",
          "[Added Lines]",
          "70: static pud_t *alloc_new_pud(struct mm_struct *mm, struct vm_area_struct *vma,",
          "81:  return pud_alloc(mm, p4d, addr);",
          "82: }",
          "84: static pmd_t *alloc_new_pmd(struct mm_struct *mm, struct vm_area_struct *vma,",
          "85:        unsigned long addr)",
          "86: {",
          "87:  pud_t *pud;",
          "88:  pmd_t *pmd;",
          "90:  pud = alloc_new_pud(mm, vma, addr);",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "250:  return true;",
          "251: }",
          "252: #endif",
          "254: unsigned long move_page_tables(struct vm_area_struct *vma,",
          "255:   unsigned long old_addr, struct vm_area_struct *new_vma,",
          "256:   unsigned long new_addr, unsigned long len,",
          "257:   bool need_rmap_locks)",
          "258: {",
          "260:  struct mmu_notifier_range range;",
          "261:  pmd_t *old_pmd, *new_pmd;",
          "",
          "[Removed Lines]",
          "259:  unsigned long extent, next, old_end;",
          "",
          "[Added Lines]",
          "271: #else",
          "272: static inline bool move_normal_pmd(struct vm_area_struct *vma,",
          "273:   unsigned long old_addr, unsigned long new_addr, pmd_t *old_pmd,",
          "274:   pmd_t *new_pmd)",
          "275: {",
          "276:  return false;",
          "277: }",
          "278: #endif",
          "280: #ifdef CONFIG_HAVE_MOVE_PUD",
          "281: static bool move_normal_pud(struct vm_area_struct *vma, unsigned long old_addr,",
          "282:     unsigned long new_addr, pud_t *old_pud, pud_t *new_pud)",
          "283: {",
          "284:  spinlock_t *old_ptl, *new_ptl;",
          "285:  struct mm_struct *mm = vma->vm_mm;",
          "286:  pud_t pud;",
          "292:  if (WARN_ON_ONCE(!pud_none(*new_pud)))",
          "293:   return false;",
          "299:  old_ptl = pud_lock(vma->vm_mm, old_pud);",
          "300:  new_ptl = pud_lockptr(mm, new_pud);",
          "301:  if (new_ptl != old_ptl)",
          "302:   spin_lock_nested(new_ptl, SINGLE_DEPTH_NESTING);",
          "305:  pud = *old_pud;",
          "306:  pud_clear(old_pud);",
          "308:  VM_BUG_ON(!pud_none(*new_pud));",
          "311:  set_pud_at(mm, new_addr, new_pud, pud);",
          "312:  flush_tlb_range(vma, old_addr, old_addr + PUD_SIZE);",
          "313:  if (new_ptl != old_ptl)",
          "314:   spin_unlock(new_ptl);",
          "315:  spin_unlock(old_ptl);",
          "317:  return true;",
          "318: }",
          "319: #else",
          "320: static inline bool move_normal_pud(struct vm_area_struct *vma,",
          "321:   unsigned long old_addr, unsigned long new_addr, pud_t *old_pud,",
          "322:   pud_t *new_pud)",
          "323: {",
          "324:  return false;",
          "325: }",
          "328: enum pgt_entry {",
          "329:  NORMAL_PMD,",
          "330:  HPAGE_PMD,",
          "331:  NORMAL_PUD,",
          "332: };",
          "339: static unsigned long get_extent(enum pgt_entry entry, unsigned long old_addr,",
          "340:    unsigned long old_end, unsigned long new_addr)",
          "341: {",
          "342:  unsigned long next, extent, mask, size;",
          "344:  switch (entry) {",
          "345:  case HPAGE_PMD:",
          "346:  case NORMAL_PMD:",
          "347:   mask = PMD_MASK;",
          "348:   size = PMD_SIZE;",
          "349:   break;",
          "350:  case NORMAL_PUD:",
          "351:   mask = PUD_MASK;",
          "352:   size = PUD_SIZE;",
          "353:   break;",
          "354:  default:",
          "355:   BUILD_BUG();",
          "356:   break;",
          "357:  }",
          "359:  next = (old_addr + size) & mask;",
          "361:  extent = (next > old_end) ? old_end - old_addr : next - old_addr;",
          "362:  next = (new_addr + size) & mask;",
          "363:  if (extent > next - new_addr)",
          "364:   extent = next - new_addr;",
          "365:  return extent;",
          "366: }",
          "372: static bool move_pgt_entry(enum pgt_entry entry, struct vm_area_struct *vma,",
          "373:    unsigned long old_addr, unsigned long new_addr,",
          "374:    void *old_entry, void *new_entry, bool need_rmap_locks)",
          "375: {",
          "376:  bool moved = false;",
          "379:  if (need_rmap_locks)",
          "380:   take_rmap_locks(vma);",
          "382:  switch (entry) {",
          "383:  case NORMAL_PMD:",
          "384:   moved = move_normal_pmd(vma, old_addr, new_addr, old_entry,",
          "385:      new_entry);",
          "386:   break;",
          "387:  case NORMAL_PUD:",
          "388:   moved = move_normal_pud(vma, old_addr, new_addr, old_entry,",
          "389:      new_entry);",
          "390:   break;",
          "391:  case HPAGE_PMD:",
          "392:   moved = IS_ENABLED(CONFIG_TRANSPARENT_HUGEPAGE) &&",
          "393:    move_huge_pmd(vma, old_addr, new_addr, old_entry,",
          "394:           new_entry);",
          "395:   break;",
          "396:  default:",
          "397:   WARN_ON_ONCE(1);",
          "398:   break;",
          "399:  }",
          "401:  if (need_rmap_locks)",
          "402:   drop_rmap_locks(vma);",
          "404:  return moved;",
          "405: }",
          "412:  unsigned long extent, old_end;",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "270:  for (; old_addr < old_end; old_addr += extent, new_addr += extent) {",
          "271:   cond_resched();",
          "280:   old_pmd = get_old_pmd(vma->vm_mm, old_addr);",
          "281:   if (!old_pmd)",
          "282:    continue;",
          "283:   new_pmd = alloc_new_pmd(vma->vm_mm, vma, new_addr);",
          "284:   if (!new_pmd)",
          "285:    break;",
          "299:    split_huge_pmd(vma, old_pmd, old_addr);",
          "300:    if (pmd_trans_unstable(old_pmd))",
          "301:     continue;",
          "317:     continue;",
          "319:   }",
          "321:   if (pte_alloc(new_vma->vm_mm, new_pmd))",
          "",
          "[Removed Lines]",
          "272:   next = (old_addr + PMD_SIZE) & PMD_MASK;",
          "274:   extent = next - old_addr;",
          "275:   if (extent > old_end - old_addr)",
          "276:    extent = old_end - old_addr;",
          "277:   next = (new_addr + PMD_SIZE) & PMD_MASK;",
          "278:   if (extent > next - new_addr)",
          "279:    extent = next - new_addr;",
          "286:   if (is_swap_pmd(*old_pmd) || pmd_trans_huge(*old_pmd) || pmd_devmap(*old_pmd)) {",
          "287:    if (extent == HPAGE_PMD_SIZE) {",
          "288:     bool moved;",
          "290:     if (need_rmap_locks)",
          "291:      take_rmap_locks(vma);",
          "292:     moved = move_huge_pmd(vma, old_addr, new_addr,",
          "293:             old_pmd, new_pmd);",
          "294:     if (need_rmap_locks)",
          "295:      drop_rmap_locks(vma);",
          "296:     if (moved)",
          "297:      continue;",
          "298:    }",
          "302:   } else if (extent == PMD_SIZE) {",
          "303: #ifdef CONFIG_HAVE_MOVE_PMD",
          "308:    bool moved;",
          "310:    if (need_rmap_locks)",
          "311:     take_rmap_locks(vma);",
          "312:    moved = move_normal_pmd(vma, old_addr, new_addr,",
          "313:       old_pmd, new_pmd);",
          "314:    if (need_rmap_locks)",
          "315:     drop_rmap_locks(vma);",
          "316:    if (moved)",
          "318: #endif",
          "",
          "[Added Lines]",
          "429:   extent = get_extent(NORMAL_PUD, old_addr, old_end, new_addr);",
          "430:   if (IS_ENABLED(CONFIG_HAVE_MOVE_PUD) && extent == PUD_SIZE) {",
          "431:    pud_t *old_pud, *new_pud;",
          "433:    old_pud = get_old_pud(vma->vm_mm, old_addr);",
          "434:    if (!old_pud)",
          "435:     continue;",
          "436:    new_pud = alloc_new_pud(vma->vm_mm, vma, new_addr);",
          "437:    if (!new_pud)",
          "438:     break;",
          "439:    if (move_pgt_entry(NORMAL_PUD, vma, old_addr, new_addr,",
          "440:         old_pud, new_pud, need_rmap_locks))",
          "441:     continue;",
          "442:   }",
          "444:   extent = get_extent(NORMAL_PMD, old_addr, old_end, new_addr);",
          "451:   if (is_swap_pmd(*old_pmd) || pmd_trans_huge(*old_pmd) ||",
          "452:       pmd_devmap(*old_pmd)) {",
          "453:    if (extent == HPAGE_PMD_SIZE &&",
          "454:        move_pgt_entry(HPAGE_PMD, vma, old_addr, new_addr,",
          "455:         old_pmd, new_pmd, need_rmap_locks))",
          "456:     continue;",
          "460:   } else if (IS_ENABLED(CONFIG_HAVE_MOVE_PMD) &&",
          "461:       extent == PMD_SIZE) {",
          "466:    if (move_pgt_entry(NORMAL_PMD, vma, old_addr, new_addr,",
          "467:         old_pmd, new_pmd, need_rmap_locks))",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "b8aa9d9d95b3b4b60d42ac95f65d33a92527aef3",
      "candidate_info": {
        "commit_hash": "b8aa9d9d95b3b4b60d42ac95f65d33a92527aef3",
        "repo": "torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/b8aa9d9d95b3b4b60d42ac95f65d33a92527aef3",
        "files": [
          "include/linux/huge_mm.h",
          "mm/huge_memory.c",
          "mm/mremap.c"
        ],
        "message": "mm/mremap: it is sure to have enough space when extent meets requirement\n\nPatch series \"mm/mremap: cleanup move_page_tables() a little\", v5.\n\nmove_page_tables() tries to move page table by PMD or PTE.\n\nThe root reason is if it tries to move PMD, both old and new range should\nbe PMD aligned.  But current code calculate old range and new range\nseparately.  This leads to some redundant check and calculation.\n\nThis cleanup tries to consolidate the range check in one place to reduce\nsome extra range handling.\n\nThis patch (of 3):\n\nold_end is passed to these two functions to check whether there is enough\nspace to do the move, while this check is done before invoking these\nfunctions.\n\nThese two functions only would be invoked when extent meets the\nrequirement and there is one check before invoking these functions:\n\n    if (extent > old_end - old_addr)\n        extent = old_end - old_addr;\n\nThis implies (old_end - old_addr) won't fail the check in these two\nfunctions.\n\nSigned-off-by: Wei Yang <richard.weiyang@linux.alibaba.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nTested-by: Dmitry Osipenko <digetx@gmail.com>\nAcked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>\nCc: Vlastimil Babka <vbabka@suse.cz>\nCc: Yang Shi <yang.shi@linux.alibaba.com>\nCc: Thomas Hellstrom (VMware) <thomas_os@shipmail.org>\nCc: Anshuman Khandual <anshuman.khandual@arm.com>\nCc: Sean Christopherson <sean.j.christopherson@intel.com>\nCc: Wei Yang <richard.weiyang@linux.alibaba.com>\nCc: Peter Xu <peterx@redhat.com>\nCc: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>\nCc: Matthew Wilcox <willy@infradead.org>\nCc: Thomas Hellstrom <thellstrom@vmware.com>\nLink: http://lkml.kernel.org/r/20200710092835.56368-1-richard.weiyang@linux.alibaba.com\nLink: http://lkml.kernel.org/r/20200710092835.56368-2-richard.weiyang@linux.alibaba.com\nLink: http://lkml.kernel.org/r/20200708095028.41706-1-richard.weiyang@linux.alibaba.com\nLink: http://lkml.kernel.org/r/20200708095028.41706-2-richard.weiyang@linux.alibaba.com\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "before_after_code_files": [
          "include/linux/huge_mm.h||include/linux/huge_mm.h",
          "mm/huge_memory.c||mm/huge_memory.c",
          "mm/mremap.c||mm/mremap.c"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "mm/mremap.c||mm/mremap.c"
          ],
          "candidate": [
            "mm/mremap.c||mm/mremap.c"
          ]
        }
      },
      "candidate_diff": {
        "include/linux/huge_mm.h||include/linux/huge_mm.h": [
          "File: include/linux/huge_mm.h -> include/linux/huge_mm.h",
          "--- Hunk 1 ---",
          "[Context before]",
          "42:    unsigned long addr, unsigned long end,",
          "43:    unsigned char *vec);",
          "44: extern bool move_huge_pmd(struct vm_area_struct *vma, unsigned long old_addr,",
          "46:     pmd_t *old_pmd, pmd_t *new_pmd);",
          "47: extern int change_huge_pmd(struct vm_area_struct *vma, pmd_t *pmd,",
          "48:    unsigned long addr, pgprot_t newprot,",
          "",
          "[Removed Lines]",
          "45:     unsigned long new_addr, unsigned long old_end,",
          "",
          "[Added Lines]",
          "45:     unsigned long new_addr,",
          "",
          "---------------"
        ],
        "mm/huge_memory.c||mm/huge_memory.c": [
          "File: mm/huge_memory.c -> mm/huge_memory.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "1722: }",
          "1724: bool move_huge_pmd(struct vm_area_struct *vma, unsigned long old_addr,",
          "1727: {",
          "1728:  spinlock_t *old_ptl, *new_ptl;",
          "1729:  pmd_t pmd;",
          "1730:  struct mm_struct *mm = vma->vm_mm;",
          "1731:  bool force_flush = false;",
          "1736:   return false;",
          "",
          "[Removed Lines]",
          "1725:     unsigned long new_addr, unsigned long old_end,",
          "1726:     pmd_t *old_pmd, pmd_t *new_pmd)",
          "1733:  if ((old_addr & ~HPAGE_PMD_MASK) ||",
          "1734:      (new_addr & ~HPAGE_PMD_MASK) ||",
          "1735:      old_end - old_addr < HPAGE_PMD_SIZE)",
          "",
          "[Added Lines]",
          "1725:     unsigned long new_addr, pmd_t *old_pmd, pmd_t *new_pmd)",
          "1732:  if ((old_addr & ~HPAGE_PMD_MASK) || (new_addr & ~HPAGE_PMD_MASK))",
          "",
          "---------------"
        ],
        "mm/mremap.c||mm/mremap.c": [
          "File: mm/mremap.c -> mm/mremap.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "194: #ifdef CONFIG_HAVE_MOVE_PMD",
          "195: static bool move_normal_pmd(struct vm_area_struct *vma, unsigned long old_addr,",
          "198: {",
          "199:  spinlock_t *old_ptl, *new_ptl;",
          "200:  struct mm_struct *mm = vma->vm_mm;",
          "201:  pmd_t pmd;",
          "205:   return false;",
          "",
          "[Removed Lines]",
          "196:     unsigned long new_addr, unsigned long old_end,",
          "197:     pmd_t *old_pmd, pmd_t *new_pmd)",
          "203:  if ((old_addr & ~PMD_MASK) || (new_addr & ~PMD_MASK)",
          "204:      || old_end - old_addr < PMD_SIZE)",
          "",
          "[Added Lines]",
          "196:     unsigned long new_addr, pmd_t *old_pmd, pmd_t *new_pmd)",
          "202:  if ((old_addr & ~PMD_MASK) || (new_addr & ~PMD_MASK))",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "292:     if (need_rmap_locks)",
          "293:      take_rmap_locks(vma);",
          "294:     moved = move_huge_pmd(vma, old_addr, new_addr,",
          "296:     if (need_rmap_locks)",
          "297:      drop_rmap_locks(vma);",
          "298:     if (moved)",
          "",
          "[Removed Lines]",
          "295:           old_end, old_pmd, new_pmd);",
          "",
          "[Added Lines]",
          "293:             old_pmd, new_pmd);",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "312:    if (need_rmap_locks)",
          "313:     take_rmap_locks(vma);",
          "314:    moved = move_normal_pmd(vma, old_addr, new_addr,",
          "316:    if (need_rmap_locks)",
          "317:     drop_rmap_locks(vma);",
          "318:    if (moved)",
          "",
          "[Removed Lines]",
          "315:      old_end, old_pmd, new_pmd);",
          "",
          "[Added Lines]",
          "313:       old_pmd, new_pmd);",
          "",
          "---------------"
        ]
      }
    }
  ]
}