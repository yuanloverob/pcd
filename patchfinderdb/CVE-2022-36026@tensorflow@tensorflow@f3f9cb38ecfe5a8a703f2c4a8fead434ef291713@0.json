{
  "cve_id": "CVE-2022-36026",
  "cve_desc": "TensorFlow is an open source platform for machine learning. If `QuantizeAndDequantizeV3` is given a nonscalar `num_bits` input tensor, it results in a `CHECK` fail that can be used to trigger a denial of service attack. We have patched the issue in GitHub commit f3f9cb38ecfe5a8a703f2c4a8fead434ef291713. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.",
  "repo": "tensorflow/tensorflow",
  "patch_hash": "f3f9cb38ecfe5a8a703f2c4a8fead434ef291713",
  "patch_info": {
    "commit_hash": "f3f9cb38ecfe5a8a703f2c4a8fead434ef291713",
    "repo": "tensorflow/tensorflow",
    "commit_url": "https://github.com/tensorflow/tensorflow/commit/f3f9cb38ecfe5a8a703f2c4a8fead434ef291713",
    "files": [
      "tensorflow/core/kernels/quantize_and_dequantize_op.cc",
      "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
    ],
    "message": "Validate the rank and number of elements of the `num_bits` tensor for QuantizeAndDequantizeV3.\n\nQuantizeAndDequantizeV3Op, which accepts `num_bits` as a tensor, has a precondition that it should be rank <= 1 and the number of elements should be 1.\nThis change adds a validation for the Compute() method for this condition.\n\nPiperOrigin-RevId: 463755293",
    "before_after_code_files": [
      "tensorflow/core/kernels/quantize_and_dequantize_op.cc||tensorflow/core/kernels/quantize_and_dequantize_op.cc",
      "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
    ]
  },
  "patch_diff": {
    "tensorflow/core/kernels/quantize_and_dequantize_op.cc||tensorflow/core/kernels/quantize_and_dequantize_op.cc": [
      "File: tensorflow/core/kernels/quantize_and_dequantize_op.cc -> tensorflow/core/kernels/quantize_and_dequantize_op.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "21: #define EIGEN_USE_GPU",
      "22: #endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
      "26: #include \"tensorflow/core/framework/op.h\"",
      "27: #include \"tensorflow/core/framework/op_kernel.h\"",
      "28: #include \"tensorflow/core/framework/register_types.h\"",
      "29: #include \"tensorflow/core/framework/type_traits.h\"",
      "30: #include \"tensorflow/core/framework/types.h\"",
      "31: #include \"tensorflow/core/lib/core/errors.h\"",
      "33: namespace tensorflow {",
      "",
      "[Removed Lines]",
      "24: #include \"tensorflow/core/kernels/quantize_and_dequantize_op.h\"",
      "35: typedef Eigen::ThreadPoolDevice CPUDevice;",
      "36: typedef Eigen::GpuDevice GPUDevice;",
      "",
      "[Added Lines]",
      "27: #include \"tensorflow/core/framework/tensor_shape.h\"",
      "30: #include \"tensorflow/core/kernels/quantize_and_dequantize_op.h\"",
      "34: namespace {",
      "36: using CpuDevice = ::Eigen::ThreadPoolDevice;",
      "37: using GpuDevice = ::Eigen::GpuDevice;",
      "38: using ::tensorflow::errors::InvalidArgument;",
      "40: }  // namespace",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "49:     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"axis\", &axis_));",
      "50:     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_bits\", &num_bits_));",
      "51:     OP_REQUIRES(ctx, num_bits_ > 0 && num_bits_ < (signed_input_ ? 62 : 63),",
      "54:     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));",
      "56:     string round_mode_string;",
      "",
      "[Removed Lines]",
      "52:                 errors::InvalidArgument(\"num_bits is out of range: \", num_bits_,",
      "53:                                         \" with signed_input_ \", signed_input_));",
      "",
      "[Added Lines]",
      "56:                 InvalidArgument(\"num_bits is out of range: \", num_bits_,",
      "57:                                 \" with signed_input_ \", signed_input_));",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "58:     OP_REQUIRES(",
      "59:         ctx,",
      "60:         (round_mode_string == \"HALF_UP\" || round_mode_string == \"HALF_TO_EVEN\"),",
      "65:     if (round_mode_string == \"HALF_UP\") {",
      "66:       round_mode_ = ROUND_HALF_UP;",
      "67:     } else if (round_mode_string == \"HALF_TO_EVEN\") {",
      "",
      "[Removed Lines]",
      "61:         errors::InvalidArgument(\"Round mode string must be \"",
      "62:                                 \"'HALF_UP' or \"",
      "63:                                 \"'HALF_TO_EVEN', is '\" +",
      "64:                                 round_mode_string + \"'\"));",
      "",
      "[Added Lines]",
      "65:         InvalidArgument(\"Round mode string must be \"",
      "66:                         \"'HALF_UP' or \"",
      "67:                         \"'HALF_TO_EVEN', is '\" +",
      "68:                         round_mode_string + \"'\"));",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "73:   void Compute(OpKernelContext* ctx) override {",
      "74:     const Tensor& input = ctx->input(0);",
      "81:                                 \" but is rank \", input.shape().dims()));",
      "82:     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);",
      "83:     Tensor input_min_tensor;",
      "",
      "[Removed Lines]",
      "75:     OP_REQUIRES(",
      "76:         ctx, axis_ >= -1,",
      "77:         errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));",
      "78:     OP_REQUIRES(",
      "79:         ctx, (axis_ == -1 || axis_ < input.shape().dims()),",
      "80:         errors::InvalidArgument(\"Shape must be at least rank \", axis_ + 1,",
      "",
      "[Added Lines]",
      "79:     OP_REQUIRES(ctx, axis_ >= -1,",
      "80:                 InvalidArgument(\"Axis must be at least -1. Found \", axis_));",
      "81:     OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),",
      "82:                 InvalidArgument(\"Shape must be at least rank \", axis_ + 1,",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "91:         auto min_val = input_min_tensor.scalar<T>()();",
      "92:         auto max_val = input_max_tensor.scalar<T>()();",
      "93:         OP_REQUIRES(ctx, min_val <= max_val,",
      "96:       } else {",
      "109:       }",
      "110:     } else {",
      "111:       auto range_shape = (axis_ == -1) ? TensorShape({}) : TensorShape({depth});",
      "",
      "[Removed Lines]",
      "94:                     errors::InvalidArgument(\"Invalid range: input_min \",",
      "95:                                             min_val, \" > input_max \", max_val));",
      "97:         OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,",
      "98:                     errors::InvalidArgument(",
      "99:                         \"input_min_tensor has incorrect size, was \",",
      "100:                         input_min_tensor.dim_size(0), \" expected \", depth,",
      "101:                         \" to match dim \", axis_, \" of the input \",",
      "102:                         input_min_tensor.shape()));",
      "103:         OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,",
      "104:                     errors::InvalidArgument(",
      "105:                         \"input_max_tensor has incorrect size, was \",",
      "106:                         input_max_tensor.dim_size(0), \" expected \", depth,",
      "107:                         \" to match dim \", axis_, \" of the input \",",
      "108:                         input_max_tensor.shape()));",
      "",
      "[Added Lines]",
      "96:                     InvalidArgument(\"Invalid range: input_min \", min_val,",
      "97:                                     \" > input_max \", max_val));",
      "99:         OP_REQUIRES(",
      "100:             ctx, input_min_tensor.dim_size(0) == depth,",
      "101:             InvalidArgument(\"input_min_tensor has incorrect size, was \",",
      "102:                             input_min_tensor.dim_size(0), \" expected \", depth,",
      "103:                             \" to match dim \", axis_, \" of the input \",",
      "104:                             input_min_tensor.shape()));",
      "105:         OP_REQUIRES(",
      "106:             ctx, input_max_tensor.dim_size(0) == depth,",
      "107:             InvalidArgument(\"input_max_tensor has incorrect size, was \",",
      "108:                             input_max_tensor.dim_size(0), \" expected \", depth,",
      "109:                             \" to match dim \", axis_, \" of the input \",",
      "110:                             input_max_tensor.shape()));",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "158:     Tensor* input_backprop = nullptr;",
      "159:     OP_REQUIRES_OK(ctx,",
      "160:                    ctx->allocate_output(0, input.shape(), &input_backprop));",
      "164:     OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),",
      "166:                     \"Axis should be -1 or 0 or a positive value less than \",",
      "167:                     input.shape().dims(), \"but given axis value was \", axis_));",
      "172:     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);",
      "173:     const Tensor& input_min_tensor = ctx->input(2);",
      "174:     OP_REQUIRES(ctx,",
      "175:                 input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,",
      "177:                     \"Input min tensor must have dimension 0 or 1. Received \",",
      "178:                     input_min_tensor.dims(), \".\"));",
      "179:     const Tensor& input_max_tensor = ctx->input(3);",
      "180:     OP_REQUIRES(ctx,",
      "181:                 input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,",
      "183:                     \"Input max tensor must have dimension 0 or 1. Received \",",
      "184:                     input_max_tensor.dims(), \".\"));",
      "185:     if (axis_ != -1) {",
      "189:                                   \" was \", input_min_tensor.dim_size(0)));",
      "193:                                   \" was \", input_max_tensor.dim_size(0)));",
      "194:     }",
      "",
      "[Removed Lines]",
      "161:     OP_REQUIRES(",
      "162:         ctx, axis_ >= -1,",
      "163:         errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));",
      "165:                 errors::InvalidArgument(",
      "169:     OP_REQUIRES(",
      "170:         ctx, input.IsSameSize(gradient),",
      "171:         errors::InvalidArgument(\"gradient and input must be the same size\"));",
      "176:                 errors::InvalidArgument(",
      "182:                 errors::InvalidArgument(",
      "186:       OP_REQUIRES(",
      "187:           ctx, input_min_tensor.dim_size(0) == depth,",
      "188:           errors::InvalidArgument(\"min has incorrect size, expected \", depth,",
      "190:       OP_REQUIRES(",
      "191:           ctx, input_max_tensor.dim_size(0) == depth,",
      "192:           errors::InvalidArgument(\"max has incorrect size, expected \", depth,",
      "",
      "[Added Lines]",
      "163:     OP_REQUIRES(ctx, axis_ >= -1,",
      "164:                 InvalidArgument(\"Axis must be at least -1. Found \", axis_));",
      "166:                 InvalidArgument(",
      "170:     OP_REQUIRES(ctx, input.IsSameSize(gradient),",
      "171:                 InvalidArgument(\"gradient and input must be the same size\"));",
      "176:                 InvalidArgument(",
      "182:                 InvalidArgument(",
      "186:       OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,",
      "187:                   InvalidArgument(\"min has incorrect size, expected \", depth,",
      "189:       OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,",
      "190:                   InvalidArgument(\"max has incorrect size, expected \", depth,",
      "",
      "---------------",
      "--- Hunk 7 ---",
      "[Context before]",
      "203:                    ctx->allocate_output(2, min_max_shape, &input_max_backprop));",
      "205:     if (axis_ == -1) {",
      "212:       functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;",
      "213:       f(ctx->eigen_device<Device>(), gradient.template flat<T>(),",
      "214:         input.template flat<T>(), input_min_tensor.scalar<T>(),",
      "",
      "[Removed Lines]",
      "206:       OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_min_tensor.shape()),",
      "207:                   errors::InvalidArgument(",
      "208:                       \"input_min must be a scalar if axis is unspecified\"));",
      "209:       OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_max_tensor.shape()),",
      "210:                   errors::InvalidArgument(",
      "211:                       \"input_max must be a scalar if axis is unspecified\"));",
      "",
      "[Added Lines]",
      "204:       OP_REQUIRES(",
      "205:           ctx, TensorShapeUtils::IsScalar(input_min_tensor.shape()),",
      "206:           InvalidArgument(\"input_min must be a scalar if axis is unspecified\"));",
      "207:       OP_REQUIRES(",
      "208:           ctx, TensorShapeUtils::IsScalar(input_max_tensor.shape()),",
      "209:           InvalidArgument(\"input_max must be a scalar if axis is unspecified\"));",
      "",
      "---------------",
      "--- Hunk 8 ---",
      "[Context before]",
      "252:   void Compute(OpKernelContext* ctx) override {",
      "253:     const Tensor& input = ctx->input(0);",
      "254:     OP_REQUIRES(ctx, axis_ < input.dims(),",
      "256:                     \"Axis requested is larger than input dimensions. Axis: \",",
      "257:                     axis_, \" Input Dimensions: \", input.dims()));",
      "258:     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);",
      "259:     Tensor* output = nullptr;",
      "260:     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
      "271:     Tensor input_min_tensor;",
      "272:     Tensor input_max_tensor;",
      "",
      "[Removed Lines]",
      "255:                 errors::InvalidArgument(",
      "262:     Tensor num_bits_tensor;",
      "263:     num_bits_tensor = ctx->input(3);",
      "264:     int num_bits_val = num_bits_tensor.scalar<int32>()();",
      "266:     OP_REQUIRES(",
      "267:         ctx, num_bits_val > 0 && num_bits_val < (signed_input_ ? 62 : 63),",
      "268:         errors::InvalidArgument(\"num_bits is out of range: \", num_bits_val,",
      "269:                                 \" with signed_input_ \", signed_input_));",
      "",
      "[Added Lines]",
      "253:                 InvalidArgument(",
      "261:     const Tensor num_bits_tensor = ctx->input(3);",
      "262:     OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(num_bits_tensor.shape()),",
      "263:                 InvalidArgument(\"Invalid shape. The `num_bits` tensor should \"",
      "264:                                 \"be a scalar. Got dimensions: \",",
      "265:                                 num_bits_tensor.dims()));",
      "267:     const int num_bits_val = num_bits_tensor.scalar<int32>()();",
      "268:     OP_REQUIRES(ctx,",
      "269:                 num_bits_val > 0 && num_bits_val < (signed_input_ ? 62 : 63),",
      "270:                 InvalidArgument(\"num_bits is out of range: \", num_bits_val,",
      "271:                                 \" with `signed_input_` \", signed_input_));",
      "",
      "---------------",
      "--- Hunk 9 ---",
      "[Context before]",
      "274:       input_min_tensor = ctx->input(1);",
      "275:       input_max_tensor = ctx->input(2);",
      "276:       if (axis_ == -1) {",
      "279:         OP_REQUIRES(ctx, min_val <= max_val,",
      "282:       } else {",
      "295:       }",
      "296:     } else {",
      "297:       auto range_shape = (axis_ == -1) ? TensorShape({}) : TensorShape({depth});",
      "",
      "[Removed Lines]",
      "277:         auto min_val = input_min_tensor.scalar<T>()();",
      "278:         auto max_val = input_max_tensor.scalar<T>()();",
      "280:                     errors::InvalidArgument(\"Invalid range: input_min \",",
      "281:                                             min_val, \" > input_max \", max_val));",
      "283:         OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,",
      "284:                     errors::InvalidArgument(",
      "285:                         \"input_min_tensor has incorrect size, was \",",
      "286:                         input_min_tensor.dim_size(0), \" expected \", depth,",
      "287:                         \" to match dim \", axis_, \" of the input \",",
      "288:                         input_min_tensor.shape()));",
      "289:         OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,",
      "290:                     errors::InvalidArgument(",
      "291:                         \"input_max_tensor has incorrect size, was \",",
      "292:                         input_max_tensor.dim_size(0), \" expected \", depth,",
      "293:                         \" to match dim \", axis_, \" of the input \",",
      "294:                         input_max_tensor.shape()));",
      "",
      "[Added Lines]",
      "279:         const auto min_val = input_min_tensor.scalar<T>()();",
      "280:         const auto max_val = input_max_tensor.scalar<T>()();",
      "282:                     InvalidArgument(\"Invalid range: input_min \", min_val,",
      "283:                                     \" > input_max \", max_val));",
      "285:         OP_REQUIRES(",
      "286:             ctx, input_min_tensor.dim_size(0) == depth,",
      "287:             InvalidArgument(\"input_min_tensor has incorrect size, was \",",
      "288:                             input_min_tensor.dim_size(0), \" expected \", depth,",
      "289:                             \" to match dim \", axis_, \" of the input \",",
      "290:                             input_min_tensor.shape()));",
      "291:         OP_REQUIRES(",
      "292:             ctx, input_max_tensor.dim_size(0) == depth,",
      "293:             InvalidArgument(\"input_max_tensor has incorrect size, was \",",
      "294:                             input_max_tensor.dim_size(0), \" expected \", depth,",
      "295:                             \" to match dim \", axis_, \" of the input \",",
      "296:                             input_max_tensor.shape()));",
      "",
      "---------------",
      "--- Hunk 10 ---",
      "[Context before]",
      "331:     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"signed_input\", &signed_input_));",
      "332:     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_bits\", &num_bits_));",
      "333:     OP_REQUIRES(ctx, num_bits_ > 0 && num_bits_ < (signed_input_ ? 62 : 63),",
      "336:     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));",
      "337:     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"input_min\", &input_min_));",
      "338:     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"input_max\", &input_max_));",
      "339:     if (range_given_) {",
      "343:                                   \" > input_max \", input_max_));",
      "344:     }",
      "345:   }",
      "",
      "[Removed Lines]",
      "334:                 errors::InvalidArgument(\"num_bits is out of range: \", num_bits_,",
      "335:                                         \" with signed_input_ \", signed_input_));",
      "340:       OP_REQUIRES(",
      "341:           ctx, input_min_ <= input_max_,",
      "342:           errors::InvalidArgument(\"Invalid range: input_min \", input_min_,",
      "",
      "[Added Lines]",
      "336:                 InvalidArgument(\"num_bits is out of range: \", num_bits_,",
      "337:                                 \" with signed_input_ \", signed_input_));",
      "342:       OP_REQUIRES(ctx, input_min_ <= input_max_,",
      "343:                   InvalidArgument(\"Invalid range: input_min \", input_min_,",
      "",
      "---------------",
      "--- Hunk 11 ---",
      "[Context before]",
      "371:   float input_max_;",
      "372: };",
      "376: namespace functor {",
      "377: template <typename T>",
      "380:                   const bool signed_input, const int num_bits,",
      "381:                   const bool range_given, Tensor* input_min_tensor,",
      "382:                   Tensor* input_max_tensor, QuantizerRoundMode round_mode,",
      "383:                   bool narrow_range, typename TTypes<T>::Vec out) {",
      "385:         d, input, signed_input, num_bits, range_given, input_min_tensor,",
      "386:         input_max_tensor, round_mode, narrow_range, out);",
      "387:   }",
      "388: };",
      "390: template <typename T>",
      "393:                   bool signed_input, int num_bits, bool range_given,",
      "394:                   Tensor* input_min_tensor, Tensor* input_max_tensor,",
      "395:                   QuantizerRoundMode round_mode, bool narrow_range,",
      "396:                   typename TTypes<T, 3>::Tensor out) {",
      "398:         d, input, signed_input, num_bits, range_given, input_min_tensor,",
      "399:         input_max_tensor, round_mode, narrow_range, out);",
      "400:   }",
      "401: };",
      "403: template <typename T>",
      "406:                   typename TTypes<T>::ConstFlat input,",
      "407:                   typename TTypes<T>::ConstScalar input_min_tensor,",
      "408:                   typename TTypes<T>::ConstScalar input_max_tensor,",
      "409:                   typename TTypes<T>::Flat input_backprop,",
      "410:                   typename TTypes<T>::Scalar input_min_backprop,",
      "411:                   typename TTypes<T>::Scalar input_max_backprop) {",
      "413:         d, gradient, input, input_min_tensor, input_max_tensor, input_backprop,",
      "414:         input_min_backprop, input_max_backprop);",
      "415:   }",
      "416: };",
      "418: template <typename T>",
      "421:                   typename TTypes<T, 3>::ConstTensor gradient,",
      "422:                   typename TTypes<T, 3>::ConstTensor input,",
      "423:                   const Tensor* input_min_tensor,",
      "",
      "[Removed Lines]",
      "378: struct QuantizeAndDequantizeOneScaleFunctor<CPUDevice, T> {",
      "379:   void operator()(const CPUDevice& d, typename TTypes<T>::ConstVec input,",
      "384:     QuantizeAndDequantizeOneScaleImpl<CPUDevice, T>::Compute(",
      "391: struct QuantizeAndDequantizePerChannelFunctor<CPUDevice, T> {",
      "392:   void operator()(const CPUDevice& d, typename TTypes<T, 3>::ConstTensor input,",
      "397:     QuantizeAndDequantizePerChannelImpl<CPUDevice, T>::Compute(",
      "404: struct QuantizeAndDequantizeOneScaleGradientFunctor<CPUDevice, T> {",
      "405:   void operator()(const CPUDevice& d, typename TTypes<T>::ConstFlat gradient,",
      "412:     QuantizeAndDequantizeOneScaleGradientImpl<CPUDevice, T>::Compute(",
      "419: struct QuantizeAndDequantizePerChannelGradientFunctor<CPUDevice, T> {",
      "420:   void operator()(const CPUDevice& d,",
      "",
      "[Added Lines]",
      "379: struct QuantizeAndDequantizeOneScaleFunctor<CpuDevice, T> {",
      "380:   void operator()(const CpuDevice& d, typename TTypes<T>::ConstVec input,",
      "385:     QuantizeAndDequantizeOneScaleImpl<CpuDevice, T>::Compute(",
      "392: struct QuantizeAndDequantizePerChannelFunctor<CpuDevice, T> {",
      "393:   void operator()(const CpuDevice& d, typename TTypes<T, 3>::ConstTensor input,",
      "398:     QuantizeAndDequantizePerChannelImpl<CpuDevice, T>::Compute(",
      "405: struct QuantizeAndDequantizeOneScaleGradientFunctor<CpuDevice, T> {",
      "406:   void operator()(const CpuDevice& d, typename TTypes<T>::ConstFlat gradient,",
      "413:     QuantizeAndDequantizeOneScaleGradientImpl<CpuDevice, T>::Compute(",
      "420: struct QuantizeAndDequantizePerChannelGradientFunctor<CpuDevice, T> {",
      "421:   void operator()(const CpuDevice& d,",
      "",
      "---------------",
      "--- Hunk 12 ---",
      "[Context before]",
      "425:                   typename TTypes<T, 3>::Tensor input_backprop,",
      "426:                   typename TTypes<T>::Flat input_min_backprop,",
      "427:                   typename TTypes<T>::Flat input_max_backprop) {",
      "429:         d, gradient, input, input_min_tensor, input_max_tensor, input_backprop,",
      "430:         input_min_backprop, input_max_backprop);",
      "431:   }",
      "432: };",
      "435:                                                                       float>;",
      "436: template struct functor::QuantizeAndDequantizePerChannelGradientFunctor<",
      "439: }  // namespace functor",
      "",
      "[Removed Lines]",
      "428:     QuantizeAndDequantizePerChannelGradientImpl<CPUDevice, T>::Compute(",
      "434: template struct functor::QuantizeAndDequantizeOneScaleGradientFunctor<CPUDevice,",
      "437:     CPUDevice, double>;",
      "",
      "[Added Lines]",
      "429:     QuantizeAndDequantizePerChannelGradientImpl<CpuDevice, T>::Compute(",
      "435: template struct functor::QuantizeAndDequantizeOneScaleGradientFunctor<CpuDevice,",
      "438:     CpuDevice, double>;",
      "",
      "---------------",
      "--- Hunk 13 ---",
      "[Context before]",
      "442:   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV2\")                      \\",
      "443:                               .Device(DEVICE_CPU)                              \\",
      "444:                               .TypeConstraint<T>(\"T\"),                         \\",
      "446:   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV3\")                      \\",
      "447:                               .Device(DEVICE_CPU)                              \\",
      "448:                               .TypeConstraint<T>(\"T\"),                         \\",
      "450:   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4\")                      \\",
      "451:                               .Device(DEVICE_CPU)                              \\",
      "452:                               .TypeConstraint<T>(\"T\"),                         \\",
      "454:   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4Grad\")                  \\",
      "455:                               .Device(DEVICE_CPU)                              \\",
      "456:                               .TypeConstraint<T>(\"T\"),                         \\",
      "458:   REGISTER_KERNEL_BUILDER(                                                     \\",
      "459:       Name(\"QuantizeAndDequantize\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\",
      "461: TF_CALL_float(REGISTER_CPU_KERNEL);",
      "462: TF_CALL_double(REGISTER_CPU_KERNEL);",
      "463: #undef REGISTER_CPU_KERNEL",
      "",
      "[Removed Lines]",
      "445:                           QuantizeAndDequantizeV2Op<CPUDevice, T>);            \\",
      "449:                           QuantizeAndDequantizeV3Op<CPUDevice, T>);            \\",
      "453:                           QuantizeAndDequantizeV2Op<CPUDevice, T>);            \\",
      "457:                           QuantizeAndDequantizeV4GradientOp<CPUDevice, T>);    \\",
      "460:       QuantizeAndDequantizeOp<CPUDevice, T>);",
      "",
      "[Added Lines]",
      "446:                           QuantizeAndDequantizeV2Op<CpuDevice, T>);            \\",
      "450:                           QuantizeAndDequantizeV3Op<CpuDevice, T>);            \\",
      "454:                           QuantizeAndDequantizeV2Op<CpuDevice, T>);            \\",
      "458:                           QuantizeAndDequantizeV4GradientOp<CpuDevice, T>);    \\",
      "461:       QuantizeAndDequantizeOp<CpuDevice, T>);",
      "",
      "---------------",
      "--- Hunk 14 ---",
      "[Context before]",
      "470:                               .HostMemory(\"input_min\")                         \\",
      "471:                               .HostMemory(\"input_max\")                         \\",
      "472:                               .TypeConstraint<T>(\"T\"),                         \\",
      "474:   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV3\")                      \\",
      "475:                               .Device(DEVICE_GPU)                              \\",
      "476:                               .HostMemory(\"input_min\")                         \\",
      "477:                               .HostMemory(\"input_max\")                         \\",
      "478:                               .HostMemory(\"num_bits\")                          \\",
      "479:                               .TypeConstraint<T>(\"T\"),                         \\",
      "481:   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4\")                      \\",
      "482:                               .Device(DEVICE_GPU)                              \\",
      "483:                               .HostMemory(\"input_min\")                         \\",
      "484:                               .HostMemory(\"input_max\")                         \\",
      "485:                               .TypeConstraint<T>(\"T\"),                         \\",
      "487:   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4Grad\")                  \\",
      "488:                               .Device(DEVICE_GPU)                              \\",
      "489:                               .HostMemory(\"input_min\")                         \\",
      "490:                               .HostMemory(\"input_max\")                         \\",
      "491:                               .TypeConstraint<T>(\"T\"),                         \\",
      "493:   REGISTER_KERNEL_BUILDER(                                                     \\",
      "494:       Name(\"QuantizeAndDequantize\").Device(DEVICE_GPU).TypeConstraint<T>(\"T\"), \\",
      "496: TF_CALL_float(REGISTER_GPU_KERNEL);",
      "497: TF_CALL_double(REGISTER_GPU_KERNEL);",
      "498: #undef REGISTER_GPU_KERNEL",
      "",
      "[Removed Lines]",
      "473:                           QuantizeAndDequantizeV2Op<GPUDevice, T>);            \\",
      "480:                           QuantizeAndDequantizeV3Op<GPUDevice, T>);            \\",
      "486:                           QuantizeAndDequantizeV2Op<GPUDevice, T>);            \\",
      "492:                           QuantizeAndDequantizeV4GradientOp<GPUDevice, T>);    \\",
      "495:       QuantizeAndDequantizeOp<GPUDevice, T>);",
      "",
      "[Added Lines]",
      "474:                           QuantizeAndDequantizeV2Op<GpuDevice, T>);            \\",
      "481:                           QuantizeAndDequantizeV3Op<GpuDevice, T>);            \\",
      "487:                           QuantizeAndDequantizeV2Op<GpuDevice, T>);            \\",
      "493:                           QuantizeAndDequantizeV4GradientOp<GpuDevice, T>);    \\",
      "496:       QuantizeAndDequantizeOp<GpuDevice, T>);",
      "",
      "---------------"
    ],
    "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py": [
      "File: tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py -> tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "15: \"\"\"Tests for tf.quantize ops.\"\"\"",
      "16: import numpy as np",
      "18: from tensorflow.python.framework import constant_op",
      "19: from tensorflow.python.framework import dtypes",
      "20: from tensorflow.python.framework import errors",
      "21: from tensorflow.python.framework import test_util",
      "22: from tensorflow.python.ops import array_ops",
      "23: from tensorflow.python.ops import math_ops",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "18: from tensorflow.python.eager import context",
      "22: from tensorflow.python.framework import ops",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "407:               out_type=dtypes.quint8))",
      "410: if __name__ == \"__main__\":",
      "411:   googletest.main()",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "412: class QuantizeAndDequantizeV3OpTest(test_util.TensorFlowTestCase):",
      "414:   @test_util.run_in_graph_and_eager_modes",
      "415:   def test_valid(self):",
      "416:     with ops.Graph().as_default(), context.eager_mode():",
      "417:       input_value = constant_op.constant([-0.8, -0.5, 0, 0.3, 0.8, -2.0],",
      "418:                                          shape=(6,),",
      "419:                                          dtype=dtypes.float32),",
      "420:       input_min = constant_op.constant(-127, shape=(), dtype=dtypes.float32)",
      "421:       input_max = constant_op.constant(127, shape=(), dtype=dtypes.float32)",
      "422:       num_bits = constant_op.constant(8, shape=(), dtype=dtypes.int32)",
      "424:       quantized = array_ops.quantize_and_dequantize_v3(",
      "425:           input_value,",
      "426:           input_min,",
      "427:           input_max,",
      "428:           num_bits,",
      "429:           signed_input=True,",
      "430:           range_given=False)",
      "431:       self.assertSequenceAlmostEqual(",
      "432:           input_value[0].numpy(), quantized.numpy()[0], delta=0.05)",
      "434:   @test_util.run_in_graph_and_eager_modes",
      "435:   def test_invalid_inputs(self):",
      "436:     input_value = constant_op.constant([-0.8, -0.5, 0, 0.3, 0.8, -2.0],",
      "437:                                        shape=(6,),",
      "438:                                        dtype=dtypes.float32),",
      "439:     input_min = constant_op.constant(-127, shape=(), dtype=dtypes.float32)",
      "440:     input_max = constant_op.constant(127, shape=(), dtype=dtypes.float32)",
      "441:     # Tensor with invalid shape and invalid number of elements.",
      "442:     num_bits = constant_op.constant([], shape=(0,), dtype=dtypes.int32)",
      "444:     # Test that running the op raises error. It raises different errors",
      "445:     # depending on whether the shape inference is run first or the op's",
      "446:     # Compute() is run first.",
      "447:     try:",
      "448:       array_ops.quantize_and_dequantize_v3(",
      "449:           input_value, input_min, input_max, num_bits, signed_input=True)",
      "450:     except Exception as ex:  # pylint: disable=broad-except",
      "451:       if isinstance(ex, errors.InvalidArgumentError):",
      "452:         self.assertRegex(str(ex), \"The `num_bits` tensor should be a scalar.\")",
      "453:       elif isinstance(ex, ValueError):",
      "454:         self.assertRegex(str(ex), \"Shape must be rank 0\")",
      "455:       else:",
      "456:         self.fail(",
      "457:             \"Raised exception other than expected: %s. \"",
      "458:             \"Expected exceptions are errors.InvalidArgumentError or ValueError\",",
      "459:             ex.__name__)",
      "460:     else:",
      "461:       self.fail(",
      "462:           \"Did not raise an exception where it is expected to raise either \"",
      "463:           \"a ValueError or errors.InvalidArgumentError.\")",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "098e7762d909bac47ce1dbabe6dfd06294cb9d58",
      "candidate_info": {
        "commit_hash": "098e7762d909bac47ce1dbabe6dfd06294cb9d58",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/098e7762d909bac47ce1dbabe6dfd06294cb9d58",
        "files": [
          "tensorflow/core/kernels/quantize_and_dequantize_op.cc"
        ],
        "message": "Fix tf.raw_ops.QuantizeAndDequantizeV4Grad vulnerability with invalid input_min or input_max.\n\nCheck that argument is actually a scalar before treating it as such.\n\nPiperOrigin-RevId: 445198280",
        "before_after_code_files": [
          "tensorflow/core/kernels/quantize_and_dequantize_op.cc||tensorflow/core/kernels/quantize_and_dequantize_op.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/quantize_and_dequantize_op.cc||tensorflow/core/kernels/quantize_and_dequantize_op.cc"
          ],
          "candidate": [
            "tensorflow/core/kernels/quantize_and_dequantize_op.cc||tensorflow/core/kernels/quantize_and_dequantize_op.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/quantize_and_dequantize_op.cc||tensorflow/core/kernels/quantize_and_dequantize_op.cc": [
          "File: tensorflow/core/kernels/quantize_and_dequantize_op.cc -> tensorflow/core/kernels/quantize_and_dequantize_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "174:     OP_REQUIRES(ctx,",
          "175:                 input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,",
          "176:                 errors::InvalidArgument(",
          "178:                     input_min_tensor.dims(), \".\"));",
          "179:     const Tensor& input_max_tensor = ctx->input(3);",
          "180:     OP_REQUIRES(ctx,",
          "181:                 input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,",
          "182:                 errors::InvalidArgument(",
          "184:                     input_max_tensor.dims(), \".\"));",
          "185:     if (axis_ != -1) {",
          "186:       OP_REQUIRES(",
          "",
          "[Removed Lines]",
          "177:                     \"Input min tensor must have dimension 1. Recieved \",",
          "183:                     \"Input max tensor must have dimension 1. Recieved \",",
          "",
          "[Added Lines]",
          "177:                     \"Input min tensor must have dimension 0 or 1. Received \",",
          "183:                     \"Input max tensor must have dimension 0 or 1. Received \",",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "203:                    ctx->allocate_output(2, min_max_shape, &input_max_backprop));",
          "205:     if (axis_ == -1) {",
          "206:       functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;",
          "207:       f(ctx->eigen_device<Device>(), gradient.template flat<T>(),",
          "208:         input.template flat<T>(), input_min_tensor.scalar<T>(),",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "206:       OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_min_tensor.shape()),",
          "207:                   errors::InvalidArgument(",
          "208:                       \"input_min must be a scalar if axis is unspecified\"));",
          "209:       OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_max_tensor.shape()),",
          "210:                   errors::InvalidArgument(",
          "211:                       \"input_max must be a scalar if axis is unspecified\"));",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "96f364a1ca3009f98980021c4b32be5fdcca33a1",
      "candidate_info": {
        "commit_hash": "96f364a1ca3009f98980021c4b32be5fdcca33a1",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/96f364a1ca3009f98980021c4b32be5fdcca33a1",
        "files": [
          "tensorflow/core/kernels/quantize_and_dequantize_op.cc"
        ],
        "message": "Validate axis input in tf.raw_ops.QuantizeAndDequantizeV4Grad\n\nPiperOrigin-RevId: 388291385\nChange-Id: I3bab68dc61d935afa96c0da021a7b722c6dc8dc8",
        "before_after_code_files": [
          "tensorflow/core/kernels/quantize_and_dequantize_op.cc||tensorflow/core/kernels/quantize_and_dequantize_op.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/quantize_and_dequantize_op.cc||tensorflow/core/kernels/quantize_and_dequantize_op.cc"
          ],
          "candidate": [
            "tensorflow/core/kernels/quantize_and_dequantize_op.cc||tensorflow/core/kernels/quantize_and_dequantize_op.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/quantize_and_dequantize_op.cc||tensorflow/core/kernels/quantize_and_dequantize_op.cc": [
          "File: tensorflow/core/kernels/quantize_and_dequantize_op.cc -> tensorflow/core/kernels/quantize_and_dequantize_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "158:     Tensor* input_backprop = nullptr;",
          "159:     OP_REQUIRES_OK(ctx,",
          "160:                    ctx->allocate_output(0, input.shape(), &input_backprop));",
          "162:     OP_REQUIRES(",
          "163:         ctx, input.IsSameSize(gradient),",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "161:     OP_REQUIRES(",
          "162:         ctx, axis_ >= -1,",
          "163:         errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));",
          "164:     OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),",
          "165:                 errors::InvalidArgument(",
          "166:                     \"Axis should be -1 or 0 or a positive value less than \",",
          "167:                     input.shape().dims(), \"but given axis value was \", axis_));",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "6eef86b9a7927445ce6e3f74e10939f2b9e9c965",
      "candidate_info": {
        "commit_hash": "6eef86b9a7927445ce6e3f74e10939f2b9e9c965",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/6eef86b9a7927445ce6e3f74e10939f2b9e9c965",
        "files": [
          "tensorflow/core/kernels/quantize_and_dequantize_op.cc",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ],
        "message": "Fix memory corruption in quantize_and_dequantize ops\n\nMemory corruption can happen when input min/max tensors are scalars and the axis is specified in these ops: QuantizeAndDequantizeV3Op, QuantizeAndDequantizeV4Op and QuantizeAndDequantizeV4GradientOp.\n\nAdded check for the dimension size of input min/max tensors to prevent the incorrect memory access.\n\nPiperOrigin-RevId: 524895739",
        "before_after_code_files": [
          "tensorflow/core/kernels/quantize_and_dequantize_op.cc||tensorflow/core/kernels/quantize_and_dequantize_op.cc",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/quantize_and_dequantize_op.cc||tensorflow/core/kernels/quantize_and_dequantize_op.cc",
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ],
          "candidate": [
            "tensorflow/core/kernels/quantize_and_dequantize_op.cc||tensorflow/core/kernels/quantize_and_dequantize_op.cc",
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/quantize_and_dequantize_op.cc||tensorflow/core/kernels/quantize_and_dequantize_op.cc": [
          "File: tensorflow/core/kernels/quantize_and_dequantize_op.cc -> tensorflow/core/kernels/quantize_and_dequantize_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "96:                     InvalidArgument(\"Invalid range: input_min \", min_val,",
          "97:                                     \" > input_max \", max_val));",
          "98:       } else {",
          "99:         OP_REQUIRES(",
          "100:             ctx, input_min_tensor.dim_size(0) == depth,",
          "101:             InvalidArgument(\"input_min_tensor has incorrect size, was \",",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "99:         OP_REQUIRES(",
          "100:             ctx, TensorShapeUtils::IsVector(input_min_tensor.shape()),",
          "101:             InvalidArgument(\"Shape must be rank 1 for input_min_tensor when the\"",
          "102:                             \" axis is specified\"));",
          "103:         OP_REQUIRES(",
          "104:             ctx, TensorShapeUtils::IsVector(input_max_tensor.shape()),",
          "105:             InvalidArgument(\"Shape must be rank 1 for input_max_tensor when the\"",
          "106:                             \" axis is specified\"));",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "183:                     \"Input max tensor must have dimension 0 or 1. Received \",",
          "184:                     input_max_tensor.dims(), \".\"));",
          "185:     if (axis_ != -1) {",
          "186:       OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,",
          "187:                   InvalidArgument(\"min has incorrect size, expected \", depth,",
          "188:                                   \" was \", input_min_tensor.dim_size(0)));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "194:       OP_REQUIRES(",
          "195:           ctx, TensorShapeUtils::IsVector(input_min_tensor.shape()),",
          "196:           InvalidArgument(\"Shape must be rank 1 for input_min_tensor when the\"",
          "197:                           \" axis is specified\"));",
          "198:       OP_REQUIRES(",
          "199:           ctx, TensorShapeUtils::IsVector(input_max_tensor.shape()),",
          "200:           InvalidArgument(\"Shape must be rank 1 for input_max_tensor when the\"",
          "201:                           \" axis is specified\"));",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "282:                     InvalidArgument(\"Invalid range: input_min \", min_val,",
          "283:                                     \" > input_max \", max_val));",
          "284:       } else {",
          "285:         OP_REQUIRES(",
          "286:             ctx, input_min_tensor.dim_size(0) == depth,",
          "287:             InvalidArgument(\"input_min_tensor has incorrect size, was \",",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "302:             ctx, TensorShapeUtils::IsVector(input_min_tensor.shape()),",
          "303:             InvalidArgument(\"Shape must be rank 1 for input_min_tensor when the\"",
          "304:                             \" axis is specified\"));",
          "305:         OP_REQUIRES(",
          "306:             ctx, TensorShapeUtils::IsVector(input_max_tensor.shape()),",
          "307:             InvalidArgument(\"Shape must be rank 1 for input_max_tensor when the\"",
          "308:                             \" axis is specified\"));",
          "309:         OP_REQUIRES(",
          "",
          "---------------"
        ],
        "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py": [
          "File: tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py -> tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "432:           input_value[0].numpy(), quantized.numpy()[0], delta=0.05)",
          "434:   @test_util.run_in_graph_and_eager_modes",
          "436:     input_value = constant_op.constant([-0.8, -0.5, 0, 0.3, 0.8, -2.0],",
          "437:                                        shape=(6,),",
          "438:                                        dtype=dtypes.float32),",
          "",
          "[Removed Lines]",
          "435:   def test_invalid_inputs(self):",
          "",
          "[Added Lines]",
          "435:   def test_invalid_num_bits(self):",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "455:       else:",
          "456:         self.fail(",
          "457:             \"Raised exception other than expected: %s. \"",
          "460:     else:",
          "461:       self.fail(",
          "462:           \"Did not raise an exception where it is expected to raise either \"",
          "463:           \"a ValueError or errors.InvalidArgumentError.\")",
          "466: if __name__ == \"__main__\":",
          "467:   googletest.main()",
          "",
          "[Removed Lines]",
          "458:             \"Expected exceptions are errors.InvalidArgumentError or ValueError\",",
          "459:             ex.__name__)",
          "",
          "[Added Lines]",
          "458:             \"Expected exceptions are errors.InvalidArgumentError or ValueError\"",
          "459:             % ex.__name__",
          "460:         )",
          "466:   @test_util.run_in_graph_and_eager_modes",
          "467:   def test_invalid_input_min_max_with_axis_specified(self):",
          "468:     input_value = (",
          "469:         constant_op.constant([1.8], shape=(1,), dtype=dtypes.float32),",
          "470:     )",
          "471:     input_min = constant_op.constant(1.0, shape=(), dtype=dtypes.float32)",
          "472:     input_max = constant_op.constant([2.0], shape=(1,), dtype=dtypes.float32)",
          "473:     num_bits = 8",
          "475:     # Test that running the op raises error. It raises different errors",
          "476:     # depending on whether the shape inference is run first or the op's",
          "477:     # Compute() is run first.",
          "478:     with self.assertRaisesRegex(",
          "479:         (errors.InvalidArgumentError, ValueError),",
          "480:         \"Shape must be rank 1\"):",
          "481:       array_ops.quantize_and_dequantize_v3(",
          "482:           input_value,",
          "483:           input_min,",
          "484:           input_max,",
          "485:           num_bits=num_bits,",
          "486:           axis=0,",
          "487:           range_given=True,",
          "488:       )",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "abc3ca2094639517358101235244fa20ff165ed9",
      "candidate_info": {
        "commit_hash": "abc3ca2094639517358101235244fa20ff165ed9",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/abc3ca2094639517358101235244fa20ff165ed9",
        "files": [
          "tensorflow/core/kernels/quantize_and_dequantize_op.cc",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ],
        "message": "Checks fails in QuantizeAndDequantizeV3.\n\nR2.8 Cherry-Pick cl/463755293 - Validate the rank and number of elements of the num_bits tensor for QuantizeAndDequantizeV3.",
        "before_after_code_files": [
          "tensorflow/core/kernels/quantize_and_dequantize_op.cc||tensorflow/core/kernels/quantize_and_dequantize_op.cc",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/quantize_and_dequantize_op.cc||tensorflow/core/kernels/quantize_and_dequantize_op.cc",
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ],
          "candidate": [
            "tensorflow/core/kernels/quantize_and_dequantize_op.cc||tensorflow/core/kernels/quantize_and_dequantize_op.cc",
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/quantize_and_dequantize_op.cc||tensorflow/core/kernels/quantize_and_dequantize_op.cc": [
          "File: tensorflow/core/kernels/quantize_and_dequantize_op.cc -> tensorflow/core/kernels/quantize_and_dequantize_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: #define EIGEN_USE_GPU",
          "22: #endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
          "26: #include \"tensorflow/core/framework/op.h\"",
          "27: #include \"tensorflow/core/framework/op_kernel.h\"",
          "28: #include \"tensorflow/core/framework/register_types.h\"",
          "29: #include \"tensorflow/core/framework/type_traits.h\"",
          "30: #include \"tensorflow/core/framework/types.h\"",
          "31: #include \"tensorflow/core/lib/core/errors.h\"",
          "33: namespace tensorflow {",
          "",
          "[Removed Lines]",
          "24: #include \"tensorflow/core/kernels/quantize_and_dequantize_op.h\"",
          "35: typedef Eigen::ThreadPoolDevice CPUDevice;",
          "36: typedef Eigen::GpuDevice GPUDevice;",
          "",
          "[Added Lines]",
          "27: #include \"tensorflow/core/framework/tensor_shape.h\"",
          "30: #include \"tensorflow/core/kernels/quantize_and_dequantize_op.h\"",
          "34: namespace {",
          "36: using CpuDevice = ::Eigen::ThreadPoolDevice;",
          "37: using GpuDevice = ::Eigen::GpuDevice;",
          "38: using ::tensorflow::errors::InvalidArgument;",
          "40: }  // namespace",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "49:     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"axis\", &axis_));",
          "50:     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_bits\", &num_bits_));",
          "51:     OP_REQUIRES(ctx, num_bits_ > 0 && num_bits_ < (signed_input_ ? 62 : 63),",
          "54:     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));",
          "56:     string round_mode_string;",
          "",
          "[Removed Lines]",
          "52:                 errors::InvalidArgument(\"num_bits is out of range: \", num_bits_,",
          "53:                                         \" with signed_input_ \", signed_input_));",
          "",
          "[Added Lines]",
          "56:                 InvalidArgument(\"num_bits is out of range: \", num_bits_,",
          "57:                                 \" with signed_input_ \", signed_input_));",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "58:     OP_REQUIRES(",
          "59:         ctx,",
          "60:         (round_mode_string == \"HALF_UP\" || round_mode_string == \"HALF_TO_EVEN\"),",
          "65:     if (round_mode_string == \"HALF_UP\") {",
          "66:       round_mode_ = ROUND_HALF_UP;",
          "67:     } else if (round_mode_string == \"HALF_TO_EVEN\") {",
          "",
          "[Removed Lines]",
          "61:         errors::InvalidArgument(\"Round mode string must be \"",
          "62:                                 \"'HALF_UP' or \"",
          "63:                                 \"'HALF_TO_EVEN', is '\" +",
          "64:                                 round_mode_string + \"'\"));",
          "",
          "[Added Lines]",
          "65:         InvalidArgument(\"Round mode string must be \"",
          "66:                         \"'HALF_UP' or \"",
          "67:                         \"'HALF_TO_EVEN', is '\" +",
          "68:                         round_mode_string + \"'\"));",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "73:   void Compute(OpKernelContext* ctx) override {",
          "74:     const Tensor& input = ctx->input(0);",
          "81:                                 \" but is rank \", input.shape().dims()));",
          "82:     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);",
          "83:     Tensor input_min_tensor;",
          "",
          "[Removed Lines]",
          "75:     OP_REQUIRES(",
          "76:         ctx, axis_ >= -1,",
          "77:         errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));",
          "78:     OP_REQUIRES(",
          "79:         ctx, (axis_ == -1 || axis_ < input.shape().dims()),",
          "80:         errors::InvalidArgument(\"Shape must be at least rank \", axis_ + 1,",
          "",
          "[Added Lines]",
          "79:     OP_REQUIRES(ctx, axis_ >= -1,",
          "80:                 InvalidArgument(\"Axis must be at least -1. Found \", axis_));",
          "81:     OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),",
          "82:                 InvalidArgument(\"Shape must be at least rank \", axis_ + 1,",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "91:         auto min_val = input_min_tensor.scalar<T>()();",
          "92:         auto max_val = input_max_tensor.scalar<T>()();",
          "93:         OP_REQUIRES(ctx, min_val <= max_val,",
          "96:       } else {",
          "109:       }",
          "110:     } else {",
          "111:       auto range_shape = (axis_ == -1) ? TensorShape({}) : TensorShape({depth});",
          "",
          "[Removed Lines]",
          "94:                     errors::InvalidArgument(\"Invalid range: input_min \",",
          "95:                                             min_val, \" > input_max \", max_val));",
          "97:         OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,",
          "98:                     errors::InvalidArgument(",
          "99:                         \"input_min_tensor has incorrect size, was \",",
          "100:                         input_min_tensor.dim_size(0), \" expected \", depth,",
          "101:                         \" to match dim \", axis_, \" of the input \",",
          "102:                         input_min_tensor.shape()));",
          "103:         OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,",
          "104:                     errors::InvalidArgument(",
          "105:                         \"input_max_tensor has incorrect size, was \",",
          "106:                         input_max_tensor.dim_size(0), \" expected \", depth,",
          "107:                         \" to match dim \", axis_, \" of the input \",",
          "108:                         input_max_tensor.shape()));",
          "",
          "[Added Lines]",
          "96:                     InvalidArgument(\"Invalid range: input_min \", min_val,",
          "97:                                     \" > input_max \", max_val));",
          "99:         OP_REQUIRES(",
          "100:             ctx, input_min_tensor.dim_size(0) == depth,",
          "101:             InvalidArgument(\"input_min_tensor has incorrect size, was \",",
          "102:                             input_min_tensor.dim_size(0), \" expected \", depth,",
          "103:                             \" to match dim \", axis_, \" of the input \",",
          "104:                             input_min_tensor.shape()));",
          "105:         OP_REQUIRES(",
          "106:             ctx, input_max_tensor.dim_size(0) == depth,",
          "107:             InvalidArgument(\"input_max_tensor has incorrect size, was \",",
          "108:                             input_max_tensor.dim_size(0), \" expected \", depth,",
          "109:                             \" to match dim \", axis_, \" of the input \",",
          "110:                             input_max_tensor.shape()));",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "158:     Tensor* input_backprop = nullptr;",
          "159:     OP_REQUIRES_OK(ctx,",
          "160:                    ctx->allocate_output(0, input.shape(), &input_backprop));",
          "164:     OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),",
          "166:                     \"Axis should be -1 or 0 or a positive value less than \",",
          "167:                     input.shape().dims(), \"but given axis value was \", axis_));",
          "172:     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);",
          "173:     const Tensor& input_min_tensor = ctx->input(2);",
          "174:     OP_REQUIRES(ctx,",
          "175:                 input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,",
          "177:                     \"Input min tensor must have dimension 0 or 1. Received \",",
          "178:                     input_min_tensor.dims(), \".\"));",
          "179:     const Tensor& input_max_tensor = ctx->input(3);",
          "180:     OP_REQUIRES(ctx,",
          "181:                 input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,",
          "183:                     \"Input max tensor must have dimension 0 or 1. Received \",",
          "184:                     input_max_tensor.dims(), \".\"));",
          "185:     if (axis_ != -1) {",
          "189:                                   \" was \", input_min_tensor.dim_size(0)));",
          "193:                                   \" was \", input_max_tensor.dim_size(0)));",
          "194:     }",
          "",
          "[Removed Lines]",
          "161:     OP_REQUIRES(",
          "162:         ctx, axis_ >= -1,",
          "163:         errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));",
          "165:                 errors::InvalidArgument(",
          "169:     OP_REQUIRES(",
          "170:         ctx, input.IsSameSize(gradient),",
          "171:         errors::InvalidArgument(\"gradient and input must be the same size\"));",
          "176:                 errors::InvalidArgument(",
          "182:                 errors::InvalidArgument(",
          "186:       OP_REQUIRES(",
          "187:           ctx, input_min_tensor.dim_size(0) == depth,",
          "188:           errors::InvalidArgument(\"min has incorrect size, expected \", depth,",
          "190:       OP_REQUIRES(",
          "191:           ctx, input_max_tensor.dim_size(0) == depth,",
          "192:           errors::InvalidArgument(\"max has incorrect size, expected \", depth,",
          "",
          "[Added Lines]",
          "163:     OP_REQUIRES(ctx, axis_ >= -1,",
          "164:                 InvalidArgument(\"Axis must be at least -1. Found \", axis_));",
          "166:                 InvalidArgument(",
          "170:     OP_REQUIRES(ctx, input.IsSameSize(gradient),",
          "171:                 InvalidArgument(\"gradient and input must be the same size\"));",
          "176:                 InvalidArgument(",
          "182:                 InvalidArgument(",
          "186:       OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,",
          "187:                   InvalidArgument(\"min has incorrect size, expected \", depth,",
          "189:       OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,",
          "190:                   InvalidArgument(\"max has incorrect size, expected \", depth,",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "203:                    ctx->allocate_output(2, min_max_shape, &input_max_backprop));",
          "205:     if (axis_ == -1) {",
          "212:       functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;",
          "213:       f(ctx->eigen_device<Device>(), gradient.template flat<T>(),",
          "214:         input.template flat<T>(), input_min_tensor.scalar<T>(),",
          "",
          "[Removed Lines]",
          "206:       OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_min_tensor.shape()),",
          "207:                   errors::InvalidArgument(",
          "208:                       \"input_min must be a scalar if axis is unspecified\"));",
          "209:       OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_max_tensor.shape()),",
          "210:                   errors::InvalidArgument(",
          "211:                       \"input_max must be a scalar if axis is unspecified\"));",
          "",
          "[Added Lines]",
          "204:       OP_REQUIRES(",
          "205:           ctx, TensorShapeUtils::IsScalar(input_min_tensor.shape()),",
          "206:           InvalidArgument(\"input_min must be a scalar if axis is unspecified\"));",
          "207:       OP_REQUIRES(",
          "208:           ctx, TensorShapeUtils::IsScalar(input_max_tensor.shape()),",
          "209:           InvalidArgument(\"input_max must be a scalar if axis is unspecified\"));",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "252:   void Compute(OpKernelContext* ctx) override {",
          "253:     const Tensor& input = ctx->input(0);",
          "254:     OP_REQUIRES(ctx, axis_ < input.dims(),",
          "256:                     \"Axis requested is larger than input dimensions. Axis: \",",
          "257:                     axis_, \" Input Dimensions: \", input.dims()));",
          "258:     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);",
          "259:     Tensor* output = nullptr;",
          "260:     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
          "271:     Tensor input_min_tensor;",
          "272:     Tensor input_max_tensor;",
          "",
          "[Removed Lines]",
          "255:                 errors::InvalidArgument(",
          "262:     Tensor num_bits_tensor;",
          "263:     num_bits_tensor = ctx->input(3);",
          "264:     int num_bits_val = num_bits_tensor.scalar<int32>()();",
          "266:     OP_REQUIRES(",
          "267:         ctx, num_bits_val > 0 && num_bits_val < (signed_input_ ? 62 : 63),",
          "268:         errors::InvalidArgument(\"num_bits is out of range: \", num_bits_val,",
          "269:                                 \" with signed_input_ \", signed_input_));",
          "",
          "[Added Lines]",
          "253:                 InvalidArgument(",
          "261:     const Tensor num_bits_tensor = ctx->input(3);",
          "262:     OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(num_bits_tensor.shape()),",
          "263:                 InvalidArgument(\"Invalid shape. The `num_bits` tensor should \"",
          "264:                                 \"be a scalar. Got dimensions: \",",
          "265:                                 num_bits_tensor.dims()));",
          "267:     const int num_bits_val = num_bits_tensor.scalar<int32>()();",
          "268:     OP_REQUIRES(ctx,",
          "269:                 num_bits_val > 0 && num_bits_val < (signed_input_ ? 62 : 63),",
          "270:                 InvalidArgument(\"num_bits is out of range: \", num_bits_val,",
          "271:                                 \" with `signed_input_` \", signed_input_));",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "274:       input_min_tensor = ctx->input(1);",
          "275:       input_max_tensor = ctx->input(2);",
          "276:       if (axis_ == -1) {",
          "279:         OP_REQUIRES(ctx, min_val <= max_val,",
          "282:       } else {",
          "295:       }",
          "296:     } else {",
          "297:       auto range_shape = (axis_ == -1) ? TensorShape({}) : TensorShape({depth});",
          "",
          "[Removed Lines]",
          "277:         auto min_val = input_min_tensor.scalar<T>()();",
          "278:         auto max_val = input_max_tensor.scalar<T>()();",
          "280:                     errors::InvalidArgument(\"Invalid range: input_min \",",
          "281:                                             min_val, \" > input_max \", max_val));",
          "283:         OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,",
          "284:                     errors::InvalidArgument(",
          "285:                         \"input_min_tensor has incorrect size, was \",",
          "286:                         input_min_tensor.dim_size(0), \" expected \", depth,",
          "287:                         \" to match dim \", axis_, \" of the input \",",
          "288:                         input_min_tensor.shape()));",
          "289:         OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,",
          "290:                     errors::InvalidArgument(",
          "291:                         \"input_max_tensor has incorrect size, was \",",
          "292:                         input_max_tensor.dim_size(0), \" expected \", depth,",
          "293:                         \" to match dim \", axis_, \" of the input \",",
          "294:                         input_max_tensor.shape()));",
          "",
          "[Added Lines]",
          "279:         const auto min_val = input_min_tensor.scalar<T>()();",
          "280:         const auto max_val = input_max_tensor.scalar<T>()();",
          "282:                     InvalidArgument(\"Invalid range: input_min \", min_val,",
          "283:                                     \" > input_max \", max_val));",
          "285:         OP_REQUIRES(",
          "286:             ctx, input_min_tensor.dim_size(0) == depth,",
          "287:             InvalidArgument(\"input_min_tensor has incorrect size, was \",",
          "288:                             input_min_tensor.dim_size(0), \" expected \", depth,",
          "289:                             \" to match dim \", axis_, \" of the input \",",
          "290:                             input_min_tensor.shape()));",
          "291:         OP_REQUIRES(",
          "292:             ctx, input_max_tensor.dim_size(0) == depth,",
          "293:             InvalidArgument(\"input_max_tensor has incorrect size, was \",",
          "294:                             input_max_tensor.dim_size(0), \" expected \", depth,",
          "295:                             \" to match dim \", axis_, \" of the input \",",
          "296:                             input_max_tensor.shape()));",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "331:     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"signed_input\", &signed_input_));",
          "332:     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_bits\", &num_bits_));",
          "333:     OP_REQUIRES(ctx, num_bits_ > 0 && num_bits_ < (signed_input_ ? 62 : 63),",
          "336:     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));",
          "337:     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"input_min\", &input_min_));",
          "338:     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"input_max\", &input_max_));",
          "339:     if (range_given_) {",
          "343:                                   \" > input_max \", input_max_));",
          "344:     }",
          "345:   }",
          "",
          "[Removed Lines]",
          "334:                 errors::InvalidArgument(\"num_bits is out of range: \", num_bits_,",
          "335:                                         \" with signed_input_ \", signed_input_));",
          "340:       OP_REQUIRES(",
          "341:           ctx, input_min_ <= input_max_,",
          "342:           errors::InvalidArgument(\"Invalid range: input_min \", input_min_,",
          "",
          "[Added Lines]",
          "336:                 InvalidArgument(\"num_bits is out of range: \", num_bits_,",
          "337:                                 \" with signed_input_ \", signed_input_));",
          "342:       OP_REQUIRES(ctx, input_min_ <= input_max_,",
          "343:                   InvalidArgument(\"Invalid range: input_min \", input_min_,",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "371:   float input_max_;",
          "372: };",
          "376: namespace functor {",
          "377: template <typename T>",
          "380:                   const bool signed_input, const int num_bits,",
          "381:                   const bool range_given, Tensor* input_min_tensor,",
          "382:                   Tensor* input_max_tensor, QuantizerRoundMode round_mode,",
          "383:                   bool narrow_range, typename TTypes<T>::Vec out) {",
          "385:         d, input, signed_input, num_bits, range_given, input_min_tensor,",
          "386:         input_max_tensor, round_mode, narrow_range, out);",
          "387:   }",
          "388: };",
          "390: template <typename T>",
          "393:                   bool signed_input, int num_bits, bool range_given,",
          "394:                   Tensor* input_min_tensor, Tensor* input_max_tensor,",
          "395:                   QuantizerRoundMode round_mode, bool narrow_range,",
          "396:                   typename TTypes<T, 3>::Tensor out) {",
          "398:         d, input, signed_input, num_bits, range_given, input_min_tensor,",
          "399:         input_max_tensor, round_mode, narrow_range, out);",
          "400:   }",
          "401: };",
          "403: template <typename T>",
          "406:                   typename TTypes<T>::ConstFlat input,",
          "407:                   typename TTypes<T>::ConstScalar input_min_tensor,",
          "408:                   typename TTypes<T>::ConstScalar input_max_tensor,",
          "409:                   typename TTypes<T>::Flat input_backprop,",
          "410:                   typename TTypes<T>::Scalar input_min_backprop,",
          "411:                   typename TTypes<T>::Scalar input_max_backprop) {",
          "413:         d, gradient, input, input_min_tensor, input_max_tensor, input_backprop,",
          "414:         input_min_backprop, input_max_backprop);",
          "415:   }",
          "416: };",
          "418: template <typename T>",
          "421:                   typename TTypes<T, 3>::ConstTensor gradient,",
          "422:                   typename TTypes<T, 3>::ConstTensor input,",
          "423:                   const Tensor* input_min_tensor,",
          "",
          "[Removed Lines]",
          "378: struct QuantizeAndDequantizeOneScaleFunctor<CPUDevice, T> {",
          "379:   void operator()(const CPUDevice& d, typename TTypes<T>::ConstVec input,",
          "384:     QuantizeAndDequantizeOneScaleImpl<CPUDevice, T>::Compute(",
          "391: struct QuantizeAndDequantizePerChannelFunctor<CPUDevice, T> {",
          "392:   void operator()(const CPUDevice& d, typename TTypes<T, 3>::ConstTensor input,",
          "397:     QuantizeAndDequantizePerChannelImpl<CPUDevice, T>::Compute(",
          "404: struct QuantizeAndDequantizeOneScaleGradientFunctor<CPUDevice, T> {",
          "405:   void operator()(const CPUDevice& d, typename TTypes<T>::ConstFlat gradient,",
          "412:     QuantizeAndDequantizeOneScaleGradientImpl<CPUDevice, T>::Compute(",
          "419: struct QuantizeAndDequantizePerChannelGradientFunctor<CPUDevice, T> {",
          "420:   void operator()(const CPUDevice& d,",
          "",
          "[Added Lines]",
          "379: struct QuantizeAndDequantizeOneScaleFunctor<CpuDevice, T> {",
          "380:   void operator()(const CpuDevice& d, typename TTypes<T>::ConstVec input,",
          "385:     QuantizeAndDequantizeOneScaleImpl<CpuDevice, T>::Compute(",
          "392: struct QuantizeAndDequantizePerChannelFunctor<CpuDevice, T> {",
          "393:   void operator()(const CpuDevice& d, typename TTypes<T, 3>::ConstTensor input,",
          "398:     QuantizeAndDequantizePerChannelImpl<CpuDevice, T>::Compute(",
          "405: struct QuantizeAndDequantizeOneScaleGradientFunctor<CpuDevice, T> {",
          "406:   void operator()(const CpuDevice& d, typename TTypes<T>::ConstFlat gradient,",
          "413:     QuantizeAndDequantizeOneScaleGradientImpl<CpuDevice, T>::Compute(",
          "420: struct QuantizeAndDequantizePerChannelGradientFunctor<CpuDevice, T> {",
          "421:   void operator()(const CpuDevice& d,",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "425:                   typename TTypes<T, 3>::Tensor input_backprop,",
          "426:                   typename TTypes<T>::Flat input_min_backprop,",
          "427:                   typename TTypes<T>::Flat input_max_backprop) {",
          "429:         d, gradient, input, input_min_tensor, input_max_tensor, input_backprop,",
          "430:         input_min_backprop, input_max_backprop);",
          "431:   }",
          "432: };",
          "435:                                                                       float>;",
          "436: template struct functor::QuantizeAndDequantizePerChannelGradientFunctor<",
          "439: }  // namespace functor",
          "",
          "[Removed Lines]",
          "428:     QuantizeAndDequantizePerChannelGradientImpl<CPUDevice, T>::Compute(",
          "434: template struct functor::QuantizeAndDequantizeOneScaleGradientFunctor<CPUDevice,",
          "437:     CPUDevice, double>;",
          "",
          "[Added Lines]",
          "429:     QuantizeAndDequantizePerChannelGradientImpl<CpuDevice, T>::Compute(",
          "435: template struct functor::QuantizeAndDequantizeOneScaleGradientFunctor<CpuDevice,",
          "438:     CpuDevice, double>;",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "442:   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV2\")                      \\",
          "443:                               .Device(DEVICE_CPU)                              \\",
          "444:                               .TypeConstraint<T>(\"T\"),                         \\",
          "446:   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV3\")                      \\",
          "447:                               .Device(DEVICE_CPU)                              \\",
          "448:                               .TypeConstraint<T>(\"T\"),                         \\",
          "450:   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4\")                      \\",
          "451:                               .Device(DEVICE_CPU)                              \\",
          "452:                               .TypeConstraint<T>(\"T\"),                         \\",
          "454:   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4Grad\")                  \\",
          "455:                               .Device(DEVICE_CPU)                              \\",
          "456:                               .TypeConstraint<T>(\"T\"),                         \\",
          "458:   REGISTER_KERNEL_BUILDER(                                                     \\",
          "459:       Name(\"QuantizeAndDequantize\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\",
          "461: TF_CALL_float(REGISTER_CPU_KERNEL);",
          "462: TF_CALL_double(REGISTER_CPU_KERNEL);",
          "463: #undef REGISTER_CPU_KERNEL",
          "",
          "[Removed Lines]",
          "445:                           QuantizeAndDequantizeV2Op<CPUDevice, T>);            \\",
          "449:                           QuantizeAndDequantizeV3Op<CPUDevice, T>);            \\",
          "453:                           QuantizeAndDequantizeV2Op<CPUDevice, T>);            \\",
          "457:                           QuantizeAndDequantizeV4GradientOp<CPUDevice, T>);    \\",
          "460:       QuantizeAndDequantizeOp<CPUDevice, T>);",
          "",
          "[Added Lines]",
          "446:                           QuantizeAndDequantizeV2Op<CpuDevice, T>);            \\",
          "450:                           QuantizeAndDequantizeV3Op<CpuDevice, T>);            \\",
          "454:                           QuantizeAndDequantizeV2Op<CpuDevice, T>);            \\",
          "458:                           QuantizeAndDequantizeV4GradientOp<CpuDevice, T>);    \\",
          "461:       QuantizeAndDequantizeOp<CpuDevice, T>);",
          "",
          "---------------",
          "--- Hunk 14 ---",
          "[Context before]",
          "470:                               .HostMemory(\"input_min\")                         \\",
          "471:                               .HostMemory(\"input_max\")                         \\",
          "472:                               .TypeConstraint<T>(\"T\"),                         \\",
          "474:   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV3\")                      \\",
          "475:                               .Device(DEVICE_GPU)                              \\",
          "476:                               .HostMemory(\"input_min\")                         \\",
          "477:                               .HostMemory(\"input_max\")                         \\",
          "478:                               .HostMemory(\"num_bits\")                          \\",
          "479:                               .TypeConstraint<T>(\"T\"),                         \\",
          "481:   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4\")                      \\",
          "482:                               .Device(DEVICE_GPU)                              \\",
          "483:                               .HostMemory(\"input_min\")                         \\",
          "484:                               .HostMemory(\"input_max\")                         \\",
          "485:                               .TypeConstraint<T>(\"T\"),                         \\",
          "487:   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4Grad\")                  \\",
          "488:                               .Device(DEVICE_GPU)                              \\",
          "489:                               .HostMemory(\"input_min\")                         \\",
          "490:                               .HostMemory(\"input_max\")                         \\",
          "491:                               .TypeConstraint<T>(\"T\"),                         \\",
          "493:   REGISTER_KERNEL_BUILDER(                                                     \\",
          "494:       Name(\"QuantizeAndDequantize\").Device(DEVICE_GPU).TypeConstraint<T>(\"T\"), \\",
          "496: TF_CALL_float(REGISTER_GPU_KERNEL);",
          "497: TF_CALL_double(REGISTER_GPU_KERNEL);",
          "498: #undef REGISTER_GPU_KERNEL",
          "",
          "[Removed Lines]",
          "473:                           QuantizeAndDequantizeV2Op<GPUDevice, T>);            \\",
          "480:                           QuantizeAndDequantizeV3Op<GPUDevice, T>);            \\",
          "486:                           QuantizeAndDequantizeV2Op<GPUDevice, T>);            \\",
          "492:                           QuantizeAndDequantizeV4GradientOp<GPUDevice, T>);    \\",
          "495:       QuantizeAndDequantizeOp<GPUDevice, T>);",
          "",
          "[Added Lines]",
          "474:                           QuantizeAndDequantizeV2Op<GpuDevice, T>);            \\",
          "481:                           QuantizeAndDequantizeV3Op<GpuDevice, T>);            \\",
          "487:                           QuantizeAndDequantizeV2Op<GpuDevice, T>);            \\",
          "493:                           QuantizeAndDequantizeV4GradientOp<GpuDevice, T>);    \\",
          "496:       QuantizeAndDequantizeOp<GpuDevice, T>);",
          "",
          "---------------"
        ],
        "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py": [
          "File: tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py -> tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "15: \"\"\"Tests for tf.quantize ops.\"\"\"",
          "16: import numpy as np",
          "18: from tensorflow.python.framework import constant_op",
          "19: from tensorflow.python.framework import dtypes",
          "20: from tensorflow.python.framework import errors",
          "21: from tensorflow.python.framework import test_util",
          "22: from tensorflow.python.ops import array_ops",
          "23: from tensorflow.python.ops import math_ops",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: from tensorflow.python.eager import context",
          "22: from tensorflow.python.framework import ops",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "327:               out_type=dtypes.quint8))",
          "330: if __name__ == \"__main__\":",
          "331:   googletest.main()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "332: class QuantizeAndDequantizeV3OpTest(test_util.TensorFlowTestCase):",
          "334:   @test_util.run_in_graph_and_eager_modes",
          "335:   def test_valid(self):",
          "336:     with ops.Graph().as_default(), context.eager_mode():",
          "337:       input_value = constant_op.constant([-0.8, -0.5, 0, 0.3, 0.8, -2.0],",
          "338:                                          shape=(6,),",
          "339:                                          dtype=dtypes.float32),",
          "340:       input_min = constant_op.constant(-127, shape=(), dtype=dtypes.float32)",
          "341:       input_max = constant_op.constant(127, shape=(), dtype=dtypes.float32)",
          "342:       num_bits = constant_op.constant(8, shape=(), dtype=dtypes.int32)",
          "344:       quantized = array_ops.quantize_and_dequantize_v3(",
          "345:           input_value,",
          "346:           input_min,",
          "347:           input_max,",
          "348:           num_bits,",
          "349:           signed_input=True,",
          "350:           range_given=False)",
          "351:       self.assertSequenceAlmostEqual(",
          "352:           input_value[0].numpy(), quantized.numpy()[0], delta=0.05)",
          "354:   @test_util.run_in_graph_and_eager_modes",
          "355:   def test_invalid_inputs(self):",
          "356:     input_value = constant_op.constant([-0.8, -0.5, 0, 0.3, 0.8, -2.0],",
          "357:                                        shape=(6,),",
          "358:                                        dtype=dtypes.float32),",
          "359:     input_min = constant_op.constant(-127, shape=(), dtype=dtypes.float32)",
          "360:     input_max = constant_op.constant(127, shape=(), dtype=dtypes.float32)",
          "361:     # Tensor with invalid shape and invalid number of elements.",
          "362:     num_bits = constant_op.constant([], shape=(0,), dtype=dtypes.int32)",
          "364:     # Test that running the op raises error. It raises different errors",
          "365:     # depending on whether the shape inference is run first or the op's",
          "366:     # Compute() is run first.",
          "367:     try:",
          "368:       array_ops.quantize_and_dequantize_v3(",
          "369:           input_value, input_min, input_max, num_bits, signed_input=True)",
          "370:     except Exception as ex:  # pylint: disable=broad-except",
          "371:       if isinstance(ex, errors.InvalidArgumentError):",
          "372:         self.assertRegex(str(ex), \"The `num_bits` tensor should be a scalar.\")",
          "373:       elif isinstance(ex, ValueError):",
          "374:         self.assertRegex(str(ex), \"Shape must be rank 0\")",
          "375:       else:",
          "376:         self.fail(",
          "377:             \"Raised exception other than expected: %s. \"",
          "378:             \"Expected exceptions are errors.InvalidArgumentError or ValueError\",",
          "379:             ex.__name__)",
          "380:     else:",
          "381:       self.fail(",
          "382:           \"Did not raise an exception where it is expected to raise either \"",
          "383:           \"a ValueError or errors.InvalidArgumentError.\")",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "d1aa5a5ee2ca0a42864d423d9927935807002b68",
      "candidate_info": {
        "commit_hash": "d1aa5a5ee2ca0a42864d423d9927935807002b68",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/d1aa5a5ee2ca0a42864d423d9927935807002b68",
        "files": [
          "tensorflow/core/kernels/quantize_and_dequantize_op.cc",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ],
        "message": "Validate the rank and number of elements of the `num_bits` tensor for QuantizeAndDequantizeV3.\n\nQuantizeAndDequantizeV3Op, which accepts `num_bits` as a tensor, has a precondition that it should be rank <= 1 and the number of elements should be 1.\nThis change adds a validation for the Compute() method for this condition.\n\nPiperOrigin-RevId: 463755293",
        "before_after_code_files": [
          "tensorflow/core/kernels/quantize_and_dequantize_op.cc||tensorflow/core/kernels/quantize_and_dequantize_op.cc",
          "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/quantize_and_dequantize_op.cc||tensorflow/core/kernels/quantize_and_dequantize_op.cc",
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ],
          "candidate": [
            "tensorflow/core/kernels/quantize_and_dequantize_op.cc||tensorflow/core/kernels/quantize_and_dequantize_op.cc",
            "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/quantize_and_dequantize_op.cc||tensorflow/core/kernels/quantize_and_dequantize_op.cc": [
          "File: tensorflow/core/kernels/quantize_and_dequantize_op.cc -> tensorflow/core/kernels/quantize_and_dequantize_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: #define EIGEN_USE_GPU",
          "22: #endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM",
          "26: #include \"tensorflow/core/framework/op.h\"",
          "27: #include \"tensorflow/core/framework/op_kernel.h\"",
          "28: #include \"tensorflow/core/framework/register_types.h\"",
          "29: #include \"tensorflow/core/framework/type_traits.h\"",
          "30: #include \"tensorflow/core/framework/types.h\"",
          "31: #include \"tensorflow/core/lib/core/errors.h\"",
          "33: namespace tensorflow {",
          "",
          "[Removed Lines]",
          "24: #include \"tensorflow/core/kernels/quantize_and_dequantize_op.h\"",
          "35: typedef Eigen::ThreadPoolDevice CPUDevice;",
          "36: typedef Eigen::GpuDevice GPUDevice;",
          "",
          "[Added Lines]",
          "27: #include \"tensorflow/core/framework/tensor_shape.h\"",
          "30: #include \"tensorflow/core/kernels/quantize_and_dequantize_op.h\"",
          "34: namespace {",
          "36: using CpuDevice = ::Eigen::ThreadPoolDevice;",
          "37: using GpuDevice = ::Eigen::GpuDevice;",
          "38: using ::tensorflow::errors::InvalidArgument;",
          "40: }  // namespace",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "49:     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"axis\", &axis_));",
          "50:     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_bits\", &num_bits_));",
          "51:     OP_REQUIRES(ctx, num_bits_ > 0 && num_bits_ < (signed_input_ ? 62 : 63),",
          "54:     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));",
          "56:     string round_mode_string;",
          "",
          "[Removed Lines]",
          "52:                 errors::InvalidArgument(\"num_bits is out of range: \", num_bits_,",
          "53:                                         \" with signed_input_ \", signed_input_));",
          "",
          "[Added Lines]",
          "56:                 InvalidArgument(\"num_bits is out of range: \", num_bits_,",
          "57:                                 \" with signed_input_ \", signed_input_));",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "58:     OP_REQUIRES(",
          "59:         ctx,",
          "60:         (round_mode_string == \"HALF_UP\" || round_mode_string == \"HALF_TO_EVEN\"),",
          "65:     if (round_mode_string == \"HALF_UP\") {",
          "66:       round_mode_ = ROUND_HALF_UP;",
          "67:     } else if (round_mode_string == \"HALF_TO_EVEN\") {",
          "",
          "[Removed Lines]",
          "61:         errors::InvalidArgument(\"Round mode string must be \"",
          "62:                                 \"'HALF_UP' or \"",
          "63:                                 \"'HALF_TO_EVEN', is '\" +",
          "64:                                 round_mode_string + \"'\"));",
          "",
          "[Added Lines]",
          "65:         InvalidArgument(\"Round mode string must be \"",
          "66:                         \"'HALF_UP' or \"",
          "67:                         \"'HALF_TO_EVEN', is '\" +",
          "68:                         round_mode_string + \"'\"));",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "73:   void Compute(OpKernelContext* ctx) override {",
          "74:     const Tensor& input = ctx->input(0);",
          "81:                                 \" but is rank \", input.shape().dims()));",
          "82:     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);",
          "83:     Tensor input_min_tensor;",
          "",
          "[Removed Lines]",
          "75:     OP_REQUIRES(",
          "76:         ctx, axis_ >= -1,",
          "77:         errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));",
          "78:     OP_REQUIRES(",
          "79:         ctx, (axis_ == -1 || axis_ < input.shape().dims()),",
          "80:         errors::InvalidArgument(\"Shape must be at least rank \", axis_ + 1,",
          "",
          "[Added Lines]",
          "79:     OP_REQUIRES(ctx, axis_ >= -1,",
          "80:                 InvalidArgument(\"Axis must be at least -1. Found \", axis_));",
          "81:     OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),",
          "82:                 InvalidArgument(\"Shape must be at least rank \", axis_ + 1,",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "91:         auto min_val = input_min_tensor.scalar<T>()();",
          "92:         auto max_val = input_max_tensor.scalar<T>()();",
          "93:         OP_REQUIRES(ctx, min_val <= max_val,",
          "96:       } else {",
          "109:       }",
          "110:     } else {",
          "111:       auto range_shape = (axis_ == -1) ? TensorShape({}) : TensorShape({depth});",
          "",
          "[Removed Lines]",
          "94:                     errors::InvalidArgument(\"Invalid range: input_min \",",
          "95:                                             min_val, \" > input_max \", max_val));",
          "97:         OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,",
          "98:                     errors::InvalidArgument(",
          "99:                         \"input_min_tensor has incorrect size, was \",",
          "100:                         input_min_tensor.dim_size(0), \" expected \", depth,",
          "101:                         \" to match dim \", axis_, \" of the input \",",
          "102:                         input_min_tensor.shape()));",
          "103:         OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,",
          "104:                     errors::InvalidArgument(",
          "105:                         \"input_max_tensor has incorrect size, was \",",
          "106:                         input_max_tensor.dim_size(0), \" expected \", depth,",
          "107:                         \" to match dim \", axis_, \" of the input \",",
          "108:                         input_max_tensor.shape()));",
          "",
          "[Added Lines]",
          "96:                     InvalidArgument(\"Invalid range: input_min \", min_val,",
          "97:                                     \" > input_max \", max_val));",
          "99:         OP_REQUIRES(",
          "100:             ctx, input_min_tensor.dim_size(0) == depth,",
          "101:             InvalidArgument(\"input_min_tensor has incorrect size, was \",",
          "102:                             input_min_tensor.dim_size(0), \" expected \", depth,",
          "103:                             \" to match dim \", axis_, \" of the input \",",
          "104:                             input_min_tensor.shape()));",
          "105:         OP_REQUIRES(",
          "106:             ctx, input_max_tensor.dim_size(0) == depth,",
          "107:             InvalidArgument(\"input_max_tensor has incorrect size, was \",",
          "108:                             input_max_tensor.dim_size(0), \" expected \", depth,",
          "109:                             \" to match dim \", axis_, \" of the input \",",
          "110:                             input_max_tensor.shape()));",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "158:     Tensor* input_backprop = nullptr;",
          "159:     OP_REQUIRES_OK(ctx,",
          "160:                    ctx->allocate_output(0, input.shape(), &input_backprop));",
          "164:     OP_REQUIRES(ctx, (axis_ == -1 || axis_ < input.shape().dims()),",
          "166:                     \"Axis should be -1 or 0 or a positive value less than \",",
          "167:                     input.shape().dims(), \"but given axis value was \", axis_));",
          "172:     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);",
          "173:     const Tensor& input_min_tensor = ctx->input(2);",
          "174:     OP_REQUIRES(ctx,",
          "175:                 input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,",
          "177:                     \"Input min tensor must have dimension 0 or 1. Received \",",
          "178:                     input_min_tensor.dims(), \".\"));",
          "179:     const Tensor& input_max_tensor = ctx->input(3);",
          "180:     OP_REQUIRES(ctx,",
          "181:                 input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,",
          "183:                     \"Input max tensor must have dimension 0 or 1. Received \",",
          "184:                     input_max_tensor.dims(), \".\"));",
          "185:     if (axis_ != -1) {",
          "189:                                   \" was \", input_min_tensor.dim_size(0)));",
          "193:                                   \" was \", input_max_tensor.dim_size(0)));",
          "194:     }",
          "",
          "[Removed Lines]",
          "161:     OP_REQUIRES(",
          "162:         ctx, axis_ >= -1,",
          "163:         errors::InvalidArgument(\"Axis must be at least -1. Found \", axis_));",
          "165:                 errors::InvalidArgument(",
          "169:     OP_REQUIRES(",
          "170:         ctx, input.IsSameSize(gradient),",
          "171:         errors::InvalidArgument(\"gradient and input must be the same size\"));",
          "176:                 errors::InvalidArgument(",
          "182:                 errors::InvalidArgument(",
          "186:       OP_REQUIRES(",
          "187:           ctx, input_min_tensor.dim_size(0) == depth,",
          "188:           errors::InvalidArgument(\"min has incorrect size, expected \", depth,",
          "190:       OP_REQUIRES(",
          "191:           ctx, input_max_tensor.dim_size(0) == depth,",
          "192:           errors::InvalidArgument(\"max has incorrect size, expected \", depth,",
          "",
          "[Added Lines]",
          "163:     OP_REQUIRES(ctx, axis_ >= -1,",
          "164:                 InvalidArgument(\"Axis must be at least -1. Found \", axis_));",
          "166:                 InvalidArgument(",
          "170:     OP_REQUIRES(ctx, input.IsSameSize(gradient),",
          "171:                 InvalidArgument(\"gradient and input must be the same size\"));",
          "176:                 InvalidArgument(",
          "182:                 InvalidArgument(",
          "186:       OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,",
          "187:                   InvalidArgument(\"min has incorrect size, expected \", depth,",
          "189:       OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,",
          "190:                   InvalidArgument(\"max has incorrect size, expected \", depth,",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "203:                    ctx->allocate_output(2, min_max_shape, &input_max_backprop));",
          "205:     if (axis_ == -1) {",
          "212:       functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;",
          "213:       f(ctx->eigen_device<Device>(), gradient.template flat<T>(),",
          "214:         input.template flat<T>(), input_min_tensor.scalar<T>(),",
          "",
          "[Removed Lines]",
          "206:       OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_min_tensor.shape()),",
          "207:                   errors::InvalidArgument(",
          "208:                       \"input_min must be a scalar if axis is unspecified\"));",
          "209:       OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(input_max_tensor.shape()),",
          "210:                   errors::InvalidArgument(",
          "211:                       \"input_max must be a scalar if axis is unspecified\"));",
          "",
          "[Added Lines]",
          "204:       OP_REQUIRES(",
          "205:           ctx, TensorShapeUtils::IsScalar(input_min_tensor.shape()),",
          "206:           InvalidArgument(\"input_min must be a scalar if axis is unspecified\"));",
          "207:       OP_REQUIRES(",
          "208:           ctx, TensorShapeUtils::IsScalar(input_max_tensor.shape()),",
          "209:           InvalidArgument(\"input_max must be a scalar if axis is unspecified\"));",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "252:   void Compute(OpKernelContext* ctx) override {",
          "253:     const Tensor& input = ctx->input(0);",
          "254:     OP_REQUIRES(ctx, axis_ < input.dims(),",
          "256:                     \"Axis requested is larger than input dimensions. Axis: \",",
          "257:                     axis_, \" Input Dimensions: \", input.dims()));",
          "258:     const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);",
          "259:     Tensor* output = nullptr;",
          "260:     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));",
          "271:     Tensor input_min_tensor;",
          "272:     Tensor input_max_tensor;",
          "",
          "[Removed Lines]",
          "255:                 errors::InvalidArgument(",
          "262:     Tensor num_bits_tensor;",
          "263:     num_bits_tensor = ctx->input(3);",
          "264:     int num_bits_val = num_bits_tensor.scalar<int32>()();",
          "266:     OP_REQUIRES(",
          "267:         ctx, num_bits_val > 0 && num_bits_val < (signed_input_ ? 62 : 63),",
          "268:         errors::InvalidArgument(\"num_bits is out of range: \", num_bits_val,",
          "269:                                 \" with signed_input_ \", signed_input_));",
          "",
          "[Added Lines]",
          "253:                 InvalidArgument(",
          "261:     const Tensor num_bits_tensor = ctx->input(3);",
          "262:     OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(num_bits_tensor.shape()),",
          "263:                 InvalidArgument(\"Invalid shape. The `num_bits` tensor should \"",
          "264:                                 \"be a scalar. Got dimensions: \",",
          "265:                                 num_bits_tensor.dims()));",
          "267:     const int num_bits_val = num_bits_tensor.scalar<int32>()();",
          "268:     OP_REQUIRES(ctx,",
          "269:                 num_bits_val > 0 && num_bits_val < (signed_input_ ? 62 : 63),",
          "270:                 InvalidArgument(\"num_bits is out of range: \", num_bits_val,",
          "271:                                 \" with `signed_input_` \", signed_input_));",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "274:       input_min_tensor = ctx->input(1);",
          "275:       input_max_tensor = ctx->input(2);",
          "276:       if (axis_ == -1) {",
          "279:         OP_REQUIRES(ctx, min_val <= max_val,",
          "282:       } else {",
          "295:       }",
          "296:     } else {",
          "297:       auto range_shape = (axis_ == -1) ? TensorShape({}) : TensorShape({depth});",
          "",
          "[Removed Lines]",
          "277:         auto min_val = input_min_tensor.scalar<T>()();",
          "278:         auto max_val = input_max_tensor.scalar<T>()();",
          "280:                     errors::InvalidArgument(\"Invalid range: input_min \",",
          "281:                                             min_val, \" > input_max \", max_val));",
          "283:         OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,",
          "284:                     errors::InvalidArgument(",
          "285:                         \"input_min_tensor has incorrect size, was \",",
          "286:                         input_min_tensor.dim_size(0), \" expected \", depth,",
          "287:                         \" to match dim \", axis_, \" of the input \",",
          "288:                         input_min_tensor.shape()));",
          "289:         OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,",
          "290:                     errors::InvalidArgument(",
          "291:                         \"input_max_tensor has incorrect size, was \",",
          "292:                         input_max_tensor.dim_size(0), \" expected \", depth,",
          "293:                         \" to match dim \", axis_, \" of the input \",",
          "294:                         input_max_tensor.shape()));",
          "",
          "[Added Lines]",
          "279:         const auto min_val = input_min_tensor.scalar<T>()();",
          "280:         const auto max_val = input_max_tensor.scalar<T>()();",
          "282:                     InvalidArgument(\"Invalid range: input_min \", min_val,",
          "283:                                     \" > input_max \", max_val));",
          "285:         OP_REQUIRES(",
          "286:             ctx, input_min_tensor.dim_size(0) == depth,",
          "287:             InvalidArgument(\"input_min_tensor has incorrect size, was \",",
          "288:                             input_min_tensor.dim_size(0), \" expected \", depth,",
          "289:                             \" to match dim \", axis_, \" of the input \",",
          "290:                             input_min_tensor.shape()));",
          "291:         OP_REQUIRES(",
          "292:             ctx, input_max_tensor.dim_size(0) == depth,",
          "293:             InvalidArgument(\"input_max_tensor has incorrect size, was \",",
          "294:                             input_max_tensor.dim_size(0), \" expected \", depth,",
          "295:                             \" to match dim \", axis_, \" of the input \",",
          "296:                             input_max_tensor.shape()));",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "331:     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"signed_input\", &signed_input_));",
          "332:     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"num_bits\", &num_bits_));",
          "333:     OP_REQUIRES(ctx, num_bits_ > 0 && num_bits_ < (signed_input_ ? 62 : 63),",
          "336:     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"range_given\", &range_given_));",
          "337:     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"input_min\", &input_min_));",
          "338:     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"input_max\", &input_max_));",
          "339:     if (range_given_) {",
          "343:                                   \" > input_max \", input_max_));",
          "344:     }",
          "345:   }",
          "",
          "[Removed Lines]",
          "334:                 errors::InvalidArgument(\"num_bits is out of range: \", num_bits_,",
          "335:                                         \" with signed_input_ \", signed_input_));",
          "340:       OP_REQUIRES(",
          "341:           ctx, input_min_ <= input_max_,",
          "342:           errors::InvalidArgument(\"Invalid range: input_min \", input_min_,",
          "",
          "[Added Lines]",
          "336:                 InvalidArgument(\"num_bits is out of range: \", num_bits_,",
          "337:                                 \" with signed_input_ \", signed_input_));",
          "342:       OP_REQUIRES(ctx, input_min_ <= input_max_,",
          "343:                   InvalidArgument(\"Invalid range: input_min \", input_min_,",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "371:   float input_max_;",
          "372: };",
          "376: namespace functor {",
          "377: template <typename T>",
          "380:                   const bool signed_input, const int num_bits,",
          "381:                   const bool range_given, Tensor* input_min_tensor,",
          "382:                   Tensor* input_max_tensor, QuantizerRoundMode round_mode,",
          "383:                   bool narrow_range, typename TTypes<T>::Vec out) {",
          "385:         d, input, signed_input, num_bits, range_given, input_min_tensor,",
          "386:         input_max_tensor, round_mode, narrow_range, out);",
          "387:   }",
          "388: };",
          "390: template <typename T>",
          "393:                   bool signed_input, int num_bits, bool range_given,",
          "394:                   Tensor* input_min_tensor, Tensor* input_max_tensor,",
          "395:                   QuantizerRoundMode round_mode, bool narrow_range,",
          "396:                   typename TTypes<T, 3>::Tensor out) {",
          "398:         d, input, signed_input, num_bits, range_given, input_min_tensor,",
          "399:         input_max_tensor, round_mode, narrow_range, out);",
          "400:   }",
          "401: };",
          "403: template <typename T>",
          "406:                   typename TTypes<T>::ConstFlat input,",
          "407:                   typename TTypes<T>::ConstScalar input_min_tensor,",
          "408:                   typename TTypes<T>::ConstScalar input_max_tensor,",
          "409:                   typename TTypes<T>::Flat input_backprop,",
          "410:                   typename TTypes<T>::Scalar input_min_backprop,",
          "411:                   typename TTypes<T>::Scalar input_max_backprop) {",
          "413:         d, gradient, input, input_min_tensor, input_max_tensor, input_backprop,",
          "414:         input_min_backprop, input_max_backprop);",
          "415:   }",
          "416: };",
          "418: template <typename T>",
          "421:                   typename TTypes<T, 3>::ConstTensor gradient,",
          "422:                   typename TTypes<T, 3>::ConstTensor input,",
          "423:                   const Tensor* input_min_tensor,",
          "",
          "[Removed Lines]",
          "378: struct QuantizeAndDequantizeOneScaleFunctor<CPUDevice, T> {",
          "379:   void operator()(const CPUDevice& d, typename TTypes<T>::ConstVec input,",
          "384:     QuantizeAndDequantizeOneScaleImpl<CPUDevice, T>::Compute(",
          "391: struct QuantizeAndDequantizePerChannelFunctor<CPUDevice, T> {",
          "392:   void operator()(const CPUDevice& d, typename TTypes<T, 3>::ConstTensor input,",
          "397:     QuantizeAndDequantizePerChannelImpl<CPUDevice, T>::Compute(",
          "404: struct QuantizeAndDequantizeOneScaleGradientFunctor<CPUDevice, T> {",
          "405:   void operator()(const CPUDevice& d, typename TTypes<T>::ConstFlat gradient,",
          "412:     QuantizeAndDequantizeOneScaleGradientImpl<CPUDevice, T>::Compute(",
          "419: struct QuantizeAndDequantizePerChannelGradientFunctor<CPUDevice, T> {",
          "420:   void operator()(const CPUDevice& d,",
          "",
          "[Added Lines]",
          "379: struct QuantizeAndDequantizeOneScaleFunctor<CpuDevice, T> {",
          "380:   void operator()(const CpuDevice& d, typename TTypes<T>::ConstVec input,",
          "385:     QuantizeAndDequantizeOneScaleImpl<CpuDevice, T>::Compute(",
          "392: struct QuantizeAndDequantizePerChannelFunctor<CpuDevice, T> {",
          "393:   void operator()(const CpuDevice& d, typename TTypes<T, 3>::ConstTensor input,",
          "398:     QuantizeAndDequantizePerChannelImpl<CpuDevice, T>::Compute(",
          "405: struct QuantizeAndDequantizeOneScaleGradientFunctor<CpuDevice, T> {",
          "406:   void operator()(const CpuDevice& d, typename TTypes<T>::ConstFlat gradient,",
          "413:     QuantizeAndDequantizeOneScaleGradientImpl<CpuDevice, T>::Compute(",
          "420: struct QuantizeAndDequantizePerChannelGradientFunctor<CpuDevice, T> {",
          "421:   void operator()(const CpuDevice& d,",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "425:                   typename TTypes<T, 3>::Tensor input_backprop,",
          "426:                   typename TTypes<T>::Flat input_min_backprop,",
          "427:                   typename TTypes<T>::Flat input_max_backprop) {",
          "429:         d, gradient, input, input_min_tensor, input_max_tensor, input_backprop,",
          "430:         input_min_backprop, input_max_backprop);",
          "431:   }",
          "432: };",
          "435:                                                                       float>;",
          "436: template struct functor::QuantizeAndDequantizePerChannelGradientFunctor<",
          "439: }  // namespace functor",
          "",
          "[Removed Lines]",
          "428:     QuantizeAndDequantizePerChannelGradientImpl<CPUDevice, T>::Compute(",
          "434: template struct functor::QuantizeAndDequantizeOneScaleGradientFunctor<CPUDevice,",
          "437:     CPUDevice, double>;",
          "",
          "[Added Lines]",
          "429:     QuantizeAndDequantizePerChannelGradientImpl<CpuDevice, T>::Compute(",
          "435: template struct functor::QuantizeAndDequantizeOneScaleGradientFunctor<CpuDevice,",
          "438:     CpuDevice, double>;",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "442:   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV2\")                      \\",
          "443:                               .Device(DEVICE_CPU)                              \\",
          "444:                               .TypeConstraint<T>(\"T\"),                         \\",
          "446:   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV3\")                      \\",
          "447:                               .Device(DEVICE_CPU)                              \\",
          "448:                               .TypeConstraint<T>(\"T\"),                         \\",
          "450:   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4\")                      \\",
          "451:                               .Device(DEVICE_CPU)                              \\",
          "452:                               .TypeConstraint<T>(\"T\"),                         \\",
          "454:   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4Grad\")                  \\",
          "455:                               .Device(DEVICE_CPU)                              \\",
          "456:                               .TypeConstraint<T>(\"T\"),                         \\",
          "458:   REGISTER_KERNEL_BUILDER(                                                     \\",
          "459:       Name(\"QuantizeAndDequantize\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\",
          "461: TF_CALL_float(REGISTER_CPU_KERNEL);",
          "462: TF_CALL_double(REGISTER_CPU_KERNEL);",
          "463: #undef REGISTER_CPU_KERNEL",
          "",
          "[Removed Lines]",
          "445:                           QuantizeAndDequantizeV2Op<CPUDevice, T>);            \\",
          "449:                           QuantizeAndDequantizeV3Op<CPUDevice, T>);            \\",
          "453:                           QuantizeAndDequantizeV2Op<CPUDevice, T>);            \\",
          "457:                           QuantizeAndDequantizeV4GradientOp<CPUDevice, T>);    \\",
          "460:       QuantizeAndDequantizeOp<CPUDevice, T>);",
          "",
          "[Added Lines]",
          "446:                           QuantizeAndDequantizeV2Op<CpuDevice, T>);            \\",
          "450:                           QuantizeAndDequantizeV3Op<CpuDevice, T>);            \\",
          "454:                           QuantizeAndDequantizeV2Op<CpuDevice, T>);            \\",
          "458:                           QuantizeAndDequantizeV4GradientOp<CpuDevice, T>);    \\",
          "461:       QuantizeAndDequantizeOp<CpuDevice, T>);",
          "",
          "---------------",
          "--- Hunk 14 ---",
          "[Context before]",
          "470:                               .HostMemory(\"input_min\")                         \\",
          "471:                               .HostMemory(\"input_max\")                         \\",
          "472:                               .TypeConstraint<T>(\"T\"),                         \\",
          "474:   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV3\")                      \\",
          "475:                               .Device(DEVICE_GPU)                              \\",
          "476:                               .HostMemory(\"input_min\")                         \\",
          "477:                               .HostMemory(\"input_max\")                         \\",
          "478:                               .HostMemory(\"num_bits\")                          \\",
          "479:                               .TypeConstraint<T>(\"T\"),                         \\",
          "481:   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4\")                      \\",
          "482:                               .Device(DEVICE_GPU)                              \\",
          "483:                               .HostMemory(\"input_min\")                         \\",
          "484:                               .HostMemory(\"input_max\")                         \\",
          "485:                               .TypeConstraint<T>(\"T\"),                         \\",
          "487:   REGISTER_KERNEL_BUILDER(Name(\"QuantizeAndDequantizeV4Grad\")                  \\",
          "488:                               .Device(DEVICE_GPU)                              \\",
          "489:                               .HostMemory(\"input_min\")                         \\",
          "490:                               .HostMemory(\"input_max\")                         \\",
          "491:                               .TypeConstraint<T>(\"T\"),                         \\",
          "493:   REGISTER_KERNEL_BUILDER(                                                     \\",
          "494:       Name(\"QuantizeAndDequantize\").Device(DEVICE_GPU).TypeConstraint<T>(\"T\"), \\",
          "496: TF_CALL_float(REGISTER_GPU_KERNEL);",
          "497: TF_CALL_double(REGISTER_GPU_KERNEL);",
          "498: #undef REGISTER_GPU_KERNEL",
          "",
          "[Removed Lines]",
          "473:                           QuantizeAndDequantizeV2Op<GPUDevice, T>);            \\",
          "480:                           QuantizeAndDequantizeV3Op<GPUDevice, T>);            \\",
          "486:                           QuantizeAndDequantizeV2Op<GPUDevice, T>);            \\",
          "492:                           QuantizeAndDequantizeV4GradientOp<GPUDevice, T>);    \\",
          "495:       QuantizeAndDequantizeOp<GPUDevice, T>);",
          "",
          "[Added Lines]",
          "474:                           QuantizeAndDequantizeV2Op<GpuDevice, T>);            \\",
          "481:                           QuantizeAndDequantizeV3Op<GpuDevice, T>);            \\",
          "487:                           QuantizeAndDequantizeV2Op<GpuDevice, T>);            \\",
          "493:                           QuantizeAndDequantizeV4GradientOp<GpuDevice, T>);    \\",
          "496:       QuantizeAndDequantizeOp<GpuDevice, T>);",
          "",
          "---------------"
        ],
        "tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py||tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py": [
          "File: tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py -> tensorflow/python/kernel_tests/quantization_ops/quantization_ops_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "15: \"\"\"Tests for tf.quantize ops.\"\"\"",
          "16: import numpy as np",
          "18: from tensorflow.python.framework import constant_op",
          "19: from tensorflow.python.framework import dtypes",
          "20: from tensorflow.python.framework import errors",
          "21: from tensorflow.python.framework import test_util",
          "22: from tensorflow.python.ops import array_ops",
          "23: from tensorflow.python.ops import math_ops",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: from tensorflow.python.eager import context",
          "22: from tensorflow.python.framework import ops",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "407:               out_type=dtypes.quint8))",
          "410: if __name__ == \"__main__\":",
          "411:   googletest.main()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "412: class QuantizeAndDequantizeV3OpTest(test_util.TensorFlowTestCase):",
          "414:   @test_util.run_in_graph_and_eager_modes",
          "415:   def test_valid(self):",
          "416:     with ops.Graph().as_default(), context.eager_mode():",
          "417:       input_value = constant_op.constant([-0.8, -0.5, 0, 0.3, 0.8, -2.0],",
          "418:                                          shape=(6,),",
          "419:                                          dtype=dtypes.float32),",
          "420:       input_min = constant_op.constant(-127, shape=(), dtype=dtypes.float32)",
          "421:       input_max = constant_op.constant(127, shape=(), dtype=dtypes.float32)",
          "422:       num_bits = constant_op.constant(8, shape=(), dtype=dtypes.int32)",
          "424:       quantized = array_ops.quantize_and_dequantize_v3(",
          "425:           input_value,",
          "426:           input_min,",
          "427:           input_max,",
          "428:           num_bits,",
          "429:           signed_input=True,",
          "430:           range_given=False)",
          "431:       self.assertSequenceAlmostEqual(",
          "432:           input_value[0].numpy(), quantized.numpy()[0], delta=0.05)",
          "434:   @test_util.run_in_graph_and_eager_modes",
          "435:   def test_invalid_inputs(self):",
          "436:     input_value = constant_op.constant([-0.8, -0.5, 0, 0.3, 0.8, -2.0],",
          "437:                                        shape=(6,),",
          "438:                                        dtype=dtypes.float32),",
          "439:     input_min = constant_op.constant(-127, shape=(), dtype=dtypes.float32)",
          "440:     input_max = constant_op.constant(127, shape=(), dtype=dtypes.float32)",
          "441:     # Tensor with invalid shape and invalid number of elements.",
          "442:     num_bits = constant_op.constant([], shape=(0,), dtype=dtypes.int32)",
          "444:     # Test that running the op raises error. It raises different errors",
          "445:     # depending on whether the shape inference is run first or the op's",
          "446:     # Compute() is run first.",
          "447:     try:",
          "448:       array_ops.quantize_and_dequantize_v3(",
          "449:           input_value, input_min, input_max, num_bits, signed_input=True)",
          "450:     except Exception as ex:  # pylint: disable=broad-except",
          "451:       if isinstance(ex, errors.InvalidArgumentError):",
          "452:         self.assertRegex(str(ex), \"The `num_bits` tensor should be a scalar.\")",
          "453:       elif isinstance(ex, ValueError):",
          "454:         self.assertRegex(str(ex), \"Shape must be rank 0\")",
          "455:       else:",
          "456:         self.fail(",
          "457:             \"Raised exception other than expected: %s. \"",
          "458:             \"Expected exceptions are errors.InvalidArgumentError or ValueError\",",
          "459:             ex.__name__)",
          "460:     else:",
          "461:       self.fail(",
          "462:           \"Did not raise an exception where it is expected to raise either \"",
          "463:           \"a ValueError or errors.InvalidArgumentError.\")",
          "",
          "---------------"
        ]
      }
    }
  ]
}