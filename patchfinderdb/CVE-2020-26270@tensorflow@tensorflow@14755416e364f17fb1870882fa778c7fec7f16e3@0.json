{
  "cve_id": "CVE-2020-26270",
  "cve_desc": "In affected versions of TensorFlow running an LSTM/GRU model where the LSTM/GRU layer receives an input with zero-length results in a CHECK failure when using the CUDA backend. This can result in a query-of-death vulnerability, via denial of service, if users can control the input to the layer. This is fixed in versions 1.15.5, 2.0.4, 2.1.3, 2.2.2, 2.3.2, and 2.4.0.",
  "repo": "tensorflow/tensorflow",
  "patch_hash": "14755416e364f17fb1870882fa778c7fec7f16e3",
  "patch_info": {
    "commit_hash": "14755416e364f17fb1870882fa778c7fec7f16e3",
    "repo": "tensorflow/tensorflow",
    "commit_url": "https://github.com/tensorflow/tensorflow/commit/14755416e364f17fb1870882fa778c7fec7f16e3",
    "files": [
      "tensorflow/stream_executor/cuda/cuda_dnn.cc"
    ],
    "message": "Prevent CHECK-fail in LSTM/GRU with zero-length input.\n\nPiperOrigin-RevId: 346239181\nChange-Id: I5f233dbc076aab7bb4e31ba24f5abd4eaf99ea4f",
    "before_after_code_files": [
      "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc"
    ]
  },
  "patch_diff": {
    "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc": [
      "File: tensorflow/stream_executor/cuda/cuda_dnn.cc -> tensorflow/stream_executor/cuda/cuda_dnn.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "1468:   static port::StatusOr<CudnnRnnSequenceTensorDescriptor> Create(",
      "1469:       GpuExecutor* parent, int max_seq_length, int batch_size, int data_size,",
      "1470:       cudnnDataType_t data_type) {",
      "1472:     int dims[] = {batch_size, data_size, 1};",
      "1473:     int strides[] = {dims[1] * dims[2], dims[2], 1};",
      "1474:     TensorDescriptor tensor_desc = CreateTensorDescriptor();",
      "",
      "[Removed Lines]",
      "1471:     CHECK_GT(max_seq_length, 0);",
      "",
      "[Added Lines]",
      "1471:     if (max_seq_length <= 0) {",
      "1472:       return port::Status(port::error::INVALID_ARGUMENT, \"max_seq_length <= 0\");",
      "1473:     }",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "1486:       GpuExecutor* parent, int max_seq_length, int batch_size, int data_size,",
      "1487:       const absl::Span<const int>& seq_lengths, bool time_major,",
      "1488:       cudnnDataType_t data_type) {",
      "1490:     int dims[] = {batch_size, data_size, 1};",
      "1491:     int strides[] = {dims[1] * dims[2], dims[2], 1};",
      "1492:     TensorDescriptor tensor_desc = CreateTensorDescriptor();",
      "",
      "[Removed Lines]",
      "1489:     CHECK_GT(max_seq_length, 0);",
      "",
      "[Added Lines]",
      "1491:     if (max_seq_length <= 0) {",
      "1492:       return port::Status(port::error::INVALID_ARGUMENT, \"max_seq_length <= 0\");",
      "1493:     }",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "84d7ddf6d6aa04b112f4e399c7cf0c4532e4835d",
      "candidate_info": {
        "commit_hash": "84d7ddf6d6aa04b112f4e399c7cf0c4532e4835d",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/84d7ddf6d6aa04b112f4e399c7cf0c4532e4835d",
        "files": [
          "tensorflow/stream_executor/cuda/cuda_dnn.cc"
        ],
        "message": "Prevent CHECK-fail in LSTM/GRU with zero-length input.\n\nPiperOrigin-RevId: 346239181\nChange-Id: I5f233dbc076aab7bb4e31ba24f5abd4eaf99ea4f",
        "before_after_code_files": [
          "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc"
          ],
          "candidate": [
            "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc": [
          "File: tensorflow/stream_executor/cuda/cuda_dnn.cc -> tensorflow/stream_executor/cuda/cuda_dnn.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "1377:   static port::StatusOr<CudnnRnnSequenceTensorDescriptor> Create(",
          "1378:       GpuExecutor* parent, int max_seq_length, int batch_size, int data_size,",
          "1379:       cudnnDataType_t data_type) {",
          "1381:     int dims[] = {batch_size, data_size, 1};",
          "1382:     int strides[] = {dims[1] * dims[2], dims[2], 1};",
          "1383:     TensorDescriptor tensor_desc = CreateTensorDescriptor();",
          "",
          "[Removed Lines]",
          "1380:     CHECK_GT(max_seq_length, 0);",
          "",
          "[Added Lines]",
          "1380:     if (max_seq_length <= 0) {",
          "1381:       return port::Status(port::error::INVALID_ARGUMENT, \"max_seq_length <= 0\");",
          "1382:     }",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1398:       const absl::Span<const int>& seq_lengths, bool time_major,",
          "1399:       cudnnDataType_t data_type) {",
          "1400: #if CUDNN_VERSION >= 7201",
          "1402:     int dims[] = {batch_size, data_size, 1};",
          "1403:     int strides[] = {dims[1] * dims[2], dims[2], 1};",
          "1404:     TensorDescriptor tensor_desc = CreateTensorDescriptor();",
          "",
          "[Removed Lines]",
          "1401:     CHECK_GT(max_seq_length, 0);",
          "",
          "[Added Lines]",
          "1403:     if (max_seq_length <= 0) {",
          "1404:       return port::Status(port::error::INVALID_ARGUMENT, \"max_seq_length <= 0\");",
          "1405:     }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "b95ccc06e049078a8deefcc2bfaadf56e1b1c87c",
      "candidate_info": {
        "commit_hash": "b95ccc06e049078a8deefcc2bfaadf56e1b1c87c",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/b95ccc06e049078a8deefcc2bfaadf56e1b1c87c",
        "files": [
          "tensorflow/stream_executor/cuda/cuda_dnn.cc"
        ],
        "message": "Prevent CHECK-fail in LSTM/GRU with zero-length input.\n\nPiperOrigin-RevId: 346239181\nChange-Id: I5f233dbc076aab7bb4e31ba24f5abd4eaf99ea4f",
        "before_after_code_files": [
          "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc"
          ],
          "candidate": [
            "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc": [
          "File: tensorflow/stream_executor/cuda/cuda_dnn.cc -> tensorflow/stream_executor/cuda/cuda_dnn.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "1474:   static port::StatusOr<CudnnRnnSequenceTensorDescriptor> Create(",
          "1475:       GpuExecutor* parent, int max_seq_length, int batch_size, int data_size,",
          "1476:       cudnnDataType_t data_type) {",
          "1478:     int dims[] = {batch_size, data_size, 1};",
          "1479:     int strides[] = {dims[1] * dims[2], dims[2], 1};",
          "1480:     TensorDescriptor tensor_desc = CreateTensorDescriptor();",
          "",
          "[Removed Lines]",
          "1477:     CHECK_GT(max_seq_length, 0);",
          "",
          "[Added Lines]",
          "1477:     if (max_seq_length <= 0) {",
          "1478:       return port::Status(port::error::INVALID_ARGUMENT, \"max_seq_length <= 0\");",
          "1479:     }",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1495:       const absl::Span<const int>& seq_lengths, bool time_major,",
          "1496:       cudnnDataType_t data_type) {",
          "1497: #if CUDNN_VERSION >= 7201",
          "1499:     int dims[] = {batch_size, data_size, 1};",
          "1500:     int strides[] = {dims[1] * dims[2], dims[2], 1};",
          "1501:     TensorDescriptor tensor_desc = CreateTensorDescriptor();",
          "",
          "[Removed Lines]",
          "1498:     CHECK_GT(max_seq_length, 0);",
          "",
          "[Added Lines]",
          "1500:     if (max_seq_length <= 0) {",
          "1501:       return port::Status(port::error::INVALID_ARGUMENT, \"max_seq_length <= 0\");",
          "1502:     }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "b550171e78e0a085b208d6a3b8b29ed29faa97ae",
      "candidate_info": {
        "commit_hash": "b550171e78e0a085b208d6a3b8b29ed29faa97ae",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/b550171e78e0a085b208d6a3b8b29ed29faa97ae",
        "files": [
          "tensorflow/stream_executor/cuda/cuda_dnn.cc"
        ],
        "message": "Prevent CHECK-fail in LSTM/GRU with zero-length input.\n\nPiperOrigin-RevId: 346239181\nChange-Id: I5f233dbc076aab7bb4e31ba24f5abd4eaf99ea4f",
        "before_after_code_files": [
          "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc"
          ],
          "candidate": [
            "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc": [
          "File: tensorflow/stream_executor/cuda/cuda_dnn.cc -> tensorflow/stream_executor/cuda/cuda_dnn.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "1465:   static port::StatusOr<CudnnRnnSequenceTensorDescriptor> Create(",
          "1466:       GpuExecutor* parent, int max_seq_length, int batch_size, int data_size,",
          "1467:       cudnnDataType_t data_type) {",
          "1469:     int dims[] = {batch_size, data_size, 1};",
          "1470:     int strides[] = {dims[1] * dims[2], dims[2], 1};",
          "1471:     TensorDescriptor tensor_desc = CreateTensorDescriptor();",
          "",
          "[Removed Lines]",
          "1468:     CHECK_GT(max_seq_length, 0);",
          "",
          "[Added Lines]",
          "1468:     if (max_seq_length <= 0) {",
          "1469:       return port::Status(port::error::INVALID_ARGUMENT, \"max_seq_length <= 0\");",
          "1470:     }",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1483:       GpuExecutor* parent, int max_seq_length, int batch_size, int data_size,",
          "1484:       const absl::Span<const int>& seq_lengths, bool time_major,",
          "1485:       cudnnDataType_t data_type) {",
          "1487:     int dims[] = {batch_size, data_size, 1};",
          "1488:     int strides[] = {dims[1] * dims[2], dims[2], 1};",
          "1489:     TensorDescriptor tensor_desc = CreateTensorDescriptor();",
          "",
          "[Removed Lines]",
          "1486:     CHECK_GT(max_seq_length, 0);",
          "",
          "[Added Lines]",
          "1488:     if (max_seq_length <= 0) {",
          "1489:       return port::Status(port::error::INVALID_ARGUMENT, \"max_seq_length <= 0\");",
          "1490:     }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "719ef26d3215ed850eef43ac5b488d32f80ea604",
      "candidate_info": {
        "commit_hash": "719ef26d3215ed850eef43ac5b488d32f80ea604",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/719ef26d3215ed850eef43ac5b488d32f80ea604",
        "files": [
          "tensorflow/stream_executor/cuda/cuda_dnn.cc"
        ],
        "message": "Prevent CHECK-fail in LSTM/GRU with zero-length input.\n\nPiperOrigin-RevId: 346239181\nChange-Id: I5f233dbc076aab7bb4e31ba24f5abd4eaf99ea4f",
        "before_after_code_files": [
          "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc"
          ],
          "candidate": [
            "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc": [
          "File: tensorflow/stream_executor/cuda/cuda_dnn.cc -> tensorflow/stream_executor/cuda/cuda_dnn.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "1379:   static port::StatusOr<CudnnRnnSequenceTensorDescriptor> Create(",
          "1380:       GpuExecutor* parent, int max_seq_length, int batch_size, int data_size,",
          "1381:       cudnnDataType_t data_type) {",
          "1383:     int dims[] = {batch_size, data_size, 1};",
          "1384:     int strides[] = {dims[1] * dims[2], dims[2], 1};",
          "1385:     TensorDescriptor tensor_desc = CreateTensorDescriptor();",
          "",
          "[Removed Lines]",
          "1382:     CHECK_GT(max_seq_length, 0);",
          "",
          "[Added Lines]",
          "1382:     if (max_seq_length <= 0) {",
          "1383:       return port::Status(port::error::INVALID_ARGUMENT, \"max_seq_length <= 0\");",
          "1384:     }",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1400:       const absl::Span<const int>& seq_lengths, bool time_major,",
          "1401:       cudnnDataType_t data_type) {",
          "1402: #if CUDNN_VERSION >= 7201",
          "1404:     int dims[] = {batch_size, data_size, 1};",
          "1405:     int strides[] = {dims[1] * dims[2], dims[2], 1};",
          "1406:     TensorDescriptor tensor_desc = CreateTensorDescriptor();",
          "",
          "[Removed Lines]",
          "1403:     CHECK_GT(max_seq_length, 0);",
          "",
          "[Added Lines]",
          "1405:     if (max_seq_length <= 0) {",
          "1406:       return port::Status(port::error::INVALID_ARGUMENT, \"max_seq_length <= 0\");",
          "1407:     }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "a605c004ff39eb85923a206d92353881ea45f261",
      "candidate_info": {
        "commit_hash": "a605c004ff39eb85923a206d92353881ea45f261",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/a605c004ff39eb85923a206d92353881ea45f261",
        "files": [
          "tensorflow/stream_executor/cuda/cuda_dnn.cc"
        ],
        "message": "Prevent CHECK-fail in LSTM/GRU with zero-length input.\n\nPiperOrigin-RevId: 346239181\nChange-Id: I5f233dbc076aab7bb4e31ba24f5abd4eaf99ea4f",
        "before_after_code_files": [
          "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc"
          ],
          "candidate": [
            "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/stream_executor/cuda/cuda_dnn.cc||tensorflow/stream_executor/cuda/cuda_dnn.cc": [
          "File: tensorflow/stream_executor/cuda/cuda_dnn.cc -> tensorflow/stream_executor/cuda/cuda_dnn.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "1449:   static port::StatusOr<CudnnRnnSequenceTensorDescriptor> Create(",
          "1450:       GpuExecutor* parent, int max_seq_length, int batch_size, int data_size,",
          "1451:       cudnnDataType_t data_type) {",
          "1453:     int dims[] = {batch_size, data_size, 1};",
          "1454:     int strides[] = {dims[1] * dims[2], dims[2], 1};",
          "1455:     TensorDescriptor tensor_desc = CreateTensorDescriptor();",
          "",
          "[Removed Lines]",
          "1452:     CHECK_GT(max_seq_length, 0);",
          "",
          "[Added Lines]",
          "1452:     if (max_seq_length <= 0) {",
          "1453:       return port::Status(port::error::INVALID_ARGUMENT, \"max_seq_length <= 0\");",
          "1454:     }",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1470:       const absl::Span<const int>& seq_lengths, bool time_major,",
          "1471:       cudnnDataType_t data_type) {",
          "1472: #if CUDNN_VERSION >= 7201",
          "1474:     int dims[] = {batch_size, data_size, 1};",
          "1475:     int strides[] = {dims[1] * dims[2], dims[2], 1};",
          "1476:     TensorDescriptor tensor_desc = CreateTensorDescriptor();",
          "",
          "[Removed Lines]",
          "1473:     CHECK_GT(max_seq_length, 0);",
          "",
          "[Added Lines]",
          "1475:     if (max_seq_length <= 0) {",
          "1476:       return port::Status(port::error::INVALID_ARGUMENT, \"max_seq_length <= 0\");",
          "1477:     }",
          "",
          "---------------"
        ]
      }
    }
  ]
}