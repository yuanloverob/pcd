{
  "cve_id": "CVE-2020-15209",
  "cve_desc": "In tensorflow-lite before versions 1.15.4, 2.0.3, 2.1.2, 2.2.1 and 2.3.1, a crafted TFLite model can force a node to have as input a tensor backed by a `nullptr` buffer. This can be achieved by changing a buffer index in the flatbuffer serialization to convert a read-only tensor to a read-write one. The runtime assumes that these buffers are written to before a possible read, hence they are initialized with `nullptr`. However, by changing the buffer index for a tensor and implicitly converting that tensor to be a read-write one, as there is nothing in the model that writes to it, we get a null pointer dereference. The issue is patched in commit 0b5662bc, and is released in TensorFlow versions 1.15.4, 2.0.3, 2.1.2, 2.2.1, or 2.3.1.",
  "repo": "tensorflow/tensorflow",
  "patch_hash": "0b5662bc2be13a8c8f044d925d87fb6e56247cd8",
  "patch_info": {
    "commit_hash": "0b5662bc2be13a8c8f044d925d87fb6e56247cd8",
    "repo": "tensorflow/tensorflow",
    "commit_url": "https://github.com/tensorflow/tensorflow/commit/0b5662bc2be13a8c8f044d925d87fb6e56247cd8",
    "files": [
      "tensorflow/lite/BUILD",
      "tensorflow/lite/core/subgraph.cc",
      "tensorflow/lite/model_test.cc",
      "tensorflow/lite/testdata/segment_sum_invalid_buffer.bin"
    ],
    "message": "[tflite] Ensure input tensors don't have `nullptr` buffers.\n\nA crafted TFLite model can force a node to have as input a tensor backed by a `nullptr` buffer. That is, by carefully changing the buffer index in the flatbuffer serialization, we can force the TFLite interpreter to consider a read-only tensor to be a read-write one and assume that there is an operator that has this tensor as output, writing to it and allocating memory before the tensor is used as input. If this does not happen, we get memory corruption.\n\nPiperOrigin-RevId: 332524692\nChange-Id: I57ef175152a29020af9ab041dc959e5631dce40f",
    "before_after_code_files": [
      "tensorflow/lite/core/subgraph.cc||tensorflow/lite/core/subgraph.cc",
      "tensorflow/lite/model_test.cc||tensorflow/lite/model_test.cc"
    ]
  },
  "patch_diff": {
    "tensorflow/lite/core/subgraph.cc||tensorflow/lite/core/subgraph.cc": [
      "File: tensorflow/lite/core/subgraph.cc -> tensorflow/lite/core/subgraph.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "19: #include <cstdint>",
      "21: #include \"tensorflow/lite/arena_planner.h\"",
      "22: #include \"tensorflow/lite/c/common.h\"",
      "23: #include \"tensorflow/lite/context_util.h\"",
      "24: #include \"tensorflow/lite/core/api/tensor_utils.h\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "22: #include \"tensorflow/lite/builtin_ops.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "1030:           tensor->data_is_stale) {",
      "1031:         TF_LITE_ENSURE_STATUS(EnsureTensorDataIsReadable(tensor_index));",
      "1032:       }",
      "1033:     }",
      "1035:     if (check_cancelled_func_ != nullptr &&",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "1034:       if (tensor->data.raw == nullptr && tensor->bytes > 0) {",
      "1035:         if (registration.builtin_code == kTfLiteBuiltinReshape && i == 1) {",
      "1039:           continue;",
      "1040:         } else {",
      "1043:           ReportError(\"Input tensor %d lacks data\", tensor_index);",
      "1044:           return kTfLiteError;",
      "1045:         }",
      "1046:       }",
      "",
      "---------------"
    ],
    "tensorflow/lite/model_test.cc||tensorflow/lite/model_test.cc": [
      "File: tensorflow/lite/model_test.cc -> tensorflow/lite/model_test.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "438: }",
      "459: }",
      "",
      "[Removed Lines]",
      "441: TEST(BasicFlatBufferModel, TestHandleMalformedModel) {",
      "442:   const auto model_paths = {",
      "444:       \"tensorflow/lite/testdata/add_shared_tensors.bin\",",
      "445:   };",
      "447:   for (const auto& model_path : model_paths) {",
      "448:     std::unique_ptr<tflite::FlatBufferModel> model =",
      "449:         FlatBufferModel::BuildFromFile(model_path);",
      "450:     ASSERT_NE(model, nullptr);",
      "452:     tflite::ops::builtin::BuiltinOpResolver resolver;",
      "453:     InterpreterBuilder builder(*model, resolver);",
      "454:     std::unique_ptr<Interpreter> interpreter;",
      "455:     ASSERT_EQ(builder(&interpreter), kTfLiteOk);",
      "456:     ASSERT_NE(interpreter, nullptr);",
      "457:     ASSERT_NE(interpreter->AllocateTensors(), kTfLiteOk);",
      "458:   }",
      "",
      "[Added Lines]",
      "447: TEST(BasicFlatBufferModel, TestHandleMalformedModelReuseTensor) {",
      "448:   const auto model_path =",
      "449:       \"tensorflow/lite/testdata/add_shared_tensors.bin\";",
      "451:   std::unique_ptr<tflite::FlatBufferModel> model =",
      "452:       FlatBufferModel::BuildFromFile(model_path);",
      "453:   ASSERT_NE(model, nullptr);",
      "455:   tflite::ops::builtin::BuiltinOpResolver resolver;",
      "456:   InterpreterBuilder builder(*model, resolver);",
      "457:   std::unique_ptr<Interpreter> interpreter;",
      "458:   ASSERT_EQ(builder(&interpreter), kTfLiteOk);",
      "459:   ASSERT_NE(interpreter, nullptr);",
      "460:   ASSERT_NE(interpreter->AllocateTensors(), kTfLiteOk);",
      "461: }",
      "468: TEST(BasicFlatBufferModel, TestHandleMalformedModelInvalidBuffer) {",
      "469:   const auto model_path =",
      "470:       \"tensorflow/lite/testdata/segment_sum_invalid_buffer.bin\";",
      "472:   std::unique_ptr<tflite::FlatBufferModel> model =",
      "473:       FlatBufferModel::BuildFromFile(model_path);",
      "474:   ASSERT_NE(model, nullptr);",
      "476:   tflite::ops::builtin::BuiltinOpResolver resolver;",
      "477:   InterpreterBuilder builder(*model, resolver);",
      "478:   std::unique_ptr<Interpreter> interpreter;",
      "479:   ASSERT_EQ(builder(&interpreter), kTfLiteOk);",
      "480:   ASSERT_NE(interpreter, nullptr);",
      "481:   ASSERT_EQ(interpreter->AllocateTensors(), kTfLiteOk);",
      "482:   ASSERT_NE(interpreter->Invoke(), kTfLiteOk);",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "1a506aef22640364ca629ebefa14605a33d2efae",
      "candidate_info": {
        "commit_hash": "1a506aef22640364ca629ebefa14605a33d2efae",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/1a506aef22640364ca629ebefa14605a33d2efae",
        "files": [
          "tensorflow/lite/core/subgraph.cc"
        ],
        "message": "[tflite] Ensure input tensors don't have `nullptr` buffers.\n\nA crafted TFLite model can force a node to have as input a tensor backed by a `nullptr` buffer. That is, by carefully changing the buffer index in the flatbuffer serialization, we can force the TFLite interpreter to consider a read-only tensor to be a read-write one and assume that there is an operator that has this tensor as output, writing to it and allocating memory before the tensor is used as input. If this does not happen, we get memory corruption.\n\nPiperOrigin-RevId: 332524692\nChange-Id: I57ef175152a29020af9ab041dc959e5631dce40f",
        "before_after_code_files": [
          "tensorflow/lite/core/subgraph.cc||tensorflow/lite/core/subgraph.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_message": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/lite/core/subgraph.cc||tensorflow/lite/core/subgraph.cc"
          ],
          "candidate": [
            "tensorflow/lite/core/subgraph.cc||tensorflow/lite/core/subgraph.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/lite/core/subgraph.cc||tensorflow/lite/core/subgraph.cc": [
          "File: tensorflow/lite/core/subgraph.cc -> tensorflow/lite/core/subgraph.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: #include <algorithm>",
          "20: #include \"tensorflow/lite/arena_planner.h\"",
          "21: #include \"tensorflow/lite/c/common.h\"",
          "22: #include \"tensorflow/lite/context_util.h\"",
          "23: #include \"tensorflow/lite/core/api/tensor_utils.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "21: #include \"third_party/tensorflow/lite/builtin_ops.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "971:           tensor->data_is_stale) {",
          "972:         TF_LITE_ENSURE_STATUS(EnsureTensorDataIsReadable(tensor_index));",
          "973:       }",
          "974:     }",
          "976:     if (check_cancelled_func_ != nullptr &&",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "975:       if (tensor->data.raw == nullptr && tensor->bytes > 0) {",
          "976:         if (registration.builtin_code == kTfLiteBuiltinReshape && i == 1) {",
          "980:           continue;",
          "981:         } else {",
          "984:           ReportError(\"Input tensor %d lacks data\", tensor_index);",
          "985:           return kTfLiteError;",
          "986:         }",
          "987:       }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "37640ce42f195dc0b91ca0cc753793f80e43b289",
      "candidate_info": {
        "commit_hash": "37640ce42f195dc0b91ca0cc753793f80e43b289",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/37640ce42f195dc0b91ca0cc753793f80e43b289",
        "files": [
          "tensorflow/lite/core/subgraph.cc"
        ],
        "message": "[tflite] Ensure input tensors don't have `nullptr` buffers.\n\nA crafted TFLite model can force a node to have as input a tensor backed by a `nullptr` buffer. That is, by carefully changing the buffer index in the flatbuffer serialization, we can force the TFLite interpreter to consider a read-only tensor to be a read-write one and assume that there is an operator that has this tensor as output, writing to it and allocating memory before the tensor is used as input. If this does not happen, we get memory corruption.\n\nPiperOrigin-RevId: 332524692\nChange-Id: I57ef175152a29020af9ab041dc959e5631dce40f",
        "before_after_code_files": [
          "tensorflow/lite/core/subgraph.cc||tensorflow/lite/core/subgraph.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_message": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/lite/core/subgraph.cc||tensorflow/lite/core/subgraph.cc"
          ],
          "candidate": [
            "tensorflow/lite/core/subgraph.cc||tensorflow/lite/core/subgraph.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/lite/core/subgraph.cc||tensorflow/lite/core/subgraph.cc": [
          "File: tensorflow/lite/core/subgraph.cc -> tensorflow/lite/core/subgraph.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: #include <algorithm>",
          "20: #include \"tensorflow/lite/arena_planner.h\"",
          "21: #include \"tensorflow/lite/c/c_api_internal.h\"",
          "22: #include \"tensorflow/lite/context_util.h\"",
          "23: #include \"tensorflow/lite/delegates/nnapi/nnapi_delegate.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "21: #include \"third_party/tensorflow/lite/builtin_ops.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "795:           tensor->data_is_stale) {",
          "796:         TF_LITE_ENSURE_STATUS(EnsureTensorDataIsReadable(tensor_index));",
          "797:       }",
          "798:     }",
          "800:     if (check_cancelled_func_ != nullptr &&",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "799:       if (tensor->data.raw == nullptr && tensor->bytes > 0) {",
          "800:         if (registration.builtin_code == kTfLiteBuiltinReshape && i == 1) {",
          "804:           continue;",
          "805:         } else {",
          "808:           ReportError(\"Input tensor %d lacks data\", tensor_index);",
          "809:           return kTfLiteError;",
          "810:         }",
          "811:       }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "7bb92eeb9f308fbfcbed79b6e08a68b7eacd6fe3",
      "candidate_info": {
        "commit_hash": "7bb92eeb9f308fbfcbed79b6e08a68b7eacd6fe3",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/7bb92eeb9f308fbfcbed79b6e08a68b7eacd6fe3",
        "files": [
          "tensorflow/lite/core/subgraph.cc"
        ],
        "message": "[tflite] Ensure input tensors don't have `nullptr` buffers.\n\nA crafted TFLite model can force a node to have as input a tensor backed by a `nullptr` buffer. That is, by carefully changing the buffer index in the flatbuffer serialization, we can force the TFLite interpreter to consider a read-only tensor to be a read-write one and assume that there is an operator that has this tensor as output, writing to it and allocating memory before the tensor is used as input. If this does not happen, we get memory corruption.\n\nPiperOrigin-RevId: 332524692\nChange-Id: I57ef175152a29020af9ab041dc959e5631dce40f",
        "before_after_code_files": [
          "tensorflow/lite/core/subgraph.cc||tensorflow/lite/core/subgraph.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_message": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/lite/core/subgraph.cc||tensorflow/lite/core/subgraph.cc"
          ],
          "candidate": [
            "tensorflow/lite/core/subgraph.cc||tensorflow/lite/core/subgraph.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/lite/core/subgraph.cc||tensorflow/lite/core/subgraph.cc": [
          "File: tensorflow/lite/core/subgraph.cc -> tensorflow/lite/core/subgraph.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: #include <algorithm>",
          "20: #include \"tensorflow/lite/arena_planner.h\"",
          "21: #include \"tensorflow/lite/c/c_api_internal.h\"",
          "22: #include \"tensorflow/lite/context_util.h\"",
          "23: #include \"tensorflow/lite/delegates/nnapi/nnapi_delegate.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "21: #include \"third_party/tensorflow/lite/builtin_ops.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "795:           tensor->data_is_stale) {",
          "796:         TF_LITE_ENSURE_STATUS(EnsureTensorDataIsReadable(tensor_index));",
          "797:       }",
          "798:     }",
          "800:     if (check_cancelled_func_ != nullptr &&",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "799:       if (tensor->data.raw == nullptr && tensor->bytes > 0) {",
          "800:         if (registration.builtin_code == kTfLiteBuiltinReshape && i == 1) {",
          "804:           continue;",
          "805:         } else {",
          "808:           ReportError(\"Input tensor %d lacks data\", tensor_index);",
          "809:           return kTfLiteError;",
          "810:         }",
          "811:       }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "7f876eae8c0bb492791d0917187ed57a848ba05c",
      "candidate_info": {
        "commit_hash": "7f876eae8c0bb492791d0917187ed57a848ba05c",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/7f876eae8c0bb492791d0917187ed57a848ba05c",
        "files": [
          "tensorflow/lite/core/subgraph.cc"
        ],
        "message": "[tflite] Ensure input tensors don't have `nullptr` buffers.\n\nA crafted TFLite model can force a node to have as input a tensor backed by a `nullptr` buffer. That is, by carefully changing the buffer index in the flatbuffer serialization, we can force the TFLite interpreter to consider a read-only tensor to be a read-write one and assume that there is an operator that has this tensor as output, writing to it and allocating memory before the tensor is used as input. If this does not happen, we get memory corruption.\n\nPiperOrigin-RevId: 332524692\nChange-Id: I57ef175152a29020af9ab041dc959e5631dce40f",
        "before_after_code_files": [
          "tensorflow/lite/core/subgraph.cc||tensorflow/lite/core/subgraph.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_message": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/lite/core/subgraph.cc||tensorflow/lite/core/subgraph.cc"
          ],
          "candidate": [
            "tensorflow/lite/core/subgraph.cc||tensorflow/lite/core/subgraph.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/lite/core/subgraph.cc||tensorflow/lite/core/subgraph.cc": [
          "File: tensorflow/lite/core/subgraph.cc -> tensorflow/lite/core/subgraph.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: #include <algorithm>",
          "20: #include \"tensorflow/lite/arena_planner.h\"",
          "21: #include \"tensorflow/lite/c/common.h\"",
          "22: #include \"tensorflow/lite/context_util.h\"",
          "23: #include \"tensorflow/lite/core/api/tensor_utils.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "21: #include \"third_party/tensorflow/lite/builtin_ops.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "934:           tensor->data_is_stale) {",
          "935:         TF_LITE_ENSURE_STATUS(EnsureTensorDataIsReadable(tensor_index));",
          "936:       }",
          "937:     }",
          "939:     if (check_cancelled_func_ != nullptr &&",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "938:       if (tensor->data.raw == nullptr && tensor->bytes > 0) {",
          "939:         if (registration.builtin_code == kTfLiteBuiltinReshape && i == 1) {",
          "943:           continue;",
          "944:         } else {",
          "947:           ReportError(\"Input tensor %d lacks data\", tensor_index);",
          "948:           return kTfLiteError;",
          "949:         }",
          "950:       }",
          "",
          "---------------"
        ]
      }
    }
  ]
}