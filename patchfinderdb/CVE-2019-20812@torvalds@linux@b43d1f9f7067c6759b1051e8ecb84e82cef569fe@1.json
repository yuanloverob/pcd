{
  "cve_id": "CVE-2019-20812",
  "cve_desc": "An issue was discovered in the Linux kernel before 5.4.7. The prb_calc_retire_blk_tmo() function in net/packet/af_packet.c can result in a denial of service (CPU consumption and soft lockup) in a certain failure case involving TPACKET_V3, aka CID-b43d1f9f7067.",
  "repo": "torvalds/linux",
  "patch_hash": "b43d1f9f7067c6759b1051e8ecb84e82cef569fe",
  "patch_info": {
    "commit_hash": "b43d1f9f7067c6759b1051e8ecb84e82cef569fe",
    "repo": "torvalds/linux",
    "commit_url": "https://github.com/torvalds/linux/commit/b43d1f9f7067c6759b1051e8ecb84e82cef569fe",
    "files": [
      "net/packet/af_packet.c"
    ],
    "message": "af_packet: set defaule value for tmo\n\nThere is softlockup when using TPACKET_V3:\n...\nNMI watchdog: BUG: soft lockup - CPU#2 stuck for 60010ms!\n(__irq_svc) from [<c0558a0c>] (_raw_spin_unlock_irqrestore+0x44/0x54)\n(_raw_spin_unlock_irqrestore) from [<c027b7e8>] (mod_timer+0x210/0x25c)\n(mod_timer) from [<c0549c30>]\n(prb_retire_rx_blk_timer_expired+0x68/0x11c)\n(prb_retire_rx_blk_timer_expired) from [<c027a7ac>]\n(call_timer_fn+0x90/0x17c)\n(call_timer_fn) from [<c027ab6c>] (run_timer_softirq+0x2d4/0x2fc)\n(run_timer_softirq) from [<c021eaf4>] (__do_softirq+0x218/0x318)\n(__do_softirq) from [<c021eea0>] (irq_exit+0x88/0xac)\n(irq_exit) from [<c0240130>] (msa_irq_exit+0x11c/0x1d4)\n(msa_irq_exit) from [<c0209cf0>] (handle_IPI+0x650/0x7f4)\n(handle_IPI) from [<c02015bc>] (gic_handle_irq+0x108/0x118)\n(gic_handle_irq) from [<c0558ee4>] (__irq_usr+0x44/0x5c)\n...\n\nIf __ethtool_get_link_ksettings() is failed in\nprb_calc_retire_blk_tmo(), msec and tmo will be zero, so tov_in_jiffies\nis zero and the timer expire for retire_blk_timer is turn to\nmod_timer(&pkc->retire_blk_timer, jiffies + 0),\nwhich will trigger cpu usage of softirq is 100%.\n\nFixes: f6fb8f100b80 (\"af-packet: TPACKET_V3 flexible buffer implementation.\")\nTested-by: Xiao Jiangfeng <xiaojiangfeng@huawei.com>\nSigned-off-by: Mao Wenan <maowenan@huawei.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>",
    "before_after_code_files": [
      "net/packet/af_packet.c||net/packet/af_packet.c"
    ]
  },
  "patch_diff": {
    "net/packet/af_packet.c||net/packet/af_packet.c": [
      "File: net/packet/af_packet.c -> net/packet/af_packet.c",
      "--- Hunk 1 ---",
      "[Context before]",
      "544:    msec = 1;",
      "545:    div = ecmd.base.speed / 1000;",
      "546:   }",
      "549:  mbits = (blk_size_in_bytes * 8) / (1024 * 1024);",
      "",
      "[Removed Lines]",
      "547:  }",
      "",
      "[Added Lines]",
      "547:  } else",
      "548:   return DEFAULT_PRB_RETIRE_TOV;",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "36deeddcd3699c2755ed21c8d2595b1728d844e5",
      "candidate_info": {
        "commit_hash": "36deeddcd3699c2755ed21c8d2595b1728d844e5",
        "repo": "torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/36deeddcd3699c2755ed21c8d2595b1728d844e5",
        "files": [
          "drivers/gpu/drm/i915/gt/intel_lrc.c"
        ],
        "message": "drm/i915/gt: Save irqstate around virtual_context_destroy\n\nAs virtual_context_destroy() may be called from a request signal, it may\nbe called from inside an irq-off section, and so we need to do a full\nsave/restore of the irq state rather than blindly re-enable irqs upon\nunlocking.\n\n<4> [110.024262] WARNING: inconsistent lock state\n<4> [110.024277] 5.4.0-rc8-CI-CI_DRM_7489+ #1 Tainted: G     U\n<4> [110.024292] --------------------------------\n<4> [110.024305] inconsistent {IN-HARDIRQ-W} -> {HARDIRQ-ON-W} usage.\n<4> [110.024323] kworker/0:0/5 [HC0[0]:SC0[0]:HE1:SE1] takes:\n<4> [110.024338] ffff88826a0c7a18 (&(&rq->lock)->rlock){?.-.}, at: i915_request_retire+0x221/0x930 [i915]\n<4> [110.024592] {IN-HARDIRQ-W} state was registered at:\n<4> [110.024612]   lock_acquire+0xa7/0x1c0\n<4> [110.024627]   _raw_spin_lock_irqsave+0x33/0x50\n<4> [110.024788]   intel_engine_breadcrumbs_irq+0x38c/0x600 [i915]\n<4> [110.024808]   irq_work_run_list+0x49/0x70\n<4> [110.024824]   irq_work_run+0x26/0x50\n<4> [110.024839]   smp_irq_work_interrupt+0x44/0x1e0\n<4> [110.024855]   irq_work_interrupt+0xf/0x20\n<4> [110.024871]   __do_softirq+0xb7/0x47f\n<4> [110.024885]   irq_exit+0xba/0xc0\n<4> [110.024898]   do_IRQ+0x83/0x160\n<4> [110.024910]   ret_from_intr+0x0/0x1d\n<4> [110.024922] irq event stamp: 172864\n<4> [110.024938] hardirqs last  enabled at (172863): [<ffffffff819ea214>] _raw_spin_unlock_irq+0x24/0x50\n<4> [110.024963] hardirqs last disabled at (172864): [<ffffffff819e9fba>] _raw_spin_lock_irq+0xa/0x40\n<4> [110.024988] softirqs last  enabled at (172812): [<ffffffff81c00385>] __do_softirq+0x385/0x47f\n<4> [110.025012] softirqs last disabled at (172797): [<ffffffff810b829a>] irq_exit+0xba/0xc0\n<4> [110.025031]\nother info that might help us debug this:\n<4> [110.025049]  Possible unsafe locking scenario:\n\n<4> [110.025065]        CPU0\n<4> [110.025075]        ----\n<4> [110.025084]   lock(&(&rq->lock)->rlock);\n<4> [110.025099]   <Interrupt>\n<4> [110.025109]     lock(&(&rq->lock)->rlock);\n<4> [110.025124]\n *** DEADLOCK ***\n\n<4> [110.025144] 4 locks held by kworker/0:0/5:\n<4> [110.025156]  #0: ffff88827588f528 ((wq_completion)events){+.+.}, at: process_one_work+0x1de/0x620\n<4> [110.025187]  #1: ffffc9000006fe78 ((work_completion)(&engine->retire_work)){+.+.}, at: process_one_work+0x1de/0x620\n<4> [110.025219]  #2: ffff88825605e270 (&kernel#2){+.+.}, at: engine_retire+0x57/0xe0 [i915]\n<4> [110.025405]  #3: ffff88826a0c7a18 (&(&rq->lock)->rlock){?.-.}, at: i915_request_retire+0x221/0x930 [i915]\n<4> [110.025634]\nstack backtrace:\n<4> [110.025653] CPU: 0 PID: 5 Comm: kworker/0:0 Tainted: G     U            5.4.0-rc8-CI-CI_DRM_7489+ #1\n<4> [110.025675] Hardware name:  /NUC7i5BNB, BIOS BNKBL357.86A.0054.2017.1025.1822 10/25/2017\n<4> [110.025856] Workqueue: events engine_retire [i915]\n<4> [110.025872] Call Trace:\n<4> [110.025891]  dump_stack+0x71/0x9b\n<4> [110.025907]  mark_lock+0x49a/0x500\n<4> [110.025926]  ? print_shortest_lock_dependencies+0x200/0x200\n<4> [110.025946]  mark_held_locks+0x49/0x70\n<4> [110.025962]  ? _raw_spin_unlock_irq+0x24/0x50\n<4> [110.025978]  lockdep_hardirqs_on+0xa2/0x1c0\n<4> [110.025995]  _raw_spin_unlock_irq+0x24/0x50\n<4> [110.026171]  virtual_context_destroy+0xc5/0x2e0 [i915]\n<4> [110.026376]  __active_retire+0xb4/0x290 [i915]\n<4> [110.026396]  dma_fence_signal_locked+0x9e/0x1b0\n<4> [110.026613]  i915_request_retire+0x451/0x930 [i915]\n<4> [110.026766]  retire_requests+0x4d/0x60 [i915]\n<4> [110.026919]  engine_retire+0x63/0xe0 [i915]\n\nFixes: b1e3177bd1d8 (\"drm/i915: Coordinate i915_active with its own mutex\")\nFixes: 6d06779e8672 (\"drm/i915: Load balancing across a virtual engine\")\nSigned-off-by: Chris Wilson <chris@chris-wilson.co.uk>\nCc: Tvrtko Ursulin <tvrtko.ursulin@intel.com>\nReviewed-by: Tvrtko Ursulin <tvrtko.ursulin@intel.com>\nLink: https://patchwork.freedesktop.org/patch/msgid/20191205145934.663183-1-chris@chris-wilson.co.uk\n(cherry picked from commit 6f7ac8285371fb0df58aba861eaab387f79ed04d)\nSigned-off-by: Joonas Lahtinen <joonas.lahtinen@linux.intel.com>",
        "before_after_code_files": [
          "drivers/gpu/drm/i915/gt/intel_lrc.c||drivers/gpu/drm/i915/gt/intel_lrc.c"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_issue": 1,
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "drivers/gpu/drm/i915/gt/intel_lrc.c||drivers/gpu/drm/i915/gt/intel_lrc.c": [
          "File: drivers/gpu/drm/i915/gt/intel_lrc.c -> drivers/gpu/drm/i915/gt/intel_lrc.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "4120:  for (n = 0; n < ve->num_siblings; n++) {",
          "4121:   struct intel_engine_cs *sibling = ve->siblings[n];",
          "4122:   struct rb_node *node = &ve->nodes[sibling->id].rb;",
          "4124:   if (RB_EMPTY_NODE(node))",
          "4125:    continue;",
          "4130:   if (!RB_EMPTY_NODE(node))",
          "4131:    rb_erase_cached(node, &sibling->execlists.virtual);",
          "4134:  }",
          "4135:  GEM_BUG_ON(__tasklet_is_scheduled(&ve->base.execlists.tasklet));",
          "",
          "[Removed Lines]",
          "4127:   spin_lock_irq(&sibling->active.lock);",
          "4133:   spin_unlock_irq(&sibling->active.lock);",
          "",
          "[Added Lines]",
          "4123:   unsigned long flags;",
          "4128:   spin_lock_irqsave(&sibling->active.lock, flags);",
          "4134:   spin_unlock_irqrestore(&sibling->active.lock, flags);",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "16c46fd505fbe33ee480f8bb67aa3807b3507c72",
      "candidate_info": {
        "commit_hash": "16c46fd505fbe33ee480f8bb67aa3807b3507c72",
        "repo": "torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/16c46fd505fbe33ee480f8bb67aa3807b3507c72",
        "files": [
          "drivers/gpu/drm/i915/gem/i915_gem_domain.c",
          "drivers/gpu/drm/i915/i915_drv.h",
          "drivers/gpu/drm/i915/i915_gem.c"
        ],
        "message": "drm/i915/gem: Avoid rcu_barrier() from shrinker paths\n\nAs i915_gem_object_unbind() waits on an rcu_barrier() to flush vm\nreleases (and destruction of their bound vma), we have to be careful not\nto invoke that barrier from beneath the shrinker:\n\n<4> [430.222671] WARNING: possible circular locking dependency detected\n<4> [430.222673] 5.4.0-rc8-CI-CI_DRM_7508+ #1 Tainted: G     U\n<4> [430.222675] ------------------------------------------------------\n<4> [430.222677] gem_pwrite/2317 is trying to acquire lock:\n<4> [430.222678] ffffffff82248218 (rcu_state.barrier_mutex){+.+.}, at: rcu_barrier+0x23/0x190\n<4> [430.222685]\nbut task is already holding lock:\n<4> [430.222687] ffffffff82263a40 (fs_reclaim){+.+.}, at: fs_reclaim_acquire.part.117+0x0/0x30\n<4> [430.222691]\nwhich lock already depends on the new lock.\n\n<4> [430.222693]\nthe existing dependency chain (in reverse order) is:\n<4> [430.222695]\n-> #2 (fs_reclaim){+.+.}:\n<4> [430.222698]        fs_reclaim_acquire.part.117+0x24/0x30\n<4> [430.222702]        kmem_cache_alloc_trace+0x2a/0x2c0\n<4> [430.222705]        intel_cpuc_prepare+0x37/0x1a0\n<4> [430.222709]        cpuhp_invoke_callback+0x9b/0x9d0\n<4> [430.222712]        _cpu_up+0xa2/0x140\n<4> [430.222714]        do_cpu_up+0x61/0xa0\n<4> [430.222718]        smp_init+0x57/0x96\n<4> [430.222722]        kernel_init_freeable+0xac/0x1c7\n<4> [430.222725]        kernel_init+0x5/0x100\n<4> [430.222728]        ret_from_fork+0x24/0x50\n<4> [430.222729]\n-> #1 (cpu_hotplug_lock.rw_sem){++++}:\n<4> [430.222733]        cpus_read_lock+0x34/0xd0\n<4> [430.222734]        rcu_barrier+0xaa/0x190\n<4> [430.222736]        kernel_init+0x21/0x100\n<4> [430.222737]        ret_from_fork+0x24/0x50\n<4> [430.222739]\n-> #0 (rcu_state.barrier_mutex){+.+.}:\n<4> [430.222742]        __lock_acquire+0x1328/0x15d0\n<4> [430.222743]        lock_acquire+0xa7/0x1c0\n<4> [430.222746]        __mutex_lock+0x9a/0x9d0\n<4> [430.222747]        rcu_barrier+0x23/0x190\n<4> [430.222850]        i915_gem_object_unbind+0x264/0x3d0 [i915]\n<4> [430.222882]        i915_gem_shrink+0x297/0x5f0 [i915]\n<4> [430.222912]        i915_gem_shrink_all+0x38/0x60 [i915]\n<4> [430.222934]        i915_drop_caches_set+0x1f0/0x240 [i915]\n<4> [430.222938]        simple_attr_write+0xb0/0xd0\n<4> [430.222941]        full_proxy_write+0x51/0x80\n<4> [430.222943]        vfs_write+0xb9/0x1d0\n<4> [430.222944]        ksys_write+0x9f/0xe0\n<4> [430.222946]        do_syscall_64+0x4f/0x210\n<4> [430.222948]        entry_SYSCALL_64_after_hwframe+0x49/0xbe\n<4> [430.222950]\nother info that might help us debug this:\n\n<4> [430.222952] Chain exists of:\n  rcu_state.barrier_mutex --> cpu_hotplug_lock.rw_sem --> fs_reclaim\n\n<4> [430.222955]  Possible unsafe locking scenario:\n\n<4> [430.222957]        CPU0                    CPU1\n<4> [430.222958]        ----                    ----\n<4> [430.222960]   lock(fs_reclaim);\n<4> [430.222961]                                lock(cpu_hotplug_lock.rw_sem);\n<4> [430.222963]                                lock(fs_reclaim);\n<4> [430.222964]   lock(rcu_state.barrier_mutex);\n<4> [430.222966]\n *** DEADLOCK ***\n\n<4> [430.222968] 3 locks held by gem_pwrite/2317:\n<4> [430.222969]  #0: ffff88849e2d9408 (sb_writers#14){.+.+}, at: vfs_write+0x1a4/0x1d0\n<4> [430.222973]  #1: ffff888496976db0 (&attr->mutex){+.+.}, at: simple_attr_write+0x36/0xd0\n<4> [430.222976]  #2: ffffffff82263a40 (fs_reclaim){+.+.}, at: fs_reclaim_acquire.part.117+0x0/0x30\n<4> [430.222980]\nstack backtrace:\n<4> [430.222982] CPU: 1 PID: 2317 Comm: gem_pwrite Tainted: G     U            5.4.0-rc8-CI-CI_DRM_7508+ #1\n<4> [430.222985] Hardware name: Intel Corporation Tiger Lake Client Platform/TigerLake U DDR4 SODIMM RVP, BIOS TGLSFWI1.R00.2321.A08.1909162051 09/16/2019\n<4> [430.222989] Call Trace:\n<4> [430.222992]  dump_stack+0x71/0x9b\n<4> [430.222995]  check_noncircular+0x19b/0x1c0\n<4> [430.222998]  ? __lock_acquire+0x1328/0x15d0\n<4> [430.222999]  __lock_acquire+0x1328/0x15d0\n<4> [430.223001]  ? mark_held_locks+0x49/0x70\n<4> [430.223003]  lock_acquire+0xa7/0x1c0\n<4> [430.223005]  ? rcu_barrier+0x23/0x190\n<4> [430.223008]  __mutex_lock+0x9a/0x9d0\n<4> [430.223009]  ? rcu_barrier+0x23/0x190\n<4> [430.223011]  ? rcu_barrier+0x23/0x190\n<4> [430.223013]  ? find_held_lock+0x2d/0x90\n<4> [430.223045]  ? i915_gem_object_unbind+0x24a/0x3d0 [i915]\n<4> [430.223048]  ? rcu_barrier+0x23/0x190\n<4> [430.223049]  rcu_barrier+0x23/0x190\n<4> [430.223081]  i915_gem_object_unbind+0x264/0x3d0 [i915]\n<4> [430.223119]  i915_gem_shrink+0x297/0x5f0 [i915]\n\nCloses: https://gitlab.freedesktop.org/drm/intel/issues/743\nSigned-off-by: Chris Wilson <chris@chris-wilson.co.uk>\nReviewed-by: Matthew Auld <matthew.auld@intel.com>\nLink: https://patchwork.freedesktop.org/patch/msgid/20191208161252.3015727-1-chris@chris-wilson.co.uk",
        "before_after_code_files": [
          "drivers/gpu/drm/i915/gem/i915_gem_domain.c||drivers/gpu/drm/i915/gem/i915_gem_domain.c",
          "drivers/gpu/drm/i915/i915_drv.h||drivers/gpu/drm/i915/i915_drv.h",
          "drivers/gpu/drm/i915/i915_gem.c||drivers/gpu/drm/i915/i915_gem.c"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_issue": 1,
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "drivers/gpu/drm/i915/gem/i915_gem_domain.c||drivers/gpu/drm/i915/gem/i915_gem_domain.c": [
          "File: drivers/gpu/drm/i915/gem/i915_gem_domain.c -> drivers/gpu/drm/i915/gem/i915_gem_domain.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "203:  i915_gem_object_unlock(obj);",
          "207: }",
          "209: int i915_gem_get_caching_ioctl(struct drm_device *dev, void *data,",
          "",
          "[Removed Lines]",
          "206:  return i915_gem_object_unbind(obj, I915_GEM_OBJECT_UNBIND_ACTIVE);",
          "",
          "[Added Lines]",
          "206:  return i915_gem_object_unbind(obj,",
          "207:           I915_GEM_OBJECT_UNBIND_ACTIVE |",
          "208:           I915_GEM_OBJECT_UNBIND_BARRIER);",
          "",
          "---------------"
        ],
        "drivers/gpu/drm/i915/i915_drv.h||drivers/gpu/drm/i915/i915_drv.h": [
          "File: drivers/gpu/drm/i915/i915_drv.h -> drivers/gpu/drm/i915/i915_drv.h",
          "--- Hunk 1 ---",
          "[Context before]",
          "1845: int i915_gem_object_unbind(struct drm_i915_gem_object *obj,",
          "1846:       unsigned long flags);",
          "1847: #define I915_GEM_OBJECT_UNBIND_ACTIVE BIT(0)",
          "1849: void i915_gem_runtime_suspend(struct drm_i915_private *dev_priv);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1848: #define I915_GEM_OBJECT_UNBIND_BARRIER BIT(1)",
          "",
          "---------------"
        ],
        "drivers/gpu/drm/i915/i915_gem.c||drivers/gpu/drm/i915/i915_gem.c": [
          "File: drivers/gpu/drm/i915/i915_gem.c -> drivers/gpu/drm/i915/i915_gem.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "178:  list_splice_init(&still_in_list, &obj->vma.list);",
          "179:  spin_unlock(&obj->vma.lock);",
          "183:   goto try_again;",
          "184:  }",
          "",
          "[Removed Lines]",
          "181:  if (ret == -EAGAIN && flags & I915_GEM_OBJECT_UNBIND_ACTIVE) {",
          "",
          "[Added Lines]",
          "181:  if (ret == -EAGAIN && flags & I915_GEM_OBJECT_UNBIND_BARRIER) {",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "aef820799274e3bd66e1857f6aa3ee8cff2c30eb",
      "candidate_info": {
        "commit_hash": "aef820799274e3bd66e1857f6aa3ee8cff2c30eb",
        "repo": "torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/aef820799274e3bd66e1857f6aa3ee8cff2c30eb",
        "files": [
          "drivers/gpu/drm/i915/gem/i915_gem_context.c"
        ],
        "message": "drm/i915/gem: Pin gen6_ppgtt prior to constructing the request\n\nAll pinning must be done prior to i915_request_create, to avoid\ntimeline->mutex inversions.\n\nHere we slightly abuse the context_barrier_task stages to utilise the\n'skip' decision as an opportunity to acquire the pin on the new ppgtt.\nConsider it s/skip/prepare/. At the moment, we only have on user of\ncontext_barrier_task, so it might be worth breaking it down for the\nspecific task of set-vm and refactor it later if we find a second\npurpose.\n\n<4> [402.377487] WARNING: possible circular locking dependency detected\n<4> [402.377493] 5.4.0-rc8-CI-CI_DRM_7491+ #1 Tainted: G     U\n<4> [402.377497] ------------------------------------------------------\n<4> [402.377502] gem_exec_parall/2506 is trying to acquire lock:\n<4> [402.377507] ffff888403cdac70 (&kernel#2){+.+.}, at: i915_request_create+0x16/0x1c0 [i915]\n<4> [402.377593]\nbut task is already holding lock:\n<4> [402.377597] ffff88835efad550 (&ppgtt->pin_mutex){+.+.}, at: gen6_ppgtt_pin+0x4d/0x110 [i915]\n<4> [402.377660]\nwhich lock already depends on the new lock.\n\n<4> [402.377664]\nthe existing dependency chain (in reverse order) is:\n<4> [402.377668]\n-> #1 (&ppgtt->pin_mutex){+.+.}:\n<4> [402.377674]        __mutex_lock+0x9a/0x9d0\n<4> [402.377713]        gen6_ppgtt_pin+0x4d/0x110 [i915]\n<4> [402.377756]        emit_ppgtt_update+0x1dc/0x370 [i915]\n<4> [402.377801]        context_barrier_task+0x176/0x310 [i915]\n<4> [402.377844]        ctx_setparam+0x400/0xb10 [i915]\n<4> [402.377886]        i915_gem_context_setparam_ioctl+0xc8/0x160 [i915]\n<4> [402.377891]        drm_ioctl_kernel+0xa7/0xf0\n<4> [402.377895]        drm_ioctl+0x2e1/0x390\n<4> [402.377899]        do_vfs_ioctl+0xa0/0x6f0\n<4> [402.377903]        ksys_ioctl+0x35/0x60\n<4> [402.377906]        __x64_sys_ioctl+0x11/0x20\n<4> [402.377910]        do_syscall_64+0x4f/0x210\n<4> [402.377914]        entry_SYSCALL_64_after_hwframe+0x49/0xbe\n<4> [402.377917]\n-> #0 (&kernel#2){+.+.}:\n<4> [402.377923]        __lock_acquire+0x1328/0x15d0\n<4> [402.377926]        lock_acquire+0xa7/0x1c0\n<4> [402.377930]        __mutex_lock+0x9a/0x9d0\n<4> [402.377977]        i915_request_create+0x16/0x1c0 [i915]\n<4> [402.378013]        intel_engine_flush_barriers+0x4c/0x100 [i915]\n<4> [402.378062]        i915_ggtt_pin+0x7d/0x130 [i915]\n<4> [402.378108]        gen6_ppgtt_pin+0x9c/0x110 [i915]\n<4> [402.378148]        ring_context_pin+0x2e/0xc0 [i915]\n<4> [402.378183]        __intel_context_do_pin+0x6b/0x190 [i915]\n<4> [402.378226]        i915_gem_do_execbuffer+0x180c/0x26b0 [i915]\n<4> [402.378268]        i915_gem_execbuffer2_ioctl+0x11b/0x460 [i915]\n<4> [402.378272]        drm_ioctl_kernel+0xa7/0xf0\n<4> [402.378275]        drm_ioctl+0x2e1/0x390\n<4> [402.378279]        do_vfs_ioctl+0xa0/0x6f0\n<4> [402.378282]        ksys_ioctl+0x35/0x60\n<4> [402.378286]        __x64_sys_ioctl+0x11/0x20\n<4> [402.378289]        do_syscall_64+0x4f/0x210\n<4> [402.378292]        entry_SYSCALL_64_after_hwframe+0x49/0xbe\n<4> [402.378295]\nother info that might help us debug this:\n\n<4> [402.378299]  Possible unsafe locking scenario:\n\n<4> [402.378302]        CPU0                    CPU1\n<4> [402.378305]        ----                    ----\n<4> [402.378307]   lock(&ppgtt->pin_mutex);\n<4> [402.378310]                                lock(&kernel#2);\n<4> [402.378314]                                lock(&ppgtt->pin_mutex);\n<4> [402.378317]   lock(&kernel#2);\n<4> [402.378320]\n\nSigned-off-by: Chris Wilson <chris@chris-wilson.co.uk>\nReviewed-by: Andi Shyti <andi.shyti@intel.com>\nLink: https://patchwork.freedesktop.org/patch/msgid/20191206105527.1130413-4-chris@chris-wilson.co.uk",
        "before_after_code_files": [
          "drivers/gpu/drm/i915/gem/i915_gem_context.c||drivers/gpu/drm/i915/gem/i915_gem_context.c"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_issue": 1,
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "drivers/gpu/drm/i915/gem/i915_gem_context.c||drivers/gpu/drm/i915/gem/i915_gem_context.c": [
          "File: drivers/gpu/drm/i915/gem/i915_gem_context.c -> drivers/gpu/drm/i915/gem/i915_gem_context.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "1140:   }",
          "1142:   intel_ring_advance(rq, cs);",
          "1146:  }",
          "1148:  return 0;",
          "",
          "[Removed Lines]",
          "1143:  } else {",
          "1145:   gen6_ppgtt_pin(i915_vm_to_ppgtt(vm));",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1151: static bool skip_ppgtt_update(struct intel_context *ce, void *data)",
          "1152: {",
          "1153:  if (HAS_LOGICAL_RING_CONTEXTS(ce->engine->i915))",
          "1157: }",
          "1159: static int set_ppgtt(struct drm_i915_file_private *file_priv,",
          "",
          "[Removed Lines]",
          "1154:   return !ce->state;",
          "1155:  else",
          "1156:   return !atomic_read(&ce->pin_count);",
          "",
          "[Added Lines]",
          "1150:  if (!test_bit(CONTEXT_ALLOC_BIT, &ce->flags))",
          "1151:   return true;",
          "1154:   return false;",
          "1156:  if (!atomic_read(&ce->pin_count))",
          "1157:   return true;",
          "1160:  if (gen6_ppgtt_pin(i915_vm_to_ppgtt(ce->vm)))",
          "1161:   return true;",
          "1163:  return false;",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "158d58335393af3956a9c06f0816ee75ed1f1447",
      "candidate_info": {
        "commit_hash": "158d58335393af3956a9c06f0816ee75ed1f1447",
        "repo": "torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/158d58335393af3956a9c06f0816ee75ed1f1447",
        "files": [
          "fs/afs/mntpt.c"
        ],
        "message": "afs: Fix mountpoint parsing\n\nEach AFS mountpoint has strings that define the target to be mounted.  This\nis required to end in a dot that is supposed to be stripped off.  The\nstring can include suffixes of \".readonly\" or \".backup\" - which are\nsupposed to come before the terminal dot.  To add to the confusion, the \"fs\nlsmount\" afs utility does not show the terminal dot when displaying the\nstring.\n\nThe kernel mount source string parser, however, assumes that the terminal\ndot marks the suffix and that the suffix is always \"\" and is thus ignored.\nIn most cases, there is no suffix and this is not a problem - but if there\nis a suffix, it is lost and this affects the ability to mount the correct\nvolume.\n\nThe command line mount command, on the other hand, is expected not to\ninclude a terminal dot - so the problem doesn't arise there.\n\nFix this by making sure that the dot exists and then stripping it when\npassing the string to the mount configuration.\n\nFixes: bec5eb614130 (\"AFS: Implement an autocell mount capability [ver #2]\")\nReported-by: Jonathan Billings <jsbillings@jsbillings.org>\nSigned-off-by: David Howells <dhowells@redhat.com>\nReviewed-by: Marc Dionne <marc.dionne@auristor.com>\nTested-by: Jonathan Billings <jsbillings@jsbillings.org>",
        "before_after_code_files": [
          "fs/afs/mntpt.c||fs/afs/mntpt.c"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_issue": 1,
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "fs/afs/mntpt.c||fs/afs/mntpt.c": [
          "File: fs/afs/mntpt.c -> fs/afs/mntpt.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "126:   if (src_as->cell)",
          "127:    ctx->cell = afs_get_cell(src_as->cell);",
          "130:    return -EINVAL;",
          "132:   page = read_mapping_page(d_inode(mntpt)->i_mapping, 0, NULL);",
          "",
          "[Removed Lines]",
          "129:   if (size > PAGE_SIZE - 1)",
          "",
          "[Added Lines]",
          "129:   if (size < 2 || size > PAGE_SIZE - 1)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "140:   }",
          "142:   buf = kmap(page);",
          "144:   kunmap(page);",
          "145:   put_page(page);",
          "146:   if (ret < 0)",
          "",
          "[Removed Lines]",
          "143:   ret = vfs_parse_fs_string(fc, \"source\", buf, size);",
          "",
          "[Added Lines]",
          "143:   ret = -EINVAL;",
          "144:   if (buf[size - 1] == '.')",
          "145:    ret = vfs_parse_fs_string(fc, \"source\", buf, size - 1);",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "894c9ef9780c5cf2f143415e867ee39a33ecb75d",
      "candidate_info": {
        "commit_hash": "894c9ef9780c5cf2f143415e867ee39a33ecb75d",
        "repo": "torvalds/linux",
        "commit_url": "https://github.com/torvalds/linux/commit/894c9ef9780c5cf2f143415e867ee39a33ecb75d",
        "files": [
          "include/linux/cpuhotplug.h",
          "kernel/padata.c"
        ],
        "message": "padata: validate cpumask without removed CPU during offline\n\nConfiguring an instance's parallel mask without any online CPUs...\n\n  echo 2 > /sys/kernel/pcrypt/pencrypt/parallel_cpumask\n  echo 0 > /sys/devices/system/cpu/cpu1/online\n\n...makes tcrypt mode=215 crash like this:\n\n  divide error: 0000 [#1] SMP PTI\n  CPU: 4 PID: 283 Comm: modprobe Not tainted 5.4.0-rc8-padata-doc-v2+ #2\n  Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS ?-20191013_105130-anatol 04/01/2014\n  RIP: 0010:padata_do_parallel+0x114/0x300\n  Call Trace:\n   pcrypt_aead_encrypt+0xc0/0xd0 [pcrypt]\n   crypto_aead_encrypt+0x1f/0x30\n   do_mult_aead_op+0x4e/0xdf [tcrypt]\n   test_mb_aead_speed.constprop.0.cold+0x226/0x564 [tcrypt]\n   do_test+0x28c2/0x4d49 [tcrypt]\n   tcrypt_mod_init+0x55/0x1000 [tcrypt]\n   ...\n\ncpumask_weight() in padata_cpu_hash() returns 0 because the mask has no\nCPUs.  The problem is __padata_remove_cpu() checks for valid masks too\nearly and so doesn't mark the instance PADATA_INVALID as expected, which\nwould have made padata_do_parallel() return error before doing the\ndivision.\n\nFix by introducing a second padata CPU hotplug state before\nCPUHP_BRINGUP_CPU so that __padata_remove_cpu() sees the online mask\nwithout @cpu.  No need for the second argument to padata_replace() since\n@cpu is now already missing from the online mask.\n\nFixes: 33e54450683c (\"padata: Handle empty padata cpumasks\")\nSigned-off-by: Daniel Jordan <daniel.m.jordan@oracle.com>\nCc: Eric Biggers <ebiggers@kernel.org>\nCc: Herbert Xu <herbert@gondor.apana.org.au>\nCc: Sebastian Andrzej Siewior <bigeasy@linutronix.de>\nCc: Steffen Klassert <steffen.klassert@secunet.com>\nCc: Thomas Gleixner <tglx@linutronix.de>\nCc: linux-crypto@vger.kernel.org\nCc: linux-kernel@vger.kernel.org\nSigned-off-by: Herbert Xu <herbert@gondor.apana.org.au>",
        "before_after_code_files": [
          "include/linux/cpuhotplug.h||include/linux/cpuhotplug.h",
          "kernel/padata.c||kernel/padata.c"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_issue": 1,
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "include/linux/cpuhotplug.h||include/linux/cpuhotplug.h": [
          "File: include/linux/cpuhotplug.h -> include/linux/cpuhotplug.h",
          "--- Hunk 1 ---",
          "[Context before]",
          "59:  CPUHP_IOMMU_INTEL_DEAD,",
          "60:  CPUHP_LUSTRE_CFS_DEAD,",
          "61:  CPUHP_AP_ARM_CACHE_B15_RAC_DEAD,",
          "62:  CPUHP_WORKQUEUE_PREP,",
          "63:  CPUHP_POWER_NUMA_PREPARE,",
          "64:  CPUHP_HRTIMERS_PREPARE,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "62:  CPUHP_PADATA_DEAD,",
          "",
          "---------------"
        ],
        "kernel/padata.c||kernel/padata.c": [
          "File: kernel/padata.c -> kernel/padata.c",
          "--- Hunk 1 ---",
          "[Context before]",
          "512:  return 0;",
          "513: }",
          "516: {",
          "517:  int notification_mask = 0;",
          "518:  struct padata_shell *ps;",
          "",
          "[Removed Lines]",
          "515: static int padata_replace(struct padata_instance *pinst, int cpu)",
          "",
          "[Added Lines]",
          "515: static int padata_replace(struct padata_instance *pinst)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "523:  cpumask_copy(pinst->omask, pinst->rcpumask.pcpu);",
          "524:  cpumask_and(pinst->rcpumask.pcpu, pinst->cpumask.pcpu,",
          "525:       cpu_online_mask);",
          "528:  if (!cpumask_equal(pinst->omask, pinst->rcpumask.pcpu))",
          "529:   notification_mask |= PADATA_CPU_PARALLEL;",
          "531:  cpumask_copy(pinst->omask, pinst->rcpumask.cbcpu);",
          "532:  cpumask_and(pinst->rcpumask.cbcpu, pinst->cpumask.cbcpu,",
          "533:       cpu_online_mask);",
          "536:  if (!cpumask_equal(pinst->omask, pinst->rcpumask.cbcpu))",
          "537:   notification_mask |= PADATA_CPU_SERIAL;",
          "",
          "[Removed Lines]",
          "526:  if (cpu >= 0)",
          "527:   cpumask_clear_cpu(cpu, pinst->rcpumask.pcpu);",
          "534:  if (cpu >= 0)",
          "535:   cpumask_clear_cpu(cpu, pinst->rcpumask.cbcpu);",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "624:  cpumask_copy(pinst->cpumask.pcpu, pcpumask);",
          "625:  cpumask_copy(pinst->cpumask.cbcpu, cbcpumask);",
          "629:  if (valid)",
          "630:   __padata_start(pinst);",
          "",
          "[Removed Lines]",
          "627:  err = padata_setup_cpumasks(pinst) ?: padata_replace(pinst, -1);",
          "",
          "[Added Lines]",
          "623:  err = padata_setup_cpumasks(pinst) ?: padata_replace(pinst);",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "715:  int err = 0;",
          "717:  if (cpumask_test_cpu(cpu, cpu_online_mask)) {",
          "720:   if (padata_validate_cpumask(pinst, pinst->cpumask.pcpu) &&",
          "721:       padata_validate_cpumask(pinst, pinst->cpumask.cbcpu))",
          "",
          "[Removed Lines]",
          "718:   err = padata_replace(pinst, -1);",
          "",
          "[Added Lines]",
          "714:   err = padata_replace(pinst);",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "729: {",
          "730:  int err = 0;",
          "733:   if (!padata_validate_cpumask(pinst, pinst->cpumask.pcpu) ||",
          "734:       !padata_validate_cpumask(pinst, pinst->cpumask.cbcpu))",
          "735:    __padata_stop(pinst);",
          "738:  }",
          "740:  return err;",
          "",
          "[Removed Lines]",
          "732:  if (cpumask_test_cpu(cpu, cpu_online_mask)) {",
          "737:   err = padata_replace(pinst, cpu);",
          "",
          "[Added Lines]",
          "728:  if (!cpumask_test_cpu(cpu, cpu_online_mask)) {",
          "733:   err = padata_replace(pinst);",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "761:  return ret;",
          "762: }",
          "765: {",
          "766:  struct padata_instance *pinst;",
          "767:  int ret;",
          "",
          "[Removed Lines]",
          "764: static int padata_cpu_prep_down(unsigned int cpu, struct hlist_node *node)",
          "",
          "[Added Lines]",
          "760: static int padata_cpu_dead(unsigned int cpu, struct hlist_node *node)",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "782: static void __padata_free(struct padata_instance *pinst)",
          "783: {",
          "784: #ifdef CONFIG_HOTPLUG_CPU",
          "785:  cpuhp_state_remove_instance_nocalls(hp_online, &pinst->node);",
          "786: #endif",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "781:  cpuhp_state_remove_instance_nocalls(CPUHP_PADATA_DEAD, &pinst->node);",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "990: #ifdef CONFIG_HOTPLUG_CPU",
          "991:  cpuhp_state_add_instance_nocalls_cpuslocked(hp_online, &pinst->node);",
          "992: #endif",
          "994:  put_online_cpus();",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "989:  cpuhp_state_add_instance_nocalls_cpuslocked(CPUHP_PADATA_DEAD,",
          "990:           &pinst->node);",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "1101:  int ret;",
          "1103:  ret = cpuhp_setup_state_multi(CPUHP_AP_ONLINE_DYN, \"padata:online\",",
          "1106:  if (ret < 0)",
          "1107:   return ret;",
          "1108:  hp_online = ret;",
          "1109:  return 0;",
          "1110: }",
          "1111: module_init(padata_driver_init);",
          "1113: static __exit void padata_driver_exit(void)",
          "1114: {",
          "1115:  cpuhp_remove_multi_state(hp_online);",
          "1116: }",
          "1117: module_exit(padata_driver_exit);",
          "",
          "[Removed Lines]",
          "1104:           padata_cpu_online,",
          "1105:           padata_cpu_prep_down);",
          "",
          "[Added Lines]",
          "1103:           padata_cpu_online, NULL);",
          "1108:  ret = cpuhp_setup_state_multi(CPUHP_PADATA_DEAD, \"padata:dead\",",
          "1109:           NULL, padata_cpu_dead);",
          "1110:  if (ret < 0) {",
          "1111:   cpuhp_remove_multi_state(hp_online);",
          "1112:   return ret;",
          "1113:  }",
          "1120:  cpuhp_remove_multi_state(CPUHP_PADATA_DEAD);",
          "",
          "---------------"
        ]
      }
    }
  ]
}