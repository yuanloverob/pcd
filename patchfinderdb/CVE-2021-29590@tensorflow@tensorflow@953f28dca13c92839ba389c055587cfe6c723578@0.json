{
  "cve_id": "CVE-2021-29590",
  "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. The implementations of the `Minimum` and `Maximum` TFLite operators can be used to read data outside of bounds of heap allocated objects, if any of the two input tensor arguments are empty. This is because the broadcasting implementation(https://github.com/tensorflow/tensorflow/blob/0d45ea1ca641b21b73bcf9c00e0179cda284e7e7/tensorflow/lite/kernels/internal/reference/maximum_minimum.h#L52-L56) indexes in both tensors with the same index but does not validate that the index is within bounds. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
  "repo": "tensorflow/tensorflow",
  "patch_hash": "953f28dca13c92839ba389c055587cfe6c723578",
  "patch_info": {
    "commit_hash": "953f28dca13c92839ba389c055587cfe6c723578",
    "repo": "tensorflow/tensorflow",
    "commit_url": "https://github.com/tensorflow/tensorflow/commit/953f28dca13c92839ba389c055587cfe6c723578",
    "files": [
      "tensorflow/lite/kernels/maximum_minimum.cc"
    ],
    "message": "Prevent a null pointer exception in TFLite\n\nPiperOrigin-RevId: 370800206\nChange-Id: Idd437ebce4ff224120d8eefc1c14c062173b71d6",
    "before_after_code_files": [
      "tensorflow/lite/kernels/maximum_minimum.cc||tensorflow/lite/kernels/maximum_minimum.cc"
    ]
  },
  "patch_diff": {
    "tensorflow/lite/kernels/maximum_minimum.cc||tensorflow/lite/kernels/maximum_minimum.cc": [
      "File: tensorflow/lite/kernels/maximum_minimum.cc -> tensorflow/lite/kernels/maximum_minimum.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "157: TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {",
      "158:   OpContext op_context(context, node);",
      "189:   return kTfLiteOk;",
      "190: }",
      "",
      "[Removed Lines]",
      "160:     switch (op_context.output->type) {",
      "161:       case kTfLiteFloat32:",
      "162:         TFLiteOperation<kernel_type, float, OpType>(context, node, op_context);",
      "163:         break;",
      "164:       case kTfLiteUInt8:",
      "165:         TFLiteOperation<kernel_type, uint8_t, OpType>(context, node,",
      "166:                                                       op_context);",
      "167:         break;",
      "168:       case kTfLiteInt8:",
      "169:         TFLiteOperation<kernel_type, int8_t, OpType>(context, node, op_context);",
      "170:         break;",
      "171:       case kTfLiteInt32:",
      "172:         TFLiteOperation<kernel_type, int32_t, OpType>(context, node,",
      "173:                                                       op_context);",
      "174:         break;",
      "175:       case kTfLiteInt64:",
      "176:         TFLiteOperation<kernel_type, int64_t, OpType>(context, node,",
      "177:                                                       op_context);",
      "178:         break;",
      "179:       case kTfLiteInt16:",
      "180:         TFLiteOperation<kernel_type, int16_t, OpType>(context, node,",
      "181:                                                       op_context);",
      "182:         break;",
      "183:       default:",
      "184:         context->ReportError(context,",
      "185:                              \"Type %d is currently not supported by Maximum.\",",
      "186:                              op_context.output->type);",
      "187:         return kTfLiteError;",
      "188:     }",
      "",
      "[Added Lines]",
      "161:   if (NumElements(op_context.input1) == 0 ||",
      "162:       NumElements(op_context.input2) == 0) {",
      "163:     return kTfLiteOk;",
      "164:   }",
      "166:   switch (op_context.output->type) {",
      "167:     case kTfLiteFloat32:",
      "168:       TFLiteOperation<kernel_type, float, OpType>(context, node, op_context);",
      "169:       break;",
      "170:     case kTfLiteUInt8:",
      "171:       TFLiteOperation<kernel_type, uint8_t, OpType>(context, node, op_context);",
      "172:       break;",
      "173:     case kTfLiteInt8:",
      "174:       TFLiteOperation<kernel_type, int8_t, OpType>(context, node, op_context);",
      "175:       break;",
      "176:     case kTfLiteInt32:",
      "177:       TFLiteOperation<kernel_type, int32_t, OpType>(context, node, op_context);",
      "178:       break;",
      "179:     case kTfLiteInt64:",
      "180:       TFLiteOperation<kernel_type, int64_t, OpType>(context, node, op_context);",
      "181:       break;",
      "182:     case kTfLiteInt16:",
      "183:       TFLiteOperation<kernel_type, int16_t, OpType>(context, node, op_context);",
      "184:       break;",
      "185:     default:",
      "186:       context->ReportError(context,",
      "187:                            \"Type %d is currently not supported by Maximum.\",",
      "188:                            op_context.output->type);",
      "189:       return kTfLiteError;",
      "190:   }",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "3f197f3f0e562be8b5ca04acb66487c8864ae5e6",
      "candidate_info": {
        "commit_hash": "3f197f3f0e562be8b5ca04acb66487c8864ae5e6",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/3f197f3f0e562be8b5ca04acb66487c8864ae5e6",
        "files": [
          "tensorflow/lite/kernels/internal/optimized/optimized_ops.h",
          "tensorflow/lite/kernels/maximum_minimum.cc"
        ],
        "message": "Optimize broadcast int8 max.\n\nPiperOrigin-RevId: 311460102\nChange-Id: Id1b3f64deca0d9aca7608985393be5814763817f",
        "before_after_code_files": [
          "tensorflow/lite/kernels/internal/optimized/optimized_ops.h||tensorflow/lite/kernels/internal/optimized/optimized_ops.h",
          "tensorflow/lite/kernels/maximum_minimum.cc||tensorflow/lite/kernels/maximum_minimum.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/lite/kernels/maximum_minimum.cc||tensorflow/lite/kernels/maximum_minimum.cc"
          ],
          "candidate": [
            "tensorflow/lite/kernels/maximum_minimum.cc||tensorflow/lite/kernels/maximum_minimum.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/lite/kernels/internal/optimized/optimized_ops.h||tensorflow/lite/kernels/internal/optimized/optimized_ops.h": [
          "File: tensorflow/lite/kernels/internal/optimized/optimized_ops.h -> tensorflow/lite/kernels/internal/optimized/optimized_ops.h",
          "--- Hunk 1 ---",
          "[Context before]",
          "7921:                       shrinked_output_shape, output_data);",
          "7922: }",
          "7924: }  // namespace optimized_ops",
          "7925: }  // namespace tflite",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "7925: inline void MaximumElementwise(int size, const ArithmeticParams& params,",
          "7926:                                const int8* input1_data, const int8* input2_data,",
          "7927:                                int8* output_data) {",
          "7928:   ruy::profiler::ScopeLabel label(\"MaximumElementwiseInt8/8bit\");",
          "7930:   int i = 0;",
          "7931: #ifdef USE_NEON",
          "7932:   for (; i <= size - 8; i += 8) {",
          "7933:     const int8x8_t input1_val_original = vld1_s8(input1_data + i);",
          "7934:     const int8x8_t input2_val_original = vld1_s8(input2_data + i);",
          "7935:     const int8x8_t max_data = vmax_s8(input1_val_original, input2_val_original);",
          "7936:     vst1_s8(output_data + i, max_data);",
          "7937:   }",
          "7938: #endif  // NEON",
          "7939:   for (; i < size; ++i) {",
          "7940:     const int8 input1_val = input1_data[i];",
          "7941:     const int8 input2_val = input2_data[i];",
          "7942:     output_data[i] = std::max(input1_val, input2_val);",
          "7943:   }",
          "7944: }",
          "7946: inline void MaximumScalarBroadcast(int size, const ArithmeticParams& params,",
          "7947:                                    int8 input1_data, const int8* input2_data,",
          "7948:                                    int8* output_data) {",
          "7949:   ruy::profiler::ScopeLabel label(\"MaximumScalarBroadcastInt8/8bit\");",
          "7950:   int i = 0;",
          "7952: #ifdef USE_NEON",
          "7953:   const int8x8_t input1_val_original = vdup_n_s8(input1_data);",
          "7954:   for (; i <= size - 8; i += 8) {",
          "7955:     const int8x8_t input2_val_original = vld1_s8(input2_data + i);",
          "7956:     const int8x8_t max_data = vmax_s8(input1_val_original, input2_val_original);",
          "7957:     vst1_s8(output_data + i, max_data);",
          "7958:   }",
          "7959: #endif  // NEON",
          "7960:   for (; i < size; ++i) {",
          "7961:     const int8 input2_val = input2_data[i];",
          "7962:     output_data[i] = std::max(input1_data, input2_val);",
          "7963:   }",
          "7964: }",
          "7966: inline void BroadcastMaximumFivefold(",
          "7967:     const ArithmeticParams& unswitched_params,",
          "7968:     const RuntimeShape& unswitched_input1_shape,",
          "7969:     const int8* unswitched_input1_data,",
          "7970:     const RuntimeShape& unswitched_input2_shape,",
          "7971:     const int8* unswitched_input2_data, const RuntimeShape& output_shape,",
          "7972:     int8* output_data) {",
          "7973:   ruy::profiler::ScopeLabel label(\"BroadcastMaximumFivefoldInt8/8bit\");",
          "7975:   ArithmeticParams switched_params = unswitched_params;",
          "7976:   switched_params.input1_offset = unswitched_params.input2_offset;",
          "7977:   switched_params.input1_multiplier = unswitched_params.input2_multiplier;",
          "7978:   switched_params.input1_shift = unswitched_params.input2_shift;",
          "7979:   switched_params.input2_offset = unswitched_params.input1_offset;",
          "7980:   switched_params.input2_multiplier = unswitched_params.input1_multiplier;",
          "7981:   switched_params.input2_shift = unswitched_params.input1_shift;",
          "7983:   const bool use_unswitched =",
          "7984:       unswitched_params.broadcast_category ==",
          "7985:       tflite::BroadcastableOpCategory::kFirstInputBroadcastsFast;",
          "7987:   const ArithmeticParams& params =",
          "7988:       use_unswitched ? unswitched_params : switched_params;",
          "7989:   const int8* input1_data =",
          "7990:       use_unswitched ? unswitched_input1_data : unswitched_input2_data;",
          "7991:   const int8* input2_data =",
          "7992:       use_unswitched ? unswitched_input2_data : unswitched_input1_data;",
          "7998:   int8* output_data_ptr = output_data;",
          "7999:   const int8* input1_data_ptr = input1_data;",
          "8000:   const int8* input2_data_reset = input2_data;",
          "8007:   int y0 = params.broadcast_shape[0];",
          "8008:   int y1 = params.broadcast_shape[1];",
          "8009:   int y2 = params.broadcast_shape[2];",
          "8010:   int y3 = params.broadcast_shape[3];",
          "8011:   int y4 = params.broadcast_shape[4];",
          "8012:   if (y4 > 1) {",
          "8015:     for (int i0 = 0; i0 < y0; ++i0) {",
          "8016:       const int8* input2_data_ptr = nullptr;",
          "8017:       for (int i1 = 0; i1 < y1; ++i1) {",
          "8018:         input2_data_ptr = input2_data_reset;",
          "8019:         for (int i2 = 0; i2 < y2; ++i2) {",
          "8020:           for (int i3 = 0; i3 < y3; ++i3) {",
          "8021:             MaximumElementwise(y4, params, input1_data_ptr, input2_data_ptr,",
          "8022:                                output_data_ptr);",
          "8023:             input2_data_ptr += y4;",
          "8024:             output_data_ptr += y4;",
          "8025:           }",
          "8027:           input1_data_ptr += y4;",
          "8028:         }",
          "8029:       }",
          "8031:       input2_data_reset = input2_data_ptr;",
          "8032:     }",
          "8033:   } else {",
          "8044:     for (int i0 = 0; i0 < y0; ++i0) {",
          "8045:       const int8* input2_data_ptr = nullptr;",
          "8046:       for (int i1 = 0; i1 < y1; ++i1) {",
          "8047:         input2_data_ptr = input2_data_reset;",
          "8048:         for (int i2 = 0; i2 < y2; ++i2) {",
          "8049:           MaximumScalarBroadcast(y3, params, *input1_data_ptr, input2_data_ptr,",
          "8050:                                  output_data_ptr);",
          "8051:           input2_data_ptr += y3;",
          "8052:           output_data_ptr += y3;",
          "8053:           input1_data_ptr += 1;",
          "8054:         }",
          "8055:       }",
          "8056:       input2_data_reset = input2_data_ptr;",
          "8057:     }",
          "8058:   }",
          "8059: }",
          "8062: template <typename Op>",
          "8063: inline void BroadcastMaximumDispatch(const ArithmeticParams& params,",
          "8064:                                      const RuntimeShape& input1_shape,",
          "8065:                                      const int8* input1_data,",
          "8066:                                      const RuntimeShape& input2_shape,",
          "8067:                                      const int8* input2_data,",
          "8068:                                      const RuntimeShape& output_shape,",
          "8069:                                      int8* output_data, Op op) {",
          "8070:   if (params.broadcast_category == BroadcastableOpCategory::kGenericBroadcast) {",
          "8071:     return reference_ops::MaximumMinimumBroadcastSlow(",
          "8072:         input1_shape, input1_data, input2_shape, input2_data, output_shape,",
          "8073:         output_data, op);",
          "8074:   }",
          "8076:   BroadcastMaximumFivefold(params, input1_shape, input1_data, input2_shape,",
          "8077:                            input2_data, output_shape, output_data);",
          "8078: }",
          "",
          "---------------"
        ],
        "tensorflow/lite/kernels/maximum_minimum.cc||tensorflow/lite/kernels/maximum_minimum.cc": [
          "File: tensorflow/lite/kernels/maximum_minimum.cc -> tensorflow/lite/kernels/maximum_minimum.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: #include \"tensorflow/lite/c/builtin_op_data.h\"",
          "20: #include \"tensorflow/lite/c/common.h\"",
          "21: #include \"tensorflow/lite/kernels/internal/reference/reference_ops.h\"",
          "22: #include \"tensorflow/lite/kernels/internal/tensor.h\"",
          "23: #include \"tensorflow/lite/kernels/kernel_util.h\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "21: #include \"tensorflow/lite/kernels/internal/optimized/optimized_ops.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "32: enum KernelType {",
          "33:   kReference,",
          "34: };",
          "36: constexpr int kInputTensor1 = 0;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "35:   kGenericOptimized,",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "85:   }",
          "86: };",
          "89: void TFLiteOperation(TfLiteContext* context, TfLiteNode* node,",
          "90:                      const OpContext& op_context) {",
          "91:   reference_ops::MaximumMinimumBroadcastSlow(",
          "",
          "[Removed Lines]",
          "88: template <typename data_type, typename op_type>",
          "",
          "[Added Lines]",
          "90: template <KernelType kernel_type, typename data_type, typename op_type>",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "98:       op_type::template op<data_type>);",
          "99: }",
          "101: template <KernelType kernel_type, typename OpType>",
          "102: TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {",
          "103:   OpContext op_context(context, node);",
          "106:     switch (op_context.output->type) {",
          "107:       case kTfLiteFloat32:",
          "109:         break;",
          "110:       case kTfLiteUInt8:",
          "112:         break;",
          "113:       case kTfLiteInt8:",
          "115:         break;",
          "116:       case kTfLiteInt32:",
          "118:         break;",
          "119:       case kTfLiteInt64:",
          "121:         break;",
          "122:       case kTfLiteInt16:",
          "124:         break;",
          "125:       default:",
          "126:         context->ReportError(context,",
          "",
          "[Removed Lines]",
          "105:   if (kernel_type == kReference) {",
          "108:         TFLiteOperation<float, OpType>(context, node, op_context);",
          "111:         TFLiteOperation<uint8_t, OpType>(context, node, op_context);",
          "114:         TFLiteOperation<int8_t, OpType>(context, node, op_context);",
          "117:         TFLiteOperation<int32_t, OpType>(context, node, op_context);",
          "120:         TFLiteOperation<int64_t, OpType>(context, node, op_context);",
          "123:         TFLiteOperation<int16_t, OpType>(context, node, op_context);",
          "",
          "[Added Lines]",
          "104: template <>",
          "105: void TFLiteOperation<maximum_minimum::kGenericOptimized, int8, MaximumOp>(",
          "106:     TfLiteContext* context, TfLiteNode* node, const OpContext& op_context) {",
          "107:   tflite::ArithmeticParams op_params;",
          "108:   const bool need_broadcast = optimized_ops::ProcessBroadcastShapes(",
          "109:       GetTensorShape(op_context.input1), GetTensorShape(op_context.input2),",
          "110:       &op_params);",
          "111:   if (need_broadcast) {",
          "112:     optimized_ops::BroadcastMaximumDispatch(",
          "113:         op_params, GetTensorShape(op_context.input1),",
          "114:         GetTensorData<int8>(op_context.input1),",
          "115:         GetTensorShape(op_context.input2),",
          "116:         GetTensorData<int8>(op_context.input2),",
          "117:         GetTensorShape(op_context.output),",
          "118:         GetTensorData<int8>(op_context.output), MaximumOp::template op<int8>);",
          "119:     return;",
          "120:   }",
          "121:   reference_ops::MaximumMinimumBroadcastSlow(",
          "122:       GetTensorShape(op_context.input1), GetTensorData<int8>(op_context.input1),",
          "123:       GetTensorShape(op_context.input2), GetTensorData<int8>(op_context.input2),",
          "124:       GetTensorShape(op_context.output), GetTensorData<int8>(op_context.output),",
          "125:       MaximumOp::template op<int8>);",
          "126: }",
          "134:         TFLiteOperation<kernel_type, float, OpType>(context, node, op_context);",
          "137:         TFLiteOperation<kernel_type, uint8_t, OpType>(context, node,",
          "138:                                                       op_context);",
          "141:         TFLiteOperation<kernel_type, int8_t, OpType>(context, node, op_context);",
          "144:         TFLiteOperation<kernel_type, int32_t, OpType>(context, node,",
          "145:                                                       op_context);",
          "148:         TFLiteOperation<kernel_type, int64_t, OpType>(context, node,",
          "149:                                                       op_context);",
          "152:         TFLiteOperation<kernel_type, int16_t, OpType>(context, node,",
          "153:                                                       op_context);",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "128:                              op_context.output->type);",
          "129:         return kTfLiteError;",
          "130:     }",
          "137:   return kTfLiteOk;",
          "138: }",
          "",
          "[Removed Lines]",
          "131:   } else {",
          "132:     context->ReportError(context,",
          "133:                          \"Type %d is currently not supported by Maximum.\",",
          "134:                          op_context.output->type);",
          "135:     return kTfLiteError;",
          "136:   }",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "147:   return &r;",
          "148: }",
          "150: TfLiteRegistration* Register_MINIMUM_REF() {",
          "151:   static TfLiteRegistration r = {",
          "152:       nullptr, nullptr, maximum_minimum::Prepare,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "174: TfLiteRegistration* Register_MAXIMUM_GENERIC_OPT() {",
          "175:   static TfLiteRegistration r = {",
          "176:       nullptr, nullptr, maximum_minimum::Prepare,",
          "177:       maximum_minimum::Eval<maximum_minimum::kGenericOptimized,",
          "178:                             maximum_minimum::MaximumOp>};",
          "179:   return &r;",
          "180: }",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "154:                             maximum_minimum::MinimumOp>};",
          "155:   return &r;",
          "156: }",
          "158: TfLiteRegistration* Register_MINIMUM() { return Register_MINIMUM_REF(); }",
          "160: }  // namespace builtin",
          "",
          "[Removed Lines]",
          "157: TfLiteRegistration* Register_MAXIMUM() { return Register_MAXIMUM_REF(); }",
          "",
          "[Added Lines]",
          "189: TfLiteRegistration* Register_MAXIMUM() {",
          "190:   return Register_MAXIMUM_GENERIC_OPT();",
          "191: }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "2d53bd19504531374b560fbfc4eceb7815dc1b05",
      "candidate_info": {
        "commit_hash": "2d53bd19504531374b560fbfc4eceb7815dc1b05",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/2d53bd19504531374b560fbfc4eceb7815dc1b05",
        "files": [
          "tensorflow/lite/kernels/maximum_minimum.cc"
        ],
        "message": "[CherryPick]: Prevent a null pointer exception in TFLite",
        "before_after_code_files": [
          "tensorflow/lite/kernels/maximum_minimum.cc||tensorflow/lite/kernels/maximum_minimum.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/lite/kernels/maximum_minimum.cc||tensorflow/lite/kernels/maximum_minimum.cc"
          ],
          "candidate": [
            "tensorflow/lite/kernels/maximum_minimum.cc||tensorflow/lite/kernels/maximum_minimum.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/lite/kernels/maximum_minimum.cc||tensorflow/lite/kernels/maximum_minimum.cc": [
          "File: tensorflow/lite/kernels/maximum_minimum.cc -> tensorflow/lite/kernels/maximum_minimum.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "100: TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {",
          "101:   OpContext op_context(context, node);",
          "131:   }",
          "132:   return kTfLiteOk;",
          "133: }",
          "",
          "[Removed Lines]",
          "103:   if (kernel_type == kReference) {",
          "104:     switch (op_context.output->type) {",
          "105:       case kTfLiteFloat32:",
          "106:         TFLiteOperation<float, OpType>(context, node, op_context);",
          "107:         break;",
          "108:       case kTfLiteUInt8:",
          "109:         TFLiteOperation<uint8_t, OpType>(context, node, op_context);",
          "110:         break;",
          "111:       case kTfLiteInt8:",
          "112:         TFLiteOperation<int8_t, OpType>(context, node, op_context);",
          "113:         break;",
          "114:       case kTfLiteInt32:",
          "115:         TFLiteOperation<int32_t, OpType>(context, node, op_context);",
          "116:         break;",
          "117:       case kTfLiteInt64:",
          "118:         TFLiteOperation<int64_t, OpType>(context, node, op_context);",
          "119:         break;",
          "120:       default:",
          "121:         context->ReportError(context,",
          "122:                              \"Type %d is currently not supported by Maximum.\",",
          "123:                              op_context.output->type);",
          "124:         return kTfLiteError;",
          "125:     }",
          "126:   } else {",
          "127:     context->ReportError(context,",
          "128:                          \"Type %d is currently not supported by Maximum.\",",
          "129:                          op_context.output->type);",
          "130:     return kTfLiteError;",
          "",
          "[Added Lines]",
          "104:   if (NumElements(op_context.input1) == 0 ||",
          "105:       NumElements(op_context.input2) == 0) {",
          "106:     return kTfLiteOk;",
          "107:   }",
          "109:   switch (op_context.output->type) {",
          "110:     case kTfLiteFloat32:",
          "111:       TFLiteOperation<kernel_type, float, OpType>(context, node, op_context);",
          "112:       break;",
          "113:     case kTfLiteUInt8:",
          "114:       TFLiteOperation<kernel_type, uint8_t, OpType>(context, node, op_context);",
          "115:       break;",
          "116:     case kTfLiteInt8:",
          "117:       TFLiteOperation<kernel_type, int8_t, OpType>(context, node, op_context);",
          "118:       break;",
          "119:     case kTfLiteInt32:",
          "120:       TFLiteOperation<kernel_type, int32_t, OpType>(context, node, op_context);",
          "121:       break;",
          "122:     case kTfLiteInt64:",
          "123:       TFLiteOperation<kernel_type, int64_t, OpType>(context, node, op_context);",
          "124:       break;",
          "125:     case kTfLiteInt16:",
          "126:       TFLiteOperation<kernel_type, int16_t, OpType>(context, node, op_context);",
          "127:       break;",
          "128:     default:",
          "129:       context->ReportError(context,",
          "130:                            \"Type %d is currently not supported by Maximum.\",",
          "131:                            op_context.output->type);",
          "132:       return kTfLiteError;",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "ac278dae2fd1f86493e0b514695e419918c1af4d",
      "candidate_info": {
        "commit_hash": "ac278dae2fd1f86493e0b514695e419918c1af4d",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/ac278dae2fd1f86493e0b514695e419918c1af4d",
        "files": [
          "tensorflow/lite/kernels/maximum_minimum.cc"
        ],
        "message": "[CherryPick]: Prevent a null pointer exception in TFLite",
        "before_after_code_files": [
          "tensorflow/lite/kernels/maximum_minimum.cc||tensorflow/lite/kernels/maximum_minimum.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/lite/kernels/maximum_minimum.cc||tensorflow/lite/kernels/maximum_minimum.cc"
          ],
          "candidate": [
            "tensorflow/lite/kernels/maximum_minimum.cc||tensorflow/lite/kernels/maximum_minimum.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/lite/kernels/maximum_minimum.cc||tensorflow/lite/kernels/maximum_minimum.cc": [
          "File: tensorflow/lite/kernels/maximum_minimum.cc -> tensorflow/lite/kernels/maximum_minimum.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "102: TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {",
          "103:   OpContext op_context(context, node);",
          "133:   }",
          "134:   return kTfLiteOk;",
          "135: }",
          "",
          "[Removed Lines]",
          "105:   if (kernel_type == kReference) {",
          "106:     switch (op_context.output->type) {",
          "107:       case kTfLiteFloat32:",
          "108:         TFLiteOperation<float, OpType>(context, node, op_context);",
          "109:         break;",
          "110:       case kTfLiteUInt8:",
          "111:         TFLiteOperation<uint8_t, OpType>(context, node, op_context);",
          "112:         break;",
          "113:       case kTfLiteInt8:",
          "114:         TFLiteOperation<int8_t, OpType>(context, node, op_context);",
          "115:         break;",
          "116:       case kTfLiteInt32:",
          "117:         TFLiteOperation<int32_t, OpType>(context, node, op_context);",
          "118:         break;",
          "119:       case kTfLiteInt64:",
          "120:         TFLiteOperation<int64_t, OpType>(context, node, op_context);",
          "121:         break;",
          "122:       default:",
          "123:         context->ReportError(context,",
          "124:                              \"Type %d is currently not supported by Maximum.\",",
          "125:                              op_context.output->type);",
          "126:         return kTfLiteError;",
          "127:     }",
          "128:   } else {",
          "129:     context->ReportError(context,",
          "130:                          \"Type %d is currently not supported by Maximum.\",",
          "131:                          op_context.output->type);",
          "132:     return kTfLiteError;",
          "",
          "[Added Lines]",
          "106:   if (NumElements(op_context.input1) == 0 ||",
          "107:       NumElements(op_context.input2) == 0) {",
          "108:     return kTfLiteOk;",
          "109:   }",
          "111:   switch (op_context.output->type) {",
          "112:     case kTfLiteFloat32:",
          "113:       TFLiteOperation<kernel_type, float, OpType>(context, node, op_context);",
          "114:       break;",
          "115:     case kTfLiteUInt8:",
          "116:       TFLiteOperation<kernel_type, uint8_t, OpType>(context, node, op_context);",
          "117:       break;",
          "118:     case kTfLiteInt8:",
          "119:       TFLiteOperation<kernel_type, int8_t, OpType>(context, node, op_context);",
          "120:       break;",
          "121:     case kTfLiteInt32:",
          "122:       TFLiteOperation<kernel_type, int32_t, OpType>(context, node, op_context);",
          "123:       break;",
          "124:     case kTfLiteInt64:",
          "125:       TFLiteOperation<kernel_type, int64_t, OpType>(context, node, op_context);",
          "126:       break;",
          "127:     case kTfLiteInt16:",
          "128:       TFLiteOperation<kernel_type, int16_t, OpType>(context, node, op_context);",
          "129:       break;",
          "130:     default:",
          "131:       context->ReportError(context,",
          "132:                            \"Type %d is currently not supported by Maximum.\",",
          "133:                            op_context.output->type);",
          "134:       return kTfLiteError;",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "a3619eff1db3f3bcc11497040b37ed70a23f896e",
      "candidate_info": {
        "commit_hash": "a3619eff1db3f3bcc11497040b37ed70a23f896e",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/a3619eff1db3f3bcc11497040b37ed70a23f896e",
        "files": [
          "tensorflow/lite/kernels/maximum_minimum.cc"
        ],
        "message": "Prevent a null pointer exception in TFLite\n\nPiperOrigin-RevId: 370800206\nChange-Id: Idd437ebce4ff224120d8eefc1c14c062173b71d6",
        "before_after_code_files": [
          "tensorflow/lite/kernels/maximum_minimum.cc||tensorflow/lite/kernels/maximum_minimum.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/lite/kernels/maximum_minimum.cc||tensorflow/lite/kernels/maximum_minimum.cc"
          ],
          "candidate": [
            "tensorflow/lite/kernels/maximum_minimum.cc||tensorflow/lite/kernels/maximum_minimum.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/lite/kernels/maximum_minimum.cc||tensorflow/lite/kernels/maximum_minimum.cc": [
          "File: tensorflow/lite/kernels/maximum_minimum.cc -> tensorflow/lite/kernels/maximum_minimum.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "157: TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {",
          "158:   OpContext op_context(context, node);",
          "189:   return kTfLiteOk;",
          "190: }",
          "",
          "[Removed Lines]",
          "160:     switch (op_context.output->type) {",
          "161:       case kTfLiteFloat32:",
          "162:         TFLiteOperation<kernel_type, float, OpType>(context, node, op_context);",
          "163:         break;",
          "164:       case kTfLiteUInt8:",
          "165:         TFLiteOperation<kernel_type, uint8_t, OpType>(context, node,",
          "166:                                                       op_context);",
          "167:         break;",
          "168:       case kTfLiteInt8:",
          "169:         TFLiteOperation<kernel_type, int8_t, OpType>(context, node, op_context);",
          "170:         break;",
          "171:       case kTfLiteInt32:",
          "172:         TFLiteOperation<kernel_type, int32_t, OpType>(context, node,",
          "173:                                                       op_context);",
          "174:         break;",
          "175:       case kTfLiteInt64:",
          "176:         TFLiteOperation<kernel_type, int64_t, OpType>(context, node,",
          "177:                                                       op_context);",
          "178:         break;",
          "179:       case kTfLiteInt16:",
          "180:         TFLiteOperation<kernel_type, int16_t, OpType>(context, node,",
          "181:                                                       op_context);",
          "182:         break;",
          "183:       default:",
          "184:         context->ReportError(context,",
          "185:                              \"Type %d is currently not supported by Maximum.\",",
          "186:                              op_context.output->type);",
          "187:         return kTfLiteError;",
          "188:     }",
          "",
          "[Added Lines]",
          "161:   if (NumElements(op_context.input1) == 0 ||",
          "162:       NumElements(op_context.input2) == 0) {",
          "163:     return kTfLiteOk;",
          "164:   }",
          "166:   switch (op_context.output->type) {",
          "167:     case kTfLiteFloat32:",
          "168:       TFLiteOperation<kernel_type, float, OpType>(context, node, op_context);",
          "169:       break;",
          "170:     case kTfLiteUInt8:",
          "171:       TFLiteOperation<kernel_type, uint8_t, OpType>(context, node, op_context);",
          "172:       break;",
          "173:     case kTfLiteInt8:",
          "174:       TFLiteOperation<kernel_type, int8_t, OpType>(context, node, op_context);",
          "175:       break;",
          "176:     case kTfLiteInt32:",
          "177:       TFLiteOperation<kernel_type, int32_t, OpType>(context, node, op_context);",
          "178:       break;",
          "179:     case kTfLiteInt64:",
          "180:       TFLiteOperation<kernel_type, int64_t, OpType>(context, node, op_context);",
          "181:       break;",
          "182:     case kTfLiteInt16:",
          "183:       TFLiteOperation<kernel_type, int16_t, OpType>(context, node, op_context);",
          "184:       break;",
          "185:     default:",
          "186:       context->ReportError(context,",
          "187:                            \"Type %d is currently not supported by Maximum.\",",
          "188:                            op_context.output->type);",
          "189:       return kTfLiteError;",
          "190:   }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "1eced2847f9e6fc1b42370411bed6178e09c3141",
      "candidate_info": {
        "commit_hash": "1eced2847f9e6fc1b42370411bed6178e09c3141",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/1eced2847f9e6fc1b42370411bed6178e09c3141",
        "files": [
          "tensorflow/lite/kernels/maximum_minimum.cc"
        ],
        "message": "Prevent a null pointer exception in TFLite\n\nPiperOrigin-RevId: 370800206\nChange-Id: Idd437ebce4ff224120d8eefc1c14c062173b71d6",
        "before_after_code_files": [
          "tensorflow/lite/kernels/maximum_minimum.cc||tensorflow/lite/kernels/maximum_minimum.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/lite/kernels/maximum_minimum.cc||tensorflow/lite/kernels/maximum_minimum.cc"
          ],
          "candidate": [
            "tensorflow/lite/kernels/maximum_minimum.cc||tensorflow/lite/kernels/maximum_minimum.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/lite/kernels/maximum_minimum.cc||tensorflow/lite/kernels/maximum_minimum.cc": [
          "File: tensorflow/lite/kernels/maximum_minimum.cc -> tensorflow/lite/kernels/maximum_minimum.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "157: TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {",
          "158:   OpContext op_context(context, node);",
          "189:   return kTfLiteOk;",
          "190: }",
          "",
          "[Removed Lines]",
          "160:     switch (op_context.output->type) {",
          "161:       case kTfLiteFloat32:",
          "162:         TFLiteOperation<kernel_type, float, OpType>(context, node, op_context);",
          "163:         break;",
          "164:       case kTfLiteUInt8:",
          "165:         TFLiteOperation<kernel_type, uint8_t, OpType>(context, node,",
          "166:                                                       op_context);",
          "167:         break;",
          "168:       case kTfLiteInt8:",
          "169:         TFLiteOperation<kernel_type, int8_t, OpType>(context, node, op_context);",
          "170:         break;",
          "171:       case kTfLiteInt32:",
          "172:         TFLiteOperation<kernel_type, int32_t, OpType>(context, node,",
          "173:                                                       op_context);",
          "174:         break;",
          "175:       case kTfLiteInt64:",
          "176:         TFLiteOperation<kernel_type, int64_t, OpType>(context, node,",
          "177:                                                       op_context);",
          "178:         break;",
          "179:       case kTfLiteInt16:",
          "180:         TFLiteOperation<kernel_type, int16_t, OpType>(context, node,",
          "181:                                                       op_context);",
          "182:         break;",
          "183:       default:",
          "184:         context->ReportError(context,",
          "185:                              \"Type %d is currently not supported by Maximum.\",",
          "186:                              op_context.output->type);",
          "187:         return kTfLiteError;",
          "188:     }",
          "",
          "[Added Lines]",
          "161:   if (NumElements(op_context.input1) == 0 ||",
          "162:       NumElements(op_context.input2) == 0) {",
          "163:     return kTfLiteOk;",
          "164:   }",
          "166:   switch (op_context.output->type) {",
          "167:     case kTfLiteFloat32:",
          "168:       TFLiteOperation<kernel_type, float, OpType>(context, node, op_context);",
          "169:       break;",
          "170:     case kTfLiteUInt8:",
          "171:       TFLiteOperation<kernel_type, uint8_t, OpType>(context, node, op_context);",
          "172:       break;",
          "173:     case kTfLiteInt8:",
          "174:       TFLiteOperation<kernel_type, int8_t, OpType>(context, node, op_context);",
          "175:       break;",
          "176:     case kTfLiteInt32:",
          "177:       TFLiteOperation<kernel_type, int32_t, OpType>(context, node, op_context);",
          "178:       break;",
          "179:     case kTfLiteInt64:",
          "180:       TFLiteOperation<kernel_type, int64_t, OpType>(context, node, op_context);",
          "181:       break;",
          "182:     case kTfLiteInt16:",
          "183:       TFLiteOperation<kernel_type, int16_t, OpType>(context, node, op_context);",
          "184:       break;",
          "185:     default:",
          "186:       context->ReportError(context,",
          "187:                            \"Type %d is currently not supported by Maximum.\",",
          "188:                            op_context.output->type);",
          "189:       return kTfLiteError;",
          "190:   }",
          "",
          "---------------"
        ]
      }
    }
  ]
}