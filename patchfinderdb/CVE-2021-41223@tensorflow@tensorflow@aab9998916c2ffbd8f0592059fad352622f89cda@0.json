{
  "cve_id": "CVE-2021-41223",
  "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions the implementation of `FusedBatchNorm` kernels is vulnerable to a heap OOB access. The fix will be included in TensorFlow 2.7.0. We will also cherrypick this commit on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
  "repo": "tensorflow/tensorflow",
  "patch_hash": "aab9998916c2ffbd8f0592059fad352622f89cda",
  "patch_info": {
    "commit_hash": "aab9998916c2ffbd8f0592059fad352622f89cda",
    "repo": "tensorflow/tensorflow",
    "commit_url": "https://github.com/tensorflow/tensorflow/commit/aab9998916c2ffbd8f0592059fad352622f89cda",
    "files": [
      "tensorflow/core/kernels/fused_batch_norm_op.cc",
      "tensorflow/python/ops/nn_fused_batchnorm_test.py"
    ],
    "message": "Add shape checks to FusedBatchNorm kernels.\n\nPiperOrigin-RevId: 399755576\nChange-Id: If8049fde109cc33badb5509d174b9b95aee1ea5e",
    "before_after_code_files": [
      "tensorflow/core/kernels/fused_batch_norm_op.cc||tensorflow/core/kernels/fused_batch_norm_op.cc",
      "tensorflow/python/ops/nn_fused_batchnorm_test.py||tensorflow/python/ops/nn_fused_batchnorm_test.py"
    ]
  },
  "patch_diff": {
    "tensorflow/core/kernels/fused_batch_norm_op.cc||tensorflow/core/kernels/fused_batch_norm_op.cc": [
      "File: tensorflow/core/kernels/fused_batch_norm_op.cc -> tensorflow/core/kernels/fused_batch_norm_op.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "1340:         errors::InvalidArgument(\"offset must have the same number of elements \"",
      "1341:                                 \"as the channels of x, got \",",
      "1342:                                 offset.NumElements(), \" and \", num_channels));",
      "1344:       OP_REQUIRES(context, estimated_mean.NumElements() == num_channels,",
      "1345:                   errors::InvalidArgument(",
      "1348:                       estimated_mean.NumElements(), \" and \", num_channels));",
      "1351:       OP_REQUIRES(context, estimated_variance.NumElements() == num_channels,",
      "1352:                   errors::InvalidArgument(",
      "1355:                       estimated_variance.NumElements(), \" and \", num_channels));",
      "1356:     }",
      "",
      "[Removed Lines]",
      "1343:     if (estimated_mean.NumElements() != 0) {",
      "1346:                       \"mean must be empty or have the same number of \"",
      "1347:                       \"elements as the channels of x, got \",",
      "1349:     }",
      "1350:     if (estimated_variance.NumElements() != 0) {",
      "1353:                       \"variance must be empty or have the same number of \"",
      "1354:                       \"elements as the channels of x, got \",",
      "",
      "[Added Lines]",
      "1343:     if (!is_training_ || exponential_avg_factor_ != 1.) {",
      "1344:       std::string prefix_msg = is_training_ ? \"When exponential_avg_factor != 1\"",
      "1345:                                             : \"When is_training=false\";",
      "1348:                       prefix_msg,",
      "1349:                       \", mean must have the same number \"",
      "1350:                       \"of elements as the channels of x, got \",",
      "1354:                       prefix_msg,",
      "1355:                       \", variance must have the same \"",
      "1356:                       \"number of elements as the channels of x, got \",",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "1543:                 errors::InvalidArgument(",
      "1544:                     \"saved variance must be 1-dimensional\",",
      "1545:                     saved_maybe_inv_var_or_pop_var.shape().DebugString()));",
      "1546:     if (use_activation) {",
      "1547:       OP_REQUIRES(",
      "1548:           context, x.dim_size(3) % 4 == 0,",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "1548:     OP_REQUIRES(",
      "1549:         context, x.shape() == y_backprop.shape(),",
      "1550:         errors::InvalidArgument(",
      "1551:             \"x and y_backprop must have same shape, but x has shape \",",
      "1552:             x.shape(), \" and y_backprop has shape \", y_backprop.shape()));",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "1569:                   errors::InvalidArgument(\"Error during tensor copy.\"));",
      "1570:     }",
      "1572:     Tensor* x_backprop = nullptr;",
      "1573:     auto alloc_shape = use_reshape ? dest_shape : x_shape;",
      "1574:     OP_REQUIRES_OK(context,",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "1579:     const auto num_channels = GetTensorDim(x, tensor_format_, 'C');",
      "1580:     OP_REQUIRES(",
      "1581:         context, scale.NumElements() == num_channels,",
      "1582:         errors::InvalidArgument(\"scale must have the same number of elements \"",
      "1583:                                 \"as the channels of x, got \",",
      "1584:                                 scale.NumElements(), \" and \", num_channels));",
      "1585:     OP_REQUIRES(",
      "1586:         context, saved_mean_or_pop_mean.NumElements() == num_channels,",
      "1587:         errors::InvalidArgument(\"reserve_space_1 must have the same number of \"",
      "1588:                                 \"elements as the channels of x, got \",",
      "1589:                                 scale.NumElements(), \" and \", num_channels));",
      "1590:     OP_REQUIRES(",
      "1591:         context, saved_maybe_inv_var_or_pop_var.NumElements() == num_channels,",
      "1592:         errors::InvalidArgument(\"reserve_space_2 must have the same number of \"",
      "1593:                                 \"elements as the channels of x, got \",",
      "1594:                                 scale.NumElements(), \" and \", num_channels));",
      "",
      "---------------"
    ],
    "tensorflow/python/ops/nn_fused_batchnorm_test.py||tensorflow/python/ops/nn_fused_batchnorm_test.py": [
      "File: tensorflow/python/ops/nn_fused_batchnorm_test.py -> tensorflow/python/ops/nn_fused_batchnorm_test.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "17: import numpy as np",
      "19: from tensorflow.python.framework import constant_op",
      "20: from tensorflow.python.framework import dtypes",
      "21: from tensorflow.python.framework import test_util",
      "22: from tensorflow.python.ops import array_ops",
      "23: from tensorflow.python.ops import gradient_checker",
      "24: from tensorflow.python.ops import gradients_impl",
      "25: from tensorflow.python.ops import math_ops",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "19: from tensorflow.python.eager import context",
      "22: from tensorflow.python.framework import errors_impl",
      "25: from tensorflow.python.ops import gen_nn_ops",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "694:     y_ref = np.maximum(y_ref, 0.)",
      "695:     self.assertAllClose(y_ref, y_val, atol=1e-3)",
      "698: if __name__ == '__main__':",
      "699:   test.main()",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "700:   def testEagerShapeErrors(self):",
      "701:     with context.eager_mode():",
      "702:       x = array_ops.ones((2, 2, 2, 2))",
      "703:       scale = array_ops.ones((3,))",
      "704:       offset = array_ops.ones((2,))",
      "705:       with self.assertRaisesRegex(",
      "706:           errors_impl.InvalidArgumentError,",
      "707:           'scale must have the same number of elements'):",
      "708:         nn_impl.fused_batch_norm(x, scale, offset)",
      "710:       x = array_ops.ones((2, 2, 2, 2))",
      "711:       scale = array_ops.ones((2,))",
      "712:       offset = array_ops.ones((3,))",
      "713:       with self.assertRaisesRegex(",
      "714:           errors_impl.InvalidArgumentError,",
      "715:           'offset must have the same number of elements'):",
      "716:         nn_impl.fused_batch_norm(x, scale, offset)",
      "718:       x = array_ops.ones((2, 2, 2, 2))",
      "719:       scale = array_ops.ones((2,))",
      "720:       offset = array_ops.ones((2,))",
      "721:       mean = array_ops.ones((0,))",
      "722:       variance = array_ops.ones((2,))",
      "723:       with self.assertRaisesRegex(",
      "724:           errors_impl.InvalidArgumentError,",
      "725:           'When is_training=false, mean must have the same number of elements'):",
      "726:         nn_impl.fused_batch_norm(",
      "727:             x, scale, offset, mean=mean, variance=variance, is_training=False)",
      "729:       x = array_ops.ones((2, 2, 2, 2))",
      "730:       scale = array_ops.ones((2,))",
      "731:       offset = array_ops.ones((2,))",
      "732:       mean = array_ops.ones((2,))",
      "733:       variance = array_ops.ones((0,))",
      "734:       with self.assertRaisesRegex(",
      "735:           errors_impl.InvalidArgumentError,",
      "736:           'When is_training=false, variance must have the same number of '",
      "737:           'elements'):",
      "738:         nn_impl.fused_batch_norm(",
      "739:             x, scale, offset, mean=mean, variance=variance, is_training=False)",
      "741:       x = array_ops.ones((2, 2, 2, 2))",
      "742:       scale = array_ops.ones((2,))",
      "743:       offset = array_ops.ones((2,))",
      "744:       mean = array_ops.ones((0,))",
      "745:       variance = array_ops.ones((2,))",
      "746:       with self.assertRaisesRegex(",
      "747:           errors_impl.InvalidArgumentError,",
      "748:           'When exponential_avg_factor != 1, mean must have the same number of '",
      "749:           'elements'):",
      "750:         nn_impl.fused_batch_norm(",
      "751:             x,",
      "752:             scale,",
      "753:             offset,",
      "754:             mean=mean,",
      "755:             variance=variance,",
      "756:             exponential_avg_factor=0.5)",
      "758:       x = array_ops.ones((2, 2, 2, 2))",
      "759:       scale = array_ops.ones((2,))",
      "760:       offset = array_ops.ones((2,))",
      "761:       mean = array_ops.ones((2,))",
      "762:       variance = array_ops.ones((0,))",
      "763:       with self.assertRaisesRegex(",
      "764:           errors_impl.InvalidArgumentError,",
      "765:           'When exponential_avg_factor != 1, variance must have the same '",
      "766:           'number of elements'):",
      "767:         nn_impl.fused_batch_norm(",
      "768:             x,",
      "769:             scale,",
      "770:             offset,",
      "771:             mean=mean,",
      "772:             variance=variance,",
      "773:             exponential_avg_factor=0.5)",
      "775:   def testEagerShapeGradErrors(self):",
      "776:     with context.eager_mode():",
      "777:       y_backprop = array_ops.ones((2, 2, 2, 3))",
      "778:       x = array_ops.ones((2, 2, 2, 2))",
      "779:       scale = array_ops.ones((2,))",
      "780:       reserve_space_1 = array_ops.ones((2,))",
      "781:       reserve_space_2 = array_ops.ones((2,))",
      "782:       with self.assertRaisesRegex(errors_impl.InvalidArgumentError,",
      "783:                                   'x and y_backprop must have same shape,'):",
      "784:         gen_nn_ops.fused_batch_norm_grad_v2(y_backprop, x, scale,",
      "785:                                             reserve_space_1, reserve_space_2)",
      "787:       y_backprop = array_ops.ones((2, 2, 2, 2))",
      "788:       x = array_ops.ones((2, 2, 2, 2))",
      "789:       scale = array_ops.ones((3,))",
      "790:       reserve_space_1 = array_ops.ones((2,))",
      "791:       reserve_space_2 = array_ops.ones((2,))",
      "792:       with self.assertRaisesRegex(",
      "793:           errors_impl.InvalidArgumentError,",
      "794:           'scale must have the same number of elements'):",
      "795:         gen_nn_ops.fused_batch_norm_grad_v2(y_backprop, x, scale,",
      "796:                                             reserve_space_1, reserve_space_2)",
      "798:       y_backprop = array_ops.ones((2, 2, 2, 2))",
      "799:       x = array_ops.ones((2, 2, 2, 2))",
      "800:       scale = array_ops.ones((2,))",
      "801:       reserve_space_1 = array_ops.ones((3,))",
      "802:       reserve_space_2 = array_ops.ones((2,))",
      "803:       with self.assertRaisesRegex(",
      "804:           errors_impl.InvalidArgumentError,",
      "805:           'reserve_space_1 must have the same number of elements'):",
      "806:         gen_nn_ops.fused_batch_norm_grad_v2(y_backprop, x, scale,",
      "807:                                             reserve_space_1, reserve_space_2)",
      "809:       y_backprop = array_ops.ones((2, 2, 2, 2))",
      "810:       x = array_ops.ones((2, 2, 2, 2))",
      "811:       scale = array_ops.ones((2,))",
      "812:       reserve_space_1 = array_ops.ones((2,))",
      "813:       reserve_space_2 = array_ops.ones((3,))",
      "814:       with self.assertRaisesRegex(",
      "815:           errors_impl.InvalidArgumentError,",
      "816:           'reserve_space_2 must have the same number of elements'):",
      "817:         gen_nn_ops.fused_batch_norm_grad_v2(y_backprop, x, scale,",
      "818:                                             reserve_space_1, reserve_space_2)",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "d7ea6945dd4d75d967ecdf7b88c2a24f981c5b9e",
      "candidate_info": {
        "commit_hash": "d7ea6945dd4d75d967ecdf7b88c2a24f981c5b9e",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/d7ea6945dd4d75d967ecdf7b88c2a24f981c5b9e",
        "files": [
          "tensorflow/core/kernels/fused_batch_norm_op.cc"
        ],
        "message": "Fix a typo",
        "before_after_code_files": [
          "tensorflow/core/kernels/fused_batch_norm_op.cc||tensorflow/core/kernels/fused_batch_norm_op.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/fused_batch_norm_op.cc||tensorflow/core/kernels/fused_batch_norm_op.cc"
          ],
          "candidate": [
            "tensorflow/core/kernels/fused_batch_norm_op.cc||tensorflow/core/kernels/fused_batch_norm_op.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/fused_batch_norm_op.cc||tensorflow/core/kernels/fused_batch_norm_op.cc": [
          "File: tensorflow/core/kernels/fused_batch_norm_op.cc -> tensorflow/core/kernels/fused_batch_norm_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "1586:         context, saved_mean_or_pop_mean.NumElements() == num_channels,",
          "1587:         errors::InvalidArgument(\"reserve_space_1 must have the same number of \"",
          "1588:                                 \"elements as the channels of x, got \",",
          "1590:     OP_REQUIRES(",
          "1591:         context, saved_maybe_inv_var_or_pop_var.NumElements() == num_channels,",
          "1592:         errors::InvalidArgument(\"reserve_space_2 must have the same number of \"",
          "1593:                                 \"elements as the channels of x, got \",",
          "1596:     Tensor* x_backprop = nullptr;",
          "1597:     auto alloc_shape = use_reshape ? dest_shape : x_shape;",
          "",
          "[Removed Lines]",
          "1589:                                 scale.NumElements(), \" and \", num_channels));",
          "1594:                                 scale.NumElements(), \" and \", num_channels));",
          "",
          "[Added Lines]",
          "1589:                                 saved_mean_or_pop_mean.NumElements(), \" and \",",
          "1590:                                 num_channels));",
          "1595:                                 saved_maybe_inv_var_or_pop_var.NumElements(),",
          "1596:                                 \" and \", num_channels));",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "6972f9dfe325636b3db4e0bc517ee22a159365c0",
      "candidate_info": {
        "commit_hash": "6972f9dfe325636b3db4e0bc517ee22a159365c0",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/6972f9dfe325636b3db4e0bc517ee22a159365c0",
        "files": [
          "tensorflow/core/kernels/fused_batch_norm_op.cc"
        ],
        "message": "Add missing valuidation to FusedBatchNorm.\n\nPiperOrigin-RevId: 372460336\nChange-Id: Ic8c4e4de67c58a741bd87f2e182bed07247d1126",
        "before_after_code_files": [
          "tensorflow/core/kernels/fused_batch_norm_op.cc||tensorflow/core/kernels/fused_batch_norm_op.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/fused_batch_norm_op.cc||tensorflow/core/kernels/fused_batch_norm_op.cc"
          ],
          "candidate": [
            "tensorflow/core/kernels/fused_batch_norm_op.cc||tensorflow/core/kernels/fused_batch_norm_op.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/fused_batch_norm_op.cc||tensorflow/core/kernels/fused_batch_norm_op.cc": [
          "File: tensorflow/core/kernels/fused_batch_norm_op.cc -> tensorflow/core/kernels/fused_batch_norm_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "1282:                   errors::InvalidArgument(\"Error during tensor copy.\"));",
          "1283:     }",
          "1285:     if (has_side_input_) {",
          "1286:       OP_REQUIRES(context, side_input->shape() == x.shape(),",
          "1287:                   errors::InvalidArgument(",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1285:     const auto num_channels = GetTensorDim(x, tensor_format_, 'C');",
          "1286:     OP_REQUIRES(",
          "1287:         context, scale.NumElements() == num_channels,",
          "1288:         errors::InvalidArgument(\"scale must have the same number of elements \"",
          "1289:                                 \"as the channels of x, got \",",
          "1290:                                 scale.NumElements(), \" and \", num_channels));",
          "1291:     OP_REQUIRES(",
          "1292:         context, offset.NumElements() == num_channels,",
          "1293:         errors::InvalidArgument(\"offset must have the same number of elements \"",
          "1294:                                 \"as the channels of x, got \",",
          "1295:                                 offset.NumElements(), \" and \", num_channels));",
          "1296:     if (estimated_mean.NumElements() != 0) {",
          "1297:       OP_REQUIRES(context, estimated_mean.NumElements() == num_channels,",
          "1298:                   errors::InvalidArgument(",
          "1299:                       \"mean must be empty or have the same number of \"",
          "1300:                       \"elements as the channels of x, got \",",
          "1301:                       estimated_mean.NumElements(), \" and \", num_channels));",
          "1302:     }",
          "1303:     if (estimated_variance.NumElements() != 0) {",
          "1304:       OP_REQUIRES(context, estimated_variance.NumElements() == num_channels,",
          "1305:                   errors::InvalidArgument(",
          "1306:                       \"variance must be empty or have the same number of \"",
          "1307:                       \"elements as the channels of x, got \",",
          "1308:                       estimated_variance.NumElements(), \" and \", num_channels));",
          "1309:     }",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1296:       OP_REQUIRES(",
          "1298:           errors::InvalidArgument(\"FusedBatchNorm with activation requires \"",
          "1299:                                   \"channel dimension to be a multiple of 4.\"));",
          "1300:     }",
          "",
          "[Removed Lines]",
          "1297:           context, !is_training_ || x.dim_size(3) % 4 == 0,",
          "",
          "[Added Lines]",
          "1323:           context, !is_training_ || num_channels % 4 == 0,",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "4b860121c234f3b918d53d0a9b49bfa9504d97db",
      "candidate_info": {
        "commit_hash": "4b860121c234f3b918d53d0a9b49bfa9504d97db",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/4b860121c234f3b918d53d0a9b49bfa9504d97db",
        "files": [
          "tensorflow/core/kernels/fused_batch_norm_op.cc",
          "tensorflow/python/ops/nn_fused_batchnorm_test.py"
        ],
        "message": "Add shape checks to FusedBatchNorm kernels.\n\nPiperOrigin-RevId: 399755576\nChange-Id: If8049fde109cc33badb5509d174b9b95aee1ea5e",
        "before_after_code_files": [
          "tensorflow/core/kernels/fused_batch_norm_op.cc||tensorflow/core/kernels/fused_batch_norm_op.cc",
          "tensorflow/python/ops/nn_fused_batchnorm_test.py||tensorflow/python/ops/nn_fused_batchnorm_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/fused_batch_norm_op.cc||tensorflow/core/kernels/fused_batch_norm_op.cc",
            "tensorflow/python/ops/nn_fused_batchnorm_test.py||tensorflow/python/ops/nn_fused_batchnorm_test.py"
          ],
          "candidate": [
            "tensorflow/core/kernels/fused_batch_norm_op.cc||tensorflow/core/kernels/fused_batch_norm_op.cc",
            "tensorflow/python/ops/nn_fused_batchnorm_test.py||tensorflow/python/ops/nn_fused_batchnorm_test.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/fused_batch_norm_op.cc||tensorflow/core/kernels/fused_batch_norm_op.cc": [
          "File: tensorflow/core/kernels/fused_batch_norm_op.cc -> tensorflow/core/kernels/fused_batch_norm_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "1293:         errors::InvalidArgument(\"offset must have the same number of elements \"",
          "1294:                                 \"as the channels of x, got \",",
          "1295:                                 offset.NumElements(), \" and \", num_channels));",
          "1297:       OP_REQUIRES(context, estimated_mean.NumElements() == num_channels,",
          "1298:                   errors::InvalidArgument(",
          "1301:                       estimated_mean.NumElements(), \" and \", num_channels));",
          "1304:       OP_REQUIRES(context, estimated_variance.NumElements() == num_channels,",
          "1305:                   errors::InvalidArgument(",
          "1308:                       estimated_variance.NumElements(), \" and \", num_channels));",
          "1309:     }",
          "",
          "[Removed Lines]",
          "1296:     if (estimated_mean.NumElements() != 0) {",
          "1299:                       \"mean must be empty or have the same number of \"",
          "1300:                       \"elements as the channels of x, got \",",
          "1302:     }",
          "1303:     if (estimated_variance.NumElements() != 0) {",
          "1306:                       \"variance must be empty or have the same number of \"",
          "1307:                       \"elements as the channels of x, got \",",
          "",
          "[Added Lines]",
          "1296:     if (!is_training_ || exponential_avg_factor_ != 1.) {",
          "1297:       std::string prefix_msg = is_training_ ? \"When exponential_avg_factor != 1\"",
          "1298:                                             : \"When is_training=false\";",
          "1301:                       prefix_msg,",
          "1302:                       \", mean must have the same number \"",
          "1303:                       \"of elements as the channels of x, got \",",
          "1307:                       prefix_msg,",
          "1308:                       \", variance must have the same \"",
          "1309:                       \"number of elements as the channels of x, got \",",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1454:                 errors::InvalidArgument(",
          "1455:                     \"saved variance must be 1-dimensional\",",
          "1456:                     saved_maybe_inv_var_or_pop_var.shape().DebugString()));",
          "1457:     bool use_reshape = (x.dims() == 5);",
          "1458:     auto x_shape = x.shape();",
          "1459:     TensorShape dest_shape;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1459:     OP_REQUIRES(",
          "1460:         context, x.shape() == y_backprop.shape(),",
          "1461:         errors::InvalidArgument(",
          "1462:             \"x and y_backprop must have same shape, but x has shape \",",
          "1463:             x.shape(), \" and y_backprop has shape \", y_backprop.shape()));",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "1471:                   errors::InvalidArgument(\"Error during tensor copy.\"));",
          "1472:     }",
          "1474:     Tensor* x_backprop = nullptr;",
          "1475:     auto alloc_shape = use_reshape ? dest_shape : x_shape;",
          "1476:     OP_REQUIRES_OK(context,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1481:     const auto num_channels = GetTensorDim(x, tensor_format_, 'C');",
          "1482:     OP_REQUIRES(",
          "1483:         context, scale.NumElements() == num_channels,",
          "1484:         errors::InvalidArgument(\"scale must have the same number of elements \"",
          "1485:                                 \"as the channels of x, got \",",
          "1486:                                 scale.NumElements(), \" and \", num_channels));",
          "1487:     OP_REQUIRES(",
          "1488:         context, saved_mean_or_pop_mean.NumElements() == num_channels,",
          "1489:         errors::InvalidArgument(\"reserve_space_1 must have the same number of \"",
          "1490:                                 \"elements as the channels of x, got \",",
          "1491:                                 scale.NumElements(), \" and \", num_channels));",
          "1492:     OP_REQUIRES(",
          "1493:         context, saved_maybe_inv_var_or_pop_var.NumElements() == num_channels,",
          "1494:         errors::InvalidArgument(\"reserve_space_2 must have the same number of \"",
          "1495:                                 \"elements as the channels of x, got \",",
          "1496:                                 scale.NumElements(), \" and \", num_channels));",
          "",
          "---------------"
        ],
        "tensorflow/python/ops/nn_fused_batchnorm_test.py||tensorflow/python/ops/nn_fused_batchnorm_test.py": [
          "File: tensorflow/python/ops/nn_fused_batchnorm_test.py -> tensorflow/python/ops/nn_fused_batchnorm_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: import numpy as np",
          "23: from tensorflow.python.framework import constant_op",
          "24: from tensorflow.python.framework import dtypes",
          "25: from tensorflow.python.framework import test_util",
          "26: from tensorflow.python.ops import array_ops",
          "27: from tensorflow.python.ops import gradient_checker",
          "28: from tensorflow.python.ops import gradients_impl",
          "29: from tensorflow.python.ops import math_ops",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "23: from tensorflow.python.eager import context",
          "26: from tensorflow.python.framework import errors_impl",
          "29: from tensorflow.python.ops import gen_nn_ops",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "669:     }",
          "670:     self._testBatchNormGradGrad(config)",
          "673: if __name__ == '__main__':",
          "674:   test.main()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "675:   def testEagerShapeErrors(self):",
          "676:     with context.eager_mode():",
          "677:       x = array_ops.ones((2, 2, 2, 2))",
          "678:       scale = array_ops.ones((3,))",
          "679:       offset = array_ops.ones((2,))",
          "680:       with self.assertRaisesRegex(",
          "681:           errors_impl.InvalidArgumentError,",
          "682:           'scale must have the same number of elements'):",
          "683:         nn_impl.fused_batch_norm(x, scale, offset)",
          "685:       x = array_ops.ones((2, 2, 2, 2))",
          "686:       scale = array_ops.ones((2,))",
          "687:       offset = array_ops.ones((3,))",
          "688:       with self.assertRaisesRegex(",
          "689:           errors_impl.InvalidArgumentError,",
          "690:           'offset must have the same number of elements'):",
          "691:         nn_impl.fused_batch_norm(x, scale, offset)",
          "693:       x = array_ops.ones((2, 2, 2, 2))",
          "694:       scale = array_ops.ones((2,))",
          "695:       offset = array_ops.ones((2,))",
          "696:       mean = array_ops.ones((0,))",
          "697:       variance = array_ops.ones((2,))",
          "698:       with self.assertRaisesRegex(",
          "699:           errors_impl.InvalidArgumentError,",
          "700:           'When is_training=false, mean must have the same number of elements'):",
          "701:         nn_impl.fused_batch_norm(",
          "702:             x, scale, offset, mean=mean, variance=variance, is_training=False)",
          "704:       x = array_ops.ones((2, 2, 2, 2))",
          "705:       scale = array_ops.ones((2,))",
          "706:       offset = array_ops.ones((2,))",
          "707:       mean = array_ops.ones((2,))",
          "708:       variance = array_ops.ones((0,))",
          "709:       with self.assertRaisesRegex(",
          "710:           errors_impl.InvalidArgumentError,",
          "711:           'When is_training=false, variance must have the same number of '",
          "712:           'elements'):",
          "713:         nn_impl.fused_batch_norm(",
          "714:             x, scale, offset, mean=mean, variance=variance, is_training=False)",
          "716:       x = array_ops.ones((2, 2, 2, 2))",
          "717:       scale = array_ops.ones((2,))",
          "718:       offset = array_ops.ones((2,))",
          "719:       mean = array_ops.ones((0,))",
          "720:       variance = array_ops.ones((2,))",
          "721:       with self.assertRaisesRegex(",
          "722:           errors_impl.InvalidArgumentError,",
          "723:           'When exponential_avg_factor != 1, mean must have the same number of '",
          "724:           'elements'):",
          "725:         nn_impl.fused_batch_norm(",
          "726:             x,",
          "727:             scale,",
          "728:             offset,",
          "729:             mean=mean,",
          "730:             variance=variance,",
          "731:             exponential_avg_factor=0.5)",
          "733:       x = array_ops.ones((2, 2, 2, 2))",
          "734:       scale = array_ops.ones((2,))",
          "735:       offset = array_ops.ones((2,))",
          "736:       mean = array_ops.ones((2,))",
          "737:       variance = array_ops.ones((0,))",
          "738:       with self.assertRaisesRegex(",
          "739:           errors_impl.InvalidArgumentError,",
          "740:           'When exponential_avg_factor != 1, variance must have the same '",
          "741:           'number of elements'):",
          "742:         nn_impl.fused_batch_norm(",
          "743:             x,",
          "744:             scale,",
          "745:             offset,",
          "746:             mean=mean,",
          "747:             variance=variance,",
          "748:             exponential_avg_factor=0.5)",
          "750:   def testEagerShapeGradErrors(self):",
          "751:     with context.eager_mode():",
          "752:       y_backprop = array_ops.ones((2, 2, 2, 3))",
          "753:       x = array_ops.ones((2, 2, 2, 2))",
          "754:       scale = array_ops.ones((2,))",
          "755:       reserve_space_1 = array_ops.ones((2,))",
          "756:       reserve_space_2 = array_ops.ones((2,))",
          "757:       with self.assertRaisesRegex(errors_impl.InvalidArgumentError,",
          "758:                                   'x and y_backprop must have same shape,'):",
          "759:         gen_nn_ops.fused_batch_norm_grad_v2(y_backprop, x, scale,",
          "760:                                             reserve_space_1, reserve_space_2)",
          "762:       y_backprop = array_ops.ones((2, 2, 2, 2))",
          "763:       x = array_ops.ones((2, 2, 2, 2))",
          "764:       scale = array_ops.ones((3,))",
          "765:       reserve_space_1 = array_ops.ones((2,))",
          "766:       reserve_space_2 = array_ops.ones((2,))",
          "767:       with self.assertRaisesRegex(",
          "768:           errors_impl.InvalidArgumentError,",
          "769:           'scale must have the same number of elements'):",
          "770:         gen_nn_ops.fused_batch_norm_grad_v2(y_backprop, x, scale,",
          "771:                                             reserve_space_1, reserve_space_2)",
          "773:       y_backprop = array_ops.ones((2, 2, 2, 2))",
          "774:       x = array_ops.ones((2, 2, 2, 2))",
          "775:       scale = array_ops.ones((2,))",
          "776:       reserve_space_1 = array_ops.ones((3,))",
          "777:       reserve_space_2 = array_ops.ones((2,))",
          "778:       with self.assertRaisesRegex(",
          "779:           errors_impl.InvalidArgumentError,",
          "780:           'reserve_space_1 must have the same number of elements'):",
          "781:         gen_nn_ops.fused_batch_norm_grad_v2(y_backprop, x, scale,",
          "782:                                             reserve_space_1, reserve_space_2)",
          "784:       y_backprop = array_ops.ones((2, 2, 2, 2))",
          "785:       x = array_ops.ones((2, 2, 2, 2))",
          "786:       scale = array_ops.ones((2,))",
          "787:       reserve_space_1 = array_ops.ones((2,))",
          "788:       reserve_space_2 = array_ops.ones((3,))",
          "789:       with self.assertRaisesRegex(",
          "790:           errors_impl.InvalidArgumentError,",
          "791:           'reserve_space_2 must have the same number of elements'):",
          "792:         gen_nn_ops.fused_batch_norm_grad_v2(y_backprop, x, scale,",
          "793:                                             reserve_space_1, reserve_space_2)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "6cce86c53185e4330b161e5dbb4bbc0d0e1a14bc",
      "candidate_info": {
        "commit_hash": "6cce86c53185e4330b161e5dbb4bbc0d0e1a14bc",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/6cce86c53185e4330b161e5dbb4bbc0d0e1a14bc",
        "files": [
          "tensorflow/core/kernels/fused_batch_norm_op.cc",
          "tensorflow/python/ops/nn_fused_batchnorm_test.py"
        ],
        "message": "Add shape checks to FusedBatchNorm kernels.\n\nPiperOrigin-RevId: 399755576\nChange-Id: If8049fde109cc33badb5509d174b9b95aee1ea5e",
        "before_after_code_files": [
          "tensorflow/core/kernels/fused_batch_norm_op.cc||tensorflow/core/kernels/fused_batch_norm_op.cc",
          "tensorflow/python/ops/nn_fused_batchnorm_test.py||tensorflow/python/ops/nn_fused_batchnorm_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/fused_batch_norm_op.cc||tensorflow/core/kernels/fused_batch_norm_op.cc",
            "tensorflow/python/ops/nn_fused_batchnorm_test.py||tensorflow/python/ops/nn_fused_batchnorm_test.py"
          ],
          "candidate": [
            "tensorflow/core/kernels/fused_batch_norm_op.cc||tensorflow/core/kernels/fused_batch_norm_op.cc",
            "tensorflow/python/ops/nn_fused_batchnorm_test.py||tensorflow/python/ops/nn_fused_batchnorm_test.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/fused_batch_norm_op.cc||tensorflow/core/kernels/fused_batch_norm_op.cc": [
          "File: tensorflow/core/kernels/fused_batch_norm_op.cc -> tensorflow/core/kernels/fused_batch_norm_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "1293:         errors::InvalidArgument(\"offset must have the same number of elements \"",
          "1294:                                 \"as the channels of x, got \",",
          "1295:                                 offset.NumElements(), \" and \", num_channels));",
          "1297:       OP_REQUIRES(context, estimated_mean.NumElements() == num_channels,",
          "1298:                   errors::InvalidArgument(",
          "1301:                       estimated_mean.NumElements(), \" and \", num_channels));",
          "1304:       OP_REQUIRES(context, estimated_variance.NumElements() == num_channels,",
          "1305:                   errors::InvalidArgument(",
          "1308:                       estimated_variance.NumElements(), \" and \", num_channels));",
          "1309:     }",
          "",
          "[Removed Lines]",
          "1296:     if (estimated_mean.NumElements() != 0) {",
          "1299:                       \"mean must be empty or have the same number of \"",
          "1300:                       \"elements as the channels of x, got \",",
          "1302:     }",
          "1303:     if (estimated_variance.NumElements() != 0) {",
          "1306:                       \"variance must be empty or have the same number of \"",
          "1307:                       \"elements as the channels of x, got \",",
          "",
          "[Added Lines]",
          "1296:     if (!is_training_ || exponential_avg_factor_ != 1.) {",
          "1297:       std::string prefix_msg = is_training_ ? \"When exponential_avg_factor != 1\"",
          "1298:                                             : \"When is_training=false\";",
          "1301:                       prefix_msg,",
          "1302:                       \", mean must have the same number \"",
          "1303:                       \"of elements as the channels of x, got \",",
          "1307:                       prefix_msg,",
          "1308:                       \", variance must have the same \"",
          "1309:                       \"number of elements as the channels of x, got \",",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1454:                 errors::InvalidArgument(",
          "1455:                     \"saved variance must be 1-dimensional\",",
          "1456:                     saved_maybe_inv_var_or_pop_var.shape().DebugString()));",
          "1457:     bool use_reshape = (x.dims() == 5);",
          "1458:     auto x_shape = x.shape();",
          "1459:     TensorShape dest_shape;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1459:     OP_REQUIRES(",
          "1460:         context, x.shape() == y_backprop.shape(),",
          "1461:         errors::InvalidArgument(",
          "1462:             \"x and y_backprop must have same shape, but x has shape \",",
          "1463:             x.shape(), \" and y_backprop has shape \", y_backprop.shape()));",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "1471:                   errors::InvalidArgument(\"Error during tensor copy.\"));",
          "1472:     }",
          "1474:     Tensor* x_backprop = nullptr;",
          "1475:     auto alloc_shape = use_reshape ? dest_shape : x_shape;",
          "1476:     OP_REQUIRES_OK(context,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1481:     const auto num_channels = GetTensorDim(x, tensor_format_, 'C');",
          "1482:     OP_REQUIRES(",
          "1483:         context, scale.NumElements() == num_channels,",
          "1484:         errors::InvalidArgument(\"scale must have the same number of elements \"",
          "1485:                                 \"as the channels of x, got \",",
          "1486:                                 scale.NumElements(), \" and \", num_channels));",
          "1487:     OP_REQUIRES(",
          "1488:         context, saved_mean_or_pop_mean.NumElements() == num_channels,",
          "1489:         errors::InvalidArgument(\"reserve_space_1 must have the same number of \"",
          "1490:                                 \"elements as the channels of x, got \",",
          "1491:                                 scale.NumElements(), \" and \", num_channels));",
          "1492:     OP_REQUIRES(",
          "1493:         context, saved_maybe_inv_var_or_pop_var.NumElements() == num_channels,",
          "1494:         errors::InvalidArgument(\"reserve_space_2 must have the same number of \"",
          "1495:                                 \"elements as the channels of x, got \",",
          "1496:                                 scale.NumElements(), \" and \", num_channels));",
          "",
          "---------------"
        ],
        "tensorflow/python/ops/nn_fused_batchnorm_test.py||tensorflow/python/ops/nn_fused_batchnorm_test.py": [
          "File: tensorflow/python/ops/nn_fused_batchnorm_test.py -> tensorflow/python/ops/nn_fused_batchnorm_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: import numpy as np",
          "23: from tensorflow.python.framework import constant_op",
          "24: from tensorflow.python.framework import dtypes",
          "25: from tensorflow.python.framework import test_util",
          "26: from tensorflow.python.ops import array_ops",
          "27: from tensorflow.python.ops import gradient_checker",
          "28: from tensorflow.python.ops import gradients_impl",
          "29: from tensorflow.python.ops import math_ops",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "23: from tensorflow.python.eager import context",
          "26: from tensorflow.python.framework import errors_impl",
          "29: from tensorflow.python.ops import gen_nn_ops",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "669:     }",
          "670:     self._testBatchNormGradGrad(config)",
          "673: if __name__ == '__main__':",
          "674:   test.main()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "675:   def testEagerShapeErrors(self):",
          "676:     with context.eager_mode():",
          "677:       x = array_ops.ones((2, 2, 2, 2))",
          "678:       scale = array_ops.ones((3,))",
          "679:       offset = array_ops.ones((2,))",
          "680:       with self.assertRaisesRegex(",
          "681:           errors_impl.InvalidArgumentError,",
          "682:           'scale must have the same number of elements'):",
          "683:         nn_impl.fused_batch_norm(x, scale, offset)",
          "685:       x = array_ops.ones((2, 2, 2, 2))",
          "686:       scale = array_ops.ones((2,))",
          "687:       offset = array_ops.ones((3,))",
          "688:       with self.assertRaisesRegex(",
          "689:           errors_impl.InvalidArgumentError,",
          "690:           'offset must have the same number of elements'):",
          "691:         nn_impl.fused_batch_norm(x, scale, offset)",
          "693:       x = array_ops.ones((2, 2, 2, 2))",
          "694:       scale = array_ops.ones((2,))",
          "695:       offset = array_ops.ones((2,))",
          "696:       mean = array_ops.ones((0,))",
          "697:       variance = array_ops.ones((2,))",
          "698:       with self.assertRaisesRegex(",
          "699:           errors_impl.InvalidArgumentError,",
          "700:           'When is_training=false, mean must have the same number of elements'):",
          "701:         nn_impl.fused_batch_norm(",
          "702:             x, scale, offset, mean=mean, variance=variance, is_training=False)",
          "704:       x = array_ops.ones((2, 2, 2, 2))",
          "705:       scale = array_ops.ones((2,))",
          "706:       offset = array_ops.ones((2,))",
          "707:       mean = array_ops.ones((2,))",
          "708:       variance = array_ops.ones((0,))",
          "709:       with self.assertRaisesRegex(",
          "710:           errors_impl.InvalidArgumentError,",
          "711:           'When is_training=false, variance must have the same number of '",
          "712:           'elements'):",
          "713:         nn_impl.fused_batch_norm(",
          "714:             x, scale, offset, mean=mean, variance=variance, is_training=False)",
          "716:       x = array_ops.ones((2, 2, 2, 2))",
          "717:       scale = array_ops.ones((2,))",
          "718:       offset = array_ops.ones((2,))",
          "719:       mean = array_ops.ones((0,))",
          "720:       variance = array_ops.ones((2,))",
          "721:       with self.assertRaisesRegex(",
          "722:           errors_impl.InvalidArgumentError,",
          "723:           'When exponential_avg_factor != 1, mean must have the same number of '",
          "724:           'elements'):",
          "725:         nn_impl.fused_batch_norm(",
          "726:             x,",
          "727:             scale,",
          "728:             offset,",
          "729:             mean=mean,",
          "730:             variance=variance,",
          "731:             exponential_avg_factor=0.5)",
          "733:       x = array_ops.ones((2, 2, 2, 2))",
          "734:       scale = array_ops.ones((2,))",
          "735:       offset = array_ops.ones((2,))",
          "736:       mean = array_ops.ones((2,))",
          "737:       variance = array_ops.ones((0,))",
          "738:       with self.assertRaisesRegex(",
          "739:           errors_impl.InvalidArgumentError,",
          "740:           'When exponential_avg_factor != 1, variance must have the same '",
          "741:           'number of elements'):",
          "742:         nn_impl.fused_batch_norm(",
          "743:             x,",
          "744:             scale,",
          "745:             offset,",
          "746:             mean=mean,",
          "747:             variance=variance,",
          "748:             exponential_avg_factor=0.5)",
          "750:   def testEagerShapeGradErrors(self):",
          "751:     with context.eager_mode():",
          "752:       y_backprop = array_ops.ones((2, 2, 2, 3))",
          "753:       x = array_ops.ones((2, 2, 2, 2))",
          "754:       scale = array_ops.ones((2,))",
          "755:       reserve_space_1 = array_ops.ones((2,))",
          "756:       reserve_space_2 = array_ops.ones((2,))",
          "757:       with self.assertRaisesRegex(errors_impl.InvalidArgumentError,",
          "758:                                   'x and y_backprop must have same shape,'):",
          "759:         gen_nn_ops.fused_batch_norm_grad_v2(y_backprop, x, scale,",
          "760:                                             reserve_space_1, reserve_space_2)",
          "762:       y_backprop = array_ops.ones((2, 2, 2, 2))",
          "763:       x = array_ops.ones((2, 2, 2, 2))",
          "764:       scale = array_ops.ones((3,))",
          "765:       reserve_space_1 = array_ops.ones((2,))",
          "766:       reserve_space_2 = array_ops.ones((2,))",
          "767:       with self.assertRaisesRegex(",
          "768:           errors_impl.InvalidArgumentError,",
          "769:           'scale must have the same number of elements'):",
          "770:         gen_nn_ops.fused_batch_norm_grad_v2(y_backprop, x, scale,",
          "771:                                             reserve_space_1, reserve_space_2)",
          "773:       y_backprop = array_ops.ones((2, 2, 2, 2))",
          "774:       x = array_ops.ones((2, 2, 2, 2))",
          "775:       scale = array_ops.ones((2,))",
          "776:       reserve_space_1 = array_ops.ones((3,))",
          "777:       reserve_space_2 = array_ops.ones((2,))",
          "778:       with self.assertRaisesRegex(",
          "779:           errors_impl.InvalidArgumentError,",
          "780:           'reserve_space_1 must have the same number of elements'):",
          "781:         gen_nn_ops.fused_batch_norm_grad_v2(y_backprop, x, scale,",
          "782:                                             reserve_space_1, reserve_space_2)",
          "784:       y_backprop = array_ops.ones((2, 2, 2, 2))",
          "785:       x = array_ops.ones((2, 2, 2, 2))",
          "786:       scale = array_ops.ones((2,))",
          "787:       reserve_space_1 = array_ops.ones((2,))",
          "788:       reserve_space_2 = array_ops.ones((3,))",
          "789:       with self.assertRaisesRegex(",
          "790:           errors_impl.InvalidArgumentError,",
          "791:           'reserve_space_2 must have the same number of elements'):",
          "792:         gen_nn_ops.fused_batch_norm_grad_v2(y_backprop, x, scale,",
          "793:                                             reserve_space_1, reserve_space_2)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "292b836b5112b9c4457fa474a8755e5bdde0f781",
      "candidate_info": {
        "commit_hash": "292b836b5112b9c4457fa474a8755e5bdde0f781",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/292b836b5112b9c4457fa474a8755e5bdde0f781",
        "files": [
          "tensorflow/core/kernels/fused_batch_norm_op.cc",
          "tensorflow/python/ops/nn_fused_batchnorm_test.py"
        ],
        "message": "Add shape checks to FusedBatchNorm kernels.\n\nPiperOrigin-RevId: 399755576\nChange-Id: If8049fde109cc33badb5509d174b9b95aee1ea5e",
        "before_after_code_files": [
          "tensorflow/core/kernels/fused_batch_norm_op.cc||tensorflow/core/kernels/fused_batch_norm_op.cc",
          "tensorflow/python/ops/nn_fused_batchnorm_test.py||tensorflow/python/ops/nn_fused_batchnorm_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/fused_batch_norm_op.cc||tensorflow/core/kernels/fused_batch_norm_op.cc",
            "tensorflow/python/ops/nn_fused_batchnorm_test.py||tensorflow/python/ops/nn_fused_batchnorm_test.py"
          ],
          "candidate": [
            "tensorflow/core/kernels/fused_batch_norm_op.cc||tensorflow/core/kernels/fused_batch_norm_op.cc",
            "tensorflow/python/ops/nn_fused_batchnorm_test.py||tensorflow/python/ops/nn_fused_batchnorm_test.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/fused_batch_norm_op.cc||tensorflow/core/kernels/fused_batch_norm_op.cc": [
          "File: tensorflow/core/kernels/fused_batch_norm_op.cc -> tensorflow/core/kernels/fused_batch_norm_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "1311:         errors::InvalidArgument(\"offset must have the same number of elements \"",
          "1312:                                 \"as the channels of x, got \",",
          "1313:                                 offset.NumElements(), \" and \", num_channels));",
          "1315:       OP_REQUIRES(context, estimated_mean.NumElements() == num_channels,",
          "1316:                   errors::InvalidArgument(",
          "1319:                       estimated_mean.NumElements(), \" and \", num_channels));",
          "1322:       OP_REQUIRES(context, estimated_variance.NumElements() == num_channels,",
          "1323:                   errors::InvalidArgument(",
          "1326:                       estimated_variance.NumElements(), \" and \", num_channels));",
          "1327:     }",
          "",
          "[Removed Lines]",
          "1314:     if (estimated_mean.NumElements() != 0) {",
          "1317:                       \"mean must be empty or have the same number of \"",
          "1318:                       \"elements as the channels of x, got \",",
          "1320:     }",
          "1321:     if (estimated_variance.NumElements() != 0) {",
          "1324:                       \"variance must be empty or have the same number of \"",
          "1325:                       \"elements as the channels of x, got \",",
          "",
          "[Added Lines]",
          "1314:     if (!is_training_ || exponential_avg_factor_ != 1.) {",
          "1315:       std::string prefix_msg = is_training_ ? \"When exponential_avg_factor != 1\"",
          "1316:                                             : \"When is_training=false\";",
          "1319:                       prefix_msg,",
          "1320:                       \", mean must have the same number \"",
          "1321:                       \"of elements as the channels of x, got \",",
          "1325:                       prefix_msg,",
          "1326:                       \", variance must have the same \"",
          "1327:                       \"number of elements as the channels of x, got \",",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1472:                 errors::InvalidArgument(",
          "1473:                     \"saved variance must be 1-dimensional\",",
          "1474:                     saved_maybe_inv_var_or_pop_var.shape().DebugString()));",
          "1475:     bool use_reshape = (x.dims() == 5);",
          "1476:     auto x_shape = x.shape();",
          "1477:     TensorShape dest_shape;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1477:     OP_REQUIRES(",
          "1478:         context, x.shape() == y_backprop.shape(),",
          "1479:         errors::InvalidArgument(",
          "1480:             \"x and y_backprop must have same shape, but x has shape \",",
          "1481:             x.shape(), \" and y_backprop has shape \", y_backprop.shape()));",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "1489:                   errors::InvalidArgument(\"Error during tensor copy.\"));",
          "1490:     }",
          "1492:     Tensor* x_backprop = nullptr;",
          "1493:     auto alloc_shape = use_reshape ? dest_shape : x_shape;",
          "1494:     OP_REQUIRES_OK(context,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1499:     const auto num_channels = GetTensorDim(x, tensor_format_, 'C');",
          "1500:     OP_REQUIRES(",
          "1501:         context, scale.NumElements() == num_channels,",
          "1502:         errors::InvalidArgument(\"scale must have the same number of elements \"",
          "1503:                                 \"as the channels of x, got \",",
          "1504:                                 scale.NumElements(), \" and \", num_channels));",
          "1505:     OP_REQUIRES(",
          "1506:         context, saved_mean_or_pop_mean.NumElements() == num_channels,",
          "1507:         errors::InvalidArgument(\"reserve_space_1 must have the same number of \"",
          "1508:                                 \"elements as the channels of x, got \",",
          "1509:                                 scale.NumElements(), \" and \", num_channels));",
          "1510:     OP_REQUIRES(",
          "1511:         context, saved_maybe_inv_var_or_pop_var.NumElements() == num_channels,",
          "1512:         errors::InvalidArgument(\"reserve_space_2 must have the same number of \"",
          "1513:                                 \"elements as the channels of x, got \",",
          "1514:                                 scale.NumElements(), \" and \", num_channels));",
          "",
          "---------------"
        ],
        "tensorflow/python/ops/nn_fused_batchnorm_test.py||tensorflow/python/ops/nn_fused_batchnorm_test.py": [
          "File: tensorflow/python/ops/nn_fused_batchnorm_test.py -> tensorflow/python/ops/nn_fused_batchnorm_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: import numpy as np",
          "23: from tensorflow.python.framework import constant_op",
          "24: from tensorflow.python.framework import dtypes",
          "25: from tensorflow.python.framework import test_util",
          "26: from tensorflow.python.ops import array_ops",
          "27: from tensorflow.python.ops import gradient_checker",
          "28: from tensorflow.python.ops import gradients_impl",
          "29: from tensorflow.python.ops import math_ops",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "23: from tensorflow.python.eager import context",
          "26: from tensorflow.python.framework import errors_impl",
          "29: from tensorflow.python.ops import gen_nn_ops",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "698:     y_ref = np.maximum(y_ref, 0.)",
          "699:     self.assertAllClose(y_ref, y_val, atol=1e-3)",
          "702: if __name__ == '__main__':",
          "703:   test.main()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "704:   def testEagerShapeErrors(self):",
          "705:     with context.eager_mode():",
          "706:       x = array_ops.ones((2, 2, 2, 2))",
          "707:       scale = array_ops.ones((3,))",
          "708:       offset = array_ops.ones((2,))",
          "709:       with self.assertRaisesRegex(",
          "710:           errors_impl.InvalidArgumentError,",
          "711:           'scale must have the same number of elements'):",
          "712:         nn_impl.fused_batch_norm(x, scale, offset)",
          "714:       x = array_ops.ones((2, 2, 2, 2))",
          "715:       scale = array_ops.ones((2,))",
          "716:       offset = array_ops.ones((3,))",
          "717:       with self.assertRaisesRegex(",
          "718:           errors_impl.InvalidArgumentError,",
          "719:           'offset must have the same number of elements'):",
          "720:         nn_impl.fused_batch_norm(x, scale, offset)",
          "722:       x = array_ops.ones((2, 2, 2, 2))",
          "723:       scale = array_ops.ones((2,))",
          "724:       offset = array_ops.ones((2,))",
          "725:       mean = array_ops.ones((0,))",
          "726:       variance = array_ops.ones((2,))",
          "727:       with self.assertRaisesRegex(",
          "728:           errors_impl.InvalidArgumentError,",
          "729:           'When is_training=false, mean must have the same number of elements'):",
          "730:         nn_impl.fused_batch_norm(",
          "731:             x, scale, offset, mean=mean, variance=variance, is_training=False)",
          "733:       x = array_ops.ones((2, 2, 2, 2))",
          "734:       scale = array_ops.ones((2,))",
          "735:       offset = array_ops.ones((2,))",
          "736:       mean = array_ops.ones((2,))",
          "737:       variance = array_ops.ones((0,))",
          "738:       with self.assertRaisesRegex(",
          "739:           errors_impl.InvalidArgumentError,",
          "740:           'When is_training=false, variance must have the same number of '",
          "741:           'elements'):",
          "742:         nn_impl.fused_batch_norm(",
          "743:             x, scale, offset, mean=mean, variance=variance, is_training=False)",
          "745:       x = array_ops.ones((2, 2, 2, 2))",
          "746:       scale = array_ops.ones((2,))",
          "747:       offset = array_ops.ones((2,))",
          "748:       mean = array_ops.ones((0,))",
          "749:       variance = array_ops.ones((2,))",
          "750:       with self.assertRaisesRegex(",
          "751:           errors_impl.InvalidArgumentError,",
          "752:           'When exponential_avg_factor != 1, mean must have the same number of '",
          "753:           'elements'):",
          "754:         nn_impl.fused_batch_norm(",
          "755:             x,",
          "756:             scale,",
          "757:             offset,",
          "758:             mean=mean,",
          "759:             variance=variance,",
          "760:             exponential_avg_factor=0.5)",
          "762:       x = array_ops.ones((2, 2, 2, 2))",
          "763:       scale = array_ops.ones((2,))",
          "764:       offset = array_ops.ones((2,))",
          "765:       mean = array_ops.ones((2,))",
          "766:       variance = array_ops.ones((0,))",
          "767:       with self.assertRaisesRegex(",
          "768:           errors_impl.InvalidArgumentError,",
          "769:           'When exponential_avg_factor != 1, variance must have the same '",
          "770:           'number of elements'):",
          "771:         nn_impl.fused_batch_norm(",
          "772:             x,",
          "773:             scale,",
          "774:             offset,",
          "775:             mean=mean,",
          "776:             variance=variance,",
          "777:             exponential_avg_factor=0.5)",
          "779:   def testEagerShapeGradErrors(self):",
          "780:     with context.eager_mode():",
          "781:       y_backprop = array_ops.ones((2, 2, 2, 3))",
          "782:       x = array_ops.ones((2, 2, 2, 2))",
          "783:       scale = array_ops.ones((2,))",
          "784:       reserve_space_1 = array_ops.ones((2,))",
          "785:       reserve_space_2 = array_ops.ones((2,))",
          "786:       with self.assertRaisesRegex(errors_impl.InvalidArgumentError,",
          "787:                                   'x and y_backprop must have same shape,'):",
          "788:         gen_nn_ops.fused_batch_norm_grad_v2(y_backprop, x, scale,",
          "789:                                             reserve_space_1, reserve_space_2)",
          "791:       y_backprop = array_ops.ones((2, 2, 2, 2))",
          "792:       x = array_ops.ones((2, 2, 2, 2))",
          "793:       scale = array_ops.ones((3,))",
          "794:       reserve_space_1 = array_ops.ones((2,))",
          "795:       reserve_space_2 = array_ops.ones((2,))",
          "796:       with self.assertRaisesRegex(",
          "797:           errors_impl.InvalidArgumentError,",
          "798:           'scale must have the same number of elements'):",
          "799:         gen_nn_ops.fused_batch_norm_grad_v2(y_backprop, x, scale,",
          "800:                                             reserve_space_1, reserve_space_2)",
          "802:       y_backprop = array_ops.ones((2, 2, 2, 2))",
          "803:       x = array_ops.ones((2, 2, 2, 2))",
          "804:       scale = array_ops.ones((2,))",
          "805:       reserve_space_1 = array_ops.ones((3,))",
          "806:       reserve_space_2 = array_ops.ones((2,))",
          "807:       with self.assertRaisesRegex(",
          "808:           errors_impl.InvalidArgumentError,",
          "809:           'reserve_space_1 must have the same number of elements'):",
          "810:         gen_nn_ops.fused_batch_norm_grad_v2(y_backprop, x, scale,",
          "811:                                             reserve_space_1, reserve_space_2)",
          "813:       y_backprop = array_ops.ones((2, 2, 2, 2))",
          "814:       x = array_ops.ones((2, 2, 2, 2))",
          "815:       scale = array_ops.ones((2,))",
          "816:       reserve_space_1 = array_ops.ones((2,))",
          "817:       reserve_space_2 = array_ops.ones((3,))",
          "818:       with self.assertRaisesRegex(",
          "819:           errors_impl.InvalidArgumentError,",
          "820:           'reserve_space_2 must have the same number of elements'):",
          "821:         gen_nn_ops.fused_batch_norm_grad_v2(y_backprop, x, scale,",
          "822:                                             reserve_space_1, reserve_space_2)",
          "",
          "---------------"
        ]
      }
    }
  ]
}