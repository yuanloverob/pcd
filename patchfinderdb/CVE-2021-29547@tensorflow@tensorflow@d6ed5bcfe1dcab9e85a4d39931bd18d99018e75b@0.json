{
  "cve_id": "CVE-2021-29547",
  "cve_desc": "TensorFlow is an end-to-end open source platform for machine learning. An attacker can cause a segfault and denial of service via accessing data outside of bounds in `tf.raw_ops.QuantizedBatchNormWithGlobalNormalization`. This is because the implementation(https://github.com/tensorflow/tensorflow/blob/55a97caa9e99c7f37a0bbbeb414dc55553d3ae7f/tensorflow/core/kernels/quantized_batch_norm_op.cc#L176-L189) assumes the inputs are not empty. If any of these inputs is empty, `.flat<T>()` is an empty buffer, so accessing the element at index 0 is accessing data outside of bounds. The fix will be included in TensorFlow 2.5.0. We will also cherrypick this commit on TensorFlow 2.4.2, TensorFlow 2.3.3, TensorFlow 2.2.3 and TensorFlow 2.1.4, as these are also affected and still in supported range.",
  "repo": "tensorflow/tensorflow",
  "patch_hash": "d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b",
  "patch_info": {
    "commit_hash": "d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b",
    "repo": "tensorflow/tensorflow",
    "commit_url": "https://github.com/tensorflow/tensorflow/commit/d6ed5bcfe1dcab9e85a4d39931bd18d99018e75b",
    "files": [
      "tensorflow/core/kernels/quantized_batch_norm_op.cc"
    ],
    "message": "Add missing validation in `QuantizedBatchNormWithGlobalNormalization`\n\nPiperOrigin-RevId: 370123451\nChange-Id: Id234d6dab1ec21230bb8e503dba30f899af87f33",
    "before_after_code_files": [
      "tensorflow/core/kernels/quantized_batch_norm_op.cc||tensorflow/core/kernels/quantized_batch_norm_op.cc"
    ]
  },
  "patch_diff": {
    "tensorflow/core/kernels/quantized_batch_norm_op.cc||tensorflow/core/kernels/quantized_batch_norm_op.cc": [
      "File: tensorflow/core/kernels/quantized_batch_norm_op.cc -> tensorflow/core/kernels/quantized_batch_norm_op.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "174:   void Compute(OpKernelContext* context) override {",
      "175:     const Tensor& input = context->input(0);",
      "178:     const Tensor& mean = context->input(3);",
      "181:     const Tensor& var = context->input(6);",
      "184:     const Tensor& beta = context->input(9);",
      "187:     const Tensor& gamma = context->input(12);",
      "191:     OP_REQUIRES(context, input.dims() == 4,",
      "192:                 errors::InvalidArgument(\"input must be 4-dimensional\",",
      "",
      "[Removed Lines]",
      "176:     const float input_min = context->input(1).flat<float>()(0);",
      "177:     const float input_max = context->input(2).flat<float>()(0);",
      "179:     const float mean_min = context->input(4).flat<float>()(0);",
      "180:     const float mean_max = context->input(5).flat<float>()(0);",
      "182:     const float var_min = context->input(7).flat<float>()(0);",
      "183:     const float var_max = context->input(8).flat<float>()(0);",
      "185:     const float beta_min = context->input(10).flat<float>()(0);",
      "186:     const float beta_max = context->input(11).flat<float>()(0);",
      "188:     const float gamma_min = context->input(13).flat<float>()(0);",
      "189:     const float gamma_max = context->input(14).flat<float>()(0);",
      "",
      "[Added Lines]",
      "176:     const auto& input_min_tensor = context->input(1);",
      "177:     OP_REQUIRES(context, input_min_tensor.NumElements() == 1,",
      "178:                 errors::InvalidArgument(\"input_min must have 1 element\"));",
      "179:     const float input_min = input_min_tensor.flat<float>()(0);",
      "180:     const auto& input_max_tensor = context->input(2);",
      "181:     OP_REQUIRES(context, input_max_tensor.NumElements() == 1,",
      "182:                 errors::InvalidArgument(\"input_max must have 1 element\"));",
      "183:     const float input_max = input_max_tensor.flat<float>()(0);",
      "185:     const auto& mean_min_tensor = context->input(4);",
      "186:     OP_REQUIRES(context, mean_min_tensor.NumElements() == 1,",
      "187:                 errors::InvalidArgument(\"mean_min must have 1 element\"));",
      "188:     const float mean_min = mean_min_tensor.flat<float>()(0);",
      "189:     const auto& mean_max_tensor = context->input(5);",
      "190:     OP_REQUIRES(context, mean_max_tensor.NumElements() == 1,",
      "191:                 errors::InvalidArgument(\"mean_max must have 1 element\"));",
      "192:     const float mean_max = mean_max_tensor.flat<float>()(0);",
      "194:     const auto& var_min_tensor = context->input(7);",
      "195:     OP_REQUIRES(context, var_min_tensor.NumElements() == 1,",
      "196:                 errors::InvalidArgument(\"var_min must have 1 element\"));",
      "197:     const float var_min = var_min_tensor.flat<float>()(0);",
      "198:     const auto& var_max_tensor = context->input(8);",
      "199:     OP_REQUIRES(context, var_max_tensor.NumElements() == 1,",
      "200:                 errors::InvalidArgument(\"var_max must have 1 element\"));",
      "201:     const float var_max = var_max_tensor.flat<float>()(0);",
      "203:     const auto& beta_min_tensor = context->input(10);",
      "204:     OP_REQUIRES(context, beta_min_tensor.NumElements() == 1,",
      "205:                 errors::InvalidArgument(\"beta_min must have 1 element\"));",
      "206:     const float beta_min = beta_min_tensor.flat<float>()(0);",
      "207:     const auto& beta_max_tensor = context->input(11);",
      "208:     OP_REQUIRES(context, beta_max_tensor.NumElements() == 1,",
      "209:                 errors::InvalidArgument(\"beta_max must have 1 element\"));",
      "210:     const float beta_max = beta_max_tensor.flat<float>()(0);",
      "212:     const auto& gamma_min_tensor = context->input(13);",
      "213:     OP_REQUIRES(context, gamma_min_tensor.NumElements() == 1,",
      "214:                 errors::InvalidArgument(\"gamma_min must have 1 element\"));",
      "215:     const float gamma_min = gamma_min_tensor.flat<float>()(0);",
      "216:     const auto& gamma_max_tensor = context->input(14);",
      "217:     OP_REQUIRES(context, gamma_max_tensor.NumElements() == 1,",
      "218:                 errors::InvalidArgument(\"gamma_max must have 1 element\"));",
      "219:     const float gamma_max = gamma_max_tensor.flat<float>()(0);",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "203:     OP_REQUIRES(context, gamma.dims() == 1,",
      "204:                 errors::InvalidArgument(\"gamma must be 1-dimensional\",",
      "205:                                         gamma.shape().DebugString()));",
      "207:     Tensor* output = nullptr;",
      "208:     OP_REQUIRES_OK(context,",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "236:     OP_REQUIRES(context, mean.NumElements() > 1,",
      "237:                 errors::InvalidArgument(\"Must have at least a mean value\",",
      "238:                                         gamma.shape().DebugString()));",
      "239:     OP_REQUIRES(context, mean.NumElements() > 1,",
      "240:                 errors::InvalidArgument(\"Must have at least a mean value\"));",
      "241:     const auto last_dim = input.shape().dims() - 1;",
      "242:     OP_REQUIRES(context,",
      "243:                 mean.shape().dim_size(0) == input.shape().dim_size(last_dim),",
      "244:                 errors::InvalidArgument(\"Must provide as many means as the \"",
      "245:                                         \"last dimension of the input tensor: \",",
      "246:                                         mean.shape().DebugString(), \" vs. \",",
      "247:                                         input.shape().DebugString()));",
      "248:     OP_REQUIRES(",
      "249:         context, mean.shape().dim_size(0) == var.shape().dim_size(0),",
      "250:         errors::InvalidArgument(",
      "251:             \"Mean and variance tensors must have the same shape: \",",
      "252:             mean.shape().DebugString(), \" vs. \", var.shape().DebugString()));",
      "253:     OP_REQUIRES(",
      "254:         context, mean.shape().dim_size(0) == beta.shape().dim_size(0),",
      "255:         errors::InvalidArgument(",
      "256:             \"Mean and beta tensors must have the same shape: \",",
      "257:             mean.shape().DebugString(), \" vs. \", beta.shape().DebugString()));",
      "258:     OP_REQUIRES(",
      "259:         context, mean.shape().dim_size(0) == gamma.shape().dim_size(0),",
      "260:         errors::InvalidArgument(",
      "261:             \"Mean and gamma tensors must have the same shape: \",",
      "262:             mean.shape().DebugString(), \" vs. \", gamma.shape().DebugString()));",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "69521621908f6623bf23d1dcca013e93848cba08",
      "candidate_info": {
        "commit_hash": "69521621908f6623bf23d1dcca013e93848cba08",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/69521621908f6623bf23d1dcca013e93848cba08",
        "files": [
          "tensorflow/core/kernels/quantized_batch_norm_op.cc"
        ],
        "message": "Add missing validation in `QuantizedBatchNormWithGlobalNormalization`\n\nPiperOrigin-RevId: 370123451\nChange-Id: Id234d6dab1ec21230bb8e503dba30f899af87f33",
        "before_after_code_files": [
          "tensorflow/core/kernels/quantized_batch_norm_op.cc||tensorflow/core/kernels/quantized_batch_norm_op.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/quantized_batch_norm_op.cc||tensorflow/core/kernels/quantized_batch_norm_op.cc"
          ],
          "candidate": [
            "tensorflow/core/kernels/quantized_batch_norm_op.cc||tensorflow/core/kernels/quantized_batch_norm_op.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/quantized_batch_norm_op.cc||tensorflow/core/kernels/quantized_batch_norm_op.cc": [
          "File: tensorflow/core/kernels/quantized_batch_norm_op.cc -> tensorflow/core/kernels/quantized_batch_norm_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "174:   void Compute(OpKernelContext* context) override {",
          "175:     const Tensor& input = context->input(0);",
          "178:     const Tensor& mean = context->input(3);",
          "181:     const Tensor& var = context->input(6);",
          "184:     const Tensor& beta = context->input(9);",
          "187:     const Tensor& gamma = context->input(12);",
          "191:     OP_REQUIRES(context, input.dims() == 4,",
          "192:                 errors::InvalidArgument(\"input must be 4-dimensional\",",
          "",
          "[Removed Lines]",
          "176:     const float input_min = context->input(1).flat<float>()(0);",
          "177:     const float input_max = context->input(2).flat<float>()(0);",
          "179:     const float mean_min = context->input(4).flat<float>()(0);",
          "180:     const float mean_max = context->input(5).flat<float>()(0);",
          "182:     const float var_min = context->input(7).flat<float>()(0);",
          "183:     const float var_max = context->input(8).flat<float>()(0);",
          "185:     const float beta_min = context->input(10).flat<float>()(0);",
          "186:     const float beta_max = context->input(11).flat<float>()(0);",
          "188:     const float gamma_min = context->input(13).flat<float>()(0);",
          "189:     const float gamma_max = context->input(14).flat<float>()(0);",
          "",
          "[Added Lines]",
          "176:     const auto& input_min_tensor = context->input(1);",
          "177:     OP_REQUIRES(context, input_min_tensor.NumElements() == 1,",
          "178:                 errors::InvalidArgument(\"input_min must have 1 element\"));",
          "179:     const float input_min = input_min_tensor.flat<float>()(0);",
          "180:     const auto& input_max_tensor = context->input(2);",
          "181:     OP_REQUIRES(context, input_max_tensor.NumElements() == 1,",
          "182:                 errors::InvalidArgument(\"input_max must have 1 element\"));",
          "183:     const float input_max = input_max_tensor.flat<float>()(0);",
          "185:     const auto& mean_min_tensor = context->input(4);",
          "186:     OP_REQUIRES(context, mean_min_tensor.NumElements() == 1,",
          "187:                 errors::InvalidArgument(\"mean_min must have 1 element\"));",
          "188:     const float mean_min = mean_min_tensor.flat<float>()(0);",
          "189:     const auto& mean_max_tensor = context->input(5);",
          "190:     OP_REQUIRES(context, mean_max_tensor.NumElements() == 1,",
          "191:                 errors::InvalidArgument(\"mean_max must have 1 element\"));",
          "192:     const float mean_max = mean_max_tensor.flat<float>()(0);",
          "194:     const auto& var_min_tensor = context->input(7);",
          "195:     OP_REQUIRES(context, var_min_tensor.NumElements() == 1,",
          "196:                 errors::InvalidArgument(\"var_min must have 1 element\"));",
          "197:     const float var_min = var_min_tensor.flat<float>()(0);",
          "198:     const auto& var_max_tensor = context->input(8);",
          "199:     OP_REQUIRES(context, var_max_tensor.NumElements() == 1,",
          "200:                 errors::InvalidArgument(\"var_max must have 1 element\"));",
          "201:     const float var_max = var_max_tensor.flat<float>()(0);",
          "203:     const auto& beta_min_tensor = context->input(10);",
          "204:     OP_REQUIRES(context, beta_min_tensor.NumElements() == 1,",
          "205:                 errors::InvalidArgument(\"beta_min must have 1 element\"));",
          "206:     const float beta_min = beta_min_tensor.flat<float>()(0);",
          "207:     const auto& beta_max_tensor = context->input(11);",
          "208:     OP_REQUIRES(context, beta_max_tensor.NumElements() == 1,",
          "209:                 errors::InvalidArgument(\"beta_max must have 1 element\"));",
          "210:     const float beta_max = beta_max_tensor.flat<float>()(0);",
          "212:     const auto& gamma_min_tensor = context->input(13);",
          "213:     OP_REQUIRES(context, gamma_min_tensor.NumElements() == 1,",
          "214:                 errors::InvalidArgument(\"gamma_min must have 1 element\"));",
          "215:     const float gamma_min = gamma_min_tensor.flat<float>()(0);",
          "216:     const auto& gamma_max_tensor = context->input(14);",
          "217:     OP_REQUIRES(context, gamma_max_tensor.NumElements() == 1,",
          "218:                 errors::InvalidArgument(\"gamma_max must have 1 element\"));",
          "219:     const float gamma_max = gamma_max_tensor.flat<float>()(0);",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "203:     OP_REQUIRES(context, gamma.dims() == 1,",
          "204:                 errors::InvalidArgument(\"gamma must be 1-dimensional\",",
          "205:                                         gamma.shape().DebugString()));",
          "207:     Tensor* output = nullptr;",
          "208:     OP_REQUIRES_OK(context,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "236:     OP_REQUIRES(context, mean.NumElements() > 1,",
          "237:                 errors::InvalidArgument(\"Must have at least a mean value\",",
          "238:                                         gamma.shape().DebugString()));",
          "239:     OP_REQUIRES(context, mean.NumElements() > 1,",
          "240:                 errors::InvalidArgument(\"Must have at least a mean value\"));",
          "241:     const auto last_dim = input.shape().dims() - 1;",
          "242:     OP_REQUIRES(context,",
          "243:                 mean.shape().dim_size(0) == input.shape().dim_size(last_dim),",
          "244:                 errors::InvalidArgument(\"Must provide as many means as the \"",
          "245:                                         \"last dimension of the input tensor: \",",
          "246:                                         mean.shape().DebugString(), \" vs. \",",
          "247:                                         input.shape().DebugString()));",
          "248:     OP_REQUIRES(",
          "249:         context, mean.shape().dim_size(0) == var.shape().dim_size(0),",
          "250:         errors::InvalidArgument(",
          "251:             \"Mean and variance tensors must have the same shape: \",",
          "252:             mean.shape().DebugString(), \" vs. \", var.shape().DebugString()));",
          "253:     OP_REQUIRES(",
          "254:         context, mean.shape().dim_size(0) == beta.shape().dim_size(0),",
          "255:         errors::InvalidArgument(",
          "256:             \"Mean and beta tensors must have the same shape: \",",
          "257:             mean.shape().DebugString(), \" vs. \", beta.shape().DebugString()));",
          "258:     OP_REQUIRES(",
          "259:         context, mean.shape().dim_size(0) == gamma.shape().dim_size(0),",
          "260:         errors::InvalidArgument(",
          "261:             \"Mean and gamma tensors must have the same shape: \",",
          "262:             mean.shape().DebugString(), \" vs. \", gamma.shape().DebugString()));",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "b04d0723df98f0efa03a729327470ad8b3adc4b2",
      "candidate_info": {
        "commit_hash": "b04d0723df98f0efa03a729327470ad8b3adc4b2",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/b04d0723df98f0efa03a729327470ad8b3adc4b2",
        "files": [
          "tensorflow/core/kernels/quantized_batch_norm_op.cc"
        ],
        "message": "Add missing validation in `QuantizedBatchNormWithGlobalNormalization`\n\nPiperOrigin-RevId: 370123451\nChange-Id: Id234d6dab1ec21230bb8e503dba30f899af87f33",
        "before_after_code_files": [
          "tensorflow/core/kernels/quantized_batch_norm_op.cc||tensorflow/core/kernels/quantized_batch_norm_op.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/quantized_batch_norm_op.cc||tensorflow/core/kernels/quantized_batch_norm_op.cc"
          ],
          "candidate": [
            "tensorflow/core/kernels/quantized_batch_norm_op.cc||tensorflow/core/kernels/quantized_batch_norm_op.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/quantized_batch_norm_op.cc||tensorflow/core/kernels/quantized_batch_norm_op.cc": [
          "File: tensorflow/core/kernels/quantized_batch_norm_op.cc -> tensorflow/core/kernels/quantized_batch_norm_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "174:   void Compute(OpKernelContext* context) override {",
          "175:     const Tensor& input = context->input(0);",
          "178:     const Tensor& mean = context->input(3);",
          "181:     const Tensor& var = context->input(6);",
          "184:     const Tensor& beta = context->input(9);",
          "187:     const Tensor& gamma = context->input(12);",
          "191:     OP_REQUIRES(context, input.dims() == 4,",
          "192:                 errors::InvalidArgument(\"input must be 4-dimensional\",",
          "",
          "[Removed Lines]",
          "176:     const float input_min = context->input(1).flat<float>()(0);",
          "177:     const float input_max = context->input(2).flat<float>()(0);",
          "179:     const float mean_min = context->input(4).flat<float>()(0);",
          "180:     const float mean_max = context->input(5).flat<float>()(0);",
          "182:     const float var_min = context->input(7).flat<float>()(0);",
          "183:     const float var_max = context->input(8).flat<float>()(0);",
          "185:     const float beta_min = context->input(10).flat<float>()(0);",
          "186:     const float beta_max = context->input(11).flat<float>()(0);",
          "188:     const float gamma_min = context->input(13).flat<float>()(0);",
          "189:     const float gamma_max = context->input(14).flat<float>()(0);",
          "",
          "[Added Lines]",
          "176:     const auto& input_min_tensor = context->input(1);",
          "177:     OP_REQUIRES(context, input_min_tensor.NumElements() == 1,",
          "178:                 errors::InvalidArgument(\"input_min must have 1 element\"));",
          "179:     const float input_min = input_min_tensor.flat<float>()(0);",
          "180:     const auto& input_max_tensor = context->input(2);",
          "181:     OP_REQUIRES(context, input_max_tensor.NumElements() == 1,",
          "182:                 errors::InvalidArgument(\"input_max must have 1 element\"));",
          "183:     const float input_max = input_max_tensor.flat<float>()(0);",
          "185:     const auto& mean_min_tensor = context->input(4);",
          "186:     OP_REQUIRES(context, mean_min_tensor.NumElements() == 1,",
          "187:                 errors::InvalidArgument(\"mean_min must have 1 element\"));",
          "188:     const float mean_min = mean_min_tensor.flat<float>()(0);",
          "189:     const auto& mean_max_tensor = context->input(5);",
          "190:     OP_REQUIRES(context, mean_max_tensor.NumElements() == 1,",
          "191:                 errors::InvalidArgument(\"mean_max must have 1 element\"));",
          "192:     const float mean_max = mean_max_tensor.flat<float>()(0);",
          "194:     const auto& var_min_tensor = context->input(7);",
          "195:     OP_REQUIRES(context, var_min_tensor.NumElements() == 1,",
          "196:                 errors::InvalidArgument(\"var_min must have 1 element\"));",
          "197:     const float var_min = var_min_tensor.flat<float>()(0);",
          "198:     const auto& var_max_tensor = context->input(8);",
          "199:     OP_REQUIRES(context, var_max_tensor.NumElements() == 1,",
          "200:                 errors::InvalidArgument(\"var_max must have 1 element\"));",
          "201:     const float var_max = var_max_tensor.flat<float>()(0);",
          "203:     const auto& beta_min_tensor = context->input(10);",
          "204:     OP_REQUIRES(context, beta_min_tensor.NumElements() == 1,",
          "205:                 errors::InvalidArgument(\"beta_min must have 1 element\"));",
          "206:     const float beta_min = beta_min_tensor.flat<float>()(0);",
          "207:     const auto& beta_max_tensor = context->input(11);",
          "208:     OP_REQUIRES(context, beta_max_tensor.NumElements() == 1,",
          "209:                 errors::InvalidArgument(\"beta_max must have 1 element\"));",
          "210:     const float beta_max = beta_max_tensor.flat<float>()(0);",
          "212:     const auto& gamma_min_tensor = context->input(13);",
          "213:     OP_REQUIRES(context, gamma_min_tensor.NumElements() == 1,",
          "214:                 errors::InvalidArgument(\"gamma_min must have 1 element\"));",
          "215:     const float gamma_min = gamma_min_tensor.flat<float>()(0);",
          "216:     const auto& gamma_max_tensor = context->input(14);",
          "217:     OP_REQUIRES(context, gamma_max_tensor.NumElements() == 1,",
          "218:                 errors::InvalidArgument(\"gamma_max must have 1 element\"));",
          "219:     const float gamma_max = gamma_max_tensor.flat<float>()(0);",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "203:     OP_REQUIRES(context, gamma.dims() == 1,",
          "204:                 errors::InvalidArgument(\"gamma must be 1-dimensional\",",
          "205:                                         gamma.shape().DebugString()));",
          "207:     Tensor* output = nullptr;",
          "208:     OP_REQUIRES_OK(context,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "236:     OP_REQUIRES(context, mean.NumElements() > 1,",
          "237:                 errors::InvalidArgument(\"Must have at least a mean value\",",
          "238:                                         gamma.shape().DebugString()));",
          "239:     OP_REQUIRES(context, mean.NumElements() > 1,",
          "240:                 errors::InvalidArgument(\"Must have at least a mean value\"));",
          "241:     const auto last_dim = input.shape().dims() - 1;",
          "242:     OP_REQUIRES(context,",
          "243:                 mean.shape().dim_size(0) == input.shape().dim_size(last_dim),",
          "244:                 errors::InvalidArgument(\"Must provide as many means as the \"",
          "245:                                         \"last dimension of the input tensor: \",",
          "246:                                         mean.shape().DebugString(), \" vs. \",",
          "247:                                         input.shape().DebugString()));",
          "248:     OP_REQUIRES(",
          "249:         context, mean.shape().dim_size(0) == var.shape().dim_size(0),",
          "250:         errors::InvalidArgument(",
          "251:             \"Mean and variance tensors must have the same shape: \",",
          "252:             mean.shape().DebugString(), \" vs. \", var.shape().DebugString()));",
          "253:     OP_REQUIRES(",
          "254:         context, mean.shape().dim_size(0) == beta.shape().dim_size(0),",
          "255:         errors::InvalidArgument(",
          "256:             \"Mean and beta tensors must have the same shape: \",",
          "257:             mean.shape().DebugString(), \" vs. \", beta.shape().DebugString()));",
          "258:     OP_REQUIRES(",
          "259:         context, mean.shape().dim_size(0) == gamma.shape().dim_size(0),",
          "260:         errors::InvalidArgument(",
          "261:             \"Mean and gamma tensors must have the same shape: \",",
          "262:             mean.shape().DebugString(), \" vs. \", gamma.shape().DebugString()));",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "2b709ac1be9554fd525ed01472b093eb3cfa03ba",
      "candidate_info": {
        "commit_hash": "2b709ac1be9554fd525ed01472b093eb3cfa03ba",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/2b709ac1be9554fd525ed01472b093eb3cfa03ba",
        "files": [
          "tensorflow/core/kernels/quantized_batch_norm_op.cc"
        ],
        "message": "Add missing validation in `QuantizedBatchNormWithGlobalNormalization`\n\nPiperOrigin-RevId: 370123451\nChange-Id: Id234d6dab1ec21230bb8e503dba30f899af87f33",
        "before_after_code_files": [
          "tensorflow/core/kernels/quantized_batch_norm_op.cc||tensorflow/core/kernels/quantized_batch_norm_op.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/quantized_batch_norm_op.cc||tensorflow/core/kernels/quantized_batch_norm_op.cc"
          ],
          "candidate": [
            "tensorflow/core/kernels/quantized_batch_norm_op.cc||tensorflow/core/kernels/quantized_batch_norm_op.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/quantized_batch_norm_op.cc||tensorflow/core/kernels/quantized_batch_norm_op.cc": [
          "File: tensorflow/core/kernels/quantized_batch_norm_op.cc -> tensorflow/core/kernels/quantized_batch_norm_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "174:   void Compute(OpKernelContext* context) override {",
          "175:     const Tensor& input = context->input(0);",
          "178:     const Tensor& mean = context->input(3);",
          "181:     const Tensor& var = context->input(6);",
          "184:     const Tensor& beta = context->input(9);",
          "187:     const Tensor& gamma = context->input(12);",
          "191:     OP_REQUIRES(context, input.dims() == 4,",
          "192:                 errors::InvalidArgument(\"input must be 4-dimensional\",",
          "",
          "[Removed Lines]",
          "176:     const float input_min = context->input(1).flat<float>()(0);",
          "177:     const float input_max = context->input(2).flat<float>()(0);",
          "179:     const float mean_min = context->input(4).flat<float>()(0);",
          "180:     const float mean_max = context->input(5).flat<float>()(0);",
          "182:     const float var_min = context->input(7).flat<float>()(0);",
          "183:     const float var_max = context->input(8).flat<float>()(0);",
          "185:     const float beta_min = context->input(10).flat<float>()(0);",
          "186:     const float beta_max = context->input(11).flat<float>()(0);",
          "188:     const float gamma_min = context->input(13).flat<float>()(0);",
          "189:     const float gamma_max = context->input(14).flat<float>()(0);",
          "",
          "[Added Lines]",
          "176:     const auto& input_min_tensor = context->input(1);",
          "177:     OP_REQUIRES(context, input_min_tensor.NumElements() == 1,",
          "178:                 errors::InvalidArgument(\"input_min must have 1 element\"));",
          "179:     const float input_min = input_min_tensor.flat<float>()(0);",
          "180:     const auto& input_max_tensor = context->input(2);",
          "181:     OP_REQUIRES(context, input_max_tensor.NumElements() == 1,",
          "182:                 errors::InvalidArgument(\"input_max must have 1 element\"));",
          "183:     const float input_max = input_max_tensor.flat<float>()(0);",
          "185:     const auto& mean_min_tensor = context->input(4);",
          "186:     OP_REQUIRES(context, mean_min_tensor.NumElements() == 1,",
          "187:                 errors::InvalidArgument(\"mean_min must have 1 element\"));",
          "188:     const float mean_min = mean_min_tensor.flat<float>()(0);",
          "189:     const auto& mean_max_tensor = context->input(5);",
          "190:     OP_REQUIRES(context, mean_max_tensor.NumElements() == 1,",
          "191:                 errors::InvalidArgument(\"mean_max must have 1 element\"));",
          "192:     const float mean_max = mean_max_tensor.flat<float>()(0);",
          "194:     const auto& var_min_tensor = context->input(7);",
          "195:     OP_REQUIRES(context, var_min_tensor.NumElements() == 1,",
          "196:                 errors::InvalidArgument(\"var_min must have 1 element\"));",
          "197:     const float var_min = var_min_tensor.flat<float>()(0);",
          "198:     const auto& var_max_tensor = context->input(8);",
          "199:     OP_REQUIRES(context, var_max_tensor.NumElements() == 1,",
          "200:                 errors::InvalidArgument(\"var_max must have 1 element\"));",
          "201:     const float var_max = var_max_tensor.flat<float>()(0);",
          "203:     const auto& beta_min_tensor = context->input(10);",
          "204:     OP_REQUIRES(context, beta_min_tensor.NumElements() == 1,",
          "205:                 errors::InvalidArgument(\"beta_min must have 1 element\"));",
          "206:     const float beta_min = beta_min_tensor.flat<float>()(0);",
          "207:     const auto& beta_max_tensor = context->input(11);",
          "208:     OP_REQUIRES(context, beta_max_tensor.NumElements() == 1,",
          "209:                 errors::InvalidArgument(\"beta_max must have 1 element\"));",
          "210:     const float beta_max = beta_max_tensor.flat<float>()(0);",
          "212:     const auto& gamma_min_tensor = context->input(13);",
          "213:     OP_REQUIRES(context, gamma_min_tensor.NumElements() == 1,",
          "214:                 errors::InvalidArgument(\"gamma_min must have 1 element\"));",
          "215:     const float gamma_min = gamma_min_tensor.flat<float>()(0);",
          "216:     const auto& gamma_max_tensor = context->input(14);",
          "217:     OP_REQUIRES(context, gamma_max_tensor.NumElements() == 1,",
          "218:                 errors::InvalidArgument(\"gamma_max must have 1 element\"));",
          "219:     const float gamma_max = gamma_max_tensor.flat<float>()(0);",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "203:     OP_REQUIRES(context, gamma.dims() == 1,",
          "204:                 errors::InvalidArgument(\"gamma must be 1-dimensional\",",
          "205:                                         gamma.shape().DebugString()));",
          "207:     Tensor* output = nullptr;",
          "208:     OP_REQUIRES_OK(context,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "236:     OP_REQUIRES(context, mean.NumElements() > 1,",
          "237:                 errors::InvalidArgument(\"Must have at least a mean value\",",
          "238:                                         gamma.shape().DebugString()));",
          "239:     OP_REQUIRES(context, mean.NumElements() > 1,",
          "240:                 errors::InvalidArgument(\"Must have at least a mean value\"));",
          "241:     const auto last_dim = input.shape().dims() - 1;",
          "242:     OP_REQUIRES(context,",
          "243:                 mean.shape().dim_size(0) == input.shape().dim_size(last_dim),",
          "244:                 errors::InvalidArgument(\"Must provide as many means as the \"",
          "245:                                         \"last dimension of the input tensor: \",",
          "246:                                         mean.shape().DebugString(), \" vs. \",",
          "247:                                         input.shape().DebugString()));",
          "248:     OP_REQUIRES(",
          "249:         context, mean.shape().dim_size(0) == var.shape().dim_size(0),",
          "250:         errors::InvalidArgument(",
          "251:             \"Mean and variance tensors must have the same shape: \",",
          "252:             mean.shape().DebugString(), \" vs. \", var.shape().DebugString()));",
          "253:     OP_REQUIRES(",
          "254:         context, mean.shape().dim_size(0) == beta.shape().dim_size(0),",
          "255:         errors::InvalidArgument(",
          "256:             \"Mean and beta tensors must have the same shape: \",",
          "257:             mean.shape().DebugString(), \" vs. \", beta.shape().DebugString()));",
          "258:     OP_REQUIRES(",
          "259:         context, mean.shape().dim_size(0) == gamma.shape().dim_size(0),",
          "260:         errors::InvalidArgument(",
          "261:             \"Mean and gamma tensors must have the same shape: \",",
          "262:             mean.shape().DebugString(), \" vs. \", gamma.shape().DebugString()));",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "076807066c00a3912815305227841d6aefb87b70",
      "candidate_info": {
        "commit_hash": "076807066c00a3912815305227841d6aefb87b70",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/076807066c00a3912815305227841d6aefb87b70",
        "files": [
          "tensorflow/core/kernels/quantized_batch_norm_op.cc"
        ],
        "message": "Add missing validation in `QuantizedBatchNormWithGlobalNormalization`\n\nPiperOrigin-RevId: 370123451\nChange-Id: Id234d6dab1ec21230bb8e503dba30f899af87f33",
        "before_after_code_files": [
          "tensorflow/core/kernels/quantized_batch_norm_op.cc||tensorflow/core/kernels/quantized_batch_norm_op.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/quantized_batch_norm_op.cc||tensorflow/core/kernels/quantized_batch_norm_op.cc"
          ],
          "candidate": [
            "tensorflow/core/kernels/quantized_batch_norm_op.cc||tensorflow/core/kernels/quantized_batch_norm_op.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/quantized_batch_norm_op.cc||tensorflow/core/kernels/quantized_batch_norm_op.cc": [
          "File: tensorflow/core/kernels/quantized_batch_norm_op.cc -> tensorflow/core/kernels/quantized_batch_norm_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "174:   void Compute(OpKernelContext* context) override {",
          "175:     const Tensor& input = context->input(0);",
          "178:     const Tensor& mean = context->input(3);",
          "181:     const Tensor& var = context->input(6);",
          "184:     const Tensor& beta = context->input(9);",
          "187:     const Tensor& gamma = context->input(12);",
          "191:     OP_REQUIRES(context, input.dims() == 4,",
          "192:                 errors::InvalidArgument(\"input must be 4-dimensional\",",
          "",
          "[Removed Lines]",
          "176:     const float input_min = context->input(1).flat<float>()(0);",
          "177:     const float input_max = context->input(2).flat<float>()(0);",
          "179:     const float mean_min = context->input(4).flat<float>()(0);",
          "180:     const float mean_max = context->input(5).flat<float>()(0);",
          "182:     const float var_min = context->input(7).flat<float>()(0);",
          "183:     const float var_max = context->input(8).flat<float>()(0);",
          "185:     const float beta_min = context->input(10).flat<float>()(0);",
          "186:     const float beta_max = context->input(11).flat<float>()(0);",
          "188:     const float gamma_min = context->input(13).flat<float>()(0);",
          "189:     const float gamma_max = context->input(14).flat<float>()(0);",
          "",
          "[Added Lines]",
          "176:     const auto& input_min_tensor = context->input(1);",
          "177:     OP_REQUIRES(context, input_min_tensor.NumElements() == 1,",
          "178:                 errors::InvalidArgument(\"input_min must have 1 element\"));",
          "179:     const float input_min = input_min_tensor.flat<float>()(0);",
          "180:     const auto& input_max_tensor = context->input(2);",
          "181:     OP_REQUIRES(context, input_max_tensor.NumElements() == 1,",
          "182:                 errors::InvalidArgument(\"input_max must have 1 element\"));",
          "183:     const float input_max = input_max_tensor.flat<float>()(0);",
          "185:     const auto& mean_min_tensor = context->input(4);",
          "186:     OP_REQUIRES(context, mean_min_tensor.NumElements() == 1,",
          "187:                 errors::InvalidArgument(\"mean_min must have 1 element\"));",
          "188:     const float mean_min = mean_min_tensor.flat<float>()(0);",
          "189:     const auto& mean_max_tensor = context->input(5);",
          "190:     OP_REQUIRES(context, mean_max_tensor.NumElements() == 1,",
          "191:                 errors::InvalidArgument(\"mean_max must have 1 element\"));",
          "192:     const float mean_max = mean_max_tensor.flat<float>()(0);",
          "194:     const auto& var_min_tensor = context->input(7);",
          "195:     OP_REQUIRES(context, var_min_tensor.NumElements() == 1,",
          "196:                 errors::InvalidArgument(\"var_min must have 1 element\"));",
          "197:     const float var_min = var_min_tensor.flat<float>()(0);",
          "198:     const auto& var_max_tensor = context->input(8);",
          "199:     OP_REQUIRES(context, var_max_tensor.NumElements() == 1,",
          "200:                 errors::InvalidArgument(\"var_max must have 1 element\"));",
          "201:     const float var_max = var_max_tensor.flat<float>()(0);",
          "203:     const auto& beta_min_tensor = context->input(10);",
          "204:     OP_REQUIRES(context, beta_min_tensor.NumElements() == 1,",
          "205:                 errors::InvalidArgument(\"beta_min must have 1 element\"));",
          "206:     const float beta_min = beta_min_tensor.flat<float>()(0);",
          "207:     const auto& beta_max_tensor = context->input(11);",
          "208:     OP_REQUIRES(context, beta_max_tensor.NumElements() == 1,",
          "209:                 errors::InvalidArgument(\"beta_max must have 1 element\"));",
          "210:     const float beta_max = beta_max_tensor.flat<float>()(0);",
          "212:     const auto& gamma_min_tensor = context->input(13);",
          "213:     OP_REQUIRES(context, gamma_min_tensor.NumElements() == 1,",
          "214:                 errors::InvalidArgument(\"gamma_min must have 1 element\"));",
          "215:     const float gamma_min = gamma_min_tensor.flat<float>()(0);",
          "216:     const auto& gamma_max_tensor = context->input(14);",
          "217:     OP_REQUIRES(context, gamma_max_tensor.NumElements() == 1,",
          "218:                 errors::InvalidArgument(\"gamma_max must have 1 element\"));",
          "219:     const float gamma_max = gamma_max_tensor.flat<float>()(0);",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "203:     OP_REQUIRES(context, gamma.dims() == 1,",
          "204:                 errors::InvalidArgument(\"gamma must be 1-dimensional\",",
          "205:                                         gamma.shape().DebugString()));",
          "207:     Tensor* output = nullptr;",
          "208:     OP_REQUIRES_OK(context,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "236:     OP_REQUIRES(context, mean.NumElements() > 1,",
          "237:                 errors::InvalidArgument(\"Must have at least a mean value\",",
          "238:                                         gamma.shape().DebugString()));",
          "239:     OP_REQUIRES(context, mean.NumElements() > 1,",
          "240:                 errors::InvalidArgument(\"Must have at least a mean value\"));",
          "241:     const auto last_dim = input.shape().dims() - 1;",
          "242:     OP_REQUIRES(context,",
          "243:                 mean.shape().dim_size(0) == input.shape().dim_size(last_dim),",
          "244:                 errors::InvalidArgument(\"Must provide as many means as the \"",
          "245:                                         \"last dimension of the input tensor: \",",
          "246:                                         mean.shape().DebugString(), \" vs. \",",
          "247:                                         input.shape().DebugString()));",
          "248:     OP_REQUIRES(",
          "249:         context, mean.shape().dim_size(0) == var.shape().dim_size(0),",
          "250:         errors::InvalidArgument(",
          "251:             \"Mean and variance tensors must have the same shape: \",",
          "252:             mean.shape().DebugString(), \" vs. \", var.shape().DebugString()));",
          "253:     OP_REQUIRES(",
          "254:         context, mean.shape().dim_size(0) == beta.shape().dim_size(0),",
          "255:         errors::InvalidArgument(",
          "256:             \"Mean and beta tensors must have the same shape: \",",
          "257:             mean.shape().DebugString(), \" vs. \", beta.shape().DebugString()));",
          "258:     OP_REQUIRES(",
          "259:         context, mean.shape().dim_size(0) == gamma.shape().dim_size(0),",
          "260:         errors::InvalidArgument(",
          "261:             \"Mean and gamma tensors must have the same shape: \",",
          "262:             mean.shape().DebugString(), \" vs. \", gamma.shape().DebugString()));",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "57f9718251e7b39981308febf91a1650461445b3",
      "candidate_info": {
        "commit_hash": "57f9718251e7b39981308febf91a1650461445b3",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/57f9718251e7b39981308febf91a1650461445b3",
        "files": [
          "tensorflow/core/kernels/quantized_batch_norm_op.cc"
        ],
        "message": "Add missing validation in `QuantizedBatchNormWithGlobalNormalization`\n\nPiperOrigin-RevId: 370123451\nChange-Id: Id234d6dab1ec21230bb8e503dba30f899af87f33",
        "before_after_code_files": [
          "tensorflow/core/kernels/quantized_batch_norm_op.cc||tensorflow/core/kernels/quantized_batch_norm_op.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/quantized_batch_norm_op.cc||tensorflow/core/kernels/quantized_batch_norm_op.cc"
          ],
          "candidate": [
            "tensorflow/core/kernels/quantized_batch_norm_op.cc||tensorflow/core/kernels/quantized_batch_norm_op.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/quantized_batch_norm_op.cc||tensorflow/core/kernels/quantized_batch_norm_op.cc": [
          "File: tensorflow/core/kernels/quantized_batch_norm_op.cc -> tensorflow/core/kernels/quantized_batch_norm_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "174:   void Compute(OpKernelContext* context) override {",
          "175:     const Tensor& input = context->input(0);",
          "178:     const Tensor& mean = context->input(3);",
          "181:     const Tensor& var = context->input(6);",
          "184:     const Tensor& beta = context->input(9);",
          "187:     const Tensor& gamma = context->input(12);",
          "191:     OP_REQUIRES(context, input.dims() == 4,",
          "192:                 errors::InvalidArgument(\"input must be 4-dimensional\",",
          "",
          "[Removed Lines]",
          "176:     const float input_min = context->input(1).flat<float>()(0);",
          "177:     const float input_max = context->input(2).flat<float>()(0);",
          "179:     const float mean_min = context->input(4).flat<float>()(0);",
          "180:     const float mean_max = context->input(5).flat<float>()(0);",
          "182:     const float var_min = context->input(7).flat<float>()(0);",
          "183:     const float var_max = context->input(8).flat<float>()(0);",
          "185:     const float beta_min = context->input(10).flat<float>()(0);",
          "186:     const float beta_max = context->input(11).flat<float>()(0);",
          "188:     const float gamma_min = context->input(13).flat<float>()(0);",
          "189:     const float gamma_max = context->input(14).flat<float>()(0);",
          "",
          "[Added Lines]",
          "176:     const auto& input_min_tensor = context->input(1);",
          "177:     OP_REQUIRES(context, input_min_tensor.NumElements() == 1,",
          "178:                 errors::InvalidArgument(\"input_min must have 1 element\"));",
          "179:     const float input_min = input_min_tensor.flat<float>()(0);",
          "180:     const auto& input_max_tensor = context->input(2);",
          "181:     OP_REQUIRES(context, input_max_tensor.NumElements() == 1,",
          "182:                 errors::InvalidArgument(\"input_max must have 1 element\"));",
          "183:     const float input_max = input_max_tensor.flat<float>()(0);",
          "185:     const auto& mean_min_tensor = context->input(4);",
          "186:     OP_REQUIRES(context, mean_min_tensor.NumElements() == 1,",
          "187:                 errors::InvalidArgument(\"mean_min must have 1 element\"));",
          "188:     const float mean_min = mean_min_tensor.flat<float>()(0);",
          "189:     const auto& mean_max_tensor = context->input(5);",
          "190:     OP_REQUIRES(context, mean_max_tensor.NumElements() == 1,",
          "191:                 errors::InvalidArgument(\"mean_max must have 1 element\"));",
          "192:     const float mean_max = mean_max_tensor.flat<float>()(0);",
          "194:     const auto& var_min_tensor = context->input(7);",
          "195:     OP_REQUIRES(context, var_min_tensor.NumElements() == 1,",
          "196:                 errors::InvalidArgument(\"var_min must have 1 element\"));",
          "197:     const float var_min = var_min_tensor.flat<float>()(0);",
          "198:     const auto& var_max_tensor = context->input(8);",
          "199:     OP_REQUIRES(context, var_max_tensor.NumElements() == 1,",
          "200:                 errors::InvalidArgument(\"var_max must have 1 element\"));",
          "201:     const float var_max = var_max_tensor.flat<float>()(0);",
          "203:     const auto& beta_min_tensor = context->input(10);",
          "204:     OP_REQUIRES(context, beta_min_tensor.NumElements() == 1,",
          "205:                 errors::InvalidArgument(\"beta_min must have 1 element\"));",
          "206:     const float beta_min = beta_min_tensor.flat<float>()(0);",
          "207:     const auto& beta_max_tensor = context->input(11);",
          "208:     OP_REQUIRES(context, beta_max_tensor.NumElements() == 1,",
          "209:                 errors::InvalidArgument(\"beta_max must have 1 element\"));",
          "210:     const float beta_max = beta_max_tensor.flat<float>()(0);",
          "212:     const auto& gamma_min_tensor = context->input(13);",
          "213:     OP_REQUIRES(context, gamma_min_tensor.NumElements() == 1,",
          "214:                 errors::InvalidArgument(\"gamma_min must have 1 element\"));",
          "215:     const float gamma_min = gamma_min_tensor.flat<float>()(0);",
          "216:     const auto& gamma_max_tensor = context->input(14);",
          "217:     OP_REQUIRES(context, gamma_max_tensor.NumElements() == 1,",
          "218:                 errors::InvalidArgument(\"gamma_max must have 1 element\"));",
          "219:     const float gamma_max = gamma_max_tensor.flat<float>()(0);",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "203:     OP_REQUIRES(context, gamma.dims() == 1,",
          "204:                 errors::InvalidArgument(\"gamma must be 1-dimensional\",",
          "205:                                         gamma.shape().DebugString()));",
          "207:     Tensor* output = nullptr;",
          "208:     OP_REQUIRES_OK(context,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "236:     OP_REQUIRES(context, mean.NumElements() > 1,",
          "237:                 errors::InvalidArgument(\"Must have at least a mean value\",",
          "238:                                         gamma.shape().DebugString()));",
          "239:     OP_REQUIRES(context, mean.NumElements() > 1,",
          "240:                 errors::InvalidArgument(\"Must have at least a mean value\"));",
          "241:     const auto last_dim = input.shape().dims() - 1;",
          "242:     OP_REQUIRES(context,",
          "243:                 mean.shape().dim_size(0) == input.shape().dim_size(last_dim),",
          "244:                 errors::InvalidArgument(\"Must provide as many means as the \"",
          "245:                                         \"last dimension of the input tensor: \",",
          "246:                                         mean.shape().DebugString(), \" vs. \",",
          "247:                                         input.shape().DebugString()));",
          "248:     OP_REQUIRES(",
          "249:         context, mean.shape().dim_size(0) == var.shape().dim_size(0),",
          "250:         errors::InvalidArgument(",
          "251:             \"Mean and variance tensors must have the same shape: \",",
          "252:             mean.shape().DebugString(), \" vs. \", var.shape().DebugString()));",
          "253:     OP_REQUIRES(",
          "254:         context, mean.shape().dim_size(0) == beta.shape().dim_size(0),",
          "255:         errors::InvalidArgument(",
          "256:             \"Mean and beta tensors must have the same shape: \",",
          "257:             mean.shape().DebugString(), \" vs. \", beta.shape().DebugString()));",
          "258:     OP_REQUIRES(",
          "259:         context, mean.shape().dim_size(0) == gamma.shape().dim_size(0),",
          "260:         errors::InvalidArgument(",
          "261:             \"Mean and gamma tensors must have the same shape: \",",
          "262:             mean.shape().DebugString(), \" vs. \", gamma.shape().DebugString()));",
          "",
          "---------------"
        ]
      }
    }
  ]
}