{
  "cve_id": "CVE-2020-15205",
  "cve_desc": "In Tensorflow before versions 1.15.4, 2.0.3, 2.1.2, 2.2.1 and 2.3.1, the `data_splits` argument of `tf.raw_ops.StringNGrams` lacks validation. This allows a user to pass values that can cause heap overflow errors and even leak contents of memory In the linked code snippet, all the binary strings after `ee ff` are contents from the memory stack. Since these can contain return addresses, this data leak can be used to defeat ASLR. The issue is patched in commit 0462de5b544ed4731aa2fb23946ac22c01856b80, and is released in TensorFlow versions 1.15.4, 2.0.3, 2.1.2, 2.2.1, or 2.3.1.",
  "repo": "tensorflow/tensorflow",
  "patch_hash": "0462de5b544ed4731aa2fb23946ac22c01856b80",
  "patch_info": {
    "commit_hash": "0462de5b544ed4731aa2fb23946ac22c01856b80",
    "repo": "tensorflow/tensorflow",
    "commit_url": "https://github.com/tensorflow/tensorflow/commit/0462de5b544ed4731aa2fb23946ac22c01856b80",
    "files": [
      "tensorflow/core/kernels/string_ngrams_op.cc",
      "tensorflow/python/ops/raw_ops_test.py"
    ],
    "message": "Validate `data_splits` for `tf.StringNGrams`.\n\nWithout validation, we can cause a heap buffer overflow which results in data leakage and/or segfaults.\n\nPiperOrigin-RevId: 332543478\nChange-Id: Iee5bda24497a195d09d122355502480830b1b317",
    "before_after_code_files": [
      "tensorflow/core/kernels/string_ngrams_op.cc||tensorflow/core/kernels/string_ngrams_op.cc",
      "tensorflow/python/ops/raw_ops_test.py||tensorflow/python/ops/raw_ops_test.py"
    ]
  },
  "patch_diff": {
    "tensorflow/core/kernels/string_ngrams_op.cc||tensorflow/core/kernels/string_ngrams_op.cc": [
      "File: tensorflow/core/kernels/string_ngrams_op.cc -> tensorflow/core/kernels/string_ngrams_op.cc",
      "--- Hunk 1 ---",
      "[Context before]",
      "19: #include \"absl/strings/ascii.h\"",
      "20: #include \"absl/strings/str_cat.h\"",
      "21: #include \"tensorflow/core/framework/op_kernel.h\"",
      "23: namespace tensorflow {",
      "24: namespace text {",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "22: #include \"tensorflow/core/platform/errors.h\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "60:     OP_REQUIRES_OK(context, context->input(\"data_splits\", &splits));",
      "61:     const auto& splits_vec = splits->flat<SPLITS_TYPE>();",
      "63:     int num_batch_items = splits_vec.size() - 1;",
      "64:     tensorflow::Tensor* ngrams_splits;",
      "65:     OP_REQUIRES_OK(",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "65:     const int input_data_size = data->flat<tstring>().size();",
      "66:     const int splits_vec_size = splits_vec.size();",
      "67:     for (int i = 0; i < splits_vec_size; ++i) {",
      "68:       bool valid_splits = splits_vec(i) >= 0;",
      "69:       valid_splits = valid_splits && (splits_vec(i) <= input_data_size);",
      "70:       OP_REQUIRES(",
      "71:           context, valid_splits,",
      "72:           errors::InvalidArgument(\"Invalid split value \", splits_vec(i),",
      "73:                                   \", must be in [0,\", input_data_size, \"]\"));",
      "74:     }",
      "",
      "---------------"
    ],
    "tensorflow/python/ops/raw_ops_test.py||tensorflow/python/ops/raw_ops_test.py": [
      "File: tensorflow/python/ops/raw_ops_test.py -> tensorflow/python/ops/raw_ops_test.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "18: from __future__ import division",
      "19: from __future__ import print_function",
      "21: from tensorflow.python.eager import context",
      "22: from tensorflow.python.framework import constant_op",
      "23: from tensorflow.python.framework import ops",
      "24: from tensorflow.python.framework import test_util",
      "25: from tensorflow.python.ops import gen_math_ops",
      "26: from tensorflow.python.platform import test",
      "29: @test_util.run_all_in_graph_and_eager_modes",
      "32:   def testSimple(self):",
      "33:     x = constant_op.constant(1)",
      "",
      "[Removed Lines]",
      "30: class RawOpsTest(test.TestCase):",
      "",
      "[Added Lines]",
      "21: from absl.testing import parameterized",
      "25: from tensorflow.python.framework import errors",
      "29: from tensorflow.python.ops import gen_string_ops",
      "34: @test_util.disable_tfrt",
      "35: class RawOpsTest(test.TestCase, parameterized.TestCase):",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "58:         gen_math_ops.Any(input=x, axis=0),",
      "59:         gen_math_ops.Any(input=x, axis=0, keep_dims=False))",
      "62: if __name__ == \"__main__\":",
      "63:   ops.enable_eager_execution()",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "66:   @parameterized.parameters([[0, 8]], [[-1, 6]])",
      "67:   def testStringNGramsBadDataSplits(self, splits):",
      "68:     data = [\"aa\", \"bb\", \"cc\", \"dd\", \"ee\", \"ff\"]",
      "69:     with self.assertRaisesRegex(errors.InvalidArgumentError,",
      "70:                                 \"Invalid split value\"):",
      "71:       self.evaluate(",
      "72:           gen_string_ops.string_n_grams(",
      "73:               data=data,",
      "74:               data_splits=splits,",
      "75:               separator=\"\",",
      "76:               ngram_widths=[2],",
      "77:               left_pad=\"\",",
      "78:               right_pad=\"\",",
      "79:               pad_width=0,",
      "80:               preserve_short_sequences=False))",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "67c8f05fc6ad9ae8652fdf1b75509638c859682c",
      "candidate_info": {
        "commit_hash": "67c8f05fc6ad9ae8652fdf1b75509638c859682c",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/67c8f05fc6ad9ae8652fdf1b75509638c859682c",
        "files": [
          "tensorflow/core/kernels/string_ngrams_op.cc",
          "tensorflow/core/kernels/string_ngrams_op_test.cc"
        ],
        "message": "Enhance validation of ngram op and handle case of 0 tokens.\n\nPiperOrigin-RevId: 369940178\nChange-Id: Ia82f42c09d14efe76e7dc013505b832a42282f0b",
        "before_after_code_files": [
          "tensorflow/core/kernels/string_ngrams_op.cc||tensorflow/core/kernels/string_ngrams_op.cc",
          "tensorflow/core/kernels/string_ngrams_op_test.cc||tensorflow/core/kernels/string_ngrams_op_test.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/string_ngrams_op.cc||tensorflow/core/kernels/string_ngrams_op.cc"
          ],
          "candidate": [
            "tensorflow/core/kernels/string_ngrams_op.cc||tensorflow/core/kernels/string_ngrams_op.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/string_ngrams_op.cc||tensorflow/core/kernels/string_ngrams_op.cc": [
          "File: tensorflow/core/kernels/string_ngrams_op.cc -> tensorflow/core/kernels/string_ngrams_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "61:     OP_REQUIRES_OK(context, context->input(\"data_splits\", &splits));",
          "62:     const auto& splits_vec = splits->flat<SPLITS_TYPE>();",
          "65:     const int input_data_size = data->flat<tstring>().size();",
          "66:     const int splits_vec_size = splits_vec.size();",
          "74:     }",
          "76:     int num_batch_items = splits_vec.size() - 1;",
          "",
          "[Removed Lines]",
          "67:     for (int i = 0; i < splits_vec_size; ++i) {",
          "68:       bool valid_splits = splits_vec(i) >= 0;",
          "69:       valid_splits = valid_splits && (splits_vec(i) <= input_data_size);",
          "70:       OP_REQUIRES(",
          "71:           context, valid_splits,",
          "72:           errors::InvalidArgument(\"Invalid split value \", splits_vec(i),",
          "73:                                   \", must be in [0,\", input_data_size, \"]\"));",
          "",
          "[Added Lines]",
          "68:     if (splits_vec_size > 0) {",
          "69:       int prev_split = splits_vec(0);",
          "70:       OP_REQUIRES(context, prev_split == 0,",
          "71:                   errors::InvalidArgument(\"First split value must be 0, got \",",
          "72:                                           prev_split));",
          "73:       for (int i = 1; i < splits_vec_size; ++i) {",
          "74:         bool valid_splits = splits_vec(i) >= prev_split;",
          "75:         valid_splits = valid_splits && (splits_vec(i) <= input_data_size);",
          "76:         OP_REQUIRES(context, valid_splits,",
          "77:                     errors::InvalidArgument(",
          "78:                         \"Invalid split value \", splits_vec(i), \", must be in [\",",
          "79:                         prev_split, \", \", input_data_size, \"]\"));",
          "80:         prev_split = splits_vec(i);",
          "81:       }",
          "82:       OP_REQUIRES(context, prev_split == input_data_size,",
          "83:                   errors::InvalidArgument(",
          "84:                       \"Last split value must be data size. Expected \",",
          "85:                       input_data_size, \", got \", prev_split));",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "174:         ngram->append(left_pad_);",
          "175:         ngram->append(separator_);",
          "176:       }",
          "177:       for (int n = 0; n < num_tokens - 1; ++n) {",
          "178:         ngram->append(data[data_start_index + n]);",
          "179:         ngram->append(separator_);",
          "180:       }",
          "184:         ngram->append(right_pad_);",
          "185:       }",
          "",
          "[Removed Lines]",
          "181:       ngram->append(data[data_start_index + num_tokens - 1]);",
          "182:       for (int n = 0; n < right_padding; ++n) {",
          "183:         ngram->append(separator_);",
          "",
          "[Added Lines]",
          "196:       if (num_tokens > 0) {",
          "200:         ngram->append(data[data_start_index + num_tokens - 1]);",
          "201:         for (int n = 0; n < right_padding; ++n) {",
          "202:           ngram->append(separator_);",
          "203:           ngram->append(right_pad_);",
          "204:         }",
          "205:       } else {",
          "210:         for (int n = 0; n < right_padding - 1; ++n) {",
          "211:           ngram->append(right_pad_);",
          "212:           ngram->append(separator_);",
          "213:         }",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/string_ngrams_op_test.cc||tensorflow/core/kernels/string_ngrams_op_test.cc": [
          "File: tensorflow/core/kernels/string_ngrams_op_test.cc -> tensorflow/core/kernels/string_ngrams_op_test.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "542:   assert_int64_equal(expected_splits, *GetOutput(1));",
          "543: }",
          "545: TEST_F(NgramKernelTest, ShapeFn) {",
          "546:   ShapeInferenceTestOp op(\"StringNGrams\");",
          "547:   INFER_OK(op, \"?;?\", \"[?];[?]\");",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "545: TEST_F(NgramKernelTest, TestNoTokens) {",
          "546:   MakeOp(\"|\", {3}, \"L\", \"R\", -1, false);",
          "550:   AddInputFromArray<tstring>(TensorShape({1}), {\"a\"});",
          "551:   AddInputFromArray<int64>(TensorShape({3}), {0, 0, 1});",
          "552:   TF_ASSERT_OK(RunOpKernel());",
          "554:   std::vector<tstring> expected_values(",
          "555:       {\"L|L|R\", \"L|R|R\",             // no input in first split",
          "556:        \"L|L|a\", \"L|a|R\", \"a|R|R\"});  // second split",
          "557:   std::vector<int64> expected_splits({0, 2, 5});",
          "559:   assert_string_equal(expected_values, *GetOutput(0));",
          "560:   assert_int64_equal(expected_splits, *GetOutput(1));",
          "561: }",
          "563: TEST_F(NgramKernelTest, TestNoTokensNoPad) {",
          "564:   MakeOp(\"|\", {3}, \"\", \"\", 0, false);",
          "568:   AddInputFromArray<tstring>(TensorShape({1}), {\"a\"});",
          "569:   AddInputFromArray<int64>(TensorShape({3}), {0, 0, 1});",
          "570:   TF_ASSERT_OK(RunOpKernel());",
          "572:   std::vector<tstring> expected_values({});",
          "573:   std::vector<int64> expected_splits({0, 0, 0});",
          "575:   assert_string_equal(expected_values, *GetOutput(0));",
          "576:   assert_int64_equal(expected_splits, *GetOutput(1));",
          "577: }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "ba424dd8f16f7110eea526a8086f1a155f14f22b",
      "candidate_info": {
        "commit_hash": "ba424dd8f16f7110eea526a8086f1a155f14f22b",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/ba424dd8f16f7110eea526a8086f1a155f14f22b",
        "files": [
          "tensorflow/core/kernels/string_ngrams_op.cc",
          "tensorflow/core/kernels/string_ngrams_op_test.cc"
        ],
        "message": "Enhance validation of ngram op and handle case of 0 tokens.\n\nPiperOrigin-RevId: 369940178\nChange-Id: Ia82f42c09d14efe76e7dc013505b832a42282f0b",
        "before_after_code_files": [
          "tensorflow/core/kernels/string_ngrams_op.cc||tensorflow/core/kernels/string_ngrams_op.cc",
          "tensorflow/core/kernels/string_ngrams_op_test.cc||tensorflow/core/kernels/string_ngrams_op_test.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/string_ngrams_op.cc||tensorflow/core/kernels/string_ngrams_op.cc"
          ],
          "candidate": [
            "tensorflow/core/kernels/string_ngrams_op.cc||tensorflow/core/kernels/string_ngrams_op.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/string_ngrams_op.cc||tensorflow/core/kernels/string_ngrams_op.cc": [
          "File: tensorflow/core/kernels/string_ngrams_op.cc -> tensorflow/core/kernels/string_ngrams_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "61:     OP_REQUIRES_OK(context, context->input(\"data_splits\", &splits));",
          "62:     const auto& splits_vec = splits->flat<SPLITS_TYPE>();",
          "65:     const int input_data_size = data->flat<tstring>().size();",
          "66:     const int splits_vec_size = splits_vec.size();",
          "74:     }",
          "76:     int num_batch_items = splits_vec.size() - 1;",
          "",
          "[Removed Lines]",
          "67:     for (int i = 0; i < splits_vec_size; ++i) {",
          "68:       bool valid_splits = splits_vec(i) >= 0;",
          "69:       valid_splits = valid_splits && (splits_vec(i) <= input_data_size);",
          "70:       OP_REQUIRES(",
          "71:           context, valid_splits,",
          "72:           errors::InvalidArgument(\"Invalid split value \", splits_vec(i),",
          "73:                                   \", must be in [0,\", input_data_size, \"]\"));",
          "",
          "[Added Lines]",
          "68:     if (splits_vec_size > 0) {",
          "69:       int prev_split = splits_vec(0);",
          "70:       OP_REQUIRES(context, prev_split == 0,",
          "71:                   errors::InvalidArgument(\"First split value must be 0, got \",",
          "72:                                           prev_split));",
          "73:       for (int i = 1; i < splits_vec_size; ++i) {",
          "74:         bool valid_splits = splits_vec(i) >= prev_split;",
          "75:         valid_splits = valid_splits && (splits_vec(i) <= input_data_size);",
          "76:         OP_REQUIRES(context, valid_splits,",
          "77:                     errors::InvalidArgument(",
          "78:                         \"Invalid split value \", splits_vec(i), \", must be in [\",",
          "79:                         prev_split, \", \", input_data_size, \"]\"));",
          "80:         prev_split = splits_vec(i);",
          "81:       }",
          "82:       OP_REQUIRES(context, prev_split == input_data_size,",
          "83:                   errors::InvalidArgument(",
          "84:                       \"Last split value must be data size. Expected \",",
          "85:                       input_data_size, \", got \", prev_split));",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "174:         ngram->append(left_pad_);",
          "175:         ngram->append(separator_);",
          "176:       }",
          "177:       for (int n = 0; n < num_tokens - 1; ++n) {",
          "178:         ngram->append(data[data_start_index + n]);",
          "179:         ngram->append(separator_);",
          "180:       }",
          "184:         ngram->append(right_pad_);",
          "185:       }",
          "",
          "[Removed Lines]",
          "181:       ngram->append(data[data_start_index + num_tokens - 1]);",
          "182:       for (int n = 0; n < right_padding; ++n) {",
          "183:         ngram->append(separator_);",
          "",
          "[Added Lines]",
          "196:       if (num_tokens > 0) {",
          "200:         ngram->append(data[data_start_index + num_tokens - 1]);",
          "201:         for (int n = 0; n < right_padding; ++n) {",
          "202:           ngram->append(separator_);",
          "203:           ngram->append(right_pad_);",
          "204:         }",
          "205:       } else {",
          "210:         for (int n = 0; n < right_padding - 1; ++n) {",
          "211:           ngram->append(right_pad_);",
          "212:           ngram->append(separator_);",
          "213:         }",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/string_ngrams_op_test.cc||tensorflow/core/kernels/string_ngrams_op_test.cc": [
          "File: tensorflow/core/kernels/string_ngrams_op_test.cc -> tensorflow/core/kernels/string_ngrams_op_test.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "542:   assert_int64_equal(expected_splits, *GetOutput(1));",
          "543: }",
          "545: TEST_F(NgramKernelTest, ShapeFn) {",
          "546:   ShapeInferenceTestOp op(\"StringNGrams\");",
          "547:   INFER_OK(op, \"?;?\", \"[?];[?]\");",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "545: TEST_F(NgramKernelTest, TestNoTokens) {",
          "546:   MakeOp(\"|\", {3}, \"L\", \"R\", -1, false);",
          "550:   AddInputFromArray<tstring>(TensorShape({1}), {\"a\"});",
          "551:   AddInputFromArray<int64>(TensorShape({3}), {0, 0, 1});",
          "552:   TF_ASSERT_OK(RunOpKernel());",
          "554:   std::vector<tstring> expected_values(",
          "555:       {\"L|L|R\", \"L|R|R\",             // no input in first split",
          "556:        \"L|L|a\", \"L|a|R\", \"a|R|R\"});  // second split",
          "557:   std::vector<int64> expected_splits({0, 2, 5});",
          "559:   assert_string_equal(expected_values, *GetOutput(0));",
          "560:   assert_int64_equal(expected_splits, *GetOutput(1));",
          "561: }",
          "563: TEST_F(NgramKernelTest, TestNoTokensNoPad) {",
          "564:   MakeOp(\"|\", {3}, \"\", \"\", 0, false);",
          "568:   AddInputFromArray<tstring>(TensorShape({1}), {\"a\"});",
          "569:   AddInputFromArray<int64>(TensorShape({3}), {0, 0, 1});",
          "570:   TF_ASSERT_OK(RunOpKernel());",
          "572:   std::vector<tstring> expected_values({});",
          "573:   std::vector<int64> expected_splits({0, 0, 0});",
          "575:   assert_string_equal(expected_values, *GetOutput(0));",
          "576:   assert_int64_equal(expected_splits, *GetOutput(1));",
          "577: }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "b9cc6d1746e0914b7efe9ba1a755e99ff5a9860d",
      "candidate_info": {
        "commit_hash": "b9cc6d1746e0914b7efe9ba1a755e99ff5a9860d",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/b9cc6d1746e0914b7efe9ba1a755e99ff5a9860d",
        "files": [
          "tensorflow/core/kernels/string_ngrams_op.cc",
          "tensorflow/core/kernels/string_ngrams_op_test.cc"
        ],
        "message": "Enhance validation of ngram op and handle case of 0 tokens.\n\nPiperOrigin-RevId: 369940178\nChange-Id: Ia82f42c09d14efe76e7dc013505b832a42282f0b",
        "before_after_code_files": [
          "tensorflow/core/kernels/string_ngrams_op.cc||tensorflow/core/kernels/string_ngrams_op.cc",
          "tensorflow/core/kernels/string_ngrams_op_test.cc||tensorflow/core/kernels/string_ngrams_op_test.cc"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/string_ngrams_op.cc||tensorflow/core/kernels/string_ngrams_op.cc"
          ],
          "candidate": [
            "tensorflow/core/kernels/string_ngrams_op.cc||tensorflow/core/kernels/string_ngrams_op.cc"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/string_ngrams_op.cc||tensorflow/core/kernels/string_ngrams_op.cc": [
          "File: tensorflow/core/kernels/string_ngrams_op.cc -> tensorflow/core/kernels/string_ngrams_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "61:     OP_REQUIRES_OK(context, context->input(\"data_splits\", &splits));",
          "62:     const auto& splits_vec = splits->flat<SPLITS_TYPE>();",
          "65:     const int input_data_size = data->flat<tstring>().size();",
          "66:     const int splits_vec_size = splits_vec.size();",
          "74:     }",
          "76:     int num_batch_items = splits_vec.size() - 1;",
          "",
          "[Removed Lines]",
          "67:     for (int i = 0; i < splits_vec_size; ++i) {",
          "68:       bool valid_splits = splits_vec(i) >= 0;",
          "69:       valid_splits = valid_splits && (splits_vec(i) <= input_data_size);",
          "70:       OP_REQUIRES(",
          "71:           context, valid_splits,",
          "72:           errors::InvalidArgument(\"Invalid split value \", splits_vec(i),",
          "73:                                   \", must be in [0,\", input_data_size, \"]\"));",
          "",
          "[Added Lines]",
          "68:     if (splits_vec_size > 0) {",
          "69:       int prev_split = splits_vec(0);",
          "70:       OP_REQUIRES(context, prev_split == 0,",
          "71:                   errors::InvalidArgument(\"First split value must be 0, got \",",
          "72:                                           prev_split));",
          "73:       for (int i = 1; i < splits_vec_size; ++i) {",
          "74:         bool valid_splits = splits_vec(i) >= prev_split;",
          "75:         valid_splits = valid_splits && (splits_vec(i) <= input_data_size);",
          "76:         OP_REQUIRES(context, valid_splits,",
          "77:                     errors::InvalidArgument(",
          "78:                         \"Invalid split value \", splits_vec(i), \", must be in [\",",
          "79:                         prev_split, \", \", input_data_size, \"]\"));",
          "80:         prev_split = splits_vec(i);",
          "81:       }",
          "82:       OP_REQUIRES(context, prev_split == input_data_size,",
          "83:                   errors::InvalidArgument(",
          "84:                       \"Last split value must be data size. Expected \",",
          "85:                       input_data_size, \", got \", prev_split));",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "174:         ngram->append(left_pad_);",
          "175:         ngram->append(separator_);",
          "176:       }",
          "177:       for (int n = 0; n < num_tokens - 1; ++n) {",
          "178:         ngram->append(data[data_start_index + n]);",
          "179:         ngram->append(separator_);",
          "180:       }",
          "184:         ngram->append(right_pad_);",
          "185:       }",
          "",
          "[Removed Lines]",
          "181:       ngram->append(data[data_start_index + num_tokens - 1]);",
          "182:       for (int n = 0; n < right_padding; ++n) {",
          "183:         ngram->append(separator_);",
          "",
          "[Added Lines]",
          "196:       if (num_tokens > 0) {",
          "200:         ngram->append(data[data_start_index + num_tokens - 1]);",
          "201:         for (int n = 0; n < right_padding; ++n) {",
          "202:           ngram->append(separator_);",
          "203:           ngram->append(right_pad_);",
          "204:         }",
          "205:       } else {",
          "210:         for (int n = 0; n < right_padding - 1; ++n) {",
          "211:           ngram->append(right_pad_);",
          "212:           ngram->append(separator_);",
          "213:         }",
          "",
          "---------------"
        ],
        "tensorflow/core/kernels/string_ngrams_op_test.cc||tensorflow/core/kernels/string_ngrams_op_test.cc": [
          "File: tensorflow/core/kernels/string_ngrams_op_test.cc -> tensorflow/core/kernels/string_ngrams_op_test.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "542:   assert_int64_equal(expected_splits, *GetOutput(1));",
          "543: }",
          "545: TEST_F(NgramKernelTest, ShapeFn) {",
          "546:   ShapeInferenceTestOp op(\"StringNGrams\");",
          "547:   INFER_OK(op, \"?;?\", \"[?];[?]\");",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "545: TEST_F(NgramKernelTest, TestNoTokens) {",
          "546:   MakeOp(\"|\", {3}, \"L\", \"R\", -1, false);",
          "550:   AddInputFromArray<tstring>(TensorShape({1}), {\"a\"});",
          "551:   AddInputFromArray<int64>(TensorShape({3}), {0, 0, 1});",
          "552:   TF_ASSERT_OK(RunOpKernel());",
          "554:   std::vector<tstring> expected_values(",
          "555:       {\"L|L|R\", \"L|R|R\",             // no input in first split",
          "556:        \"L|L|a\", \"L|a|R\", \"a|R|R\"});  // second split",
          "557:   std::vector<int64> expected_splits({0, 2, 5});",
          "559:   assert_string_equal(expected_values, *GetOutput(0));",
          "560:   assert_int64_equal(expected_splits, *GetOutput(1));",
          "561: }",
          "563: TEST_F(NgramKernelTest, TestNoTokensNoPad) {",
          "564:   MakeOp(\"|\", {3}, \"\", \"\", 0, false);",
          "568:   AddInputFromArray<tstring>(TensorShape({1}), {\"a\"});",
          "569:   AddInputFromArray<int64>(TensorShape({3}), {0, 0, 1});",
          "570:   TF_ASSERT_OK(RunOpKernel());",
          "572:   std::vector<tstring> expected_values({});",
          "573:   std::vector<int64> expected_splits({0, 0, 0});",
          "575:   assert_string_equal(expected_values, *GetOutput(0));",
          "576:   assert_int64_equal(expected_splits, *GetOutput(1));",
          "577: }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "892d5e599f25a9b17befc54fb9be7e893bcd14b8",
      "candidate_info": {
        "commit_hash": "892d5e599f25a9b17befc54fb9be7e893bcd14b8",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/892d5e599f25a9b17befc54fb9be7e893bcd14b8",
        "files": [
          "tensorflow/core/kernels/string_ngrams_op.cc",
          "tensorflow/python/ops/raw_ops_test.py"
        ],
        "message": "Validate `data_splits` for `tf.StringNGrams`.\n\nWithout validation, we can cause a heap buffer overflow which results in data leakage and/or segfaults.\n\nPiperOrigin-RevId: 332543478\nChange-Id: Iee5bda24497a195d09d122355502480830b1b317",
        "before_after_code_files": [
          "tensorflow/core/kernels/string_ngrams_op.cc||tensorflow/core/kernels/string_ngrams_op.cc",
          "tensorflow/python/ops/raw_ops_test.py||tensorflow/python/ops/raw_ops_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/string_ngrams_op.cc||tensorflow/core/kernels/string_ngrams_op.cc",
            "tensorflow/python/ops/raw_ops_test.py||tensorflow/python/ops/raw_ops_test.py"
          ],
          "candidate": [
            "tensorflow/core/kernels/string_ngrams_op.cc||tensorflow/core/kernels/string_ngrams_op.cc",
            "tensorflow/python/ops/raw_ops_test.py||tensorflow/python/ops/raw_ops_test.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/string_ngrams_op.cc||tensorflow/core/kernels/string_ngrams_op.cc": [
          "File: tensorflow/core/kernels/string_ngrams_op.cc -> tensorflow/core/kernels/string_ngrams_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: #include \"absl/strings/ascii.h\"",
          "20: #include \"absl/strings/str_cat.h\"",
          "21: #include \"tensorflow/core/framework/op_kernel.h\"",
          "23: namespace tensorflow {",
          "24: namespace text {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "22: #include \"tensorflow/core/platform/errors.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "60:     OP_REQUIRES_OK(context, context->input(\"data_splits\", &splits));",
          "61:     const auto& splits_vec = splits->flat<SPLITS_TYPE>();",
          "63:     int num_batch_items = splits_vec.size() - 1;",
          "64:     tensorflow::Tensor* ngrams_splits;",
          "65:     OP_REQUIRES_OK(",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "65:     const int input_data_size = data->flat<tstring>().size();",
          "66:     const int splits_vec_size = splits_vec.size();",
          "67:     for (int i = 0; i < splits_vec_size; ++i) {",
          "68:       bool valid_splits = splits_vec(i) >= 0;",
          "69:       valid_splits = valid_splits && (splits_vec(i) <= input_data_size);",
          "70:       OP_REQUIRES(",
          "71:           context, valid_splits,",
          "72:           errors::InvalidArgument(\"Invalid split value \", splits_vec(i),",
          "73:                                   \", must be in [0,\", input_data_size, \"]\"));",
          "74:     }",
          "",
          "---------------"
        ],
        "tensorflow/python/ops/raw_ops_test.py||tensorflow/python/ops/raw_ops_test.py": [
          "File: tensorflow/python/ops/raw_ops_test.py -> tensorflow/python/ops/raw_ops_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: from __future__ import division",
          "19: from __future__ import print_function",
          "21: from tensorflow.python.eager import context",
          "22: from tensorflow.python.framework import constant_op",
          "23: from tensorflow.python.framework import ops",
          "24: from tensorflow.python.framework import test_util",
          "25: from tensorflow.python.ops import gen_math_ops",
          "26: from tensorflow.python.platform import test",
          "29: @test_util.run_all_in_graph_and_eager_modes",
          "32:   def testSimple(self):",
          "33:     x = constant_op.constant(1)",
          "",
          "[Removed Lines]",
          "30: class RawOpsTest(test.TestCase):",
          "",
          "[Added Lines]",
          "21: from absl.testing import parameterized",
          "25: from tensorflow.python.framework import errors",
          "29: from tensorflow.python.ops import gen_string_ops",
          "34: @test_util.disable_tfrt",
          "35: class RawOpsTest(test.TestCase, parameterized.TestCase):",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "58:         gen_math_ops.Any(input=x, axis=0),",
          "59:         gen_math_ops.Any(input=x, axis=0, keep_dims=False))",
          "62: if __name__ == \"__main__\":",
          "63:   ops.enable_eager_execution()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "66:   @parameterized.parameters([[0, 8]], [[-1, 6]])",
          "67:   def testStringNGramsBadDataSplits(self, splits):",
          "68:     data = [\"aa\", \"bb\", \"cc\", \"dd\", \"ee\", \"ff\"]",
          "69:     with self.assertRaisesRegex(errors.InvalidArgumentError,",
          "70:                                 \"Invalid split value\"):",
          "71:       self.evaluate(",
          "72:           gen_string_ops.string_n_grams(",
          "73:               data=data,",
          "74:               data_splits=splits,",
          "75:               separator=\"\",",
          "76:               ngram_widths=[2],",
          "77:               left_pad=\"\",",
          "78:               right_pad=\"\",",
          "79:               pad_width=0,",
          "80:               preserve_short_sequences=False))",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "4a436e156d4c27b0cd086d4a059c9549624a3b89",
      "candidate_info": {
        "commit_hash": "4a436e156d4c27b0cd086d4a059c9549624a3b89",
        "repo": "tensorflow/tensorflow",
        "commit_url": "https://github.com/tensorflow/tensorflow/commit/4a436e156d4c27b0cd086d4a059c9549624a3b89",
        "files": [
          "tensorflow/core/kernels/string_ngrams_op.cc",
          "tensorflow/python/ops/raw_ops_test.py"
        ],
        "message": "Validate `data_splits` for `tf.StringNGrams`.\n\nWithout validation, we can cause a heap buffer overflow which results in data leakage and/or segfaults.\n\nPiperOrigin-RevId: 332543478\nChange-Id: Iee5bda24497a195d09d122355502480830b1b317",
        "before_after_code_files": [
          "tensorflow/core/kernels/string_ngrams_op.cc||tensorflow/core/kernels/string_ngrams_op.cc",
          "tensorflow/python/ops/raw_ops_test.py||tensorflow/python/ops/raw_ops_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "tensorflow/core/kernels/string_ngrams_op.cc||tensorflow/core/kernels/string_ngrams_op.cc",
            "tensorflow/python/ops/raw_ops_test.py||tensorflow/python/ops/raw_ops_test.py"
          ],
          "candidate": [
            "tensorflow/core/kernels/string_ngrams_op.cc||tensorflow/core/kernels/string_ngrams_op.cc",
            "tensorflow/python/ops/raw_ops_test.py||tensorflow/python/ops/raw_ops_test.py"
          ]
        }
      },
      "candidate_diff": {
        "tensorflow/core/kernels/string_ngrams_op.cc||tensorflow/core/kernels/string_ngrams_op.cc": [
          "File: tensorflow/core/kernels/string_ngrams_op.cc -> tensorflow/core/kernels/string_ngrams_op.cc",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: #include \"absl/strings/ascii.h\"",
          "20: #include \"absl/strings/str_cat.h\"",
          "21: #include \"tensorflow/core/framework/op_kernel.h\"",
          "23: namespace tensorflow {",
          "24: namespace text {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "22: #include \"tensorflow/core/platform/errors.h\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "60:     OP_REQUIRES_OK(context, context->input(\"data_splits\", &splits));",
          "61:     const auto& splits_vec = splits->flat<SPLITS_TYPE>();",
          "64:     if (data->flat<tstring>().size() == 0 || splits_vec.size() == 0) {",
          "65:       tensorflow::Tensor* empty;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "65:     const int input_data_size = data->flat<tstring>().size();",
          "66:     const int splits_vec_size = splits_vec.size();",
          "67:     for (int i = 0; i < splits_vec_size; ++i) {",
          "68:       bool valid_splits = splits_vec(i) >= 0;",
          "69:       valid_splits = valid_splits && (splits_vec(i) <= input_data_size);",
          "70:       OP_REQUIRES(",
          "71:           context, valid_splits,",
          "72:           errors::InvalidArgument(\"Invalid split value \", splits_vec(i),",
          "73:                                   \", must be in [0,\", input_data_size, \"]\"));",
          "74:     }",
          "",
          "---------------"
        ],
        "tensorflow/python/ops/raw_ops_test.py||tensorflow/python/ops/raw_ops_test.py": [
          "File: tensorflow/python/ops/raw_ops_test.py -> tensorflow/python/ops/raw_ops_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: from __future__ import division",
          "19: from __future__ import print_function",
          "21: from tensorflow.python.eager import context",
          "22: from tensorflow.python.framework import constant_op",
          "23: from tensorflow.python.framework import ops",
          "24: from tensorflow.python.framework import test_util",
          "25: from tensorflow.python.ops import gen_math_ops",
          "26: from tensorflow.python.platform import test",
          "29: @test_util.run_all_in_graph_and_eager_modes",
          "32:   def testSimple(self):",
          "33:     x = constant_op.constant(1)",
          "",
          "[Removed Lines]",
          "30: class RawOpsTest(test.TestCase):",
          "",
          "[Added Lines]",
          "21: from absl.testing import parameterized",
          "25: from tensorflow.python.framework import errors",
          "29: from tensorflow.python.ops import gen_string_ops",
          "34: @test_util.disable_tfrt",
          "35: class RawOpsTest(test.TestCase, parameterized.TestCase):",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "58:         gen_math_ops.Any(input=x, axis=0),",
          "59:         gen_math_ops.Any(input=x, axis=0, keep_dims=False))",
          "62: if __name__ == \"__main__\":",
          "63:   ops.enable_eager_execution()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "66:   @parameterized.parameters([[0, 8]], [[-1, 6]])",
          "67:   def testStringNGramsBadDataSplits(self, splits):",
          "68:     data = [\"aa\", \"bb\", \"cc\", \"dd\", \"ee\", \"ff\"]",
          "69:     with self.assertRaisesRegex(errors.InvalidArgumentError,",
          "70:                                 \"Invalid split value\"):",
          "71:       self.evaluate(",
          "72:           gen_string_ops.string_n_grams(",
          "73:               data=data,",
          "74:               data_splits=splits,",
          "75:               separator=\"\",",
          "76:               ngram_widths=[2],",
          "77:               left_pad=\"\",",
          "78:               right_pad=\"\",",
          "79:               pad_width=0,",
          "80:               preserve_short_sequences=False))",
          "",
          "---------------"
        ]
      }
    }
  ]
}