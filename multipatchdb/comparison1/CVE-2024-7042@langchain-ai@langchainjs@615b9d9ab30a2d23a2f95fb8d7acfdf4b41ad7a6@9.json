{
  "cve_id": "CVE-2024-7042",
  "cve_desc": "A vulnerability in the GraphCypherQAChain class of langchain-ai/langchainjs versions 0.2.5 and all versions with this class allows for prompt injection, leading to SQL injection. This vulnerability permits unauthorized data manipulation, data exfiltration, denial of service (DoS) by deleting all data, breaches in multi-tenant security environments, and data integrity issues. Attackers can create, update, or delete nodes and relationships without proper authorization, extract sensitive data, disrupt services, access data across different tenants, and compromise the integrity of the database.",
  "repo": "langchain-ai/langchainjs",
  "patch_hash": "615b9d9ab30a2d23a2f95fb8d7acfdf4b41ad7a6",
  "patch_info": {
    "commit_hash": "615b9d9ab30a2d23a2f95fb8d7acfdf4b41ad7a6",
    "repo": "langchain-ai/langchainjs",
    "commit_url": "https://github.com/langchain-ai/langchainjs/commit/615b9d9ab30a2d23a2f95fb8d7acfdf4b41ad7a6",
    "files": [
      "examples/package.json",
      "examples/src/indexes/vector_stores/lancedb/fromDocs.ts",
      "examples/src/indexes/vector_stores/lancedb/fromTexts.ts",
      "libs/langchain-community/package.json",
      "libs/langchain-community/src/vectorstores/lancedb.ts",
      "libs/langchain-community/src/vectorstores/tests/lancedb.int.test.ts",
      "yarn.lock"
    ],
    "message": "feat(community): Remove required param from LanceDB integration (#6706)\n\nCo-authored-by: jacoblee93 <jacoblee93@gmail.com>",
    "before_after_code_files": [
      "examples/src/indexes/vector_stores/lancedb/fromDocs.ts||examples/src/indexes/vector_stores/lancedb/fromDocs.ts",
      "examples/src/indexes/vector_stores/lancedb/fromTexts.ts||examples/src/indexes/vector_stores/lancedb/fromTexts.ts",
      "libs/langchain-community/src/vectorstores/lancedb.ts||libs/langchain-community/src/vectorstores/lancedb.ts",
      "libs/langchain-community/src/vectorstores/tests/lancedb.int.test.ts||libs/langchain-community/src/vectorstores/tests/lancedb.int.test.ts",
      "yarn.lock||yarn.lock"
    ]
  },
  "patch_diff": {
    "examples/src/indexes/vector_stores/lancedb/fromDocs.ts||examples/src/indexes/vector_stores/lancedb/fromDocs.ts": [
      "File: examples/src/indexes/vector_stores/lancedb/fromDocs.ts -> examples/src/indexes/vector_stores/lancedb/fromDocs.ts",
      "--- Hunk 1 ---",
      "[Context before]",
      "4: import fs from \"node:fs/promises\";",
      "5: import path from \"node:path\";",
      "6: import os from \"node:os\";",
      "10: const loader = new TextLoader(\"src/document_loaders/example_data/example.txt\");",
      "11: const docs = await loader.load();",
      "13: export const run = async () => {",
      "14:   const dir = await fs.mkdtemp(path.join(os.tmpdir(), \"lancedb-\"));",
      "26:   const resultOne = await vectorStore.similaritySearch(\"hello world\", 1);",
      "27:   console.log(resultOne);",
      "",
      "[Removed Lines]",
      "7: import { connect } from \"vectordb\";",
      "15:   const db = await connect(dir);",
      "16:   const table = await db.createTable(\"vectors\", [",
      "17:     { vector: Array(1536), text: \"sample\", source: \"a\" },",
      "18:   ]);",
      "20:   const vectorStore = await LanceDB.fromDocuments(",
      "21:     docs,",
      "22:     new OpenAIEmbeddings(),",
      "23:     { table }",
      "24:   );",
      "",
      "[Added Lines]",
      "13:   const vectorStore = await LanceDB.fromDocuments(docs, new OpenAIEmbeddings());",
      "15:   const resultOne = await vectorStore.similaritySearch(\"hello world\", 1);",
      "16:   console.log(resultOne);",
      "24: };",
      "26: export const run_with_existing_table = async () => {",
      "29:   const vectorStore = await LanceDB.fromDocuments(docs, new OpenAIEmbeddings());",
      "",
      "---------------"
    ],
    "examples/src/indexes/vector_stores/lancedb/fromTexts.ts||examples/src/indexes/vector_stores/lancedb/fromTexts.ts": [
      "File: examples/src/indexes/vector_stores/lancedb/fromTexts.ts -> examples/src/indexes/vector_stores/lancedb/fromTexts.ts",
      "--- Hunk 1 ---",
      "[Context before]",
      "1: import { LanceDB } from \"@langchain/community/vectorstores/lancedb\";",
      "2: import { OpenAIEmbeddings } from \"@langchain/openai\";",
      "4: import * as fs from \"node:fs/promises\";",
      "5: import * as path from \"node:path\";",
      "6: import os from \"node:os\";",
      "8: export const run = async () => {",
      "15:   const vectorStore = await LanceDB.fromTexts(",
      "16:     [\"Hello world\", \"Bye bye\", \"hello nice world\"],",
      "17:     [{ id: 2 }, { id: 1 }, { id: 3 }],",
      "20:   );",
      "22:   const resultOne = await vectorStore.similaritySearch(\"hello world\", 1);",
      "",
      "[Removed Lines]",
      "3: import { connect } from \"vectordb\";",
      "9:   const dir = await fs.mkdtemp(path.join(os.tmpdir(), \"lancedb-\"));",
      "10:   const db = await connect(dir);",
      "11:   const table = await db.createTable(\"vectors\", [",
      "12:     { vector: Array(1536), text: \"sample\", id: 1 },",
      "13:   ]);",
      "18:     new OpenAIEmbeddings(),",
      "19:     { table }",
      "",
      "[Added Lines]",
      "8:   const vectorStore = await LanceDB.fromTexts(",
      "9:     [\"Hello world\", \"Bye bye\", \"hello nice world\"],",
      "10:     [{ id: 2 }, { id: 1 }, { id: 3 }],",
      "11:     new OpenAIEmbeddings()",
      "12:   );",
      "14:   const resultOne = await vectorStore.similaritySearch(\"hello world\", 1);",
      "15:   console.log(resultOne);",
      "17: };",
      "19: export const run_with_existing_table = async () => {",
      "20:   const dir = await fs.mkdtemp(path.join(os.tmpdir(), \"lancedb-\"));",
      "24:     new OpenAIEmbeddings()",
      "",
      "---------------"
    ],
    "libs/langchain-community/src/vectorstores/lancedb.ts||libs/langchain-community/src/vectorstores/lancedb.ts": [
      "File: libs/langchain-community/src/vectorstores/lancedb.ts -> libs/langchain-community/src/vectorstores/lancedb.ts",
      "--- Hunk 1 ---",
      "[Context before]",
      "2: import type { EmbeddingsInterface } from \"@langchain/core/embeddings\";",
      "3: import { VectorStore } from \"@langchain/core/vectorstores\";",
      "4: import { Document } from \"@langchain/core/documents\";",
      "",
      "[Removed Lines]",
      "1: import { Table } from \"vectordb\";",
      "",
      "[Added Lines]",
      "1: import { connect, Table, Connection, WriteMode } from \"vectordb\";",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "10: export type LanceDBArgs = {",
      "12:   textKey?: string;",
      "13: };",
      "",
      "[Removed Lines]",
      "11:   table: Table;",
      "",
      "[Added Lines]",
      "11:   table?: Table;",
      "13:   uri?: string;",
      "14:   tableName?: string;",
      "15:   mode?: WriteMode;",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "20: export class LanceDB extends VectorStore {",
      "23:   private textKey: string;",
      "28:     this.embeddings = embeddings;",
      "30:   }",
      "",
      "[Removed Lines]",
      "21:   private table: Table;",
      "25:   constructor(embeddings: EmbeddingsInterface, args: LanceDBArgs) {",
      "26:     super(embeddings, args);",
      "27:     this.table = args.table;",
      "29:     this.textKey = args.textKey || \"text\";",
      "",
      "[Added Lines]",
      "24:   private table?: Table;",
      "28:   private uri: string;",
      "30:   private tableName: string;",
      "32:   private mode?: WriteMode;",
      "34:   constructor(embeddings: EmbeddingsInterface, args?: LanceDBArgs) {",
      "35:     super(embeddings, args || {});",
      "36:     this.table = args?.table;",
      "38:     this.textKey = args?.textKey || \"text\";",
      "39:     this.uri = args?.uri || \"~/lancedb\";",
      "40:     this.tableName = args?.tableName || \"langchain\";",
      "41:     this.mode = args?.mode || WriteMode.Overwrite;",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "71:       });",
      "72:       data.push(record);",
      "73:     }",
      "74:     await this.table.add(data);",
      "75:   }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "86:     if (!this.table) {",
      "87:       const db: Connection = await connect(this.uri);",
      "88:       this.table = await db.createTable(this.tableName, data, {",
      "89:         writeMode: this.mode,",
      "90:       });",
      "92:       return;",
      "93:     }",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "85:     query: number[],",
      "86:     k: number",
      "87:   ): Promise<[Document, number][]> {",
      "88:     const results = await this.table.search(query).limit(k).execute();",
      "90:     const docsAndScore: [Document, number][] = [];",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "108:     if (!this.table) {",
      "109:       throw new Error(",
      "110:         \"Table not found. Please add vectors to the table first.\"",
      "111:       );",
      "112:     }",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "119:     texts: string[],",
      "120:     metadatas: object[] | object,",
      "121:     embeddings: EmbeddingsInterface,",
      "123:   ): Promise<LanceDB> {",
      "124:     const docs: Document[] = [];",
      "125:     for (let i = 0; i < texts.length; i += 1) {",
      "",
      "[Removed Lines]",
      "122:     dbConfig: LanceDBArgs",
      "",
      "[Added Lines]",
      "147:     dbConfig?: LanceDBArgs",
      "",
      "---------------",
      "--- Hunk 7 ---",
      "[Context before]",
      "143:   static async fromDocuments(",
      "144:     docs: Document[],",
      "145:     embeddings: EmbeddingsInterface,",
      "147:   ): Promise<LanceDB> {",
      "148:     const instance = new this(embeddings, dbConfig);",
      "149:     await instance.addDocuments(docs);",
      "",
      "[Removed Lines]",
      "146:     dbConfig: LanceDBArgs",
      "",
      "[Added Lines]",
      "171:     dbConfig?: LanceDBArgs",
      "",
      "---------------"
    ],
    "libs/langchain-community/src/vectorstores/tests/lancedb.int.test.ts||libs/langchain-community/src/vectorstores/tests/lancedb.int.test.ts": [
      "File: libs/langchain-community/src/vectorstores/tests/lancedb.int.test.ts -> libs/langchain-community/src/vectorstores/tests/lancedb.int.test.ts",
      "--- Hunk 1 ---",
      "[Context before]",
      "45:     expect(resultsTwo.length).toBe(5);",
      "46:   });",
      "47: });",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "49: describe(\"LanceDB empty schema\", () => {",
      "50:   test(\"Test fromTexts + addDocuments\", async () => {",
      "51:     const embeddings = new OpenAIEmbeddings();",
      "52:     const vectorStore = await LanceDB.fromTexts(",
      "53:       [\"hello bye\", \"hello world\", \"bye bye\"],",
      "54:       [{ id: 1 }, { id: 2 }, { id: 3 }],",
      "55:       embeddings",
      "56:     );",
      "58:     const results = await vectorStore.similaritySearch(\"hello bye\", 10);",
      "59:     expect(results.length).toBe(3);",
      "61:     await vectorStore.addDocuments([",
      "62:       new Document({",
      "63:         pageContent: \"a new world\",",
      "64:         metadata: { id: 4 },",
      "65:       }),",
      "66:     ]);",
      "68:     const resultsTwo = await vectorStore.similaritySearch(\"hello bye\", 10);",
      "69:     expect(resultsTwo.length).toBe(4);",
      "70:   });",
      "71: });",
      "",
      "---------------"
    ],
    "yarn.lock||yarn.lock": [
      "File: yarn.lock -> yarn.lock",
      "--- Hunk 1 ---",
      "[Context before]",
      "251:   languageName: node",
      "252:   linkType: hard",
      "272: \"@apify/consts@npm:^2.13.0, @apify/consts@npm:^2.9.0\":",
      "273:   version: 2.13.0",
      "274:   resolution: \"@apify/consts@npm:2.13.0\"",
      "",
      "[Removed Lines]",
      "254: \"@apache-arrow/ts@npm:^12.0.0\":",
      "255:   version: 12.0.0",
      "256:   resolution: \"@apache-arrow/ts@npm:12.0.0\"",
      "257:   dependencies:",
      "258:     \"@types/command-line-args\": 5.2.0",
      "259:     \"@types/command-line-usage\": 5.0.2",
      "260:     \"@types/node\": 18.14.5",
      "261:     \"@types/pad-left\": 2.1.1",
      "262:     command-line-args: 5.2.1",
      "263:     command-line-usage: 6.1.3",
      "264:     flatbuffers: 23.3.3",
      "265:     json-bignum: ^0.0.3",
      "266:     pad-left: ^2.1.0",
      "267:     tslib: ^2.5.0",
      "268:   checksum: 67b2791e14d5377b1d160a0d8390decc386e013c517713f8b9c100737a0e478a394086d91a8c846848d4e30289070a119d8e65191998f4c2555b18a29564df50",
      "269:   languageName: node",
      "270:   linkType: hard",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "11112:   languageName: node",
      "11113:   linkType: hard",
      "11115: \"@langchain/anthropic@*, @langchain/anthropic@workspace:*, @langchain/anthropic@workspace:libs/langchain-anthropic\":",
      "11116:   version: 0.0.0-use.local",
      "11117:   resolution: \"@langchain/anthropic@workspace:libs/langchain-anthropic\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "11097: \"@lancedb/vectordb-darwin-arm64@npm:0.4.20\":",
      "11098:   version: 0.4.20",
      "11099:   resolution: \"@lancedb/vectordb-darwin-arm64@npm:0.4.20\"",
      "11100:   conditions: os=darwin & cpu=arm64",
      "11101:   languageName: node",
      "11102:   linkType: hard",
      "11104: \"@lancedb/vectordb-darwin-x64@npm:0.4.20\":",
      "11105:   version: 0.4.20",
      "11106:   resolution: \"@lancedb/vectordb-darwin-x64@npm:0.4.20\"",
      "11107:   conditions: os=darwin & cpu=x64",
      "11108:   languageName: node",
      "11109:   linkType: hard",
      "11111: \"@lancedb/vectordb-linux-arm64-gnu@npm:0.4.20\":",
      "11112:   version: 0.4.20",
      "11113:   resolution: \"@lancedb/vectordb-linux-arm64-gnu@npm:0.4.20\"",
      "11114:   conditions: os=linux & cpu=arm64",
      "11115:   languageName: node",
      "11116:   linkType: hard",
      "11118: \"@lancedb/vectordb-linux-x64-gnu@npm:0.4.20\":",
      "11119:   version: 0.4.20",
      "11120:   resolution: \"@lancedb/vectordb-linux-x64-gnu@npm:0.4.20\"",
      "11121:   conditions: os=linux & cpu=x64",
      "11122:   languageName: node",
      "11123:   linkType: hard",
      "11125: \"@lancedb/vectordb-win32-x64-msvc@npm:0.4.20\":",
      "11126:   version: 0.4.20",
      "11127:   resolution: \"@lancedb/vectordb-win32-x64-msvc@npm:0.4.20\"",
      "11128:   conditions: os=win32 & cpu=x64",
      "11129:   languageName: node",
      "11130:   linkType: hard",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "11577:     typesense: ^1.5.3",
      "11578:     usearch: ^1.1.1",
      "11579:     uuid: ^10.0.0",
      "11581:     voy-search: 0.6.2",
      "11582:     weaviate-ts-client: ^1.4.0",
      "11583:     web-auth-library: ^1.0.3",
      "",
      "[Removed Lines]",
      "11580:     vectordb: ^0.1.4",
      "",
      "[Added Lines]",
      "11597:     vectordb: ^0.9.0",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "13039:   languageName: node",
      "13040:   linkType: hard",
      "13042: \"@neondatabase/serverless@npm:0.6.0\":",
      "13043:   version: 0.6.0",
      "13044:   resolution: \"@neondatabase/serverless@npm:0.6.0\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "13059: \"@neon-rs/load@npm:^0.0.74\":",
      "13060:   version: 0.0.74",
      "13061:   resolution: \"@neon-rs/load@npm:0.0.74\"",
      "13062:   checksum: d26ec9b08cdf1a7c5aeefe98f77112d205d11b4005a7934b21fe8fd27528847e08e4749e7e6c3fc05ae9f701175a58c11a095ae6af449634df3991a2c82e1dfa",
      "13063:   languageName: node",
      "13064:   linkType: hard",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "20774:   languageName: node",
      "20775:   linkType: hard",
      "20797: \"apache-arrow@npm:^12.0.1\":",
      "20798:   version: 12.0.1",
      "20799:   resolution: \"apache-arrow@npm:12.0.1\"",
      "",
      "[Removed Lines]",
      "20777: \"apache-arrow@npm:^12.0.0\":",
      "20778:   version: 12.0.0",
      "20779:   resolution: \"apache-arrow@npm:12.0.0\"",
      "20780:   dependencies:",
      "20781:     \"@types/command-line-args\": 5.2.0",
      "20782:     \"@types/command-line-usage\": 5.0.2",
      "20783:     \"@types/node\": 18.14.5",
      "20784:     \"@types/pad-left\": 2.1.1",
      "20785:     command-line-args: 5.2.1",
      "20786:     command-line-usage: 6.1.3",
      "20787:     flatbuffers: 23.3.3",
      "20788:     json-bignum: ^0.0.3",
      "20789:     pad-left: ^2.1.0",
      "20790:     tslib: ^2.5.0",
      "20791:   bin:",
      "20792:     arrow2csv: bin/arrow2csv.js",
      "20793:   checksum: 3285189517c2b298cda42852321ce127754918513116eade6e4914c57983f68b6ba96605cfaa2202796d3d6e14755d3b3758f76c1374492affa3d95714eaca40",
      "20794:   languageName: node",
      "20795:   linkType: hard",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "27133:     typescript: ~5.1.6",
      "27134:     typesense: ^1.5.3",
      "27135:     uuid: ^10.0.0",
      "27137:     voy-search: 0.6.2",
      "27138:     weaviate-ts-client: ^2.0.0",
      "27139:     zod: ^3.22.4",
      "",
      "[Removed Lines]",
      "27136:     vectordb: ^0.1.4",
      "",
      "[Added Lines]",
      "27140:     vectordb: ^0.9.0",
      "",
      "---------------",
      "--- Hunk 7 ---",
      "[Context before]",
      "42444:   languageName: node",
      "42445:   linkType: hard",
      "42454:   languageName: node",
      "42455:   linkType: hard",
      "",
      "[Removed Lines]",
      "42447: \"vectordb@npm:^0.1.4\":",
      "42448:   version: 0.1.4",
      "42449:   resolution: \"vectordb@npm:0.1.4\"",
      "42450:   dependencies:",
      "42451:     \"@apache-arrow/ts\": ^12.0.0",
      "42452:     apache-arrow: ^12.0.0",
      "42453:   checksum: 8a40abf4466479b0b9e61687416b5ab232458401917bf9a1d5f3d8ea8c8320ecc5691174f4d4c0cfef0bb6c16328a9088419fd90ac85fd7267dbccdd1f9e55d7",
      "",
      "[Added Lines]",
      "42451: \"vectordb@npm:^0.9.0\":",
      "42452:   version: 0.9.0",
      "42453:   resolution: \"vectordb@npm:0.9.0\"",
      "42454:   dependencies:",
      "42455:     \"@lancedb/vectordb-darwin-arm64\": 0.4.20",
      "42456:     \"@lancedb/vectordb-darwin-x64\": 0.4.20",
      "42457:     \"@lancedb/vectordb-linux-arm64-gnu\": 0.4.20",
      "42458:     \"@lancedb/vectordb-linux-x64-gnu\": 0.4.20",
      "42459:     \"@lancedb/vectordb-win32-x64-msvc\": 0.4.20",
      "42460:     \"@neon-rs/load\": ^0.0.74",
      "42461:     axios: ^1.4.0",
      "42462:   peerDependencies:",
      "42463:     \"@apache-arrow/ts\": ^14.0.2",
      "42464:     apache-arrow: ^14.0.2",
      "42465:   dependenciesMeta:",
      "42466:     \"@lancedb/vectordb-darwin-arm64\":",
      "42467:       optional: true",
      "42468:     \"@lancedb/vectordb-darwin-x64\":",
      "42469:       optional: true",
      "42470:     \"@lancedb/vectordb-linux-arm64-gnu\":",
      "42471:       optional: true",
      "42472:     \"@lancedb/vectordb-linux-x64-gnu\":",
      "42473:       optional: true",
      "42474:     \"@lancedb/vectordb-win32-x64-msvc\":",
      "42475:       optional: true",
      "42476:   conditions: (os=darwin | os=linux | os=win32) & (cpu=x64 | cpu=arm64)",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "c65147da655558125f8a43860a1ba4d4c95c4122",
      "candidate_info": {
        "commit_hash": "c65147da655558125f8a43860a1ba4d4c95c4122",
        "repo": "langchain-ai/langchainjs",
        "commit_url": "https://github.com/langchain-ai/langchainjs/commit/c65147da655558125f8a43860a1ba4d4c95c4122",
        "files": [
          "langchain/package.json",
          "langchain/src/chat_models/universal.ts",
          "libs/langchain-xai/src/chat_models.ts",
          "libs/langchain-xai/src/tests/chat_models.test.ts",
          "yarn.lock"
        ],
        "message": "feat(langchain): Adds xAI to initChatModel (#7721)",
        "before_after_code_files": [
          "langchain/src/chat_models/universal.ts||langchain/src/chat_models/universal.ts",
          "libs/langchain-xai/src/chat_models.ts||libs/langchain-xai/src/chat_models.ts",
          "libs/langchain-xai/src/tests/chat_models.test.ts||libs/langchain-xai/src/tests/chat_models.test.ts",
          "yarn.lock||yarn.lock"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "yarn.lock||yarn.lock"
          ],
          "candidate": [
            "yarn.lock||yarn.lock"
          ]
        }
      },
      "candidate_diff": {
        "langchain/src/chat_models/universal.ts||langchain/src/chat_models/universal.ts": [
          "File: langchain/src/chat_models/universal.ts -> langchain/src/chat_models/universal.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "50:   \"bedrock\",",
          "51:   \"cerebras\",",
          "52:   \"deepseek\",",
          "53: ] as const;",
          "55: export type ChatModelProvider = (typeof _SUPPORTED_PROVIDERS)[number];",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "53:   \"xai\",",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "135:         const { ChatDeepSeek } = await import(\"@langchain/deepseek\");",
          "136:         return new ChatDeepSeek({ model, ...passedParams });",
          "137:       }",
          "138:       case \"fireworks\": {",
          "139:         const { ChatFireworks } = await import(",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "139:       case \"xai\": {",
          "140:         const { ChatXAI } = await import(\"@langchain/xai\");",
          "141:         return new ChatXAI({ model, ...passedParams });",
          "142:       }",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "194:   if (",
          "195:     modelName.startsWith(\"gpt-3\") ||",
          "196:     modelName.startsWith(\"gpt-4\") ||",
          "198:   ) {",
          "199:     return \"openai\";",
          "200:   } else if (modelName.startsWith(\"claude\")) {",
          "",
          "[Removed Lines]",
          "197:     modelName.startsWith(\"o1\")",
          "",
          "[Added Lines]",
          "202:     modelName.startsWith(\"o1\") ||",
          "203:     modelName.startsWith(\"o3\")",
          "",
          "---------------"
        ],
        "libs/langchain-xai/src/chat_models.ts||libs/langchain-xai/src/chat_models.ts": [
          "File: libs/langchain-xai/src/chat_models.ts -> libs/langchain-xai/src/chat_models.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "396:   }",
          "398:   _llmType() {",
          "400:   }",
          "402:   get lc_secrets(): { [key: string]: string } | undefined {",
          "",
          "[Removed Lines]",
          "399:     return \"xAI\";",
          "",
          "[Added Lines]",
          "399:     return \"xai\";",
          "",
          "---------------"
        ],
        "libs/langchain-xai/src/tests/chat_models.test.ts||libs/langchain-xai/src/tests/chat_models.test.ts": [
          "File: libs/langchain-xai/src/tests/chat_models.test.ts -> libs/langchain-xai/src/tests/chat_models.test.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "2: import { test, expect } from \"@jest/globals\";",
          "3: import { ChatXAI } from \"../chat_models.js\";",
          "5: test(\"Serialization\", () => {",
          "6:   const model = new ChatXAI({",
          "8:   });",
          "9:   expect(JSON.stringify(model)).toEqual(",
          "11:   );",
          "12: });",
          "14: test(\"Serialization with no params\", () => {",
          "16:   const model = new ChatXAI();",
          "17:   expect(JSON.stringify(model)).toEqual(",
          "19:   );",
          "20: });",
          "",
          "[Removed Lines]",
          "7:     apiKey: \"foo\",",
          "10:     `{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"chat_models\",\"xai\",\"ChatXAI\"],\"kwargs\":{\"api_key\":{\"lc\":1,\"type\":\"secret\",\"id\":[\"XAI_API_KEY\"]}}}`",
          "15:   process.env.GROQ_API_KEY = \"foo\";",
          "18:     `{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"chat_models\",\"xai\",\"ChatXAI\"],\"kwargs\":{\"api_key\":{\"lc\":1,\"type\":\"secret\",\"id\":[\"XAI_API_KEY\"]}}}`",
          "",
          "[Added Lines]",
          "5: beforeEach(() => {",
          "6:   process.env.XAI_API_KEY = \"foo\";",
          "7: });",
          "10:   delete process.env.XAI_API_KEY;",
          "12:     model: \"grok-2-1212\",",
          "13:     apiKey: \"bar\",",
          "16:     `{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"chat_models\",\"xai\",\"ChatXAI\"],\"kwargs\":{\"model\":\"grok-2-1212\"}}`",
          "23:     `{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"chat_models\",\"xai\",\"ChatXAI\"],\"kwargs\":{\"model\":\"grok-beta\"}}`",
          "",
          "---------------"
        ],
        "yarn.lock||yarn.lock": [
          "File: yarn.lock -> yarn.lock",
          "--- Hunk 1 ---",
          "[Context before]",
          "13305:   languageName: unknown",
          "13306:   linkType: soft",
          "13309:   version: 0.0.0-use.local",
          "13310:   resolution: \"@langchain/xai@workspace:libs/langchain-xai\"",
          "13311:   dependencies:",
          "",
          "[Removed Lines]",
          "13308: \"@langchain/xai@workspace:*, @langchain/xai@workspace:libs/langchain-xai\":",
          "",
          "[Added Lines]",
          "13308: \"@langchain/xai@*, @langchain/xai@workspace:*, @langchain/xai@workspace:libs/langchain-xai\":",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "33472:     \"@langchain/openai\": \">=0.1.0 <0.5.0\"",
          "33473:     \"@langchain/scripts\": \">=0.1.0 <0.2.0\"",
          "33474:     \"@langchain/textsplitters\": \">=0.0.0 <0.2.0\"",
          "33475:     \"@swc/core\": ^1.3.90",
          "33476:     \"@swc/jest\": ^0.2.29",
          "33477:     \"@tsconfig/recommended\": ^1.0.2",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "33475:     \"@langchain/xai\": \"*\"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "33530:     \"@langchain/groq\": \"*\"",
          "33531:     \"@langchain/mistralai\": \"*\"",
          "33532:     \"@langchain/ollama\": \"*\"",
          "33533:     axios: \"*\"",
          "33534:     cheerio: \"*\"",
          "33535:     handlebars: ^4.7.8",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "33534:     \"@langchain/xai\": \"*\"",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "33558:       optional: true",
          "33559:     \"@langchain/ollama\":",
          "33560:       optional: true",
          "33561:     axios:",
          "33562:       optional: true",
          "33563:     cheerio:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "33563:     \"@langchain/xai\":",
          "33564:       optional: true",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "c8a1cdf105ec2fc247b9af5c21c4de98d13f167d",
      "candidate_info": {
        "commit_hash": "c8a1cdf105ec2fc247b9af5c21c4de98d13f167d",
        "repo": "langchain-ai/langchainjs",
        "commit_url": "https://github.com/langchain-ai/langchainjs/commit/c8a1cdf105ec2fc247b9af5c21c4de98d13f167d",
        "files": [
          "libs/langchain-openai/package.json",
          "libs/langchain-openai/src/chat_models.ts",
          "libs/langchain-openai/src/tests/chat_models.int.test.ts",
          "libs/langchain-openai/src/tests/chat_models_structured_output.int.test.ts",
          "libs/langchain-openai/src/types.ts",
          "yarn.lock"
        ],
        "message": "feat(openai): Alias system messages as developer messages for o1, add reasoning_effort param (#7398)",
        "before_after_code_files": [
          "libs/langchain-openai/src/chat_models.ts||libs/langchain-openai/src/chat_models.ts",
          "libs/langchain-openai/src/tests/chat_models.int.test.ts||libs/langchain-openai/src/tests/chat_models.int.test.ts",
          "libs/langchain-openai/src/tests/chat_models_structured_output.int.test.ts||libs/langchain-openai/src/tests/chat_models_structured_output.int.test.ts",
          "libs/langchain-openai/src/types.ts||libs/langchain-openai/src/types.ts",
          "yarn.lock||yarn.lock"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "yarn.lock||yarn.lock"
          ],
          "candidate": [
            "yarn.lock||yarn.lock"
          ]
        }
      },
      "candidate_diff": {
        "libs/langchain-openai/src/chat_models.ts||libs/langchain-openai/src/chat_models.ts": [
          "File: libs/langchain-openai/src/chat_models.ts -> libs/langchain-openai/src/chat_models.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "95: }",
          "100: type OpenAICompletionParam =",
          "101:   OpenAIClient.Chat.Completions.ChatCompletionMessageParam;",
          "",
          "[Removed Lines]",
          "98: type OpenAIRoleEnum = \"system\" | \"assistant\" | \"user\" | \"function\" | \"tool\";",
          "",
          "[Added Lines]",
          "98: type OpenAIRoleEnum =",
          "99:   | \"system\"",
          "100:   | \"developer\"",
          "101:   | \"assistant\"",
          "102:   | \"user\"",
          "103:   | \"function\"",
          "104:   | \"tool\";",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "105: function extractGenericMessageCustomRole(message: ChatMessage) {",
          "106:   if (",
          "107:     message.role !== \"system\" &&",
          "108:     message.role !== \"assistant\" &&",
          "109:     message.role !== \"user\" &&",
          "110:     message.role !== \"function\" &&",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "114:     message.role !== \"developer\" &&",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "249:     });",
          "250:   } else if (role === \"system\") {",
          "251:     return new SystemMessageChunk({ content, response_metadata });",
          "252:   } else if (role === \"function\") {",
          "253:     return new FunctionMessageChunk({",
          "254:       content,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "259:   } else if (role === \"developer\") {",
          "260:     return new SystemMessageChunk({",
          "261:       content,",
          "262:       response_metadata,",
          "263:       additional_kwargs: {",
          "264:         __openai_role__: \"developer\",",
          "265:       },",
          "266:     });",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "272: export function _convertMessagesToOpenAIParams(",
          "274: ): OpenAICompletionParam[] {",
          "276:   return messages.flatMap((message) => {",
          "278:     const completionParam: Record<string, any> = {",
          "280:       content: message.content,",
          "281:     };",
          "282:     if (message.name != null) {",
          "",
          "[Removed Lines]",
          "273:   messages: BaseMessage[]",
          "279:       role: messageToOpenAIRole(message),",
          "",
          "[Added Lines]",
          "288:   messages: BaseMessage[],",
          "289:   model?: string",
          "293:     let role = messageToOpenAIRole(message);",
          "294:     if (role === \"system\" && model?.startsWith(\"o1\")) {",
          "295:       role = \"developer\";",
          "296:     }",
          "299:       role,",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "430:   prediction?: OpenAIClient.ChatCompletionPredictionContent;",
          "431: }",
          "433: export interface ChatOpenAIFields",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "456:   reasoning_effort?: OpenAIClient.Chat.ChatCompletionReasoningEffort;",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "994:       \"promptIndex\",",
          "995:       \"response_format\",",
          "996:       \"seed\",",
          "997:     ];",
          "998:   }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1023:       \"reasoning_effort\",",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "1093:   modalities?: Array<OpenAIClient.Chat.ChatCompletionModality>;",
          "1095:   constructor(",
          "1096:     fields?: ChatOpenAIFields,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1122:   reasoningEffort?: OpenAIClient.Chat.ChatCompletionReasoningEffort;",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "1162:     this.__includeRawResponse = fields?.__includeRawResponse;",
          "1163:     this.audio = fields?.audio;",
          "1164:     this.modalities = fields?.modalities;",
          "1166:     if (this.azureOpenAIApiKey || this.azureADTokenProvider) {",
          "1167:       if (",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1194:     this.reasoningEffort = fields?.reasoningEffort;",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "1337:     if (options?.prediction !== undefined) {",
          "1338:       params.prediction = options.prediction;",
          "1339:     }",
          "1340:     return params;",
          "1341:   }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1370:     const reasoningEffort = options?.reasoning_effort ?? this.reasoningEffort;",
          "1371:     if (reasoningEffort !== undefined) {",
          "1372:       params.reasoning_effort = reasoningEffort;",
          "1373:     }",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "1360:     runManager?: CallbackManagerForLLMRun",
          "1361:   ): AsyncGenerator<ChatGenerationChunk> {",
          "1362:     const messagesMapped: OpenAICompletionParam[] =",
          "1364:     const params = {",
          "1365:       ...this.invocationParams(options, {",
          "1366:         streaming: true,",
          "",
          "[Removed Lines]",
          "1363:       _convertMessagesToOpenAIParams(messages);",
          "",
          "[Added Lines]",
          "1397:       _convertMessagesToOpenAIParams(messages, this.model);",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "1489:     const usageMetadata = {} as UsageMetadata;",
          "1490:     const params = this.invocationParams(options);",
          "1491:     const messagesMapped: OpenAICompletionParam[] =",
          "1494:     if (params.stream) {",
          "1495:       const stream = this._streamResponseChunks(messages, options, runManager);",
          "",
          "[Removed Lines]",
          "1492:       _convertMessagesToOpenAIParams(messages);",
          "",
          "[Added Lines]",
          "1526:       _convertMessagesToOpenAIParams(messages, this.model);",
          "",
          "---------------"
        ],
        "libs/langchain-openai/src/tests/chat_models.int.test.ts||libs/langchain-openai/src/tests/chat_models.int.test.ts": [
          "File: libs/langchain-openai/src/tests/chat_models.int.test.ts -> libs/langchain-openai/src/tests/chat_models.int.test.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "1191:     expect(finalMsg.content.length).toBeGreaterThanOrEqual(1);",
          "1192:   }",
          "1195:   expect(numChunks).toBeGreaterThan(3);",
          "1196: });",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1195: test(\"Allows developer messages with o1\", async () => {",
          "1196:   const model = new ChatOpenAI({",
          "1197:     model: \"o1\",",
          "1198:     reasoningEffort: \"low\",",
          "1199:   });",
          "1200:   const res = await model.invoke([",
          "1201:     {",
          "1202:       role: \"developer\",",
          "1203:       content: `Always respond only with the word \"testing\"`,",
          "1204:     },",
          "1205:     {",
          "1206:       role: \"user\",",
          "1207:       content: \"hi\",",
          "1208:     },",
          "1209:   ]);",
          "1210:   expect(res.content).toEqual(\"testing\");",
          "1211: });",
          "",
          "---------------"
        ],
        "libs/langchain-openai/src/tests/chat_models_structured_output.int.test.ts||libs/langchain-openai/src/tests/chat_models_structured_output.int.test.ts": [
          "File: libs/langchain-openai/src/tests/chat_models_structured_output.int.test.ts -> libs/langchain-openai/src/tests/chat_models_structured_output.int.test.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "36:   expect(\"number2\" in result).toBe(true);",
          "37: });",
          "39: test(\"withStructuredOutput zod schema streaming\", async () => {",
          "40:   const model = new ChatOpenAI({",
          "41:     temperature: 0,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "39: test(\"withStructuredOutput with o1\", async () => {",
          "40:   const model = new ChatOpenAI({",
          "41:     model: \"o1\",",
          "42:   });",
          "44:   const calculatorSchema = z.object({",
          "45:     operation: z.enum([\"add\", \"subtract\", \"multiply\", \"divide\"]),",
          "46:     number1: z.number(),",
          "47:     number2: z.number(),",
          "48:   });",
          "49:   const modelWithStructuredOutput = model.withStructuredOutput(",
          "50:     calculatorSchema,",
          "51:     {",
          "52:       name: \"calculator\",",
          "53:     }",
          "54:   );",
          "56:   const prompt = ChatPromptTemplate.fromMessages([",
          "57:     [\"developer\", \"You are VERY bad at math and must always use a calculator.\"],",
          "58:     [\"human\", \"Please help me!! What is 2 + 2?\"],",
          "59:   ]);",
          "60:   const chain = prompt.pipe(modelWithStructuredOutput);",
          "61:   const result = await chain.invoke({});",
          "63:   expect(\"operation\" in result).toBe(true);",
          "64:   expect(\"number1\" in result).toBe(true);",
          "65:   expect(\"number2\" in result).toBe(true);",
          "66: });",
          "",
          "---------------"
        ],
        "libs/langchain-openai/src/types.ts||libs/langchain-openai/src/types.ts": [
          "File: libs/langchain-openai/src/types.ts -> libs/langchain-openai/src/types.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "190:   audio?: OpenAIClient.Chat.ChatCompletionAudioParam;",
          "191: }",
          "193: export declare interface AzureOpenAIInput {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "196:   reasoningEffort?: OpenAIClient.ChatCompletionReasoningEffort;",
          "",
          "---------------"
        ],
        "yarn.lock||yarn.lock": [
          "File: yarn.lock -> yarn.lock",
          "--- Hunk 1 ---",
          "[Context before]",
          "12904:     jest: ^29.5.0",
          "12905:     jest-environment-node: ^29.6.4",
          "12906:     js-tiktoken: ^1.0.12",
          "12908:     prettier: ^2.8.3",
          "12909:     release-it: ^17.6.0",
          "12910:     rimraf: ^5.0.1",
          "",
          "[Removed Lines]",
          "12907:     openai: ^4.71.0",
          "",
          "[Added Lines]",
          "12907:     openai: ^4.77.0",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "36216:   languageName: node",
          "36217:   linkType: hard",
          "36222:   dependencies:",
          "36223:     \"@types/node\": ^18.11.18",
          "36224:     \"@types/node-fetch\": ^2.6.4",
          "",
          "[Removed Lines]",
          "36219: \"openai@npm:^4.71.0\":",
          "36220:   version: 4.71.0",
          "36221:   resolution: \"openai@npm:4.71.0\"",
          "",
          "[Added Lines]",
          "36219: \"openai@npm:^4.77.0\":",
          "36220:   version: 4.77.0",
          "36221:   resolution: \"openai@npm:4.77.0\"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "36234:       optional: true",
          "36235:   bin:",
          "36236:     openai: bin/cli",
          "36238:   languageName: node",
          "36239:   linkType: hard",
          "",
          "[Removed Lines]",
          "36237:   checksum: ba4b3772e806c59b1ea1235a40486392c797906e45dd97914f2cd819b4be2996e207c7b7c67d43236692300354f4e9ffa8ebfca6e97d3555655ebf0f3f01e3f2",
          "",
          "[Added Lines]",
          "36237:   checksum: e311130e3b35a7dc924e7125cca3246b7ac958b3c451f2f4ef2cae72144c82429f9c6db7bf67059fc9e10f3911087ebf8a9a4b2919ac915235ed3c324897b146",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "bd9ce751936a64066ae16b109708e9fce84389f8",
      "candidate_info": {
        "commit_hash": "bd9ce751936a64066ae16b109708e9fce84389f8",
        "repo": "langchain-ai/langchainjs",
        "commit_url": "https://github.com/langchain-ai/langchainjs/commit/bd9ce751936a64066ae16b109708e9fce84389f8",
        "files": [
          "docs/core_docs/docs/integrations/chat/ibm.ipynb",
          "docs/core_docs/docs/integrations/llms/ibm.ipynb",
          "docs/core_docs/docs/integrations/text_embedding/ibm.ipynb",
          "libs/langchain-community/.gitignore",
          "libs/langchain-community/langchain.config.js",
          "libs/langchain-community/package.json",
          "libs/langchain-community/src/chat_models/ibm.ts",
          "libs/langchain-community/src/chat_models/tests/ibm.int.test.ts",
          "libs/langchain-community/src/chat_models/tests/ibm.standard.int.test.ts",
          "libs/langchain-community/src/chat_models/tests/ibm.standard.test.ts",
          "libs/langchain-community/src/chat_models/tests/ibm.test.ts",
          "libs/langchain-community/src/embeddings/ibm.ts",
          "libs/langchain-community/src/embeddings/tests/ibm.int.test.ts",
          "libs/langchain-community/src/embeddings/tests/ibm.test.ts",
          "libs/langchain-community/src/llms/ibm.ts",
          "libs/langchain-community/src/llms/tests/ibm.int.test.ts",
          "libs/langchain-community/src/llms/tests/ibm.test.ts",
          "libs/langchain-community/src/llms/watsonx_ai.ts",
          "libs/langchain-community/src/load/import_constants.ts",
          "libs/langchain-community/src/load/import_type.ts",
          "libs/langchain-community/src/types/ibm.ts",
          "libs/langchain-community/src/utils/ibm.ts",
          "yarn.lock"
        ],
        "message": "feat(community): Prepare implementation IBM WatsonxAI to langchain community package. (#6916)\n\nCo-authored-by: jacoblee93 <jacoblee93@gmail.com>",
        "before_after_code_files": [
          "libs/langchain-community/langchain.config.js||libs/langchain-community/langchain.config.js",
          "libs/langchain-community/src/chat_models/ibm.ts||libs/langchain-community/src/chat_models/ibm.ts",
          "libs/langchain-community/src/chat_models/tests/ibm.int.test.ts||libs/langchain-community/src/chat_models/tests/ibm.int.test.ts",
          "libs/langchain-community/src/chat_models/tests/ibm.standard.int.test.ts||libs/langchain-community/src/chat_models/tests/ibm.standard.int.test.ts",
          "libs/langchain-community/src/chat_models/tests/ibm.standard.test.ts||libs/langchain-community/src/chat_models/tests/ibm.standard.test.ts",
          "libs/langchain-community/src/chat_models/tests/ibm.test.ts||libs/langchain-community/src/chat_models/tests/ibm.test.ts",
          "libs/langchain-community/src/embeddings/ibm.ts||libs/langchain-community/src/embeddings/ibm.ts",
          "libs/langchain-community/src/embeddings/tests/ibm.int.test.ts||libs/langchain-community/src/embeddings/tests/ibm.int.test.ts",
          "libs/langchain-community/src/embeddings/tests/ibm.test.ts||libs/langchain-community/src/embeddings/tests/ibm.test.ts",
          "libs/langchain-community/src/llms/ibm.ts||libs/langchain-community/src/llms/ibm.ts",
          "libs/langchain-community/src/llms/tests/ibm.int.test.ts||libs/langchain-community/src/llms/tests/ibm.int.test.ts",
          "libs/langchain-community/src/llms/tests/ibm.test.ts||libs/langchain-community/src/llms/tests/ibm.test.ts",
          "libs/langchain-community/src/llms/watsonx_ai.ts||libs/langchain-community/src/llms/watsonx_ai.ts",
          "libs/langchain-community/src/load/import_constants.ts||libs/langchain-community/src/load/import_constants.ts",
          "libs/langchain-community/src/load/import_type.ts||libs/langchain-community/src/load/import_type.ts",
          "libs/langchain-community/src/types/ibm.ts||libs/langchain-community/src/types/ibm.ts",
          "libs/langchain-community/src/utils/ibm.ts||libs/langchain-community/src/utils/ibm.ts",
          "yarn.lock||yarn.lock"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "yarn.lock||yarn.lock"
          ],
          "candidate": [
            "yarn.lock||yarn.lock"
          ]
        }
      },
      "candidate_diff": {
        "libs/langchain-community/langchain.config.js||libs/langchain-community/langchain.config.js": [
          "File: libs/langchain-community/langchain.config.js -> libs/langchain-community/langchain.config.js",
          "--- Hunk 1 ---",
          "[Context before]",
          "29:     \"notion-to-md/build/utils/notion.js\",",
          "30:     \"@getzep/zep-cloud/api\",",
          "31:     \"@supabase/postgrest-js\",",
          "32:   ],",
          "33:   entrypoints: {",
          "34:     load: \"load/index\",",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "32:     \"@ibm-cloud/watsonx-ai/dist/watsonx-ai-ml/vml_v1.js\",",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "75:     \"embeddings/gradient_ai\": \"embeddings/gradient_ai\",",
          "76:     \"embeddings/hf\": \"embeddings/hf\",",
          "77:     \"embeddings/hf_transformers\": \"embeddings/hf_transformers\",",
          "78:     \"embeddings/jina\": \"embeddings/jina\",",
          "79:     \"embeddings/llama_cpp\": \"embeddings/llama_cpp\",",
          "80:     \"embeddings/minimax\": \"embeddings/minimax\",",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "79:     \"embeddings/ibm\": \"embeddings/ibm\",",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "99:     \"llms/friendli\": \"llms/friendli\",",
          "100:     \"llms/gradient_ai\": \"llms/gradient_ai\",",
          "101:     \"llms/hf\": \"llms/hf\",",
          "102:     \"llms/llama_cpp\": \"llms/llama_cpp\",",
          "103:     \"llms/ollama\": \"llms/ollama\",",
          "104:     \"llms/portkey\": \"llms/portkey\",",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "104:     \"llms/ibm\": \"llms/ibm\",",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "168:     \"chat_models/deepinfra\": \"chat_models/deepinfra\",",
          "169:     \"chat_models/fireworks\": \"chat_models/fireworks\",",
          "170:     \"chat_models/friendli\": \"chat_models/friendli\",",
          "171:     \"chat_models/iflytek_xinghuo\": \"chat_models/iflytek_xinghuo/index\",",
          "172:     \"chat_models/iflytek_xinghuo/web\": \"chat_models/iflytek_xinghuo/web\",",
          "173:     \"chat_models/llama_cpp\": \"chat_models/llama_cpp\",",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "174:     \"chat_models/ibm\": \"chat_models/ibm\",",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "336:     \"embeddings/tensorflow\",",
          "337:     \"embeddings/hf\",",
          "338:     \"embeddings/hf_transformers\",",
          "339:     \"embeddings/jina\",",
          "340:     \"embeddings/llama_cpp\",",
          "341:     \"embeddings/gradient_ai\",",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "343:     \"embeddings/ibm\",",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "349:     \"llms/gradient_ai\",",
          "350:     \"llms/hf\",",
          "351:     \"llms/raycast\",",
          "352:     \"llms/replicate\",",
          "353:     \"llms/sagemaker_endpoint\",",
          "354:     \"llms/watsonx_ai\",",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "357:     \"llms/ibm\",",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "410:     \"chat_models/premai\",",
          "411:     \"chat_models/tencent_hunyuan\",",
          "412:     \"chat_models/tencent_hunyuan/web\",",
          "413:     \"chat_models/iflytek_xinghuo\",",
          "414:     \"chat_models/iflytek_xinghuo/web\",",
          "415:     \"chat_models/webllm\",",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "419:     \"chat_models/ibm\",",
          "",
          "---------------"
        ],
        "libs/langchain-community/src/chat_models/ibm.ts||libs/langchain-community/src/chat_models/ibm.ts": [
          "File: libs/langchain-community/src/chat_models/ibm.ts -> libs/langchain-community/src/chat_models/ibm.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: import {",
          "2:   AIMessage,",
          "3:   AIMessageChunk,",
          "4:   ChatMessage,",
          "5:   ChatMessageChunk,",
          "6:   FunctionMessageChunk,",
          "7:   HumanMessageChunk,",
          "8:   isAIMessage,",
          "9:   MessageType,",
          "10:   ToolMessageChunk,",
          "11:   UsageMetadata,",
          "12:   type BaseMessage,",
          "13: } from \"@langchain/core/messages\";",
          "14: import {",
          "15:   BaseLanguageModelInput,",
          "16:   FunctionDefinition,",
          "17:   StructuredOutputMethodOptions,",
          "18:   type BaseLanguageModelCallOptions,",
          "19: } from \"@langchain/core/language_models/base\";",
          "20: import { CallbackManagerForLLMRun } from \"@langchain/core/callbacks/manager\";",
          "21: import {",
          "22:   BaseChatModel,",
          "23:   BindToolsInput,",
          "24:   LangSmithParams,",
          "25:   type BaseChatModelParams,",
          "26: } from \"@langchain/core/language_models/chat_models\";",
          "27: import {",
          "28:   ChatGeneration,",
          "29:   ChatGenerationChunk,",
          "30:   ChatResult,",
          "31: } from \"@langchain/core/outputs\";",
          "32: import { AsyncCaller } from \"@langchain/core/utils/async_caller\";",
          "33: import {",
          "34:   TextChatConstants,",
          "35:   TextChatMessagesTextChatMessageAssistant,",
          "36:   TextChatParameterTools,",
          "37:   TextChatParams,",
          "38:   TextChatResponse,",
          "39:   TextChatResponseFormat,",
          "40:   TextChatResultChoice,",
          "41:   TextChatResultMessage,",
          "42:   TextChatToolCall,",
          "43:   TextChatToolChoiceTool,",
          "44:   TextChatUsage,",
          "45: } from \"@ibm-cloud/watsonx-ai/dist/watsonx-ai-ml/vml_v1.js\";",
          "46: import { WatsonXAI } from \"@ibm-cloud/watsonx-ai\";",
          "47: import {",
          "48:   convertLangChainToolCallToOpenAI,",
          "49:   makeInvalidToolCall,",
          "50:   parseToolCall,",
          "51: } from \"@langchain/core/output_parsers/openai_tools\";",
          "52: import { ToolCallChunk } from \"@langchain/core/messages/tool\";",
          "53: import {",
          "54:   Runnable,",
          "55:   RunnablePassthrough,",
          "56:   RunnableSequence,",
          "57: } from \"@langchain/core/runnables\";",
          "58: import { z } from \"zod\";",
          "59: import {",
          "60:   BaseLLMOutputParser,",
          "61:   JsonOutputParser,",
          "62:   StructuredOutputParser,",
          "63: } from \"@langchain/core/output_parsers\";",
          "64: import { isZodSchema } from \"@langchain/core/utils/types\";",
          "65: import { zodToJsonSchema } from \"zod-to-json-schema\";",
          "66: import { NewTokenIndices } from \"@langchain/core/callbacks/base\";",
          "67: import { WatsonxAuth, WatsonxParams } from \"../types/ibm.js\";",
          "68: import {",
          "69:   _convertToolCallIdToMistralCompatible,",
          "70:   authenticateAndSetInstance,",
          "71:   WatsonxToolsOutputParser,",
          "72: } from \"../utils/ibm.js\";",
          "74: export interface WatsonxDeltaStream {",
          "75:   role?: string;",
          "76:   content?: string;",
          "77:   tool_calls?: TextChatToolCall[];",
          "78:   refusal?: string;",
          "79: }",
          "81: export interface WatsonxCallParams",
          "82:   extends Partial<",
          "83:     Omit<",
          "84:       TextChatParams,",
          "85:       | \"toolChoiceOption\"",
          "86:       | \"toolChoice\"",
          "87:       | \"frequencyPenalty\"",
          "88:       | \"topLogprobs\"",
          "89:       | \"maxTokens\"",
          "90:       | \"presencePenalty\"",
          "91:       | \"responseFormat\"",
          "92:       | \"timeLimit\"",
          "93:       | \"modelId\"",
          "94:     >",
          "95:   > {",
          "96:   maxRetries?: number;",
          "97:   tool_choice?: TextChatToolChoiceTool;",
          "98:   tool_choice_option?: TextChatConstants.ToolChoiceOption | string;",
          "99:   frequency_penalty?: number;",
          "100:   top_logprobs?: number;",
          "101:   max_new_tokens?: number;",
          "102:   presence_penalty?: number;",
          "103:   top_p?: number;",
          "104:   time_limit?: number;",
          "105:   response_format?: TextChatResponseFormat;",
          "106: }",
          "107: export interface WatsonxCallOptionsChat",
          "108:   extends Omit<BaseLanguageModelCallOptions, \"stop\">,",
          "109:     WatsonxCallParams {",
          "110:   promptIndex?: number;",
          "111: }",
          "113: type ChatWatsonxToolType = BindToolsInput | TextChatParameterTools;",
          "115: export interface ChatWatsonxInput extends BaseChatModelParams, WatsonxParams {",
          "116:   streaming?: boolean;",
          "117: }",
          "119: function _convertToValidToolId(modelId: string, tool_call_id: string) {",
          "120:   if (modelId.startsWith(\"mistralai\"))",
          "121:     return _convertToolCallIdToMistralCompatible(tool_call_id);",
          "122:   else return tool_call_id;",
          "123: }",
          "125: function _convertToolToWatsonxTool(",
          "126:   tools: ChatWatsonxToolType[]",
          "127: ): WatsonXAI.TextChatParameterTools[] {",
          "128:   return tools.map((tool) => {",
          "129:     if (\"type\" in tool) {",
          "130:       return tool as WatsonXAI.TextChatParameterTools;",
          "131:     }",
          "132:     return {",
          "133:       type: \"function\",",
          "134:       function: {",
          "135:         name: tool.name,",
          "136:         description: tool.description ?? \"Tool: \" + tool.name,",
          "137:         parameters: zodToJsonSchema(tool.schema),",
          "138:       },",
          "139:     };",
          "140:   });",
          "141: }",
          "143: function _convertMessagesToWatsonxMessages(",
          "144:   messages: BaseMessage[],",
          "145:   modelId: string",
          "146: ): TextChatResultMessage[] {",
          "147:   const getRole = (role: MessageType) => {",
          "148:     switch (role) {",
          "149:       case \"human\":",
          "150:         return \"user\";",
          "151:       case \"ai\":",
          "152:         return \"assistant\";",
          "153:       case \"system\":",
          "154:         return \"system\";",
          "155:       case \"tool\":",
          "156:         return \"tool\";",
          "157:       case \"function\":",
          "158:         return \"function\";",
          "159:       default:",
          "160:         throw new Error(`Unknown message type: ${role}`);",
          "161:     }",
          "162:   };",
          "164:   const getTools = (message: BaseMessage): TextChatToolCall[] | undefined => {",
          "165:     if (isAIMessage(message) && message.tool_calls?.length) {",
          "166:       return message.tool_calls",
          "167:         .map((toolCall) => ({",
          "168:           ...toolCall,",
          "169:           id: _convertToValidToolId(modelId, toolCall.id ?? \"\"),",
          "170:         }))",
          "171:         .map(convertLangChainToolCallToOpenAI) as TextChatToolCall[];",
          "172:     }",
          "173:     return undefined;",
          "174:   };",
          "176:   return messages.map((message) => {",
          "177:     const toolCalls = getTools(message);",
          "178:     const content = toolCalls === undefined ? message.content : \"\";",
          "179:     if (\"tool_call_id\" in message && typeof message.tool_call_id === \"string\") {",
          "180:       return {",
          "181:         role: getRole(message._getType()),",
          "182:         content,",
          "183:         name: message.name,",
          "184:         tool_call_id: _convertToValidToolId(modelId, message.tool_call_id),",
          "185:       };",
          "186:     }",
          "188:     return {",
          "189:       role: getRole(message._getType()),",
          "190:       content,",
          "191:       tool_calls: toolCalls,",
          "192:     };",
          "193:   }) as TextChatResultMessage[];",
          "194: }",
          "196: function _watsonxResponseToChatMessage(",
          "197:   choice: TextChatResultChoice,",
          "198:   rawDataId: string,",
          "199:   usage?: TextChatUsage",
          "200: ): BaseMessage {",
          "201:   const { message } = choice;",
          "202:   if (!message) throw new Error(\"No message presented\");",
          "203:   const rawToolCalls: TextChatToolCall[] = message.tool_calls ?? [];",
          "205:   switch (message.role) {",
          "206:     case \"assistant\": {",
          "207:       const toolCalls = [];",
          "208:       const invalidToolCalls = [];",
          "209:       for (const rawToolCall of rawToolCalls) {",
          "210:         try {",
          "211:           const parsed = parseToolCall(rawToolCall, { returnId: true });",
          "212:           toolCalls.push(parsed);",
          "213:         } catch (e: any) {",
          "214:           invalidToolCalls.push(makeInvalidToolCall(rawToolCall, e.message));",
          "215:         }",
          "216:       }",
          "217:       const additional_kwargs: Record<string, unknown> = {",
          "218:         tool_calls: rawToolCalls.map((toolCall) => ({",
          "219:           ...toolCall,",
          "220:           type: \"function\",",
          "221:         })),",
          "222:       };",
          "224:       return new AIMessage({",
          "225:         id: rawDataId,",
          "226:         content: message.content ?? \"\",",
          "227:         tool_calls: toolCalls,",
          "228:         invalid_tool_calls: invalidToolCalls,",
          "229:         additional_kwargs,",
          "230:         usage_metadata: usage",
          "231:           ? {",
          "232:               input_tokens: usage.prompt_tokens ?? 0,",
          "233:               output_tokens: usage.completion_tokens ?? 0,",
          "234:               total_tokens: usage.total_tokens ?? 0,",
          "235:             }",
          "236:           : undefined,",
          "237:       });",
          "238:     }",
          "239:     default:",
          "240:       return new ChatMessage(message.content ?? \"\", message.role ?? \"unknown\");",
          "241:   }",
          "242: }",
          "244: function _convertDeltaToMessageChunk(",
          "245:   delta: WatsonxDeltaStream,",
          "246:   rawData: TextChatResponse,",
          "247:   modelId: string,",
          "248:   usage?: TextChatUsage,",
          "249:   defaultRole?: TextChatMessagesTextChatMessageAssistant.Constants.Role",
          "250: ) {",
          "251:   if (delta.refusal) throw new Error(delta.refusal);",
          "252:   const rawToolCalls = delta.tool_calls?.length",
          "253:     ? delta.tool_calls?.map(",
          "254:         (",
          "255:           toolCall,",
          "256:           index",
          "257:         ): TextChatToolCall & {",
          "258:           index: number;",
          "259:           type: \"function\";",
          "260:         } => ({",
          "261:           ...toolCall,",
          "262:           index,",
          "263:           id: _convertToValidToolId(modelId, toolCall.id),",
          "264:           type: \"function\",",
          "265:         })",
          "266:       )",
          "267:     : undefined;",
          "269:   let role = \"assistant\";",
          "270:   if (delta.role) {",
          "271:     role = delta.role;",
          "272:   } else if (defaultRole) {",
          "273:     role = defaultRole;",
          "274:   }",
          "275:   const content = delta.content ?? \"\";",
          "276:   let additional_kwargs;",
          "277:   if (rawToolCalls) {",
          "278:     additional_kwargs = {",
          "279:       tool_calls: rawToolCalls,",
          "280:     };",
          "281:   } else {",
          "282:     additional_kwargs = {};",
          "283:   }",
          "285:   if (role === \"user\") {",
          "286:     return new HumanMessageChunk({ content });",
          "287:   } else if (role === \"assistant\") {",
          "288:     const toolCallChunks: ToolCallChunk[] = [];",
          "289:     if (rawToolCalls && rawToolCalls.length > 0)",
          "290:       for (const rawToolCallChunk of rawToolCalls) {",
          "291:         toolCallChunks.push({",
          "292:           name: rawToolCallChunk.function?.name,",
          "293:           args: rawToolCallChunk.function?.arguments,",
          "294:           id: rawToolCallChunk.id,",
          "295:           index: rawToolCallChunk.index,",
          "296:           type: \"tool_call_chunk\",",
          "297:         });",
          "298:       }",
          "300:     return new AIMessageChunk({",
          "301:       content,",
          "302:       tool_call_chunks: toolCallChunks,",
          "303:       additional_kwargs,",
          "304:       usage_metadata: {",
          "305:         input_tokens: usage?.prompt_tokens ?? 0,",
          "306:         output_tokens: usage?.completion_tokens ?? 0,",
          "307:         total_tokens: usage?.total_tokens ?? 0,",
          "308:       },",
          "309:       id: rawData.id,",
          "310:     });",
          "311:   } else if (role === \"tool\") {",
          "312:     if (rawToolCalls)",
          "313:       return new ToolMessageChunk({",
          "314:         content,",
          "315:         additional_kwargs,",
          "316:         tool_call_id: _convertToValidToolId(modelId, rawToolCalls?.[0].id),",
          "317:       });",
          "318:   } else if (role === \"function\") {",
          "319:     return new FunctionMessageChunk({",
          "320:       content,",
          "321:       additional_kwargs,",
          "322:     });",
          "323:   } else {",
          "324:     return new ChatMessageChunk({ content, role });",
          "325:   }",
          "326:   return null;",
          "327: }",
          "329: export class ChatWatsonx<",
          "330:     CallOptions extends WatsonxCallOptionsChat = WatsonxCallOptionsChat",
          "331:   >",
          "332:   extends BaseChatModel<CallOptions>",
          "333:   implements ChatWatsonxInput",
          "334: {",
          "335:   static lc_name() {",
          "336:     return \"ChatWatsonx\";",
          "337:   }",
          "339:   lc_serializable = true;",
          "341:   get lc_secrets(): { [key: string]: string } {",
          "342:     return {",
          "343:       authenticator: \"AUTHENTICATOR\",",
          "344:       apiKey: \"WATSONX_AI_APIKEY\",",
          "345:       apikey: \"WATSONX_AI_APIKEY\",",
          "346:       watsonxAIAuthType: \"WATSONX_AI_AUTH_TYPE\",",
          "347:       watsonxAIApikey: \"WATSONX_AI_APIKEY\",",
          "348:       watsonxAIBearerToken: \"WATSONX_AI_BEARER_TOKEN\",",
          "349:       watsonxAIUsername: \"WATSONX_AI_USERNAME\",",
          "350:       watsonxAIPassword: \"WATSONX_AI_PASSWORD\",",
          "351:       watsonxAIUrl: \"WATSONX_AI_URL\",",
          "352:     };",
          "353:   }",
          "355:   get lc_aliases(): { [key: string]: string } {",
          "356:     return {",
          "357:       authenticator: \"authenticator\",",
          "358:       apikey: \"watsonx_ai_apikey\",",
          "359:       apiKey: \"watsonx_ai_apikey\",",
          "360:       watsonxAIAuthType: \"watsonx_ai_auth_type\",",
          "361:       watsonxAIApikey: \"watsonx_ai_apikey\",",
          "362:       watsonxAIBearerToken: \"watsonx_ai_bearer_token\",",
          "363:       watsonxAIUsername: \"watsonx_ai_username\",",
          "364:       watsonxAIPassword: \"watsonx_ai_password\",",
          "365:       watsonxAIUrl: \"watsonx_ai_url\",",
          "366:     };",
          "367:   }",
          "369:   getLsParams(options: this[\"ParsedCallOptions\"]): LangSmithParams {",
          "370:     const params = this.invocationParams(options);",
          "371:     return {",
          "372:       ls_provider: \"watsonx\",",
          "373:       ls_model_name: this.model,",
          "374:       ls_model_type: \"chat\",",
          "375:       ls_temperature: params.temperature ?? undefined,",
          "376:       ls_max_tokens: params.maxTokens ?? undefined,",
          "377:     };",
          "378:   }",
          "380:   model = \"mistralai/mistral-large\";",
          "382:   version = \"2024-05-31\";",
          "384:   max_new_tokens = 100;",
          "386:   maxRetries = 0;",
          "388:   serviceUrl: string;",
          "390:   spaceId?: string;",
          "392:   projectId?: string;",
          "394:   frequency_penalty?: number;",
          "396:   logprobs?: boolean;",
          "398:   top_logprobs?: number;",
          "400:   n?: number;",
          "402:   presence_penalty?: number;",
          "404:   temperature?: number;",
          "406:   top_p?: number;",
          "408:   time_limit?: number;",
          "410:   maxConcurrency?: number;",
          "412:   service: WatsonXAI;",
          "414:   response_format?: TextChatResponseFormat | string;",
          "416:   streaming: boolean;",
          "418:   constructor(",
          "419:     fields: ChatWatsonxInput &",
          "420:       WatsonxAuth &",
          "421:       Partial<Omit<WatsonxCallParams, \"tool_choice\">>",
          "422:   ) {",
          "423:     super(fields);",
          "424:     if (",
          "425:       (fields.projectId && fields.spaceId) ||",
          "426:       (fields.idOrName && fields.projectId) ||",
          "427:       (fields.spaceId && fields.idOrName)",
          "428:     )",
          "429:       throw new Error(\"Maximum 1 id type can be specified per instance\");",
          "431:     if (!fields.projectId && !fields.spaceId && !fields.idOrName)",
          "432:       throw new Error(",
          "433:         \"No id specified! At least ide of 1 type has to be specified\"",
          "434:       );",
          "435:     this.projectId = fields?.projectId;",
          "436:     this.spaceId = fields?.spaceId;",
          "437:     this.temperature = fields?.temperature;",
          "438:     this.maxRetries = fields?.maxRetries || this.maxRetries;",
          "439:     this.maxConcurrency = fields?.maxConcurrency;",
          "440:     this.frequency_penalty = fields?.frequency_penalty;",
          "441:     this.top_logprobs = fields?.top_logprobs;",
          "442:     this.max_new_tokens = fields?.max_new_tokens ?? this.max_new_tokens;",
          "443:     this.presence_penalty = fields?.presence_penalty;",
          "444:     this.top_p = fields?.top_p;",
          "445:     this.time_limit = fields?.time_limit;",
          "446:     this.response_format = fields?.response_format ?? this.response_format;",
          "447:     this.serviceUrl = fields?.serviceUrl;",
          "448:     this.streaming = fields?.streaming ?? this.streaming;",
          "449:     this.n = fields?.n ?? this.n;",
          "450:     this.model = fields?.model ?? this.model;",
          "451:     this.version = fields?.version ?? this.version;",
          "453:     const {",
          "454:       watsonxAIApikey,",
          "455:       watsonxAIAuthType,",
          "456:       watsonxAIBearerToken,",
          "457:       watsonxAIUsername,",
          "458:       watsonxAIPassword,",
          "459:       watsonxAIUrl,",
          "460:       version,",
          "461:       serviceUrl,",
          "462:     } = fields;",
          "464:     const auth = authenticateAndSetInstance({",
          "465:       watsonxAIApikey,",
          "466:       watsonxAIAuthType,",
          "467:       watsonxAIBearerToken,",
          "468:       watsonxAIUsername,",
          "469:       watsonxAIPassword,",
          "470:       watsonxAIUrl,",
          "471:       version,",
          "472:       serviceUrl,",
          "473:     });",
          "474:     if (auth) this.service = auth;",
          "475:     else throw new Error(\"You have not provided one type of authentication\");",
          "476:   }",
          "478:   _llmType() {",
          "479:     return \"watsonx\";",
          "480:   }",
          "482:   invocationParams(options: this[\"ParsedCallOptions\"]) {",
          "483:     return {",
          "484:       maxTokens: options.max_new_tokens ?? this.max_new_tokens,",
          "485:       temperature: options?.temperature ?? this.temperature,",
          "486:       timeLimit: options?.time_limit ?? this.time_limit,",
          "487:       topP: options?.top_p ?? this.top_p,",
          "488:       presencePenalty: options?.presence_penalty ?? this.presence_penalty,",
          "489:       n: options?.n ?? this.n,",
          "490:       topLogprobs: options?.top_logprobs ?? this.top_logprobs,",
          "491:       logprobs: options?.logprobs ?? this?.logprobs,",
          "492:       frequencyPenalty: options?.frequency_penalty ?? this.frequency_penalty,",
          "493:       tools: options.tools",
          "494:         ? _convertToolToWatsonxTool(options.tools)",
          "495:         : undefined,",
          "496:       toolChoice: options.tool_choice,",
          "497:       responseFormat: options.response_format,",
          "498:       toolChoiceOption: options.tool_choice_option,",
          "499:     };",
          "500:   }",
          "502:   override bindTools(",
          "503:     tools: ChatWatsonxToolType[],",
          "504:     kwargs?: Partial<CallOptions>",
          "505:   ): Runnable<BaseLanguageModelInput, AIMessageChunk, CallOptions> {",
          "506:     return this.bind({",
          "507:       tools: _convertToolToWatsonxTool(tools),",
          "508:       ...kwargs,",
          "509:     } as CallOptions);",
          "510:   }",
          "512:   scopeId() {",
          "513:     if (this.projectId)",
          "514:       return { projectId: this.projectId, modelId: this.model };",
          "515:     else return { spaceId: this.spaceId, modelId: this.model };",
          "516:   }",
          "518:   async completionWithRetry<T>(",
          "519:     callback: () => T,",
          "520:     options?: this[\"ParsedCallOptions\"]",
          "521:   ) {",
          "522:     const caller = new AsyncCaller({",
          "523:       maxConcurrency: options?.maxConcurrency || this.maxConcurrency,",
          "524:       maxRetries: this.maxRetries,",
          "525:     });",
          "526:     const result = options",
          "527:       ? caller.callWithOptions(",
          "528:           {",
          "529:             signal: options.signal,",
          "530:           },",
          "531:           async () => callback()",
          "532:         )",
          "533:       : caller.call(async () => callback());",
          "535:     return result;",
          "536:   }",
          "538:   async _generate(",
          "539:     messages: BaseMessage[],",
          "540:     options: this[\"ParsedCallOptions\"],",
          "541:     runManager?: CallbackManagerForLLMRun",
          "542:   ): Promise<ChatResult> {",
          "543:     if (this.streaming) {",
          "544:       const stream = this._streamResponseChunks(messages, options, runManager);",
          "545:       const finalChunks: Record<number, ChatGenerationChunk> = {};",
          "546:       let tokenUsage: UsageMetadata = {",
          "547:         input_tokens: 0,",
          "548:         output_tokens: 0,",
          "549:         total_tokens: 0,",
          "550:       };",
          "551:       const tokenUsages: UsageMetadata[] = [];",
          "552:       for await (const chunk of stream) {",
          "553:         const message = chunk.message as AIMessageChunk;",
          "554:         if (message?.usage_metadata) {",
          "555:           const completion = chunk.generationInfo?.completion;",
          "556:           if (tokenUsages[completion])",
          "557:             tokenUsages[completion].output_tokens +=",
          "558:               message.usage_metadata.output_tokens;",
          "559:           else tokenUsages[completion] = message.usage_metadata;",
          "560:         }",
          "561:         chunk.message.response_metadata = {",
          "562:           ...chunk.generationInfo,",
          "563:           ...chunk.message.response_metadata,",
          "564:         };",
          "566:         const index =",
          "567:           (chunk.generationInfo as NewTokenIndices)?.completion ?? 0;",
          "568:         if (finalChunks[index] === undefined) {",
          "569:           finalChunks[index] = chunk;",
          "570:         } else {",
          "571:           finalChunks[index] = finalChunks[index].concat(chunk);",
          "572:         }",
          "573:       }",
          "574:       tokenUsage = tokenUsages.reduce((acc, curr) => {",
          "575:         return {",
          "576:           input_tokens: acc.input_tokens + curr.input_tokens,",
          "577:           output_tokens: acc.output_tokens + curr.output_tokens,",
          "578:           total_tokens: acc.total_tokens + curr.total_tokens,",
          "579:         };",
          "580:       });",
          "581:       const generations = Object.entries(finalChunks)",
          "582:         .sort(([aKey], [bKey]) => parseInt(aKey, 10) - parseInt(bKey, 10))",
          "583:         .map(([_, value]) => value);",
          "584:       return { generations, llmOutput: { tokenUsage } };",
          "585:     } else {",
          "586:       const params: Omit<TextChatParams, \"messages\"> = {",
          "587:         ...this.invocationParams(options),",
          "588:         ...this.scopeId(),",
          "589:       };",
          "590:       const watsonxMessages = _convertMessagesToWatsonxMessages(",
          "591:         messages,",
          "592:         this.model",
          "593:       );",
          "594:       const callback = () =>",
          "595:         this.service.textChat({",
          "596:           ...params,",
          "597:           messages: watsonxMessages,",
          "598:         });",
          "599:       const { result } = await this.completionWithRetry(callback, options);",
          "601:       const generations: ChatGeneration[] = [];",
          "602:       for (const part of result.choices) {",
          "603:         const generation: ChatGeneration = {",
          "604:           text: part.message?.content ?? \"\",",
          "605:           message: _watsonxResponseToChatMessage(",
          "606:             part,",
          "607:             result.id,",
          "608:             result?.usage",
          "609:           ),",
          "610:         };",
          "611:         if (part.finish_reason) {",
          "612:           generation.generationInfo = { finish_reason: part.finish_reason };",
          "613:         }",
          "614:         generations.push(generation);",
          "615:       }",
          "616:       if (options.signal?.aborted) {",
          "617:         throw new Error(\"AbortError\");",
          "618:       }",
          "620:       return {",
          "621:         generations,",
          "622:         llmOutput: {",
          "623:           tokenUsage: result?.usage,",
          "624:         },",
          "625:       };",
          "626:     }",
          "627:   }",
          "629:   async *_streamResponseChunks(",
          "630:     messages: BaseMessage[],",
          "631:     options: this[\"ParsedCallOptions\"],",
          "632:     _runManager?: CallbackManagerForLLMRun",
          "633:   ): AsyncGenerator<ChatGenerationChunk> {",
          "634:     const params = { ...this.invocationParams(options), ...this.scopeId() };",
          "635:     const watsonxMessages = _convertMessagesToWatsonxMessages(",
          "636:       messages,",
          "637:       this.model",
          "638:     );",
          "639:     const callback = () =>",
          "640:       this.service.textChatStream({",
          "641:         ...params,",
          "642:         messages: watsonxMessages,",
          "643:         returnObject: true,",
          "644:       });",
          "645:     const stream = await this.completionWithRetry(callback, options);",
          "646:     let defaultRole;",
          "647:     for await (const chunk of stream) {",
          "648:       if (options.signal?.aborted) {",
          "649:         throw new Error(\"AbortError\");",
          "650:       }",
          "651:       const { data } = chunk;",
          "652:       const choice = data.choices[0] as TextChatResultChoice &",
          "653:         Record<\"delta\", TextChatResultMessage>;",
          "654:       if (choice && !(\"delta\" in choice)) {",
          "655:         continue;",
          "656:       }",
          "657:       const delta = choice?.delta;",
          "659:       if (!delta) {",
          "660:         continue;",
          "661:       }",
          "663:       const newTokenIndices = {",
          "664:         prompt: options.promptIndex ?? 0,",
          "665:         completion: choice.index ?? 0,",
          "666:       };",
          "668:       const generationInfo = {",
          "669:         ...newTokenIndices,",
          "670:         finish_reason: choice.finish_reason,",
          "671:       };",
          "673:       const message = _convertDeltaToMessageChunk(",
          "674:         delta,",
          "675:         data,",
          "676:         this.model,",
          "677:         chunk.data.usage,",
          "678:         defaultRole",
          "679:       );",
          "681:       defaultRole =",
          "682:         (delta.role as TextChatMessagesTextChatMessageAssistant.Constants.Role) ??",
          "683:         defaultRole;",
          "685:       if (message === null || (!delta.content && !delta.tool_calls)) {",
          "686:         continue;",
          "687:       }",
          "689:       const generationChunk = new ChatGenerationChunk({",
          "690:         message,",
          "691:         text: delta.content ?? \"\",",
          "692:         generationInfo,",
          "693:       });",
          "695:       yield generationChunk;",
          "697:       void _runManager?.handleLLMNewToken(",
          "698:         generationChunk.text ?? \"\",",
          "699:         newTokenIndices,",
          "700:         undefined,",
          "701:         undefined,",
          "702:         undefined,",
          "703:         { chunk: generationChunk }",
          "704:       );",
          "705:     }",
          "706:   }",
          "709:   _combineLLMOutput() {",
          "710:     return [];",
          "711:   }",
          "713:   withStructuredOutput<",
          "715:     RunOutput extends Record<string, any> = Record<string, any>",
          "716:   >(",
          "717:     outputSchema:",
          "718:       | z.ZodType<RunOutput>",
          "720:       | Record<string, any>,",
          "721:     config?: StructuredOutputMethodOptions<false>",
          "722:   ): Runnable<BaseLanguageModelInput, RunOutput>;",
          "724:   withStructuredOutput<",
          "726:     RunOutput extends Record<string, any> = Record<string, any>",
          "727:   >(",
          "728:     outputSchema:",
          "729:       | z.ZodType<RunOutput>",
          "731:       | Record<string, any>,",
          "732:     config?: StructuredOutputMethodOptions<true>",
          "733:   ): Runnable<BaseLanguageModelInput, { raw: BaseMessage; parsed: RunOutput }>;",
          "735:   withStructuredOutput<",
          "737:     RunOutput extends Record<string, any> = Record<string, any>",
          "738:   >(",
          "739:     outputSchema:",
          "740:       | z.ZodType<RunOutput>",
          "742:       | Record<string, any>,",
          "743:     config?: StructuredOutputMethodOptions<boolean>",
          "744:   ):",
          "745:     | Runnable<BaseLanguageModelInput, RunOutput>",
          "746:     | Runnable<",
          "747:         BaseLanguageModelInput,",
          "748:         { raw: BaseMessage; parsed: RunOutput }",
          "749:       > {",
          "751:     const schema: z.ZodType<RunOutput> | Record<string, any> = outputSchema;",
          "752:     const name = config?.name;",
          "753:     const method = config?.method;",
          "754:     const includeRaw = config?.includeRaw;",
          "755:     let functionName = name ?? \"extract\";",
          "756:     let outputParser: BaseLLMOutputParser<RunOutput>;",
          "757:     let llm: Runnable<BaseLanguageModelInput>;",
          "758:     if (method === \"jsonMode\") {",
          "759:       const options = {",
          "760:         response_format: { type: \"json_object\" },",
          "761:       } as Partial<CallOptions>;",
          "762:       llm = this.bind(options);",
          "764:       if (isZodSchema(schema)) {",
          "765:         outputParser = StructuredOutputParser.fromZodSchema(schema);",
          "766:       } else {",
          "767:         outputParser = new JsonOutputParser<RunOutput>();",
          "768:       }",
          "769:     } else {",
          "770:       if (isZodSchema(schema)) {",
          "771:         const asJsonSchema = zodToJsonSchema(schema);",
          "772:         llm = this.bind({",
          "773:           tools: [",
          "774:             {",
          "775:               type: \"function\" as const,",
          "776:               function: {",
          "777:                 name: functionName,",
          "778:                 description: asJsonSchema.description,",
          "779:                 parameters: asJsonSchema,",
          "780:               },",
          "781:             },",
          "782:           ],",
          "784:           tool_choice: {",
          "785:             type: \"function\",",
          "786:             function: {",
          "787:               name: functionName,",
          "788:             },",
          "789:           },",
          "790:         } as Partial<CallOptions>);",
          "791:         outputParser = new WatsonxToolsOutputParser({",
          "792:           returnSingle: true,",
          "793:           keyName: functionName,",
          "794:           zodSchema: schema,",
          "795:         });",
          "796:       } else {",
          "797:         let openAIFunctionDefinition: FunctionDefinition;",
          "798:         if (",
          "799:           typeof schema.name === \"string\" &&",
          "800:           typeof schema.parameters === \"object\" &&",
          "801:           schema.parameters != null",
          "802:         ) {",
          "803:           openAIFunctionDefinition = schema as FunctionDefinition;",
          "804:           functionName = schema.name;",
          "805:         } else {",
          "806:           openAIFunctionDefinition = {",
          "807:             name: functionName,",
          "808:             description: schema.description ?? \"\",",
          "809:             parameters: schema,",
          "810:           };",
          "811:         }",
          "812:         llm = this.bind({",
          "813:           tools: [",
          "814:             {",
          "815:               type: \"function\" as const,",
          "816:               function: openAIFunctionDefinition,",
          "817:             },",
          "818:           ],",
          "820:           tool_choice: {",
          "821:             type: \"function\",",
          "822:             function: {",
          "823:               name: functionName,",
          "824:             },",
          "825:           },",
          "826:         } as Partial<CallOptions>);",
          "827:         outputParser = new WatsonxToolsOutputParser<RunOutput>({",
          "828:           returnSingle: true,",
          "829:           keyName: functionName,",
          "830:         });",
          "831:       }",
          "832:     }",
          "834:     if (!includeRaw) {",
          "835:       return llm.pipe(outputParser) as Runnable<",
          "836:         BaseLanguageModelInput,",
          "837:         RunOutput",
          "838:       >;",
          "839:     }",
          "841:     const parserAssign = RunnablePassthrough.assign({",
          "842:       parsed: (input: any, config) => outputParser.invoke(input.raw, config),",
          "843:     });",
          "844:     const parserNone = RunnablePassthrough.assign({",
          "845:       parsed: () => null,",
          "846:     });",
          "847:     const parsedWithFallback = parserAssign.withFallbacks({",
          "848:       fallbacks: [parserNone],",
          "849:     });",
          "850:     return RunnableSequence.from<",
          "851:       BaseLanguageModelInput,",
          "852:       { raw: BaseMessage; parsed: RunOutput }",
          "853:     >([",
          "854:       {",
          "855:         raw: llm,",
          "856:       },",
          "857:       parsedWithFallback,",
          "858:     ]);",
          "859:   }",
          "860: }",
          "",
          "---------------"
        ],
        "libs/langchain-community/src/chat_models/tests/ibm.int.test.ts||libs/langchain-community/src/chat_models/tests/ibm.int.test.ts": [
          "File: libs/langchain-community/src/chat_models/tests/ibm.int.test.ts -> libs/langchain-community/src/chat_models/tests/ibm.int.test.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "2: import {",
          "3:   AIMessage,",
          "4:   AIMessageChunk,",
          "5:   HumanMessage,",
          "6:   SystemMessage,",
          "7: } from \"@langchain/core/messages\";",
          "8: import { z } from \"zod\";",
          "9: import { StringOutputParser } from \"@langchain/core/output_parsers\";",
          "10: import { CallbackManager } from \"@langchain/core/callbacks/manager\";",
          "11: import { LLMResult } from \"@langchain/core/outputs\";",
          "12: import { ChatPromptTemplate } from \"@langchain/core/prompts\";",
          "13: import { tool } from \"@langchain/core/tools\";",
          "14: import { NewTokenIndices } from \"@langchain/core/callbacks/base\";",
          "15: import * as fs from \"node:fs/promises\";",
          "16: import { fileURLToPath } from \"node:url\";",
          "17: import * as path from \"node:path\";",
          "18: import { ChatWatsonx } from \"../ibm.js\";",
          "20: describe(\"Tests for chat\", () => {",
          "21:   describe(\"Test ChatWatsonx invoke and generate\", () => {",
          "22:     test(\"Basic invoke\", async () => {",
          "23:       const service = new ChatWatsonx({",
          "24:         version: \"2024-05-31\",",
          "25:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "26:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "27:       });",
          "28:       const res = await service.invoke(\"Print hello world\");",
          "29:       expect(res).toBeInstanceOf(AIMessage);",
          "30:     });",
          "31:     test(\"Basic generate\", async () => {",
          "32:       const service = new ChatWatsonx({",
          "33:         version: \"2024-05-31\",",
          "34:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "35:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "36:       });",
          "37:       const message = new HumanMessage(\"Hello\");",
          "38:       const res = await service.generate([[message], [message]]);",
          "39:       expect(res.generations.length).toBe(2);",
          "40:     });",
          "41:     test(\"Invoke with system message\", async () => {",
          "42:       const service = new ChatWatsonx({",
          "43:         version: \"2024-05-31\",",
          "44:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "45:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "46:       });",
          "47:       const messages = [",
          "48:         new SystemMessage(\"Translate the following from English into Italian\"),",
          "49:         new HumanMessage(\"hi!\"),",
          "50:       ];",
          "51:       const res = await service.invoke(messages);",
          "52:       expect(res).toBeInstanceOf(AIMessage);",
          "53:     });",
          "54:     test(\"Invoke with output parser\", async () => {",
          "55:       const service = new ChatWatsonx({",
          "56:         version: \"2024-05-31\",",
          "57:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "58:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "59:       });",
          "60:       const parser = new StringOutputParser();",
          "61:       const messages = [",
          "62:         new SystemMessage(\"Translate the following from English into Italian\"),",
          "63:         new HumanMessage(\"hi!\"),",
          "64:       ];",
          "65:       const res = await service.invoke(messages);",
          "66:       const parsed = await parser.invoke(res);",
          "67:       expect(typeof parsed).toBe(\"string\");",
          "68:     });",
          "69:     test(\"Invoke with prompt\", async () => {",
          "70:       const service = new ChatWatsonx({",
          "71:         version: \"2024-05-31\",",
          "72:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "73:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "74:       });",
          "75:       const systemTemplate = \"Translate the following into {language}:\";",
          "76:       const promptTemplate = ChatPromptTemplate.fromMessages([",
          "77:         [\"system\", systemTemplate],",
          "78:         [\"user\", \"{text}\"],",
          "79:       ]);",
          "80:       const llmChain = promptTemplate.pipe(service);",
          "81:       const res = await llmChain.invoke({ language: \"italian\", text: \"hi\" });",
          "82:       expect(res).toBeInstanceOf(AIMessage);",
          "83:     });",
          "84:     test(\"Invoke with chat conversation\", async () => {",
          "85:       const service = new ChatWatsonx({",
          "86:         version: \"2024-05-31\",",
          "87:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "88:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "89:       });",
          "90:       const res = await service.invoke([",
          "91:         { role: \"user\", content: \"Hi! I'm Bob\" },",
          "92:         {",
          "93:           role: \"assistant\",",
          "94:           content: \"Hello Bob! How can I assist you today?\",",
          "95:         },",
          "96:         { role: \"user\", content: \"What's my name?\" },",
          "97:       ]);",
          "98:       expect(res).toBeInstanceOf(AIMessage);",
          "99:     });",
          "100:     test(\"Token usage\", async () => {",
          "101:       let tokenUsage = {",
          "102:         completion_tokens: 0,",
          "103:         prompt_tokens: 0,",
          "104:         totalTokens: 0,",
          "105:       };",
          "106:       const service = new ChatWatsonx({",
          "107:         version: \"2024-05-31\",",
          "108:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "109:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "110:         callbackManager: CallbackManager.fromHandlers({",
          "111:           async handleLLMEnd(output: LLMResult) {",
          "112:             tokenUsage = output.llmOutput?.tokenUsage;",
          "113:           },",
          "114:         }),",
          "115:       });",
          "117:       const message = new HumanMessage(\"Hello\");",
          "118:       await service.invoke([message]);",
          "119:       expect(tokenUsage.prompt_tokens).toBeGreaterThan(0);",
          "120:     });",
          "121:     test(\"Timeout\", async () => {",
          "122:       const service = new ChatWatsonx({",
          "123:         version: \"2024-05-31\",",
          "124:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "125:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "126:       });",
          "127:       await expect(() =>",
          "128:         service.invoke(\"Print hello world\", {",
          "129:           timeout: 10,",
          "130:         })",
          "131:       ).rejects.toThrow();",
          "132:     }, 5000);",
          "133:     test(\"Controller options\", async () => {",
          "134:       const service = new ChatWatsonx({",
          "135:         version: \"2024-05-31\",",
          "136:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "137:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "138:       });",
          "139:       const controller = new AbortController();",
          "140:       await expect(() => {",
          "141:         const res = service.invoke(\"Print hello world\", {",
          "142:           signal: controller.signal,",
          "143:         });",
          "144:         controller.abort();",
          "145:         return res;",
          "146:       }).rejects.toThrow();",
          "147:     }, 5000);",
          "148:   });",
          "150:   describe(\"Test ChatWatsonx invoke and generate with stream mode\", () => {",
          "151:     test(\"Basic invoke\", async () => {",
          "152:       const service = new ChatWatsonx({",
          "153:         version: \"2024-05-31\",",
          "154:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "155:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "156:       });",
          "157:       const res = await service.invoke(\"Print hello world\");",
          "159:       expect(res).toBeInstanceOf(AIMessage);",
          "160:     });",
          "161:     test(\"Basic generate\", async () => {",
          "162:       const service = new ChatWatsonx({",
          "163:         version: \"2024-05-31\",",
          "164:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "165:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "166:       });",
          "167:       const message = new HumanMessage(\"Hello\");",
          "168:       const res = await service.generate([[message], [message]]);",
          "169:       expect(res.generations.length).toBe(2);",
          "170:     });",
          "171:     test(\"Generate with n>1\", async () => {",
          "172:       const service = new ChatWatsonx({",
          "173:         version: \"2024-05-31\",",
          "174:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "175:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "176:         n: 3,",
          "177:       });",
          "178:       const message = new HumanMessage(\"Print hello world\");",
          "179:       const res = await service.generate([[message]]);",
          "180:       for (const generation of res.generations) {",
          "181:         expect(generation.length).toBe(3);",
          "182:         for (const gen of generation) {",
          "183:           expect(typeof gen.text).toBe(\"string\");",
          "184:         }",
          "185:       }",
          "186:     });",
          "187:     test(\"Generate with n>1 token count\", async () => {",
          "188:       process.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"false\";",
          "190:       let tokenUsage = {",
          "191:         input_tokens: 0,",
          "192:         output_tokens: 0,",
          "193:         total_tokens: 0,",
          "194:       };",
          "195:       const generationsStreamed = [",
          "196:         [\"\", \"\"],",
          "197:         [\"\", \"\"],",
          "198:       ];",
          "199:       let tokenUsed = 0;",
          "200:       const service = new ChatWatsonx({",
          "201:         version: \"2024-05-31\",",
          "202:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "203:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "204:         n: 2,",
          "205:         max_new_tokens: 5,",
          "206:         streaming: true,",
          "207:         callbackManager: CallbackManager.fromHandlers({",
          "208:           async handleLLMEnd(output: LLMResult) {",
          "209:             const usage = output.llmOutput?.tokenUsage;",
          "210:             tokenUsage = {",
          "211:               input_tokens: usage.input_tokens + tokenUsage.input_tokens,",
          "212:               output_tokens: usage.output_tokens + tokenUsage.output_tokens,",
          "213:               total_tokens: usage.total_tokens + tokenUsage.total_tokens,",
          "214:             };",
          "215:           },",
          "216:           async handleLLMNewToken(token: string, idx: NewTokenIndices) {",
          "217:             const { prompt, completion } = idx;",
          "218:             generationsStreamed[prompt][completion] += token;",
          "219:             tokenUsed += 1;",
          "220:           },",
          "221:         }),",
          "222:       });",
          "223:       const message = new HumanMessage(\"Print hello world\");",
          "224:       const res = await service.generate([[message], [message]]);",
          "226:       for (const generation of res.generations) {",
          "227:         expect(generation.length).toBe(2);",
          "228:         for (const gen of generation) {",
          "229:           expect(typeof gen.text).toBe(\"string\");",
          "230:         }",
          "231:       }",
          "232:       expect(tokenUsed).toBe(tokenUsage.output_tokens);",
          "233:       expect(res.generations.map((g) => g.map((gg) => gg.text))).toEqual(",
          "234:         generationsStreamed",
          "235:       );",
          "236:     });",
          "237:     test(\"Invoke with system message\", async () => {",
          "238:       const service = new ChatWatsonx({",
          "239:         version: \"2024-05-31\",",
          "240:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "241:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "242:       });",
          "243:       const messages = [",
          "244:         new SystemMessage(\"Translate the following from English into Italian\"),",
          "245:         new HumanMessage(\"hi!\"),",
          "246:       ];",
          "247:       const res = await service.invoke(messages);",
          "248:       expect(res).toBeInstanceOf(AIMessage);",
          "249:     });",
          "250:     test(\"Invoke with output parser\", async () => {",
          "251:       const service = new ChatWatsonx({",
          "252:         version: \"2024-05-31\",",
          "253:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "254:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "255:       });",
          "256:       const parser = new StringOutputParser();",
          "257:       const messages = [",
          "258:         new SystemMessage(\"Translate the following from English into Italian\"),",
          "259:         new HumanMessage(\"hi!\"),",
          "260:       ];",
          "261:       const res = await service.invoke(messages);",
          "262:       const parsed = await parser.invoke(res);",
          "263:       expect(typeof parsed).toBe(\"string\");",
          "264:     });",
          "265:     test(\"Invoke with prompt\", async () => {",
          "266:       const service = new ChatWatsonx({",
          "267:         version: \"2024-05-31\",",
          "268:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "269:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "270:       });",
          "271:       const systemTemplate = \"Translate the following into {language}:\";",
          "272:       const promptTemplate = ChatPromptTemplate.fromMessages([",
          "273:         [\"system\", systemTemplate],",
          "274:         [\"user\", \"{text}\"],",
          "275:       ]);",
          "276:       const llmChain = promptTemplate.pipe(service);",
          "277:       const res = await llmChain.invoke({ language: \"italian\", text: \"hi\" });",
          "278:       expect(res).toBeInstanceOf(AIMessage);",
          "279:     });",
          "280:     test(\"Invoke with chat conversation\", async () => {",
          "281:       const service = new ChatWatsonx({",
          "282:         version: \"2024-05-31\",",
          "283:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "284:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "285:       });",
          "286:       const res = await service.invoke([",
          "287:         { role: \"user\", content: \"Hi! I'm Bob\" },",
          "288:         {",
          "289:           role: \"assistant\",",
          "290:           content: \"Hello Bob! How can I assist you today?\",",
          "291:         },",
          "292:         { role: \"user\", content: \"What's my name?\" },",
          "293:       ]);",
          "294:       expect(res).toBeInstanceOf(AIMessage);",
          "295:     });",
          "296:     test(\"Token usage\", async () => {",
          "297:       let tokenUsage = {",
          "298:         completion_tokens: 0,",
          "299:         prompt_tokens: 0,",
          "300:         totalTokens: 0,",
          "301:       };",
          "302:       const service = new ChatWatsonx({",
          "303:         version: \"2024-05-31\",",
          "304:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "305:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "306:         callbackManager: CallbackManager.fromHandlers({",
          "307:           async handleLLMEnd(output: LLMResult) {",
          "308:             tokenUsage = output.llmOutput?.tokenUsage;",
          "309:           },",
          "310:         }),",
          "311:       });",
          "313:       const message = new HumanMessage(\"Hello\");",
          "314:       await service.invoke([message]);",
          "315:       expect(tokenUsage.prompt_tokens).toBeGreaterThan(0);",
          "316:     });",
          "317:     test(\"Timeout\", async () => {",
          "318:       const service = new ChatWatsonx({",
          "319:         version: \"2024-05-31\",",
          "320:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "321:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "322:       });",
          "323:       await expect(() =>",
          "324:         service.invoke(\"Print hello world\", {",
          "325:           timeout: 10,",
          "326:         })",
          "327:       ).rejects.toThrow();",
          "328:     }, 5000);",
          "329:     test(\"Controller options\", async () => {",
          "330:       const service = new ChatWatsonx({",
          "331:         version: \"2024-05-31\",",
          "332:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "333:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "334:       });",
          "335:       const controller = new AbortController();",
          "336:       await expect(() => {",
          "337:         const res = service.invoke(\"Print hello world\", {",
          "338:           signal: controller.signal,",
          "339:         });",
          "340:         controller.abort();",
          "341:         return res;",
          "342:       }).rejects.toThrow();",
          "343:     }, 5000);",
          "344:   });",
          "346:   describe(\"Test ChatWatsonx stream\", () => {",
          "347:     test(\"Basic stream\", async () => {",
          "348:       const service = new ChatWatsonx({",
          "349:         version: \"2024-05-31\",",
          "350:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "351:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "352:       });",
          "353:       const prompt = ChatPromptTemplate.fromMessages([",
          "354:         [\"system\", \"You are a helpful assistant\"],",
          "355:         [\"human\", \"{input}\"],",
          "356:       ]);",
          "357:       const res = await prompt.pipe(service).stream({",
          "358:         input: \"Print hello world.\",",
          "359:       });",
          "360:       const chunks = [];",
          "361:       for await (const chunk of res) {",
          "362:         chunks.push(chunk);",
          "363:       }",
          "364:       expect(chunks.length).toBeGreaterThan(1);",
          "365:       expect(chunks.join(\"\").length).toBeGreaterThan(1);",
          "366:     });",
          "367:     test(\"Timeout\", async () => {",
          "368:       const service = new ChatWatsonx({",
          "369:         version: \"2024-05-31\",",
          "370:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "371:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "372:       });",
          "373:       await expect(() =>",
          "374:         service.stream(\"Print hello world\", {",
          "375:           timeout: 10,",
          "376:         })",
          "377:       ).rejects.toThrow();",
          "378:     }, 5000);",
          "379:     test(\"Controller options\", async () => {",
          "380:       const service = new ChatWatsonx({",
          "381:         version: \"2024-05-31\",",
          "382:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "383:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "384:       });",
          "385:       const controller = new AbortController();",
          "386:       await expect(async () => {",
          "387:         const res = await service.stream(\"Print hello world\", {",
          "388:           signal: controller.signal,",
          "389:         });",
          "390:         let hasEntered = false;",
          "391:         for await (const chunk of res) {",
          "392:           hasEntered = true;",
          "393:           expect(chunk).toBeDefined();",
          "394:           controller.abort();",
          "395:         }",
          "396:         expect(hasEntered).toBe(true);",
          "397:       }).rejects.toThrow();",
          "398:     }, 5000);",
          "399:     test(\"Token count and response equality\", async () => {",
          "400:       let generation = \"\";",
          "401:       const service = new ChatWatsonx({",
          "402:         version: \"2024-05-31\",",
          "403:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "404:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "405:         callbackManager: CallbackManager.fromHandlers({",
          "406:           async handleLLMEnd(output: LLMResult) {",
          "407:             generation = output.generations[0][0].text;",
          "408:           },",
          "409:         }),",
          "410:       });",
          "411:       const prompt = ChatPromptTemplate.fromMessages([",
          "412:         [\"system\", \"You are a helpful assistant\"],",
          "413:         [\"human\", \"{input}\"],",
          "414:       ]);",
          "415:       const res = await prompt.pipe(service).stream({",
          "416:         input: \"Print hello world\",",
          "417:       });",
          "418:       let tokenCount = 0;",
          "419:       const chunks = [];",
          "420:       for await (const chunk of res) {",
          "421:         tokenCount += 1;",
          "422:         chunks.push(chunk.content);",
          "423:       }",
          "424:       expect(tokenCount).toBeGreaterThan(1);",
          "425:       expect(chunks.join(\"\")).toBe(generation);",
          "426:     });",
          "427:     test(\"Token count usage_metadata\", async () => {",
          "428:       const service = new ChatWatsonx({",
          "429:         version: \"2024-05-31\",",
          "430:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "431:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "432:       });",
          "433:       let res: AIMessageChunk | null = null;",
          "434:       const stream = await service.stream(\"Why is the sky blue? Be concise.\");",
          "435:       for await (const chunk of stream) {",
          "436:         res = chunk;",
          "437:       }",
          "438:       expect(res?.usage_metadata).toBeDefined();",
          "439:       if (!res?.usage_metadata) {",
          "440:         return;",
          "441:       }",
          "442:       expect(res.usage_metadata.input_tokens).toBeGreaterThan(1);",
          "443:       expect(res.usage_metadata.output_tokens).toBe(1);",
          "444:       expect(res.usage_metadata.total_tokens).toBe(",
          "445:         res.usage_metadata.input_tokens + res.usage_metadata.output_tokens",
          "446:       );",
          "447:     });",
          "448:   });",
          "450:   describe(\"Test tool usage\", () => {",
          "451:     test(\"Passing tool to chat model\", async () => {",
          "452:       const service = new ChatWatsonx({",
          "453:         version: \"2024-05-31\",",
          "454:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "455:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "456:       });",
          "457:       const calculatorSchema = z.object({",
          "458:         operation: z",
          "459:           .enum([\"add\", \"subtract\", \"multiply\", \"divide\"])",
          "460:           .describe(\"The type of operation to execute.\"),",
          "461:         number1: z.number().describe(\"The first number to operate on.\"),",
          "462:         number2: z.number().describe(\"The second number to operate on.\"),",
          "463:       });",
          "465:       const calculatorTool = tool(",
          "466:         async ({",
          "467:           operation,",
          "468:           number1,",
          "469:           number2,",
          "470:         }: {",
          "471:           operation: string;",
          "472:           number1: number;",
          "473:           number2: number;",
          "474:         }) => {",
          "476:           if (operation === \"add\") {",
          "477:             return `${number1 + number2}`;",
          "478:           } else if (operation === \"subtract\") {",
          "479:             return `${number1 - number2}`;",
          "480:           } else if (operation === \"multiply\") {",
          "481:             return `${number1 * number2}`;",
          "482:           } else if (operation === \"divide\") {",
          "483:             return `${number1 / number2}`;",
          "484:           } else {",
          "485:             throw new Error(\"Invalid operation.\");",
          "486:           }",
          "487:         },",
          "488:         {",
          "489:           name: \"calculator\",",
          "490:           description: \"Can perform mathematical operations.\",",
          "491:           schema: calculatorSchema,",
          "492:         }",
          "493:       );",
          "494:       const llmWithTools = service.bindTools([calculatorTool]);",
          "495:       const res = await llmWithTools.invoke(\"What is 3 * 12\");",
          "497:       expect(res).toBeInstanceOf(AIMessage);",
          "498:       expect(res.tool_calls?.[0].name).toBe(\"calculator\");",
          "499:       expect(typeof res.tool_calls?.[0].args?.operation).toBe(\"string\");",
          "500:       expect(typeof res.tool_calls?.[0].args?.number1).toBe(\"number\");",
          "501:       expect(typeof res.tool_calls?.[0].args?.number2).toBe(\"number\");",
          "502:       expect(res.response_metadata.finish_reason).toBe(\"tool_calls\");",
          "503:     });",
          "504:     test(\"Passing tool to chat model extended\", async () => {",
          "505:       const service = new ChatWatsonx({",
          "506:         version: \"2024-05-31\",",
          "507:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "508:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "509:       });",
          "510:       const calculatorSchema = z.object({",
          "511:         operation: z",
          "512:           .enum([\"add\", \"subtract\", \"multiply\", \"divide\"])",
          "513:           .describe(\"The type of operation to execute.\"),",
          "514:         number1: z.number().describe(\"The first number to operate on.\"),",
          "515:         number2: z.number().describe(\"The second number to operate on.\"),",
          "516:       });",
          "518:       const calculatorTool = tool(",
          "519:         async ({",
          "520:           operation,",
          "521:           number1,",
          "522:           number2,",
          "523:         }: {",
          "524:           operation: string;",
          "525:           number1: number;",
          "526:           number2: number;",
          "527:         }) => {",
          "529:           if (operation === \"add\") {",
          "530:             return `${number1 + number2}`;",
          "531:           } else if (operation === \"subtract\") {",
          "532:             return `${number1 - number2}`;",
          "533:           } else if (operation === \"multiply\") {",
          "534:             return `${number1 * number2}`;",
          "535:           } else if (operation === \"divide\") {",
          "536:             return `${number1 / number2}`;",
          "537:           } else {",
          "538:             throw new Error(\"Invalid operation.\");",
          "539:           }",
          "540:         },",
          "541:         {",
          "542:           name: \"calculator\",",
          "543:           description: \"Can perform mathematical operations.\",",
          "544:           schema: calculatorSchema,",
          "545:         }",
          "546:       );",
          "547:       const llmWithTools = service.bindTools([calculatorTool]);",
          "548:       const res = await llmWithTools.invoke(",
          "549:         \"What is 3 * 12? Also, what is 11 + 49?\"",
          "550:       );",
          "552:       expect(res).toBeInstanceOf(AIMessage);",
          "553:       expect(res.tool_calls).toBeDefined();",
          "554:       if (!res.tool_calls) return;",
          "555:       expect(res.tool_calls.length).toBe(2);",
          "557:       for (const tool_call of res.tool_calls) {",
          "558:         expect(tool_call.name).toBe(\"calculator\");",
          "559:         expect(typeof tool_call.args?.operation).toBe(\"string\");",
          "560:         expect(typeof tool_call.args?.number1).toBe(\"number\");",
          "561:         expect(typeof tool_call.args?.number2).toBe(\"number\");",
          "562:       }",
          "563:     });",
          "564:     test(\"Binding model-specific formats\", async () => {",
          "565:       const service = new ChatWatsonx({",
          "566:         version: \"2024-05-31\",",
          "567:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "568:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "569:       });",
          "571:       const modelWithTools = service.bind({",
          "572:         tools: [",
          "573:           {",
          "574:             type: \"function\",",
          "575:             function: {",
          "576:               name: \"calculator\",",
          "577:               description: \"Can perform mathematical operations.\",",
          "578:               parameters: {",
          "579:                 type: \"object\",",
          "580:                 properties: {",
          "581:                   operation: {",
          "582:                     type: \"string\",",
          "583:                     description: \"The type of operation to execute.\",",
          "584:                     enum: [\"add\", \"subtract\", \"multiply\", \"divide\"],",
          "585:                   },",
          "586:                   number1: { type: \"number\", description: \"First integer\" },",
          "587:                   number2: { type: \"number\", description: \"Second integer\" },",
          "588:                 },",
          "589:                 required: [\"number1\", \"number2\"],",
          "590:               },",
          "591:             },",
          "592:           },",
          "593:         ],",
          "594:       });",
          "595:       const res = await modelWithTools.invoke(\"What is 32 * 122\");",
          "597:       expect(res).toBeInstanceOf(AIMessage);",
          "598:       expect(res.tool_calls?.[0].name).toBe(\"calculator\");",
          "599:       expect(typeof res.tool_calls?.[0].args?.operation).toBe(\"string\");",
          "600:       expect(typeof res.tool_calls?.[0].args?.number1).toBe(\"number\");",
          "601:       expect(typeof res.tool_calls?.[0].args?.number2).toBe(\"number\");",
          "602:       expect(res.response_metadata.finish_reason).toBe(\"tool_calls\");",
          "603:     });",
          "604:     test(\"Passing tool to chat model\", async () => {",
          "605:       const service = new ChatWatsonx({",
          "606:         version: \"2024-05-31\",",
          "607:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "608:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "609:       });",
          "610:       const addTool = tool(",
          "611:         async (input) => {",
          "612:           return input.a + input.b;",
          "613:         },",
          "614:         {",
          "615:           name: \"add\",",
          "616:           description: \"Adds a and b.\",",
          "617:           schema: z.object({",
          "618:             a: z.number(),",
          "619:             b: z.number(),",
          "620:           }),",
          "621:         }",
          "622:       );",
          "624:       const multiplyTool = tool(",
          "625:         async (input) => {",
          "626:           return input.a * input.b;",
          "627:         },",
          "628:         {",
          "629:           name: \"multiply\",",
          "630:           description: \"Multiplies a and b.\",",
          "631:           schema: z.object({",
          "632:             a: z.number(),",
          "633:             b: z.number(),",
          "634:           }),",
          "635:         }",
          "636:       );",
          "637:       const tools = [addTool, multiplyTool];",
          "639:       const modelWithTools = service.bindTools(tools);",
          "640:       const res = await modelWithTools.invoke(",
          "641:         \"What is 3 * 12? Also, what is 11 + 49?\"",
          "642:       );",
          "644:       expect(res).toBeInstanceOf(AIMessage);",
          "645:       expect(res.tool_calls).toBeDefined();",
          "646:       if (!res.tool_calls) return;",
          "647:       expect(res.tool_calls.length).toBe(2);",
          "649:       expect(res.tool_calls[0].name).not.toBe(res.tool_calls[1].name);",
          "650:       expect(res.tool_calls[0].args.a).not.toBe(res.tool_calls[1].args.a);",
          "651:       expect(res.tool_calls[0].args.b).not.toBe(res.tool_calls[1].args.b);",
          "652:     });",
          "653:   });",
          "655:   describe(\"Test withStructuredOutput usage\", () => {",
          "656:     test(\"Schema with zod\", async () => {",
          "657:       const service = new ChatWatsonx({",
          "658:         version: \"2024-05-31\",",
          "659:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "660:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "661:       });",
          "662:       const joke = z.object({",
          "663:         setup: z.string().describe(\"The setup of the joke\"),",
          "664:         punchline: z.string().describe(\"The punchline to the joke\"),",
          "665:         rating: z",
          "666:           .number()",
          "667:           .optional()",
          "668:           .describe(\"How funny the joke is, from 1 to 10\"),",
          "669:       });",
          "671:       const structuredLlm = service.withStructuredOutput(joke);",
          "673:       const res = await structuredLlm.invoke(\"Tell me a joke about cats\");",
          "674:       expect(\"setup\" in res).toBe(true);",
          "675:       expect(\"punchline\" in res).toBe(true);",
          "676:     });",
          "678:     test(\"Schema with zod and stream\", async () => {",
          "679:       const service = new ChatWatsonx({",
          "680:         version: \"2024-05-31\",",
          "681:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "682:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "683:         temperature: 0.2,",
          "684:       });",
          "685:       const joke = z.object({",
          "686:         setup: z.string().describe(\"The setup of the joke\"),",
          "687:         punchline: z.string().describe(\"The punchline to the joke\"),",
          "688:         rating: z",
          "689:           .number()",
          "690:           .optional()",
          "691:           .describe(\"How funny the joke is, from 1 to 10\"),",
          "692:       });",
          "694:       const structuredLlm = service.withStructuredOutput(joke);",
          "695:       const res = await structuredLlm.stream(\"Tell me a joke about cats\");",
          "696:       let object = {};",
          "697:       for await (const chunk of res) {",
          "698:         expect(typeof chunk).toBe(\"object\");",
          "699:         object = chunk;",
          "700:       }",
          "701:       expect(\"setup\" in object).toBe(true);",
          "702:       expect(\"punchline\" in object).toBe(true);",
          "703:     });",
          "704:     test(\"Schema with object\", async () => {",
          "705:       const service = new ChatWatsonx({",
          "706:         version: \"2024-05-31\",",
          "707:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "708:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "709:         temperature: 0.2,",
          "710:       });",
          "711:       const structuredLlm = service.withStructuredOutput({",
          "712:         name: \"joke\",",
          "713:         description: \"Joke to tell user.\",",
          "714:         parameters: {",
          "715:           title: \"Joke\",",
          "716:           type: \"object\",",
          "717:           properties: {",
          "718:             setup: { type: \"string\", description: \"The setup for the joke\" },",
          "719:             punchline: { type: \"string\", description: \"The joke's punchline\" },",
          "720:           },",
          "721:           required: [\"setup\", \"punchline\"],",
          "722:         },",
          "723:       });",
          "725:       const res = await structuredLlm.invoke(\"Tell me a joke about cats\");",
          "726:       expect(res).toBeDefined();",
          "727:       expect(typeof res.setup).toBe(\"string\");",
          "728:       expect(typeof res.punchline).toBe(\"string\");",
          "729:     });",
          "730:     test(\"Schema with rawOutput\", async () => {",
          "731:       const service = new ChatWatsonx({",
          "732:         version: \"2024-05-31\",",
          "733:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "734:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "735:         temperature: 0.2,",
          "736:       });",
          "737:       const structuredLlm = service.withStructuredOutput(",
          "738:         {",
          "739:           name: \"joke\",",
          "740:           description: \"Joke to tell user.\",",
          "741:           parameters: {",
          "742:             title: \"Joke\",",
          "743:             type: \"object\",",
          "744:             properties: {",
          "745:               setup: { type: \"string\", description: \"The setup for the joke\" },",
          "746:               punchline: {",
          "747:                 type: \"string\",",
          "748:                 description: \"The joke's punchline\",",
          "749:               },",
          "750:             },",
          "751:             required: [\"setup\", \"punchline\"],",
          "752:           },",
          "753:         },",
          "754:         { includeRaw: true }",
          "755:       );",
          "757:       const res = await structuredLlm.invoke(\"Tell me a joke about cats\");",
          "758:       expect(res.raw).toBeInstanceOf(AIMessage);",
          "759:       expect(typeof res.parsed.setup).toBe(\"string\");",
          "760:       expect(typeof res.parsed.setup).toBe(\"string\");",
          "761:     });",
          "762:     test(\"Schema with zod and JSON mode\", async () => {",
          "763:       const service = new ChatWatsonx({",
          "764:         version: \"2024-05-31\",",
          "765:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "766:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "767:         temperature: 0,",
          "768:       });",
          "769:       const calculatorSchema = z.object({",
          "770:         operation: z.enum([\"add\", \"subtract\", \"multiply\", \"divide\"]),",
          "771:         number1: z.number(),",
          "772:         number2: z.number(),",
          "773:       });",
          "774:       const modelWithStructuredOutput = service.withStructuredOutput(",
          "775:         calculatorSchema,",
          "776:         {",
          "777:           name: \"calculator\",",
          "778:           method: \"jsonMode\",",
          "779:         }",
          "780:       );",
          "781:       const prompt = ChatPromptTemplate.fromMessages([",
          "782:         {",
          "783:           role: \"system\",",
          "784:           content: `Reply structure should be type of JSON as followed:",
          "785:     'operation': the type of operation to execute, either 'add', 'subtract', 'multiply' or 'divide',",
          "786:     'number1': the first number to operate on,",
          "787:     'number2': the second number to operate on.",
          "788:     `,",
          "789:         },",
          "790:         { role: \"human\", content: \"What is 21 * 12?\" },",
          "791:       ]);",
          "792:       const modelWithStructuredOutoputJson = prompt.pipe(",
          "793:         modelWithStructuredOutput",
          "794:       );",
          "795:       const result = await modelWithStructuredOutoputJson.invoke(\"\");",
          "796:       expect(typeof result.operation).toBe(\"string\");",
          "797:       expect(typeof result.number1).toBe(\"number\");",
          "798:       expect(typeof result.number2).toBe(\"number\");",
          "799:     });",
          "800:   });",
          "802:   describe(\"Test image input\", () => {",
          "803:     test(\"Image input\", async () => {",
          "804:       const service = new ChatWatsonx({",
          "805:         version: \"2024-05-31\",",
          "806:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "807:         model: \"meta-llama/llama-3-2-11b-vision-instruct\",",
          "808:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "809:         max_new_tokens: 100,",
          "810:       });",
          "811:       const __filename = fileURLToPath(import.meta.url);",
          "812:       const __dirname = path.dirname(__filename);",
          "813:       const encodedString = await fs.readFile(",
          "814:         path.join(__dirname, \"/data/hotdog.jpg\")",
          "815:       );",
          "816:       const question = \"What is on the picture\";",
          "817:       const messages = [",
          "818:         {",
          "819:           role: \"user\",",
          "820:           content: [",
          "821:             {",
          "822:               type: \"text\",",
          "823:               text: question,",
          "824:             },",
          "825:             {",
          "826:               type: \"image_url\",",
          "827:               image_url: {",
          "828:                 url:",
          "829:                   \"data:image/jpeg;base64,\" + encodedString.toString(\"base64\"),",
          "830:               },",
          "831:             },",
          "832:           ],",
          "833:         },",
          "834:       ];",
          "835:       const res = await service.stream(messages);",
          "836:       const chunks = [];",
          "837:       for await (const chunk of res) {",
          "838:         expect(chunk).toBeInstanceOf(AIMessageChunk);",
          "839:         chunks.push(chunk.content);",
          "840:       }",
          "841:       expect(typeof chunks.join(\"\")).toBe(\"string\");",
          "842:     });",
          "843:   });",
          "844: });",
          "",
          "---------------"
        ],
        "libs/langchain-community/src/chat_models/tests/ibm.standard.int.test.ts||libs/langchain-community/src/chat_models/tests/ibm.standard.int.test.ts": [
          "File: libs/langchain-community/src/chat_models/tests/ibm.standard.int.test.ts -> libs/langchain-community/src/chat_models/tests/ibm.standard.int.test.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "2: import { test, expect } from \"@jest/globals\";",
          "3: import { ChatModelIntegrationTests } from \"@langchain/standard-tests\";",
          "4: import { AIMessageChunk } from \"@langchain/core/messages\";",
          "5: import {",
          "6:   ChatWatsonx,",
          "7:   ChatWatsonxInput,",
          "8:   WatsonxCallOptionsChat,",
          "9:   WatsonxCallParams,",
          "10: } from \"../ibm.js\";",
          "11: import { WatsonxAuth } from \"../../types/ibm.js\";",
          "13: class ChatWatsonxStandardIntegrationTests extends ChatModelIntegrationTests<",
          "14:   WatsonxCallOptionsChat,",
          "15:   AIMessageChunk,",
          "16:   ChatWatsonxInput &",
          "17:     WatsonxAuth &",
          "18:     Partial<Omit<WatsonxCallParams, \"tool_choice\">>",
          "19: > {",
          "20:   constructor() {",
          "21:     if (!process.env.WATSONX_AI_APIKEY) {",
          "22:       throw new Error(\"Cannot run tests. Api key not provided\");",
          "23:     }",
          "24:     super({",
          "25:       Cls: ChatWatsonx,",
          "26:       chatModelHasToolCalling: true,",
          "27:       chatModelHasStructuredOutput: true,",
          "28:       constructorArgs: {",
          "29:         version: \"2024-05-31\",",
          "30:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "31:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "32:         temperature: 0,",
          "33:       },",
          "34:     });",
          "35:   }",
          "36: }",
          "38: const testClass = new ChatWatsonxStandardIntegrationTests();",
          "40: test(\"ChatWatsonxStandardIntegrationTests\", async () => {",
          "41:   const testResults = await testClass.runTests();",
          "42:   expect(testResults).toBe(true);",
          "43: });",
          "",
          "---------------"
        ],
        "libs/langchain-community/src/chat_models/tests/ibm.standard.test.ts||libs/langchain-community/src/chat_models/tests/ibm.standard.test.ts": [
          "File: libs/langchain-community/src/chat_models/tests/ibm.standard.test.ts -> libs/langchain-community/src/chat_models/tests/ibm.standard.test.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "2: import { test, expect } from \"@jest/globals\";",
          "3: import { ChatModelUnitTests } from \"@langchain/standard-tests\";",
          "4: import { AIMessageChunk } from \"@langchain/core/messages\";",
          "5: import { LangSmithParams } from \"@langchain/core/language_models/chat_models\";",
          "6: import {",
          "7:   ChatWatsonx,",
          "8:   ChatWatsonxInput,",
          "9:   WatsonxCallOptionsChat,",
          "10:   WatsonxCallParams,",
          "11: } from \"../ibm.js\";",
          "12: import { WatsonxAuth } from \"../../types/ibm.js\";",
          "14: class ChatWatsonxStandardTests extends ChatModelUnitTests<",
          "15:   WatsonxCallOptionsChat,",
          "16:   AIMessageChunk,",
          "17:   ChatWatsonxInput &",
          "18:     WatsonxAuth &",
          "19:     Partial<Omit<WatsonxCallParams, \"tool_choice\">>",
          "20: > {",
          "21:   constructor() {",
          "22:     super({",
          "23:       Cls: ChatWatsonx,",
          "24:       chatModelHasToolCalling: true,",
          "25:       chatModelHasStructuredOutput: true,",
          "26:       constructorArgs: {",
          "27:         watsonxAIApikey: \"testString\",",
          "28:         version: \"2024-05-31\",",
          "29:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "30:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "31:         watsonxAIAuthType: \"iam\",",
          "32:       },",
          "33:     });",
          "34:   }",
          "36:   expectedLsParams(): Partial<LangSmithParams> {",
          "37:     console.warn(",
          "38:       \"ChatWatsonx does not support stop sequences. Overwrite params.\"",
          "39:     );",
          "40:     return {",
          "41:       ls_provider: \"watsonx\",",
          "42:       ls_model_name: \"string\",",
          "43:       ls_model_type: \"chat\",",
          "44:       ls_temperature: 0,",
          "45:       ls_max_tokens: 0,",
          "46:     };",
          "47:   }",
          "48: }",
          "50: const testClass = new ChatWatsonxStandardTests();",
          "52: test(\"ChatWatsonxStandardTests\", () => {",
          "53:   const testResults = testClass.runTests();",
          "54:   expect(testResults).toBe(true);",
          "55: });",
          "",
          "---------------"
        ],
        "libs/langchain-community/src/chat_models/tests/ibm.test.ts||libs/langchain-community/src/chat_models/tests/ibm.test.ts": [
          "File: libs/langchain-community/src/chat_models/tests/ibm.test.ts -> libs/langchain-community/src/chat_models/tests/ibm.test.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "2: import WatsonxAiMlVml_v1 from \"@ibm-cloud/watsonx-ai/dist/watsonx-ai-ml/vml_v1.js\";",
          "3: import { ChatWatsonx, ChatWatsonxInput, WatsonxCallParams } from \"../ibm.js\";",
          "4: import { authenticateAndSetInstance } from \"../../utils/ibm.js\";",
          "6: const fakeAuthProp = {",
          "7:   watsonxAIAuthType: \"iam\",",
          "8:   watsonxAIApikey: \"fake_key\",",
          "9: };",
          "10: export function getKey<K>(key: K): K {",
          "11:   return key;",
          "12: }",
          "13: export const testProperties = (",
          "14:   instance: ChatWatsonx,",
          "15:   testProps: ChatWatsonxInput,",
          "16:   notExTestProps?: { [key: string]: any }",
          "17: ) => {",
          "18:   const checkProperty = <T extends { [key: string]: any }>(",
          "19:     testProps: T,",
          "20:     instance: T,",
          "21:     existing = true",
          "22:   ) => {",
          "23:     Object.keys(testProps).forEach((key) => {",
          "24:       const keys = getKey<keyof T>(key);",
          "25:       type Type = Pick<T, typeof keys>;",
          "27:       if (typeof testProps[key as keyof T] === \"object\")",
          "28:         checkProperty<Type>(testProps[key as keyof T], instance[key], existing);",
          "29:       else {",
          "30:         if (existing)",
          "31:           expect(instance[key as keyof T]).toBe(testProps[key as keyof T]);",
          "32:         else if (instance) expect(instance[key as keyof T]).toBeUndefined();",
          "33:       }",
          "34:     });",
          "35:   };",
          "36:   checkProperty<typeof testProps>(testProps, instance);",
          "37:   if (notExTestProps)",
          "38:     checkProperty<typeof notExTestProps>(notExTestProps, instance, false);",
          "39: };",
          "41: describe(\"LLM unit tests\", () => {",
          "42:   describe(\"Positive tests\", () => {",
          "43:     test(\"Test authentication function\", () => {",
          "44:       const instance = authenticateAndSetInstance({",
          "45:         version: \"2024-05-31\",",
          "46:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "47:         ...fakeAuthProp,",
          "48:       });",
          "49:       expect(instance).toBeInstanceOf(WatsonxAiMlVml_v1);",
          "50:     });",
          "52:     test(\"Test basic properties after init\", async () => {",
          "53:       const testProps = {",
          "54:         version: \"2024-05-31\",",
          "55:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "56:         projectId: process.env.WATSONX_AI_PROJECT_ID || \"testString\",",
          "57:       };",
          "58:       const instance = new ChatWatsonx({ ...testProps, ...fakeAuthProp });",
          "60:       testProperties(instance, testProps);",
          "61:     });",
          "63:     test(\"Test methods after init\", () => {",
          "64:       const testProps: ChatWatsonxInput = {",
          "65:         version: \"2024-05-31\",",
          "66:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "67:         projectId: process.env.WATSONX_AI_PROJECT_ID || \"testString\",",
          "68:       };",
          "69:       const instance = new ChatWatsonx({",
          "70:         ...testProps,",
          "71:         ...fakeAuthProp,",
          "72:       });",
          "73:       expect(instance.getNumTokens).toBeDefined();",
          "74:       expect(instance._generate).toBeDefined();",
          "75:       expect(instance._streamResponseChunks).toBeDefined();",
          "76:       expect(instance.invocationParams).toBeDefined();",
          "77:     });",
          "79:     test(\"Test properties after init\", async () => {",
          "80:       const testProps: WatsonxCallParams & ChatWatsonxInput = {",
          "81:         version: \"2024-05-31\",",
          "82:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "83:         projectId: process.env.WATSONX_AI_PROJECT_ID || \"testString\",",
          "84:         model: \"ibm/granite-13b-chat-v2\",",
          "85:         max_new_tokens: 100,",
          "86:         temperature: 0.1,",
          "87:         time_limit: 10000,",
          "88:         top_p: 1,",
          "89:         maxRetries: 3,",
          "90:         maxConcurrency: 3,",
          "91:       };",
          "92:       const instance = new ChatWatsonx({ ...testProps, ...fakeAuthProp });",
          "94:       testProperties(instance, testProps);",
          "95:     });",
          "96:   });",
          "98:   describe(\"Negative tests\", () => {",
          "99:     test(\"Missing id\", async () => {",
          "100:       const testProps: ChatWatsonxInput = {",
          "101:         version: \"2024-05-31\",",
          "102:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "103:       };",
          "104:       expect(",
          "105:         () =>",
          "106:           new ChatWatsonx({",
          "107:             ...testProps,",
          "108:             ...fakeAuthProp,",
          "109:           })",
          "110:       ).toThrowError();",
          "111:     });",
          "113:     test(\"Missing other props\", async () => {",
          "115:       const testPropsProjectId: ChatWatsonxInput = {",
          "116:         projectId: process.env.WATSONX_AI_PROJECT_ID || \"testString\",",
          "117:       };",
          "119:       expect(",
          "120:         () =>",
          "121:           new ChatWatsonx({",
          "122:             ...testPropsProjectId,",
          "123:             ...fakeAuthProp,",
          "124:           })",
          "125:       ).toThrowError();",
          "127:       const testPropsServiceUrl: ChatWatsonxInput = {",
          "128:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "129:       };",
          "130:       expect(",
          "131:         () =>",
          "132:           new ChatWatsonx({",
          "133:             ...testPropsServiceUrl,",
          "134:             ...fakeAuthProp,",
          "135:           })",
          "136:       ).toThrowError();",
          "137:       const testPropsVersion = {",
          "138:         version: \"2024-05-31\",",
          "139:       };",
          "140:       expect(",
          "141:         () =>",
          "142:           new ChatWatsonx({",
          "144:             testPropsVersion,",
          "145:           })",
          "146:       ).toThrowError();",
          "147:     });",
          "149:     test(\"Passing more than one id\", async () => {",
          "150:       const testProps: ChatWatsonxInput = {",
          "151:         version: \"2024-05-31\",",
          "152:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "153:         projectId: process.env.WATSONX_AI_PROJECT_ID || \"testString\",",
          "154:         spaceId: process.env.WATSONX_AI_PROJECT_ID || \"testString\",",
          "155:       };",
          "156:       expect(",
          "157:         () =>",
          "158:           new ChatWatsonx({",
          "159:             ...testProps,",
          "160:             ...fakeAuthProp,",
          "161:           })",
          "162:       ).toThrowError();",
          "163:     });",
          "165:     test(\"Not existing property passed\", async () => {",
          "166:       const testProps = {",
          "167:         version: \"2024-05-31\",",
          "168:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "169:         projectId: process.env.WATSONX_AI_PROJECT_ID || \"testString\",",
          "170:       };",
          "171:       const notExTestProps = {",
          "172:         notExisting: 12,",
          "173:         notExObj: {",
          "174:           notExProp: 12,",
          "175:         },",
          "176:       };",
          "177:       const instance = new ChatWatsonx({",
          "178:         ...testProps,",
          "179:         ...notExTestProps,",
          "180:         ...fakeAuthProp,",
          "181:       });",
          "182:       testProperties(instance, testProps, notExTestProps);",
          "183:     });",
          "184:   });",
          "185: });",
          "",
          "---------------"
        ],
        "libs/langchain-community/src/embeddings/ibm.ts||libs/langchain-community/src/embeddings/ibm.ts": [
          "File: libs/langchain-community/src/embeddings/ibm.ts -> libs/langchain-community/src/embeddings/ibm.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: import { Embeddings } from \"@langchain/core/embeddings\";",
          "2: import {",
          "3:   EmbeddingParameters,",
          "4:   TextEmbeddingsParams,",
          "5: } from \"@ibm-cloud/watsonx-ai/dist/watsonx-ai-ml/vml_v1.js\";",
          "6: import { WatsonXAI } from \"@ibm-cloud/watsonx-ai\";",
          "7: import { AsyncCaller } from \"@langchain/core/utils/async_caller\";",
          "8: import { WatsonxAuth, WatsonxParams } from \"../types/ibm.js\";",
          "9: import { authenticateAndSetInstance } from \"../utils/ibm.js\";",
          "11: export interface WatsonxEmbeddingsParams",
          "12:   extends Omit<EmbeddingParameters, \"return_options\">,",
          "13:     Pick<TextEmbeddingsParams, \"headers\"> {}",
          "15: export class WatsonxEmbeddings",
          "16:   extends Embeddings",
          "17:   implements WatsonxEmbeddingsParams, WatsonxParams",
          "18: {",
          "19:   model = \"ibm/slate-125m-english-rtrvr\";",
          "21:   serviceUrl: string;",
          "23:   version: string;",
          "25:   spaceId?: string;",
          "27:   projectId?: string;",
          "29:   truncate_input_tokens?: number;",
          "31:   maxRetries?: number;",
          "33:   maxConcurrency?: number;",
          "35:   private service: WatsonXAI;",
          "37:   constructor(fields: WatsonxEmbeddingsParams & WatsonxAuth & WatsonxParams) {",
          "38:     const superProps = { maxConcurrency: 2, ...fields };",
          "39:     super(superProps);",
          "40:     this.model = fields?.model ? fields.model : this.model;",
          "41:     this.version = fields.version;",
          "42:     this.serviceUrl = fields.serviceUrl;",
          "43:     this.truncate_input_tokens = fields.truncate_input_tokens;",
          "44:     this.maxConcurrency = fields.maxConcurrency;",
          "45:     this.maxRetries = fields.maxRetries;",
          "46:     if (fields.projectId && fields.spaceId)",
          "47:       throw new Error(\"Maximum 1 id type can be specified per instance\");",
          "48:     else if (!fields.projectId && !fields.spaceId && !fields.idOrName)",
          "49:       throw new Error(",
          "50:         \"No id specified! At least id of 1 type has to be specified\"",
          "51:       );",
          "52:     this.projectId = fields?.projectId;",
          "53:     this.spaceId = fields?.spaceId;",
          "54:     this.serviceUrl = fields?.serviceUrl;",
          "55:     const {",
          "56:       watsonxAIApikey,",
          "57:       watsonxAIAuthType,",
          "58:       watsonxAIBearerToken,",
          "59:       watsonxAIUsername,",
          "60:       watsonxAIPassword,",
          "61:       watsonxAIUrl,",
          "62:       version,",
          "63:       serviceUrl,",
          "64:     } = fields;",
          "65:     const auth = authenticateAndSetInstance({",
          "66:       watsonxAIApikey,",
          "67:       watsonxAIAuthType,",
          "68:       watsonxAIBearerToken,",
          "69:       watsonxAIUsername,",
          "70:       watsonxAIPassword,",
          "71:       watsonxAIUrl,",
          "72:       version,",
          "73:       serviceUrl,",
          "74:     });",
          "75:     if (auth) this.service = auth;",
          "76:     else throw new Error(\"You have not provided one type of authentication\");",
          "77:   }",
          "79:   scopeId() {",
          "80:     if (this.projectId) return { projectId: this.projectId };",
          "81:     else return { spaceId: this.spaceId };",
          "82:   }",
          "84:   invocationParams(): EmbeddingParameters {",
          "85:     return {",
          "86:       truncate_input_tokens: this.truncate_input_tokens,",
          "87:     };",
          "88:   }",
          "90:   async listModels() {",
          "91:     const listModelParams = {",
          "92:       filters: \"function_embedding\",",
          "93:     };",
          "94:     const caller = new AsyncCaller({",
          "95:       maxConcurrency: this.maxConcurrency,",
          "96:       maxRetries: this.maxRetries,",
          "97:     });",
          "98:     const listModels = await caller.call(() =>",
          "99:       this.service.listFoundationModelSpecs(listModelParams)",
          "100:     );",
          "101:     return listModels.result.resources?.map((item) => item.model_id);",
          "102:   }",
          "104:   private async embedSingleText(inputs: string[]) {",
          "105:     const textEmbeddingParams: TextEmbeddingsParams = {",
          "106:       inputs,",
          "107:       modelId: this.model,",
          "108:       ...this.scopeId(),",
          "109:       parameters: this.invocationParams(),",
          "110:     };",
          "111:     const caller = new AsyncCaller({",
          "112:       maxConcurrency: this.maxConcurrency,",
          "113:       maxRetries: this.maxRetries,",
          "114:     });",
          "115:     const embeddings = await caller.call(() =>",
          "116:       this.service.embedText(textEmbeddingParams)",
          "117:     );",
          "118:     return embeddings.result.results.map((item) => item.embedding);",
          "119:   }",
          "121:   async embedDocuments(documents: string[]): Promise<number[][]> {",
          "122:     const data = await this.embedSingleText(documents);",
          "123:     return data;",
          "124:   }",
          "126:   async embedQuery(document: string): Promise<number[]> {",
          "127:     const data = await this.embedSingleText([document]);",
          "128:     return data[0];",
          "129:   }",
          "130: }",
          "",
          "---------------"
        ],
        "libs/langchain-community/src/embeddings/tests/ibm.int.test.ts||libs/langchain-community/src/embeddings/tests/ibm.int.test.ts": [
          "File: libs/langchain-community/src/embeddings/tests/ibm.int.test.ts -> libs/langchain-community/src/embeddings/tests/ibm.int.test.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "2: import { test } from \"@jest/globals\";",
          "3: import { WatsonxEmbeddings } from \"../ibm.js\";",
          "5: describe(\"Test embeddings\", () => {",
          "6:   test(\"embedQuery method\", async () => {",
          "7:     const embeddings = new WatsonxEmbeddings({",
          "8:       version: \"2024-05-31\",",
          "9:       serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "10:       projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "11:     });",
          "12:     const res = await embeddings.embedQuery(\"Hello world\");",
          "13:     expect(typeof res[0]).toBe(\"number\");",
          "14:   });",
          "16:   test(\"embedDocuments\", async () => {",
          "17:     const embeddings = new WatsonxEmbeddings({",
          "18:       version: \"2024-05-31\",",
          "19:       serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "20:       projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "21:     });",
          "22:     const res = await embeddings.embedDocuments([\"Hello world\", \"Bye world\"]);",
          "23:     expect(res).toHaveLength(2);",
          "24:     expect(typeof res[0][0]).toBe(\"number\");",
          "25:     expect(typeof res[1][0]).toBe(\"number\");",
          "26:   });",
          "28:   test(\"Concurrency\", async () => {",
          "29:     const embeddings = new WatsonxEmbeddings({",
          "30:       version: \"2024-05-31\",",
          "31:       serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "32:       projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "33:       maxConcurrency: 4,",
          "34:     });",
          "35:     const res = await embeddings.embedDocuments([",
          "36:       \"Hello world\",",
          "37:       \"Bye world\",",
          "38:       \"Hello world\",",
          "39:       \"Bye world\",",
          "40:       \"Hello world\",",
          "41:       \"Bye world\",",
          "42:       \"Hello world\",",
          "43:       \"Bye world\",",
          "44:     ]);",
          "45:     expect(res).toHaveLength(8);",
          "46:     expect(res.find((embedding) => typeof embedding[0] !== \"number\")).toBe(",
          "47:       undefined",
          "48:     );",
          "49:   });",
          "51:   test(\"List models\", async () => {",
          "52:     const embeddings = new WatsonxEmbeddings({",
          "53:       version: \"2024-05-31\",",
          "54:       serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "55:       projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "56:       maxConcurrency: 4,",
          "57:     });",
          "58:     const res = await embeddings.listModels();",
          "59:     expect(res?.length).toBeGreaterThan(0);",
          "60:     if (res) expect(typeof res[0]).toBe(\"string\");",
          "61:   });",
          "62: });",
          "",
          "---------------"
        ],
        "libs/langchain-community/src/embeddings/tests/ibm.test.ts||libs/langchain-community/src/embeddings/tests/ibm.test.ts": [
          "File: libs/langchain-community/src/embeddings/tests/ibm.test.ts -> libs/langchain-community/src/embeddings/tests/ibm.test.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "2: import { testProperties } from \"../../llms/tests/ibm.test.js\";",
          "3: import { WatsonxEmbeddings } from \"../ibm.js\";",
          "5: const fakeAuthProp = {",
          "6:   watsonxAIAuthType: \"iam\",",
          "7:   watsonxAIApikey: \"fake_key\",",
          "8: };",
          "9: describe(\"Embeddings unit tests\", () => {",
          "10:   describe(\"Positive tests\", () => {",
          "11:     test(\"Basic properties\", () => {",
          "12:       const testProps = {",
          "13:         version: \"2024-05-31\",",
          "14:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "15:         projectId: process.env.WATSONX_AI_PROJECT_ID || \"testString\",",
          "16:       };",
          "17:       const instance = new WatsonxEmbeddings({ ...testProps, ...fakeAuthProp });",
          "18:       testProperties(instance, testProps);",
          "19:     });",
          "21:     test(\"Basic properties\", () => {",
          "22:       const testProps = {",
          "23:         version: \"2024-05-31\",",
          "24:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "25:         projectId: process.env.WATSONX_AI_PROJECT_ID || \"testString\",",
          "26:         truncate_input_tokens: 10,",
          "27:         maxConcurrency: 2,",
          "28:         maxRetries: 2,",
          "29:         model: \"ibm/slate-125m-english-rtrvr\",",
          "30:       };",
          "31:       const instance = new WatsonxEmbeddings({ ...testProps, ...fakeAuthProp });",
          "33:       testProperties(instance, testProps);",
          "34:     });",
          "35:   });",
          "37:   describe(\"Negative tests\", () => {",
          "38:     test(\"Missing id\", async () => {",
          "39:       const testProps = {",
          "40:         version: \"2024-05-31\",",
          "41:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "42:       };",
          "43:       expect(",
          "44:         () =>",
          "45:           new WatsonxEmbeddings({",
          "46:             ...testProps,",
          "47:             ...fakeAuthProp,",
          "48:           })",
          "49:       ).toThrowError();",
          "50:     });",
          "52:     test(\"Missing other props\", async () => {",
          "54:       const testPropsProjectId: WatsonxInputLLM = {",
          "55:         projectId: process.env.WATSONX_AI_PROJECT_ID || \"testString\",",
          "56:       };",
          "57:       expect(",
          "58:         () =>",
          "59:           new WatsonxEmbeddings({",
          "60:             ...testPropsProjectId,",
          "61:           })",
          "62:       ).toThrowError();",
          "64:       const testPropsServiceUrl: WatsonxInputLLM = {",
          "65:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "66:       };",
          "67:       expect(",
          "68:         () =>",
          "69:           new WatsonxEmbeddings({",
          "70:             ...testPropsServiceUrl,",
          "71:           })",
          "72:       ).toThrowError();",
          "73:       const testPropsVersion = {",
          "74:         version: \"2024-05-31\",",
          "75:       };",
          "76:       expect(",
          "77:         () =>",
          "78:           new WatsonxEmbeddings({",
          "80:             testPropsVersion,",
          "81:           })",
          "82:       ).toThrowError();",
          "83:     });",
          "85:     test(\"Passing more than one id\", async () => {",
          "86:       const testProps = {",
          "87:         version: \"2024-05-31\",",
          "88:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "89:         projectId: process.env.WATSONX_AI_PROJECT_ID || \"testString\",",
          "90:         spaceId: process.env.WATSONX_AI_PROJECT_ID || \"testString\",",
          "91:       };",
          "92:       expect(",
          "93:         () =>",
          "94:           new WatsonxEmbeddings({",
          "95:             ...testProps,",
          "96:             ...fakeAuthProp,",
          "97:           })",
          "98:       ).toThrowError();",
          "99:     });",
          "101:     test(\"Invalid properties\", () => {",
          "102:       const testProps = {",
          "103:         version: \"2024-05-31\",",
          "104:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "105:         projectId: process.env.WATSONX_AI_PROJECT_ID || \"testString\",",
          "106:       };",
          "107:       const notExTestProps = {",
          "108:         notExisting: 12,",
          "109:         notExObj: {",
          "110:           notExProp: 12,",
          "111:         },",
          "112:       };",
          "113:       const instance = new WatsonxEmbeddings({",
          "114:         ...testProps,",
          "115:         ...notExTestProps,",
          "116:         ...fakeAuthProp,",
          "117:       });",
          "119:       testProperties(instance, testProps, notExTestProps);",
          "120:     });",
          "121:   });",
          "122: });",
          "",
          "---------------"
        ],
        "libs/langchain-community/src/llms/ibm.ts||libs/langchain-community/src/llms/ibm.ts": [
          "File: libs/langchain-community/src/llms/ibm.ts -> libs/langchain-community/src/llms/ibm.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "2: import { CallbackManagerForLLMRun } from \"@langchain/core/callbacks/manager\";",
          "3: import { BaseLLM, BaseLLMParams } from \"@langchain/core/language_models/llms\";",
          "4: import { WatsonXAI } from \"@ibm-cloud/watsonx-ai\";",
          "5: import {",
          "6:   DeploymentsTextGenerationParams,",
          "7:   DeploymentsTextGenerationStreamParams,",
          "8:   DeploymentTextGenProperties,",
          "9:   ReturnOptionProperties,",
          "10:   TextGenerationParams,",
          "11:   TextGenerationStreamParams,",
          "12:   TextGenLengthPenalty,",
          "13:   TextGenParameters,",
          "14:   TextTokenizationParams,",
          "15:   TextTokenizeParameters,",
          "16: } from \"@ibm-cloud/watsonx-ai/dist/watsonx-ai-ml/vml_v1.js\";",
          "17: import {",
          "18:   Generation,",
          "19:   LLMResult,",
          "20:   GenerationChunk,",
          "21: } from \"@langchain/core/outputs\";",
          "22: import { BaseLanguageModelCallOptions } from \"@langchain/core/language_models/base\";",
          "23: import { AsyncCaller } from \"@langchain/core/utils/async_caller\";",
          "24: import { authenticateAndSetInstance } from \"../utils/ibm.js\";",
          "25: import {",
          "26:   GenerationInfo,",
          "27:   ResponseChunk,",
          "28:   TokenUsage,",
          "29:   WatsonxAuth,",
          "30:   WatsonxParams,",
          "31: } from \"../types/ibm.js\";",
          "37: export interface WatsonxCallOptionsLLM",
          "38:   extends BaseLanguageModelCallOptions,",
          "39:     Omit<",
          "40:       Partial<",
          "41:         TextGenerationParams &",
          "42:           TextGenerationStreamParams &",
          "43:           DeploymentsTextGenerationParams &",
          "44:           DeploymentsTextGenerationStreamParams",
          "45:       >,",
          "46:       \"input\"",
          "47:     > {",
          "48:   maxRetries?: number;",
          "49: }",
          "51: export interface WatsonxInputLLM",
          "52:   extends TextGenParameters,",
          "53:     WatsonxParams,",
          "54:     BaseLLMParams {",
          "55:   streaming?: boolean;",
          "56: }",
          "61: export class WatsonxLLM<",
          "62:     CallOptions extends WatsonxCallOptionsLLM = WatsonxCallOptionsLLM",
          "63:   >",
          "64:   extends BaseLLM<CallOptions>",
          "65:   implements WatsonxInputLLM",
          "66: {",
          "68:   static lc_name() {",
          "69:     return \"Watsonx\";",
          "70:   }",
          "72:   lc_serializable = true;",
          "74:   streaming = false;",
          "76:   model = \"ibm/granite-13b-chat-v2\";",
          "78:   maxRetries = 0;",
          "80:   version = \"2024-05-31\";",
          "82:   serviceUrl: string;",
          "84:   max_new_tokens?: number;",
          "86:   spaceId?: string;",
          "88:   projectId?: string;",
          "90:   idOrName?: string;",
          "92:   decoding_method?: TextGenParameters.Constants.DecodingMethod | string;",
          "94:   length_penalty?: TextGenLengthPenalty;",
          "96:   min_new_tokens?: number;",
          "98:   random_seed?: number;",
          "100:   stop_sequences?: string[];",
          "102:   temperature?: number;",
          "104:   time_limit?: number;",
          "106:   top_k?: number;",
          "108:   top_p?: number;",
          "110:   repetition_penalty?: number;",
          "112:   truncate_input_tokens?: number;",
          "114:   return_options?: ReturnOptionProperties;",
          "116:   include_stop_sequence?: boolean;",
          "118:   maxConcurrency?: number;",
          "120:   private service: WatsonXAI;",
          "122:   constructor(fields: WatsonxInputLLM & WatsonxAuth) {",
          "123:     super(fields);",
          "124:     this.model = fields.model ?? this.model;",
          "125:     this.version = fields.version;",
          "126:     this.max_new_tokens = fields.max_new_tokens ?? this.max_new_tokens;",
          "127:     this.serviceUrl = fields.serviceUrl;",
          "128:     this.decoding_method = fields.decoding_method;",
          "129:     this.length_penalty = fields.length_penalty;",
          "130:     this.min_new_tokens = fields.min_new_tokens;",
          "131:     this.random_seed = fields.random_seed;",
          "132:     this.stop_sequences = fields.stop_sequences;",
          "133:     this.temperature = fields.temperature;",
          "134:     this.time_limit = fields.time_limit;",
          "135:     this.top_k = fields.top_k;",
          "136:     this.top_p = fields.top_p;",
          "137:     this.repetition_penalty = fields.repetition_penalty;",
          "138:     this.truncate_input_tokens = fields.truncate_input_tokens;",
          "139:     this.return_options = fields.return_options;",
          "140:     this.include_stop_sequence = fields.include_stop_sequence;",
          "141:     this.maxRetries = fields.maxRetries || this.maxRetries;",
          "142:     this.maxConcurrency = fields.maxConcurrency;",
          "143:     this.streaming = fields.streaming || this.streaming;",
          "144:     if (",
          "145:       (fields.projectId && fields.spaceId) ||",
          "146:       (fields.idOrName && fields.projectId) ||",
          "147:       (fields.spaceId && fields.idOrName)",
          "148:     )",
          "149:       throw new Error(\"Maximum 1 id type can be specified per instance\");",
          "151:     if (!fields.projectId && !fields.spaceId && !fields.idOrName)",
          "152:       throw new Error(",
          "153:         \"No id specified! At least ide of 1 type has to be specified\"",
          "154:       );",
          "155:     this.projectId = fields?.projectId;",
          "156:     this.spaceId = fields?.spaceId;",
          "157:     this.idOrName = fields?.idOrName;",
          "159:     this.serviceUrl = fields?.serviceUrl;",
          "160:     const {",
          "161:       watsonxAIApikey,",
          "162:       watsonxAIAuthType,",
          "163:       watsonxAIBearerToken,",
          "164:       watsonxAIUsername,",
          "165:       watsonxAIPassword,",
          "166:       watsonxAIUrl,",
          "167:       version,",
          "168:       serviceUrl,",
          "169:     } = fields;",
          "171:     const auth = authenticateAndSetInstance({",
          "172:       watsonxAIApikey,",
          "173:       watsonxAIAuthType,",
          "174:       watsonxAIBearerToken,",
          "175:       watsonxAIUsername,",
          "176:       watsonxAIPassword,",
          "177:       watsonxAIUrl,",
          "178:       version,",
          "179:       serviceUrl,",
          "180:     });",
          "181:     if (auth) this.service = auth;",
          "182:     else throw new Error(\"You have not provided one type of authentication\");",
          "183:   }",
          "185:   get lc_secrets(): { [key: string]: string } {",
          "186:     return {",
          "187:       authenticator: \"AUTHENTICATOR\",",
          "188:       apiKey: \"WATSONX_AI_APIKEY\",",
          "189:       apikey: \"WATSONX_AI_APIKEY\",",
          "190:       watsonxAIAuthType: \"WATSONX_AI_AUTH_TYPE\",",
          "191:       watsonxAIApikey: \"WATSONX_AI_APIKEY\",",
          "192:       watsonxAIBearerToken: \"WATSONX_AI_BEARER_TOKEN\",",
          "193:       watsonxAIUsername: \"WATSONX_AI_USERNAME\",",
          "194:       watsonxAIPassword: \"WATSONX_AI_PASSWORD\",",
          "195:       watsonxAIUrl: \"WATSONX_AI_URL\",",
          "196:     };",
          "197:   }",
          "199:   get lc_aliases(): { [key: string]: string } {",
          "200:     return {",
          "201:       authenticator: \"authenticator\",",
          "202:       apikey: \"watsonx_ai_apikey\",",
          "203:       apiKey: \"watsonx_ai_apikey\",",
          "204:       watsonxAIAuthType: \"watsonx_ai_auth_type\",",
          "205:       watsonxAIApikey: \"watsonx_ai_apikey\",",
          "206:       watsonxAIBearerToken: \"watsonx_ai_bearer_token\",",
          "207:       watsonxAIUsername: \"watsonx_ai_username\",",
          "208:       watsonxAIPassword: \"watsonx_ai_password\",",
          "209:       watsonxAIUrl: \"watsonx_ai_url\",",
          "210:     };",
          "211:   }",
          "213:   invocationParams(",
          "214:     options: this[\"ParsedCallOptions\"]",
          "215:   ): TextGenParameters | DeploymentTextGenProperties {",
          "216:     const { parameters } = options;",
          "218:     return {",
          "219:       max_new_tokens: parameters?.max_new_tokens ?? this.max_new_tokens,",
          "220:       decoding_method: parameters?.decoding_method ?? this.decoding_method,",
          "221:       length_penalty: parameters?.length_penalty ?? this.length_penalty,",
          "222:       min_new_tokens: parameters?.min_new_tokens ?? this.min_new_tokens,",
          "223:       random_seed: parameters?.random_seed ?? this.random_seed,",
          "224:       stop_sequences: options?.stop ?? this.stop_sequences,",
          "225:       temperature: parameters?.temperature ?? this.temperature,",
          "226:       time_limit: parameters?.time_limit ?? this.time_limit,",
          "227:       top_k: parameters?.top_k ?? this.top_k,",
          "228:       top_p: parameters?.top_p ?? this.top_p,",
          "229:       repetition_penalty:",
          "230:         parameters?.repetition_penalty ?? this.repetition_penalty,",
          "231:       truncate_input_tokens:",
          "232:         parameters?.truncate_input_tokens ?? this.truncate_input_tokens,",
          "233:       return_options: parameters?.return_options ?? this.return_options,",
          "234:       include_stop_sequence:",
          "235:         parameters?.include_stop_sequence ?? this.include_stop_sequence,",
          "236:     };",
          "237:   }",
          "239:   scopeId() {",
          "240:     if (this.projectId)",
          "241:       return { projectId: this.projectId, modelId: this.model };",
          "242:     else if (this.spaceId)",
          "243:       return { spaceId: this.spaceId, modelId: this.model };",
          "244:     else if (this.idOrName)",
          "245:       return { idOrName: this.idOrName, modelId: this.model };",
          "246:     else return { spaceId: this.spaceId, modelId: this.model };",
          "247:   }",
          "249:   async listModels() {",
          "250:     const listModelParams = {",
          "251:       filters: \"function_text_generation\",",
          "252:     };",
          "253:     const listModels = await this.completionWithRetry(() =>",
          "254:       this.service.listFoundationModelSpecs(listModelParams)",
          "255:     );",
          "256:     return listModels.result.resources?.map((item) => item.model_id);",
          "257:   }",
          "259:   private async generateSingleMessage(",
          "260:     input: string,",
          "261:     options: this[\"ParsedCallOptions\"],",
          "262:     stream: true",
          "263:   ): Promise<AsyncIterable<string>>;",
          "265:   private async generateSingleMessage(",
          "266:     input: string,",
          "267:     options: this[\"ParsedCallOptions\"],",
          "268:     stream: false",
          "269:   ): Promise<Generation[]>;",
          "271:   private async generateSingleMessage(",
          "272:     input: string,",
          "273:     options: this[\"ParsedCallOptions\"],",
          "274:     stream: boolean",
          "275:   ) {",
          "276:     const {",
          "277:       signal,",
          "278:       stop,",
          "279:       maxRetries,",
          "280:       maxConcurrency,",
          "281:       timeout,",
          "282:       ...requestOptions",
          "283:     } = options;",
          "284:     const tokenUsage = { generated_token_count: 0, input_token_count: 0 };",
          "285:     const idOrName = options?.idOrName ?? this.idOrName;",
          "286:     const parameters = this.invocationParams(options);",
          "287:     if (stream) {",
          "288:       const textStream = idOrName",
          "289:         ? await this.service.deploymentGenerateTextStream({",
          "290:             idOrName,",
          "291:             ...requestOptions,",
          "292:             parameters: {",
          "293:               ...parameters,",
          "294:               prompt_variables: {",
          "295:                 input,",
          "296:               },",
          "297:             },",
          "298:           })",
          "299:         : await this.service.generateTextStream({",
          "300:             input,",
          "301:             parameters,",
          "302:             ...this.scopeId(),",
          "303:             ...requestOptions,",
          "304:           });",
          "305:       return textStream as unknown as AsyncIterable<string>;",
          "306:     } else {",
          "307:       const textGenerationPromise = idOrName",
          "308:         ? this.service.deploymentGenerateText({",
          "309:             ...requestOptions,",
          "310:             idOrName,",
          "311:             parameters: {",
          "312:               ...parameters,",
          "313:               prompt_variables: {",
          "314:                 input,",
          "315:               },",
          "316:             },",
          "317:           })",
          "318:         : this.service.generateText({",
          "319:             input,",
          "320:             parameters,",
          "321:             ...this.scopeId(),",
          "322:             ...requestOptions,",
          "323:           });",
          "325:       const textGeneration = await textGenerationPromise;",
          "326:       const singleGeneration: Generation[] = textGeneration.result.results.map(",
          "327:         (result) => {",
          "328:           tokenUsage.generated_token_count += result.generated_token_count",
          "329:             ? result.generated_token_count",
          "330:             : 0;",
          "331:           tokenUsage.input_token_count += result.input_token_count",
          "332:             ? result.input_token_count",
          "333:             : 0;",
          "334:           return {",
          "335:             text: result.generated_text,",
          "336:             generationInfo: {",
          "337:               stop_reason: result.stop_reason,",
          "338:               input_token_count: result.input_token_count,",
          "339:               generated_token_count: result.generated_token_count,",
          "340:             },",
          "341:           };",
          "342:         }",
          "343:       );",
          "344:       return singleGeneration;",
          "345:     }",
          "346:   }",
          "348:   async completionWithRetry<T>(",
          "349:     callback: () => T,",
          "350:     options?: this[\"ParsedCallOptions\"]",
          "351:   ) {",
          "352:     const caller = new AsyncCaller({",
          "353:       maxConcurrency: options?.maxConcurrency || this.maxConcurrency,",
          "354:       maxRetries: this.maxRetries,",
          "355:     });",
          "356:     const result = options",
          "357:       ? caller.callWithOptions(",
          "358:           {",
          "359:             signal: options.signal,",
          "360:           },",
          "361:           async () => callback()",
          "362:         )",
          "363:       : caller.call(async () => callback());",
          "365:     return result;",
          "366:   }",
          "368:   async _generate(",
          "369:     prompts: string[],",
          "370:     options: this[\"ParsedCallOptions\"],",
          "371:     _runManager?: CallbackManagerForLLMRun",
          "372:   ): Promise<LLMResult> {",
          "373:     const tokenUsage: TokenUsage = {",
          "374:       generated_token_count: 0,",
          "375:       input_token_count: 0,",
          "376:     };",
          "377:     if (this.streaming) {",
          "378:       const generations: Generation[][] = await Promise.all(",
          "379:         prompts.map(async (prompt, promptIdx) => {",
          "380:           if (options.signal?.aborted) {",
          "381:             throw new Error(\"AbortError\");",
          "382:           }",
          "383:           const callback = () =>",
          "384:             this.generateSingleMessage(prompt, options, true);",
          "386:           type ReturnMessage = ReturnType<typeof callback>;",
          "387:           const stream = await this.completionWithRetry<ReturnMessage>(",
          "388:             callback,",
          "389:             options",
          "390:           );",
          "392:           const responseChunk: ResponseChunk = {",
          "393:             id: 0,",
          "394:             event: \"\",",
          "395:             data: {",
          "396:               results: [],",
          "397:             },",
          "398:           };",
          "399:           const messages: ResponseChunk[] = [];",
          "400:           type ResponseChunkKeys = keyof ResponseChunk;",
          "401:           for await (const chunk of stream) {",
          "402:             if (chunk.length > 0) {",
          "403:               const index = chunk.indexOf(\": \");",
          "404:               const [key, value] = [",
          "405:                 chunk.substring(0, index) as ResponseChunkKeys,",
          "406:                 chunk.substring(index + 2),",
          "407:               ];",
          "408:               if (key === \"id\") {",
          "409:                 responseChunk[key] = Number(value);",
          "410:               } else if (key === \"event\") {",
          "411:                 responseChunk[key] = String(value);",
          "412:               } else {",
          "413:                 responseChunk[key] = JSON.parse(value);",
          "414:               }",
          "415:             } else if (chunk.length === 0) {",
          "416:               messages.push(JSON.parse(JSON.stringify(responseChunk)));",
          "417:               Object.assign(responseChunk, { id: 0, event: \"\", data: {} });",
          "418:             }",
          "419:           }",
          "421:           const geneartionsArray: GenerationInfo[] = [];",
          "422:           for (const message of messages) {",
          "423:             message.data.results.forEach((item, index) => {",
          "424:               const generationInfo: GenerationInfo = {",
          "425:                 text: \"\",",
          "426:                 stop_reason: \"\",",
          "427:                 generated_token_count: 0,",
          "428:                 input_token_count: 0,",
          "429:               };",
          "430:               void _runManager?.handleLLMNewToken(item.generated_text ?? \"\", {",
          "431:                 prompt: promptIdx,",
          "432:                 completion: 1,",
          "433:               });",
          "434:               geneartionsArray[index] ??= generationInfo;",
          "435:               geneartionsArray[index].generated_token_count =",
          "436:                 item.generated_token_count;",
          "437:               geneartionsArray[index].input_token_count +=",
          "438:                 item.input_token_count;",
          "439:               geneartionsArray[index].stop_reason = item.stop_reason;",
          "440:               geneartionsArray[index].text += item.generated_text;",
          "441:             });",
          "442:           }",
          "443:           return geneartionsArray.map((item) => {",
          "444:             const { text, ...rest } = item;",
          "445:             tokenUsage.generated_token_count += rest.generated_token_count;",
          "446:             tokenUsage.input_token_count += rest.input_token_count;",
          "447:             return {",
          "448:               text,",
          "449:               generationInfo: rest,",
          "450:             };",
          "451:           });",
          "452:         })",
          "453:       );",
          "454:       const result: LLMResult = { generations, llmOutput: { tokenUsage } };",
          "455:       return result;",
          "456:     } else {",
          "457:       const generations: Generation[][] = await Promise.all(",
          "458:         prompts.map(async (prompt) => {",
          "459:           if (options.signal?.aborted) {",
          "460:             throw new Error(\"AbortError\");",
          "461:           }",
          "463:           const callback = () =>",
          "464:             this.generateSingleMessage(prompt, options, false);",
          "465:           type ReturnMessage = ReturnType<typeof callback>;",
          "467:           const response = await this.completionWithRetry<ReturnMessage>(",
          "468:             callback,",
          "469:             options",
          "470:           );",
          "471:           const [generated_token_count, input_token_count] = response.reduce(",
          "472:             (acc, curr) => {",
          "473:               let generated = 0;",
          "474:               let inputed = 0;",
          "475:               if (curr?.generationInfo?.generated_token_count)",
          "476:                 generated = curr.generationInfo.generated_token_count + acc[0];",
          "477:               if (curr?.generationInfo?.input_token_count)",
          "478:                 inputed = curr.generationInfo.input_token_count + acc[1];",
          "479:               return [generated, inputed];",
          "480:             },",
          "481:             [0, 0]",
          "482:           );",
          "483:           tokenUsage.generated_token_count += generated_token_count;",
          "484:           tokenUsage.input_token_count += input_token_count;",
          "485:           return response;",
          "486:         })",
          "487:       );",
          "489:       const result: LLMResult = { generations, llmOutput: { tokenUsage } };",
          "490:       return result;",
          "491:     }",
          "492:   }",
          "494:   async getNumTokens(",
          "495:     content: string,",
          "496:     options?: TextTokenizeParameters",
          "497:   ): Promise<number> {",
          "498:     const params: TextTokenizationParams = {",
          "499:       ...this.scopeId(),",
          "500:       input: content,",
          "501:       parameters: options,",
          "502:     };",
          "503:     const callback = () => this.service.tokenizeText(params);",
          "504:     type ReturnTokens = ReturnType<typeof callback>;",
          "506:     const response = await this.completionWithRetry<ReturnTokens>(callback);",
          "507:     return response.result.result.token_count;",
          "508:   }",
          "510:   async *_streamResponseChunks(",
          "511:     prompt: string,",
          "512:     options: this[\"ParsedCallOptions\"],",
          "513:     runManager?: CallbackManagerForLLMRun",
          "514:   ): AsyncGenerator<GenerationChunk> {",
          "515:     const callback = () => this.generateSingleMessage(prompt, options, true);",
          "516:     type ReturnStream = ReturnType<typeof callback>;",
          "517:     const streamInferDeployedPrompt =",
          "518:       await this.completionWithRetry<ReturnStream>(callback);",
          "519:     const responseChunk: ResponseChunk = {",
          "520:       id: 0,",
          "521:       event: \"\",",
          "522:       data: {",
          "523:         results: [],",
          "524:       },",
          "525:     };",
          "526:     for await (const chunk of streamInferDeployedPrompt) {",
          "527:       if (options.signal?.aborted) {",
          "528:         throw new Error(\"AbortError\");",
          "529:       }",
          "531:       type Keys = keyof typeof responseChunk;",
          "532:       if (chunk.length > 0) {",
          "533:         const index = chunk.indexOf(\": \");",
          "534:         const [key, value] = [",
          "535:           chunk.substring(0, index) as Keys,",
          "536:           chunk.substring(index + 2),",
          "537:         ];",
          "538:         if (key === \"id\") {",
          "539:           responseChunk[key] = Number(value);",
          "540:         } else if (key === \"event\") {",
          "541:           responseChunk[key] = String(value);",
          "542:         } else {",
          "543:           responseChunk[key] = JSON.parse(value);",
          "544:         }",
          "545:       } else if (",
          "546:         chunk.length === 0 &&",
          "547:         responseChunk.data?.results?.length > 0",
          "548:       ) {",
          "549:         for (const item of responseChunk.data.results) {",
          "550:           yield new GenerationChunk({",
          "551:             text: item.generated_text,",
          "552:             generationInfo: {",
          "553:               stop_reason: item.stop_reason,",
          "554:             },",
          "555:           });",
          "556:           await runManager?.handleLLMNewToken(item.generated_text ?? \"\");",
          "557:         }",
          "558:         Object.assign(responseChunk, { id: 0, event: \"\", data: {} });",
          "559:       }",
          "560:     }",
          "561:   }",
          "563:   _llmType() {",
          "564:     return \"watsonx\";",
          "565:   }",
          "566: }",
          "",
          "---------------"
        ],
        "libs/langchain-community/src/llms/tests/ibm.int.test.ts||libs/langchain-community/src/llms/tests/ibm.int.test.ts": [
          "File: libs/langchain-community/src/llms/tests/ibm.int.test.ts -> libs/langchain-community/src/llms/tests/ibm.int.test.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "2: import { CallbackManager } from \"@langchain/core/callbacks/manager\";",
          "3: import { LLMResult } from \"@langchain/core/outputs\";",
          "4: import { StringPromptValue } from \"@langchain/core/prompt_values\";",
          "5: import { TokenUsage } from \"../../types/ibm.js\";",
          "6: import { WatsonxLLM, WatsonxInputLLM } from \"../ibm.js\";",
          "8: const originalBackground = process.env.LANGCHAIN_CALLBACKS_BACKGROUND;",
          "10: describe(\"Text generation\", () => {",
          "11:   describe(\"Test invoke method\", () => {",
          "12:     test(\"Correct value\", async () => {",
          "13:       const watsonXInstance = new WatsonxLLM({",
          "14:         version: \"2024-05-31\",",
          "15:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "16:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "17:       });",
          "18:       await watsonXInstance.invoke(\"Hello world?\");",
          "19:     });",
          "21:     test(\"Invalid projectId\", async () => {",
          "22:       const watsonXInstance = new WatsonxLLM({",
          "23:         version: \"2024-05-31\",",
          "24:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "25:         projectId: \"Test wrong value\",",
          "26:       });",
          "27:       await expect(watsonXInstance.invoke(\"Hello world?\")).rejects.toThrow();",
          "28:     });",
          "30:     test(\"Invalid credentials\", async () => {",
          "31:       const watsonXInstance = new WatsonxLLM({",
          "32:         version: \"2024-05-31\",",
          "33:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "34:         projectId: \"Test wrong value\",",
          "35:         watsonxAIAuthType: \"iam\",",
          "36:         watsonxAIApikey: \"WrongApiKey\",",
          "37:         watsonxAIUrl: \"https://wrong.wrong/\",",
          "38:       });",
          "39:       await expect(watsonXInstance.invoke(\"Hello world?\")).rejects.toThrow();",
          "40:     });",
          "42:     test(\"Wrong value\", async () => {",
          "43:       const watsonXInstance = new WatsonxLLM({",
          "44:         version: \"2024-05-31\",",
          "45:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "46:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "47:       });",
          "49:       await watsonXInstance.invoke({});",
          "50:     });",
          "52:     test(\"Stop\", async () => {",
          "53:       const watsonXInstance = new WatsonxLLM({",
          "54:         version: \"2024-05-31\",",
          "55:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "56:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "57:       });",
          "58:       await watsonXInstance.invoke(\"Hello, how are you?\", {",
          "59:         stop: [\"Hello\"],",
          "60:       });",
          "61:     }, 5000);",
          "63:     test(\"Stop with timeout\", async () => {",
          "64:       const watsonXInstance = new WatsonxLLM({",
          "65:         version: \"2024-05-31\",",
          "66:         serviceUrl: \"sdadasdas\" as string,",
          "67:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "68:         max_new_tokens: 5,",
          "69:         maxRetries: 3,",
          "70:       });",
          "72:       await expect(() =>",
          "73:         watsonXInstance.invoke(\"Print hello world\", { timeout: 10 })",
          "74:       ).rejects.toThrowError(\"AbortError\");",
          "75:     }, 5000);",
          "77:     test(\"Signal in call options\", async () => {",
          "78:       const watsonXInstance = new WatsonxLLM({",
          "79:         version: \"2024-05-31\",",
          "80:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "81:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "82:         max_new_tokens: 5,",
          "83:         maxRetries: 3,",
          "84:       });",
          "85:       const controllerNoAbortion = new AbortController();",
          "86:       await expect(",
          "87:         watsonXInstance.invoke(\"Print hello world\", {",
          "88:           signal: controllerNoAbortion.signal,",
          "89:         })",
          "90:       ).resolves.toBeDefined();",
          "91:       const controllerToAbort = new AbortController();",
          "92:       await expect(async () => {",
          "93:         const ret = watsonXInstance.invoke(\"Print hello world\", {",
          "94:           signal: controllerToAbort.signal,",
          "95:         });",
          "96:         controllerToAbort.abort();",
          "97:         return ret;",
          "98:       }).rejects.toThrowError(\"AbortError\");",
          "99:     }, 5000);",
          "101:     test(\"Concurenccy\", async () => {",
          "102:       const model = new WatsonxLLM({",
          "103:         maxConcurrency: 1,",
          "104:         version: \"2024-05-31\",",
          "105:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "106:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "107:       });",
          "108:       await Promise.all([",
          "109:         model.invoke(\"Print hello world\"),",
          "110:         model.invoke(\"Print hello world\"),",
          "111:       ]);",
          "112:     });",
          "114:     test(\"Token usage\", async () => {",
          "115:       process.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"false\";",
          "116:       try {",
          "117:         const tokenUsage: TokenUsage = {",
          "118:           generated_token_count: 0,",
          "119:           input_token_count: 0,",
          "120:         };",
          "121:         const model = new WatsonxLLM({",
          "122:           maxConcurrency: 1,",
          "123:           version: \"2024-05-31\",",
          "124:           max_new_tokens: 1,",
          "125:           serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "126:           projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "127:           callbacks: CallbackManager.fromHandlers({",
          "128:             async handleLLMEnd(output: LLMResult) {",
          "129:               const singleTokenUsage: TokenUsage | undefined =",
          "130:                 output.llmOutput?.tokenUsage;",
          "131:               if (singleTokenUsage) {",
          "132:                 tokenUsage.generated_token_count +=",
          "133:                   singleTokenUsage.generated_token_count;",
          "134:                 tokenUsage.input_token_count +=",
          "135:                   singleTokenUsage.input_token_count;",
          "136:               }",
          "137:             },",
          "138:           }),",
          "139:         });",
          "140:         await model.invoke(\"Hello\");",
          "141:         expect(tokenUsage.generated_token_count).toBe(1);",
          "142:         expect(tokenUsage.input_token_count).toBe(1);",
          "143:       } finally {",
          "144:         process.env.LANGCHAIN_CALLBACKS_BACKGROUND = originalBackground;",
          "145:       }",
          "146:     });",
          "148:     test(\"Streaming mode\", async () => {",
          "149:       let countedTokens = 0;",
          "150:       let streamedText = \"\";",
          "151:       let usedTokens = 0;",
          "152:       const model = new WatsonxLLM({",
          "153:         version: \"2024-05-31\",",
          "154:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "155:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "156:         max_new_tokens: 5,",
          "157:         streaming: true,",
          "159:         callbacks: CallbackManager.fromHandlers({",
          "160:           async handleLLMEnd(output) {",
          "161:             usedTokens = output.llmOutput?.tokenUsage.generated_token_count;",
          "162:           },",
          "163:           async handleLLMNewToken(token: string) {",
          "164:             countedTokens += 1;",
          "165:             streamedText += token;",
          "166:           },",
          "167:         }),",
          "168:       });",
          "170:       const res = await model.invoke(\" Print hello world?\");",
          "171:       expect(countedTokens).toBe(usedTokens);",
          "172:       expect(res).toBe(streamedText);",
          "173:     });",
          "174:   });",
          "176:   describe(\"Test generate methods\", () => {",
          "177:     test(\"Basic usage\", async () => {",
          "178:       const model = new WatsonxLLM({",
          "179:         version: \"2024-05-31\",",
          "180:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "181:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "182:         max_new_tokens: 5,",
          "183:       });",
          "184:       const res = await model.generate([",
          "185:         \"Print hello world!\",",
          "186:         \"Print hello universe!\",",
          "187:       ]);",
          "188:       expect(res.generations.length).toBe(2);",
          "189:     });",
          "191:     test(\"Stop\", async () => {",
          "192:       const model = new WatsonxLLM({",
          "193:         version: \"2024-05-31\",",
          "194:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "195:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "196:         max_new_tokens: 100,",
          "197:       });",
          "199:       const res = await model.generate(",
          "200:         [\"Print hello world!\", \"Print hello world hello!\"],",
          "201:         {",
          "202:           stop: [\"Hello\"],",
          "203:         }",
          "204:       );",
          "206:       expect(",
          "207:         res.generations",
          "208:           .map((generation) => generation.map((item) => item.text))",
          "209:           .join(\"\")",
          "210:           .indexOf(\"world\")",
          "211:       ).toBe(-1);",
          "212:     });",
          "214:     test(\"Streaming mode with multiple prompts\", async () => {",
          "215:       const nrNewTokens = [0, 0, 0];",
          "216:       const completions = [\"\", \"\", \"\"];",
          "217:       const model = new WatsonxLLM({",
          "218:         version: \"2024-05-31\",",
          "219:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "220:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "221:         max_new_tokens: 5,",
          "222:         streaming: true,",
          "223:         callbacks: CallbackManager.fromHandlers({",
          "224:           async handleLLMNewToken(token: string, idx) {",
          "225:             nrNewTokens[idx.prompt] += 1;",
          "226:             completions[idx.prompt] += token;",
          "227:           },",
          "228:         }),",
          "229:       });",
          "230:       const res = await model.generate([",
          "231:         \"Print bye bye world!\",",
          "232:         \"Print bye bye world!\",",
          "233:         \"Print Hello IBM!\",",
          "234:       ]);",
          "235:       res.generations.forEach((generation, index) => {",
          "236:         generation.forEach((g) => {",
          "237:           expect(g.generationInfo?.generated_token_count).toBe(",
          "238:             nrNewTokens[index]",
          "239:           );",
          "240:         });",
          "241:       });",
          "242:       nrNewTokens.forEach((tokens) => expect(tokens > 0).toBe(true));",
          "243:       expect(res.generations.length).toBe(3);",
          "244:     });",
          "246:     test(\"Prompt value\", async () => {",
          "247:       const model = new WatsonxLLM({",
          "248:         version: \"2024-05-31\",",
          "249:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "250:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "251:         max_new_tokens: 5,",
          "252:       });",
          "253:       const res = await model.generatePrompt([",
          "254:         new StringPromptValue(\"Print hello world!\"),",
          "255:       ]);",
          "256:       for (const generation of res.generations) {",
          "257:         expect(generation.length).toBe(1);",
          "258:       }",
          "259:     });",
          "260:   });",
          "262:   describe(\"Test stream method\", () => {",
          "263:     test(\"Basic usage\", async () => {",
          "264:       let countedTokens = 0;",
          "265:       let streamedText = \"\";",
          "266:       const model = new WatsonxLLM({",
          "267:         version: \"2024-05-31\",",
          "268:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "269:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "270:         max_new_tokens: 100,",
          "271:         callbacks: CallbackManager.fromHandlers({",
          "272:           async handleLLMNewToken(token: string) {",
          "273:             countedTokens += 1;",
          "274:             streamedText += token;",
          "275:           },",
          "276:         }),",
          "277:       });",
          "278:       const stream = await model.stream(\"Print hello world.\");",
          "279:       const chunks = [];",
          "280:       for await (const chunk of stream) {",
          "281:         chunks.push(chunk);",
          "282:       }",
          "283:       expect(chunks.length).toBeGreaterThan(1);",
          "284:       expect(chunks.join(\"\")).toBe(streamedText);",
          "285:     });",
          "287:     test(\"Stop\", async () => {",
          "288:       const model = new WatsonxLLM({",
          "289:         version: \"2024-05-31\",",
          "290:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "291:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "292:         max_new_tokens: 100,",
          "293:       });",
          "295:       const stream = await model.stream(\"Print hello world!\", {",
          "296:         stop: [\"Hello\"],",
          "297:       });",
          "298:       const chunks = [];",
          "299:       for await (const chunk of stream) {",
          "300:         chunks.push(chunk);",
          "301:       }",
          "302:       expect(chunks.join(\"\").indexOf(\"world\")).toBe(-1);",
          "303:     });",
          "305:     test(\"Timeout\", async () => {",
          "306:       const model = new WatsonxLLM({",
          "307:         version: \"2024-05-31\",",
          "308:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "309:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "310:         max_new_tokens: 1000,",
          "311:       });",
          "312:       await expect(async () => {",
          "313:         const stream = await model.stream(",
          "314:           \"How is your day going? Be precise and tell me a lot about it/\",",
          "315:           {",
          "316:             signal: AbortSignal.timeout(750),",
          "317:           }",
          "318:         );",
          "319:         const chunks = [];",
          "320:         for await (const chunk of stream) {",
          "321:           chunks.push(chunk);",
          "322:         }",
          "323:       }).rejects.toThrowError();",
          "324:     });",
          "326:     test(\"Signal in call options\", async () => {",
          "327:       const model = new WatsonxLLM({",
          "328:         version: \"2024-05-31\",",
          "329:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "330:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "331:         max_new_tokens: 1000,",
          "332:       });",
          "333:       const controller = new AbortController();",
          "334:       await expect(async () => {",
          "335:         const stream = await model.stream(",
          "336:           \"How is your day going? Be precise and tell me a lot about it\",",
          "337:           {",
          "338:             signal: controller.signal,",
          "339:           }",
          "340:         );",
          "341:         const chunks = [];",
          "342:         let i = 0;",
          "343:         for await (const chunk of stream) {",
          "344:           i += 1;",
          "345:           chunks.push(chunk);",
          "346:           if (i === 5) {",
          "347:             controller.abort();",
          "348:           }",
          "349:         }",
          "350:       }).rejects.toThrowError();",
          "351:     });",
          "352:   });",
          "354:   describe(\"Test getNumToken method\", () => {",
          "355:     test(\"Passing correct value\", async () => {",
          "356:       const testProps: WatsonxInputLLM = {",
          "357:         version: \"2024-05-31\",",
          "358:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "359:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "360:       };",
          "361:       const instance = new WatsonxLLM({",
          "362:         ...testProps,",
          "363:       });",
          "364:       await expect(",
          "365:         instance.getNumTokens(\"Hello\")",
          "366:       ).resolves.toBeGreaterThanOrEqual(0);",
          "367:       await expect(",
          "368:         instance.getNumTokens(\"Hello\", { return_tokens: true })",
          "369:       ).resolves.toBeGreaterThanOrEqual(0);",
          "370:     });",
          "372:     test(\"Passing wrong value\", async () => {",
          "373:       const testProps: WatsonxInputLLM = {",
          "374:         version: \"2024-05-31\",",
          "375:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "376:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "377:         maxRetries: 3,",
          "378:       };",
          "379:       const instance = new WatsonxLLM({",
          "380:         ...testProps,",
          "381:       });",
          "384:       await expect(instance.getNumTokens(12)).rejects.toThrowError();",
          "385:       await expect(",
          "387:         instance.getNumTokens(12, { wrong: \"Wrong\" })",
          "388:       ).rejects.toThrowError();",
          "389:     });",
          "390:   });",
          "391: });",
          "",
          "---------------"
        ],
        "libs/langchain-community/src/llms/tests/ibm.test.ts||libs/langchain-community/src/llms/tests/ibm.test.ts": [
          "File: libs/langchain-community/src/llms/tests/ibm.test.ts -> libs/langchain-community/src/llms/tests/ibm.test.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "2: import WatsonxAiMlVml_v1 from \"@ibm-cloud/watsonx-ai/dist/watsonx-ai-ml/vml_v1.js\";",
          "3: import { WatsonxLLM, WatsonxInputLLM } from \"../ibm.js\";",
          "4: import { authenticateAndSetInstance } from \"../../utils/ibm.js\";",
          "5: import {",
          "6:   WatsonxEmbeddings,",
          "7:   WatsonxEmbeddingsParams,",
          "8: } from \"../../embeddings/ibm.js\";",
          "10: const fakeAuthProp = {",
          "11:   watsonxAIAuthType: \"iam\",",
          "12:   watsonxAIApikey: \"fake_key\",",
          "13: };",
          "14: export function getKey<K>(key: K): K {",
          "15:   return key;",
          "16: }",
          "17: export const testProperties = (",
          "18:   instance: WatsonxLLM | WatsonxEmbeddings,",
          "19:   testProps: WatsonxInputLLM,",
          "20:   notExTestProps?: { [key: string]: any }",
          "21: ) => {",
          "22:   const checkProperty = <T extends { [key: string]: any }>(",
          "23:     testProps: T,",
          "24:     instance: T,",
          "25:     existing = true",
          "26:   ) => {",
          "27:     Object.keys(testProps).forEach((key) => {",
          "28:       const keys = getKey<keyof T>(key);",
          "29:       type Type = Pick<T, typeof keys>;",
          "31:       if (typeof testProps[key as keyof T] === \"object\")",
          "32:         checkProperty<Type>(testProps[key as keyof T], instance[key], existing);",
          "33:       else {",
          "34:         if (existing)",
          "35:           expect(instance[key as keyof T]).toBe(testProps[key as keyof T]);",
          "36:         else if (instance) expect(instance[key as keyof T]).toBeUndefined();",
          "37:       }",
          "38:     });",
          "39:   };",
          "40:   checkProperty<WatsonxEmbeddingsParams>(testProps, instance);",
          "41:   if (notExTestProps)",
          "42:     checkProperty<typeof notExTestProps>(notExTestProps, instance, false);",
          "43: };",
          "45: describe(\"LLM unit tests\", () => {",
          "46:   describe(\"Positive tests\", () => {",
          "47:     test(\"Test authentication function\", () => {",
          "48:       const instance = authenticateAndSetInstance({",
          "49:         version: \"2024-05-31\",",
          "50:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "51:         ...fakeAuthProp,",
          "52:       });",
          "53:       expect(instance).toBeInstanceOf(WatsonxAiMlVml_v1);",
          "54:     });",
          "56:     test(\"Test basic properties after init\", async () => {",
          "57:       const testProps = {",
          "58:         version: \"2024-05-31\",",
          "59:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "60:         projectId: process.env.WATSONX_AI_PROJECT_ID || \"testString\",",
          "61:       };",
          "62:       const instance = new WatsonxLLM({ ...testProps, ...fakeAuthProp });",
          "64:       testProperties(instance, testProps);",
          "65:     });",
          "67:     test(\"Test methods after init\", () => {",
          "68:       const testProps: WatsonxInputLLM = {",
          "69:         version: \"2024-05-31\",",
          "70:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "71:         projectId: process.env.WATSONX_AI_PROJECT_ID || \"testString\",",
          "72:       };",
          "73:       const instance = new WatsonxLLM({",
          "74:         ...testProps,",
          "75:         ...fakeAuthProp,",
          "76:       });",
          "77:       expect(instance.getNumTokens).toBeDefined();",
          "78:       expect(instance._generate).toBeDefined();",
          "79:       expect(instance._streamResponseChunks).toBeDefined();",
          "80:       expect(instance.invocationParams).toBeDefined();",
          "81:     });",
          "83:     test(\"Test properties after init\", async () => {",
          "84:       const testProps = {",
          "85:         version: \"2024-05-31\",",
          "86:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "87:         projectId: process.env.WATSONX_AI_PROJECT_ID || \"testString\",",
          "88:         model: \"ibm/granite-13b-chat-v2\",",
          "89:         max_new_tokens: 100,",
          "90:         decoding_method: \"sample\",",
          "91:         length_penalty: { decay_factor: 1, start_index: 1 },",
          "92:         min_new_tokens: 10,",
          "93:         random_seed: 1,",
          "94:         stop_sequences: [\"hello\"],",
          "95:         temperature: 0.1,",
          "96:         time_limit: 10000,",
          "97:         top_k: 1,",
          "98:         top_p: 1,",
          "99:         repetition_penalty: 1,",
          "100:         truncate_input_tokens: 1,",
          "101:         return_options: {",
          "102:           input_text: true,",
          "103:           generated_tokens: true,",
          "104:           input_tokens: true,",
          "105:           token_logprobs: true,",
          "106:           token_ranks: true,",
          "108:           top_n_tokens: 2,",
          "109:         },",
          "110:         include_stop_sequence: false,",
          "111:         maxRetries: 3,",
          "112:         maxConcurrency: 3,",
          "113:       };",
          "114:       const instance = new WatsonxLLM({ ...testProps, ...fakeAuthProp });",
          "116:       testProperties(instance, testProps);",
          "117:     });",
          "118:   });",
          "120:   describe(\"Negative tests\", () => {",
          "121:     test(\"Missing id\", async () => {",
          "122:       const testProps: WatsonxInputLLM = {",
          "123:         version: \"2024-05-31\",",
          "124:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "125:       };",
          "126:       expect(",
          "127:         () =>",
          "128:           new WatsonxLLM({",
          "129:             ...testProps,",
          "130:             ...fakeAuthProp,",
          "131:           })",
          "132:       ).toThrowError();",
          "133:     });",
          "135:     test(\"Missing other props\", async () => {",
          "137:       const testPropsProjectId: WatsonxInputLLM = {",
          "138:         projectId: process.env.WATSONX_AI_PROJECT_ID || \"testString\",",
          "139:       };",
          "141:       expect(",
          "142:         () =>",
          "143:           new WatsonxLLM({",
          "144:             ...testPropsProjectId,",
          "145:             ...fakeAuthProp,",
          "146:           })",
          "147:       ).toThrowError();",
          "149:       const testPropsServiceUrl: WatsonxInputLLM = {",
          "150:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "151:       };",
          "152:       expect(",
          "153:         () =>",
          "154:           new WatsonxLLM({",
          "155:             ...testPropsServiceUrl,",
          "156:             ...fakeAuthProp,",
          "157:           })",
          "158:       ).toThrowError();",
          "159:       const testPropsVersion = {",
          "160:         version: \"2024-05-31\",",
          "161:       };",
          "162:       expect(",
          "163:         () =>",
          "164:           new WatsonxLLM({",
          "166:             testPropsVersion,",
          "167:           })",
          "168:       ).toThrowError();",
          "169:     });",
          "171:     test(\"Passing more than one id\", async () => {",
          "172:       const testProps: WatsonxInputLLM = {",
          "173:         version: \"2024-05-31\",",
          "174:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "175:         projectId: process.env.WATSONX_AI_PROJECT_ID || \"testString\",",
          "176:         spaceId: process.env.WATSONX_AI_PROJECT_ID || \"testString\",",
          "177:       };",
          "178:       expect(",
          "179:         () =>",
          "180:           new WatsonxLLM({",
          "181:             ...testProps,",
          "182:             ...fakeAuthProp,",
          "183:           })",
          "184:       ).toThrowError();",
          "185:     });",
          "187:     test(\"Not existing property passed\", async () => {",
          "188:       const testProps = {",
          "189:         version: \"2024-05-31\",",
          "190:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "191:         projectId: process.env.WATSONX_AI_PROJECT_ID || \"testString\",",
          "192:       };",
          "193:       const notExTestProps = {",
          "194:         notExisting: 12,",
          "195:         notExObj: {",
          "196:           notExProp: 12,",
          "197:         },",
          "198:       };",
          "199:       const instance = new WatsonxLLM({",
          "200:         ...testProps,",
          "201:         ...notExTestProps,",
          "202:         ...fakeAuthProp,",
          "203:       });",
          "204:       testProperties(instance, testProps, notExTestProps);",
          "205:     });",
          "206:   });",
          "207: });",
          "",
          "---------------"
        ],
        "libs/langchain-community/src/llms/watsonx_ai.ts||libs/langchain-community/src/llms/watsonx_ai.ts": [
          "File: libs/langchain-community/src/llms/watsonx_ai.ts -> libs/langchain-community/src/llms/watsonx_ai.ts"
        ],
        "libs/langchain-community/src/load/import_constants.ts||libs/langchain-community/src/load/import_constants.ts": [
          "File: libs/langchain-community/src/load/import_constants.ts -> libs/langchain-community/src/load/import_constants.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "14:   \"langchain_community/embeddings/gradient_ai\",",
          "15:   \"langchain_community/embeddings/hf\",",
          "16:   \"langchain_community/embeddings/hf_transformers\",",
          "17:   \"langchain_community/embeddings/jina\",",
          "18:   \"langchain_community/embeddings/llama_cpp\",",
          "19:   \"langchain_community/embeddings/premai\",",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "17:   \"langchain_community/embeddings/ibm\",",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "27:   \"langchain_community/llms/cohere\",",
          "28:   \"langchain_community/llms/gradient_ai\",",
          "29:   \"langchain_community/llms/hf\",",
          "30:   \"langchain_community/llms/llama_cpp\",",
          "31:   \"langchain_community/llms/portkey\",",
          "32:   \"langchain_community/llms/raycast\",",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "31:   \"langchain_community/llms/ibm\",",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "82:   \"langchain_community/chat_models/arcjet\",",
          "83:   \"langchain_community/chat_models/bedrock\",",
          "84:   \"langchain_community/chat_models/bedrock/web\",",
          "85:   \"langchain_community/chat_models/iflytek_xinghuo\",",
          "86:   \"langchain_community/chat_models/iflytek_xinghuo/web\",",
          "87:   \"langchain_community/chat_models/llama_cpp\",",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "87:   \"langchain_community/chat_models/ibm\",",
          "",
          "---------------"
        ],
        "libs/langchain-community/src/load/import_type.ts||libs/langchain-community/src/load/import_type.ts": [
          "File: libs/langchain-community/src/load/import_type.ts -> libs/langchain-community/src/load/import_type.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "5: export interface SecretMap {",
          "6:   ALIBABA_API_KEY?: string;",
          "7:   AWS_ACCESS_KEY_ID?: string;",
          "8:   AWS_SECRETE_ACCESS_KEY?: string;",
          "9:   AWS_SECRET_ACCESS_KEY?: string;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "7:   AUTHENTICATOR?: string;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "60:   VECTARA_API_KEY?: string;",
          "61:   VECTARA_CORPUS_ID?: string;",
          "62:   VECTARA_CUSTOMER_ID?: string;",
          "63:   WATSONX_PROJECT_ID?: string;",
          "64:   WRITER_API_KEY?: string;",
          "65:   WRITER_ORG_ID?: string;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "64:   WATSONX_AI_APIKEY?: string;",
          "65:   WATSONX_AI_AUTH_TYPE?: string;",
          "66:   WATSONX_AI_BEARER_TOKEN?: string;",
          "67:   WATSONX_AI_PASSWORD?: string;",
          "68:   WATSONX_AI_URL?: string;",
          "69:   WATSONX_AI_USERNAME?: string;",
          "",
          "---------------"
        ],
        "libs/langchain-community/src/types/ibm.ts||libs/langchain-community/src/types/ibm.ts": [
          "File: libs/langchain-community/src/types/ibm.ts -> libs/langchain-community/src/types/ibm.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: export interface TokenUsage {",
          "2:   generated_token_count: number;",
          "3:   input_token_count: number;",
          "4: }",
          "5: export interface WatsonxAuth {",
          "6:   watsonxAIApikey?: string;",
          "7:   watsonxAIBearerToken?: string;",
          "8:   watsonxAIUsername?: string;",
          "9:   watsonxAIPassword?: string;",
          "10:   watsonxAIUrl?: string;",
          "11:   watsonxAIAuthType?: string;",
          "12: }",
          "14: export interface WatsonxInit {",
          "15:   authenticator?: string;",
          "16:   serviceUrl: string;",
          "17:   version: string;",
          "18: }",
          "20: export interface WatsonxParams extends WatsonxInit {",
          "21:   model?: string;",
          "22:   spaceId?: string;",
          "23:   projectId?: string;",
          "24:   idOrName?: string;",
          "25:   maxConcurrency?: number;",
          "26:   maxRetries?: number;",
          "27: }",
          "29: export interface GenerationInfo {",
          "30:   text: string;",
          "31:   stop_reason: string | undefined;",
          "32:   generated_token_count: number;",
          "33:   input_token_count: number;",
          "34: }",
          "36: export interface ResponseChunk {",
          "37:   id: number;",
          "38:   event: string;",
          "39:   data: {",
          "40:     results: (TokenUsage & {",
          "41:       stop_reason?: string;",
          "42:       generated_text: string;",
          "43:     })[];",
          "44:   };",
          "45: }",
          "",
          "---------------"
        ],
        "libs/langchain-community/src/utils/ibm.ts||libs/langchain-community/src/utils/ibm.ts": [
          "File: libs/langchain-community/src/utils/ibm.ts -> libs/langchain-community/src/utils/ibm.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: import { WatsonXAI } from \"@ibm-cloud/watsonx-ai\";",
          "2: import {",
          "3:   IamAuthenticator,",
          "4:   BearerTokenAuthenticator,",
          "5:   CloudPakForDataAuthenticator,",
          "6: } from \"ibm-cloud-sdk-core\";",
          "7: import {",
          "8:   JsonOutputKeyToolsParserParams,",
          "9:   JsonOutputToolsParser,",
          "10: } from \"@langchain/core/output_parsers/openai_tools\";",
          "11: import { OutputParserException } from \"@langchain/core/output_parsers\";",
          "12: import { z } from \"zod\";",
          "13: import { ChatGeneration } from \"@langchain/core/outputs\";",
          "14: import { AIMessageChunk } from \"@langchain/core/messages\";",
          "15: import { ToolCall } from \"@langchain/core/messages/tool\";",
          "16: import { WatsonxAuth, WatsonxInit } from \"../types/ibm.js\";",
          "18: export const authenticateAndSetInstance = ({",
          "19:   watsonxAIApikey,",
          "20:   watsonxAIAuthType,",
          "21:   watsonxAIBearerToken,",
          "22:   watsonxAIUsername,",
          "23:   watsonxAIPassword,",
          "24:   watsonxAIUrl,",
          "25:   version,",
          "26:   serviceUrl,",
          "27: }: WatsonxAuth & Omit<WatsonxInit, \"authenticator\">): WatsonXAI | undefined => {",
          "28:   if (watsonxAIAuthType === \"iam\" && watsonxAIApikey) {",
          "29:     return WatsonXAI.newInstance({",
          "30:       version,",
          "31:       serviceUrl,",
          "32:       authenticator: new IamAuthenticator({",
          "33:         apikey: watsonxAIApikey,",
          "34:       }),",
          "35:     });",
          "36:   } else if (watsonxAIAuthType === \"bearertoken\" && watsonxAIBearerToken) {",
          "37:     return WatsonXAI.newInstance({",
          "38:       version,",
          "39:       serviceUrl,",
          "40:       authenticator: new BearerTokenAuthenticator({",
          "41:         bearerToken: watsonxAIBearerToken,",
          "42:       }),",
          "43:     });",
          "44:   } else if (watsonxAIAuthType === \"cp4d\" && watsonxAIUrl) {",
          "45:     if (watsonxAIUsername && watsonxAIPassword && watsonxAIApikey)",
          "46:       return WatsonXAI.newInstance({",
          "47:         version,",
          "48:         serviceUrl,",
          "49:         authenticator: new CloudPakForDataAuthenticator({",
          "50:           username: watsonxAIUsername,",
          "51:           password: watsonxAIPassword,",
          "52:           url: watsonxAIUrl,",
          "53:           apikey: watsonxAIApikey,",
          "54:         }),",
          "55:       });",
          "56:   } else",
          "57:     return WatsonXAI.newInstance({",
          "58:       version,",
          "59:       serviceUrl,",
          "60:     });",
          "61:   return undefined;",
          "62: };",
          "66: const TOOL_CALL_ID_PATTERN = /^[a-zA-Z0-9]{9}$/;",
          "68: export function _isValidMistralToolCallId(toolCallId: string): boolean {",
          "69:   return TOOL_CALL_ID_PATTERN.test(toolCallId);",
          "70: }",
          "72: function _base62Encode(num: number): string {",
          "73:   let numCopy = num;",
          "74:   const base62 =",
          "75:     \"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\";",
          "76:   if (numCopy === 0) return base62[0];",
          "77:   const arr: string[] = [];",
          "78:   const base = base62.length;",
          "79:   while (numCopy) {",
          "80:     arr.push(base62[numCopy % base]);",
          "81:     numCopy = Math.floor(numCopy / base);",
          "82:   }",
          "83:   return arr.reverse().join(\"\");",
          "84: }",
          "86: function _simpleHash(str: string): number {",
          "87:   let hash = 0;",
          "88:   for (let i = 0; i < str.length; i += 1) {",
          "89:     const char = str.charCodeAt(i);",
          "90:     hash = (hash << 5) - hash + char;",
          "91:     hash &= hash; // Convert to 32-bit integer",
          "92:   }",
          "93:   return Math.abs(hash);",
          "94: }",
          "96: export function _convertToolCallIdToMistralCompatible(",
          "97:   toolCallId: string",
          "98: ): string {",
          "99:   if (_isValidMistralToolCallId(toolCallId)) {",
          "100:     return toolCallId;",
          "101:   } else {",
          "102:     const hash = _simpleHash(toolCallId);",
          "103:     const base62Str = _base62Encode(hash);",
          "104:     if (base62Str.length >= 9) {",
          "105:       return base62Str.slice(0, 9);",
          "106:     } else {",
          "107:       return base62Str.padStart(9, \"0\");",
          "108:     }",
          "109:   }",
          "110: }",
          "112: interface WatsonxToolsOutputParserParams<T extends Record<string, any>>",
          "113:   extends JsonOutputKeyToolsParserParams<T> {}",
          "115: export class WatsonxToolsOutputParser<",
          "116:   T extends Record<string, any> = Record<string, any>",
          "117: > extends JsonOutputToolsParser<T> {",
          "118:   static lc_name() {",
          "119:     return \"WatsonxToolsOutputParser\";",
          "120:   }",
          "122:   lc_namespace = [\"langchain\", \"watsonx\", \"output_parsers\"];",
          "124:   returnId = false;",
          "126:   keyName: string;",
          "128:   returnSingle = false;",
          "130:   zodSchema?: z.ZodType<T>;",
          "132:   latestCorrect?: ToolCall;",
          "134:   constructor(params: WatsonxToolsOutputParserParams<T>) {",
          "135:     super(params);",
          "136:     this.keyName = params.keyName;",
          "137:     this.returnSingle = params.returnSingle ?? this.returnSingle;",
          "138:     this.zodSchema = params.zodSchema;",
          "139:   }",
          "141:   protected async _validateResult(result: unknown): Promise<T> {",
          "142:     let parsedResult = result;",
          "143:     if (typeof result === \"string\") {",
          "144:       try {",
          "145:         parsedResult = JSON.parse(result);",
          "146:       } catch (e: any) {",
          "147:         throw new OutputParserException(",
          "148:           `Failed to parse. Text: \"${JSON.stringify(",
          "149:             result,",
          "150:             null,",
          "151:             2",
          "152:           )}\". Error: ${JSON.stringify(e.message)}`,",
          "153:           result",
          "154:         );",
          "155:       }",
          "156:     } else {",
          "157:       parsedResult = result;",
          "158:     }",
          "159:     if (this.zodSchema === undefined) {",
          "160:       return parsedResult as T;",
          "161:     }",
          "162:     const zodParsedResult = await this.zodSchema.safeParseAsync(parsedResult);",
          "163:     if (zodParsedResult.success) {",
          "164:       return zodParsedResult.data;",
          "165:     } else {",
          "166:       throw new OutputParserException(",
          "167:         `Failed to parse. Text: \"${JSON.stringify(",
          "168:           result,",
          "169:           null,",
          "170:           2",
          "171:         )}\". Error: ${JSON.stringify(zodParsedResult.error.errors)}`,",
          "172:         JSON.stringify(result, null, 2)",
          "173:       );",
          "174:     }",
          "175:   }",
          "177:   async parsePartialResult(generations: ChatGeneration[]): Promise<T> {",
          "178:     const tools = generations.flatMap((generation) => {",
          "179:       const message = generation.message as AIMessageChunk;",
          "180:       if (!Array.isArray(message.tool_calls)) {",
          "181:         return [];",
          "182:       }",
          "183:       const tool = message.tool_calls;",
          "184:       return tool;",
          "185:     });",
          "186:     if (tools[0] === undefined) {",
          "187:       if (this.latestCorrect) tools.push(this.latestCorrect);",
          "188:     }",
          "189:     const [tool] = tools;",
          "190:     this.latestCorrect = tool;",
          "191:     return tool.args as T;",
          "192:   }",
          "193: }",
          "",
          "---------------"
        ],
        "yarn.lock||yarn.lock": [
          "File: yarn.lock -> yarn.lock",
          "--- Hunk 1 ---",
          "[Context before]",
          "10495:   languageName: node",
          "10496:   linkType: hard",
          "10498: \"@inquirer/figures@npm:^1.0.3\":",
          "10499:   version: 1.0.5",
          "10500:   resolution: \"@inquirer/figures@npm:1.0.5\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "10498: \"@ibm-cloud/watsonx-ai@npm:^1.1.0\":",
          "10499:   version: 1.1.0",
          "10500:   resolution: \"@ibm-cloud/watsonx-ai@npm:1.1.0\"",
          "10501:   dependencies:",
          "10502:     \"@types/node\": ^12.0.8",
          "10503:     extend: 3.0.2",
          "10504:     ibm-cloud-sdk-core: ^4.2.5",
          "10505:   checksum: 0151bb0abe2a7d1dbcd6f8367ea02dfc924f15bdcbe8ec58bb89c8e055fa35c399b2253d6be3b84292f96c9161e49bcd6d6f5e1df0f2cd9adf21d1f3c0bc24b4",
          "10506:   languageName: node",
          "10507:   linkType: hard",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "11463:     \"@google-cloud/storage\": ^7.7.0",
          "11464:     \"@gradientai/nodejs-sdk\": ^1.2.0",
          "11465:     \"@huggingface/inference\": ^2.6.4",
          "11466:     \"@jest/globals\": ^29.5.0",
          "11467:     \"@langchain/core\": \"workspace:*\"",
          "11468:     \"@langchain/openai\": \">=0.2.0 <0.4.0\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "11477:     \"@ibm-cloud/watsonx-ai\": ^1.1.0",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "11560:     hdb: 0.19.8",
          "11561:     hnswlib-node: ^3.0.0",
          "11562:     html-to-text: ^9.0.5",
          "11563:     ignore: ^5.2.0",
          "11564:     interface-datastore: ^8.2.11",
          "11565:     ioredis: ^5.3.2",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "11575:     ibm-cloud-sdk-core: ^5.0.2",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "11638:     \"@google-cloud/storage\": ^6.10.1 || ^7.7.0",
          "11639:     \"@gradientai/nodejs-sdk\": ^1.2.0",
          "11640:     \"@huggingface/inference\": ^2.6.4",
          "11641:     \"@langchain/core\": \">=0.2.21 <0.4.0\"",
          "11642:     \"@layerup/layerup-security\": ^1.5.12",
          "11643:     \"@libsql/client\": ^0.14.0",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "11654:     \"@ibm-cloud/watsonx-ai\": \"*\"",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "11695:     googleapis: \"*\"",
          "11696:     hnswlib-node: ^3.0.0",
          "11697:     html-to-text: ^9.0.5",
          "11698:     ignore: ^5.2.0",
          "11699:     interface-datastore: ^8.2.11",
          "11700:     ioredis: ^5.3.2",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "11712:     ibm-cloud-sdk-core: \"*\"",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "18685:   languageName: node",
          "18686:   linkType: hard",
          "18688: \"@types/decamelize@npm:^1.2.0\":",
          "18689:   version: 1.2.0",
          "18690:   resolution: \"@types/decamelize@npm:1.2.0\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18703: \"@types/debug@npm:^4.1.12\":",
          "18704:   version: 4.1.12",
          "18705:   resolution: \"@types/debug@npm:4.1.12\"",
          "18706:   dependencies:",
          "18707:     \"@types/ms\": \"*\"",
          "18708:   checksum: 47876a852de8240bfdaf7481357af2b88cb660d30c72e73789abf00c499d6bc7cd5e52f41c915d1b9cd8ec9fef5b05688d7b7aef17f7f272c2d04679508d1053",
          "18709:   languageName: node",
          "18710:   linkType: hard",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "19097:   languageName: node",
          "19098:   linkType: hard",
          "19100: \"@types/mustache@npm:^4\":",
          "19101:   version: 4.2.5",
          "19102:   resolution: \"@types/mustache@npm:4.2.5\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19124: \"@types/ms@npm:*\":",
          "19125:   version: 0.7.34",
          "19126:   resolution: \"@types/ms@npm:0.7.34\"",
          "19127:   checksum: f38d36e7b6edecd9badc9cf50474159e9da5fa6965a75186cceaf883278611b9df6669dc3a3cc122b7938d317b68a9e3d573d316fcb35d1be47ec9e468c6bd8a",
          "19128:   languageName: node",
          "19129:   linkType: hard",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "19164:   languageName: node",
          "19165:   linkType: hard",
          "19167: \"@types/node@npm:^17.0.5\":",
          "19168:   version: 17.0.45",
          "19169:   resolution: \"@types/node@npm:17.0.45\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19198: \"@types/node@npm:^12.0.8\":",
          "19199:   version: 12.20.55",
          "19200:   resolution: \"@types/node@npm:12.20.55\"",
          "19201:   checksum: e4f86785f4092706e0d3b0edff8dca5a13b45627e4b36700acd8dfe6ad53db71928c8dee914d4276c7fd3b6ccd829aa919811c9eb708a2c8e4c6eb3701178c37",
          "19202:   languageName: node",
          "19203:   linkType: hard",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "19219:   languageName: node",
          "19220:   linkType: hard",
          "19222: \"@types/offscreencanvas@npm:~2019.3.0\":",
          "19223:   version: 2019.3.0",
          "19224:   resolution: \"@types/offscreencanvas@npm:2019.3.0\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19260: \"@types/node@npm:~10.14.19\":",
          "19261:   version: 10.14.22",
          "19262:   resolution: \"@types/node@npm:10.14.22\"",
          "19263:   checksum: 5dc12f9f284afe195584bfa553b3bd46828f0f568e1a349dcd7e6357d81fa82f8b3cd454f375b7478ad8e9b93a6e3341f102960ead4619829e5e82ea2bd8d204",
          "19264:   languageName: node",
          "19265:   linkType: hard",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "21432:   languageName: node",
          "21433:   linkType: hard",
          "21435: \"axios@npm:^0.25.0\":",
          "21436:   version: 0.25.0",
          "21437:   resolution: \"axios@npm:0.25.0\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "21480: \"axios@npm:1.7.4\":",
          "21481:   version: 1.7.4",
          "21482:   resolution: \"axios@npm:1.7.4\"",
          "21483:   dependencies:",
          "21484:     follow-redirects: ^1.15.6",
          "21485:     form-data: ^4.0.0",
          "21486:     proxy-from-env: ^1.1.0",
          "21487:   checksum: 0c17039a9acfe6a566fca8431ba5c1b455c83d30ea6157fec68a6722878fcd30f3bd32d172f6bee0c51fe75ca98e6414ddcd968a87b5606b573731629440bfaf",
          "21488:   languageName: node",
          "21489:   linkType: hard",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "21494:   languageName: node",
          "21495:   linkType: hard",
          "21497: \"axobject-query@npm:^3.1.1, axobject-query@npm:^3.2.1\":",
          "21498:   version: 3.2.1",
          "21499:   resolution: \"axobject-query@npm:3.2.1\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "21553: \"axios@npm:^1.7.5\":",
          "21554:   version: 1.7.7",
          "21555:   resolution: \"axios@npm:1.7.7\"",
          "21556:   dependencies:",
          "21557:     follow-redirects: ^1.15.6",
          "21558:     form-data: ^4.0.0",
          "21559:     proxy-from-env: ^1.1.0",
          "21560:   checksum: 882d4fe0ec694a07c7f5c1f68205eb6dc5a62aecdb632cc7a4a3d0985188ce3030e0b277e1a8260ac3f194d314ae342117660a151fabffdc5081ca0b5a8b47fe",
          "21561:   languageName: node",
          "21562:   linkType: hard",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "22417:   languageName: node",
          "22418:   linkType: hard",
          "22421:   version: 6.3.0",
          "22422:   resolution: \"camelcase@npm:6.3.0\"",
          "22423:   checksum: 8c96818a9076434998511251dcb2761a94817ea17dbdc37f47ac080bd088fc62c7369429a19e2178b993497132c8cbcf5cc1f44ba963e76782ba469c0474938d",
          "",
          "[Removed Lines]",
          "22420: \"camelcase@npm:6, camelcase@npm:^6.2.0\":",
          "",
          "[Added Lines]",
          "22487: \"camelcase@npm:6, camelcase@npm:^6.2.0, camelcase@npm:^6.3.0\":",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "25162:   languageName: node",
          "25163:   linkType: hard",
          "25165: \"diff-sequences@npm:^29.4.3\":",
          "25166:   version: 29.4.3",
          "25167:   resolution: \"diff-sequences@npm:29.4.3\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "25232: \"diff-sequences@npm:^27.5.1\":",
          "25233:   version: 27.5.1",
          "25234:   resolution: \"diff-sequences@npm:27.5.1\"",
          "25235:   checksum: a00db5554c9da7da225db2d2638d85f8e41124eccbd56cbaefb3b276dcbb1c1c2ad851c32defe2055a54a4806f030656cbf6638105fd6ce97bb87b90b32a33ca",
          "25236:   languageName: node",
          "25237:   linkType: hard",
          "",
          "---------------",
          "--- Hunk 14 ---",
          "[Context before]",
          "27385:   languageName: node",
          "27386:   linkType: hard",
          "27388: \"expect@npm:^29.0.0\":",
          "27389:   version: 29.6.1",
          "27390:   resolution: \"expect@npm:29.6.1\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "27462: \"expect@npm:^27.5.1\":",
          "27463:   version: 27.5.1",
          "27464:   resolution: \"expect@npm:27.5.1\"",
          "27465:   dependencies:",
          "27466:     \"@jest/types\": ^27.5.1",
          "27467:     jest-get-type: ^27.5.1",
          "27468:     jest-matcher-utils: ^27.5.1",
          "27469:     jest-message-util: ^27.5.1",
          "27470:   checksum: b2c66beb52de53ef1872165aace40224e722bca3c2274c54cfa74b6d617d55cf0ccdbf36783ccd64dbea501b280098ed33fd0b207d4f15bc03cd3c7a24364a6a",
          "27471:   languageName: node",
          "27472:   linkType: hard",
          "",
          "---------------",
          "--- Hunk 15 ---",
          "[Context before]",
          "27535:   languageName: node",
          "27536:   linkType: hard",
          "27539:   version: 3.0.2",
          "27540:   resolution: \"extend@npm:3.0.2\"",
          "27541:   checksum: a50a8309ca65ea5d426382ff09f33586527882cf532931cb08ca786ea3146c0553310bda688710ff61d7668eba9f96b923fe1420cdf56a2c3eaf30fcab87b515",
          "",
          "[Removed Lines]",
          "27538: \"extend@npm:^3.0.0, extend@npm:^3.0.2\":",
          "",
          "[Added Lines]",
          "27624: \"extend@npm:3.0.2, extend@npm:^3.0.0, extend@npm:^3.0.2\":",
          "",
          "---------------",
          "--- Hunk 16 ---",
          "[Context before]",
          "27878:   languageName: node",
          "27879:   linkType: hard",
          "27882:   version: 16.5.4",
          "27883:   resolution: \"file-type@npm:16.5.4\"",
          "27884:   dependencies:",
          "",
          "[Removed Lines]",
          "27881: \"file-type@npm:^16.5.4\":",
          "",
          "[Added Lines]",
          "27967: \"file-type@npm:16.5.4, file-type@npm:^16.5.4\":",
          "",
          "---------------",
          "--- Hunk 17 ---",
          "[Context before]",
          "30043:   languageName: node",
          "30044:   linkType: hard",
          "30046: \"iconv-lite@npm:0.4, iconv-lite@npm:0.4.24, iconv-lite@npm:^0.4.18, iconv-lite@npm:^0.4.24\":",
          "30047:   version: 0.4.24",
          "30048:   resolution: \"iconv-lite@npm:0.4.24\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "30132: \"ibm-cloud-sdk-core@npm:^4.2.5\":",
          "30133:   version: 4.3.4",
          "30134:   resolution: \"ibm-cloud-sdk-core@npm:4.3.4\"",
          "30135:   dependencies:",
          "30136:     \"@types/debug\": ^4.1.12",
          "30137:     \"@types/node\": ~10.14.19",
          "30138:     \"@types/tough-cookie\": ^4.0.0",
          "30139:     axios: ^1.7.5",
          "30140:     camelcase: ^6.3.0",
          "30141:     debug: ^4.3.4",
          "30142:     dotenv: ^16.4.5",
          "30143:     expect: ^27.5.1",
          "30144:     extend: 3.0.2",
          "30145:     file-type: 16.5.4",
          "30146:     form-data: 4.0.0",
          "30147:     isstream: 0.1.2",
          "30148:     jsonwebtoken: ^9.0.2",
          "30149:     mime-types: 2.1.35",
          "30150:     retry-axios: ^2.6.0",
          "30151:     tough-cookie: ^4.1.3",
          "30152:   checksum: 27d6bd692cde66766a7cea36e75d53a6a089e2b2b726cf86108ab48f9d452bb6d6a01324d2160e3bb54df7750240129bae989934ab2fd80c0950ecdb5bfc07b3",
          "30153:   languageName: node",
          "30154:   linkType: hard",
          "30156: \"ibm-cloud-sdk-core@npm:^5.0.2\":",
          "30157:   version: 5.0.2",
          "30158:   resolution: \"ibm-cloud-sdk-core@npm:5.0.2\"",
          "30159:   dependencies:",
          "30160:     \"@types/debug\": ^4.1.12",
          "30161:     \"@types/node\": ~10.14.19",
          "30162:     \"@types/tough-cookie\": ^4.0.0",
          "30163:     axios: 1.7.4",
          "30164:     camelcase: ^6.3.0",
          "30165:     debug: ^4.3.4",
          "30166:     dotenv: ^16.4.5",
          "30167:     extend: 3.0.2",
          "30168:     file-type: 16.5.4",
          "30169:     form-data: 4.0.0",
          "30170:     isstream: 0.1.2",
          "30171:     jsonwebtoken: ^9.0.2",
          "30172:     mime-types: 2.1.35",
          "30173:     retry-axios: ^2.6.0",
          "30174:     tough-cookie: ^4.1.3",
          "30175:   checksum: fed92b851f816cbe94f4f28c6b45eed3b214f570897ed9936e5b7fd332b8c25c599f49d96866b9d936499b39a65e4d9db5a3191940b5a2489656e966e8fa6526",
          "30176:   languageName: node",
          "30177:   linkType: hard",
          "",
          "---------------",
          "--- Hunk 18 ---",
          "[Context before]",
          "31199:   languageName: node",
          "31200:   linkType: hard",
          "31202: \"issue-parser@npm:6.0.0\":",
          "31203:   version: 6.0.0",
          "31204:   resolution: \"issue-parser@npm:6.0.0\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "31335: \"isstream@npm:0.1.2\":",
          "31336:   version: 0.1.2",
          "31337:   resolution: \"isstream@npm:0.1.2\"",
          "31338:   checksum: 1eb2fe63a729f7bdd8a559ab552c69055f4f48eb5c2f03724430587c6f450783c8f1cd936c1c952d0a927925180fcc892ebd5b174236cf1065d4bd5bdb37e963",
          "31339:   languageName: node",
          "31340:   linkType: hard",
          "",
          "---------------",
          "--- Hunk 19 ---",
          "[Context before]",
          "31534:   languageName: node",
          "31535:   linkType: hard",
          "31537: \"jest-diff@npm:^29.5.0\":",
          "31538:   version: 29.5.0",
          "31539:   resolution: \"jest-diff@npm:29.5.0\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "31677: \"jest-diff@npm:^27.5.1\":",
          "31678:   version: 27.5.1",
          "31679:   resolution: \"jest-diff@npm:27.5.1\"",
          "31680:   dependencies:",
          "31681:     chalk: ^4.0.0",
          "31682:     diff-sequences: ^27.5.1",
          "31683:     jest-get-type: ^27.5.1",
          "31684:     pretty-format: ^27.5.1",
          "31685:   checksum: 8be27c1e1ee57b2bb2bef9c0b233c19621b4c43d53a3c26e2c00a4e805eb4ea11fe1694a06a9fb0e80ffdcfdc0d2b1cb0b85920b3f5c892327ecd1e7bd96b865",
          "31686:   languageName: node",
          "31687:   linkType: hard",
          "",
          "---------------",
          "--- Hunk 20 ---",
          "[Context before]",
          "31620:   languageName: node",
          "31621:   linkType: hard",
          "31623: \"jest-get-type@npm:^29.4.3\":",
          "31624:   version: 29.4.3",
          "31625:   resolution: \"jest-get-type@npm:29.4.3\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "31775: \"jest-get-type@npm:^27.5.1\":",
          "31776:   version: 27.5.1",
          "31777:   resolution: \"jest-get-type@npm:27.5.1\"",
          "31778:   checksum: 63064ab70195c21007d897c1157bf88ff94a790824a10f8c890392e7d17eda9c3900513cb291ca1c8d5722cad79169764e9a1279f7c8a9c4cd6e9109ff04bbc0",
          "31779:   languageName: node",
          "31780:   linkType: hard",
          "",
          "---------------",
          "--- Hunk 21 ---",
          "[Context before]",
          "31690:   languageName: node",
          "31691:   linkType: hard",
          "31693: \"jest-matcher-utils@npm:^29.5.0\":",
          "31694:   version: 29.5.0",
          "31695:   resolution: \"jest-matcher-utils@npm:29.5.0\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "31852: \"jest-matcher-utils@npm:^27.5.1\":",
          "31853:   version: 27.5.1",
          "31854:   resolution: \"jest-matcher-utils@npm:27.5.1\"",
          "31855:   dependencies:",
          "31856:     chalk: ^4.0.0",
          "31857:     jest-diff: ^27.5.1",
          "31858:     jest-get-type: ^27.5.1",
          "31859:     pretty-format: ^27.5.1",
          "31860:   checksum: bb2135fc48889ff3fe73888f6cc7168ddab9de28b51b3148f820c89fdfd2effdcad005f18be67d0b9be80eda208ad47290f62f03d0a33f848db2dd0273c8217a",
          "31861:   languageName: node",
          "31862:   linkType: hard",
          "",
          "---------------",
          "--- Hunk 22 ---",
          "[Context before]",
          "31726:   languageName: node",
          "31727:   linkType: hard",
          "31729: \"jest-message-util@npm:^29.5.0\":",
          "31730:   version: 29.5.0",
          "31731:   resolution: \"jest-message-util@npm:29.5.0\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "31900: \"jest-message-util@npm:^27.5.1\":",
          "31901:   version: 27.5.1",
          "31902:   resolution: \"jest-message-util@npm:27.5.1\"",
          "31903:   dependencies:",
          "31904:     \"@babel/code-frame\": ^7.12.13",
          "31905:     \"@jest/types\": ^27.5.1",
          "31906:     \"@types/stack-utils\": ^2.0.0",
          "31907:     chalk: ^4.0.0",
          "31908:     graceful-fs: ^4.2.9",
          "31909:     micromatch: ^4.0.4",
          "31910:     pretty-format: ^27.5.1",
          "31911:     slash: ^3.0.0",
          "31912:     stack-utils: ^2.0.3",
          "31913:   checksum: eb6d637d1411c71646de578c49826b6da8e33dd293e501967011de9d1916d53d845afbfb52a5b661ff1c495be7c13f751c48c7f30781fd94fbd64842e8195796",
          "31914:   languageName: node",
          "31915:   linkType: hard",
          "",
          "---------------",
          "--- Hunk 23 ---",
          "[Context before]",
          "37201:   languageName: node",
          "37202:   linkType: hard",
          "37204: \"pretty-format@npm:^29.0.0, pretty-format@npm:^29.6.1\":",
          "37205:   version: 29.6.1",
          "37206:   resolution: \"pretty-format@npm:29.6.1\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "37392: \"pretty-format@npm:^27.5.1\":",
          "37393:   version: 27.5.1",
          "37394:   resolution: \"pretty-format@npm:27.5.1\"",
          "37395:   dependencies:",
          "37396:     ansi-regex: ^5.0.1",
          "37397:     ansi-styles: ^5.0.0",
          "37398:     react-is: ^17.0.1",
          "37399:   checksum: cf610cffcb793885d16f184a62162f2dd0df31642d9a18edf4ca298e909a8fe80bdbf556d5c9573992c102ce8bf948691da91bf9739bee0ffb6e79c8a8a6e088",
          "37400:   languageName: node",
          "37401:   linkType: hard",
          "",
          "---------------",
          "--- Hunk 24 ---",
          "[Context before]",
          "37872:   languageName: node",
          "37873:   linkType: hard",
          "37875: \"react-is@npm:^18.0.0\":",
          "37876:   version: 18.2.0",
          "37877:   resolution: \"react-is@npm:18.2.0\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "38074: \"react-is@npm:^17.0.1\":",
          "38075:   version: 17.0.2",
          "38076:   resolution: \"react-is@npm:17.0.2\"",
          "38077:   checksum: 9d6d111d8990dc98bc5402c1266a808b0459b5d54830bbea24c12d908b536df7883f268a7868cfaedde3dd9d4e0d574db456f84d2e6df9c4526f99bb4b5344d8",
          "38078:   languageName: node",
          "38079:   linkType: hard",
          "",
          "---------------",
          "--- Hunk 25 ---",
          "[Context before]",
          "38724:   languageName: node",
          "38725:   linkType: hard",
          "38727: \"retry-request@npm:^7.0.0\":",
          "38728:   version: 7.0.2",
          "38729:   resolution: \"retry-request@npm:7.0.2\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "38933: \"retry-axios@npm:^2.6.0\":",
          "38934:   version: 2.6.0",
          "38935:   resolution: \"retry-axios@npm:2.6.0\"",
          "38936:   peerDependencies:",
          "38937:     axios: \"*\"",
          "38938:   checksum: cf7e63d89f00ead2633e60f00b504ec10217db8165327879b6feb0fa787fffe687d06ee145b2f43d2b4ea8916d42c951d34ee32ee1ea47c9d0b602d4963bd7f9",
          "38939:   languageName: node",
          "38940:   linkType: hard",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "99829ef1c1dcb9f4946e7ae709ed4133722c9f1e",
      "candidate_info": {
        "commit_hash": "99829ef1c1dcb9f4946e7ae709ed4133722c9f1e",
        "repo": "langchain-ai/langchainjs",
        "commit_url": "https://github.com/langchain-ai/langchainjs/commit/99829ef1c1dcb9f4946e7ae709ed4133722c9f1e",
        "files": [
          "libs/langchain-community/package.json",
          "libs/langchain-community/src/chat_models/ibm.ts",
          "libs/langchain-community/src/chat_models/tests/ibm.int.test.ts",
          "libs/langchain-community/src/chat_models/tests/ibm.standard.int.test.ts",
          "libs/langchain-community/src/chat_models/tests/ibm.test.ts",
          "libs/langchain-community/src/llms/ibm.ts",
          "libs/langchain-community/src/llms/tests/ibm.int.test.ts",
          "libs/langchain-community/src/llms/tests/ibm.test.ts",
          "libs/langchain-community/src/types/ibm.ts",
          "libs/langchain-community/src/utils/ibm.ts",
          "yarn.lock"
        ],
        "message": "feat[community]: Add chat deployment to IBM chat class (#7633)",
        "before_after_code_files": [
          "libs/langchain-community/src/chat_models/ibm.ts||libs/langchain-community/src/chat_models/ibm.ts",
          "libs/langchain-community/src/chat_models/tests/ibm.int.test.ts||libs/langchain-community/src/chat_models/tests/ibm.int.test.ts",
          "libs/langchain-community/src/chat_models/tests/ibm.standard.int.test.ts||libs/langchain-community/src/chat_models/tests/ibm.standard.int.test.ts",
          "libs/langchain-community/src/chat_models/tests/ibm.test.ts||libs/langchain-community/src/chat_models/tests/ibm.test.ts",
          "libs/langchain-community/src/llms/ibm.ts||libs/langchain-community/src/llms/ibm.ts",
          "libs/langchain-community/src/llms/tests/ibm.int.test.ts||libs/langchain-community/src/llms/tests/ibm.int.test.ts",
          "libs/langchain-community/src/llms/tests/ibm.test.ts||libs/langchain-community/src/llms/tests/ibm.test.ts",
          "libs/langchain-community/src/types/ibm.ts||libs/langchain-community/src/types/ibm.ts",
          "libs/langchain-community/src/utils/ibm.ts||libs/langchain-community/src/utils/ibm.ts",
          "yarn.lock||yarn.lock"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "yarn.lock||yarn.lock"
          ],
          "candidate": [
            "yarn.lock||yarn.lock"
          ]
        }
      },
      "candidate_diff": {
        "libs/langchain-community/src/chat_models/ibm.ts||libs/langchain-community/src/chat_models/ibm.ts": [
          "File: libs/langchain-community/src/chat_models/ibm.ts -> libs/langchain-community/src/chat_models/ibm.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "33: } from \"@langchain/core/outputs\";",
          "34: import { AsyncCaller } from \"@langchain/core/utils/async_caller\";",
          "35: import {",
          "36:   RequestCallbacks,",
          "37:   TextChatMessagesTextChatMessageAssistant,",
          "38:   TextChatParameterTools,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "36:   DeploymentsTextChatParams,",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "65: import { isZodSchema } from \"@langchain/core/utils/types\";",
          "66: import { zodToJsonSchema } from \"zod-to-json-schema\";",
          "67: import { NewTokenIndices } from \"@langchain/core/callbacks/base\";",
          "69: import {",
          "70:   _convertToolCallIdToMistralCompatible,",
          "71:   authenticateAndSetInstance,",
          "",
          "[Removed Lines]",
          "68: import { WatsonxAuth, WatsonxParams } from \"../types/ibm.js\";",
          "",
          "[Added Lines]",
          "69: import {",
          "70:   Neverify,",
          "71:   WatsonxAuth,",
          "72:   WatsonxChatBasicOptions,",
          "73:   WatsonxDeployedParams,",
          "74:   WatsonxParams,",
          "75: } from \"../types/ibm.js\";",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "80: }",
          "82: export interface WatsonxCallParams",
          "87: export interface WatsonxCallOptionsChat",
          "88:   extends Omit<BaseChatModelCallOptions, \"stop\">,",
          "90:   promptIndex?: number;",
          "91:   tool_choice?: TextChatParameterTools | string | \"auto\" | \"any\";",
          "93: }",
          "95: type ChatWatsonxToolType = BindToolsInput | TextChatParameterTools;",
          "",
          "[Removed Lines]",
          "83:   extends Partial<Omit<TextChatParams, \"modelId\" | \"toolChoice\">> {",
          "84:   maxRetries?: number;",
          "85:   watsonxCallbacks?: RequestCallbacks;",
          "86: }",
          "89:     WatsonxCallParams {",
          "92:   watsonxCallbacks?: RequestCallbacks;",
          "",
          "[Added Lines]",
          "90:   extends Partial<",
          "91:     Omit<TextChatParams, \"modelId\" | \"toolChoice\" | \"messages\" | \"headers\">",
          "92:   > {}",
          "94: export interface WatsonxCallDeployedParams extends DeploymentsTextChatParams {}",
          "98:     WatsonxCallParams,",
          "99:     WatsonxChatBasicOptions {",
          "102: }",
          "104: export interface WatsonxCallOptionsDeployedChat",
          "105:   extends WatsonxCallDeployedParams,",
          "106:     WatsonxChatBasicOptions {",
          "107:   promptIndex?: number;",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "97: export interface ChatWatsonxInput",
          "98:   extends BaseChatModelParams,",
          "99:     WatsonxParams,",
          "104: function _convertToValidToolId(model: string, tool_call_id: string) {",
          "105:   if (model.startsWith(\"mistralai\"))",
          "106:     return _convertToolCallIdToMistralCompatible(tool_call_id);",
          "",
          "[Removed Lines]",
          "100:     WatsonxCallParams {",
          "101:   streaming?: boolean;",
          "102: }",
          "",
          "[Added Lines]",
          "115:     WatsonxCallParams,",
          "116:     Neverify<DeploymentsTextChatParams> {}",
          "118: export interface ChatWatsonxDeployedInput",
          "119:   extends BaseChatModelParams,",
          "120:     WatsonxDeployedParams,",
          "121:     Neverify<TextChatParams> {}",
          "123: export type ChatWatsonxConstructor = BaseChatModelParams &",
          "124:   Partial<WatsonxParams> &",
          "125:   WatsonxDeployedParams &",
          "126:   WatsonxCallParams;",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "128: function _convertMessagesToWatsonxMessages(",
          "129:   messages: BaseMessage[],",
          "131: ): TextChatResultMessage[] {",
          "132:   const getRole = (role: MessageType) => {",
          "133:     switch (role) {",
          "",
          "[Removed Lines]",
          "130:   model: string",
          "",
          "[Added Lines]",
          "153:   model?: string",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "151:       return message.tool_calls",
          "152:         .map((toolCall) => ({",
          "153:           ...toolCall,",
          "155:         }))",
          "156:         .map(convertLangChainToolCallToOpenAI) as TextChatToolCall[];",
          "157:     }",
          "",
          "[Removed Lines]",
          "154:           id: _convertToValidToolId(model, toolCall.id ?? \"\"),",
          "",
          "[Added Lines]",
          "177:           id: _convertToValidToolId(model ?? \"\", toolCall.id ?? \"\"),",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "166:         role: getRole(message._getType()),",
          "167:         content,",
          "168:         name: message.name,",
          "170:       };",
          "171:     }",
          "",
          "[Removed Lines]",
          "169:         tool_call_id: _convertToValidToolId(model, message.tool_call_id),",
          "",
          "[Added Lines]",
          "192:         tool_call_id: _convertToValidToolId(model ?? \"\", message.tool_call_id),",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "229: function _convertDeltaToMessageChunk(",
          "230:   delta: WatsonxDeltaStream,",
          "231:   rawData: TextChatResponse,",
          "233:   usage?: TextChatUsage,",
          "234:   defaultRole?: TextChatMessagesTextChatMessageAssistant.Constants.Role",
          "235: ) {",
          "",
          "[Removed Lines]",
          "232:   model: string,",
          "",
          "[Added Lines]",
          "255:   model?: string,",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "245:         } => ({",
          "246:           ...toolCall,",
          "247:           index,",
          "249:           type: \"function\",",
          "250:         })",
          "251:       )",
          "",
          "[Removed Lines]",
          "248:           id: _convertToValidToolId(model, toolCall.id),",
          "",
          "[Added Lines]",
          "271:           id: _convertToValidToolId(model ?? \"\", toolCall.id),",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "298:       return new ToolMessageChunk({",
          "299:         content,",
          "300:         additional_kwargs,",
          "302:       });",
          "303:   } else if (role === \"function\") {",
          "304:     return new FunctionMessageChunk({",
          "",
          "[Removed Lines]",
          "301:         tool_call_id: _convertToValidToolId(model, rawToolCalls?.[0].id),",
          "",
          "[Added Lines]",
          "324:         tool_call_id: _convertToValidToolId(model ?? \"\", rawToolCalls?.[0].id),",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "335: }",
          "337: export class ChatWatsonx<",
          "339:   >",
          "340:   extends BaseChatModel<CallOptions>",
          "342: {",
          "343:   static lc_name() {",
          "344:     return \"ChatWatsonx\";",
          "",
          "[Removed Lines]",
          "338:     CallOptions extends WatsonxCallOptionsChat = WatsonxCallOptionsChat",
          "341:   implements ChatWatsonxInput",
          "",
          "[Added Lines]",
          "361:     CallOptions extends WatsonxCallOptionsChat =",
          "362:       | WatsonxCallOptionsChat",
          "363:       | WatsonxCallOptionsDeployedChat",
          "366:   implements ChatWatsonxConstructor",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "385:     };",
          "386:   }",
          "390:   version = \"2024-05-31\";",
          "",
          "[Removed Lines]",
          "388:   model: string;",
          "",
          "[Added Lines]",
          "413:   model?: string;",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "400:   projectId?: string;",
          "402:   frequencyPenalty?: number;",
          "404:   logprobs?: boolean;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "427:   idOrName?: string;",
          "",
          "---------------",
          "--- Hunk 14 ---",
          "[Context before]",
          "426:   watsonxCallbacks?: RequestCallbacks;",
          "429:     super(fields);",
          "430:     if (",
          "434:     )",
          "435:       throw new Error(\"Maximum 1 id type can be specified per instance\");",
          "438:       throw new Error(",
          "439:         \"No id specified! At least id of 1 type has to be specified\"",
          "440:       );",
          "453:     this.serviceUrl = fields?.serviceUrl;",
          "457:     this.version = fields?.version ?? this.version;",
          "459:     const {",
          "460:       watsonxAIApikey,",
          "461:       watsonxAIAuthType,",
          "",
          "[Removed Lines]",
          "428:   constructor(fields: ChatWatsonxInput & WatsonxAuth) {",
          "431:       (fields.projectId && fields.spaceId) ||",
          "432:       (fields.idOrName && fields.projectId) ||",
          "433:       (fields.spaceId && fields.idOrName)",
          "437:     if (!fields.projectId && !fields.spaceId && !fields.idOrName)",
          "441:     this.projectId = fields?.projectId;",
          "442:     this.spaceId = fields?.spaceId;",
          "443:     this.temperature = fields?.temperature;",
          "444:     this.maxRetries = fields?.maxRetries || this.maxRetries;",
          "445:     this.maxConcurrency = fields?.maxConcurrency;",
          "446:     this.frequencyPenalty = fields?.frequencyPenalty;",
          "447:     this.topLogprobs = fields?.topLogprobs;",
          "448:     this.maxTokens = fields?.maxTokens ?? this.maxTokens;",
          "449:     this.presencePenalty = fields?.presencePenalty;",
          "450:     this.topP = fields?.topP;",
          "451:     this.timeLimit = fields?.timeLimit;",
          "452:     this.responseFormat = fields?.responseFormat ?? this.responseFormat;",
          "454:     this.streaming = fields?.streaming ?? this.streaming;",
          "455:     this.n = fields?.n ?? this.n;",
          "456:     this.model = fields?.model ?? this.model;",
          "458:     this.watsonxCallbacks = fields?.watsonxCallbacks ?? this.watsonxCallbacks;",
          "",
          "[Added Lines]",
          "455:   constructor(",
          "456:     fields: (ChatWatsonxInput | ChatWatsonxDeployedInput) & WatsonxAuth",
          "457:   ) {",
          "460:       (\"projectId\" in fields && \"spaceId\" in fields) ||",
          "461:       (\"projectId\" in fields && \"idOrName\" in fields) ||",
          "462:       (\"spaceId\" in fields && \"idOrName\" in fields)",
          "466:     if (!(\"projectId\" in fields || \"spaceId\" in fields || \"idOrName\" in fields))",
          "471:     if (\"model\" in fields) {",
          "472:       this.projectId = fields?.projectId;",
          "473:       this.spaceId = fields?.spaceId;",
          "474:       this.temperature = fields?.temperature;",
          "475:       this.maxRetries = fields?.maxRetries || this.maxRetries;",
          "476:       this.maxConcurrency = fields?.maxConcurrency;",
          "477:       this.frequencyPenalty = fields?.frequencyPenalty;",
          "478:       this.topLogprobs = fields?.topLogprobs;",
          "479:       this.maxTokens = fields?.maxTokens ?? this.maxTokens;",
          "480:       this.presencePenalty = fields?.presencePenalty;",
          "481:       this.topP = fields?.topP;",
          "482:       this.timeLimit = fields?.timeLimit;",
          "483:       this.responseFormat = fields?.responseFormat ?? this.responseFormat;",
          "484:       this.streaming = fields?.streaming ?? this.streaming;",
          "485:       this.n = fields?.n ?? this.n;",
          "486:       this.model = fields?.model ?? this.model;",
          "487:     } else this.idOrName = fields?.idOrName;",
          "489:     this.watsonxCallbacks = fields?.watsonxCallbacks ?? this.watsonxCallbacks;",
          "",
          "---------------",
          "--- Hunk 15 ---",
          "[Context before]",
          "486:   }",
          "488:   invocationParams(options: this[\"ParsedCallOptions\"]) {",
          "489:     const params = {",
          "490:       maxTokens: options.maxTokens ?? this.maxTokens,",
          "491:       temperature: options?.temperature ?? this.temperature,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "523:     const { signal, promptIndex, ...rest } = options;",
          "524:     if (this.idOrName && Object.keys(rest).length > 0)",
          "525:       throw new Error(\"Options cannot be provided to a deployed model\");",
          "",
          "---------------",
          "--- Hunk 16 ---",
          "[Context before]",
          "521:     } as CallOptions);",
          "522:   }",
          "526:       return { projectId: this.projectId, modelId: this.model };",
          "528:   }",
          "530:   async completionWithRetry<T>(",
          "",
          "[Removed Lines]",
          "524:   scopeId() {",
          "525:     if (this.projectId)",
          "527:     else return { spaceId: this.spaceId, modelId: this.model };",
          "",
          "[Added Lines]",
          "562:   scopeId():",
          "563:     | { idOrName: string }",
          "564:     | { projectId: string; modelId: string }",
          "565:     | { spaceId: string; modelId: string } {",
          "566:     if (this.projectId && this.model)",
          "568:     else if (this.spaceId && this.model)",
          "569:       return { spaceId: this.spaceId, modelId: this.model };",
          "570:     else if (this.idOrName) return { idOrName: this.idOrName };",
          "571:     else throw new Error(\"No scope id provided\");",
          "",
          "---------------",
          "--- Hunk 17 ---",
          "[Context before]",
          "595:         .map(([_, value]) => value);",
          "596:       return { generations, llmOutput: { tokenUsage } };",
          "597:     } else {",
          "602:       const watsonxCallbacks = this.invocationCallbacks(options);",
          "603:       const watsonxMessages = _convertMessagesToWatsonxMessages(",
          "604:         messages,",
          "605:         this.model",
          "606:       );",
          "607:       const callback = () =>",
          "615:       const { result } = await this.completionWithRetry(callback, options);",
          "616:       const generations: ChatGeneration[] = [];",
          "617:       for (const part of result.choices) {",
          "",
          "[Removed Lines]",
          "598:       const params = {",
          "599:         ...this.invocationParams(options),",
          "600:         ...this.scopeId(),",
          "601:       };",
          "608:         this.service.textChat(",
          "609:           {",
          "610:             ...params,",
          "611:             messages: watsonxMessages,",
          "612:           },",
          "613:           watsonxCallbacks",
          "614:         );",
          "",
          "[Added Lines]",
          "642:       const params = this.invocationParams(options);",
          "643:       const scopeId = this.scopeId();",
          "650:         \"idOrName\" in scopeId",
          "651:           ? this.service.deploymentsTextChat(",
          "652:               {",
          "653:                 ...scopeId,",
          "654:                 messages: watsonxMessages,",
          "655:               },",
          "656:               watsonxCallbacks",
          "657:             )",
          "658:           : this.service.textChat(",
          "659:               {",
          "660:                 ...params,",
          "661:                 ...scopeId,",
          "662:                 messages: watsonxMessages,",
          "663:               },",
          "664:               watsonxCallbacks",
          "665:             );",
          "",
          "---------------",
          "--- Hunk 18 ---",
          "[Context before]",
          "646:     options: this[\"ParsedCallOptions\"],",
          "647:     _runManager?: CallbackManagerForLLMRun",
          "648:   ): AsyncGenerator<ChatGenerationChunk> {",
          "650:     const watsonxMessages = _convertMessagesToWatsonxMessages(",
          "651:       messages,",
          "652:       this.model",
          "653:     );",
          "654:     const watsonxCallbacks = this.invocationCallbacks(options);",
          "655:     const callback = () =>",
          "664:     const stream = await this.completionWithRetry(callback, options);",
          "665:     let defaultRole;",
          "666:     let usage: TextChatUsage | undefined;",
          "",
          "[Removed Lines]",
          "649:     const params = { ...this.invocationParams(options), ...this.scopeId() };",
          "656:       this.service.textChatStream(",
          "657:         {",
          "658:           ...params,",
          "659:           messages: watsonxMessages,",
          "660:           returnObject: true,",
          "661:         },",
          "662:         watsonxCallbacks",
          "663:       );",
          "",
          "[Added Lines]",
          "700:     const params = this.invocationParams(options);",
          "701:     const scopeId = this.scopeId();",
          "708:       \"idOrName\" in scopeId",
          "709:         ? this.service.deploymentsTextChatStream(",
          "710:             {",
          "711:               ...scopeId,",
          "712:               messages: watsonxMessages,",
          "713:               returnObject: true,",
          "714:             },",
          "715:             watsonxCallbacks",
          "716:           )",
          "717:         : this.service.textChatStream(",
          "718:             {",
          "719:               ...params,",
          "720:               ...scopeId,",
          "721:               messages: watsonxMessages,",
          "722:               returnObject: true,",
          "723:             },",
          "724:             watsonxCallbacks",
          "725:           );",
          "",
          "---------------"
        ],
        "libs/langchain-community/src/chat_models/tests/ibm.int.test.ts||libs/langchain-community/src/chat_models/tests/ibm.int.test.ts": [
          "File: libs/langchain-community/src/chat_models/tests/ibm.int.test.ts -> libs/langchain-community/src/chat_models/tests/ibm.int.test.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: describe(\"Tests for chat\", () => {",
          "18:   describe(\"Test ChatWatsonx invoke and generate\", () => {",
          "20:       const service = new ChatWatsonx({",
          "21:         model: \"mistralai/mistral-large\",",
          "22:         version: \"2024-05-31\",",
          "",
          "[Removed Lines]",
          "19:     test(\"Basic invoke\", async () => {",
          "",
          "[Added Lines]",
          "19:     test(\"Basic invoke with projectId\", async () => {",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "26:       const res = await service.invoke(\"Print hello world\");",
          "27:       expect(res).toBeInstanceOf(AIMessage);",
          "28:     });",
          "29:     test(\"Basic generate\", async () => {",
          "30:       const service = new ChatWatsonx({",
          "31:         model: \"mistralai/mistral-large\",",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "29:     test(\"Basic invoke with spaceId\", async () => {",
          "30:       const service = new ChatWatsonx({",
          "31:         model: \"mistralai/mistral-large\",",
          "32:         version: \"2024-05-31\",",
          "33:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "34:         spaceId: process.env.WATSONX_AI_SPACE_ID ?? \"testString\",",
          "35:       });",
          "36:       const res = await service.invoke(\"Print hello world\");",
          "37:       expect(res).toBeInstanceOf(AIMessage);",
          "38:     });",
          "39:     test(\"Basic invoke with idOrName\", async () => {",
          "40:       const service = new ChatWatsonx({",
          "41:         version: \"2024-05-31\",",
          "42:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "43:         idOrName: process.env.WATSONX_AI_ID_OR_NAME ?? \"testString\",",
          "44:       });",
          "45:       const res = await service.invoke(\"Print hello world\");",
          "46:       expect(res).toBeInstanceOf(AIMessage);",
          "47:     });",
          "48:     test(\"Invalide invoke with idOrName and options as second argument\", async () => {",
          "49:       const service = new ChatWatsonx({",
          "50:         version: \"2024-05-31\",",
          "51:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "52:         idOrName: process.env.WATSONX_AI_ID_OR_NAME ?? \"testString\",",
          "53:       });",
          "54:       await expect(() =>",
          "55:         service.invoke(\"Print hello world\", {",
          "56:           maxTokens: 100,",
          "57:         })",
          "58:       ).rejects.toThrow(\"Options cannot be provided to a deployed model\");",
          "59:     });",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "711:     test(\"Schema with zod and stream\", async () => {",
          "712:       const service = new ChatWatsonx({",
          "714:         version: \"2024-05-31\",",
          "715:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "716:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "",
          "[Removed Lines]",
          "713:         model: \"mistralai/mistral-large\",",
          "",
          "[Added Lines]",
          "744:         model: \"meta-llama/llama-3-1-70b-instruct\",",
          "",
          "---------------"
        ],
        "libs/langchain-community/src/chat_models/tests/ibm.standard.int.test.ts||libs/langchain-community/src/chat_models/tests/ibm.standard.int.test.ts": [
          "File: libs/langchain-community/src/chat_models/tests/ibm.standard.int.test.ts -> libs/langchain-community/src/chat_models/tests/ibm.standard.int.test.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "34:       },",
          "35:     });",
          "36:   }",
          "37: }",
          "39: const testClass = new ChatWatsonxStandardIntegrationTests();",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "38:   async testInvokeMoreComplexTools() {",
          "39:     this.skipTestMessage(",
          "40:       \"testInvokeMoreComplexTools\",",
          "41:       \"ChatWatsonx\",",
          "42:       \"Watsonx does not support tool schemas which contain object with unknown/any parameters.\" +",
          "43:         \"Watsonx only supports objects in schemas when the parameters are defined.\"",
          "44:     );",
          "45:   }",
          "",
          "---------------"
        ],
        "libs/langchain-community/src/chat_models/tests/ibm.test.ts||libs/langchain-community/src/chat_models/tests/ibm.test.ts": [
          "File: libs/langchain-community/src/chat_models/tests/ibm.test.ts -> libs/langchain-community/src/chat_models/tests/ibm.test.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "3: import WatsonxAiMlVml_v1 from \"@ibm-cloud/watsonx-ai/dist/watsonx-ai-ml/vml_v1.js\";",
          "5: import { authenticateAndSetInstance } from \"../../utils/ibm.js\";",
          "7: const fakeAuthProp = {",
          "",
          "[Removed Lines]",
          "4: import { ChatWatsonx, ChatWatsonxInput, WatsonxCallParams } from \"../ibm.js\";",
          "",
          "[Added Lines]",
          "4: import {",
          "5:   ChatWatsonx,",
          "6:   ChatWatsonxConstructor,",
          "7:   ChatWatsonxInput,",
          "8:   WatsonxCallParams,",
          "9: } from \"../ibm.js\";",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "13: }",
          "14: export const testProperties = (",
          "15:   instance: ChatWatsonx,",
          "17:   notExTestProps?: { [key: string]: any }",
          "18: ) => {",
          "19:   const checkProperty = <T extends { [key: string]: any }>(",
          "",
          "[Removed Lines]",
          "16:   testProps: ChatWatsonxInput,",
          "",
          "[Added Lines]",
          "21:   testProps: ChatWatsonxConstructor,",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "24:     Object.keys(testProps).forEach((key) => {",
          "25:       const keys = getKey<keyof T>(key);",
          "26:       type Type = Pick<T, typeof keys>;",
          "28:       if (typeof testProps[key as keyof T] === \"object\")",
          "30:       else {",
          "31:         if (existing)",
          "34:       }",
          "35:     });",
          "36:   };",
          "",
          "[Removed Lines]",
          "29:         checkProperty<Type>(testProps[key as keyof T], instance[key], existing);",
          "32:           expect(instance[key as keyof T]).toBe(testProps[key as keyof T]);",
          "33:         else if (instance) expect(instance[key as keyof T]).toBeUndefined();",
          "",
          "[Added Lines]",
          "33:         checkProperty<Type>(",
          "34:           testProps[key as keyof T],",
          "35:           instance[key as keyof typeof instance],",
          "36:           existing",
          "37:         );",
          "40:           expect(instance[key as keyof typeof instance]).toBe(",
          "41:             testProps[key as keyof T]",
          "42:           );",
          "43:         else if (instance)",
          "44:           expect(instance[key as keyof typeof instance]).toBeUndefined();",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "62:       testProperties(instance, testProps);",
          "63:     });",
          "65:     test(\"Test methods after init\", () => {",
          "66:       const testProps: ChatWatsonxInput = {",
          "67:         model: \"mistralai/mistral-large\",",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "76:     test(\"Authenticate with projectId\", async () => {",
          "77:       const testProps = {",
          "78:         model: \"mistralai/mistral-large\",",
          "79:         version: \"2024-05-31\",",
          "80:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "81:         projectId: process.env.WATSONX_AI_PROJECT_ID || \"testString\",",
          "82:       };",
          "83:       const instance = new ChatWatsonx({ ...testProps, ...fakeAuthProp });",
          "85:       testProperties(instance, testProps);",
          "86:     });",
          "88:     test(\"Authenticate with spaceId\", async () => {",
          "89:       const testProps = {",
          "90:         model: \"mistralai/mistral-large\",",
          "91:         version: \"2024-05-31\",",
          "92:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "93:         spaceId: process.env.WATSONX_AI_SPACE_ID || \"testString\",",
          "94:       };",
          "95:       const instance = new ChatWatsonx({ ...testProps, ...fakeAuthProp });",
          "97:       testProperties(instance, testProps);",
          "98:     });",
          "100:     test(\"Authenticate with idOrName\", async () => {",
          "101:       const testProps = {",
          "102:         version: \"2024-05-31\",",
          "103:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "104:         idOrName: process.env.WATSONX_AI_ID_OR_NAME || \"testString\",",
          "105:       };",
          "106:       const instance = new ChatWatsonx({ ...testProps, ...fakeAuthProp });",
          "107:       testProperties(instance, testProps);",
          "108:     });",
          "",
          "---------------"
        ],
        "libs/langchain-community/src/llms/ibm.ts||libs/langchain-community/src/llms/ibm.ts": [
          "File: libs/langchain-community/src/llms/ibm.ts -> libs/langchain-community/src/llms/ibm.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "3: import { BaseLLM, BaseLLMParams } from \"@langchain/core/language_models/llms\";",
          "4: import { WatsonXAI } from \"@ibm-cloud/watsonx-ai\";",
          "5: import {",
          "7:   RequestCallbacks,",
          "8:   ReturnOptionProperties,",
          "9:   TextGenLengthPenalty,",
          "",
          "[Removed Lines]",
          "6:   DeploymentTextGenProperties,",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "21: import { authenticateAndSetInstance } from \"../utils/ibm.js\";",
          "22: import {",
          "23:   GenerationInfo,",
          "24:   ResponseChunk,",
          "25:   TokenUsage,",
          "26:   WatsonxAuth,",
          "27:   WatsonxParams,",
          "28: } from \"../types/ibm.js\";",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "23:   Neverify,",
          "27:   WatsonxDeployedParams,",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "43:   maxNewTokens?: number;",
          "44:   decodingMethod?: TextGenParameters.Constants.DecodingMethod | string;",
          "45:   lengthPenalty?: TextGenLengthPenalty;",
          "",
          "[Removed Lines]",
          "34: export interface WatsonxCallOptionsLLM extends BaseLanguageModelCallOptions {",
          "35:   maxRetries?: number;",
          "36:   parameters?: Partial<WatsonxInputLLM>;",
          "37:   idOrName?: string;",
          "38:   watsonxCallbacks?: RequestCallbacks;",
          "39: }",
          "41: export interface WatsonxInputLLM extends WatsonxParams, BaseLLMParams {",
          "42:   streaming?: boolean;",
          "",
          "[Added Lines]",
          "35: export interface WatsonxLLMParams {",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "54:   truncateInpuTokens?: number;",
          "55:   returnOptions?: ReturnOptionProperties;",
          "56:   includeStopSequence?: boolean;",
          "57:   watsonxCallbacks?: RequestCallbacks;",
          "58: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "50: }",
          "52: export interface WatsonxDeploymentLLMParams {",
          "53:   idOrName: string;",
          "54: }",
          "56: export interface WatsonxCallOptionsLLM extends BaseLanguageModelCallOptions {",
          "57:   maxRetries?: number;",
          "58:   parameters?: Partial<WatsonxLLMParams>;",
          "62: export interface WatsonxInputLLM",
          "63:   extends WatsonxParams,",
          "64:     BaseLLMParams,",
          "65:     WatsonxLLMParams,",
          "66:     Neverify<WatsonxDeploymentLLMParams> {}",
          "68: export interface WatsonxDeployedInputLLM",
          "69:   extends WatsonxDeployedParams,",
          "70:     BaseLLMParams,",
          "71:     Neverify<WatsonxLLMParams> {",
          "72:   model?: never;",
          "73: }",
          "75: export type WatsonxLLMConstructor = BaseLLMParams &",
          "76:   WatsonxLLMParams &",
          "77:   Partial<WatsonxParams> &",
          "78:   WatsonxDeployedParams;",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "64:     CallOptions extends WatsonxCallOptionsLLM = WatsonxCallOptionsLLM",
          "65:   >",
          "66:   extends BaseLLM<CallOptions>",
          "68: {",
          "70:   static lc_name() {",
          "",
          "[Removed Lines]",
          "67:   implements WatsonxInputLLM",
          "",
          "[Added Lines]",
          "87:   implements WatsonxLLMConstructor",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "124:   private service: WatsonXAI;",
          "127:     super(fields);",
          "145:     this.maxRetries = fields.maxRetries || this.maxRetries;",
          "146:     this.maxConcurrency = fields.maxConcurrency;",
          "147:     this.streaming = fields.streaming || this.streaming;",
          "148:     this.watsonxCallbacks = fields.watsonxCallbacks || this.watsonxCallbacks;",
          "149:     if (",
          "153:     )",
          "154:       throw new Error(\"Maximum 1 id type can be specified per instance\");",
          "157:       throw new Error(",
          "158:         \"No id specified! At least id of 1 type has to be specified\"",
          "159:       );",
          "164:     this.serviceUrl = fields?.serviceUrl;",
          "165:     const {",
          "",
          "[Removed Lines]",
          "126:   constructor(fields: WatsonxInputLLM & WatsonxAuth) {",
          "128:     this.model = fields.model ?? this.model;",
          "129:     this.version = fields.version;",
          "130:     this.maxNewTokens = fields.maxNewTokens ?? this.maxNewTokens;",
          "131:     this.serviceUrl = fields.serviceUrl;",
          "132:     this.decodingMethod = fields.decodingMethod;",
          "133:     this.lengthPenalty = fields.lengthPenalty;",
          "134:     this.minNewTokens = fields.minNewTokens;",
          "135:     this.randomSeed = fields.randomSeed;",
          "136:     this.stopSequence = fields.stopSequence;",
          "137:     this.temperature = fields.temperature;",
          "138:     this.timeLimit = fields.timeLimit;",
          "139:     this.topK = fields.topK;",
          "140:     this.topP = fields.topP;",
          "141:     this.repetitionPenalty = fields.repetitionPenalty;",
          "142:     this.truncateInpuTokens = fields.truncateInpuTokens;",
          "143:     this.returnOptions = fields.returnOptions;",
          "144:     this.includeStopSequence = fields.includeStopSequence;",
          "150:       (fields.projectId && fields.spaceId) ||",
          "151:       (fields.idOrName && fields.projectId) ||",
          "152:       (fields.spaceId && fields.idOrName)",
          "156:     if (!fields.projectId && !fields.spaceId && !fields.idOrName)",
          "160:     this.projectId = fields?.projectId;",
          "161:     this.spaceId = fields?.spaceId;",
          "162:     this.idOrName = fields?.idOrName;",
          "",
          "[Added Lines]",
          "146:   constructor(",
          "147:     fields: (WatsonxInputLLM | WatsonxDeployedInputLLM) & WatsonxAuth",
          "148:   ) {",
          "151:     if (fields.model) {",
          "152:       this.model = fields.model ?? this.model;",
          "153:       this.version = fields.version;",
          "154:       this.maxNewTokens = fields.maxNewTokens ?? this.maxNewTokens;",
          "155:       this.serviceUrl = fields.serviceUrl;",
          "156:       this.decodingMethod = fields.decodingMethod;",
          "157:       this.lengthPenalty = fields.lengthPenalty;",
          "158:       this.minNewTokens = fields.minNewTokens;",
          "159:       this.randomSeed = fields.randomSeed;",
          "160:       this.stopSequence = fields.stopSequence;",
          "161:       this.temperature = fields.temperature;",
          "162:       this.timeLimit = fields.timeLimit;",
          "163:       this.topK = fields.topK;",
          "164:       this.topP = fields.topP;",
          "165:       this.repetitionPenalty = fields.repetitionPenalty;",
          "166:       this.truncateInpuTokens = fields.truncateInpuTokens;",
          "167:       this.returnOptions = fields.returnOptions;",
          "168:       this.includeStopSequence = fields.includeStopSequence;",
          "169:       this.projectId = fields?.projectId;",
          "170:       this.spaceId = fields?.spaceId;",
          "171:     } else {",
          "172:       this.idOrName = fields?.idOrName;",
          "173:     }",
          "181:       (\"projectId\" in fields && \"spaceId\" in fields) ||",
          "182:       (\"projectId\" in fields && \"idOrName\" in fields) ||",
          "183:       (\"spaceId\" in fields && \"idOrName\" in fields)",
          "187:     if (!(\"projectId\" in fields || \"spaceId\" in fields || \"idOrName\" in fields))",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "215:     };",
          "216:   }",
          "221:     const { parameters } = options;",
          "223:     return {",
          "224:       max_new_tokens: parameters?.maxNewTokens ?? this.maxNewTokens,",
          "225:       decoding_method: parameters?.decodingMethod ?? this.decodingMethod,",
          "",
          "[Removed Lines]",
          "218:   invocationParams(",
          "219:     options: this[\"ParsedCallOptions\"]",
          "220:   ): TextGenParameters | DeploymentTextGenProperties {",
          "",
          "[Added Lines]",
          "246:   invocationParams(options: this[\"ParsedCallOptions\"]) {",
          "248:     const { signal, ...rest } = options;",
          "249:     if (this.idOrName && Object.keys(rest).length > 0)",
          "250:       throw new Error(\"Options cannot be provided to a deployed model\");",
          "251:     if (this.idOrName) return undefined;",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "293:       ...requestOptions",
          "294:     } = options;",
          "295:     const tokenUsage = { generated_token_count: 0, input_token_count: 0 };",
          "297:     const parameters = this.invocationParams(options);",
          "298:     const watsonxCallbacks = this.invocationCallbacks(options);",
          "299:     if (stream) {",
          "",
          "[Removed Lines]",
          "296:     const idOrName = options?.idOrName ?? this.idOrName;",
          "",
          "[Added Lines]",
          "325:     const idOrName = this.idOrName;",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "425:             geneartionsArray[completion].stop_reason =",
          "426:               chunk?.generationInfo?.stop_reason;",
          "427:             geneartionsArray[completion].text += chunk.text;",
          "432:           }",
          "434:           return geneartionsArray.map((item) => {",
          "",
          "[Removed Lines]",
          "428:             void runManager?.handleLLMNewToken(chunk.text, {",
          "429:               prompt: promptIdx,",
          "430:               completion: 0,",
          "431:             });",
          "",
          "[Added Lines]",
          "457:             if (chunk.text)",
          "458:               void runManager?.handleLLMNewToken(chunk.text, {",
          "459:                 prompt: promptIdx,",
          "460:                 completion: 0,",
          "461:               });",
          "",
          "---------------"
        ],
        "libs/langchain-community/src/llms/tests/ibm.int.test.ts||libs/langchain-community/src/llms/tests/ibm.int.test.ts": [
          "File: libs/langchain-community/src/llms/tests/ibm.int.test.ts -> libs/langchain-community/src/llms/tests/ibm.int.test.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "11:   describe(\"Test invoke method\", () => {",
          "12:     test(\"Correct value\", async () => {",
          "13:       const watsonXInstance = new WatsonxLLM({",
          "15:         version: \"2024-05-31\",",
          "16:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "17:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "",
          "[Removed Lines]",
          "14:         model: \"ibm/granite-13b-chat-v2\",",
          "",
          "[Added Lines]",
          "14:         model: \"ibm/granite-3-8b-instruct\",",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "22:     test(\"Overwritte params\", async () => {",
          "23:       const watsonXInstance = new WatsonxLLM({",
          "25:         version: \"2024-05-31\",",
          "26:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "27:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "",
          "[Removed Lines]",
          "24:         model: \"ibm/granite-13b-chat-v2\",",
          "",
          "[Added Lines]",
          "24:         model: \"ibm/granite-3-8b-instruct\",",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "34:     test(\"Invalid projectId\", async () => {",
          "35:       const watsonXInstance = new WatsonxLLM({",
          "37:         version: \"2024-05-31\",",
          "38:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "39:         projectId: \"Test wrong value\",",
          "",
          "[Removed Lines]",
          "36:         model: \"ibm/granite-13b-chat-v2\",",
          "",
          "[Added Lines]",
          "36:         model: \"ibm/granite-3-8b-instruct\",",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "44:     test(\"Invalid credentials\", async () => {",
          "45:       const watsonXInstance = new WatsonxLLM({",
          "47:         version: \"2024-05-31\",",
          "48:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "49:         projectId: \"Test wrong value\",",
          "",
          "[Removed Lines]",
          "46:         model: \"ibm/granite-13b-chat-v2\",",
          "",
          "[Added Lines]",
          "46:         model: \"ibm/granite-3-8b-instruct\",",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "57:     test(\"Wrong value\", async () => {",
          "58:       const watsonXInstance = new WatsonxLLM({",
          "60:         version: \"2024-05-31\",",
          "61:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "62:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "",
          "[Removed Lines]",
          "59:         model: \"ibm/granite-13b-chat-v2\",",
          "",
          "[Added Lines]",
          "59:         model: \"ibm/granite-3-8b-instruct\",",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "68:     test(\"Stop\", async () => {",
          "69:       const watsonXInstance = new WatsonxLLM({",
          "71:         version: \"2024-05-31\",",
          "72:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "73:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "",
          "[Removed Lines]",
          "70:         model: \"ibm/granite-13b-chat-v2\",",
          "",
          "[Added Lines]",
          "70:         model: \"ibm/granite-3-8b-instruct\",",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "80:     test(\"Stop with timeout\", async () => {",
          "81:       const watsonXInstance = new WatsonxLLM({",
          "83:         version: \"2024-05-31\",",
          "84:         serviceUrl: \"sdadasdas\" as string,",
          "85:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "",
          "[Removed Lines]",
          "82:         model: \"ibm/granite-13b-chat-v2\",",
          "",
          "[Added Lines]",
          "82:         model: \"ibm/granite-3-8b-instruct\",",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "95:     test(\"Signal in call options\", async () => {",
          "96:       const watsonXInstance = new WatsonxLLM({",
          "98:         version: \"2024-05-31\",",
          "99:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "100:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "",
          "[Removed Lines]",
          "97:         model: \"ibm/granite-13b-chat-v2\",",
          "",
          "[Added Lines]",
          "97:         model: \"ibm/granite-3-8b-instruct\",",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "120:     test(\"Concurenccy\", async () => {",
          "121:       const model = new WatsonxLLM({",
          "123:         maxConcurrency: 1,",
          "124:         version: \"2024-05-31\",",
          "125:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "",
          "[Removed Lines]",
          "122:         model: \"ibm/granite-13b-chat-v2\",",
          "",
          "[Added Lines]",
          "122:         model: \"ibm/granite-3-8b-instruct\",",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "139:           input_token_count: 0,",
          "140:         };",
          "141:         const model = new WatsonxLLM({",
          "143:           version: \"2024-05-31\",",
          "144:           maxNewTokens: 1,",
          "145:           maxConcurrency: 1,",
          "",
          "[Removed Lines]",
          "142:           model: \"ibm/granite-13b-chat-v2\",",
          "",
          "[Added Lines]",
          "142:           model: \"ibm/granite-3-8b-instruct\",",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "171:       let streamedText = \"\";",
          "172:       let usedTokens = 0;",
          "173:       const model = new WatsonxLLM({",
          "175:         version: \"2024-05-31\",",
          "176:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "177:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "",
          "[Removed Lines]",
          "174:         model: \"ibm/granite-13b-chat-v2\",",
          "",
          "[Added Lines]",
          "174:         model: \"ibm/granite-3-8b-instruct\",",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "198:   describe(\"Test generate methods\", () => {",
          "199:     test(\"Basic usage\", async () => {",
          "200:       const model = new WatsonxLLM({",
          "202:         version: \"2024-05-31\",",
          "203:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "204:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "",
          "[Removed Lines]",
          "201:         model: \"ibm/granite-13b-chat-v2\",",
          "",
          "[Added Lines]",
          "201:         model: \"ibm/granite-3-8b-instruct\",",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "214:     test(\"Stop\", async () => {",
          "215:       const model = new WatsonxLLM({",
          "217:         version: \"2024-05-31\",",
          "218:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "219:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "",
          "[Removed Lines]",
          "216:         model: \"ibm/granite-13b-chat-v2\",",
          "",
          "[Added Lines]",
          "216:         model: \"ibm/granite-3-8b-instruct\",",
          "",
          "---------------",
          "--- Hunk 14 ---",
          "[Context before]",
          "221:       });",
          "223:       const res = await model.generate(",
          "225:         {",
          "227:         }",
          "228:       );",
          "230:       expect(",
          "231:         res.generations",
          "232:           .map((generation) => generation.map((item) => item.text))",
          "",
          "[Removed Lines]",
          "224:         [\"Print hello world!\", \"Print hello world hello!\"],",
          "226:           stop: [\"Hello\"],",
          "",
          "[Added Lines]",
          "224:         [",
          "225:           \"Print hello world in JavaScript!!\",",
          "226:           \"Print hello world twice in Python!\",",
          "227:         ],",
          "229:           stop: [\"hello\"],",
          "",
          "---------------",
          "--- Hunk 15 ---",
          "[Context before]",
          "239:       const nrNewTokens = [0, 0, 0];",
          "240:       const completions = [\"\", \"\", \"\"];",
          "241:       const model = new WatsonxLLM({",
          "243:         version: \"2024-05-31\",",
          "244:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "245:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "",
          "[Removed Lines]",
          "242:         model: \"ibm/granite-13b-chat-v2\",",
          "",
          "[Added Lines]",
          "244:         model: \"ibm/granite-3-8b-instruct\",",
          "",
          "---------------",
          "--- Hunk 16 ---",
          "[Context before]",
          "271:     test(\"Prompt value\", async () => {",
          "272:       const model = new WatsonxLLM({",
          "274:         version: \"2024-05-31\",",
          "275:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "276:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "",
          "[Removed Lines]",
          "273:         model: \"ibm/granite-13b-chat-v2\",",
          "",
          "[Added Lines]",
          "275:         model: \"ibm/granite-3-8b-instruct\",",
          "",
          "---------------",
          "--- Hunk 17 ---",
          "[Context before]",
          "290:       let countedTokens = 0;",
          "291:       let streamedText = \"\";",
          "292:       const model = new WatsonxLLM({",
          "294:         version: \"2024-05-31\",",
          "295:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "296:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "",
          "[Removed Lines]",
          "293:         model: \"ibm/granite-13b-chat-v2\",",
          "",
          "[Added Lines]",
          "295:         model: \"ibm/granite-3-8b-instruct\",",
          "",
          "---------------",
          "--- Hunk 18 ---",
          "[Context before]",
          "314:     test(\"Stop\", async () => {",
          "315:       const model = new WatsonxLLM({",
          "317:         version: \"2024-05-31\",",
          "318:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "319:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "320:         maxNewTokens: 100,",
          "321:       });",
          "325:       });",
          "326:       const chunks = [];",
          "327:       for await (const chunk of stream) {",
          "",
          "[Removed Lines]",
          "316:         model: \"ibm/granite-13b-chat-v2\",",
          "323:       const stream = await model.stream(\"Print hello world!\", {",
          "324:         stop: [\"Hello\"],",
          "",
          "[Added Lines]",
          "318:         model: \"ibm/granite-3-8b-instruct\",",
          "325:       const stream = await model.stream(\"Print hello world in JavaScript!\", {",
          "326:         stop: [\"hello\"],",
          "",
          "---------------",
          "--- Hunk 19 ---",
          "[Context before]",
          "333:     test(\"Timeout\", async () => {",
          "334:       const model = new WatsonxLLM({",
          "336:         version: \"2024-05-31\",",
          "337:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "338:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "",
          "[Removed Lines]",
          "335:         model: \"ibm/granite-13b-chat-v2\",",
          "",
          "[Added Lines]",
          "337:         model: \"ibm/granite-3-8b-instruct\",",
          "",
          "---------------",
          "--- Hunk 20 ---",
          "[Context before]",
          "355:     test(\"Signal in call options\", async () => {",
          "356:       const model = new WatsonxLLM({",
          "358:         version: \"2024-05-31\",",
          "359:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "360:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "",
          "[Removed Lines]",
          "357:         model: \"ibm/granite-13b-chat-v2\",",
          "",
          "[Added Lines]",
          "359:         model: \"ibm/granite-3-8b-instruct\",",
          "",
          "---------------",
          "--- Hunk 21 ---",
          "[Context before]",
          "384:   describe(\"Test getNumToken method\", () => {",
          "385:     test(\"Passing correct value\", async () => {",
          "386:       const testProps: WatsonxInputLLM = {",
          "388:         version: \"2024-05-31\",",
          "389:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "390:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "",
          "[Removed Lines]",
          "387:         model: \"ibm/granite-13b-chat-v2\",",
          "",
          "[Added Lines]",
          "389:         model: \"ibm/granite-3-8b-instruct\",",
          "",
          "---------------",
          "--- Hunk 22 ---",
          "[Context before]",
          "403:     test(\"Passing wrong value\", async () => {",
          "404:       const testProps: WatsonxInputLLM = {",
          "406:         version: \"2024-05-31\",",
          "407:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "408:         projectId: process.env.WATSONX_AI_PROJECT_ID,",
          "",
          "[Removed Lines]",
          "405:         model: \"ibm/granite-13b-chat-v2\",",
          "",
          "[Added Lines]",
          "407:         model: \"ibm/granite-3-8b-instruct\",",
          "",
          "---------------",
          "--- Hunk 23 ---",
          "[Context before]",
          "425:     test(\"Single request callback\", async () => {",
          "426:       let callbackFlag = false;",
          "427:       const service = new WatsonxLLM({",
          "429:         version: \"2024-05-31\",",
          "430:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "431:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "",
          "[Removed Lines]",
          "428:         model: \"mistralai/mistral-large\",",
          "",
          "[Added Lines]",
          "430:         model: \"ibm/granite-3-8b-instruct\",",
          "",
          "---------------",
          "--- Hunk 24 ---",
          "[Context before]",
          "445:     test(\"Single response callback\", async () => {",
          "446:       let callbackFlag = false;",
          "447:       const service = new WatsonxLLM({",
          "449:         version: \"2024-05-31\",",
          "450:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "451:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "",
          "[Removed Lines]",
          "448:         model: \"mistralai/mistral-large\",",
          "",
          "[Added Lines]",
          "450:         model: \"ibm/granite-3-8b-instruct\",",
          "",
          "---------------",
          "--- Hunk 25 ---",
          "[Context before]",
          "467:       let callbackFlagReq = false;",
          "468:       let callbackFlagRes = false;",
          "469:       const service = new WatsonxLLM({",
          "471:         version: \"2024-05-31\",",
          "472:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "473:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "",
          "[Removed Lines]",
          "470:         model: \"mistralai/mistral-large\",",
          "",
          "[Added Lines]",
          "472:         model: \"ibm/granite-3-8b-instruct\",",
          "",
          "---------------",
          "--- Hunk 26 ---",
          "[Context before]",
          "495:       let langchainCallback = false;",
          "497:       const service = new WatsonxLLM({",
          "499:         version: \"2024-05-31\",",
          "500:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL ?? \"testString\",",
          "501:         projectId: process.env.WATSONX_AI_PROJECT_ID ?? \"testString\",",
          "",
          "[Removed Lines]",
          "498:         model: \"mistralai/mistral-large\",",
          "",
          "[Added Lines]",
          "500:         model: \"ibm/granite-3-8b-instruct\",",
          "",
          "---------------"
        ],
        "libs/langchain-community/src/llms/tests/ibm.test.ts||libs/langchain-community/src/llms/tests/ibm.test.ts": [
          "File: libs/langchain-community/src/llms/tests/ibm.test.ts -> libs/langchain-community/src/llms/tests/ibm.test.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "3: import WatsonxAiMlVml_v1 from \"@ibm-cloud/watsonx-ai/dist/watsonx-ai-ml/vml_v1.js\";",
          "5: import { authenticateAndSetInstance } from \"../../utils/ibm.js\";",
          "6: import { WatsonxEmbeddings } from \"../../embeddings/ibm.js\";",
          "",
          "[Removed Lines]",
          "4: import { WatsonxLLM, WatsonxInputLLM } from \"../ibm.js\";",
          "",
          "[Added Lines]",
          "4: import { WatsonxLLM, WatsonxInputLLM, WatsonxLLMConstructor } from \"../ibm.js\";",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "14: }",
          "15: export const testProperties = (",
          "16:   instance: WatsonxLLM | WatsonxEmbeddings,",
          "18:   notExTestProps?: { [key: string]: any }",
          "19: ) => {",
          "20:   const checkProperty = <T extends { [key: string]: any }>(",
          "",
          "[Removed Lines]",
          "17:   testProps: WatsonxInputLLM,",
          "",
          "[Added Lines]",
          "17:   testProps: WatsonxLLMConstructor,",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "63:       testProperties(instance, testProps);",
          "64:     });",
          "66:     test(\"Test methods after init\", () => {",
          "67:       const testProps: WatsonxInputLLM = {",
          "68:         model: \"ibm/granite-13b-chat-v2\",",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "66:     test(\"Test basic properties after init\", async () => {",
          "67:       const testProps = {",
          "68:         version: \"2024-05-31\",",
          "69:         serviceUrl: process.env.WATSONX_AI_SERVICE_URL as string,",
          "70:         idOrName: process.env.WATSONX_AI_PROJECT_ID || \"testString\",",
          "71:       };",
          "72:       const instance = new WatsonxLLM({ ...testProps, ...fakeAuthProp });",
          "74:       testProperties(instance, testProps);",
          "75:     });",
          "",
          "---------------"
        ],
        "libs/langchain-community/src/types/ibm.ts||libs/langchain-community/src/types/ibm.ts": [
          "File: libs/langchain-community/src/types/ibm.ts -> libs/langchain-community/src/types/ibm.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "1: export interface TokenUsage {",
          "2:   generated_token_count: number;",
          "3:   input_token_count: number;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: import { RequestCallbacks } from \"@ibm-cloud/watsonx-ai/dist/watsonx-ai-ml/vml_v1.js\";",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "17:   version: string;",
          "18: }",
          "21:   model: string;",
          "22:   spaceId?: string;",
          "23:   projectId?: string;",
          "24:   idOrName?: string;",
          "27: }",
          "29: export interface GenerationInfo {",
          "",
          "[Removed Lines]",
          "20: export interface WatsonxParams extends WatsonxInit {",
          "25:   maxConcurrency?: number;",
          "26:   maxRetries?: number;",
          "",
          "[Added Lines]",
          "22: export interface WatsonxChatBasicOptions {",
          "23:   maxConcurrency?: number;",
          "24:   maxRetries?: number;",
          "25:   streaming?: boolean;",
          "26:   watsonxCallbacks?: RequestCallbacks;",
          "27: }",
          "29: export interface WatsonxParams extends WatsonxInit, WatsonxChatBasicOptions {",
          "33: }",
          "35: export type Neverify<T> = {",
          "36:   [K in keyof T]?: never;",
          "37: };",
          "39: export interface WatsonxDeployedParams",
          "40:   extends WatsonxInit,",
          "41:     WatsonxChatBasicOptions {",
          "",
          "---------------"
        ],
        "libs/langchain-community/src/utils/ibm.ts||libs/langchain-community/src/utils/ibm.ts": [
          "File: libs/langchain-community/src/utils/ibm.ts -> libs/langchain-community/src/utils/ibm.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "184:       const tool = message.tool_calls;",
          "185:       return tool;",
          "186:     });",
          "187:     if (tools[0] === undefined) {",
          "189:     }",
          "190:     const [tool] = tools;",
          "191:     this.latestCorrect = tool;",
          "192:     return tool.args as T;",
          "193:   }",
          "",
          "[Removed Lines]",
          "188:       if (this.latestCorrect) tools.push(this.latestCorrect);",
          "",
          "[Added Lines]",
          "189:       if (this.latestCorrect) {",
          "190:         tools.push(this.latestCorrect);",
          "191:       } else {",
          "192:         const toolCall: ToolCall = { name: \"\", args: {} };",
          "193:         tools.push(toolCall);",
          "194:       }",
          "198:     tool.name = \"\";",
          "",
          "---------------"
        ],
        "yarn.lock||yarn.lock": [
          "File: yarn.lock -> yarn.lock",
          "--- Hunk 1 ---",
          "[Context before]",
          "10669:   languageName: node",
          "10670:   linkType: hard",
          "10675:   dependencies:",
          "10676:     \"@types/node\": ^18.0.0",
          "10677:     extend: 3.0.2",
          "10678:     ibm-cloud-sdk-core: ^5.0.2",
          "10680:   languageName: node",
          "10681:   linkType: hard",
          "",
          "[Removed Lines]",
          "10672: \"@ibm-cloud/watsonx-ai@npm:^1.3.0\":",
          "10673:   version: 1.3.0",
          "10674:   resolution: \"@ibm-cloud/watsonx-ai@npm:1.3.0\"",
          "10679:   checksum: 6a2127391ca70005b942d3c4ab1abc738946c42bbf3ee0f8eb6f778434b5f8806d622f1f36446f00b9fb82dc2c8aea3526426ec46cc53fa8a075ba7a294da096",
          "",
          "[Added Lines]",
          "10672: \"@ibm-cloud/watsonx-ai@npm:^1.4.0\":",
          "10673:   version: 1.4.0",
          "10674:   resolution: \"@ibm-cloud/watsonx-ai@npm:1.4.0\"",
          "10676:     \"@langchain/textsplitters\": ^0.1.0",
          "10680:   checksum: 5250816f9ad93839cf26e3788eeace8155721765c39c65547eff8ebbd5fc8a0dfa107f6e799593f1209f4b3489be24aa674aa92b7ecbc5fc2bd29390a28e84ff",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "11899:     \"@gradientai/nodejs-sdk\": ^1.2.0",
          "11900:     \"@huggingface/inference\": ^2.6.4",
          "11901:     \"@huggingface/transformers\": ^3.2.3",
          "11903:     \"@jest/globals\": ^29.5.0",
          "11904:     \"@lancedb/lancedb\": ^0.13.0",
          "11905:     \"@langchain/core\": \"workspace:*\"",
          "",
          "[Removed Lines]",
          "11902:     \"@ibm-cloud/watsonx-ai\": ^1.3.0",
          "",
          "[Added Lines]",
          "11903:     \"@ibm-cloud/watsonx-ai\": ^1.4.0",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "13237:   languageName: unknown",
          "13238:   linkType: soft",
          "13241:   version: 0.0.0-use.local",
          "13242:   resolution: \"@langchain/textsplitters@workspace:libs/langchain-textsplitters\"",
          "13243:   dependencies:",
          "",
          "[Removed Lines]",
          "13240: \"@langchain/textsplitters@>=0.0.0 <0.2.0, @langchain/textsplitters@workspace:*, @langchain/textsplitters@workspace:libs/langchain-textsplitters\":",
          "",
          "[Added Lines]",
          "13241: \"@langchain/textsplitters@>=0.0.0 <0.2.0, @langchain/textsplitters@^0.1.0, @langchain/textsplitters@workspace:*, @langchain/textsplitters@workspace:libs/langchain-textsplitters\":",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "61b6cbbbf9a37745d12e360208c193ff4ebc0ee0",
      "candidate_info": {
        "commit_hash": "61b6cbbbf9a37745d12e360208c193ff4ebc0ee0",
        "repo": "langchain-ai/langchainjs",
        "commit_url": "https://github.com/langchain-ai/langchainjs/commit/61b6cbbbf9a37745d12e360208c193ff4ebc0ee0",
        "files": [
          "libs/langchain-google-common/package.json",
          "libs/langchain-google-gauth/package.json",
          "libs/langchain-google-vertexai-web/package.json",
          "libs/langchain-google-vertexai/package.json",
          "libs/langchain-google-webauth/package.json",
          "yarn.lock"
        ],
        "message": "release(google-vertex): 0.1.5 (#7410)",
        "before_after_code_files": [
          "yarn.lock||yarn.lock"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "yarn.lock||yarn.lock"
          ],
          "candidate": [
            "yarn.lock||yarn.lock"
          ]
        }
      },
      "candidate_diff": {
        "yarn.lock||yarn.lock": [
          "File: yarn.lock -> yarn.lock",
          "--- Hunk 1 ---",
          "[Context before]",
          "12413:   languageName: unknown",
          "12414:   linkType: soft",
          "12417:   version: 0.0.0-use.local",
          "12418:   resolution: \"@langchain/google-common@workspace:libs/langchain-google-common\"",
          "12419:   dependencies:",
          "",
          "[Removed Lines]",
          "12416: \"@langchain/google-common@^0.1.0, @langchain/google-common@workspace:*, @langchain/google-common@workspace:libs/langchain-google-common, @langchain/google-common@~0.1.4\":",
          "",
          "[Added Lines]",
          "12416: \"@langchain/google-common@^0.1.0, @langchain/google-common@workspace:*, @langchain/google-common@workspace:libs/langchain-google-common, @langchain/google-common@~0.1.5\":",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "12448:   languageName: unknown",
          "12449:   linkType: soft",
          "12452:   version: 0.0.0-use.local",
          "12453:   resolution: \"@langchain/google-gauth@workspace:libs/langchain-google-gauth\"",
          "12454:   dependencies:",
          "12455:     \"@jest/globals\": ^29.5.0",
          "12456:     \"@langchain/core\": \"workspace:*\"",
          "12458:     \"@langchain/scripts\": \">=0.1.0 <0.2.0\"",
          "12459:     \"@swc/core\": ^1.3.90",
          "12460:     \"@swc/jest\": ^0.2.29",
          "",
          "[Removed Lines]",
          "12451: \"@langchain/google-gauth@workspace:libs/langchain-google-gauth, @langchain/google-gauth@~0.1.4\":",
          "12457:     \"@langchain/google-common\": ~0.1.4",
          "",
          "[Added Lines]",
          "12451: \"@langchain/google-gauth@workspace:libs/langchain-google-gauth, @langchain/google-gauth@~0.1.5\":",
          "12457:     \"@langchain/google-common\": ~0.1.5",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "12527:     \"@jest/globals\": ^29.5.0",
          "12528:     \"@langchain/core\": \"workspace:*\"",
          "12529:     \"@langchain/google-common\": ^0.1.0",
          "12531:     \"@langchain/scripts\": \">=0.1.0 <0.2.0\"",
          "12532:     \"@langchain/standard-tests\": 0.0.0",
          "12533:     \"@swc/core\": ^1.3.90",
          "",
          "[Removed Lines]",
          "12530:     \"@langchain/google-webauth\": ~0.1.4",
          "",
          "[Added Lines]",
          "12530:     \"@langchain/google-webauth\": ~0.1.5",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "12563:     \"@jest/globals\": ^29.5.0",
          "12564:     \"@langchain/core\": \"workspace:*\"",
          "12565:     \"@langchain/google-common\": ^0.1.0",
          "12567:     \"@langchain/scripts\": \">=0.1.0 <0.2.0\"",
          "12568:     \"@langchain/standard-tests\": 0.0.0",
          "12569:     \"@swc/core\": ^1.3.90",
          "",
          "[Removed Lines]",
          "12566:     \"@langchain/google-gauth\": ~0.1.4",
          "",
          "[Added Lines]",
          "12566:     \"@langchain/google-gauth\": ~0.1.5",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "12592:   languageName: unknown",
          "12593:   linkType: soft",
          "12596:   version: 0.0.0-use.local",
          "12597:   resolution: \"@langchain/google-webauth@workspace:libs/langchain-google-webauth\"",
          "12598:   dependencies:",
          "12599:     \"@jest/globals\": ^29.5.0",
          "12600:     \"@langchain/core\": \"workspace:*\"",
          "12602:     \"@langchain/scripts\": \">=0.1.0 <0.2.0\"",
          "12603:     \"@swc/core\": ^1.3.90",
          "12604:     \"@swc/jest\": ^0.2.29",
          "",
          "[Removed Lines]",
          "12595: \"@langchain/google-webauth@workspace:libs/langchain-google-webauth, @langchain/google-webauth@~0.1.4\":",
          "12601:     \"@langchain/google-common\": ~0.1.4",
          "",
          "[Added Lines]",
          "12595: \"@langchain/google-webauth@workspace:libs/langchain-google-webauth, @langchain/google-webauth@~0.1.5\":",
          "12601:     \"@langchain/google-common\": ~0.1.5",
          "",
          "---------------"
        ]
      }
    }
  ]
}