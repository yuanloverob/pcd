{
  "cve_id": "CVE-2024-22231",
  "cve_desc": "Syndic cache directory creation is vulnerable to a directory traversal attack in salt project which can lead\u00a0a malicious attacker to create an arbitrary directory on a Salt master.",
  "repo": "saltstack/salt",
  "patch_hash": "e0cdb80b55123f4a024759ffcf2b3f0e0788e7ab",
  "patch_info": {
    "commit_hash": "e0cdb80b55123f4a024759ffcf2b3f0e0788e7ab",
    "repo": "saltstack/salt",
    "commit_url": "https://github.com/saltstack/salt/commit/e0cdb80b55123f4a024759ffcf2b3f0e0788e7ab",
    "files": [
      "salt/fileserver/__init__.py",
      "salt/fileserver/roots.py",
      "salt/master.py",
      "tests/pytests/unit/fileserver/test_roots.py",
      "tests/pytests/unit/test_fileserver.py",
      "tests/pytests/unit/test_master.py",
      "tests/unit/test_fileserver.py"
    ],
    "message": "CVE fix",
    "before_after_code_files": [
      "salt/fileserver/__init__.py||salt/fileserver/__init__.py",
      "salt/fileserver/roots.py||salt/fileserver/roots.py",
      "salt/master.py||salt/master.py",
      "tests/pytests/unit/fileserver/test_roots.py||tests/pytests/unit/fileserver/test_roots.py",
      "tests/pytests/unit/test_fileserver.py||tests/pytests/unit/test_fileserver.py",
      "tests/pytests/unit/test_master.py||tests/pytests/unit/test_master.py",
      "tests/unit/test_fileserver.py||tests/unit/test_fileserver.py"
    ]
  },
  "patch_diff": {
    "salt/fileserver/__init__.py||salt/fileserver/__init__.py": [
      "File: salt/fileserver/__init__.py -> salt/fileserver/__init__.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "568:         saltenv = salt.utils.stringutils.to_unicode(saltenv)",
      "569:         back = self.backends(back)",
      "570:         kwargs = {}",
      "576:         if salt.utils.url.is_escaped(path):",
      "577:             # don't attempt to find URL query arguments in the path",
      "578:             path = salt.utils.url.unescape(path)",
      "",
      "[Removed Lines]",
      "571:         fnd = {\"path\": \"\", \"rel\": \"\"}",
      "572:         if os.path.isabs(path):",
      "573:             return fnd",
      "574:         if \"../\" in path:",
      "575:             return fnd",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "588:                     args = comp.split(\"=\", 1)",
      "589:                     kwargs[args[0]] = args[1]",
      "591:         if \"env\" in kwargs:",
      "592:             # \"env\" is not supported; Use \"saltenv\".",
      "593:             kwargs.pop(\"env\")",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "586:         fnd = {\"path\": \"\", \"rel\": \"\"}",
      "587:         if os.path.isabs(path) or \"../\" in path:",
      "588:             return fnd",
      "",
      "---------------"
    ],
    "salt/fileserver/roots.py||salt/fileserver/roots.py": [
      "File: salt/fileserver/roots.py -> salt/fileserver/roots.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "27: import salt.utils.path",
      "28: import salt.utils.platform",
      "29: import salt.utils.stringutils",
      "30: import salt.utils.versions",
      "32: log = logging.getLogger(__name__)",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "30: import salt.utils.verify",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "98:         if saltenv == \"__env__\":",
      "99:             root = root.replace(\"__env__\", actual_saltenv)",
      "100:         full = os.path.join(root, path)",
      "101:         if os.path.isfile(full) and not salt.fileserver.is_file_ignored(__opts__, full):",
      "102:             fnd[\"path\"] = full",
      "103:             fnd[\"rel\"] = path",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "103:         # Refuse to serve file that is not under the root.",
      "104:         if not salt.utils.verify.clean_path(root, full, subdir=True):",
      "105:             continue",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "128:     ret[\"dest\"] = fnd[\"rel\"]",
      "129:     gzip = load.get(\"gzip\", None)",
      "130:     fpath = os.path.normpath(fnd[\"path\"])",
      "131:     with salt.utils.files.fopen(fpath, \"rb\") as fp_:",
      "132:         fp_.seek(load[\"loc\"])",
      "133:         data = fp_.read(__opts__[\"file_buffer_size\"])",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "138:     actual_saltenv = saltenv = load[\"saltenv\"]",
      "139:     if saltenv not in __opts__[\"file_roots\"]:",
      "140:         if \"__env__\" in __opts__[\"file_roots\"]:",
      "141:             log.debug(",
      "142:                 \"salt environment '%s' maps to __env__ file_roots directory\", saltenv",
      "143:             )",
      "144:             saltenv = \"__env__\"",
      "145:         else:",
      "146:             return fnd",
      "147:     file_in_root = False",
      "148:     for root in __opts__[\"file_roots\"][saltenv]:",
      "149:         if saltenv == \"__env__\":",
      "150:             root = root.replace(\"__env__\", actual_saltenv)",
      "151:         # Refuse to serve file that is not under the root.",
      "152:         if salt.utils.verify.clean_path(root, fpath, subdir=True):",
      "153:             file_in_root = True",
      "154:     if not file_in_root:",
      "155:         return ret",
      "",
      "---------------"
    ],
    "salt/master.py||salt/master.py": [
      "File: salt/master.py -> salt/master.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "1036:         \"\"\"",
      "1037:         key = payload[\"enc\"]",
      "1038:         load = payload[\"load\"]",
      "1040:         raise salt.ext.tornado.gen.Return(ret)",
      "1042:     def _post_stats(self, start, cmd):",
      "",
      "[Removed Lines]",
      "1039:         ret = {\"aes\": self._handle_aes, \"clear\": self._handle_clear}[key](load)",
      "",
      "[Added Lines]",
      "1039:         if key == \"aes\":",
      "1040:             ret = self.handle_aes(load)",
      "1041:         else:",
      "1042:             ret = self.handle_clear(load)",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "1738:                 self.mminion.returners[fstr](load[\"jid\"], load[\"load\"])",
      "1740:             # Register the syndic",
      "1741:             syndic_cache_path = os.path.join(",
      "1742:                 self.opts[\"cachedir\"], \"syndics\", load[\"id\"]",
      "1743:             )",
      "1745:                 path_name = os.path.split(syndic_cache_path)[0]",
      "1746:                 if not os.path.exists(path_name):",
      "1747:                     os.makedirs(path_name)",
      "",
      "[Removed Lines]",
      "1744:             if not os.path.exists(syndic_cache_path):",
      "",
      "[Added Lines]",
      "1745:             # We are creating a path using user suplied input. Use the",
      "1746:             # clean_path to prevent a directory traversal.",
      "1747:             root = os.path.join(self.opts[\"cachedir\"], \"syndics\")",
      "1751:             if salt.utils.verify.clean_path(",
      "1752:                 root, syndic_cache_path",
      "1753:             ) and not os.path.exists(syndic_cache_path):",
      "",
      "---------------"
    ],
    "tests/pytests/unit/fileserver/test_roots.py||tests/pytests/unit/fileserver/test_roots.py": [
      "File: tests/pytests/unit/fileserver/test_roots.py -> tests/pytests/unit/fileserver/test_roots.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "53:     return dirname",
      "56: @pytest.fixture",
      "57: def configure_loader_modules(tmp_state_tree, temp_salt_master):",
      "58:     opts = temp_salt_master.config.copy()",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "56: @pytest.fixture(autouse=True)",
      "57: def testfilepath(tmp_state_tree, testfile):",
      "58:     return tmp_state_tree / testfile.name",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "75:     assert full_path_to_file == ret[\"path\"]",
      "79:     with patch.dict(roots.__opts__, {\"file_buffer_size\": 262144}):",
      "80:         load = {",
      "81:             \"saltenv\": \"base\",",
      "83:             \"loc\": 0,",
      "84:         }",
      "86:         ret = roots.serve_file(load, fnd)",
      "89:             data = fp_.read()",
      "91:         assert ret == {\"data\": data, \"dest\": \"testfile\"}",
      "",
      "[Removed Lines]",
      "78: def test_serve_file(testfile):",
      "82:             \"path\": str(testfile),",
      "85:         fnd = {\"path\": str(testfile), \"rel\": \"testfile\"}",
      "88:         with salt.utils.files.fopen(str(testfile), \"rb\") as fp_:",
      "",
      "[Added Lines]",
      "83: def test_serve_file(testfilepath):",
      "87:             \"path\": str(testfilepath),",
      "90:         fnd = {\"path\": str(testfilepath), \"rel\": \"testfile\"}",
      "93:         with salt.utils.files.fopen(str(testfilepath), \"rb\") as fp_:",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "236:     # between Python releases.",
      "237:     lines_written = sorted(mtime_map_mock.write_calls())",
      "238:     expected = sorted(",
      "240:         for key, val in new_mtime_map.items()",
      "241:     )",
      "242:     assert lines_written == expected, lines_written",
      "",
      "[Removed Lines]",
      "239:         salt.utils.stringutils.to_bytes(\"{key}:{val}\\n\".format(key=key, val=val))",
      "",
      "[Added Lines]",
      "244:         salt.utils.stringutils.to_bytes(f\"{key}:{val}\\n\")",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "277:         },",
      "278:         \"backend\": \"roots\",",
      "279:     }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "287: def test_find_file_not_in_root(tmp_state_tree):",
      "288:     \"\"\"",
      "289:     Fileroots should never 'find' a file that is outside of it's root.",
      "290:     \"\"\"",
      "291:     badfile = pathlib.Path(tmp_state_tree).parent / \"bar\"",
      "292:     badfile.write_text(\"Bad file\")",
      "293:     badpath = f\"../bar\"",
      "294:     ret = roots.find_file(badpath)",
      "295:     assert ret == {\"path\": \"\", \"rel\": \"\"}",
      "296:     badpath = f\"{tmp_state_tree / '..' / 'bar'}\"",
      "297:     ret = roots.find_file(badpath)",
      "298:     assert ret == {\"path\": \"\", \"rel\": \"\"}",
      "301: def test_serve_file_not_in_root(tmp_state_tree):",
      "302:     \"\"\"",
      "303:     Fileroots should never 'serve' a file that is outside of it's root.",
      "304:     \"\"\"",
      "305:     badfile = pathlib.Path(tmp_state_tree).parent / \"bar\"",
      "306:     badfile.write_text(\"Bad file\")",
      "307:     badpath = f\"../bar\"",
      "308:     load = {\"path\": \"salt://|..\\\\bar\", \"saltenv\": \"base\", \"loc\": 0}",
      "309:     fnd = {",
      "310:         \"path\": f\"{tmp_state_tree / '..' / 'bar'}\",",
      "311:         \"rel\": f\"{pathlib.Path('..') / 'bar'}\",",
      "312:     }",
      "313:     ret = roots.serve_file(load, fnd)",
      "314:     assert ret == {\"data\": \"\", \"dest\": \"../bar\"}",
      "",
      "---------------"
    ],
    "tests/pytests/unit/test_fileserver.py||tests/pytests/unit/test_fileserver.py": [
      "File: tests/pytests/unit/test_fileserver.py -> tests/pytests/unit/test_fileserver.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "[No context available]",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "1: \"\"\"",
      "2: \"\"\"",
      "5: import datetime",
      "6: import os",
      "7: import time",
      "9: import salt.fileserver",
      "10: import salt.utils.files",
      "13: def test_diff_with_diffent_keys():",
      "14:     \"\"\"",
      "15:     Test that different maps are indeed reported different",
      "16:     \"\"\"",
      "17:     map1 = {\"file1\": 1234}",
      "18:     map2 = {\"file2\": 1234}",
      "19:     assert salt.fileserver.diff_mtime_map(map1, map2) is True",
      "22: def test_diff_with_diffent_values():",
      "23:     \"\"\"",
      "24:     Test that different maps are indeed reported different",
      "25:     \"\"\"",
      "26:     map1 = {\"file1\": 12345}",
      "27:     map2 = {\"file1\": 1234}",
      "28:     assert salt.fileserver.diff_mtime_map(map1, map2) is True",
      "31: def test_whitelist():",
      "32:     opts = {",
      "33:         \"fileserver_backend\": [\"roots\", \"git\", \"s3fs\", \"hgfs\", \"svn\"],",
      "34:         \"extension_modules\": \"\",",
      "35:     }",
      "36:     fs = salt.fileserver.Fileserver(opts)",
      "37:     assert sorted(fs.servers.whitelist) == sorted(",
      "38:         [\"git\", \"gitfs\", \"hg\", \"hgfs\", \"svn\", \"svnfs\", \"roots\", \"s3fs\"]",
      "39:     ), fs.servers.whitelist",
      "42: def test_future_file_list_cache_file_ignored(tmp_path):",
      "43:     opts = {",
      "44:         \"fileserver_backend\": [\"roots\"],",
      "45:         \"cachedir\": tmp_path,",
      "46:         \"extension_modules\": \"\",",
      "47:     }",
      "49:     back_cachedir = os.path.join(tmp_path, \"file_lists/roots\")",
      "50:     os.makedirs(os.path.join(back_cachedir))",
      "52:     # Touch a couple files",
      "53:     for filename in (\"base.p\", \"foo.txt\"):",
      "54:         with salt.utils.files.fopen(os.path.join(back_cachedir, filename), \"wb\") as _f:",
      "55:             if filename == \"base.p\":",
      "56:                 _f.write(b\"\\x80\")",
      "58:     # Set modification time to file list cache file to 1 year in the future",
      "59:     now = datetime.datetime.utcnow()",
      "60:     future = now + datetime.timedelta(days=365)",
      "61:     mod_time = time.mktime(future.timetuple())",
      "62:     os.utime(os.path.join(back_cachedir, \"base.p\"), (mod_time, mod_time))",
      "64:     list_cache = os.path.join(back_cachedir, \"base.p\")",
      "65:     w_lock = os.path.join(back_cachedir, \".base.w\")",
      "66:     ret = salt.fileserver.check_file_list_cache(opts, \"files\", list_cache, w_lock)",
      "67:     assert (",
      "68:         ret[1] is True",
      "69:     ), \"Cache file list cache file is not refreshed when future modification time\"",
      "72: def test_file_server_url_escape(tmp_path):",
      "73:     (tmp_path / \"srv\").mkdir()",
      "74:     (tmp_path / \"srv\" / \"salt\").mkdir()",
      "75:     (tmp_path / \"foo\").mkdir()",
      "76:     (tmp_path / \"foo\" / \"bar\").write_text(\"Bad file\")",
      "77:     fileroot = str(tmp_path / \"srv\" / \"salt\")",
      "78:     badfile = str(tmp_path / \"foo\" / \"bar\")",
      "79:     opts = {",
      "80:         \"fileserver_backend\": [\"roots\"],",
      "81:         \"extension_modules\": \"\",",
      "82:         \"optimization_order\": [",
      "83:             0,",
      "84:         ],",
      "85:         \"file_roots\": {",
      "86:             \"base\": [fileroot],",
      "87:         },",
      "88:         \"file_ignore_regex\": \"\",",
      "89:         \"file_ignore_glob\": \"\",",
      "90:     }",
      "91:     fs = salt.fileserver.Fileserver(opts)",
      "92:     ret = fs.find_file(",
      "93:         \"salt://|..\\\\..\\\\..\\\\foo/bar\",",
      "94:         \"base\",",
      "95:     )",
      "96:     assert ret == {\"path\": \"\", \"rel\": \"\"}",
      "99: def test_file_server_serve_url_escape(tmp_path):",
      "100:     (tmp_path / \"srv\").mkdir()",
      "101:     (tmp_path / \"srv\" / \"salt\").mkdir()",
      "102:     (tmp_path / \"foo\").mkdir()",
      "103:     (tmp_path / \"foo\" / \"bar\").write_text(\"Bad file\")",
      "104:     fileroot = str(tmp_path / \"srv\" / \"salt\")",
      "105:     badfile = str(tmp_path / \"foo\" / \"bar\")",
      "106:     opts = {",
      "107:         \"fileserver_backend\": [\"roots\"],",
      "108:         \"extension_modules\": \"\",",
      "109:         \"optimization_order\": [",
      "110:             0,",
      "111:         ],",
      "112:         \"file_roots\": {",
      "113:             \"base\": [fileroot],",
      "114:         },",
      "115:         \"file_ignore_regex\": \"\",",
      "116:         \"file_ignore_glob\": \"\",",
      "117:         \"file_buffer_size\": 2048,",
      "118:     }",
      "119:     fs = salt.fileserver.Fileserver(opts)",
      "120:     ret = fs.serve_file(",
      "121:         {",
      "122:             \"path\": \"salt://|..\\\\..\\\\..\\\\foo/bar\",",
      "123:             \"saltenv\": \"base\",",
      "124:             \"loc\": 0,",
      "125:         }",
      "126:     )",
      "127:     assert ret == {\"data\": \"\", \"dest\": \"\"}",
      "",
      "---------------"
    ],
    "tests/pytests/unit/test_master.py||tests/pytests/unit/test_master.py": [
      "File: tests/pytests/unit/test_master.py -> tests/pytests/unit/test_master.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "1: import time",
      "3: import pytest",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "1: import pathlib",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "160:     with patch.object(encrypted_requests, \"_return\", autospec=True) as fake_return:",
      "161:         encrypted_requests._syndic_return(payload)",
      "162:         fake_return.assert_called_with(expected_return)",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "166: def test_syndic_return_cache_dir_creation(encrypted_requests):",
      "167:     \"\"\"master's cachedir for a syndic will be created by AESFuncs._syndic_return method\"\"\"",
      "168:     cachedir = pathlib.Path(encrypted_requests.opts[\"cachedir\"])",
      "169:     assert not (cachedir / \"syndics\").exists()",
      "170:     encrypted_requests._syndic_return(",
      "171:         {",
      "172:             \"id\": \"mamajama\",",
      "173:             \"jid\": \"\",",
      "174:             \"return\": {},",
      "175:         }",
      "176:     )",
      "177:     assert (cachedir / \"syndics\").exists()",
      "178:     assert (cachedir / \"syndics\" / \"mamajama\").exists()",
      "181: def test_syndic_return_cache_dir_creation_traversal(encrypted_requests):",
      "182:     \"\"\"",
      "183:     master's  AESFuncs._syndic_return method cachdir creation is not vulnerable to a directory traversal",
      "184:     \"\"\"",
      "185:     cachedir = pathlib.Path(encrypted_requests.opts[\"cachedir\"])",
      "186:     assert not (cachedir / \"syndics\").exists()",
      "187:     encrypted_requests._syndic_return(",
      "188:         {",
      "189:             \"id\": \"../mamajama\",",
      "190:             \"jid\": \"\",",
      "191:             \"return\": {},",
      "192:         }",
      "193:     )",
      "194:     assert not (cachedir / \"syndics\").exists()",
      "195:     assert not (cachedir / \"mamajama\").exists()",
      "",
      "---------------"
    ],
    "tests/unit/test_fileserver.py||tests/unit/test_fileserver.py": [
      "File: tests/unit/test_fileserver.py -> tests/unit/test_fileserver.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "[No context available]",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "287de2b898c8b622b4eb01e05754f6b43fe099cc",
      "candidate_info": {
        "commit_hash": "287de2b898c8b622b4eb01e05754f6b43fe099cc",
        "repo": "saltstack/salt",
        "commit_url": "https://github.com/saltstack/salt/commit/287de2b898c8b622b4eb01e05754f6b43fe099cc",
        "files": [
          "pytest.ini",
          "tests/pytests/unit/utils/test_aws.py"
        ],
        "message": "Timeout the tests instead of just hanging indefinitely\n\nSigned-off-by: Pedro Algarvio <palgarvio@vmware.com>",
        "before_after_code_files": [
          "tests/pytests/unit/utils/test_aws.py||tests/pytests/unit/utils/test_aws.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/saltstack/salt/pull/65969"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "tests/pytests/unit/utils/test_aws.py||tests/pytests/unit/utils/test_aws.py": [
          "File: tests/pytests/unit/utils/test_aws.py -> tests/pytests/unit/utils/test_aws.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "16: from tests.support.helpers import patched_environ",
          "17: from tests.support.mock import MagicMock, patch",
          "20: @pytest.fixture(autouse=True)",
          "21: def _cleanup():",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19: pytestmark = [",
          "20:     # Skip testing on windows since it does not support signals",
          "21:     # which is what the timeout marker is using.",
          "22:     pytest.mark.skip_on_windows,",
          "23:     pytest.mark.timeout(60, method=\"signal\"),",
          "24: ]",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "8244df032540dbd5258806beb92b530843b99476",
      "candidate_info": {
        "commit_hash": "8244df032540dbd5258806beb92b530843b99476",
        "repo": "saltstack/salt",
        "commit_url": "https://github.com/saltstack/salt/commit/8244df032540dbd5258806beb92b530843b99476",
        "files": [
          ".github/workflows/ci.yml",
          ".github/workflows/nightly.yml",
          ".github/workflows/scheduled.yml",
          ".github/workflows/staging.yml",
          ".github/workflows/templates/layout.yml.jinja",
          ".github/workflows/templates/nightly.yml.jinja",
          ".github/workflows/templates/scheduled.yml.jinja",
          ".github/workflows/templates/staging.yml.jinja",
          ".github/workflows/templates/test-package-downloads-action.yml.jinja",
          ".github/workflows/templates/test-salt-pkg.yml.jinja",
          ".github/workflows/templates/test-salt.yml.jinja",
          ".github/workflows/test-action-linux.yml",
          ".github/workflows/test-action-macos.yml",
          ".github/workflows/test-action-windows.yml",
          ".github/workflows/test-package-downloads-action.yml",
          ".github/workflows/test-packages-action-linux.yml",
          ".github/workflows/test-packages-action-macos.yml",
          ".github/workflows/test-packages-action-windows.yml"
        ],
        "message": "Reduce the amount of annotations on workflows. Suggested by GitHub.\n\nSince our bigger builds always throw 500's by GitHub. We have to refresh\na few times before being able to see the workflow.\n\nSigned-off-by: Pedro Algarvio <palgarvio@vmware.com>",
        "before_after_code_files": [
          ".github/workflows/templates/layout.yml.jinja||.githuworkflows/templates/layout.yml.jinja",
          ".github/workflows/templates/nightly.yml.jinja||.githuworkflows/templates/nightly.yml.jinja",
          ".github/workflows/templates/scheduled.yml.jinja||.githuworkflows/templates/scheduled.yml.jinja",
          ".github/workflows/templates/staging.yml.jinja||.githuworkflows/templates/staging.yml.jinja",
          ".github/workflows/templates/test-package-downloads-action.yml.jinja||.githuworkflows/templates/test-package-downloads-action.yml.jinja",
          ".github/workflows/templates/test-salt-pkg.yml.jinja||.githuworkflows/templates/test-salt-pkg.yml.jinja",
          ".github/workflows/templates/test-salt.yml.jinja||.githuworkflows/templates/test-salt.yml.jinja"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/saltstack/salt/pull/65969"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        ".github/workflows/templates/layout.yml.jinja||.githuworkflows/templates/layout.yml.jinja": [
          "File: .github/workflows/templates/layout.yml.jinja -> .githuworkflows/templates/layout.yml.jinja",
          "--- Hunk 1 ---",
          "[Context before]",
          "6: <%- set prepare_workflow_skip_pkg_download_test_suite = prepare_workflow_skip_pkg_download_test_suite|default(\"\") %>",
          "7: <%- set prepare_workflow_salt_version_input = prepare_workflow_salt_version_input|default(\"\") %>",
          "8: <%- set skip_test_coverage_check = skip_test_coverage_check|default(\"${{ fromJSON(needs.prepare-workflow.outputs.testrun)['skip_code_coverage'] }}\") %>",
          "10: <%- set gpg_key_id = \"64CBBC8173D76B3F\" %>",
          "11: <%- set prepare_actual_release = prepare_actual_release | default(False) %>",
          "12: <%- set gh_actions_workflows_python_version = \"3.10\" %>",
          "",
          "[Removed Lines]",
          "9: <%- set skip_junit_reports_check = skip_junit_reports_check|default(\"${{ github.event_name == 'pull_request' }}\") %>",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        ".github/workflows/templates/nightly.yml.jinja||.githuworkflows/templates/nightly.yml.jinja": [
          "File: .github/workflows/templates/nightly.yml.jinja -> .githuworkflows/templates/nightly.yml.jinja",
          "--- Hunk 1 ---",
          "[Context before]",
          "1: <%- set gh_environment = gh_environment|default(\"nightly\") %>",
          "2: <%- set skip_test_coverage_check = skip_test_coverage_check|default(\"false\") %>",
          "4: <%- set prepare_workflow_skip_test_suite = \"${{ inputs.skip-salt-test-suite && ' --skip-tests' || '' }}\" %>",
          "5: <%- set prepare_workflow_skip_pkg_test_suite = \"${{ inputs.skip-salt-pkg-test-suite && ' --skip-pkg-tests' || '' }}\" %>",
          "6: <%- set prepare_workflow_if_check = prepare_workflow_if_check|default(\"${{ fromJSON(needs.workflow-requirements.outputs.requirements-met) }}\") %>",
          "",
          "[Removed Lines]",
          "3: <%- set skip_junit_reports_check = skip_junit_reports_check|default(\"false\") %>",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        ".github/workflows/templates/scheduled.yml.jinja||.githuworkflows/templates/scheduled.yml.jinja": [
          "File: .github/workflows/templates/scheduled.yml.jinja -> .githuworkflows/templates/scheduled.yml.jinja",
          "--- Hunk 1 ---",
          "[Context before]",
          "1: <%- set prepare_workflow_if_check = \"${{ fromJSON(needs.workflow-requirements.outputs.requirements-met) }}\" %>",
          "2: <%- set skip_test_coverage_check = \"false\" %>",
          "4: <%- extends 'ci.yml.jinja' %>",
          "",
          "[Removed Lines]",
          "3: <%- set skip_junit_reports_check = \"false\" %>",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        ".github/workflows/templates/staging.yml.jinja||.githuworkflows/templates/staging.yml.jinja": [
          "File: .github/workflows/templates/staging.yml.jinja -> .githuworkflows/templates/staging.yml.jinja",
          "--- Hunk 1 ---",
          "[Context before]",
          "6: <%- set gh_environment = \"staging\" %>",
          "7: <%- set prepare_actual_release = True %>",
          "8: <%- set skip_test_coverage_check = \"true\" %>",
          "10: <%- extends 'nightly.yml.jinja' %>",
          "12: <%- block name %>",
          "",
          "[Removed Lines]",
          "9: <%- set skip_junit_reports_check = \"true\" %>",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        ".github/workflows/templates/test-package-downloads-action.yml.jinja||.githuworkflows/templates/test-package-downloads-action.yml.jinja": [
          "File: .github/workflows/templates/test-package-downloads-action.yml.jinja -> .githuworkflows/templates/test-package-downloads-action.yml.jinja",
          "--- Hunk 1 ---",
          "[Context before]",
          "282:             !artifacts/salt/*",
          "283:             !artifacts/salt-*.tar.*",
          "295:   macos:",
          "296:     name: MacOS",
          "",
          "[Removed Lines]",
          "285:       - name: Publish Test Report",
          "286:         uses: mikepenz/action-junit-report@v3",
          "287:         # always run even if the previous steps fails",
          "288:         if: always() && job.status != 'cancelled' && steps.download-artifacts-from-vm.outcome == 'success'",
          "289:         with:",
          "290:           check_name: Overall Test Results(${{ matrix.distro-slug }} ${{ matrix.arch }})",
          "291:           report_paths: 'artifacts/xml-unittests-output/*.xml'",
          "292:           annotate_only: true",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "500:             !artifacts/salt/*",
          "501:             !artifacts/salt-*.tar.*",
          "513:   windows:",
          "514:     name: Windows",
          "",
          "[Removed Lines]",
          "503:       - name: Publish Test Report",
          "504:         uses: mikepenz/action-junit-report@v3",
          "505:         # always run even if the previous steps fails",
          "506:         if: always() && job.status != 'cancelled'",
          "507:         with:",
          "508:           check_name: Overall Test Results(${{ matrix.distro-slug }} ${{ matrix.arch }})",
          "509:           report_paths: 'artifacts/xml-unittests-output/*.xml'",
          "510:           annotate_only: true",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "728:             artifacts",
          "729:             !artifacts/salt/*",
          "730:             !artifacts/salt-*.tar.*",
          "",
          "[Removed Lines]",
          "732:       - name: Publish Test Report",
          "733:         uses: mikepenz/action-junit-report@v3",
          "734:         # always run even if the previous steps fails",
          "735:         if: always() && job.status != 'cancelled' && steps.download-artifacts-from-vm.outcome == 'success'",
          "736:         with:",
          "737:           check_name: Overall Test Results(${{ matrix.distro-slug }} ${{ matrix.arch }} ${{ matrix.pkg-type }} )",
          "738:           report_paths: 'artifacts/xml-unittests-output/*.xml'",
          "739:           annotate_only: true",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        ".github/workflows/templates/test-salt-pkg.yml.jinja||.githuworkflows/templates/test-salt-pkg.yml.jinja": [
          "File: .github/workflows/templates/test-salt-pkg.yml.jinja -> .githuworkflows/templates/test-salt-pkg.yml.jinja",
          "--- Hunk 1 ---",
          "[Context before]",
          "21:       python-version: \"<{ gh_actions_workflows_python_version }>\"",
          "22:       cache-prefix: ${{ needs.prepare-workflow.outputs.cache-seed }}|<{ python_version }>",
          "23:       skip-code-coverage: <{ skip_test_coverage_check }>",
          "25:       testing-releases: ${{ needs.prepare-workflow.outputs.testing-releases }}",
          "26:       nox-archive-hash: \"${{ needs.prepare-workflow.outputs.nox-archive-hash }}\"",
          "27:     <%- if fips == \"fips\" %>",
          "",
          "[Removed Lines]",
          "24:       skip-junit-reports: <{ skip_junit_reports_check }>",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "55:       python-version: \"<{ gh_actions_workflows_python_version }>\"",
          "56:       cache-prefix: ${{ needs.prepare-workflow.outputs.cache-seed }}|<{ python_version }>",
          "57:       skip-code-coverage: <{ skip_test_coverage_check }>",
          "59:       testing-releases: ${{ needs.prepare-workflow.outputs.testing-releases }}",
          "60:       nox-archive-hash: \"${{ needs.prepare-workflow.outputs.nox-archive-hash }}\"",
          "",
          "[Removed Lines]",
          "58:       skip-junit-reports: <{ skip_junit_reports_check }>",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "86:       python-version: \"<{ gh_actions_workflows_python_version }>\"",
          "87:       cache-prefix: ${{ needs.prepare-workflow.outputs.cache-seed }}|<{ python_version }>",
          "88:       skip-code-coverage: <{ skip_test_coverage_check }>",
          "90:       testing-releases: ${{ needs.prepare-workflow.outputs.testing-releases }}",
          "91:       nox-archive-hash: \"${{ needs.prepare-workflow.outputs.nox-archive-hash }}\"",
          "",
          "[Removed Lines]",
          "89:       skip-junit-reports: <{ skip_junit_reports_check }>",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        ".github/workflows/templates/test-salt.yml.jinja||.githuworkflows/templates/test-salt.yml.jinja": [
          "File: .github/workflows/templates/test-salt.yml.jinja -> .githuworkflows/templates/test-salt.yml.jinja",
          "--- Hunk 1 ---",
          "[Context before]",
          "25:       salt-version: \"${{ needs.prepare-workflow.outputs.salt-version }}\"",
          "26:       cache-prefix: ${{ needs.prepare-workflow.outputs.cache-seed }}|<{ python_version }>",
          "27:       skip-code-coverage: <{ skip_test_coverage_check }>",
          "29:       workflow-slug: <{ workflow_slug }>",
          "30:       default-timeout: <{ timeout_value }>",
          "31:       nox-archive-hash: \"${{ needs.prepare-workflow.outputs.nox-archive-hash }}\"",
          "",
          "[Removed Lines]",
          "28:       skip-junit-reports: <{ skip_junit_reports_check }>",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "54:       salt-version: \"${{ needs.prepare-workflow.outputs.salt-version }}\"",
          "55:       cache-prefix: ${{ needs.prepare-workflow.outputs.cache-seed }}|<{ python_version }>",
          "56:       skip-code-coverage: <{ skip_test_coverage_check }>",
          "58:       workflow-slug: <{ workflow_slug }>",
          "59:       default-timeout: <{ timeout_value }>",
          "60:       nox-archive-hash: \"${{ needs.prepare-workflow.outputs.nox-archive-hash }}\"",
          "",
          "[Removed Lines]",
          "57:       skip-junit-reports: <{ skip_junit_reports_check }>",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "82:       salt-version: \"${{ needs.prepare-workflow.outputs.salt-version }}\"",
          "83:       cache-prefix: ${{ needs.prepare-workflow.outputs.cache-seed }}|<{ python_version }>",
          "84:       skip-code-coverage: <{ skip_test_coverage_check }>",
          "86:       workflow-slug: <{ workflow_slug }>",
          "87:       default-timeout: <{ timeout_value }>",
          "88:       nox-archive-hash: \"${{ needs.prepare-workflow.outputs.nox-archive-hash }}\"",
          "",
          "[Removed Lines]",
          "85:       skip-junit-reports: <{ skip_junit_reports_check }>",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "02f0daab696d2b7f1466b21e137b559e1aa36d0f",
      "candidate_info": {
        "commit_hash": "02f0daab696d2b7f1466b21e137b559e1aa36d0f",
        "repo": "saltstack/salt",
        "commit_url": "https://github.com/saltstack/salt/commit/02f0daab696d2b7f1466b21e137b559e1aa36d0f",
        "files": [
          ".github/workflows/nightly.yml",
          ".github/workflows/staging.yml",
          "tools/precommit/workflows.py"
        ],
        "message": "Programmatically discover which OS versions to build repos\n\nSigned-off-by: Pedro Algarvio <palgarvio@vmware.com>",
        "before_after_code_files": [
          "tools/precommit/workflows.py||tools/precommit/workflows.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/saltstack/salt/pull/65969"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "tools/precommit/workflows.py||tools/precommit/workflows.py": [
          "File: tools/precommit/workflows.py -> tools/precommit/workflows.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "253:             test_salt_pkg_downloads_needs_slugs.add(\"build-ci-deps\")",
          "255:     build_rpms_listing = []",
          "263:             for arch in (\"x86_64\", \"arm64\", \"aarch64\"):",
          "264:                 build_rpms_listing.append((distro, release, arch))",
          "266:     build_debs_listing = []",
          "275:     env = Environment(",
          "276:         block_start_string=\"<%\",",
          "",
          "[Removed Lines]",
          "256:     for distro, releases in (",
          "257:         (\"amazon\", (\"2\", \"2023\")),",
          "258:         (\"redhat\", (\"7\", \"8\", \"9\")),",
          "259:         (\"fedora\", (\"36\", \"37\", \"38\")),",
          "260:         (\"photon\", (\"3\", \"4\", \"5\")),",
          "261:     ):",
          "262:         for release in releases:",
          "267:     for distro, releases in (",
          "268:         (\"debian\", (\"10\", \"11\", \"12\")),",
          "269:         (\"ubuntu\", (\"20.04\", \"22.04\")),",
          "270:     ):",
          "271:         for release in releases:",
          "272:             for arch in (\"x86_64\", \"arm64\"):",
          "273:                 build_debs_listing.append((distro, release, arch))",
          "",
          "[Added Lines]",
          "256:     rpm_os_versions: dict[str, list[str]] = {",
          "257:         \"amazon\": [],",
          "258:         \"fedora\": [],",
          "259:         \"photon\": [],",
          "260:         \"redhat\": [],",
          "261:     }",
          "262:     for slug in sorted(AMIS):",
          "263:         if slug.endswith(\"-arm64\"):",
          "264:             continue",
          "265:         if not slug.startswith(",
          "266:             (\"amazonlinux\", \"almalinux\", \"centos\", \"fedora\", \"photonos\")",
          "267:         ):",
          "268:             continue",
          "269:         os_name, os_version = slug.split(\"-\")",
          "270:         if os_name == \"amazonlinux\":",
          "271:             rpm_os_versions[\"amazon\"].append(os_version)",
          "272:         elif os_name == \"photonos\":",
          "273:             rpm_os_versions[\"photon\"].append(os_version)",
          "274:         elif os_name == \"fedora\":",
          "275:             rpm_os_versions[\"fedora\"].append(os_version)",
          "276:         else:",
          "277:             rpm_os_versions[\"redhat\"].append(os_version)",
          "279:     for distro, releases in sorted(rpm_os_versions.items()):",
          "280:         for release in sorted(set(releases)):",
          "285:     for slug in sorted(AMIS):",
          "286:         if not slug.startswith((\"debian-\", \"ubuntu-\")):",
          "287:             continue",
          "288:         if slug.endswith(\"-arm64\"):",
          "289:             continue",
          "290:         os_name, os_version = slug.split(\"-\")",
          "291:         for arch in (\"x86_64\", \"arm64\"):",
          "292:             build_debs_listing.append((os_name, os_version, arch))",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "10a54bcd311580b39ea01b5c997f3b385e9ecc6b",
      "candidate_info": {
        "commit_hash": "10a54bcd311580b39ea01b5c997f3b385e9ecc6b",
        "repo": "saltstack/salt",
        "commit_url": "https://github.com/saltstack/salt/commit/10a54bcd311580b39ea01b5c997f3b385e9ecc6b",
        "files": [
          ".github/workflows/ci.yml",
          ".github/workflows/nightly.yml",
          ".github/workflows/release.yml",
          ".github/workflows/scheduled.yml",
          ".github/workflows/staging.yml",
          ".github/workflows/templates/layout.yml.jinja",
          ".github/workflows/templates/release.yml.jinja",
          "pkg/common/env-cleanup-rules.yml",
          "tools/pkg/__init__.py"
        ],
        "message": "Allow excluding paths when cleaning up archives\n\nSigned-off-by: Pedro Algarvio <palgarvio@vmware.com>",
        "before_after_code_files": [
          ".github/workflows/templates/layout.yml.jinja||.githuworkflows/templates/layout.yml.jinja",
          ".github/workflows/templates/release.yml.jinja||.githuworkflows/templates/release.yml.jinja",
          "tools/pkg/__init__.py||tools/pkg/__init__.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/saltstack/salt/pull/65969"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        ".github/workflows/templates/layout.yml.jinja||.githuworkflows/templates/layout.yml.jinja": [
          "File: .github/workflows/templates/layout.yml.jinja -> .githuworkflows/templates/layout.yml.jinja",
          "--- Hunk 1 ---",
          "[Context before]",
          "9: <%- set gpg_key_id = \"64CBBC8173D76B3F\" %>",
          "10: <%- set prepare_actual_release = prepare_actual_release | default(False) %>",
          "11: <%- set gh_actions_workflows_python_version = \"3.10\" %>",
          "12: ---",
          "13: <%- block name %>",
          "14: name: <{ workflow_name }>",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "215:       - name: Get Hash For Nox Tarball Cache",
          "216:         id: nox-archive-hash",
          "217:         run: |",
          "220:       <%- if prepare_actual_release %>",
          "",
          "[Removed Lines]",
          "218:           echo \"nox-archive-hash=${{ hashFiles('requirements/**/*.txt', 'cicd/golden-images.json', 'noxfile.py') }}\" | tee -a \"$GITHUB_OUTPUT\"",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        ".github/workflows/templates/release.yml.jinja||.githuworkflows/templates/release.yml.jinja": [
          "File: .github/workflows/templates/release.yml.jinja -> .githuworkflows/templates/release.yml.jinja",
          "--- Hunk 1 ---",
          "[Context before]",
          "143:       - name: Get Hash For Nox Tarball Cache",
          "144:         id: nox-archive-hash",
          "145:         run: |",
          "148:   <%- endblock prepare_workflow_job %>",
          "149:   <%- endif %>",
          "",
          "[Removed Lines]",
          "146:           echo \"nox-archive-hash=${{ hashFiles('requirements/**/*.txt', 'cicd/golden-images.json', 'noxfile.py') }}\" | tee -a \"$GITHUB_OUTPUT\"",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "tools/pkg/__init__.py||tools/pkg/__init__.py": [
          "File: tools/pkg/__init__.py -> tools/pkg/__init__.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "257:         else:",
          "258:             yield patterns",
          "260:     dir_patterns = set()",
          "261:     for pattern in unnest_lists(patterns[\"dir_patterns\"]):",
          "262:         dir_patterns.add(pattern)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "260:     exclude_patterns = set()",
          "261:     for pattern in unnest_lists(patterns[\"exclude_patterns\"]):",
          "262:         exclude_patterns.add(pattern)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "271:             if not path.exists():",
          "272:                 continue",
          "273:             match_path = path.as_posix()",
          "274:             for pattern in dir_patterns:",
          "275:                 if fnmatch.fnmatch(str(match_path), pattern):",
          "276:                     ctx.info(",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "278:             skip_match = False",
          "279:             for pattern in exclude_patterns:",
          "280:                 if fnmatch.fnmatch(str(match_path), pattern):",
          "281:                     ctx.info(",
          "282:                         f\"Excluded file: {match_path}; Matching pattern: {pattern!r}\"",
          "283:                     )",
          "284:                     skip_match = True",
          "285:                     break",
          "286:             if skip_match:",
          "287:                 continue",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "283:             if not path.exists():",
          "284:                 continue",
          "285:             match_path = path.as_posix()",
          "286:             for pattern in file_patterns:",
          "287:                 if fnmatch.fnmatch(str(match_path), pattern):",
          "288:                     ctx.info(",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "300:             skip_match = False",
          "301:             for pattern in exclude_patterns:",
          "302:                 if fnmatch.fnmatch(str(match_path), pattern):",
          "303:                     ctx.info(",
          "304:                         f\"Excluded file: {match_path}; Matching pattern: {pattern!r}\"",
          "305:                     )",
          "306:                     skip_match = True",
          "307:                     break",
          "308:             if skip_match:",
          "309:                 continue",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "8c5b8518df5f21e16eda69e78e33d517df7cf48d",
      "candidate_info": {
        "commit_hash": "8c5b8518df5f21e16eda69e78e33d517df7cf48d",
        "repo": "saltstack/salt",
        "commit_url": "https://github.com/saltstack/salt/commit/8c5b8518df5f21e16eda69e78e33d517df7cf48d",
        "files": [
          "tools/release.py"
        ],
        "message": "Fix onedir download step",
        "before_after_code_files": [
          "tools/release.py||tools/release.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/saltstack/salt/pull/65969"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "tools/release.py||tools/release.py": [
          "File: tools/release.py -> tools/release.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "133:     s3 = boto3.client(\"s3\")",
          "134:     if platform == \"darwin\":",
          "135:         platform = \"macos\"",
          "138:     arch = arch.lower()",
          "139:     platform = platform.lower()",
          "140:     if platform in (\"linux\", \"macos\") and arch not in (\"x86_64\", \"aarch64\"):",
          "",
          "[Removed Lines]",
          "136:     if arch == \"arm64\":",
          "137:         arch = \"aarch64\"",
          "",
          "[Added Lines]",
          "136:     if arch == \"aarch64\":",
          "137:         arch = \"arm64\"",
          "",
          "---------------"
        ]
      }
    }
  ]
}