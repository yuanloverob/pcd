{
  "cve_id": "CVE-2021-45456",
  "cve_desc": "Apache kylin checks the legitimacy of the project before executing some commands with the project name passed in by the user. There is a mismatch between what is being checked and what is being used as the shell command argument in DiagnosisService. This may cause an illegal project name to pass the check and perform the following steps, resulting in a command injection vulnerability. This issue affects Apache Kylin 4.0.0.",
  "repo": "apache/kylin",
  "patch_hash": "f4daf14dde99b934c92ce2c832509f24342bc845",
  "patch_info": {
    "commit_hash": "f4daf14dde99b934c92ce2c832509f24342bc845",
    "repo": "apache/kylin",
    "commit_url": "https://github.com/apache/kylin/commit/f4daf14dde99b934c92ce2c832509f24342bc845",
    "files": [
      "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
      "core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java",
      "core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java",
      "server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java",
      "server/src/main/webapp/WEB-INF/web.xml"
    ],
    "message": "test fix",
    "before_after_code_files": [
      "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
      "core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java||core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java",
      "core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java||core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java",
      "server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java||server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java"
    ]
  },
  "patch_diff": {
    "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java": [
      "File: core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java -> core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "3403:     public String getKerberosPrincipal() {",
      "3404:         return getOptional(\"kylin.kerberos.principal\");",
      "3405:     }",
      "3406: }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "3407:     public String getEncryptCipherIvSpec() {",
      "3408:         return getOptional(\"kylin.security.encrypt.cipher.ivSpec\", \"AAAAAAAAAAAAAAAA\");",
      "3409:     }",
      "",
      "---------------"
    ],
    "core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java||core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java": [
      "File: core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java -> core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "25: import java.security.NoSuchAlgorithmException;",
      "27: import org.apache.commons.codec.binary.Base64;",
      "29: import javax.crypto.Cipher;",
      "30: import javax.crypto.NoSuchPaddingException;",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "28: import org.apache.kylin.common.KylinConfig;",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "42:             InvalidKeyException, NoSuchPaddingException, NoSuchAlgorithmException, UnsupportedEncodingException {",
      "43:         Cipher cipher = Cipher.getInstance(\"AES/CFB/PKCS5Padding\");",
      "44:         final SecretKeySpec secretKey = new SecretKeySpec(key, \"AES\");",
      "46:         cipher.init(cipherMode, secretKey, ivSpec);",
      "47:         return cipher;",
      "48:     }",
      "",
      "[Removed Lines]",
      "45:         IvParameterSpec ivSpec = new IvParameterSpec(\"AAAAAAAAAAAAAAAA\".getBytes(\"UTF-8\"));",
      "",
      "[Added Lines]",
      "46:         IvParameterSpec ivSpec = new IvParameterSpec(KylinConfig.getInstanceFromEnv().getEncryptCipherIvSpec().getBytes(\"UTF-8\"));",
      "",
      "---------------"
    ],
    "core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java||core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java": [
      "File: core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java -> core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "19: package org.apache.kylin.common.util;",
      "21: import org.junit.Assert;",
      "22: import org.junit.Test;",
      "26:     @Test",
      "27:     public void testAESEncrypt(){",
      "",
      "[Removed Lines]",
      "24: public class EncryptUtilTest {",
      "",
      "[Added Lines]",
      "21: import org.junit.After;",
      "23: import org.junit.Before;",
      "26: public class EncryptUtilTest extends LocalFileMetadataTestCase {",
      "27:     @Before",
      "28:     public void setUp() throws Exception {",
      "29:         this.createTestMetadata();",
      "30:     }",
      "32:     @After",
      "33:     public void after() throws Exception {",
      "34:         this.cleanupTestMetadata();",
      "35:     }",
      "",
      "---------------"
    ],
    "server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java||server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java": [
      "File: server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java -> server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "87:     public String dumpProjectDiagnosisInfo(String project, File exportPath) throws IOException {",
      "88:         Message msg = MsgPicker.getMsg();",
      "89:         ProjectInstance projectInstance =",
      "90:                 ProjectManager.getInstance(KylinConfig.getInstanceFromEnv())",
      "92:         if (null == projectInstance) {",
      "93:             throw new BadRequestException(",
      "95:         }",
      "96:         aclEvaluate.checkProjectOperationPermission(projectInstance);",
      "98:         runDiagnosisCLI(args);",
      "99:         return getDiagnosisPackageName(exportPath);",
      "100:     }",
      "",
      "[Removed Lines]",
      "91:                         .getProject(ValidateUtil.convertStringToBeAlphanumericUnderscore(project));",
      "94:                     String.format(Locale.ROOT, msg.getDIAG_PROJECT_NOT_FOUND(), project));",
      "97:         String[] args = { project, exportPath.getAbsolutePath() };",
      "",
      "[Added Lines]",
      "89:         String projectName = ValidateUtil.convertStringToBeAlphanumericUnderscore(project);",
      "92:                         .getProject(projectName);",
      "95:                     String.format(Locale.ROOT, msg.getDIAG_PROJECT_NOT_FOUND(), projectName));",
      "98:         String[] args = { projectName, exportPath.getAbsolutePath() };",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "7fa1b9d8d1651198d23c177f4aa1b41fbb1536ca",
      "candidate_info": {
        "commit_hash": "7fa1b9d8d1651198d23c177f4aa1b41fbb1536ca",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/7fa1b9d8d1651198d23c177f4aa1b41fbb1536ca",
        "files": [
          "webapp/app/js/model/cubeConfig.js"
        ],
        "message": "Remove EXTENDE_COLUMN measure from web ui",
        "before_after_code_files": [
          "webapp/app/js/model/cubeConfig.js||webapp/app/js/model/cubeConfig.js"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "webapp/app/js/model/cubeConfig.js||webapp/app/js/model/cubeConfig.js": [
          "File: webapp/app/js/model/cubeConfig.js -> webapp/app/js/model/cubeConfig.js",
          "--- Hunk 1 ---",
          "[Context before]",
          "22:   measureParamType: ['column', 'constant'],",
          "24:   dimensionDataTypes: [\"string\", \"tinyint\", \"int\", \"bigint\", \"date\"],",
          "25:   cubePartitionTypes: ['APPEND'],",
          "26:   engineType:[",
          "",
          "[Removed Lines]",
          "23:   measureExpressions: ['SUM', 'MIN', 'MAX', 'COUNT', 'COUNT_DISTINCT',\"TOP_N\", 'RAW','EXTENDED_COLUMN','PERCENTILE'],",
          "",
          "[Added Lines]",
          "23:   measureExpressions: ['SUM', 'MIN', 'MAX', 'COUNT', 'COUNT_DISTINCT',\"TOP_N\", 'RAW','PERCENTILE'],",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "e6ca98d9e047efee4e6505e55f5aca573c9c0052",
      "candidate_info": {
        "commit_hash": "e6ca98d9e047efee4e6505e55f5aca573c9c0052",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/e6ca98d9e047efee4e6505e55f5aca573c9c0052",
        "files": [
          "tool/src/main/java/org/apache/kylin/tool/CubeMigrationCLI.java"
        ],
        "message": "KYLIN-4923 CubeMigration Tools support migrate meta from 2.x/3.x cluster to 4.0 cluster",
        "before_after_code_files": [
          "tool/src/main/java/org/apache/kylin/tool/CubeMigrationCLI.java||tool/src/main/java/org/apache/kylin/tool/CubeMigrationCLI.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "tool/src/main/java/org/apache/kylin/tool/CubeMigrationCLI.java||tool/src/main/java/org/apache/kylin/tool/CubeMigrationCLI.java": [
          "File: tool/src/main/java/org/apache/kylin/tool/CubeMigrationCLI.java -> tool/src/main/java/org/apache/kylin/tool/CubeMigrationCLI.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: package org.apache.kylin.tool;",
          "21: import java.io.File;",
          "22: import java.io.IOException;",
          "23: import java.util.ArrayList;",
          "24: import java.util.HashMap;",
          "25: import java.util.HashSet;",
          "26: import java.util.List;",
          "27: import java.util.Map;",
          "28: import java.util.Set;",
          "30: import org.apache.commons.cli.Options;",
          "31: import org.apache.hadoop.conf.Configuration;",
          "32: import org.apache.hadoop.fs.FileSystem;",
          "33: import org.apache.hadoop.fs.FileUtil;",
          "34: import org.apache.hadoop.fs.Path;",
          "35: import org.apache.kylin.common.KylinConfig;",
          "36: import org.apache.kylin.common.StorageURL;",
          "37: import org.apache.kylin.common.persistence.JsonSerializer;",
          "38: import org.apache.kylin.common.persistence.RawResource;",
          "39: import org.apache.kylin.common.persistence.ResourceStore;",
          "40: import org.apache.kylin.common.persistence.Serializer;",
          "41: import org.apache.kylin.common.restclient.RestClient;",
          "42: import org.apache.kylin.common.util.AbstractApplication;",
          "43: import org.apache.kylin.common.util.HadoopUtil;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "21: import java.io.DataOutputStream;",
          "24: import java.io.ByteArrayOutputStream;",
          "25: import java.io.ByteArrayInputStream;",
          "32: import java.util.Locale;",
          "33: import java.util.Arrays;",
          "36: import org.apache.commons.cli.Option;",
          "37: import org.apache.commons.cli.OptionBuilder;",
          "38: import org.apache.commons.cli.OptionGroup;",
          "40: import org.apache.commons.lang.StringUtils;",
          "46: import org.apache.kylin.common.KylinVersion;",
          "52: import org.apache.kylin.common.persistence.ContentReader;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "55: import org.apache.kylin.metadata.model.TableRef;",
          "56: import org.apache.kylin.metadata.model.TableExtDesc;",
          "57: import org.apache.kylin.metadata.model.DataModelManager;",
          "58: import org.apache.kylin.metadata.project.ProjectInstance;",
          "59: import org.apache.kylin.metadata.realization.RealizationStatusEnum;",
          "60: import org.apache.kylin.metadata.realization.RealizationType;",
          "61: import org.slf4j.Logger;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "70: import org.apache.kylin.metadata.model.IStorageAware;",
          "71: import org.apache.kylin.metadata.model.IEngineAware;",
          "73: import org.apache.kylin.metadata.project.ProjectManager;",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "82:     protected Configuration conf;",
          "83:     protected boolean doAclCopy = false;",
          "84:     protected boolean doOverwrite = false;",
          "86:     protected String dstProject;",
          "87:     protected String srcHdfsWorkDir;",
          "88:     protected String dstHdfsWorkDir;",
          "90:     private static final String ACL_PREFIX = \"/acl/\";",
          "91:     private static final String GLOBAL_DICT_PREFIX = \"/dict/global_dict/\";",
          "95:         CubeMigrationCLI cli = new CubeMigrationCLI();",
          "98:             System.exit(1);",
          "99:         }",
          "105:     }",
          "128:     }",
          "147:     }",
          "163:         CubeInstance cube = cubeManager.getCube(cubeName);",
          "165:         dstHdfsWorkDir = dstConfig.getHdfsWorkingDirectory(dstProject);",
          "166:         logger.info(\"cube to be moved is : \" + cubeName);",
          "169:             checkCubeState(cube);",
          "170:         }",
          "172:         checkAndGetMetadataUrl();",
          "174:         hdfsFs = HadoopUtil.getWorkingFileSystem();",
          "175:         operations = new ArrayList<Opt>();",
          "178:             clearSegments(cubeName); // this should be after copyFilesInMetaStore",
          "179:         }",
          "183:             purgeAndDisable(cubeName); // this should be the last action",
          "184:         }",
          "186:         if (realExecute) {",
          "187:             doOpts();",
          "189:         } else {",
          "190:             showOpts();",
          "191:         }",
          "",
          "[Removed Lines]",
          "85:     protected boolean doMigrateSegment = true;",
          "93:     public static void main(String[] args) throws IOException, InterruptedException {",
          "96:         if (args.length != 8 && args.length != 9) {",
          "97:             cli.usage();",
          "100:         if (args.length == 8) {",
          "101:             cli.moveCube(args[0], args[1], args[2], args[3], args[4], args[5], args[6], args[7]);",
          "102:         } else if (args.length == 9) {",
          "103:             cli.moveCube(args[0], args[1], args[2], args[3], args[4], args[5], args[6], args[7], args[8]);",
          "104:         }",
          "107:     protected void usage() {",
          "108:         System.out.println(",
          "109:                 \"Usage: CubeMigrationCLI srcKylinConfigUri dstKylinConfigUri cubeName projectName copyAclOrNot purgeOrNot overwriteIfExists realExecute migrateSegmentOrNot\");",
          "110:         System.out.println(\"srcKylinConfigUri: The KylinConfig of the cube\u2019s source \\n\"",
          "111:                 + \"dstKylinConfigUri: The KylinConfig of the cube\u2019s new home \\n\"",
          "112:                 + \"cubeName: the name of cube to be migrated. \\n\"",
          "113:                 + \"projectName: The target project in the target environment.(Make sure it exist) \\n\"",
          "114:                 + \"copyAclOrNot: true or false: whether copy cube ACL to target environment. \\n\"",
          "115:                 + \"purgeOrNot: true or false: whether purge the cube from src server after the migration. \\n\"",
          "116:                 + \"overwriteIfExists: overwrite cube if it already exists in the target environment. \\n\"",
          "117:                 + \"realExecute: if false, just print the operations to take, if true, do the real migration. \\n\"",
          "118:                 + \"migrateSegmentOrNot:(optional) true or false: whether copy segment data to target environment. \\n\");",
          "120:     }",
          "122:     public void moveCube(String srcCfgUri, String dstCfgUri, String cubeName, String projectName, String copyAcl,",
          "123:                          String purgeAndDisable, String overwriteIfExists, String realExecute)",
          "124:             throws IOException, InterruptedException {",
          "126:         moveCube(KylinConfig.createInstanceFromUri(srcCfgUri), KylinConfig.createInstanceFromUri(dstCfgUri), cubeName,",
          "127:                 projectName, copyAcl, purgeAndDisable, overwriteIfExists, realExecute);",
          "130:     public void moveCube(KylinConfig srcCfg, KylinConfig dstCfg, String cubeName, String projectName, String copyAcl,",
          "131:                          String purgeAndDisable, String overwriteIfExists, String realExecute)",
          "132:             throws IOException, InterruptedException {",
          "134:         moveCube(srcCfg, dstCfg, cubeName, projectName, Boolean.parseBoolean(copyAcl),",
          "135:                 Boolean.parseBoolean(purgeAndDisable), Boolean.parseBoolean(overwriteIfExists),",
          "136:                 Boolean.parseBoolean(realExecute), true);",
          "137:     }",
          "139:     public void moveCube(String srcCfgUri, String dstCfgUri, String cubeName, String projectName, String copyAcl,",
          "140:                          String purgeAndDisable, String overwriteIfExists, String realExecute, String migrateSegment)",
          "141:             throws IOException, InterruptedException {",
          "143:         moveCube(KylinConfig.createInstanceFromUri(srcCfgUri), KylinConfig.createInstanceFromUri(dstCfgUri), cubeName,",
          "144:                 projectName, Boolean.parseBoolean(copyAcl), Boolean.parseBoolean(purgeAndDisable),",
          "145:                 Boolean.parseBoolean(overwriteIfExists), Boolean.parseBoolean(realExecute),",
          "146:                 Boolean.parseBoolean(migrateSegment));",
          "149:     public void moveCube(KylinConfig srcCfg, KylinConfig dstCfg, String cubeName, String projectName, boolean copyAcl,",
          "150:                          boolean purgeAndDisable, boolean overwriteIfExists, boolean realExecute, boolean migrateSegment)",
          "151:             throws IOException, InterruptedException {",
          "152:         doAclCopy = copyAcl;",
          "153:         doOverwrite = overwriteIfExists;",
          "154:         doMigrateSegment = migrateSegment;",
          "155:         srcConfig = srcCfg;",
          "156:         srcStore = ResourceStore.getStore(srcConfig);",
          "157:         dstConfig = dstCfg;",
          "158:         dstStore = ResourceStore.getStore(dstConfig);",
          "159:         dstProject = projectName;",
          "160:         conf = HadoopUtil.getCurrentConfiguration();",
          "162:         CubeManager cubeManager = CubeManager.getInstance(srcConfig);",
          "164:         srcHdfsWorkDir = srcConfig.getHdfsWorkingDirectory(cube.getProject());",
          "168:         if (migrateSegment) {",
          "176:         copyFilesInMetaStore(cube);",
          "177:         if (!migrateSegment) {",
          "180:         addCubeAndModelIntoProject(cube, cubeName);",
          "182:         if (migrateSegment && purgeAndDisable) {",
          "188:             updateMeta(dstConfig, projectName, cubeName, cube.getModel());",
          "",
          "[Added Lines]",
          "100:     protected boolean doMigrateSegment = false;",
          "104:     private boolean realExecute;",
          "105:     private boolean purgeAndDisable;",
          "106:     private OptionsHelper optHelper;",
          "111:     private static final Option OPTION_SRC_CONFIG = OptionBuilder.isRequired(true).hasArg().withDescription(\"The KylinConfig of the cube\u2019s source\").create(\"srcConfig\");",
          "112:     private static final Option OPTION_DST_CONFIG = OptionBuilder.isRequired(true).hasArg().withDescription(\"The KylinConfig of the cube\u2019s new home\").create(\"dstConfig\");",
          "113:     private static final Option OPTION_ALL_CUBES = OptionBuilder.isRequired(false).withDescription(\"migrate all cubes meta from source cluster\").create(\"allCubes\");",
          "114:     private static final Option OPTION_CUBE = OptionBuilder.isRequired(false).hasArg().withDescription(\"Cube name to migrate\").create(\"cube\");",
          "115:     private static final Option OPTION_DST_PROJECT = OptionBuilder.isRequired(false).hasArg().withDescription(\"cube's new project home, if not set, keep the same as source cluster\").create(\"dstProject\");",
          "116:     private static final Option OPTION_SRC_PROJECT = OptionBuilder.isRequired(false).hasArg().withDescription(\"source project to migrate\").create(\"srcProject\");",
          "117:     private static final Option OPTION_COPY_ACL = OptionBuilder.isRequired(false).hasArg().withDescription(\"copy ACL\").create(\"copyAcl\");",
          "118:     private static final Option OPTION_PURGE_AND_DISABLE = OptionBuilder.isRequired(false).withDescription(\"purge source cluster data\").create(\"purgeAndDisable\");",
          "119:     private static final Option OPTION_OVERWRITE = OptionBuilder.isRequired(false).withDescription(\"overwrite target cluster's meta if exists\").create(\"overwriteIfExists\");",
          "120:     private static final Option OPTION_EXECUTE = OptionBuilder.isRequired(false).hasArg().withDescription(\"execute migration\").create(\"realMigrate\");",
          "121:     private static final Option OPTION_MIGRATE_SEGMENTS = OptionBuilder.isRequired(false).withDescription(\"migrate segment data\").create(\"migrateSegment\");",
          "123:     public static void main(String[] args) throws Exception {",
          "124:         CubeMigrationCLI cli = new CubeMigrationCLI();",
          "125:         cli.init(args);",
          "126:         cli.moveCube();",
          "127:     }",
          "129:     public void init(String[] args) {",
          "130:         optHelper = new OptionsHelper();",
          "132:         try {",
          "133:             optHelper.parseOptions(cli.getOptions(), args);",
          "134:         } catch (Exception e) {",
          "135:             logger.error(\"failed to parse arguments\", e);",
          "136:             optHelper.printUsage(\"CubeMigrationCLI\", cli.getOptions());",
          "139:         doAclCopy = optHelper.hasOption(OPTION_COPY_ACL);",
          "140:         doOverwrite = optHelper.hasOption(OPTION_OVERWRITE);",
          "141:         doMigrateSegment = optHelper.hasOption(OPTION_MIGRATE_SEGMENTS);",
          "142:         purgeAndDisable = optHelper.hasOption(OPTION_PURGE_AND_DISABLE);",
          "143:         srcConfig = KylinConfig.createInstanceFromUri(optHelper.getOptionValue(OPTION_SRC_CONFIG));",
          "144:         srcStore = ResourceStore.getStore(srcConfig);",
          "145:         dstConfig = KylinConfig.createInstanceFromUri(optHelper.getOptionValue(OPTION_DST_CONFIG));",
          "146:         dstStore = ResourceStore.getStore(dstConfig);",
          "147:         realExecute = optHelper.hasOption(OPTION_EXECUTE) ? Boolean.valueOf(optHelper.getOptionValue(OPTION_EXECUTE)) : true;",
          "148:         dstProject = optHelper.getOptionValue(OPTION_DST_PROJECT);",
          "149:         conf = HadoopUtil.getCurrentConfiguration();",
          "152:     public void moveCube() throws Exception {",
          "153:         conf = HadoopUtil.getCurrentConfiguration();",
          "155:         if (optHelper.hasOption(OPTION_CUBE)) {",
          "156:             CubeManager cubeManager = CubeManager.getInstance(srcConfig);",
          "157:             moveSingleCube(optHelper.getOptionValue(OPTION_CUBE), dstProject, cubeManager);",
          "158:         } else if (optHelper.hasOption(OPTION_SRC_PROJECT)) {",
          "159:             moveAllCubesUnderProject(optHelper.getOptionValue(OPTION_SRC_PROJECT), ProjectManager.getInstance(srcConfig), ProjectManager.getInstance(dstConfig));",
          "160:         } else if (optHelper.hasOption(OPTION_ALL_CUBES)) {",
          "161:             moveAllProjectAndCubes();",
          "162:         }",
          "166:     private void moveAllCubesUnderProject(String srcProject, ProjectManager srcProjectManager, ProjectManager dstProjectManager) throws Exception {",
          "167:         ProjectInstance srcProjectInstance = srcProjectManager.getProject(srcProject);",
          "169:         if (StringUtils.isEmpty(dstProject)) {",
          "170:             if (null == dstProjectManager.getProject(srcProject)) {",
          "171:                 dstProjectManager.createProject(srcProjectInstance.getName(),",
          "172:                         srcProjectInstance.getOwner(), srcProjectInstance.getDescription(), srcProjectInstance.getOverrideKylinProps());",
          "173:             }",
          "174:         }",
          "176:         CubeManager cubeManager = CubeManager.getInstance(srcConfig);",
          "178:         srcProjectInstance.getRealizationEntries(RealizationType.CUBE).forEach(cube -> {",
          "179:             try {",
          "180:                 if (StringUtils.isEmpty(dstProject)) {",
          "181:                     moveSingleCube(cube.getRealization(), srcProject, cubeManager);",
          "182:                 } else {",
          "183:                     moveSingleCube(cube.getRealization(), dstProject, cubeManager);",
          "184:                 }",
          "185:             } catch (Exception e) {",
          "186:                 logger.error(\"failed to move cube: {}\", cube.getRealization(), e);",
          "187:             }",
          "188:         });",
          "192:     private void moveAllProjectAndCubes() throws Exception {",
          "193:         ProjectManager srcProjectManager = ProjectManager.getInstance(srcConfig);",
          "194:         List<ProjectInstance> projects = srcProjectManager.listAllProjects();",
          "195:         for (ProjectInstance project : projects) {",
          "196:             moveAllCubesUnderProject(project.getName(), srcProjectManager, ProjectManager.getInstance(dstConfig));",
          "197:         }",
          "198:     }",
          "200:     private void moveSingleCube(String cubeName, String dstProject, CubeManager cubeManager) throws IOException, InterruptedException {",
          "204:         if (StringUtils.isEmpty(dstProject)) {",
          "205:             dstProject = cube.getProject();",
          "206:         }",
          "208:         ProjectManager dstProjectManager = ProjectManager.getInstance(dstConfig);",
          "209:         ProjectInstance instance = dstProjectManager.getProject(dstProject);",
          "211:         if (null == instance) {",
          "212:             ProjectManager scrProjectManager = ProjectManager.getInstance(srcConfig);",
          "213:             ProjectInstance originProject = scrProjectManager.getProject(cube.getProject());",
          "215:             dstProjectManager.createProject(dstProject, originProject.getOwner(),",
          "216:                     originProject.getDescription(), originProject.getOverrideKylinProps());",
          "217:         }",
          "219:         if (null == cube) {",
          "220:             logger.warn(\"source cube: {} not exists\", cubeName);",
          "221:             return;",
          "222:         }",
          "224:         srcHdfsWorkDir = srcConfig.getHdfsWorkingDirectory(dstProject);",
          "228:         if (doMigrateSegment) {",
          "230:             KylinVersion srcVersion = new KylinVersion(cube.getVersion());",
          "231:             if (srcVersion.major != KylinVersion.getCurrentVersion().major) {",
          "232:                 throw new IllegalArgumentException(String.format(Locale.ROOT,",
          "233:                         \"can not migrate segment data from version: %s  to version: %s\",",
          "234:                         srcVersion.toString(), KylinVersion.getCurrentVersion().toString()));",
          "235:             }",
          "242:         copyFilesInMetaStore(cube, dstProject);",
          "243:         if (!doMigrateSegment) {",
          "246:         addCubeAndModelIntoProject(cube, cubeName, dstProject);",
          "248:         if (doMigrateSegment && purgeAndDisable) {",
          "254:             updateMeta(dstConfig, dstProject, cubeName, cube.getModel());",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "211:     }",
          "213:     protected void clearSegments(String cubeName) throws IOException {",
          "215:     }",
          "219:         if (dstStore.exists(cube.getResourcePath()) && !doOverwrite)",
          "220:             throw new IllegalStateException(\"The cube named \" + cube.getName()",
          "",
          "[Removed Lines]",
          "214:         operations.add(new Opt(OptType.CLEAR_SEGMENTS, new Object[]{cubeName}));",
          "217:     protected void copyFilesInMetaStore(CubeInstance cube) throws IOException {",
          "",
          "[Added Lines]",
          "280:         operations.add(new Opt(OptType.CLEAR_SEGMENTS, new Object[]{cubeName}, null));",
          "283:     protected void copyFilesInMetaStore(CubeInstance cube, String dstProject) throws IOException {",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "227:         listCubeRelatedResources(cube, metaItems, dictAndSnapshot, srcParquetFiles, dstParquetFiles);",
          "229:         for (String item : metaItems) {",
          "231:         }",
          "233:         if (doMigrateSegment) {",
          "234:             for (String item : dictAndSnapshot) {",
          "236:             }",
          "238:             for (int i = 0; i < srcParquetFiles.size(); i++) {",
          "240:             }",
          "241:         }",
          "242:     }",
          "245:         String projectResPath = ProjectInstance.concatResourcePath(dstProject);",
          "246:         if (!dstStore.exists(projectResPath))",
          "247:             throw new IllegalStateException(\"The target project \" + dstProject + \" does not exist\");",
          "250:     }",
          "252:     private void purgeAndDisable(String cubeName) throws IOException {",
          "254:     }",
          "256:     private List<String> getCompatibleTablePath(Set<TableRef> tableRefs, String project, String rootPath)",
          "",
          "[Removed Lines]",
          "230:             operations.add(new Opt(OptType.COPY_FILE_IN_META, new Object[]{item}));",
          "235:                 operations.add(new Opt(OptType.COPY_DICT_OR_SNAPSHOT, new Object[]{item, cube.getName()}));",
          "239:                 operations.add(new Opt(OptType.COPY_PARQUET_FILE, new Object[]{srcParquetFiles.get(i), dstParquetFiles.get(i)}));",
          "244:     protected void addCubeAndModelIntoProject(CubeInstance srcCube, String cubeName) throws IOException {",
          "249:         operations.add(new Opt(OptType.ADD_INTO_PROJECT, new Object[]{srcCube, cubeName, dstProject}));",
          "253:         operations.add(new Opt(OptType.PURGE_AND_DISABLE, new Object[]{cubeName}));",
          "",
          "[Added Lines]",
          "296:             operations.add(new Opt(OptType.COPY_FILE_IN_META, new Object[]{item}, dstProject));",
          "301:                 operations.add(new Opt(OptType.COPY_DICT_OR_SNAPSHOT, new Object[]{item, cube.getName()}, dstProject));",
          "305:                 operations.add(new Opt(OptType.COPY_PARQUET_FILE, new Object[]{srcParquetFiles.get(i), dstParquetFiles.get(i)}, dstProject));",
          "310:     protected void addCubeAndModelIntoProject(CubeInstance srcCube, String cubeName, String dstProject) throws IOException {",
          "315:         operations.add(new Opt(OptType.ADD_INTO_PROJECT, new Object[]{srcCube, cubeName}, dstProject));",
          "319:         operations.add(new Opt(OptType.PURGE_AND_DISABLE, new Object[]{cubeName}, null));",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "324:     @Override",
          "325:     protected Options getOptions() {",
          "326:         Options options = new Options();",
          "327:         return options;",
          "328:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "393:         options.addOption(OPTION_SRC_CONFIG);",
          "394:         options.addOption(OPTION_DST_CONFIG);",
          "396:         OptionGroup srcGroup = new OptionGroup();",
          "397:         srcGroup.addOption(OPTION_ALL_CUBES);",
          "398:         srcGroup.addOption(OPTION_CUBE);",
          "399:         srcGroup.addOption(OPTION_SRC_PROJECT);",
          "400:         srcGroup.setRequired(true);",
          "401:         options.addOptionGroup(srcGroup);",
          "403:         options.addOption(OPTION_DST_PROJECT);",
          "404:         options.addOption(OPTION_OVERWRITE);",
          "405:         options.addOption(OPTION_COPY_ACL);",
          "406:         options.addOption(OPTION_PURGE_AND_DISABLE);",
          "407:         options.addOption(OPTION_EXECUTE);",
          "408:         options.addOption(OPTION_MIGRATE_SEGMENTS);",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "335:         COPY_FILE_IN_META, COPY_DICT_OR_SNAPSHOT, COPY_PARQUET_FILE, ADD_INTO_PROJECT, PURGE_AND_DISABLE, CLEAR_SEGMENTS",
          "336:     }",
          "340:     }",
          "342:     private class Opt {",
          "343:         private OptType type;",
          "344:         private Object[] params;",
          "347:             this.type = type;",
          "348:             this.params = params;",
          "349:         }",
          "351:         public String toString() {",
          "",
          "[Removed Lines]",
          "338:     protected void addOpt(OptType type, Object[] params) {",
          "339:         operations.add(new Opt(type, params));",
          "346:         private Opt(OptType type, Object[] params) {",
          "",
          "[Added Lines]",
          "420:     protected void addOpt(OptType type, Object[] params, String dstProject) {",
          "421:         operations.add(new Opt(type, params, dstProject));",
          "427:         private String dstProject;",
          "429:         private Opt(OptType type, Object[] params, String dstProject) {",
          "432:             this.dstProject = dstProject;",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "353:             sb.append(type).append(\":\");",
          "354:             for (Object s : params)",
          "355:                 sb.append(s).append(\", \");",
          "356:             return sb.toString();",
          "357:         }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "440:             sb.append(dstProject);",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "408:                 if (item.startsWith(ResourceStore.DATA_MODEL_DESC_RESOURCE_ROOT)) {",
          "409:                     DataModelDesc dataModelDesc = srcStore.getResource(item, DataModelManager.getInstance(srcConfig).getDataModelSerializer());",
          "412:                         dstStore.putResource(item, dataModelDesc, res.lastModified(), DataModelManager.getInstance(srcConfig).getDataModelSerializer());",
          "413:                         logger.info(\"Item \" + item + \" is copied.\");",
          "414:                         break;",
          "415:                     }",
          "416:                 }",
          "417:                 dstStore.putResource(renameTableWithinProject(item), res.content(), res.lastModified());",
          "419:                 logger.info(\"Item \" + item + \" is copied\");",
          "420:                 break;",
          "421:             }",
          "",
          "[Removed Lines]",
          "410:                     if (dataModelDesc != null && dataModelDesc.getProjectName() != null && !dataModelDesc.getProjectName().equals(dstProject)) {",
          "411:                         dataModelDesc.setProjectName(dstProject);",
          "418:                 res.content().close();",
          "",
          "[Added Lines]",
          "497:                     List<ProjectInstance> projectContainsModel = ProjectManager.getInstance(dstConfig).findProjectsByModel(dataModelDesc.getName());",
          "498:                     if (projectContainsModel.size() > 1) {",
          "499:                         throw new RuntimeException(String.format(Locale.ROOT, \"model: %s belongs to several projects: %s\",",
          "500:                                 dataModelDesc.getName(), Arrays.toString(projectContainsModel.toArray())));",
          "501:                     }",
          "502:                     if (projectContainsModel.size() == 1 && !opt.dstProject.equals(projectContainsModel.get(0).getName())) {",
          "503:                             throw new IllegalArgumentException(String.format(Locale.ROOT,",
          "504:                                     \"there already exists model: %s in project: %s, can't create model with the same name in dest project: %s\",",
          "505:                                     dataModelDesc.getName(), projectContainsModel.get(0).getName(), opt.dstProject));",
          "506:                     }",
          "508:                     if (dataModelDesc != null && dataModelDesc.getProjectName() != null && !dataModelDesc.getProjectName().equals(opt.dstProject)) {",
          "509:                         dataModelDesc.setProjectName(opt.dstProject);",
          "512:                         res.close();",
          "516:                 if (item.startsWith(ResourceStore.CUBE_DESC_RESOURCE_ROOT)) {",
          "517:                     JsonSerializer serializer = new JsonSerializer(CubeDesc.class, false);",
          "518:                     ContentReader<CubeDesc> reader = new ContentReader<>(serializer);",
          "519:                     CubeDesc cubeDesc = reader.readContent(res);",
          "522:                     cubeDesc.setStorageType(IStorageAware.ID_PARQUET);",
          "523:                     cubeDesc.setEngineType(IEngineAware.ID_SPARK_II);",
          "524:                     cubeDesc.setVersion(KylinVersion.getCurrentVersion().toString());",
          "526:                     cubeDesc.setSignature(cubeDesc.calculateSignature());",
          "528:                     ByteArrayOutputStream buf = new ByteArrayOutputStream();",
          "529:                     DataOutputStream dout = new DataOutputStream(buf);",
          "530:                     serializer.serialize(cubeDesc, dout);",
          "531:                     dstStore.putResource(item, new ByteArrayInputStream(buf.toByteArray()), res.lastModified());",
          "532:                     dout.close();",
          "533:                     buf.close();",
          "534:                     res.close();",
          "535:                     break;",
          "536:                 }",
          "538:                 res.close();",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "446:             case ADD_INTO_PROJECT: {",
          "447:                 CubeInstance srcCube = (CubeInstance) opt.params[0];",
          "448:                 String cubeName = (String) opt.params[1];",
          "450:                 String modelName = srcCube.getDescriptor().getModelName();",
          "452:                 String projectResPath = ProjectInstance.concatResourcePath(projectName);",
          "",
          "[Removed Lines]",
          "449:                 String projectName = (String) opt.params[2];",
          "",
          "[Added Lines]",
          "569:                 String projectName = opt.dstProject;",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "4100e5007624ae29b8e5e97319261064896ea699",
      "candidate_info": {
        "commit_hash": "4100e5007624ae29b8e5e97319261064896ea699",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/4100e5007624ae29b8e5e97319261064896ea699",
        "files": [
          "kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/execution/datasource/FilePruner.scala"
        ],
        "message": "KYLIN-5021 FilePruner throws NPE when there is no timePartitionColunm in cube (#1680)\n\n* KYLIN-5021 FilePruner throws NPE when there is no timePartitionColumn in cube\n\n* minor, use isDefined to check None\n\n* optimize performance of file pruner\n\nCo-authored-by: tianhui5 <tianhui5@xiaomi.com>\nCo-authored-by: Congling XIA <xiacongling@xiaomi.com>",
        "before_after_code_files": [
          "kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/execution/datasource/FilePruner.scala||kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/execution/datasource/FilePruner.scala"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/execution/datasource/FilePruner.scala||kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/execution/datasource/FilePruner.scala": [
          "File: kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/execution/datasource/FilePruner.scala -> kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/execution/datasource/FilePruner.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "295:   }",
          "297:   private def getSegmentFilter(dataFilters: Seq[Expression], col: Attribute): Seq[Expression] = {",
          "299:   }",
          "301:   private def extractSegmentFilter(filter: Expression, col: Attribute): Option[Expression] = {",
          "302:     filter match {",
          "303:       case expressions.Or(left, right) =>",
          "304:         val leftChild = extractSegmentFilter(left, col)",
          "",
          "[Removed Lines]",
          "298:     dataFilters.map(extractSegmentFilter(_, col)).filter(!_.equals(None)).map(_.get)",
          "",
          "[Added Lines]",
          "298:     dataFilters.map(extractSegmentFilter(_, col)).filter(_.isDefined).map(_.get)",
          "302:     if (col == null) {",
          "303:       return None",
          "304:     }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "7370489ed53c044841955d9481a6fe00035aa697",
      "candidate_info": {
        "commit_hash": "7370489ed53c044841955d9481a6fe00035aa697",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/7370489ed53c044841955d9481a6fe00035aa697",
        "files": [
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/BuildLayoutWithUpdate.java"
        ],
        "message": "KYLIN-4903 cache parent datasource to accelerate next layer's cuboid building\n\nFix bug",
        "before_after_code_files": [
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/BuildLayoutWithUpdate.java||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/BuildLayoutWithUpdate.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/BuildLayoutWithUpdate.java||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/BuildLayoutWithUpdate.java": [
          "File: kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/BuildLayoutWithUpdate.java -> kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/BuildLayoutWithUpdate.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "76:     public void submit(JobEntity job, KylinConfig config) {",
          "81:             if(!layout2DataSet.containsKey(job.getBuildSourceInfo().getLayoutId())){",
          "82:                 logger.error(\"persist parent dataset is enabled, but parent dataset not registered\");",
          "",
          "[Removed Lines]",
          "79:         if (persistParentDataset && job.getBuildSourceInfo() != null && job.getBuildSourceInfo().getToBuildCuboids().size() > 1) {",
          "",
          "[Added Lines]",
          "80:         if (persistParentDataset && job.getBuildSourceInfo() != null) {",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "102:                     throwable = t;",
          "103:                 } finally {",
          "106:                         long remain = toBuildCuboidSize.get(job.getBuildSourceInfo().getLayoutId()).decrementAndGet();",
          "107:                         if (remain == 0) {",
          "108:                             toBuildCuboidSize.remove(job.getBuildSourceInfo().getLayoutId());",
          "",
          "[Removed Lines]",
          "105:                     if (persistParentDataset && job.getBuildSourceInfo() != null && job.getBuildSourceInfo().getToBuildCuboids().size() > 1) {",
          "",
          "[Added Lines]",
          "106:                     if (persistParentDataset && job.getBuildSourceInfo() != null) {",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "540e861102fa4cacd5ef257b742b2385ed3d42f9",
      "candidate_info": {
        "commit_hash": "540e861102fa4cacd5ef257b742b2385ed3d42f9",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/540e861102fa4cacd5ef257b742b2385ed3d42f9",
        "files": [
          "webapp/app/js/model/jobListModel.js"
        ],
        "message": "KYLIN-4537 Give a friendly tips to the user when getting task list fails\n\n(cherry picked from commit ed7658d87104c9ab365062cbfed239341d33aa2b)",
        "before_after_code_files": [
          "webapp/app/js/model/jobListModel.js||webapp/app/js/model/jobListModel.js"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "webapp/app/js/model/jobListModel.js||webapp/app/js/model/jobListModel.js": [
          "File: webapp/app/js/model/jobListModel.js -> webapp/app/js/model/jobListModel.js",
          "--- Hunk 1 ---",
          "[Context before]",
          "56:                 _this.jobs[id].dropped = false;",
          "57:             });",
          "58:             defer.resolve(jobs.length);",
          "61:         });",
          "62:         return defer.promise;",
          "63:     };",
          "",
          "[Removed Lines]",
          "59:           },function(){",
          "60:             defer.reject(\"failed to load jobs\");",
          "",
          "[Added Lines]",
          "59:         },function(e){",
          "60:           var msg = 'failed to load jobs';",
          "61:           if (e.data && e.data.exception) {",
          "62:             var message = e.data.exception;",
          "63:             msg = !!(message) ? message : msg;",
          "64:           }",
          "65:           defer.reject(msg);",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "73:           }",
          "74:         });",
          "75:         defer.resolve(jobsOverview);",
          "78:       });",
          "79:       return defer.promise;",
          "80:     };",
          "",
          "[Removed Lines]",
          "76:       },function(){",
          "77:         defer.reject(\"failed to load job overview\");",
          "",
          "[Added Lines]",
          "81:       },function(e){",
          "82:         var msg = 'failed to load job overview';",
          "83:         if (e.data && e.data.exception) {",
          "84:           var message = e.data.exception;",
          "85:           msg = !!(message) ? message : msg;",
          "86:         }",
          "87:         defer.reject(msg);",
          "",
          "---------------"
        ]
      }
    }
  ]
}