{
  "cve_id": "CVE-2024-29735",
  "cve_desc": "Improper Preservation of Permissions vulnerability in Apache Airflow.This issue affects Apache Airflow from 2.8.2 through 2.8.3.\n\nAirflow's local file task handler in Airflow incorrectly set permissions for all parent folders of log folder, in default configuration adding write access to Unix group\u00a0of the folders. In the case Airflow is run with the root user (not recommended) it added group write permission to all folders up to the root of the filesystem.\n\nIf your log files are stored in the home directory, these permission changes might impact your ability to run SSH operations after your home directory becomes group-writeable.\n\nThis issue does not affect users who use or extend Airflow using Official Airflow Docker reference images ( https://hub.docker.com/r/apache/airflow/ ) - those images require to have group write permission set anyway.\n\nYou are affected only if you install Airflow using local installation / virtualenv or other Docker images, but the issue has no impact if docker containers are used as intended, i.e. where Airflow components do not share containers with other applications and users.\n\nAlso you should not be affected if your umask is 002 (group write enabled) - this is the default on many linux systems.\n\nRecommendation for users using Airflow outside of the containers:\n\n  *  if you are using root to run Airflow, change your Airflow user to use non-root\n  *  upgrade Apache Airflow to 2.8.4 or above\n  *  If you prefer not to upgrade, you can change the  https://airflow.apache.org/docs/apache-airflow/stable/configurations-ref.html#file-task-handler-new-folder-permissions \u00a0to 0o755 (original value 0o775).\n  *  if you already ran Airflow tasks before and your default umask is 022 (group write disabled) you should stop Airflow components, check permissions of AIRFLOW_HOME/logs\u00a0in all your components and all parent directories of this directory and remove group write access for all the parent directories",
  "repo": "apache/airflow",
  "patch_hash": "aae4a83cdfb3be4afeefd88a7bfa3c4d8d184958",
  "patch_info": {
    "commit_hash": "aae4a83cdfb3be4afeefd88a7bfa3c4d8d184958",
    "repo": "apache/airflow",
    "commit_url": "https://github.com/apache/airflow/commit/aae4a83cdfb3be4afeefd88a7bfa3c4d8d184958",
    "files": [
      "airflow/utils/log/file_task_handler.py",
      "tests/utils/test_log_handlers.py"
    ],
    "message": "Fix permissions of parent folders for log file handler (#37310)\n\nWhen we created a new folder during log file handler directory creation\nwe did not change the permissions of parent folders.\n\nFixes: #37200",
    "before_after_code_files": [
      "airflow/utils/log/file_task_handler.py||airflow/utils/log/file_task_handler.py",
      "tests/utils/test_log_handlers.py||tests/utils/test_log_handlers.py"
    ]
  },
  "patch_diff": {
    "airflow/utils/log/file_task_handler.py||airflow/utils/log/file_task_handler.py": [
      "File: airflow/utils/log/file_task_handler.py -> airflow/utils/log/file_task_handler.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "159:         raise AirflowException(f\"Could not find TaskInstance for {ti}\")",
      "162: class FileTaskHandler(logging.Handler):",
      "163:     \"\"\"",
      "164:     FileTaskHandler is a python log handler that handles and reads task instance logs.",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "162: def _change_directory_permissions_up(directory: Path, folder_permissions: int):",
      "163:     \"\"\"",
      "164:     Change permissions of the given directory and its parents.",
      "166:     Only attempt to change permissions for directories owned by the current user.",
      "168:     :param directory: directory to change permissions of (including parents)",
      "169:     :param folder_permissions: permissions to set",
      "170:     \"\"\"",
      "171:     if directory.stat().st_uid == os.getuid():",
      "172:         if directory.stat().st_mode % 0o1000 != folder_permissions % 0o1000:",
      "173:             print(f\"Changing {directory} permission to {folder_permissions}\")",
      "174:             try:",
      "175:                 directory.chmod(folder_permissions)",
      "176:             except PermissionError as e:",
      "177:                 # In some circumstances (depends on user and filesystem) we might not be able to",
      "178:                 # change the permission for the folder (when the folder was created by another user",
      "179:                 # before or when the filesystem does not allow to change permission). We should not",
      "180:                 # fail in this case but rather ignore it.",
      "181:                 print(f\"Failed to change {directory} permission to {folder_permissions}: {e}\")",
      "182:                 return",
      "183:         if directory.parent != directory:",
      "184:             _change_directory_permissions_up(directory.parent, folder_permissions)",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "484:             conf.get(\"logging\", \"file_task_handler_new_folder_permissions\", fallback=\"0o775\"), 8",
      "485:         )",
      "486:         directory.mkdir(mode=new_folder_permissions, parents=True, exist_ok=True)",
      "499:     def _init_file(self, ti, *, identifier: str | None = None):",
      "500:         \"\"\"",
      "",
      "[Removed Lines]",
      "487:         if directory.stat().st_mode % 0o1000 != new_folder_permissions % 0o1000:",
      "488:             print(f\"Changing {directory} permission to {new_folder_permissions}\")",
      "489:             try:",
      "490:                 directory.chmod(new_folder_permissions)",
      "491:             except PermissionError as e:",
      "492:                 # In some circumstances (depends on user and filesystem) we might not be able to",
      "493:                 # change the permission for the folder (when the folder was created by another user",
      "494:                 # before or when the filesystem does not allow to change permission). We should not",
      "495:                 # fail in this case but rather ignore it.",
      "496:                 print(f\"Failed to change {directory} permission to {new_folder_permissions}: {e}\")",
      "497:                 pass",
      "",
      "[Added Lines]",
      "512:         _change_directory_permissions_up(directory, new_folder_permissions)",
      "",
      "---------------"
    ],
    "tests/utils/test_log_handlers.py||tests/utils/test_log_handlers.py": [
      "File: tests/utils/test_log_handlers.py -> tests/utils/test_log_handlers.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "21: import logging.config",
      "22: import os",
      "23: import re",
      "24: from pathlib import Path",
      "25: from unittest import mock",
      "26: from unittest.mock import patch",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "24: import shutil",
      "25: import tempfile",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "40: from airflow.utils.log.file_task_handler import (",
      "41:     FileTaskHandler,",
      "42:     LogType,",
      "43:     _interleave_logs,",
      "44:     _parse_timestamps_in_log_file,",
      "45: )",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "45:     _change_directory_permissions_up,",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "719:     \"\"\"",
      "721:     assert sample_with_dupe == \"\\n\".join(_interleave_logs(sample_with_dupe, \"\", sample_with_dupe))",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "727: def test_permissions_for_new_directories():",
      "728:     tmp_path = Path(tempfile.mkdtemp())",
      "729:     try:",
      "730:         # Set umask to 0o027: owner rwx, group rx-w, other -rwx",
      "731:         old_umask = os.umask(0o027)",
      "732:         try:",
      "733:             subdir = tmp_path / \"subdir1\" / \"subdir2\"",
      "734:             # force permissions for the new folder to be owner rwx, group -rxw, other -rwx",
      "735:             new_folder_permissions = 0o700",
      "736:             # default permissions are owner rwx, group rx-w, other -rwx (umask bit negative)",
      "737:             default_permissions = 0o750",
      "738:             subdir.mkdir(mode=new_folder_permissions, parents=True, exist_ok=True)",
      "739:             assert subdir.exists()",
      "740:             assert subdir.is_dir()",
      "741:             assert subdir.stat().st_mode % 0o1000 == new_folder_permissions",
      "742:             # initially parent permissions are as per umask",
      "743:             assert subdir.parent.stat().st_mode % 0o1000 == default_permissions",
      "744:             _change_directory_permissions_up(subdir, new_folder_permissions)",
      "745:             assert subdir.stat().st_mode % 0o1000 == new_folder_permissions",
      "746:             # now parent permissions are as per new_folder_permissions",
      "747:             assert subdir.parent.stat().st_mode % 0o1000 == new_folder_permissions",
      "748:         finally:",
      "749:             os.umask(old_umask)",
      "750:     finally:",
      "751:         shutil.rmtree(tmp_path)",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "76a701d804457b0718aae0d721dbd15e48ff0e0d",
      "candidate_info": {
        "commit_hash": "76a701d804457b0718aae0d721dbd15e48ff0e0d",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/76a701d804457b0718aae0d721dbd15e48ff0e0d",
        "files": [
          "airflow/utils/log/file_task_handler.py",
          "tests/utils/test_log_handlers.py"
        ],
        "message": "Fix permissions of parent folders for log file handler (#37310)\n\nWhen we created a new folder during log file handler directory creation\nwe did not change the permissions of parent folders.\n\nFixes: #37200\n(cherry picked from commit aae4a83cdfb3be4afeefd88a7bfa3c4d8d184958)",
        "before_after_code_files": [
          "airflow/utils/log/file_task_handler.py||airflow/utils/log/file_task_handler.py",
          "tests/utils/test_log_handlers.py||tests/utils/test_log_handlers.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_cherry_pick": 1,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "airflow/utils/log/file_task_handler.py||airflow/utils/log/file_task_handler.py",
            "tests/utils/test_log_handlers.py||tests/utils/test_log_handlers.py"
          ],
          "candidate": [
            "airflow/utils/log/file_task_handler.py||airflow/utils/log/file_task_handler.py",
            "tests/utils/test_log_handlers.py||tests/utils/test_log_handlers.py"
          ]
        }
      },
      "candidate_diff": {
        "airflow/utils/log/file_task_handler.py||airflow/utils/log/file_task_handler.py": [
          "File: airflow/utils/log/file_task_handler.py -> airflow/utils/log/file_task_handler.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "159:         raise AirflowException(f\"Could not find TaskInstance for {ti}\")",
          "162: class FileTaskHandler(logging.Handler):",
          "163:     \"\"\"",
          "164:     FileTaskHandler is a python log handler that handles and reads task instance logs.",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "162: def _change_directory_permissions_up(directory: Path, folder_permissions: int):",
          "163:     \"\"\"",
          "164:     Change permissions of the given directory and its parents.",
          "166:     Only attempt to change permissions for directories owned by the current user.",
          "168:     :param directory: directory to change permissions of (including parents)",
          "169:     :param folder_permissions: permissions to set",
          "170:     \"\"\"",
          "171:     if directory.stat().st_uid == os.getuid():",
          "172:         if directory.stat().st_mode % 0o1000 != folder_permissions % 0o1000:",
          "173:             print(f\"Changing {directory} permission to {folder_permissions}\")",
          "174:             try:",
          "175:                 directory.chmod(folder_permissions)",
          "176:             except PermissionError as e:",
          "177:                 # In some circumstances (depends on user and filesystem) we might not be able to",
          "178:                 # change the permission for the folder (when the folder was created by another user",
          "179:                 # before or when the filesystem does not allow to change permission). We should not",
          "180:                 # fail in this case but rather ignore it.",
          "181:                 print(f\"Failed to change {directory} permission to {folder_permissions}: {e}\")",
          "182:                 return",
          "183:         if directory.parent != directory:",
          "184:             _change_directory_permissions_up(directory.parent, folder_permissions)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "484:             conf.get(\"logging\", \"file_task_handler_new_folder_permissions\", fallback=\"0o775\"), 8",
          "485:         )",
          "486:         directory.mkdir(mode=new_folder_permissions, parents=True, exist_ok=True)",
          "499:     def _init_file(self, ti, *, identifier: str | None = None):",
          "500:         \"\"\"",
          "",
          "[Removed Lines]",
          "487:         if directory.stat().st_mode % 0o1000 != new_folder_permissions % 0o1000:",
          "488:             print(f\"Changing {directory} permission to {new_folder_permissions}\")",
          "489:             try:",
          "490:                 directory.chmod(new_folder_permissions)",
          "491:             except PermissionError as e:",
          "492:                 # In some circumstances (depends on user and filesystem) we might not be able to",
          "493:                 # change the permission for the folder (when the folder was created by another user",
          "494:                 # before or when the filesystem does not allow to change permission). We should not",
          "495:                 # fail in this case but rather ignore it.",
          "496:                 print(f\"Failed to change {directory} permission to {new_folder_permissions}: {e}\")",
          "497:                 pass",
          "",
          "[Added Lines]",
          "512:         _change_directory_permissions_up(directory, new_folder_permissions)",
          "",
          "---------------"
        ],
        "tests/utils/test_log_handlers.py||tests/utils/test_log_handlers.py": [
          "File: tests/utils/test_log_handlers.py -> tests/utils/test_log_handlers.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: import logging.config",
          "22: import os",
          "23: import re",
          "24: from pathlib import Path",
          "25: from unittest import mock",
          "26: from unittest.mock import patch",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "24: import shutil",
          "25: import tempfile",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "40: from airflow.utils.log.file_task_handler import (",
          "41:     FileTaskHandler,",
          "42:     LogType,",
          "43:     _interleave_logs,",
          "44:     _parse_timestamps_in_log_file,",
          "45: )",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "45:     _change_directory_permissions_up,",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "719:     \"\"\"",
          "721:     assert sample_with_dupe == \"\\n\".join(_interleave_logs(sample_with_dupe, \"\", sample_with_dupe))",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "727: def test_permissions_for_new_directories():",
          "728:     tmp_path = Path(tempfile.mkdtemp())",
          "729:     try:",
          "730:         # Set umask to 0o027: owner rwx, group rx-w, other -rwx",
          "731:         old_umask = os.umask(0o027)",
          "732:         try:",
          "733:             subdir = tmp_path / \"subdir1\" / \"subdir2\"",
          "734:             # force permissions for the new folder to be owner rwx, group -rxw, other -rwx",
          "735:             new_folder_permissions = 0o700",
          "736:             # default permissions are owner rwx, group rx-w, other -rwx (umask bit negative)",
          "737:             default_permissions = 0o750",
          "738:             subdir.mkdir(mode=new_folder_permissions, parents=True, exist_ok=True)",
          "739:             assert subdir.exists()",
          "740:             assert subdir.is_dir()",
          "741:             assert subdir.stat().st_mode % 0o1000 == new_folder_permissions",
          "742:             # initially parent permissions are as per umask",
          "743:             assert subdir.parent.stat().st_mode % 0o1000 == default_permissions",
          "744:             _change_directory_permissions_up(subdir, new_folder_permissions)",
          "745:             assert subdir.stat().st_mode % 0o1000 == new_folder_permissions",
          "746:             # now parent permissions are as per new_folder_permissions",
          "747:             assert subdir.parent.stat().st_mode % 0o1000 == new_folder_permissions",
          "748:         finally:",
          "749:             os.umask(old_umask)",
          "750:     finally:",
          "751:         shutil.rmtree(tmp_path)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "2660188559b5b2bf6781d8df1eae910c538d6bb1",
      "candidate_info": {
        "commit_hash": "2660188559b5b2bf6781d8df1eae910c538d6bb1",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/2660188559b5b2bf6781d8df1eae910c538d6bb1",
        "files": [
          "pyproject.toml",
          "tests/conftest.py",
          "tests/dag_processing/test_processor.py",
          "tests/utils/test_log_handlers.py"
        ],
        "message": "Disable support of a legacy `LocalPath` in favor of stdlib `pathlib.Path` (#38624)\n\n* Disable support of a legacy `LocalPath` in favor of stdlib `pathlib.Path`\n\n* Fixup tests which use tmpdir instead of tmp_path",
        "before_after_code_files": [
          "tests/conftest.py||tests/conftest.py",
          "tests/dag_processing/test_processor.py||tests/dag_processing/test_processor.py",
          "tests/utils/test_log_handlers.py||tests/utils/test_log_handlers.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "tests/utils/test_log_handlers.py||tests/utils/test_log_handlers.py"
          ],
          "candidate": [
            "tests/utils/test_log_handlers.py||tests/utils/test_log_handlers.py"
          ]
        }
      },
      "candidate_diff": {
        "tests/conftest.py||tests/conftest.py": [
          "File: tests/conftest.py -> tests/conftest.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1158: @pytest.fixture(autouse=True)",
          "1168:             f\"All test method files in tests/system must start with 'example_' or 'test_'. \"",
          "1170:             f\"Please rename the file to follow the example_* or test_* pattern if you want to run the tests \"",
          "1171:             f\"in it.\"",
          "1172:         )",
          "1177:             f\"follow the test_* pattern if you want to run the tests in it.\"",
          "1178:         )",
          "",
          "[Removed Lines]",
          "1159: def refuse_to_run_test_from_wrongly_named_files(request):",
          "1160:     dirname: str = request.node.fspath.dirname",
          "1161:     filename: str = request.node.fspath.basename",
          "1162:     is_system_test: bool = \"tests/system/\" in dirname",
          "1163:     if is_system_test and not (",
          "1164:         request.node.fspath.basename.startswith(\"example_\")",
          "1165:         or request.node.fspath.basename.startswith(\"test_\")",
          "1166:     ):",
          "1167:         raise Exception(",
          "1169:             f\"Seems that {filename} contains {request.function} that looks like a test case. \"",
          "1173:     if not is_system_test and not request.node.fspath.basename.startswith(\"test_\"):",
          "1174:         raise Exception(",
          "1175:             f\"All test method files in tests/ must start with 'test_'. Seems that {filename} \"",
          "1176:             f\"contains {request.function} that looks like a test case. Please rename the file to \"",
          "",
          "[Added Lines]",
          "1159: def refuse_to_run_test_from_wrongly_named_files(request: pytest.FixtureRequest):",
          "1160:     filepath = request.node.path",
          "1161:     is_system_test: bool = \"tests/system/\" in os.fspath(filepath.parent)",
          "1162:     test_name = request.node.name",
          "1163:     if request.node.cls:",
          "1164:         test_name = f\"{request.node.cls.__name__}.{test_name}\"",
          "1165:     if is_system_test and not filepath.name.startswith((\"example_\", \"test_\")):",
          "1166:         pytest.fail(",
          "1168:             f\"Seems that {os.fspath(filepath)!r} contains {test_name!r} that looks like a test case. \"",
          "1172:     elif not is_system_test and not filepath.name.startswith(\"test_\"):",
          "1173:         pytest.fail(",
          "1174:             f\"All test method files in tests/ must start with 'test_'. Seems that {os.fspath(filepath)!r} \"",
          "1175:             f\"contains {test_name!r} that looks like a test case. Please rename the file to \"",
          "",
          "---------------"
        ],
        "tests/dag_processing/test_processor.py||tests/dag_processing/test_processor.py": [
          "File: tests/dag_processing/test_processor.py -> tests/dag_processing/test_processor.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "597:         assert msg in callback_file.read_text()",
          "599:     @conf_vars({(\"core\", \"dagbag_import_error_tracebacks\"): \"False\"})",
          "602:         with open(unparseable_filename, \"w\") as unparseable_file:",
          "603:             unparseable_file.writelines(UNPARSEABLE_DAG_FILE_CONTENTS)",
          "605:         with create_session() as session:",
          "607:             import_errors = session.query(errors.ImportError).all()",
          "609:             assert len(import_errors) == 1",
          "",
          "[Removed Lines]",
          "600:     def test_add_unparseable_file_before_sched_start_creates_import_error(self, tmpdir):",
          "601:         unparseable_filename = os.path.join(tmpdir, TEMP_DAG_FILENAME)",
          "606:             self._process_file(unparseable_filename, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "600:     def test_add_unparseable_file_before_sched_start_creates_import_error(self, tmp_path):",
          "601:         unparseable_filename = tmp_path.joinpath(TEMP_DAG_FILENAME).as_posix()",
          "606:             self._process_file(unparseable_filename, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "613:             session.rollback()",
          "615:     @conf_vars({(\"core\", \"dagbag_import_error_tracebacks\"): \"False\"})",
          "618:         invalid_dag_filename = os.path.join(zip_filename, TEMP_DAG_FILENAME)",
          "619:         with ZipFile(zip_filename, \"w\") as zip_file:",
          "620:             zip_file.writestr(TEMP_DAG_FILENAME, UNPARSEABLE_DAG_FILE_CONTENTS)",
          "622:         with create_session() as session:",
          "624:             import_errors = session.query(errors.ImportError).all()",
          "626:             assert len(import_errors) == 1",
          "",
          "[Removed Lines]",
          "616:     def test_add_unparseable_zip_file_creates_import_error(self, tmpdir):",
          "617:         zip_filename = os.path.join(tmpdir, \"test_zip.zip\")",
          "623:             self._process_file(zip_filename, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "616:     def test_add_unparseable_zip_file_creates_import_error(self, tmp_path):",
          "617:         zip_filename = (tmp_path / \"test_zip.zip\").as_posix()",
          "623:             self._process_file(zip_filename, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "630:             session.rollback()",
          "632:     @conf_vars({(\"core\", \"dagbag_import_error_tracebacks\"): \"False\"})",
          "634:         dag_file = os.path.join(TEST_DAGS_FOLDER, \"test_example_bash_operator.py\")",
          "636:         with open(dag_file) as main_dag, open(temp_dagfile, \"w\") as next_dag:",
          "637:             for line in main_dag:",
          "638:                 next_dag.write(line)",
          "639:         # first we parse the dag",
          "641:         # assert DagModel.has_import_errors is false",
          "642:         dm = session.query(DagModel).filter(DagModel.fileloc == temp_dagfile).first()",
          "643:         assert not dm.has_import_errors",
          "",
          "[Removed Lines]",
          "633:     def test_dag_model_has_import_error_is_true_when_import_error_exists(self, tmpdir, session):",
          "635:         temp_dagfile = os.path.join(tmpdir, TEMP_DAG_FILENAME)",
          "640:         self._process_file(temp_dagfile, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "633:     def test_dag_model_has_import_error_is_true_when_import_error_exists(self, tmp_path, session):",
          "635:         temp_dagfile = tmp_path.joinpath(TEMP_DAG_FILENAME).as_posix()",
          "640:         self._process_file(temp_dagfile, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "645:         with open(temp_dagfile, \"a\") as file:",
          "646:             file.writelines(UNPARSEABLE_DAG_FILE_CONTENTS)",
          "649:         import_errors = session.query(errors.ImportError).all()",
          "651:         assert len(import_errors) == 1",
          "",
          "[Removed Lines]",
          "648:         self._process_file(temp_dagfile, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "648:         self._process_file(temp_dagfile, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "655:         dm = session.query(DagModel).filter(DagModel.fileloc == temp_dagfile).first()",
          "656:         assert dm.has_import_errors",
          "664:         with create_session() as session:",
          "666:             import_errors = session.query(errors.ImportError).all()",
          "668:             assert len(import_errors) == 0",
          "670:             session.rollback()",
          "674:         with ZipFile(zip_filename, \"w\") as zip_file:",
          "675:             zip_file.writestr(TEMP_DAG_FILENAME, PARSEABLE_DAG_FILE_CONTENTS)",
          "677:         with create_session() as session:",
          "679:             import_errors = session.query(errors.ImportError).all()",
          "681:             assert len(import_errors) == 0",
          "",
          "[Removed Lines]",
          "658:     def test_no_import_errors_with_parseable_dag(self, tmpdir):",
          "659:         parseable_filename = os.path.join(tmpdir, TEMP_DAG_FILENAME)",
          "661:         with open(parseable_filename, \"w\") as parseable_file:",
          "662:             parseable_file.writelines(PARSEABLE_DAG_FILE_CONTENTS)",
          "665:             self._process_file(parseable_filename, dag_directory=tmpdir, session=session)",
          "672:     def test_no_import_errors_with_parseable_dag_in_zip(self, tmpdir):",
          "673:         zip_filename = os.path.join(tmpdir, \"test_zip.zip\")",
          "678:             self._process_file(zip_filename, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "658:     def test_no_import_errors_with_parseable_dag(self, tmp_path):",
          "659:         parseable_filename = tmp_path / TEMP_DAG_FILENAME",
          "660:         parseable_filename.write_text(PARSEABLE_DAG_FILE_CONTENTS)",
          "663:             self._process_file(parseable_filename.as_posix(), dag_directory=tmp_path, session=session)",
          "670:     def test_no_import_errors_with_parseable_dag_in_zip(self, tmp_path):",
          "671:         zip_filename = (tmp_path / \"test_zip.zip\").as_posix()",
          "676:             self._process_file(zip_filename, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "683:             session.rollback()",
          "685:     @conf_vars({(\"core\", \"dagbag_import_error_tracebacks\"): \"False\"})",
          "689:         # Generate original import error",
          "692:         session = settings.Session()",
          "695:         # Generate replacement import error (the error will be on the second line now)",
          "702:         import_errors = session.query(errors.ImportError).all()",
          "704:         assert len(import_errors) == 1",
          "705:         import_error = import_errors[0]",
          "707:         assert import_error.stacktrace == f\"invalid syntax ({TEMP_DAG_FILENAME}, line 2)\"",
          "709:         session.rollback()",
          "712:         \"\"\"",
          "713:         Test that existing import error is updated and new record not created",
          "714:         for a dag with the same filename",
          "715:         \"\"\"",
          "718:         # Generate original import error",
          "719:         with open(filename_to_parse, \"w\") as file_to_parse:",
          "720:             file_to_parse.writelines(UNPARSEABLE_DAG_FILE_CONTENTS)",
          "721:         session = settings.Session()",
          "724:         import_error_1 = (",
          "725:             session.query(errors.ImportError).filter(errors.ImportError.filename == filename_to_parse).one()",
          "",
          "[Removed Lines]",
          "686:     def test_new_import_error_replaces_old(self, tmpdir):",
          "687:         unparseable_filename = os.path.join(tmpdir, TEMP_DAG_FILENAME)",
          "690:         with open(unparseable_filename, \"w\") as unparseable_file:",
          "691:             unparseable_file.writelines(UNPARSEABLE_DAG_FILE_CONTENTS)",
          "693:         self._process_file(unparseable_filename, dag_directory=tmpdir, session=session)",
          "696:         with open(unparseable_filename, \"w\") as unparseable_file:",
          "697:             unparseable_file.writelines(",
          "698:                 PARSEABLE_DAG_FILE_CONTENTS + os.linesep + UNPARSEABLE_DAG_FILE_CONTENTS",
          "699:             )",
          "700:         self._process_file(unparseable_filename, dag_directory=tmpdir, session=session)",
          "706:         assert import_error.filename == unparseable_filename",
          "711:     def test_import_error_record_is_updated_not_deleted_and_recreated(self, tmpdir):",
          "716:         filename_to_parse = os.path.join(tmpdir, TEMP_DAG_FILENAME)",
          "722:         self._process_file(filename_to_parse, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "684:     def test_new_import_error_replaces_old(self, tmp_path):",
          "685:         unparseable_filename = tmp_path / TEMP_DAG_FILENAME",
          "687:         unparseable_filename.write_text(UNPARSEABLE_DAG_FILE_CONTENTS)",
          "690:         self._process_file(unparseable_filename.as_posix(), dag_directory=tmp_path, session=session)",
          "693:         unparseable_filename.write_text(",
          "694:             PARSEABLE_DAG_FILE_CONTENTS + os.linesep + UNPARSEABLE_DAG_FILE_CONTENTS",
          "695:         )",
          "696:         self._process_file(unparseable_filename.as_posix(), dag_directory=tmp_path, session=session)",
          "702:         assert import_error.filename == unparseable_filename.as_posix()",
          "707:     def test_import_error_record_is_updated_not_deleted_and_recreated(self, tmp_path):",
          "712:         filename_to_parse = tmp_path.joinpath(TEMP_DAG_FILENAME).as_posix()",
          "717:         self._process_file(filename_to_parse, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "728:         # process the file multiple times",
          "729:         for _ in range(10):",
          "732:         import_error_2 = (",
          "733:             session.query(errors.ImportError).filter(errors.ImportError.filename == filename_to_parse).one()",
          "",
          "[Removed Lines]",
          "730:             self._process_file(filename_to_parse, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "725:             self._process_file(filename_to_parse, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "736:         # assert that the ID of the import error did not change",
          "737:         assert import_error_1.id == import_error_2.id",
          "742:         # Generate original import error",
          "743:         with open(filename_to_parse, \"w\") as file_to_parse:",
          "744:             file_to_parse.writelines(UNPARSEABLE_DAG_FILE_CONTENTS)",
          "745:         session = settings.Session()",
          "748:         # Remove the import error from the file",
          "749:         with open(filename_to_parse, \"w\") as file_to_parse:",
          "750:             file_to_parse.writelines(PARSEABLE_DAG_FILE_CONTENTS)",
          "753:         import_errors = session.query(errors.ImportError).all()",
          "",
          "[Removed Lines]",
          "739:     def test_remove_error_clears_import_error(self, tmpdir):",
          "740:         filename_to_parse = os.path.join(tmpdir, TEMP_DAG_FILENAME)",
          "746:         self._process_file(filename_to_parse, dag_directory=tmpdir, session=session)",
          "751:         self._process_file(filename_to_parse, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "734:     def test_remove_error_clears_import_error(self, tmp_path):",
          "735:         filename_to_parse = tmp_path.joinpath(TEMP_DAG_FILENAME).as_posix()",
          "741:         self._process_file(filename_to_parse, dag_directory=tmp_path, session=session)",
          "746:         self._process_file(filename_to_parse, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "757:         session.rollback()",
          "760:         session = settings.Session()",
          "762:         # Generate original import error",
          "764:         with ZipFile(zip_filename, \"w\") as zip_file:",
          "765:             zip_file.writestr(TEMP_DAG_FILENAME, UNPARSEABLE_DAG_FILE_CONTENTS)",
          "768:         import_errors = session.query(errors.ImportError).all()",
          "769:         assert len(import_errors) == 1",
          "",
          "[Removed Lines]",
          "759:     def test_remove_error_clears_import_error_zip(self, tmpdir):",
          "763:         zip_filename = os.path.join(tmpdir, \"test_zip.zip\")",
          "766:         self._process_file(zip_filename, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "754:     def test_remove_error_clears_import_error_zip(self, tmp_path):",
          "758:         zip_filename = (tmp_path / \"test_zip.zip\").as_posix()",
          "761:         self._process_file(zip_filename, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "771:         # Remove the import error from the file",
          "772:         with ZipFile(zip_filename, \"w\") as zip_file:",
          "773:             zip_file.writestr(TEMP_DAG_FILENAME, \"import os # airflow DAG\")",
          "776:         import_errors = session.query(errors.ImportError).all()",
          "777:         assert len(import_errors) == 0",
          "779:         session.rollback()",
          "783:         with open(unparseable_filename, \"w\") as unparseable_file:",
          "784:             unparseable_file.writelines(INVALID_DAG_WITH_DEPTH_FILE_CONTENTS)",
          "786:         with create_session() as session:",
          "788:             import_errors = session.query(errors.ImportError).all()",
          "790:             assert len(import_errors) == 1",
          "",
          "[Removed Lines]",
          "774:         self._process_file(zip_filename, dag_directory=tmpdir, session=session)",
          "781:     def test_import_error_tracebacks(self, tmpdir):",
          "782:         unparseable_filename = os.path.join(tmpdir, TEMP_DAG_FILENAME)",
          "787:             self._process_file(unparseable_filename, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "769:         self._process_file(zip_filename, dag_directory=tmp_path, session=session)",
          "776:     def test_import_error_tracebacks(self, tmp_path):",
          "777:         unparseable_filename = (tmp_path / TEMP_DAG_FILENAME).as_posix()",
          "782:             self._process_file(unparseable_filename, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "815:             session.rollback()",
          "817:     @conf_vars({(\"core\", \"dagbag_import_error_traceback_depth\"): \"1\"})",
          "820:         with open(unparseable_filename, \"w\") as unparseable_file:",
          "821:             unparseable_file.writelines(INVALID_DAG_WITH_DEPTH_FILE_CONTENTS)",
          "823:         with create_session() as session:",
          "825:             import_errors = session.query(errors.ImportError).all()",
          "827:             assert len(import_errors) == 1",
          "",
          "[Removed Lines]",
          "818:     def test_import_error_traceback_depth(self, tmpdir):",
          "819:         unparseable_filename = os.path.join(tmpdir, TEMP_DAG_FILENAME)",
          "824:             self._process_file(unparseable_filename, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "813:     def test_import_error_traceback_depth(self, tmp_path):",
          "814:         unparseable_filename = tmp_path.joinpath(TEMP_DAG_FILENAME).as_posix()",
          "819:             self._process_file(unparseable_filename, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "847:             session.rollback()",
          "851:         invalid_dag_filename = os.path.join(invalid_zip_filename, TEMP_DAG_FILENAME)",
          "852:         with ZipFile(invalid_zip_filename, \"w\") as invalid_zip_file:",
          "853:             invalid_zip_file.writestr(TEMP_DAG_FILENAME, INVALID_DAG_WITH_DEPTH_FILE_CONTENTS)",
          "855:         with create_session() as session:",
          "857:             import_errors = session.query(errors.ImportError).all()",
          "859:             assert len(import_errors) == 1",
          "",
          "[Removed Lines]",
          "849:     def test_import_error_tracebacks_zip(self, tmpdir):",
          "850:         invalid_zip_filename = os.path.join(tmpdir, \"test_zip_invalid.zip\")",
          "856:             self._process_file(invalid_zip_filename, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "844:     def test_import_error_tracebacks_zip(self, tmp_path):",
          "845:         invalid_zip_filename = (tmp_path / \"test_zip_invalid.zip\").as_posix()",
          "851:             self._process_file(invalid_zip_filename, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "884:             session.rollback()",
          "886:     @conf_vars({(\"core\", \"dagbag_import_error_traceback_depth\"): \"1\"})",
          "889:         invalid_dag_filename = os.path.join(invalid_zip_filename, TEMP_DAG_FILENAME)",
          "890:         with ZipFile(invalid_zip_filename, \"w\") as invalid_zip_file:",
          "891:             invalid_zip_file.writestr(TEMP_DAG_FILENAME, INVALID_DAG_WITH_DEPTH_FILE_CONTENTS)",
          "893:         with create_session() as session:",
          "895:             import_errors = session.query(errors.ImportError).all()",
          "897:             assert len(import_errors) == 1",
          "",
          "[Removed Lines]",
          "887:     def test_import_error_tracebacks_zip_depth(self, tmpdir):",
          "888:         invalid_zip_filename = os.path.join(tmpdir, \"test_zip_invalid.zip\")",
          "894:             self._process_file(invalid_zip_filename, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "882:     def test_import_error_tracebacks_zip_depth(self, tmp_path):",
          "883:         invalid_zip_filename = (tmp_path / \"test_zip_invalid.zip\").as_posix()",
          "889:             self._process_file(invalid_zip_filename, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 14 ---",
          "[Context before]",
          "964:     @mock.patch(\"airflow.dag_processing.processor.settings.dispose_orm\", MagicMock)",
          "965:     @mock.patch.object(DagFileProcessorProcess, \"_get_multiprocessing_context\")",
          "967:         mock_context.return_value.Pipe.return_value = (MagicMock(), MagicMock())",
          "969:         with ZipFile(zip_filename, \"w\") as zip_file:",
          "970:             zip_file.writestr(TEMP_DAG_FILENAME, PARSEABLE_DAG_FILE_CONTENTS)",
          "",
          "[Removed Lines]",
          "966:     def test_no_valueerror_with_parseable_dag_in_zip(self, mock_context, tmpdir):",
          "968:         zip_filename = os.path.join(tmpdir, \"test_zip.zip\")",
          "",
          "[Added Lines]",
          "961:     def test_no_valueerror_with_parseable_dag_in_zip(self, mock_context, tmp_path):",
          "963:         zip_filename = (tmp_path / \"test_zip.zip\").as_posix()",
          "",
          "---------------",
          "--- Hunk 15 ---",
          "[Context before]",
          "981:     @mock.patch(\"airflow.dag_processing.processor.settings.dispose_orm\", MagicMock)",
          "982:     @mock.patch.object(DagFileProcessorProcess, \"_get_multiprocessing_context\")",
          "984:         mock_context.return_value.Pipe.return_value = (MagicMock(), MagicMock())",
          "986:         with open(dag_filename, \"wb\") as file:",
          "987:             file.write(b\"hello\\x00world\")",
          "",
          "[Removed Lines]",
          "983:     def test_nullbyte_exception_handling_when_preimporting_airflow(self, mock_context, tmpdir):",
          "985:         dag_filename = os.path.join(tmpdir, \"test_dag.py\")",
          "",
          "[Added Lines]",
          "978:     def test_nullbyte_exception_handling_when_preimporting_airflow(self, mock_context, tmp_path):",
          "980:         dag_filename = (tmp_path / \"test_dag.py\").as_posix()",
          "",
          "---------------"
        ],
        "tests/utils/test_log_handlers.py||tests/utils/test_log_handlers.py": [
          "File: tests/utils/test_log_handlers.py -> tests/utils/test_log_handlers.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: import logging.config",
          "22: import os",
          "23: import re",
          "25: from importlib import reload",
          "26: from pathlib import Path",
          "27: from unittest import mock",
          "",
          "[Removed Lines]",
          "24: import shutil",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "728:     assert sample_with_dupe == \"\\n\".join(_interleave_logs(sample_with_dupe, \"\", sample_with_dupe))",
          "733:     try:",
          "752:     finally:",
          "",
          "[Removed Lines]",
          "731: def test_permissions_for_new_directories(tmpdir):",
          "732:     tmpdir_path = Path(tmpdir)",
          "734:         # Set umask to 0o027: owner rwx, group rx-w, other -rwx",
          "735:         old_umask = os.umask(0o027)",
          "736:         try:",
          "737:             base_dir = tmpdir_path / \"base\"",
          "738:             base_dir.mkdir()",
          "739:             log_dir = base_dir / \"subdir1\" / \"subdir2\"",
          "740:             # force permissions for the new folder to be owner rwx, group -rxw, other -rwx",
          "741:             new_folder_permissions = 0o700",
          "742:             # default permissions are owner rwx, group rx-w, other -rwx (umask bit negative)",
          "743:             default_permissions = 0o750",
          "744:             FileTaskHandler._prepare_log_folder(log_dir, new_folder_permissions)",
          "745:             assert log_dir.exists()",
          "746:             assert log_dir.is_dir()",
          "747:             assert log_dir.stat().st_mode % 0o1000 == new_folder_permissions",
          "748:             assert log_dir.parent.stat().st_mode % 0o1000 == new_folder_permissions",
          "749:             assert base_dir.stat().st_mode % 0o1000 == default_permissions",
          "750:         finally:",
          "751:             os.umask(old_umask)",
          "753:         shutil.rmtree(tmpdir_path)",
          "",
          "[Added Lines]",
          "730: def test_permissions_for_new_directories(tmp_path):",
          "731:     # Set umask to 0o027: owner rwx, group rx-w, other -rwx",
          "732:     old_umask = os.umask(0o027)",
          "734:         base_dir = tmp_path / \"base\"",
          "735:         base_dir.mkdir()",
          "736:         log_dir = base_dir / \"subdir1\" / \"subdir2\"",
          "737:         # force permissions for the new folder to be owner rwx, group -rxw, other -rwx",
          "738:         new_folder_permissions = 0o700",
          "739:         # default permissions are owner rwx, group rx-w, other -rwx (umask bit negative)",
          "740:         default_permissions = 0o750",
          "741:         FileTaskHandler._prepare_log_folder(log_dir, new_folder_permissions)",
          "742:         assert log_dir.exists()",
          "743:         assert log_dir.is_dir()",
          "744:         assert log_dir.stat().st_mode % 0o1000 == new_folder_permissions",
          "745:         assert log_dir.parent.stat().st_mode % 0o1000 == new_folder_permissions",
          "746:         assert base_dir.stat().st_mode % 0o1000 == default_permissions",
          "748:         os.umask(old_umask)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "5cc3dc85c35a15968ad8a53ed6911a7eb6753772",
      "candidate_info": {
        "commit_hash": "5cc3dc85c35a15968ad8a53ed6911a7eb6753772",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/5cc3dc85c35a15968ad8a53ed6911a7eb6753772",
        "files": [
          "pyproject.toml",
          "tests/conftest.py",
          "tests/dag_processing/test_processor.py",
          "tests/utils/test_log_handlers.py"
        ],
        "message": "Disable support of a legacy `LocalPath` in favor of stdlib `pathlib.Path` (#38624)\n\n* Disable support of a legacy `LocalPath` in favor of stdlib `pathlib.Path`\n\n* Fixup tests which use tmpdir instead of tmp_path\n\n(cherry picked from commit 2660188559b5b2bf6781d8df1eae910c538d6bb1)",
        "before_after_code_files": [
          "tests/conftest.py||tests/conftest.py",
          "tests/dag_processing/test_processor.py||tests/dag_processing/test_processor.py",
          "tests/utils/test_log_handlers.py||tests/utils/test_log_handlers.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "tests/utils/test_log_handlers.py||tests/utils/test_log_handlers.py"
          ],
          "candidate": [
            "tests/utils/test_log_handlers.py||tests/utils/test_log_handlers.py"
          ]
        }
      },
      "candidate_diff": {
        "tests/conftest.py||tests/conftest.py": [
          "File: tests/conftest.py -> tests/conftest.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1158: @pytest.fixture(autouse=True)",
          "1168:             f\"All test method files in tests/system must start with 'example_' or 'test_'. \"",
          "1170:             f\"Please rename the file to follow the example_* or test_* pattern if you want to run the tests \"",
          "1171:             f\"in it.\"",
          "1172:         )",
          "1177:             f\"follow the test_* pattern if you want to run the tests in it.\"",
          "1178:         )",
          "",
          "[Removed Lines]",
          "1159: def refuse_to_run_test_from_wrongly_named_files(request):",
          "1160:     dirname: str = request.node.fspath.dirname",
          "1161:     filename: str = request.node.fspath.basename",
          "1162:     is_system_test: bool = \"tests/system/\" in dirname",
          "1163:     if is_system_test and not (",
          "1164:         request.node.fspath.basename.startswith(\"example_\")",
          "1165:         or request.node.fspath.basename.startswith(\"test_\")",
          "1166:     ):",
          "1167:         raise Exception(",
          "1169:             f\"Seems that {filename} contains {request.function} that looks like a test case. \"",
          "1173:     if not is_system_test and not request.node.fspath.basename.startswith(\"test_\"):",
          "1174:         raise Exception(",
          "1175:             f\"All test method files in tests/ must start with 'test_'. Seems that {filename} \"",
          "1176:             f\"contains {request.function} that looks like a test case. Please rename the file to \"",
          "",
          "[Added Lines]",
          "1159: def refuse_to_run_test_from_wrongly_named_files(request: pytest.FixtureRequest):",
          "1160:     filepath = request.node.path",
          "1161:     is_system_test: bool = \"tests/system/\" in os.fspath(filepath.parent)",
          "1162:     test_name = request.node.name",
          "1163:     if request.node.cls:",
          "1164:         test_name = f\"{request.node.cls.__name__}.{test_name}\"",
          "1165:     if is_system_test and not filepath.name.startswith((\"example_\", \"test_\")):",
          "1166:         pytest.fail(",
          "1168:             f\"Seems that {os.fspath(filepath)!r} contains {test_name!r} that looks like a test case. \"",
          "1172:     elif not is_system_test and not filepath.name.startswith(\"test_\"):",
          "1173:         pytest.fail(",
          "1174:             f\"All test method files in tests/ must start with 'test_'. Seems that {os.fspath(filepath)!r} \"",
          "1175:             f\"contains {test_name!r} that looks like a test case. Please rename the file to \"",
          "",
          "---------------"
        ],
        "tests/dag_processing/test_processor.py||tests/dag_processing/test_processor.py": [
          "File: tests/dag_processing/test_processor.py -> tests/dag_processing/test_processor.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "597:         assert msg in callback_file.read_text()",
          "599:     @conf_vars({(\"core\", \"dagbag_import_error_tracebacks\"): \"False\"})",
          "602:         with open(unparseable_filename, \"w\") as unparseable_file:",
          "603:             unparseable_file.writelines(UNPARSEABLE_DAG_FILE_CONTENTS)",
          "605:         with create_session() as session:",
          "607:             import_errors = session.query(errors.ImportError).all()",
          "609:             assert len(import_errors) == 1",
          "",
          "[Removed Lines]",
          "600:     def test_add_unparseable_file_before_sched_start_creates_import_error(self, tmpdir):",
          "601:         unparseable_filename = os.path.join(tmpdir, TEMP_DAG_FILENAME)",
          "606:             self._process_file(unparseable_filename, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "600:     def test_add_unparseable_file_before_sched_start_creates_import_error(self, tmp_path):",
          "601:         unparseable_filename = tmp_path.joinpath(TEMP_DAG_FILENAME).as_posix()",
          "606:             self._process_file(unparseable_filename, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "613:             session.rollback()",
          "615:     @conf_vars({(\"core\", \"dagbag_import_error_tracebacks\"): \"False\"})",
          "618:         invalid_dag_filename = os.path.join(zip_filename, TEMP_DAG_FILENAME)",
          "619:         with ZipFile(zip_filename, \"w\") as zip_file:",
          "620:             zip_file.writestr(TEMP_DAG_FILENAME, UNPARSEABLE_DAG_FILE_CONTENTS)",
          "622:         with create_session() as session:",
          "624:             import_errors = session.query(errors.ImportError).all()",
          "626:             assert len(import_errors) == 1",
          "",
          "[Removed Lines]",
          "616:     def test_add_unparseable_zip_file_creates_import_error(self, tmpdir):",
          "617:         zip_filename = os.path.join(tmpdir, \"test_zip.zip\")",
          "623:             self._process_file(zip_filename, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "616:     def test_add_unparseable_zip_file_creates_import_error(self, tmp_path):",
          "617:         zip_filename = (tmp_path / \"test_zip.zip\").as_posix()",
          "623:             self._process_file(zip_filename, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "630:             session.rollback()",
          "632:     @conf_vars({(\"core\", \"dagbag_import_error_tracebacks\"): \"False\"})",
          "634:         dag_file = os.path.join(TEST_DAGS_FOLDER, \"test_example_bash_operator.py\")",
          "636:         with open(dag_file) as main_dag, open(temp_dagfile, \"w\") as next_dag:",
          "637:             for line in main_dag:",
          "638:                 next_dag.write(line)",
          "639:         # first we parse the dag",
          "641:         # assert DagModel.has_import_errors is false",
          "642:         dm = session.query(DagModel).filter(DagModel.fileloc == temp_dagfile).first()",
          "643:         assert not dm.has_import_errors",
          "",
          "[Removed Lines]",
          "633:     def test_dag_model_has_import_error_is_true_when_import_error_exists(self, tmpdir, session):",
          "635:         temp_dagfile = os.path.join(tmpdir, TEMP_DAG_FILENAME)",
          "640:         self._process_file(temp_dagfile, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "633:     def test_dag_model_has_import_error_is_true_when_import_error_exists(self, tmp_path, session):",
          "635:         temp_dagfile = tmp_path.joinpath(TEMP_DAG_FILENAME).as_posix()",
          "640:         self._process_file(temp_dagfile, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "645:         with open(temp_dagfile, \"a\") as file:",
          "646:             file.writelines(UNPARSEABLE_DAG_FILE_CONTENTS)",
          "649:         import_errors = session.query(errors.ImportError).all()",
          "651:         assert len(import_errors) == 1",
          "",
          "[Removed Lines]",
          "648:         self._process_file(temp_dagfile, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "648:         self._process_file(temp_dagfile, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "655:         dm = session.query(DagModel).filter(DagModel.fileloc == temp_dagfile).first()",
          "656:         assert dm.has_import_errors",
          "664:         with create_session() as session:",
          "666:             import_errors = session.query(errors.ImportError).all()",
          "668:             assert len(import_errors) == 0",
          "670:             session.rollback()",
          "674:         with ZipFile(zip_filename, \"w\") as zip_file:",
          "675:             zip_file.writestr(TEMP_DAG_FILENAME, PARSEABLE_DAG_FILE_CONTENTS)",
          "677:         with create_session() as session:",
          "679:             import_errors = session.query(errors.ImportError).all()",
          "681:             assert len(import_errors) == 0",
          "",
          "[Removed Lines]",
          "658:     def test_no_import_errors_with_parseable_dag(self, tmpdir):",
          "659:         parseable_filename = os.path.join(tmpdir, TEMP_DAG_FILENAME)",
          "661:         with open(parseable_filename, \"w\") as parseable_file:",
          "662:             parseable_file.writelines(PARSEABLE_DAG_FILE_CONTENTS)",
          "665:             self._process_file(parseable_filename, dag_directory=tmpdir, session=session)",
          "672:     def test_no_import_errors_with_parseable_dag_in_zip(self, tmpdir):",
          "673:         zip_filename = os.path.join(tmpdir, \"test_zip.zip\")",
          "678:             self._process_file(zip_filename, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "658:     def test_no_import_errors_with_parseable_dag(self, tmp_path):",
          "659:         parseable_filename = tmp_path / TEMP_DAG_FILENAME",
          "660:         parseable_filename.write_text(PARSEABLE_DAG_FILE_CONTENTS)",
          "663:             self._process_file(parseable_filename.as_posix(), dag_directory=tmp_path, session=session)",
          "670:     def test_no_import_errors_with_parseable_dag_in_zip(self, tmp_path):",
          "671:         zip_filename = (tmp_path / \"test_zip.zip\").as_posix()",
          "676:             self._process_file(zip_filename, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "683:             session.rollback()",
          "685:     @conf_vars({(\"core\", \"dagbag_import_error_tracebacks\"): \"False\"})",
          "689:         # Generate original import error",
          "692:         session = settings.Session()",
          "695:         # Generate replacement import error (the error will be on the second line now)",
          "702:         import_errors = session.query(errors.ImportError).all()",
          "704:         assert len(import_errors) == 1",
          "705:         import_error = import_errors[0]",
          "707:         assert import_error.stacktrace == f\"invalid syntax ({TEMP_DAG_FILENAME}, line 2)\"",
          "709:         session.rollback()",
          "712:         \"\"\"",
          "713:         Test that existing import error is updated and new record not created",
          "714:         for a dag with the same filename",
          "715:         \"\"\"",
          "718:         # Generate original import error",
          "719:         with open(filename_to_parse, \"w\") as file_to_parse:",
          "720:             file_to_parse.writelines(UNPARSEABLE_DAG_FILE_CONTENTS)",
          "721:         session = settings.Session()",
          "724:         import_error_1 = (",
          "725:             session.query(errors.ImportError).filter(errors.ImportError.filename == filename_to_parse).one()",
          "",
          "[Removed Lines]",
          "686:     def test_new_import_error_replaces_old(self, tmpdir):",
          "687:         unparseable_filename = os.path.join(tmpdir, TEMP_DAG_FILENAME)",
          "690:         with open(unparseable_filename, \"w\") as unparseable_file:",
          "691:             unparseable_file.writelines(UNPARSEABLE_DAG_FILE_CONTENTS)",
          "693:         self._process_file(unparseable_filename, dag_directory=tmpdir, session=session)",
          "696:         with open(unparseable_filename, \"w\") as unparseable_file:",
          "697:             unparseable_file.writelines(",
          "698:                 PARSEABLE_DAG_FILE_CONTENTS + os.linesep + UNPARSEABLE_DAG_FILE_CONTENTS",
          "699:             )",
          "700:         self._process_file(unparseable_filename, dag_directory=tmpdir, session=session)",
          "706:         assert import_error.filename == unparseable_filename",
          "711:     def test_import_error_record_is_updated_not_deleted_and_recreated(self, tmpdir):",
          "716:         filename_to_parse = os.path.join(tmpdir, TEMP_DAG_FILENAME)",
          "722:         self._process_file(filename_to_parse, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "684:     def test_new_import_error_replaces_old(self, tmp_path):",
          "685:         unparseable_filename = tmp_path / TEMP_DAG_FILENAME",
          "687:         unparseable_filename.write_text(UNPARSEABLE_DAG_FILE_CONTENTS)",
          "690:         self._process_file(unparseable_filename.as_posix(), dag_directory=tmp_path, session=session)",
          "693:         unparseable_filename.write_text(",
          "694:             PARSEABLE_DAG_FILE_CONTENTS + os.linesep + UNPARSEABLE_DAG_FILE_CONTENTS",
          "695:         )",
          "696:         self._process_file(unparseable_filename.as_posix(), dag_directory=tmp_path, session=session)",
          "702:         assert import_error.filename == unparseable_filename.as_posix()",
          "707:     def test_import_error_record_is_updated_not_deleted_and_recreated(self, tmp_path):",
          "712:         filename_to_parse = tmp_path.joinpath(TEMP_DAG_FILENAME).as_posix()",
          "717:         self._process_file(filename_to_parse, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "728:         # process the file multiple times",
          "729:         for _ in range(10):",
          "732:         import_error_2 = (",
          "733:             session.query(errors.ImportError).filter(errors.ImportError.filename == filename_to_parse).one()",
          "",
          "[Removed Lines]",
          "730:             self._process_file(filename_to_parse, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "725:             self._process_file(filename_to_parse, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "736:         # assert that the ID of the import error did not change",
          "737:         assert import_error_1.id == import_error_2.id",
          "742:         # Generate original import error",
          "743:         with open(filename_to_parse, \"w\") as file_to_parse:",
          "744:             file_to_parse.writelines(UNPARSEABLE_DAG_FILE_CONTENTS)",
          "745:         session = settings.Session()",
          "748:         # Remove the import error from the file",
          "749:         with open(filename_to_parse, \"w\") as file_to_parse:",
          "750:             file_to_parse.writelines(PARSEABLE_DAG_FILE_CONTENTS)",
          "753:         import_errors = session.query(errors.ImportError).all()",
          "",
          "[Removed Lines]",
          "739:     def test_remove_error_clears_import_error(self, tmpdir):",
          "740:         filename_to_parse = os.path.join(tmpdir, TEMP_DAG_FILENAME)",
          "746:         self._process_file(filename_to_parse, dag_directory=tmpdir, session=session)",
          "751:         self._process_file(filename_to_parse, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "734:     def test_remove_error_clears_import_error(self, tmp_path):",
          "735:         filename_to_parse = tmp_path.joinpath(TEMP_DAG_FILENAME).as_posix()",
          "741:         self._process_file(filename_to_parse, dag_directory=tmp_path, session=session)",
          "746:         self._process_file(filename_to_parse, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "757:         session.rollback()",
          "760:         session = settings.Session()",
          "762:         # Generate original import error",
          "764:         with ZipFile(zip_filename, \"w\") as zip_file:",
          "765:             zip_file.writestr(TEMP_DAG_FILENAME, UNPARSEABLE_DAG_FILE_CONTENTS)",
          "768:         import_errors = session.query(errors.ImportError).all()",
          "769:         assert len(import_errors) == 1",
          "",
          "[Removed Lines]",
          "759:     def test_remove_error_clears_import_error_zip(self, tmpdir):",
          "763:         zip_filename = os.path.join(tmpdir, \"test_zip.zip\")",
          "766:         self._process_file(zip_filename, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "754:     def test_remove_error_clears_import_error_zip(self, tmp_path):",
          "758:         zip_filename = (tmp_path / \"test_zip.zip\").as_posix()",
          "761:         self._process_file(zip_filename, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "771:         # Remove the import error from the file",
          "772:         with ZipFile(zip_filename, \"w\") as zip_file:",
          "773:             zip_file.writestr(TEMP_DAG_FILENAME, \"import os # airflow DAG\")",
          "776:         import_errors = session.query(errors.ImportError).all()",
          "777:         assert len(import_errors) == 0",
          "779:         session.rollback()",
          "783:         with open(unparseable_filename, \"w\") as unparseable_file:",
          "784:             unparseable_file.writelines(INVALID_DAG_WITH_DEPTH_FILE_CONTENTS)",
          "786:         with create_session() as session:",
          "788:             import_errors = session.query(errors.ImportError).all()",
          "790:             assert len(import_errors) == 1",
          "",
          "[Removed Lines]",
          "774:         self._process_file(zip_filename, dag_directory=tmpdir, session=session)",
          "781:     def test_import_error_tracebacks(self, tmpdir):",
          "782:         unparseable_filename = os.path.join(tmpdir, TEMP_DAG_FILENAME)",
          "787:             self._process_file(unparseable_filename, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "769:         self._process_file(zip_filename, dag_directory=tmp_path, session=session)",
          "776:     def test_import_error_tracebacks(self, tmp_path):",
          "777:         unparseable_filename = (tmp_path / TEMP_DAG_FILENAME).as_posix()",
          "782:             self._process_file(unparseable_filename, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "815:             session.rollback()",
          "817:     @conf_vars({(\"core\", \"dagbag_import_error_traceback_depth\"): \"1\"})",
          "820:         with open(unparseable_filename, \"w\") as unparseable_file:",
          "821:             unparseable_file.writelines(INVALID_DAG_WITH_DEPTH_FILE_CONTENTS)",
          "823:         with create_session() as session:",
          "825:             import_errors = session.query(errors.ImportError).all()",
          "827:             assert len(import_errors) == 1",
          "",
          "[Removed Lines]",
          "818:     def test_import_error_traceback_depth(self, tmpdir):",
          "819:         unparseable_filename = os.path.join(tmpdir, TEMP_DAG_FILENAME)",
          "824:             self._process_file(unparseable_filename, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "813:     def test_import_error_traceback_depth(self, tmp_path):",
          "814:         unparseable_filename = tmp_path.joinpath(TEMP_DAG_FILENAME).as_posix()",
          "819:             self._process_file(unparseable_filename, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "847:             session.rollback()",
          "851:         invalid_dag_filename = os.path.join(invalid_zip_filename, TEMP_DAG_FILENAME)",
          "852:         with ZipFile(invalid_zip_filename, \"w\") as invalid_zip_file:",
          "853:             invalid_zip_file.writestr(TEMP_DAG_FILENAME, INVALID_DAG_WITH_DEPTH_FILE_CONTENTS)",
          "855:         with create_session() as session:",
          "857:             import_errors = session.query(errors.ImportError).all()",
          "859:             assert len(import_errors) == 1",
          "",
          "[Removed Lines]",
          "849:     def test_import_error_tracebacks_zip(self, tmpdir):",
          "850:         invalid_zip_filename = os.path.join(tmpdir, \"test_zip_invalid.zip\")",
          "856:             self._process_file(invalid_zip_filename, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "844:     def test_import_error_tracebacks_zip(self, tmp_path):",
          "845:         invalid_zip_filename = (tmp_path / \"test_zip_invalid.zip\").as_posix()",
          "851:             self._process_file(invalid_zip_filename, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "884:             session.rollback()",
          "886:     @conf_vars({(\"core\", \"dagbag_import_error_traceback_depth\"): \"1\"})",
          "889:         invalid_dag_filename = os.path.join(invalid_zip_filename, TEMP_DAG_FILENAME)",
          "890:         with ZipFile(invalid_zip_filename, \"w\") as invalid_zip_file:",
          "891:             invalid_zip_file.writestr(TEMP_DAG_FILENAME, INVALID_DAG_WITH_DEPTH_FILE_CONTENTS)",
          "893:         with create_session() as session:",
          "895:             import_errors = session.query(errors.ImportError).all()",
          "897:             assert len(import_errors) == 1",
          "",
          "[Removed Lines]",
          "887:     def test_import_error_tracebacks_zip_depth(self, tmpdir):",
          "888:         invalid_zip_filename = os.path.join(tmpdir, \"test_zip_invalid.zip\")",
          "894:             self._process_file(invalid_zip_filename, dag_directory=tmpdir, session=session)",
          "",
          "[Added Lines]",
          "882:     def test_import_error_tracebacks_zip_depth(self, tmp_path):",
          "883:         invalid_zip_filename = (tmp_path / \"test_zip_invalid.zip\").as_posix()",
          "889:             self._process_file(invalid_zip_filename, dag_directory=tmp_path, session=session)",
          "",
          "---------------",
          "--- Hunk 14 ---",
          "[Context before]",
          "964:     @mock.patch(\"airflow.dag_processing.processor.settings.dispose_orm\", MagicMock)",
          "965:     @mock.patch.object(DagFileProcessorProcess, \"_get_multiprocessing_context\")",
          "967:         mock_context.return_value.Pipe.return_value = (MagicMock(), MagicMock())",
          "969:         with ZipFile(zip_filename, \"w\") as zip_file:",
          "970:             zip_file.writestr(TEMP_DAG_FILENAME, PARSEABLE_DAG_FILE_CONTENTS)",
          "",
          "[Removed Lines]",
          "966:     def test_no_valueerror_with_parseable_dag_in_zip(self, mock_context, tmpdir):",
          "968:         zip_filename = os.path.join(tmpdir, \"test_zip.zip\")",
          "",
          "[Added Lines]",
          "961:     def test_no_valueerror_with_parseable_dag_in_zip(self, mock_context, tmp_path):",
          "963:         zip_filename = (tmp_path / \"test_zip.zip\").as_posix()",
          "",
          "---------------",
          "--- Hunk 15 ---",
          "[Context before]",
          "981:     @mock.patch(\"airflow.dag_processing.processor.settings.dispose_orm\", MagicMock)",
          "982:     @mock.patch.object(DagFileProcessorProcess, \"_get_multiprocessing_context\")",
          "984:         mock_context.return_value.Pipe.return_value = (MagicMock(), MagicMock())",
          "986:         with open(dag_filename, \"wb\") as file:",
          "987:             file.write(b\"hello\\x00world\")",
          "",
          "[Removed Lines]",
          "983:     def test_nullbyte_exception_handling_when_preimporting_airflow(self, mock_context, tmpdir):",
          "985:         dag_filename = os.path.join(tmpdir, \"test_dag.py\")",
          "",
          "[Added Lines]",
          "978:     def test_nullbyte_exception_handling_when_preimporting_airflow(self, mock_context, tmp_path):",
          "980:         dag_filename = (tmp_path / \"test_dag.py\").as_posix()",
          "",
          "---------------"
        ],
        "tests/utils/test_log_handlers.py||tests/utils/test_log_handlers.py": [
          "File: tests/utils/test_log_handlers.py -> tests/utils/test_log_handlers.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: import logging.config",
          "22: import os",
          "23: import re",
          "25: from importlib import reload",
          "26: from pathlib import Path",
          "27: from unittest import mock",
          "",
          "[Removed Lines]",
          "24: import shutil",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "728:     assert sample_with_dupe == \"\\n\".join(_interleave_logs(sample_with_dupe, \"\", sample_with_dupe))",
          "733:     try:",
          "752:     finally:",
          "",
          "[Removed Lines]",
          "731: def test_permissions_for_new_directories(tmpdir):",
          "732:     tmpdir_path = Path(tmpdir)",
          "734:         # Set umask to 0o027: owner rwx, group rx-w, other -rwx",
          "735:         old_umask = os.umask(0o027)",
          "736:         try:",
          "737:             base_dir = tmpdir_path / \"base\"",
          "738:             base_dir.mkdir()",
          "739:             log_dir = base_dir / \"subdir1\" / \"subdir2\"",
          "740:             # force permissions for the new folder to be owner rwx, group -rxw, other -rwx",
          "741:             new_folder_permissions = 0o700",
          "742:             # default permissions are owner rwx, group rx-w, other -rwx (umask bit negative)",
          "743:             default_permissions = 0o750",
          "744:             FileTaskHandler._prepare_log_folder(log_dir, new_folder_permissions)",
          "745:             assert log_dir.exists()",
          "746:             assert log_dir.is_dir()",
          "747:             assert log_dir.stat().st_mode % 0o1000 == new_folder_permissions",
          "748:             assert log_dir.parent.stat().st_mode % 0o1000 == new_folder_permissions",
          "749:             assert base_dir.stat().st_mode % 0o1000 == default_permissions",
          "750:         finally:",
          "751:             os.umask(old_umask)",
          "753:         shutil.rmtree(tmpdir_path)",
          "",
          "[Added Lines]",
          "730: def test_permissions_for_new_directories(tmp_path):",
          "731:     # Set umask to 0o027: owner rwx, group rx-w, other -rwx",
          "732:     old_umask = os.umask(0o027)",
          "734:         base_dir = tmp_path / \"base\"",
          "735:         base_dir.mkdir()",
          "736:         log_dir = base_dir / \"subdir1\" / \"subdir2\"",
          "737:         # force permissions for the new folder to be owner rwx, group -rxw, other -rwx",
          "738:         new_folder_permissions = 0o700",
          "739:         # default permissions are owner rwx, group rx-w, other -rwx (umask bit negative)",
          "740:         default_permissions = 0o750",
          "741:         FileTaskHandler._prepare_log_folder(log_dir, new_folder_permissions)",
          "742:         assert log_dir.exists()",
          "743:         assert log_dir.is_dir()",
          "744:         assert log_dir.stat().st_mode % 0o1000 == new_folder_permissions",
          "745:         assert log_dir.parent.stat().st_mode % 0o1000 == new_folder_permissions",
          "746:         assert base_dir.stat().st_mode % 0o1000 == default_permissions",
          "748:         os.umask(old_umask)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "2c1d0f8c4121589e92e4c0ca1665b89a2691d2d8",
      "candidate_info": {
        "commit_hash": "2c1d0f8c4121589e92e4c0ca1665b89a2691d2d8",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/2c1d0f8c4121589e92e4c0ca1665b89a2691d2d8",
        "files": [
          "airflow/utils/log/file_task_handler.py",
          "tests/utils/test_log_handlers.py"
        ],
        "message": "Fix excessive permission changing for log task handler (#38164)\n\nWhen log dir permission was changed by log handler, we've\nimplemented also changing permissions of parent folders recursively,\nhowever it was quite a bit too much to change it for home directory\nwhere the log folder could have been created - because in some cases\nchanging permissions might lead to unexpected side-effects - such\nas loosing ability to login to ssh server.\n\nFixes: #38137",
        "before_after_code_files": [
          "airflow/utils/log/file_task_handler.py||airflow/utils/log/file_task_handler.py",
          "tests/utils/test_log_handlers.py||tests/utils/test_log_handlers.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "airflow/utils/log/file_task_handler.py||airflow/utils/log/file_task_handler.py",
            "tests/utils/test_log_handlers.py||tests/utils/test_log_handlers.py"
          ],
          "candidate": [
            "airflow/utils/log/file_task_handler.py||airflow/utils/log/file_task_handler.py",
            "tests/utils/test_log_handlers.py||tests/utils/test_log_handlers.py"
          ]
        }
      },
      "candidate_diff": {
        "airflow/utils/log/file_task_handler.py||airflow/utils/log/file_task_handler.py": [
          "File: airflow/utils/log/file_task_handler.py -> airflow/utils/log/file_task_handler.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "160:         raise AirflowException(f\"Could not find TaskInstance for {ti}\")",
          "188: class FileTaskHandler(logging.Handler):",
          "189:     \"\"\"",
          "190:     FileTaskHandler is a python log handler that handles and reads task instance logs.",
          "",
          "[Removed Lines]",
          "163: def _change_directory_permissions_up(directory: Path, folder_permissions: int):",
          "164:     \"\"\"",
          "165:     Change permissions of the given directory and its parents.",
          "167:     Only attempt to change permissions for directories owned by the current user.",
          "169:     :param directory: directory to change permissions of (including parents)",
          "170:     :param folder_permissions: permissions to set",
          "171:     \"\"\"",
          "172:     if directory.stat().st_uid == os.getuid():",
          "173:         if directory.stat().st_mode % 0o1000 != folder_permissions % 0o1000:",
          "174:             print(f\"Changing {directory} permission to {folder_permissions}\")",
          "175:             try:",
          "176:                 directory.chmod(folder_permissions)",
          "177:             except PermissionError as e:",
          "178:                 # In some circumstances (depends on user and filesystem) we might not be able to",
          "179:                 # change the permission for the folder (when the folder was created by another user",
          "180:                 # before or when the filesystem does not allow to change permission). We should not",
          "181:                 # fail in this case but rather ignore it.",
          "182:                 print(f\"Failed to change {directory} permission to {folder_permissions}: {e}\")",
          "183:                 return",
          "184:         if directory.parent != directory:",
          "185:             _change_directory_permissions_up(directory.parent, folder_permissions)",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "483:         return logs, metadata_array",
          "486:         \"\"\"",
          "487:         Prepare the log folder and ensure its mode is as configured.",
          "",
          "[Removed Lines]",
          "485:     def _prepare_log_folder(self, directory: Path):",
          "",
          "[Added Lines]",
          "460:     @staticmethod",
          "461:     def _prepare_log_folder(directory: Path, new_folder_permissions: int):",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "506:         sure that the same group is set as default group for both - impersonated user and main airflow",
          "507:         user.",
          "508:         \"\"\"",
          "515:     def _init_file(self, ti, *, identifier: str | None = None):",
          "516:         \"\"\"",
          "",
          "[Removed Lines]",
          "509:         new_folder_permissions = int(",
          "510:             conf.get(\"logging\", \"file_task_handler_new_folder_permissions\", fallback=\"0o775\"), 8",
          "511:         )",
          "512:         directory.mkdir(mode=new_folder_permissions, parents=True, exist_ok=True)",
          "513:         _change_directory_permissions_up(directory, new_folder_permissions)",
          "",
          "[Added Lines]",
          "485:         for parent in reversed(directory.parents):",
          "486:             parent.mkdir(mode=new_folder_permissions, exist_ok=True)",
          "487:         directory.mkdir(mode=new_folder_permissions, exist_ok=True)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "532:             # if this is true, we're invoked via set_context in the context of",
          "533:             # setting up individual trigger logging. return trigger log path.",
          "534:             full_path = self.add_triggerer_suffix(full_path=full_path, job_id=ti.triggerer_job.id)",
          "537:         if not os.path.exists(full_path):",
          "538:             open(full_path, \"a\").close()",
          "",
          "[Removed Lines]",
          "535:         self._prepare_log_folder(Path(full_path).parent)",
          "",
          "[Added Lines]",
          "509:         new_folder_permissions = int(",
          "510:             conf.get(\"logging\", \"file_task_handler_new_folder_permissions\", fallback=\"0o775\"), 8",
          "511:         )",
          "512:         self._prepare_log_folder(Path(full_path).parent, new_folder_permissions)",
          "",
          "---------------"
        ],
        "tests/utils/test_log_handlers.py||tests/utils/test_log_handlers.py": [
          "File: tests/utils/test_log_handlers.py -> tests/utils/test_log_handlers.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: import os",
          "23: import re",
          "24: import shutil",
          "26: from importlib import reload",
          "27: from pathlib import Path",
          "28: from unittest import mock",
          "",
          "[Removed Lines]",
          "25: import tempfile",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "44: from airflow.utils.log.file_task_handler import (",
          "45:     FileTaskHandler,",
          "46:     LogType,",
          "48:     _interleave_logs,",
          "49:     _parse_timestamps_in_log_file,",
          "50: )",
          "",
          "[Removed Lines]",
          "47:     _change_directory_permissions_up,",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "729:     assert sample_with_dupe == \"\\n\".join(_interleave_logs(sample_with_dupe, \"\", sample_with_dupe))",
          "734:     try:",
          "735:         # Set umask to 0o027: owner rwx, group rx-w, other -rwx",
          "736:         old_umask = os.umask(0o027)",
          "737:         try:",
          "739:             # force permissions for the new folder to be owner rwx, group -rxw, other -rwx",
          "740:             new_folder_permissions = 0o700",
          "741:             # default permissions are owner rwx, group rx-w, other -rwx (umask bit negative)",
          "742:             default_permissions = 0o750",
          "753:         finally:",
          "754:             os.umask(old_umask)",
          "755:     finally:",
          "",
          "[Removed Lines]",
          "732: def test_permissions_for_new_directories():",
          "733:     tmp_path = Path(tempfile.mkdtemp())",
          "738:             subdir = tmp_path / \"subdir1\" / \"subdir2\"",
          "743:             subdir.mkdir(mode=new_folder_permissions, parents=True, exist_ok=True)",
          "744:             assert subdir.exists()",
          "745:             assert subdir.is_dir()",
          "746:             assert subdir.stat().st_mode % 0o1000 == new_folder_permissions",
          "747:             # initially parent permissions are as per umask",
          "748:             assert subdir.parent.stat().st_mode % 0o1000 == default_permissions",
          "749:             _change_directory_permissions_up(subdir, new_folder_permissions)",
          "750:             assert subdir.stat().st_mode % 0o1000 == new_folder_permissions",
          "751:             # now parent permissions are as per new_folder_permissions",
          "752:             assert subdir.parent.stat().st_mode % 0o1000 == new_folder_permissions",
          "756:         shutil.rmtree(tmp_path)",
          "",
          "[Added Lines]",
          "730: def test_permissions_for_new_directories(tmpdir):",
          "731:     tmpdir_path = Path(tmpdir)",
          "736:             base_dir = tmpdir_path / \"base\"",
          "737:             base_dir.mkdir()",
          "738:             log_dir = base_dir / \"subdir1\" / \"subdir2\"",
          "743:             FileTaskHandler._prepare_log_folder(log_dir, new_folder_permissions)",
          "744:             assert log_dir.exists()",
          "745:             assert log_dir.is_dir()",
          "746:             assert log_dir.stat().st_mode % 0o1000 == new_folder_permissions",
          "747:             assert log_dir.parent.stat().st_mode % 0o1000 == new_folder_permissions",
          "748:             assert base_dir.stat().st_mode % 0o1000 == default_permissions",
          "752:         shutil.rmtree(tmpdir_path)",
          "",
          "---------------"
        ]
      }
    }
  ]
}