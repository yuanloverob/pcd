{
  "cve_id": "CVE-2023-50944",
  "cve_desc": "Apache Airflow, versions before 2.8.1, have a vulnerability that allows an authenticated user to access the source code of a DAG to which they don't have access.\u00a0This vulnerability is considered low since it requires an authenticated user to exploit it. Users are recommended to upgrade to version 2.8.1, which fixes this issue.",
  "repo": "apache/airflow",
  "patch_hash": "8d76538d6e105947272b000581c6fabec20146b1",
  "patch_info": {
    "commit_hash": "8d76538d6e105947272b000581c6fabec20146b1",
    "repo": "apache/airflow",
    "commit_url": "https://github.com/apache/airflow/commit/8d76538d6e105947272b000581c6fabec20146b1",
    "files": [
      "airflow/api_connexion/endpoints/dag_source_endpoint.py",
      "airflow/models/dagcode.py",
      "tests/api_connexion/endpoints/test_dag_source_endpoint.py"
    ],
    "message": "Check DAG read permission before accessing DAG code (#36257)\n\n(cherry picked from commit 30ea37e0d247ce54c2d25b115e807fdb0074d795)",
    "before_after_code_files": [
      "airflow/api_connexion/endpoints/dag_source_endpoint.py||airflow/api_connexion/endpoints/dag_source_endpoint.py",
      "airflow/models/dagcode.py||airflow/models/dagcode.py",
      "tests/api_connexion/endpoints/test_dag_source_endpoint.py||tests/api_connexion/endpoints/test_dag_source_endpoint.py"
    ]
  },
  "patch_diff": {
    "airflow/api_connexion/endpoints/dag_source_endpoint.py||airflow/api_connexion/endpoints/dag_source_endpoint.py": [
      "File: airflow/api_connexion/endpoints/dag_source_endpoint.py -> airflow/api_connexion/endpoints/dag_source_endpoint.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "17: from __future__ import annotations",
      "19: from http import HTTPStatus",
      "21: from flask import Response, current_app, request",
      "22: from itsdangerous import BadSignature, URLSafeSerializer",
      "24: from airflow.api_connexion import security",
      "26: from airflow.api_connexion.schemas.dag_source_schema import dag_source_schema",
      "27: from airflow.auth.managers.models.resource_details import DagAccessEntity",
      "28: from airflow.models.dagcode import DagCode",
      "31: @security.requires_access_dag(\"GET\", DagAccessEntity.CODE)",
      "33:     \"\"\"Get source code using file token.\"\"\"",
      "34:     secret_key = current_app.config[\"SECRET_KEY\"]",
      "35:     auth_s = URLSafeSerializer(secret_key)",
      "36:     try:",
      "37:         path = auth_s.loads(file_token)",
      "39:     except (BadSignature, FileNotFoundError):",
      "40:         raise NotFound(\"Dag source not found\")",
      "",
      "[Removed Lines]",
      "25: from airflow.api_connexion.exceptions import NotFound",
      "32: def get_dag_source(*, file_token: str) -> Response:",
      "38:         dag_source = DagCode.code(path)",
      "",
      "[Added Lines]",
      "20: from typing import TYPE_CHECKING",
      "26: from airflow.api_connexion.exceptions import NotFound, PermissionDenied",
      "28: from airflow.api_connexion.security import get_readable_dags",
      "30: from airflow.models.dag import DagModel",
      "32: from airflow.utils.session import NEW_SESSION, provide_session",
      "34: if TYPE_CHECKING:",
      "35:     from sqlalchemy.orm import Session",
      "39: @provide_session",
      "40: def get_dag_source(*, file_token: str, session: Session = NEW_SESSION) -> Response:",
      "46:         dag_ids = session.query(DagModel.dag_id).filter(DagModel.fileloc == path).all()",
      "47:         readable_dags = get_readable_dags()",
      "48:         # Check if user has read access to all the DAGs defined in the file",
      "49:         if any(dag_id[0] not in readable_dags for dag_id in dag_ids):",
      "50:             raise PermissionDenied()",
      "51:         dag_source = DagCode.code(path, session=session)",
      "",
      "---------------"
    ],
    "airflow/models/dagcode.py||airflow/models/dagcode.py": [
      "File: airflow/models/dagcode.py -> airflow/models/dagcode.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "177:         return cls.code(fileloc)",
      "179:     @classmethod",
      "181:         \"\"\"Return source code for this DagCode object.",
      "183:         :return: source code as string",
      "184:         \"\"\"",
      "187:     @staticmethod",
      "188:     def _get_code_from_file(fileloc):",
      "",
      "[Removed Lines]",
      "180:     def code(cls, fileloc) -> str:",
      "185:         return cls._get_code_from_db(fileloc)",
      "",
      "[Added Lines]",
      "180:     @provide_session",
      "181:     def code(cls, fileloc, session: Session = NEW_SESSION) -> str:",
      "186:         return cls._get_code_from_db(fileloc, session)",
      "",
      "---------------"
    ],
    "tests/api_connexion/endpoints/test_dag_source_endpoint.py||tests/api_connexion/endpoints/test_dag_source_endpoint.py": [
      "File: tests/api_connexion/endpoints/test_dag_source_endpoint.py -> tests/api_connexion/endpoints/test_dag_source_endpoint.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "35: ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir, os.pardir))",
      "36: EXAMPLE_DAG_FILE = os.path.join(\"airflow\", \"example_dags\", \"example_bash_operator.py\")",
      "39: @pytest.fixture(scope=\"module\")",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "37: EXAMPLE_DAG_ID = \"example_bash_operator\"",
      "38: TEST_DAG_ID = \"latest_only\"",
      "39: NOT_READABLE_DAG_ID = \"latest_only_with_trigger\"",
      "40: TEST_MULTIPLE_DAGS_ID = \"dataset_produces_1\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "45:         role_name=\"Test\",",
      "46:         permissions=[(permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG_CODE)],  # type: ignore",
      "47:     )",
      "48:     create_user(app, username=\"test_no_permissions\", role_name=\"TestNoPermissions\")  # type: ignore",
      "50:     yield app",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "52:     app.appbuilder.sm.sync_perm_for_dag(  # type: ignore",
      "53:         TEST_DAG_ID,",
      "54:         access_control={\"Test\": [permissions.ACTION_CAN_READ]},",
      "55:     )",
      "56:     app.appbuilder.sm.sync_perm_for_dag(  # type: ignore",
      "57:         EXAMPLE_DAG_ID,",
      "58:         access_control={\"Test\": [permissions.ACTION_CAN_READ]},",
      "59:     )",
      "60:     app.appbuilder.sm.sync_perm_for_dag(  # type: ignore",
      "61:         TEST_MULTIPLE_DAGS_ID,",
      "62:         access_control={\"Test\": [permissions.ACTION_CAN_READ]},",
      "63:     )",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "80:     def test_should_respond_200_text(self, url_safe_serializer):",
      "81:         dagbag = DagBag(dag_folder=EXAMPLE_DAG_FILE)",
      "82:         dagbag.sync_to_db()",
      "87:         response = self.client.get(",
      "88:             url, headers={\"Accept\": \"text/plain\"}, environ_overrides={\"REMOTE_USER\": \"test\"}",
      "89:         )",
      "",
      "[Removed Lines]",
      "83:         first_dag: DAG = next(iter(dagbag.dags.values()))",
      "84:         dag_docstring = self._get_dag_file_docstring(first_dag.fileloc)",
      "86:         url = f\"/api/v1/dagSources/{url_safe_serializer.dumps(first_dag.fileloc)}\"",
      "",
      "[Added Lines]",
      "99:         test_dag: DAG = dagbag.dags[TEST_DAG_ID]",
      "100:         dag_docstring = self._get_dag_file_docstring(test_dag.fileloc)",
      "102:         url = f\"/api/v1/dagSources/{url_safe_serializer.dumps(test_dag.fileloc)}\"",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "95:     def test_should_respond_200_json(self, url_safe_serializer):",
      "96:         dagbag = DagBag(dag_folder=EXAMPLE_DAG_FILE)",
      "97:         dagbag.sync_to_db()",
      "102:         response = self.client.get(",
      "103:             url, headers={\"Accept\": \"application/json\"}, environ_overrides={\"REMOTE_USER\": \"test\"}",
      "104:         )",
      "",
      "[Removed Lines]",
      "98:         first_dag: DAG = next(iter(dagbag.dags.values()))",
      "99:         dag_docstring = self._get_dag_file_docstring(first_dag.fileloc)",
      "101:         url = f\"/api/v1/dagSources/{url_safe_serializer.dumps(first_dag.fileloc)}\"",
      "",
      "[Added Lines]",
      "114:         test_dag: DAG = dagbag.dags[TEST_DAG_ID]",
      "115:         dag_docstring = self._get_dag_file_docstring(test_dag.fileloc)",
      "117:         url = f\"/api/v1/dagSources/{url_safe_serializer.dumps(test_dag.fileloc)}\"",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "110:     def test_should_respond_406(self, url_safe_serializer):",
      "111:         dagbag = DagBag(dag_folder=EXAMPLE_DAG_FILE)",
      "112:         dagbag.sync_to_db()",
      "116:         response = self.client.get(",
      "117:             url, headers={\"Accept\": \"image/webp\"}, environ_overrides={\"REMOTE_USER\": \"test\"}",
      "118:         )",
      "",
      "[Removed Lines]",
      "113:         first_dag: DAG = next(iter(dagbag.dags.values()))",
      "115:         url = f\"/api/v1/dagSources/{url_safe_serializer.dumps(first_dag.fileloc)}\"",
      "",
      "[Added Lines]",
      "129:         test_dag: DAG = dagbag.dags[TEST_DAG_ID]",
      "131:         url = f\"/api/v1/dagSources/{url_safe_serializer.dumps(test_dag.fileloc)}\"",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "151:             environ_overrides={\"REMOTE_USER\": \"test_no_permissions\"},",
      "152:         )",
      "153:         assert response.status_code == 403",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "171:     def test_should_respond_403_not_readable(self, url_safe_serializer):",
      "172:         dagbag = DagBag(dag_folder=EXAMPLE_DAG_FILE)",
      "173:         dagbag.sync_to_db()",
      "174:         dag: DAG = dagbag.dags[NOT_READABLE_DAG_ID]",
      "176:         response = self.client.get(",
      "177:             f\"/api/v1/dagSources/{url_safe_serializer.dumps(dag.fileloc)}\",",
      "178:             headers={\"Accept\": \"text/plain\"},",
      "179:             environ_overrides={\"REMOTE_USER\": \"test\"},",
      "180:         )",
      "181:         read_dag = self.client.get(",
      "182:             f\"/api/v1/dags/{NOT_READABLE_DAG_ID}\",",
      "183:             environ_overrides={\"REMOTE_USER\": \"test\"},",
      "184:         )",
      "185:         assert response.status_code == 403",
      "186:         assert read_dag.status_code == 403",
      "188:     def test_should_respond_403_some_dags_not_readable_in_the_file(self, url_safe_serializer):",
      "189:         dagbag = DagBag(dag_folder=EXAMPLE_DAG_FILE)",
      "190:         dagbag.sync_to_db()",
      "191:         dag: DAG = dagbag.dags[TEST_MULTIPLE_DAGS_ID]",
      "193:         response = self.client.get(",
      "194:             f\"/api/v1/dagSources/{url_safe_serializer.dumps(dag.fileloc)}\",",
      "195:             headers={\"Accept\": \"text/plain\"},",
      "196:             environ_overrides={\"REMOTE_USER\": \"test\"},",
      "197:         )",
      "199:         read_dag = self.client.get(",
      "200:             f\"/api/v1/dags/{TEST_MULTIPLE_DAGS_ID}\",",
      "201:             environ_overrides={\"REMOTE_USER\": \"test\"},",
      "202:         )",
      "203:         assert response.status_code == 403",
      "204:         assert read_dag.status_code == 200",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "99ec731487e57cf3245953fda4d9a5746677a4c7",
      "candidate_info": {
        "commit_hash": "99ec731487e57cf3245953fda4d9a5746677a4c7",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/99ec731487e57cf3245953fda4d9a5746677a4c7",
        "files": [
          "dev/breeze/src/airflow_breeze/commands/common_package_installation_options.py",
          "images/breeze/output_release-management_install-provider-packages.svg",
          "images/breeze/output_release-management_install-provider-packages.txt",
          "images/breeze/output_release-management_verify-provider-packages.svg",
          "images/breeze/output_release-management_verify-provider-packages.txt",
          "images/breeze/output_shell.svg",
          "images/breeze/output_shell.txt",
          "images/breeze/output_start-airflow.svg",
          "images/breeze/output_start-airflow.txt",
          "scripts/in_container/install_airflow_and_providers.py"
        ],
        "message": "Fix --use-airflow-version constraints (#36378)\n\nWhen `--use-airflow-version` is a numeric or rc version, the constraints\nshould be specific for that version when installing airflow. For example\nwhen we install 2.7.3rc1, `constraints-2.7.3rc1` should be used.\n\nThis has been lost when fixing version in CI.\n\nThis PR introduces these fixes:\n\n* default varlue for airflow constraints is DEFAULT_AIRFLOW_CONSTRAINTS_BRANCH\n\n* when --use-airflow-version is numeric version and default value is\n  used for constraints (DEFAULT_AIRFLOW_CONSTRAINTS_BRANCH) then it\n  is replaced with `constraints-VERSION`\n\n* when we print out constraints used, we print which are the\n  constraints used by Airflow and which by providers.\n\n(cherry picked from commit 5ddd67a9a670caf210fbcd15e033561ebe4404d8)",
        "before_after_code_files": [
          "dev/breeze/src/airflow_breeze/commands/common_package_installation_options.py||dev/breeze/src/airflow_breeze/commands/common_package_installation_options.py",
          "scripts/in_container/install_airflow_and_providers.py||scripts/in_container/install_airflow_and_providers.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "dev/breeze/src/airflow_breeze/commands/common_package_installation_options.py||dev/breeze/src/airflow_breeze/commands/common_package_installation_options.py": [
          "File: dev/breeze/src/airflow_breeze/commands/common_package_installation_options.py -> dev/breeze/src/airflow_breeze/commands/common_package_installation_options.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: import click",
          "22: from airflow_breeze.global_constants import ALLOWED_CONSTRAINTS_MODES_CI, ALLOWED_CONSTRAINTS_MODES_PROD",
          "23: from airflow_breeze.utils.custom_param_types import BetterChoice",
          "25: option_airflow_constraints_reference = click.option(",
          "26:     \"--airflow-constraints-reference\",",
          "29:     envvar=\"AIRFLOW_CONSTRAINTS_REFERENCE\",",
          "30: )",
          "31: option_airflow_constraints_location = click.option(",
          "",
          "[Removed Lines]",
          "27:     help=\"Constraint reference to use for airflow installation (used in calculated constraints URL). \"",
          "28:     \"Can be 'default' in which case the default constraints-reference is used.\",",
          "",
          "[Added Lines]",
          "22: from airflow_breeze.branch_defaults import DEFAULT_AIRFLOW_CONSTRAINTS_BRANCH",
          "28:     default=DEFAULT_AIRFLOW_CONSTRAINTS_BRANCH,",
          "29:     help=\"Constraint reference to use for airflow installation (used in calculated constraints URL).\",",
          "",
          "---------------"
        ],
        "scripts/in_container/install_airflow_and_providers.py||scripts/in_container/install_airflow_and_providers.py": [
          "File: scripts/in_container/install_airflow_and_providers.py -> scripts/in_container/install_airflow_and_providers.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "76:     constraints_reference: str | None,",
          "77:     github_repository: str,",
          "78:     python_version: str,",
          "79: ):",
          "80:     constraints_base = f\"https://raw.githubusercontent.com/{github_repository}/{constraints_reference}\"",
          "81:     location = f\"{constraints_base}/{constraints_mode}-{python_version}.txt\"",
          "83:     return location",
          "",
          "[Removed Lines]",
          "82:     console.print(f\"[info]Determined constraints as: {location}\")",
          "",
          "[Added Lines]",
          "79:     providers: bool,",
          "83:     console.print(f\"[info]Determined {'providers' if providers else 'airflow'} constraints as: {location}\")",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "126:         constraints_reference=airflow_constraints_reference,",
          "127:         github_repository=github_repository,",
          "128:         python_version=python_version,",
          "129:     )",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "130:         providers=False,",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "157:         constraints_reference=providers_constraints_reference,",
          "158:         python_version=python_version,",
          "159:         github_repository=github_repository,",
          "160:     )",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "162:         providers=True,",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "ba3213bb9378185d99fb2141b8423851cbd191e8",
      "candidate_info": {
        "commit_hash": "ba3213bb9378185d99fb2141b8423851cbd191e8",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/ba3213bb9378185d99fb2141b8423851cbd191e8",
        "files": [
          ".github/workflows/ci.yml",
          "Dockerfile",
          "Dockerfile.ci",
          "IMAGES.rst",
          "dev/breeze/src/airflow_breeze/commands/release_management_commands.py",
          "dev/breeze/src/airflow_breeze/global_constants.py",
          "docs/docker-stack/build-arg-ref.rst",
          "scripts/docker/common.sh"
        ],
        "message": "Upgrade to just released `pip` 23.3.2 (#36271)\n\n(cherry picked from commit 41096e0c266e3adb0ac3985d2609701f53aded00)",
        "before_after_code_files": [
          "Dockerfile.ci||Dockerfile.ci",
          "dev/breeze/src/airflow_breeze/commands/release_management_commands.py||dev/breeze/src/airflow_breeze/commands/release_management_commands.py",
          "dev/breeze/src/airflow_breeze/global_constants.py||dev/breeze/src/airflow_breeze/global_constants.py",
          "scripts/docker/common.sh||scripts/docker/common.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "Dockerfile.ci||Dockerfile.ci": [
          "File: Dockerfile.ci -> Dockerfile.ci",
          "--- Hunk 1 ---",
          "[Context before]",
          "491: function common::override_pip_version_if_needed() {",
          "492:     if [[ -n ${AIRFLOW_VERSION} ]]; then",
          "493:         if [[ ${AIRFLOW_VERSION} =~ ^2\\.0.* || ${AIRFLOW_VERSION} =~ ^1\\.* ]]; then",
          "495:         fi",
          "496:     fi",
          "497: }",
          "",
          "[Removed Lines]",
          "494:             export AIRFLOW_PIP_VERSION=\"23.3.1\"",
          "",
          "[Added Lines]",
          "494:             export AIRFLOW_PIP_VERSION=\"23.3.2\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "995: # THE 3 LINES ARE ONLY NEEDED IN ORDER TO MAKE PYMSSQL BUILD WORK WITH LATEST CYTHON",
          "996: # AND SHOULD BE REMOVED WHEN WORKAROUND IN install_mssql.sh IS REMOVED",
          "998: ENV AIRFLOW_PIP_VERSION=${AIRFLOW_PIP_VERSION}",
          "999: COPY --from=scripts common.sh /scripts/docker/",
          "",
          "[Removed Lines]",
          "997: ARG AIRFLOW_PIP_VERSION=23.3.1",
          "",
          "[Added Lines]",
          "997: ARG AIRFLOW_PIP_VERSION=23.3.2",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "1059: ARG AIRFLOW_PRE_CACHED_PIP_PACKAGES=\"true\"",
          "1060: # By default in the image, we are installing all providers when installing from sources",
          "1061: ARG INSTALL_PROVIDERS_FROM_SOURCES=\"true\"",
          "1063: # Setup PIP",
          "1064: # By default PIP install run without cache to make image smaller",
          "1065: ARG PIP_NO_CACHE_DIR=\"true\"",
          "",
          "[Removed Lines]",
          "1062: ARG AIRFLOW_PIP_VERSION=23.3.1",
          "",
          "[Added Lines]",
          "1062: ARG AIRFLOW_PIP_VERSION=23.3.2",
          "",
          "---------------"
        ],
        "dev/breeze/src/airflow_breeze/commands/release_management_commands.py||dev/breeze/src/airflow_breeze/commands/release_management_commands.py": [
          "File: dev/breeze/src/airflow_breeze/commands/release_management_commands.py -> dev/breeze/src/airflow_breeze/commands/release_management_commands.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "205:     comparable_version: Version",
          "209: WHEEL_VERSION = \"0.36.2\"",
          "210: GITPYTHON_VERSION = \"3.1.40\"",
          "211: RICH_VERSION = \"13.7.0\"",
          "",
          "[Removed Lines]",
          "208: AIRFLOW_PIP_VERSION = \"23.3.1\"",
          "",
          "[Added Lines]",
          "208: AIRFLOW_PIP_VERSION = \"23.3.2\"",
          "",
          "---------------"
        ],
        "dev/breeze/src/airflow_breeze/global_constants.py||dev/breeze/src/airflow_breeze/global_constants.py": [
          "File: dev/breeze/src/airflow_breeze/global_constants.py -> dev/breeze/src/airflow_breeze/global_constants.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "121: ALLOWED_MSSQL_VERSIONS = [\"2017-latest\", \"2019-latest\"]",
          "125: # packages that  providers docs",
          "126: REGULAR_DOC_PACKAGES = [",
          "",
          "[Removed Lines]",
          "123: PIP_VERSION = \"23.3.1\"",
          "",
          "[Added Lines]",
          "123: PIP_VERSION = \"23.3.2\"",
          "",
          "---------------"
        ],
        "scripts/docker/common.sh||scripts/docker/common.sh": [
          "File: scripts/docker/common.sh -> scripts/docker/common.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "43: function common::override_pip_version_if_needed() {",
          "44:     if [[ -n ${AIRFLOW_VERSION} ]]; then",
          "45:         if [[ ${AIRFLOW_VERSION} =~ ^2\\.0.* || ${AIRFLOW_VERSION} =~ ^1\\.* ]]; then",
          "47:         fi",
          "48:     fi",
          "49: }",
          "",
          "[Removed Lines]",
          "46:             export AIRFLOW_PIP_VERSION=\"23.3.1\"",
          "",
          "[Added Lines]",
          "46:             export AIRFLOW_PIP_VERSION=\"23.3.2\"",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "7237331ee162abaf023e67ebf2b414833d138deb",
      "candidate_info": {
        "commit_hash": "7237331ee162abaf023e67ebf2b414833d138deb",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/7237331ee162abaf023e67ebf2b414833d138deb",
        "files": [
          "airflow/www/auth.py",
          "airflow/www/views.py"
        ],
        "message": "Allow anoymous user edit/show resource when set `AUTH_ROLE_PUBLIC` (#36750)\n\n(cherry picked from commit 512461c74523f8e015b5ccc1cc01184e4fd3960f)",
        "before_after_code_files": [
          "airflow/www/auth.py||airflow/www/auth.py",
          "airflow/www/views.py||airflow/www/views.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/www/auth.py||airflow/www/auth.py": [
          "File: airflow/www/auth.py -> airflow/www/auth.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "107:             _permission_name = self.method_permission_name.get(f.__name__)",
          "108:             if _permission_name:",
          "109:                 permission_str = f\"{PERMISSION_PREFIX}{_permission_name}\"",
          "118:         ):",
          "119:             return f(self, *args, **kwargs)",
          "120:         else:",
          "",
          "[Removed Lines]",
          "110:         if (",
          "111:             get_auth_manager().is_logged_in()",
          "112:             and permission_str in self.base_permissions",
          "113:             and self.appbuilder.sm.has_access(",
          "114:                 action_name=permission_str,",
          "115:                 resource_name=self.class_permission_name,",
          "116:                 resource_pk=kwargs.get(\"pk\"),",
          "117:             )",
          "",
          "[Added Lines]",
          "110:         if permission_str in self.base_permissions and self.appbuilder.sm.has_access(",
          "111:             action_name=permission_str,",
          "112:             resource_name=self.class_permission_name,",
          "113:             resource_pk=kwargs.get(\"pk\"),",
          "",
          "---------------"
        ],
        "airflow/www/views.py||airflow/www/views.py": [
          "File: airflow/www/views.py -> airflow/www/views.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "133: from airflow.utils.timezone import td_format, utcnow",
          "134: from airflow.version import version",
          "135: from airflow.www import auth, utils as wwwutils",
          "137: from airflow.www.decorators import action_logging, gzipped",
          "138: from airflow.www.extensions.init_auth_manager import get_auth_manager",
          "139: from airflow.www.forms import (",
          "",
          "[Removed Lines]",
          "136: from airflow.www.auth import has_access_with_pk",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "4002:         return attribute",
          "4004:     @expose(\"/show/<pk>\", methods=[\"GET\"])",
          "4006:     def show(self, pk):",
          "4007:         \"\"\"",
          "4008:         Show view.",
          "",
          "[Removed Lines]",
          "4005:     @has_access_with_pk",
          "",
          "[Added Lines]",
          "4004:     @auth.has_access_with_pk",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "4024:         )",
          "4026:     @expose(\"/edit/<pk>\", methods=[\"GET\", \"POST\"])",
          "4028:     def edit(self, pk):",
          "4029:         \"\"\"",
          "4030:         Edit view.",
          "",
          "[Removed Lines]",
          "4027:     @has_access_with_pk",
          "",
          "[Added Lines]",
          "4026:     @auth.has_access_with_pk",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "4048:             )",
          "4050:     @expose(\"/delete/<pk>\", methods=[\"GET\", \"POST\"])",
          "4052:     def delete(self, pk):",
          "4053:         \"\"\"",
          "4054:         Delete view.",
          "",
          "[Removed Lines]",
          "4051:     @has_access_with_pk",
          "",
          "[Added Lines]",
          "4050:     @auth.has_access_with_pk",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "4746:         return redirect(self.get_redirect())",
          "4748:     @expose(\"/delete/<pk>\", methods=[\"GET\", \"POST\"])",
          "4750:     def delete(self, pk):",
          "4751:         \"\"\"Single delete.\"\"\"",
          "4752:         if models.Pool.is_default_pool(pk):",
          "",
          "[Removed Lines]",
          "4749:     @has_access_with_pk",
          "",
          "[Added Lines]",
          "4748:     @auth.has_access_with_pk",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "4f05fe6583d32efab6141be516c71b55d769c1ef",
      "candidate_info": {
        "commit_hash": "4f05fe6583d32efab6141be516c71b55d769c1ef",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/4f05fe6583d32efab6141be516c71b55d769c1ef",
        "files": [
          "airflow/decorators/branch_external_python.py",
          "airflow/decorators/branch_python.py",
          "airflow/decorators/branch_virtualenv.py",
          "airflow/decorators/external_python.py",
          "airflow/decorators/python_virtualenv.py",
          "airflow/decorators/short_circuit.py",
          "airflow/models/abstractoperator.py",
          "tests/decorators/test_branch_virtualenv.py",
          "tests/decorators/test_external_python.py",
          "tests/decorators/test_python_virtualenv.py"
        ],
        "message": "Fix Python-based decorators templating (#36103)\n\nTemplating of Python-based decorators has been broken since\nimplementation. The decorators used template_fields definition\nas defined originally in PythonOperator rather than the ones from\nvirtualenv because template fields were redefined in\n_PythonDecoratedOperator class and they took precedence (MRU).\n\nThis PR add explicit copying of template_fields from the operators\nthat they are decorating.\n\nFixes: #36102\n(cherry picked from commit 3904206b69428525db31ff7813daa0322f7b83e8)",
        "before_after_code_files": [
          "airflow/decorators/branch_external_python.py||airflow/decorators/branch_external_python.py",
          "airflow/decorators/branch_python.py||airflow/decorators/branch_python.py",
          "airflow/decorators/branch_virtualenv.py||airflow/decorators/branch_virtualenv.py",
          "airflow/decorators/external_python.py||airflow/decorators/external_python.py",
          "airflow/decorators/python_virtualenv.py||airflow/decorators/python_virtualenv.py",
          "airflow/decorators/short_circuit.py||airflow/decorators/short_circuit.py",
          "airflow/models/abstractoperator.py||airflow/models/abstractoperator.py",
          "tests/decorators/test_branch_virtualenv.py||tests/decorators/test_branch_virtualenv.py",
          "tests/decorators/test_external_python.py||tests/decorators/test_external_python.py",
          "tests/decorators/test_python_virtualenv.py||tests/decorators/test_python_virtualenv.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/decorators/branch_external_python.py||airflow/decorators/branch_external_python.py": [
          "File: airflow/decorators/branch_external_python.py -> airflow/decorators/branch_external_python.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "29: class _BranchExternalPythonDecoratedOperator(_PythonDecoratedOperator, BranchExternalPythonOperator):",
          "30:     \"\"\"Wraps a Python callable and captures args/kwargs when called for execution.\"\"\"",
          "32:     custom_operator_name: str = \"@task.branch_external_python\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "32:     template_fields = BranchExternalPythonOperator.template_fields",
          "",
          "---------------"
        ],
        "airflow/decorators/branch_python.py||airflow/decorators/branch_python.py": [
          "File: airflow/decorators/branch_python.py -> airflow/decorators/branch_python.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "29: class _BranchPythonDecoratedOperator(_PythonDecoratedOperator, BranchPythonOperator):",
          "30:     \"\"\"Wraps a Python callable and captures args/kwargs when called for execution.\"\"\"",
          "32:     custom_operator_name: str = \"@task.branch\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "32:     template_fields = BranchPythonOperator.template_fields",
          "",
          "---------------"
        ],
        "airflow/decorators/branch_virtualenv.py||airflow/decorators/branch_virtualenv.py": [
          "File: airflow/decorators/branch_virtualenv.py -> airflow/decorators/branch_virtualenv.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "29: class _BranchPythonVirtualenvDecoratedOperator(_PythonDecoratedOperator, BranchPythonVirtualenvOperator):",
          "30:     \"\"\"Wraps a Python callable and captures args/kwargs when called for execution.\"\"\"",
          "32:     custom_operator_name: str = \"@task.branch_virtualenv\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "32:     template_fields = BranchPythonVirtualenvOperator.template_fields",
          "",
          "---------------"
        ],
        "airflow/decorators/external_python.py||airflow/decorators/external_python.py": [
          "File: airflow/decorators/external_python.py -> airflow/decorators/external_python.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "29: class _PythonExternalDecoratedOperator(_PythonDecoratedOperator, ExternalPythonOperator):",
          "30:     \"\"\"Wraps a Python callable and captures args/kwargs when called for execution.\"\"\"",
          "32:     custom_operator_name: str = \"@task.external_python\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "32:     template_fields = ExternalPythonOperator.template_fields",
          "",
          "---------------"
        ],
        "airflow/decorators/python_virtualenv.py||airflow/decorators/python_virtualenv.py": [
          "File: airflow/decorators/python_virtualenv.py -> airflow/decorators/python_virtualenv.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "29: class _PythonVirtualenvDecoratedOperator(_PythonDecoratedOperator, PythonVirtualenvOperator):",
          "30:     \"\"\"Wraps a Python callable and captures args/kwargs when called for execution.\"\"\"",
          "32:     custom_operator_name: str = \"@task.virtualenv\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "32:     template_fields = PythonVirtualenvOperator.template_fields",
          "",
          "---------------"
        ],
        "airflow/decorators/short_circuit.py||airflow/decorators/short_circuit.py": [
          "File: airflow/decorators/short_circuit.py -> airflow/decorators/short_circuit.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "29: class _ShortCircuitDecoratedOperator(_PythonDecoratedOperator, ShortCircuitOperator):",
          "30:     \"\"\"Wraps a Python callable and captures args/kwargs when called for execution.\"\"\"",
          "32:     custom_operator_name: str = \"@task.short_circuit\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "32:     template_fields = ShortCircuitOperator.template_fields",
          "",
          "---------------"
        ],
        "airflow/models/abstractoperator.py||airflow/models/abstractoperator.py": [
          "File: airflow/models/abstractoperator.py -> airflow/models/abstractoperator.py"
        ],
        "tests/decorators/test_branch_virtualenv.py||tests/decorators/test_branch_virtualenv.py": [
          "File: tests/decorators/test_branch_virtualenv.py -> tests/decorators/test_branch_virtualenv.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "31:     # possibilities. So we are increasing the timeout for this test to 3x of the default timeout",
          "32:     @pytest.mark.execution_timeout(180)",
          "33:     @pytest.mark.parametrize(\"branch_task_name\", [\"task_1\", \"task_2\"])",
          "35:         @task",
          "36:         def dummy_f():",
          "37:             pass",
          "",
          "[Removed Lines]",
          "34:     def test_branch_one(self, dag_maker, branch_task_name):",
          "",
          "[Added Lines]",
          "34:     def test_branch_one(self, dag_maker, branch_task_name, tmp_path):",
          "35:         requirements_file = tmp_path / \"requirements.txt\"",
          "36:         requirements_file.write_text(\"funcsigs==0.4\")",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "58:         else:",
          "61:             def branch_operator():",
          "62:                 import funcsigs",
          "64:                 print(f\"We successfully imported funcsigs version {funcsigs.__version__}\")",
          "65:                 return \"task_2\"",
          "68:             branchoperator = branch_operator()",
          "69:             df = dummy_f()",
          "70:             task_1 = task_1()",
          "",
          "[Removed Lines]",
          "60:             @task.branch_virtualenv(task_id=\"branching\", requirements=[\"funcsigs\"])",
          "67:         with dag_maker():",
          "",
          "[Added Lines]",
          "63:             @task.branch_virtualenv(task_id=\"branching\", requirements=\"requirements.txt\")",
          "70:         with dag_maker(template_searchpath=tmp_path.as_posix()):",
          "",
          "---------------"
        ],
        "tests/decorators/test_external_python.py||tests/decorators/test_external_python.py": [
          "File: tests/decorators/test_external_python.py -> tests/decorators/test_external_python.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "75:         ret.operator.run(start_date=DEFAULT_DATE, end_date=DEFAULT_DATE)",
          "77:     def test_no_dill_installed_raises_exception_when_use_dill(self, dag_maker, venv_python):",
          "78:         @task.external_python(python=venv_python, use_dill=True)",
          "79:         def f():",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "77:     def test_with_templated_python(self, dag_maker, venv_python_with_dill):",
          "78:         # add template that produces empty string when rendered",
          "79:         templated_python_with_dill = venv_python_with_dill.as_posix() + \"{{ '' }}\"",
          "81:         @task.external_python(python=templated_python_with_dill, use_dill=True)",
          "82:         def f():",
          "83:             \"\"\"Import dill to double-check it is installed .\"\"\"",
          "84:             import dill  # noqa: F401",
          "86:         with dag_maker():",
          "87:             ret = f()",
          "89:         ret.operator.run(start_date=DEFAULT_DATE, end_date=DEFAULT_DATE)",
          "",
          "---------------"
        ],
        "tests/decorators/test_python_virtualenv.py||tests/decorators/test_python_virtualenv.py": [
          "File: tests/decorators/test_python_virtualenv.py -> tests/decorators/test_python_virtualenv.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "104:         ret.operator.run(start_date=DEFAULT_DATE, end_date=DEFAULT_DATE)",
          "106:     def test_unpinned_requirements(self, dag_maker):",
          "107:         @task.virtualenv(",
          "108:             system_site_packages=False,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "106:     def test_with_requirements_file(self, dag_maker, tmp_path):",
          "107:         requirements_file = tmp_path / \"requirements.txt\"",
          "108:         requirements_file.write_text(\"funcsigs==0.4\\nattrs==23.1.0\")",
          "110:         @task.virtualenv(",
          "111:             system_site_packages=False,",
          "112:             requirements=\"requirements.txt\",",
          "113:             python_version=PYTHON_VERSION,",
          "114:             use_dill=True,",
          "115:         )",
          "116:         def f():",
          "117:             import funcsigs",
          "119:             if funcsigs.__version__ != \"0.4\":",
          "120:                 raise Exception",
          "122:             import attrs",
          "124:             if attrs.__version__ != \"23.1.0\":",
          "125:                 raise Exception",
          "127:         with dag_maker(template_searchpath=tmp_path.as_posix()):",
          "128:             ret = f()",
          "130:         ret.operator.run(start_date=DEFAULT_DATE, end_date=DEFAULT_DATE)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "171981fce86d8448a880914040680475b2e5edaa",
      "candidate_info": {
        "commit_hash": "171981fce86d8448a880914040680475b2e5edaa",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/171981fce86d8448a880914040680475b2e5edaa",
        "files": [
          "airflow/jobs/scheduler_job_runner.py"
        ],
        "message": "Fix the type hint for tis_query in _process_executor_events (#36655)\n\n(cherry picked from commit 98f5ce269acf7165b4c620f7a018d5ba34a7606e)",
        "before_after_code_files": [
          "airflow/jobs/scheduler_job_runner.py||airflow/jobs/scheduler_job_runner.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/jobs/scheduler_job_runner.py||airflow/jobs/scheduler_job_runner.py": [
          "File: airflow/jobs/scheduler_job_runner.py -> airflow/jobs/scheduler_job_runner.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "706:         query = select(TI).where(filter_for_tis).options(selectinload(TI.dag_model))",
          "707:         # row lock this entire set of taskinstances to make sure the scheduler doesn't fail when we have",
          "708:         # multi-schedulers",
          "710:             query,",
          "711:             of=TI,",
          "712:             session=session,",
          "714:         )",
          "716:         for ti in tis:",
          "717:             try_number = ti_primary_key_to_try_number_map[ti.key.primary]",
          "718:             buffer_key = ti.key.with_try_number(try_number)",
          "",
          "[Removed Lines]",
          "709:         tis: Iterator[TI] = with_row_locks(",
          "715:         tis = session.scalars(tis)",
          "",
          "[Added Lines]",
          "709:         tis_query: Query = with_row_locks(",
          "715:         tis: Iterator[TI] = session.scalars(tis_query)",
          "",
          "---------------"
        ]
      }
    }
  ]
}