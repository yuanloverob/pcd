{
  "cve_id": "CVE-2021-45456",
  "cve_desc": "Apache kylin checks the legitimacy of the project before executing some commands with the project name passed in by the user. There is a mismatch between what is being checked and what is being used as the shell command argument in DiagnosisService. This may cause an illegal project name to pass the check and perform the following steps, resulting in a command injection vulnerability. This issue affects Apache Kylin 4.0.0.",
  "repo": "apache/kylin",
  "patch_hash": "f4daf14dde99b934c92ce2c832509f24342bc845",
  "patch_info": {
    "commit_hash": "f4daf14dde99b934c92ce2c832509f24342bc845",
    "repo": "apache/kylin",
    "commit_url": "https://github.com/apache/kylin/commit/f4daf14dde99b934c92ce2c832509f24342bc845",
    "files": [
      "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
      "core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java",
      "core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java",
      "server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java",
      "server/src/main/webapp/WEB-INF/web.xml"
    ],
    "message": "test fix",
    "before_after_code_files": [
      "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
      "core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java||core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java",
      "core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java||core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java",
      "server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java||server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java"
    ]
  },
  "patch_diff": {
    "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java": [
      "File: core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java -> core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "3403:     public String getKerberosPrincipal() {",
      "3404:         return getOptional(\"kylin.kerberos.principal\");",
      "3405:     }",
      "3406: }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "3407:     public String getEncryptCipherIvSpec() {",
      "3408:         return getOptional(\"kylin.security.encrypt.cipher.ivSpec\", \"AAAAAAAAAAAAAAAA\");",
      "3409:     }",
      "",
      "---------------"
    ],
    "core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java||core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java": [
      "File: core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java -> core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "25: import java.security.NoSuchAlgorithmException;",
      "27: import org.apache.commons.codec.binary.Base64;",
      "29: import javax.crypto.Cipher;",
      "30: import javax.crypto.NoSuchPaddingException;",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "28: import org.apache.kylin.common.KylinConfig;",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "42:             InvalidKeyException, NoSuchPaddingException, NoSuchAlgorithmException, UnsupportedEncodingException {",
      "43:         Cipher cipher = Cipher.getInstance(\"AES/CFB/PKCS5Padding\");",
      "44:         final SecretKeySpec secretKey = new SecretKeySpec(key, \"AES\");",
      "46:         cipher.init(cipherMode, secretKey, ivSpec);",
      "47:         return cipher;",
      "48:     }",
      "",
      "[Removed Lines]",
      "45:         IvParameterSpec ivSpec = new IvParameterSpec(\"AAAAAAAAAAAAAAAA\".getBytes(\"UTF-8\"));",
      "",
      "[Added Lines]",
      "46:         IvParameterSpec ivSpec = new IvParameterSpec(KylinConfig.getInstanceFromEnv().getEncryptCipherIvSpec().getBytes(\"UTF-8\"));",
      "",
      "---------------"
    ],
    "core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java||core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java": [
      "File: core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java -> core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "19: package org.apache.kylin.common.util;",
      "21: import org.junit.Assert;",
      "22: import org.junit.Test;",
      "26:     @Test",
      "27:     public void testAESEncrypt(){",
      "",
      "[Removed Lines]",
      "24: public class EncryptUtilTest {",
      "",
      "[Added Lines]",
      "21: import org.junit.After;",
      "23: import org.junit.Before;",
      "26: public class EncryptUtilTest extends LocalFileMetadataTestCase {",
      "27:     @Before",
      "28:     public void setUp() throws Exception {",
      "29:         this.createTestMetadata();",
      "30:     }",
      "32:     @After",
      "33:     public void after() throws Exception {",
      "34:         this.cleanupTestMetadata();",
      "35:     }",
      "",
      "---------------"
    ],
    "server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java||server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java": [
      "File: server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java -> server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "87:     public String dumpProjectDiagnosisInfo(String project, File exportPath) throws IOException {",
      "88:         Message msg = MsgPicker.getMsg();",
      "89:         ProjectInstance projectInstance =",
      "90:                 ProjectManager.getInstance(KylinConfig.getInstanceFromEnv())",
      "92:         if (null == projectInstance) {",
      "93:             throw new BadRequestException(",
      "95:         }",
      "96:         aclEvaluate.checkProjectOperationPermission(projectInstance);",
      "98:         runDiagnosisCLI(args);",
      "99:         return getDiagnosisPackageName(exportPath);",
      "100:     }",
      "",
      "[Removed Lines]",
      "91:                         .getProject(ValidateUtil.convertStringToBeAlphanumericUnderscore(project));",
      "94:                     String.format(Locale.ROOT, msg.getDIAG_PROJECT_NOT_FOUND(), project));",
      "97:         String[] args = { project, exportPath.getAbsolutePath() };",
      "",
      "[Added Lines]",
      "89:         String projectName = ValidateUtil.convertStringToBeAlphanumericUnderscore(project);",
      "92:                         .getProject(projectName);",
      "95:                     String.format(Locale.ROOT, msg.getDIAG_PROJECT_NOT_FOUND(), projectName));",
      "98:         String[] args = { projectName, exportPath.getAbsolutePath() };",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "d9a5c70136c29b77f981058c7166492ce53ea2a4",
      "candidate_info": {
        "commit_hash": "d9a5c70136c29b77f981058c7166492ce53ea2a4",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/d9a5c70136c29b77f981058c7166492ce53ea2a4",
        "files": [
          "core-common/src/main/java/org/apache/kylin/common/QueryContext.java",
          "core-common/src/main/java/org/apache/kylin/common/QueryTrace.java",
          "core-common/src/test/java/org/apache/kylin/common/QueryTraceTest.java",
          "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/SparkEngine.java",
          "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/ResultPlan.scala",
          "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/util/SparkJobTrace.scala",
          "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/spark/sql/metrics/AppStatus.scala",
          "query/src/main/java/org/apache/kylin/query/relnode/OLAPToEnumerableConverter.java",
          "server-base/src/main/java/org/apache/kylin/rest/response/SQLResponse.java",
          "server-base/src/main/java/org/apache/kylin/rest/response/SQLResponseTrace.java",
          "server-base/src/main/java/org/apache/kylin/rest/service/QueryService.java",
          "server-base/src/test/java/org/apache/kylin/rest/response/SQLResponseTest.java"
        ],
        "message": "KYLIN-5111 Record the time spent for each stage of query in kylin4's log",
        "before_after_code_files": [
          "core-common/src/main/java/org/apache/kylin/common/QueryContext.java||core-common/src/main/java/org/apache/kylin/common/QueryContext.java",
          "core-common/src/main/java/org/apache/kylin/common/QueryTrace.java||core-common/src/main/java/org/apache/kylin/common/QueryTrace.java",
          "core-common/src/test/java/org/apache/kylin/common/QueryTraceTest.java||core-common/src/test/java/org/apache/kylin/common/QueryTraceTest.java",
          "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/SparkEngine.java||kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/SparkEngine.java",
          "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/ResultPlan.scala||kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/ResultPlan.scala",
          "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/util/SparkJobTrace.scala||kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/util/SparkJobTrace.scala",
          "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/spark/sql/metrics/AppStatus.scala||kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/spark/sql/metrics/AppStatus.scala",
          "query/src/main/java/org/apache/kylin/query/relnode/OLAPToEnumerableConverter.java||query/src/main/java/org/apache/kylin/query/relnode/OLAPToEnumerableConverter.java",
          "server-base/src/main/java/org/apache/kylin/rest/response/SQLResponse.java||server-base/src/main/java/org/apache/kylin/rest/response/SQLResponse.java",
          "server-base/src/main/java/org/apache/kylin/rest/response/SQLResponseTrace.java||server-base/src/main/java/org/apache/kylin/rest/response/SQLResponseTrace.java",
          "server-base/src/main/java/org/apache/kylin/rest/service/QueryService.java||server-base/src/main/java/org/apache/kylin/rest/service/QueryService.java",
          "server-base/src/test/java/org/apache/kylin/rest/response/SQLResponseTest.java||server-base/src/test/java/org/apache/kylin/rest/response/SQLResponseTest.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "core-common/src/main/java/org/apache/kylin/common/QueryContext.java||core-common/src/main/java/org/apache/kylin/common/QueryContext.java": [
          "File: core-common/src/main/java/org/apache/kylin/common/QueryContext.java -> core-common/src/main/java/org/apache/kylin/common/QueryContext.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "69:     private boolean isHighPriorityQuery = false;",
          "70:     private boolean isTableIndex = false;",
          "71:     private boolean withoutSyntaxError;",
          "73:     private AtomicBoolean isRunning = new AtomicBoolean(true);",
          "74:     private AtomicReference<Throwable> throwable = new AtomicReference<>();",
          "75:     private String stopReason;",
          "76:     private List<QueryStopListener> stopListeners = Lists.newCopyOnWriteArrayList();",
          "78:     private List<RPCStatistics> rpcStatisticsList = Lists.newCopyOnWriteArrayList();",
          "79:     private Map<Integer, CubeSegmentStatisticsResult> cubeSegmentStatisticsResultMap = Maps.newConcurrentMap();",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "72:     private QueryTrace queryTrace = new QueryTrace();",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "205:         return metadataTime.addAndGet(time);",
          "206:     }",
          "209:     public long getScanTime() {",
          "210:         return scanTime.get();",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "208:     public QueryTrace getQueryTrace() {",
          "209:         return queryTrace;",
          "210:     }",
          "212:     public void setQueryTrace(QueryTrace queryTrace) {",
          "213:         this.queryTrace = queryTrace;",
          "214:     }",
          "",
          "---------------"
        ],
        "core-common/src/main/java/org/apache/kylin/common/QueryTrace.java||core-common/src/main/java/org/apache/kylin/common/QueryTrace.java": [
          "File: core-common/src/main/java/org/apache/kylin/common/QueryTrace.java -> core-common/src/main/java/org/apache/kylin/common/QueryTrace.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19: package org.apache.kylin.common;",
          "21: import java.util.HashMap;",
          "22: import java.util.LinkedList;",
          "23: import java.util.List;",
          "24: import java.util.Map;",
          "25: import java.util.Optional;",
          "27: public class QueryTrace {",
          "30:     public static final String SQL_TRANSFORMATION = \"SQL_TRANSFORMATION\";",
          "31:     public static final String SQL_PARSE_AND_OPTIMIZE = \"SQL_PARSE_AND_OPTIMIZE\";",
          "32:     public static final String CUBE_MATCHING = \"CUBE_MATCHING\";",
          "33:     public static final String PREPARE_AND_SUBMIT_JOB = \"PREPARE_AND_SUBMIT_JOB\";",
          "34:     public static final String WAIT_FOR_EXECUTION = \"WAIT_FOR_EXECUTION\";",
          "35:     public static final String EXECUTION = \"EXECUTION\";",
          "36:     public static final String FETCH_RESULT = \"FETCH_RESULT\";",
          "39:     static final String PREPARATION = \"PREPARATION\";",
          "40:     static final Map<String, String> SPAN_GROUPS = new HashMap<>();",
          "41:     static {",
          "42:         SPAN_GROUPS.put(SQL_TRANSFORMATION, PREPARATION);",
          "43:         SPAN_GROUPS.put(SQL_PARSE_AND_OPTIMIZE, PREPARATION);",
          "44:         SPAN_GROUPS.put(CUBE_MATCHING, PREPARATION);",
          "45:     }",
          "48:     private List<Span> spans = new LinkedList<>();",
          "50:     public Optional<Span> getLastSpan() {",
          "51:         return spans.isEmpty() ? Optional.empty() : Optional.of(spans.get(spans.size() - 1));",
          "52:     }",
          "54:     public void endLastSpan() {",
          "55:         getLastSpan().ifPresent(span -> {",
          "56:             if (span.duration == -1) {",
          "57:                 span.duration = System.currentTimeMillis() - span.start;",
          "58:             }",
          "59:         });",
          "60:     }",
          "62:     public void startSpan(String name) {",
          "63:         endLastSpan();",
          "64:         spans.add(new Span(name, System.currentTimeMillis()));",
          "65:     }",
          "67:     public void appendSpan(String name, long duration) {",
          "68:         spans.add(new Span(name,",
          "69:                 getLastSpan().map(span -> span.getStart() + span.getDuration()).orElse(System.currentTimeMillis()),",
          "70:                 duration));",
          "71:     }",
          "73:     public void amendLast(String name, long endAt) {",
          "74:         for (int i = spans.size() - 1; i >= 0; i--) {",
          "75:             if (spans.get(i).name.equals(name)) {",
          "76:                 spans.get(i).duration = endAt - spans.get(i).start;",
          "77:                 return;",
          "78:             }",
          "79:         }",
          "80:     }",
          "82:     public List<Span> spans() {",
          "83:         return spans;",
          "84:     }",
          "86:     public static class Span {",
          "87:         String name;",
          "89:         String group;",
          "91:         long start;",
          "93:         long duration = -1;",
          "95:         public long getDuration() {",
          "96:             return duration;",
          "97:         }",
          "99:         public long getStart() {",
          "100:             return start;",
          "101:         }",
          "103:         public String getGroup() {",
          "104:             return group;",
          "105:         }",
          "107:         public String getName() {",
          "108:             return name;",
          "109:         }",
          "111:         public void setDuration(long duration) {",
          "112:             this.duration = duration;",
          "113:         }",
          "115:         public void setGroup(String group) {",
          "116:             this.group = group;",
          "117:         }",
          "119:         public void setName(String name) {",
          "120:             this.name = name;",
          "121:         }",
          "123:         public void setStart(long start) {",
          "124:             this.start = start;",
          "125:         }",
          "127:         public Span(String name, long start, long duration) {",
          "128:             this.name = name;",
          "129:             this.start = start;",
          "130:             this.duration = duration;",
          "131:             this.group = SPAN_GROUPS.get(name);",
          "132:         }",
          "134:         public Span(String name, long start) {",
          "135:             this.name = name;",
          "136:             this.start = start;",
          "137:             this.group = SPAN_GROUPS.get(name);",
          "138:         }",
          "139:     }",
          "140: }",
          "",
          "---------------"
        ],
        "core-common/src/test/java/org/apache/kylin/common/QueryTraceTest.java||core-common/src/test/java/org/apache/kylin/common/QueryTraceTest.java": [
          "File: core-common/src/test/java/org/apache/kylin/common/QueryTraceTest.java -> core-common/src/test/java/org/apache/kylin/common/QueryTraceTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19: package org.apache.kylin.common;",
          "21: import org.junit.Assert;",
          "22: import org.junit.Test;",
          "24: public class QueryTraceTest {",
          "26:     @Test",
          "27:     public void test() throws InterruptedException {",
          "28:         QueryTrace trace = new QueryTrace();",
          "29:         trace.startSpan(\"span 1\");",
          "30:         Thread.sleep(100);",
          "31:         trace.startSpan(\"span 2\");",
          "32:         Thread.sleep(100);",
          "33:         trace.endLastSpan();",
          "34:         Assert.assertEquals(2, trace.spans().size());",
          "35:         Assert.assertTrue(trace.getLastSpan().isPresent());",
          "36:         Assert.assertEquals(\"span 2\", trace.getLastSpan().get().name);",
          "37:         assertTimeEqual(100, trace.getLastSpan().get().duration);",
          "39:         trace.amendLast(\"span 2\", trace.getLastSpan().get().start + trace.getLastSpan().get().getDuration() + 1000);",
          "40:         assertTimeEqual(1100, trace.getLastSpan().get().duration);",
          "41:     }",
          "43:     private void assertTimeEqual(long expected, long actual) {",
          "44:         Assert.assertTrue(Math.abs(expected - actual) < 1000);",
          "45:     }",
          "47: }",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/SparkEngine.java||kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/SparkEngine.java": [
          "File: kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/SparkEngine.java -> kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/SparkEngine.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: import org.apache.calcite.linq4j.Enumerable;",
          "23: import org.apache.calcite.rel.RelNode;",
          "24: import org.apache.calcite.rel.type.RelDataType;",
          "25: import org.apache.kylin.query.exec.QueryEngine;",
          "26: import org.apache.kylin.query.runtime.plans.ResultPlan;",
          "27: import org.apache.kylin.query.runtime.plans.ResultType;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "25: import org.apache.kylin.common.QueryContextFacade;",
          "26: import org.apache.kylin.common.QueryTrace;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "56:     private Dataset<Row> toSparkPlan(DataContext dataContext, RelNode relNode) {",
          "57:         log.trace(\"Begin planning spark plan.\");",
          "58:         long start = System.currentTimeMillis();",
          "59:         CalciteToSparkPlaner calciteToSparkPlaner = new CalciteToSparkPlaner(dataContext);",
          "60:         calciteToSparkPlaner.go(relNode);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "60:         QueryContextFacade.current().getQueryTrace().startSpan(QueryTrace.PREPARE_AND_SUBMIT_JOB);",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/ResultPlan.scala||kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/ResultPlan.scala": [
          "File: kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/ResultPlan.scala -> kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/ResultPlan.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "27: import org.apache.kylin.common.util.HadoopUtil",
          "28: import org.apache.kylin.metadata.project.ProjectManager",
          "29: import org.apache.kylin.query.runtime.plans.ResultType.ResultType",
          "30: import org.apache.spark.internal.Logging",
          "31: import org.apache.spark.sql.{DataFrame, SparderContext}",
          "32: import org.apache.spark.sql.hive.utils.QueryMetricUtils",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "30: import org.apache.kylin.query.util.SparkJobTrace",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "104:     sparkContext.setJobGroup(jobGroup,",
          "105:       \"Query Id: \" + QueryContextFacade.current().getQueryId,",
          "106:       interruptOnCancel = true)",
          "107:     try {",
          "108:       val rows = df.collect()",
          "109:       val (scanRows, scanFiles, metadataTime, scanTime, scanBytes) = QueryMetricUtils.collectScanMetrics(df.queryExecution.executedPlan)",
          "110:       QueryContextFacade.current().addAndGetScannedRows(scanRows.asScala.map(Long2long(_)).sum)",
          "111:       QueryContextFacade.current().addAndGetScanFiles(scanFiles.asScala.map(Long2long(_)).sum)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "108:     val currentTrace = QueryContextFacade.current().getQueryTrace",
          "109:     currentTrace.endLastSpan()",
          "110:     val jobTrace = new SparkJobTrace(jobGroup, currentTrace, sparkContext)",
          "113:       jobTrace.jobFinished()",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/util/SparkJobTrace.scala||kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/util/SparkJobTrace.scala": [
          "File: kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/util/SparkJobTrace.scala -> kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/util/SparkJobTrace.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19: package org.apache.kylin.query.util",
          "21: import org.apache.kylin.common.QueryTrace",
          "22: import org.apache.spark.SparkContext",
          "23: import org.apache.spark.sql.metrics.AppStatus",
          "24: import org.apache.spark.utils.LogEx",
          "29: class SparkJobTrace(jobGroup: String,",
          "30:                     queryTrace: QueryTrace,",
          "31:                     sparkContext: SparkContext,",
          "32:                     startAt: Long = System.currentTimeMillis()) extends LogEx {",
          "34:   val appStatus = new AppStatus(sparkContext)",
          "56:   def jobFinished(): Unit = {",
          "57:     try {",
          "58:       val jobDataSeq = appStatus.getJobData(jobGroup)",
          "60:       if (jobDataSeq.isEmpty) {",
          "61:         endAbnormalExecutionTrace()",
          "62:         return",
          "63:       }",
          "65:       var jobExecutionTime = System.currentTimeMillis() - startAt",
          "66:       val submissionTime = jobDataSeq.map(_.submissionTime).min",
          "67:       if (submissionTime.isDefined) {",
          "68:         queryTrace.amendLast(QueryTrace.PREPARE_AND_SUBMIT_JOB, submissionTime.get.getTime)",
          "69:       }",
          "70:       val completionTime = jobDataSeq.map(_.completionTime).max",
          "71:       if (submissionTime.isDefined && completionTime.isDefined) {",
          "72:         jobExecutionTime = completionTime.get.getTime - submissionTime.get.getTime",
          "73:       }",
          "75:       val jobMetrics = jobDataSeq.map(_.jobId)",
          "76:         .flatMap(appStatus.getJobStagesSummary(_, 0.5))",
          "77:         .foldLeft((0.0, 0.0)) { (acc, taskMetrics) =>",
          "78:           (",
          "79:             acc._1 + taskMetrics.executorRunTime.head + taskMetrics.executorDeserializeTime.head,",
          "80:             acc._2 + taskMetrics.gettingResultTime.head",
          "81:           )",
          "82:         }",
          "83:       val launchDelayTimeSum = jobDataSeq.flatMap(_.stageIds).flatMap(appStatus.getStage).map { stage =>",
          "84:         appStatus.getTaskLaunchTime(stage.stageId(), 0.5) - stage.submissionTime()",
          "85:       }.sum",
          "86:       val sum = jobMetrics._1 + jobMetrics._2 + launchDelayTimeSum",
          "87:       val computingTime = jobMetrics._1 * jobExecutionTime / sum",
          "88:       val getResultTime = jobMetrics._2 * jobExecutionTime / sum",
          "89:       val launchDelayTime = launchDelayTimeSum * jobExecutionTime / sum",
          "91:       queryTrace.appendSpan(QueryTrace.WAIT_FOR_EXECUTION, launchDelayTime.longValue());",
          "92:       queryTrace.appendSpan(QueryTrace.EXECUTION, computingTime.longValue());",
          "93:       queryTrace.appendSpan(QueryTrace.FETCH_RESULT, getResultTime.longValue());",
          "94:     } catch {",
          "95:       case e =>",
          "96:         logWarning(s\"Failed trace spark job execution for $jobGroup\", e)",
          "97:         endAbnormalExecutionTrace()",
          "98:     }",
          "99:   }",
          "105:   def resultConverted(): Unit = {",
          "106:     queryTrace.amendLast(QueryTrace.FETCH_RESULT, System.currentTimeMillis())",
          "107:   }",
          "112:   def endAbnormalExecutionTrace(): Unit = {",
          "113:     queryTrace.appendSpan(QueryTrace.WAIT_FOR_EXECUTION, 0);",
          "114:     queryTrace.appendSpan(QueryTrace.EXECUTION, System.currentTimeMillis() - startAt);",
          "115:     queryTrace.appendSpan(QueryTrace.FETCH_RESULT, 0);",
          "116:   }",
          "117: }",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/spark/sql/metrics/AppStatus.scala||kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/spark/sql/metrics/AppStatus.scala": [
          "File: kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/spark/sql/metrics/AppStatus.scala -> kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/spark/sql/metrics/AppStatus.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19: package org.apache.spark.sql.metrics",
          "21: import org.apache.spark.{SparkContext, SparkStageInfo}",
          "22: import org.apache.spark.status.{TaskDataWrapper, TaskIndexNames}",
          "23: import org.apache.spark.util.Utils",
          "24: import org.apache.spark.status.api.v1",
          "26: class AppStatus(sparkContext: SparkContext) {",
          "28:   def getTaskLaunchTime(stageId: Int, quantile: Double): Double = {",
          "29:     scanTasks(stageId, TaskIndexNames.LAUNCH_TIME, quantile) { t => t.launchTime }",
          "30:   }",
          "33:   def scanTasks(stageId: Int, index: String, quantile: Double)(fn: TaskDataWrapper => Long): Double = {",
          "34:     val stageKey = Array(stageId, 0)",
          "35:     val count = {",
          "36:       Utils.tryWithResource(",
          "37:         sparkContext.statusStore.store.view(classOf[TaskDataWrapper])",
          "38:           .parent(stageKey)",
          "39:           .index(TaskIndexNames.EXEC_RUN_TIME)",
          "40:           .first(0L)",
          "41:           .closeableIterator()",
          "42:       ) { it =>",
          "43:         var _count = 0L",
          "44:         while (it.hasNext()) {",
          "45:           _count += 1",
          "46:           it.skip(1)",
          "47:         }",
          "48:         _count",
          "49:       }",
          "50:     }",
          "52:     val idx = math.min((quantile * count).toLong, count - 1)",
          "53:     Utils.tryWithResource(",
          "54:       sparkContext.statusStore.store.view(classOf[TaskDataWrapper])",
          "55:         .parent(stageKey)",
          "56:         .index(index)",
          "57:         .first(0L)",
          "58:         .closeableIterator()",
          "59:     ) { it =>",
          "60:       var last = Double.NaN",
          "61:       var currentIdx = -1L",
          "62:       if (idx == currentIdx) {",
          "63:         last",
          "64:       } else {",
          "65:         val diff = idx - currentIdx",
          "66:         currentIdx = idx",
          "67:         if (it.skip(diff - 1)) {",
          "68:           last = fn(it.next()).toDouble",
          "69:           last",
          "70:         } else {",
          "71:           Double.NaN",
          "72:         }",
          "73:       }",
          "74:     }",
          "75:   }",
          "77:   def getJobStagesSummary(jobId: Int, quantile: Double): Seq[v1.TaskMetricDistributions] = {",
          "78:     getJobData(jobId).map { jobData =>",
          "79:       jobData.stageIds.flatMap { stageId =>",
          "80:         sparkContext.statusStore.taskSummary(stageId, 0, Array(quantile))",
          "81:       }",
          "82:     }.getOrElse(Seq.empty)",
          "83:   }",
          "85:   def getStage(stageId: Int): Option[SparkStageInfo] = {",
          "86:     sparkContext.statusTracker.getStageInfo(stageId)",
          "87:   }",
          "89:   def getJobData(jobGroup: String): Seq[v1.JobData] = {",
          "90:     sparkContext.statusTracker.getJobIdsForGroup(jobGroup).map(getJobData).filter(_.isDefined).map(_.get)",
          "91:   }",
          "93:   def getJobData(jobId: Int): Option[v1.JobData] = {",
          "94:     try {",
          "95:       Some(sparkContext.statusStore.job(jobId))",
          "96:     } catch {",
          "97:       case _: NoSuchElementException => None",
          "98:     }",
          "99:   }",
          "100: }",
          "",
          "---------------"
        ],
        "query/src/main/java/org/apache/kylin/query/relnode/OLAPToEnumerableConverter.java||query/src/main/java/org/apache/kylin/query/relnode/OLAPToEnumerableConverter.java": [
          "File: query/src/main/java/org/apache/kylin/query/relnode/OLAPToEnumerableConverter.java -> query/src/main/java/org/apache/kylin/query/relnode/OLAPToEnumerableConverter.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: import java.util.stream.Collectors;",
          "24: import com.google.common.collect.Lists;",
          "25: import org.slf4j.Logger;",
          "26: import org.slf4j.LoggerFactory;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "25: import org.apache.kylin.common.QueryTrace;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "107:             logger.debug(dumpPlan);",
          "108:         }",
          "110:         RealizationChooser.selectRealization(contexts);",
          "112:         QueryInfoCollector.current().setCubeNames(contexts.stream()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "111:         QueryContextFacade.current().getQueryTrace().startSpan(QueryTrace.CUBE_MATCHING);",
          "",
          "---------------"
        ],
        "server-base/src/main/java/org/apache/kylin/rest/response/SQLResponse.java||server-base/src/main/java/org/apache/kylin/rest/response/SQLResponse.java": [
          "File: server-base/src/main/java/org/apache/kylin/rest/response/SQLResponse.java -> server-base/src/main/java/org/apache/kylin/rest/response/SQLResponse.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "96:     protected long lazyQueryStartTime = -1L;",
          "98:     public SQLResponse() {",
          "99:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "98:     private List<SQLResponseTrace> traces;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "296:         this.realizationTypes = realizationTypes;",
          "297:     }",
          "299:     @JsonIgnore",
          "300:     public List<QueryContext.CubeSegmentStatisticsResult> getCubeSegmentStatisticsList() {",
          "301:         try {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "301:     public void setTraces(List<SQLResponseTrace> traces) {",
          "302:         this.traces = traces;",
          "303:     }",
          "305:     public List<SQLResponseTrace> getTraces() {",
          "306:         return traces;",
          "307:     }",
          "",
          "---------------"
        ],
        "server-base/src/main/java/org/apache/kylin/rest/response/SQLResponseTrace.java||server-base/src/main/java/org/apache/kylin/rest/response/SQLResponseTrace.java": [
          "File: server-base/src/main/java/org/apache/kylin/rest/response/SQLResponseTrace.java -> server-base/src/main/java/org/apache/kylin/rest/response/SQLResponseTrace.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19: package org.apache.kylin.rest.response;",
          "21: public class SQLResponseTrace {",
          "23:     public void setName(String name) {",
          "24:         this.name = name;",
          "25:     }",
          "27:     public void setGroup(String group) {",
          "28:         this.group = group;",
          "29:     }",
          "31:     public void setDuration(long duration) {",
          "32:         this.duration = duration;",
          "33:     }",
          "35:     public String getName() {",
          "36:         return name;",
          "37:     }",
          "39:     public String getGroup() {",
          "40:         return group;",
          "41:     }",
          "43:     public long getDuration() {",
          "44:         return duration;",
          "45:     }",
          "47:     private String name;",
          "49:     private String group;",
          "51:     private long duration;",
          "53:     public SQLResponseTrace() {",
          "54:     }",
          "56:     public SQLResponseTrace(String name, String group, long duration) {",
          "57:         this.name = name;",
          "58:         this.group = group;",
          "59:         this.duration = duration;",
          "60:     }",
          "61: }",
          "",
          "---------------"
        ],
        "server-base/src/main/java/org/apache/kylin/rest/service/QueryService.java||server-base/src/main/java/org/apache/kylin/rest/service/QueryService.java": [
          "File: server-base/src/main/java/org/apache/kylin/rest/service/QueryService.java -> server-base/src/main/java/org/apache/kylin/rest/service/QueryService.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "43: import java.util.Locale;",
          "44: import java.util.Map;",
          "45: import java.util.NoSuchElementException;",
          "47: import javax.annotation.PostConstruct;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "46: import java.util.stream.Collectors;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "66: import org.apache.kylin.common.KylinConfig;",
          "67: import org.apache.kylin.common.QueryContext;",
          "68: import org.apache.kylin.common.QueryContextFacade;",
          "69: import org.apache.kylin.metrics.QuerySparkMetrics;",
          "70: import org.apache.kylin.common.debug.BackdoorToggles;",
          "71: import org.apache.kylin.common.exceptions.ResourceLimitExceededException;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "70: import org.apache.kylin.common.QueryTrace;",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "113: import org.apache.kylin.rest.request.PrepareSqlRequest;",
          "114: import org.apache.kylin.rest.request.SQLRequest;",
          "115: import org.apache.kylin.rest.response.SQLResponse;",
          "116: import org.apache.kylin.rest.util.AclEvaluate;",
          "117: import org.apache.kylin.rest.util.AclPermissionUtil;",
          "118: import org.apache.kylin.rest.util.QueryRequestLimits;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "118: import org.apache.kylin.rest.response.SQLResponseTrace;",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "219:             badQueryDetector.queryStart(Thread.currentThread(), sqlRequest, user, queryId);",
          "221:             ret = queryWithSqlMassage(sqlRequest);",
          "222:             return ret;",
          "224:         } finally {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "225:             ret.setTraces(QueryContextFacade.current().getQueryTrace().spans().stream()",
          "226:                     .map(span -> new SQLResponseTrace(span.getName(), span.getGroup(), span.getDuration()))",
          "227:                     .collect(Collectors.toList()));",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "386:         stringBuilder.append(\"Used Spark pool: \").append(response.getSparkPool()).append(newLine);",
          "387:         stringBuilder.append(\"Trace URL: \").append(response.getTraceUrl()).append(newLine);",
          "388:         stringBuilder.append(\"Message: \").append(response.getExceptionMessage()).append(newLine);",
          "389:         stringBuilder.append(\"==========================[QUERY]===============================\").append(newLine);",
          "391:         logger.info(stringBuilder.toString());",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "395:         if (response.getTraces() != null) {",
          "396:             stringBuilder.append(\"Time consuming for each query stage: -----------------\").append(newLine);",
          "397:             response.getTraces().forEach(trace -> stringBuilder.append(trace.getName() + \" : \" + trace.getDuration() + \"ms\").append(newLine));",
          "398:             stringBuilder.append(\"Time consuming for each query stage: -----------------\").append(newLine);",
          "399:         }",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "408:     public SQLResponse doQueryWithCache(SQLRequest sqlRequest, boolean isQueryInspect) {",
          "409:         Message msg = MsgPicker.getMsg();",
          "410:         sqlRequest.setUsername(getUserName());",
          "412:         KylinConfig kylinConfig = KylinConfig.getInstanceFromEnv();",
          "413:         if (!ServerMode.SERVER_MODE.canServeQuery()) {",
          "414:             throw new BadRequestException(",
          "415:                     String.format(Locale.ROOT, msg.getQUERY_NOT_ALLOWED(), kylinConfig.getServerMode()));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "422:         final QueryContext queryContext = QueryContextFacade.current();",
          "425:         queryContext.getQueryTrace().startSpan(QueryTrace.SQL_TRANSFORMATION);",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "430:         if (sqlRequest.getBackdoorToggles() != null)",
          "431:             BackdoorToggles.addToggles(sqlRequest.getBackdoorToggles());",
          "435:         try (SetThreadName ignored = new SetThreadName(\"Query %s\", queryContext.getQueryId())) {",
          "437:             OLAPContext.clearThreadLocalContexts();",
          "",
          "[Removed Lines]",
          "433:         final QueryContext queryContext = QueryContextFacade.current();",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "1023:         try {",
          "1024:             stat = conn.createStatement();",
          "1025:             processStatementAttr(stat, sqlRequest);",
          "1026:             resultSet = stat.executeQuery(correctedSql);",
          "1028:             r = createResponseFromResultSet(resultSet);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1037:             QueryContextFacade.current().getQueryTrace().startSpan(QueryTrace.SQL_PARSE_AND_OPTIMIZE);",
          "",
          "---------------"
        ],
        "server-base/src/test/java/org/apache/kylin/rest/response/SQLResponseTest.java||server-base/src/test/java/org/apache/kylin/rest/response/SQLResponseTest.java": [
          "File: server-base/src/test/java/org/apache/kylin/rest/response/SQLResponseTest.java -> server-base/src/test/java/org/apache/kylin/rest/response/SQLResponseTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "36:                 \"realizationTypes\", \"affectedRowCount\", \"isException\",",
          "37:                 \"exceptionMessage\", \"duration\", \"partial\", \"totalScanCount\", \"hitExceptionCache\",",
          "38:                 \"storageCacheUsed\", \"sparkPool\", \"pushDown\", \"traceUrl\", \"totalScanBytes\",",
          "41:         SQLResponse sqlResponse = new SQLResponse(null, null, \"learn_cube\", 100, false, null, false, false);",
          "42:         String jsonStr = JsonUtil.writeValueAsString(sqlResponse);",
          "",
          "[Removed Lines]",
          "39:                 \"totalScanFiles\", \"metadataTime\", \"totalSparkScanTime\" };",
          "",
          "[Added Lines]",
          "39:                 \"totalScanFiles\", \"metadataTime\", \"totalSparkScanTime\", \"traces\"};",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "12aeea918df9a0065cd1f507a67dbf271de45336",
      "candidate_info": {
        "commit_hash": "12aeea918df9a0065cd1f507a67dbf271de45336",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/12aeea918df9a0065cd1f507a67dbf271de45336",
        "files": [
          "kylin-it/src/test/resources/query/sql_percentile/query03.sql",
          "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/SchemaProcessor.scala",
          "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/AggregatePlan.scala"
        ],
        "message": "KYLIN-5117 Support percentile function after aggregate sub query (#1760)\n\n* Support percentile function after aggregate sub query\n\n* add test",
        "before_after_code_files": [
          "kylin-it/src/test/resources/query/sql_percentile/query03.sql||kylin-it/src/test/resources/query/sql_percentile/query03.sql",
          "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/SchemaProcessor.scala||kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/SchemaProcessor.scala",
          "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/AggregatePlan.scala||kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/AggregatePlan.scala"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "kylin-it/src/test/resources/query/sql_percentile/query03.sql||kylin-it/src/test/resources/query/sql_percentile/query03.sql": [
          "File: kylin-it/src/test/resources/query/sql_percentile/query03.sql -> kylin-it/src/test/resources/query/sql_percentile/query03.sql",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: --",
          "2: -- Licensed to the Apache Software Foundation (ASF) under one",
          "3: -- or more contributor license agreements.  See the NOTICE file",
          "4: -- distributed with this work for additional information",
          "5: -- regarding copyright ownership.  The ASF licenses this file",
          "6: -- to you under the Apache License, Version 2.0 (the",
          "7: -- \"License\"); you may not use this file except in compliance",
          "8: -- with the License.  You may obtain a copy of the License at",
          "9: --",
          "10: --     http://www.apache.org/licenses/LICENSE-2.0",
          "11: --",
          "12: -- Unless required by applicable law or agreed to in writing, software",
          "13: -- distributed under the License is distributed on an \"AS IS\" BASIS,",
          "14: -- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
          "15: -- See the License for the specific language governing permissions and",
          "16: -- limitations under the License.",
          "17: --",
          "19: select percentile_approx(t.gmv, 0.5) from ( select seller_id,sum(price) as gmv from test_kylin_fact group by seller_id ) t",
          "20: ;{\"scanRowCount\":9928,\"scanBytes\":0,\"scanFiles\":1,\"cuboidId\":[1310735]}",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/SchemaProcessor.scala||kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/SchemaProcessor.scala": [
          "File: kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/SchemaProcessor.scala -> kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/SchemaProcessor.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "194:   hash: String,",
          "195:   args: String*) {",
          "196:   override def toString: String =",
          "198: }",
          "200: case class TopNColumnInfo(tableName: String, columnId: Int, columnName: String)",
          "",
          "[Removed Lines]",
          "197:     s\"$funcName(${args.mkString(\"_\")})_${index}_$hash\"",
          "",
          "[Added Lines]",
          "197:     s\"${funcName}_${args.mkString(\"_\")}__${index}_$hash\"",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/AggregatePlan.scala||kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/AggregatePlan.scala": [
          "File: kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/AggregatePlan.scala -> kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/AggregatePlan.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: package org.apache.kylin.query.runtime.plans",
          "20: import org.apache.calcite.DataContext",
          "23: import org.apache.calcite.sql.SqlKind",
          "24: import org.apache.kylin.common.KylinConfig",
          "25: import org.apache.kylin.cube.CubeInstance",
          "29: import org.apache.kylin.query.SchemaProcessor",
          "30: import org.apache.spark.sql.KylinFunctions._",
          "31: import org.apache.spark.sql._",
          "32: import org.apache.spark.sql.catalyst.expressions.{CreateArray, In}",
          "",
          "[Removed Lines]",
          "21: import org.apache.calcite.rel.core.Aggregate",
          "22: import org.apache.calcite.rel.core.AggregateCall",
          "26: import org.apache.kylin.metadata.model.{FunctionDesc, PartitionDesc, SegmentStatusEnum, TblColRef}",
          "27: import org.apache.kylin.query.relnode.{KylinAggregateCall, OLAPAggregateRel}",
          "28: import org.apache.kylin.query.runtime.RuntimeHelper",
          "",
          "[Added Lines]",
          "21: import org.apache.calcite.rel.core.{Aggregate, AggregateCall}",
          "25: import org.apache.kylin.metadata.model.{FunctionDesc, PartitionDesc, SegmentStatusEnum}",
          "27: import org.apache.kylin.query.relnode.{KylinAggregateCall, OLAPAggregateRel, OLAPRel}",
          "28: import org.apache.kylin.query.runtime.RuntimeHelper",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "217:             first(argNames.head).alias(aggName)",
          "218:           case FunctionDesc.FUNC_GROUPING =>",
          "219:             grouping(argNames.head).alias(aggName)",
          "220:           case _ =>",
          "221:             throw new IllegalArgumentException(",
          "222:               s\"\"\"Unsupported function name $funcName\"\"\")",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "219:           case FunctionDesc.FUNC_PERCENTILE => {",
          "220:             val col = argNames(0)",
          "221:             val inputColumnRowType = rel.getInput.asInstanceOf[OLAPRel].getColumnRowType",
          "222:             val percentage = inputColumnRowType.getColumnByIndex(call.getArgList.get(1)).getName",
          "223:             expr(s\"approx_percentile($col, $percentage)\").alias(aggName)",
          "224:           }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "e2635c1763d25fdd9d7fb629670a1fce59edad1e",
      "candidate_info": {
        "commit_hash": "e2635c1763d25fdd9d7fb629670a1fce59edad1e",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/e2635c1763d25fdd9d7fb629670a1fce59edad1e",
        "files": [
          "webapp/app/js/controllers/cubeAdvanceSetting.js",
          "webapp/app/partials/cubeDesigner/advanced_settings.html",
          "webapp/app/partials/tables/table_detail.html"
        ],
        "message": "KYLIN-4549 Show column cardinality in rowkeys area of advanced settings\n\n(cherry picked from commit 26b26468b067a940c8af9382ea80341b4c4b4617)",
        "before_after_code_files": [
          "webapp/app/js/controllers/cubeAdvanceSetting.js||webapp/app/js/controllers/cubeAdvanceSetting.js",
          "webapp/app/partials/cubeDesigner/advanced_settings.html||webapp/app/partials/cubeDesigner/advanced_settings.html",
          "webapp/app/partials/tables/table_detail.html||webapp/app/partials/tables/table_detail.html"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "webapp/app/js/controllers/cubeAdvanceSetting.js||webapp/app/js/controllers/cubeAdvanceSetting.js": [
          "File: webapp/app/js/controllers/cubeAdvanceSetting.js -> webapp/app/js/controllers/cubeAdvanceSetting.js",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: 'use strict';",
          "22:   $scope.cubesManager = cubesManager;",
          "24:   var needLengthKeyList=cubeConfig.needSetLengthEncodingList;",
          "25:   $scope.convertedRowkeys = [];",
          "26:   $scope.dim_cap = $scope.cubeMetaFrame.aggregation_groups.length > 0 && $scope.cubeMetaFrame.aggregation_groups[0].select_rule.dim_cap ? $scope.cubeMetaFrame.aggregation_groups[0].select_rule.dim_cap : 0;",
          "56:   $scope.rule={",
          "",
          "[Removed Lines]",
          "21: KylinApp.controller('CubeAdvanceSettingCtrl', function ($scope, $modal,cubeConfig,MetaModel,cubesManager,CubeDescModel,SweetAlert,VdmUtil,modelsManager) {",
          "27:   angular.forEach($scope.cubeMetaFrame.rowkey.rowkey_columns,function(item){",
          "28:     item.encoding=$scope.removeVersion(item.encoding);",
          "29:     var _valueLength;",
          "30:     var tableName=VdmUtil.getNameSpaceTopName(item.column);",
          "31:     var databaseName=modelsManager.getDatabaseByColumnName(item.column);",
          "32:     var baseKey=item.encoding.replace(/:\\d+/,'');",
          "33:     if(needLengthKeyList.indexOf(baseKey)>-1){",
          "34:       var result=/:(\\d+)/.exec(item.encoding);",
          "35:       _valueLength=result?result[1]:0;",
          "36:     }",
          "37:     var _encoding=baseKey;",
          "38:     var rowkeyObj = {",
          "39:       column:item.column,",
          "40:       encoding:_encoding+(item.encoding_version?\"[v\"+item.encoding_version+\"]\":\"[v1]\"),",
          "41:       encodingName:_encoding,",
          "42:       valueLength:_valueLength,",
          "43:       isShardBy:item.isShardBy,",
          "44:       encoding_version:item.encoding_version||1,",
          "45:       table:tableName,",
          "46:       database:databaseName",
          "47:     }",
          "48:     if(item.index){",
          "49:       rowkeyObj.index=item.index;",
          "50:     }",
          "51:     $scope.convertedRowkeys.push(rowkeyObj);",
          "53:   })",
          "",
          "[Added Lines]",
          "21: KylinApp.controller('CubeAdvanceSettingCtrl', function ($scope, $modal,cubeConfig,MetaModel,TableService,cubesManager,CubeDescModel,SweetAlert,VdmUtil,modelsManager) {",
          "28:   TableService.list({ext: true, project:$scope.projectModel.selectedProject}, function(tables) {",
          "29:     $scope.initRowKey(tables);",
          "30:   }, function (error) {",
          "31:     $scope.initRowKey([]);",
          "32:   });",
          "34:   $scope.initRowKey = function(tables) {",
          "35:     angular.forEach($scope.cubeMetaFrame.rowkey.rowkey_columns,function(item){",
          "36:       item.encoding=$scope.removeVersion(item.encoding);",
          "37:       var _valueLength;",
          "38:       var tableName=VdmUtil.getNameSpaceTopName(item.column);",
          "39:       var databaseName=modelsManager.getDatabaseByColumnName(item.column);",
          "40:       var baseKey=item.encoding.replace(/:\\d+/,'');",
          "41:       if(needLengthKeyList.indexOf(baseKey)>-1){",
          "42:         var result=/:(\\d+)/.exec(item.encoding);",
          "43:         _valueLength=result?result[1]:0;",
          "44:       }$scope.cubeMetaFrame",
          "45:       var _encoding=baseKey;",
          "46:       var rowkeyTable = _.find(tables, function(table) {",
          "47:         var modelDesc = modelsManager.getModel($scope.cubeMetaFrame.model_name);",
          "48:         var lookupTable = modelDesc ? _.find(modelDesc.lookups, function(lookup){ return lookup.alias === tableName; }) : undefined;",
          "49:         return ((modelDesc && modelDesc.fact_table === (table.database + '.' + table.name) && table.name === tableName) || (lookupTable && lookupTable.table === (table.name + table.database)));",
          "50:       });",
          "51:       var cardinality = rowkeyTable ? rowkeyTable.cardinality[VdmUtil.removeNameSpace(item.column)] : undefined;",
          "52:       var rowkeyObj = {",
          "53:         column:item.column,",
          "54:         encoding:_encoding+(item.encoding_version?\"[v\"+item.encoding_version+\"]\":\"[v1]\"),",
          "55:         encodingName:_encoding,",
          "56:         valueLength:_valueLength,",
          "57:         isShardBy:item.isShardBy,",
          "58:         encoding_version:item.encoding_version||1,",
          "59:         table:tableName,",
          "60:         database:databaseName,",
          "61:         cardinality: cardinality || 'N/A'",
          "62:       }",
          "63:       if(item.index){",
          "64:         rowkeyObj.index=item.index;",
          "65:       }",
          "66:       $scope.convertedRowkeys.push(rowkeyObj);",
          "67:     })",
          "68:   }",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "66:     var isShardBy = item.isShardBy;",
          "67:     var version=$scope.getTypeVersion(item.encoding);",
          "68:     var encodingType=$scope.removeVersion(item.encoding);",
          "70:     if(needLengthKeyList.indexOf(encodingType)!=-1){",
          "71:       encoding = encodingType+\":\"+item.valueLength;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "84:     var cardinality = item.cardinality;",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "77:     $scope.cubeMetaFrame.rowkey.rowkey_columns[index].encoding = encoding;",
          "78:     $scope.cubeMetaFrame.rowkey.rowkey_columns[index].encoding_version =version;",
          "79:     $scope.cubeMetaFrame.rowkey.rowkey_columns[index].isShardBy = isShardBy;",
          "80:     if(checkShard == true){",
          "81:       $scope.checkShardByColumn();",
          "82:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "96:     $scope.cubeMetaFrame.rowkey.rowkey_columns[index].cardinality = cardinality;",
          "",
          "---------------"
        ],
        "webapp/app/partials/cubeDesigner/advanced_settings.html||webapp/app/partials/cubeDesigner/advanced_settings.html": [
          "File: webapp/app/partials/cubeDesigner/advanced_settings.html -> webapp/app/partials/cubeDesigner/advanced_settings.html",
          "--- Hunk 1 ---",
          "[Context before]",
          "211:                     <th>ID</th>",
          "212:                     <th class=\"col-xs-5\">Column</th>",
          "213:                     <th>Shard By</th>",
          "214:                   </tr>",
          "215:                   </thead>",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "214:                     <th>Cardinality</th>",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "232:                   <td>",
          "233:                    <span>{{rowkey_column.isShardBy}}</span>",
          "234:                   </td>",
          "235:                 </tr>",
          "236:                 </tbody>",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "237:                   <td>",
          "238:                     <span>{{rowkey_column.cardinality | number}}</span>",
          "239:                   </td>",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "266:                       <small class=\"help-block red\" ng-show=\"state.mode=='edit' && rule.shardColumnAvailable==false && rowkey_column.isShardBy == true\">at most one 'shard by' column is allowed.</small>",
          "267:                     </td>",
          "268:                   </tr>",
          "269:                   </tbody>",
          "270:                 </table>",
          "271:               </div>",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "275:                   <td>",
          "276:                     <span>{{rowkey_column.cardinality | number}}</span>",
          "277:                   </td>",
          "",
          "---------------"
        ],
        "webapp/app/partials/tables/table_detail.html||webapp/app/partials/tables/table_detail.html": [
          "File: webapp/app/partials/tables/table_detail.html -> webapp/app/partials/tables/table_detail.html",
          "--- Hunk 1 ---",
          "[Context before]",
          "148:                   <td",
          "149:                     style=\"{{(tableModel.selectedSrcTable.selectedSrcColumn.id == column.id)? 'background-color:#EBF9FE':''}}\">",
          "150:                     <!--{{ tableModel.selectedSrcTable.cardinality[column.name]}}-->",
          "152:                   </td>",
          "153:                   <td",
          "154:                     style=\"{{(tableModel.selectedSrcTable.selectedSrcColumn.id == column.id)? 'background-color:#EBF9FE':''}}\">",
          "",
          "[Removed Lines]",
          "151:                     {{column.cardinality}}",
          "",
          "[Added Lines]",
          "151:                     {{column.cardinality || 'N/A'}}",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "760636cc854da9790e993d43d7e41c7b0e34c58c",
      "candidate_info": {
        "commit_hash": "760636cc854da9790e993d43d7e41c7b0e34c58c",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/760636cc854da9790e993d43d7e41c7b0e34c58c",
        "files": [
          "server-base/src/main/java/org/apache/kylin/rest/service/CubeService.java"
        ],
        "message": "KYLIN-4753 Merging job stop working after Kylin upgrade\n\n(cherry picked from commit 3c21e72f6cf149e549a2efe749acdcd328052fa9)",
        "before_after_code_files": [
          "server-base/src/main/java/org/apache/kylin/rest/service/CubeService.java||server-base/src/main/java/org/apache/kylin/rest/service/CubeService.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "server-base/src/main/java/org/apache/kylin/rest/service/CubeService.java||server-base/src/main/java/org/apache/kylin/rest/service/CubeService.java": [
          "File: server-base/src/main/java/org/apache/kylin/rest/service/CubeService.java -> server-base/src/main/java/org/apache/kylin/rest/service/CubeService.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "810:                 EnumSet.of(ExecutableState.DISCARDED));",
          "811:         for (CubingJob cubingJob : jobInstanceList) {",
          "812:             String jobSegmentName = cubingJob.getSegmentName();",
          "814:                 logger.debug(\"Merge job {} has been discarded before, will not merge.\", segmentName);",
          "815:                 return true;",
          "816:             }",
          "",
          "[Removed Lines]",
          "813:             if (jobSegmentName != null && jobSegmentName.equals(segmentName)) {",
          "",
          "[Added Lines]",
          "813:             if (jobSegmentName != null && segmentName.equals(jobSegmentName)) {",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "76492b5b0eea24aba0665a5b9b76476abe547c40",
      "candidate_info": {
        "commit_hash": "76492b5b0eea24aba0665a5b9b76476abe547c40",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/76492b5b0eea24aba0665a5b9b76476abe547c40",
        "files": [
          "build/bin/replace-jars-under-spark.sh"
        ],
        "message": "Minor, fix replace-jars-under-spark.sh",
        "before_after_code_files": [
          "build/bin/replace-jars-under-spark.sh||build/bin/replace-jars-under-spark.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "build/bin/replace-jars-under-spark.sh||build/bin/replace-jars-under-spark.sh": [
          "File: build/bin/replace-jars-under-spark.sh -> build/bin/replace-jars-under-spark.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: # limitations under the License.",
          "18: #",
          "20: BYPASS=${KYLIN_HOME}/spark/jars/replace-jars-bypass",
          "21: cdh_mapreduce_path=\"/opt/cloudera/parcels/CDH/lib/hadoop-mapreduce\"",
          "22: hadoop_lib_path=\"/usr/lib/hadoop\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "20: # check https://cwiki.apache.org/confluence/display/KYLIN/Deploy+Kylin+4+on+CDH+6",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "119:   find ${KYLIN_HOME}/spark/jars -name \"hadoop-hdfs-*.jar\" -exec rm -f {} \\;",
          "120:   find ${KYLIN_HOME}/spark/jars -name \"hadoop-yarn-*.jar\" -exec rm -f {} \\;",
          "121:   find ${KYLIN_HOME}/spark/jars -name \"hadoop-mapreduce-*.jar\" -exec rm -f {} \\;",
          "122:   find ${KYLIN_HOME}/spark/jars -name \"hive-exec-*.jar\" -exec rm -f {} \\;",
          "124: fi",
          "126: for jar_file in ${jar_list}; do",
          "",
          "[Removed Lines]",
          "123: #  cp ${KYLIN_HOME}/bin/hadoop3_jars/cdh6/*.jar ${SPARK_HOME}/jars",
          "",
          "[Added Lines]",
          "124:   find ${KYLIN_HOME}/spark/jars -name \"hadoop-annotations-*.jar\" -exec rm -f {} \\;",
          "125:   find ${KYLIN_HOME}/spark/jars -name \"hadoop-auth-*.jar\" -exec rm -f {} \\;",
          "126:   find ${KYLIN_HOME}/spark/jars -name \"hadoop-client-*.jar\" -exec rm -f {} \\;",
          "127:   find ${KYLIN_HOME}/spark/jars -name \"hadoop-common-*.jar\" -exec rm -f {} \\;",
          "129:   if [ -d \"${KYLIN_HOME}/bin/hadoop3_jars/cdh6\" ]; then",
          "130:     echo \"Copy jars from ${KYLIN_HOME}/bin/hadoop3_jars/cdh6\"",
          "131:     cp ${KYLIN_HOME}/bin/hadoop3_jars/cdh6/*.jar ${SPARK_HOME}/jars",
          "132:   fi",
          "",
          "---------------"
        ]
      }
    }
  ]
}