{
  "cve_id": "CVE-2021-32061",
  "cve_desc": "S3Scanner before 2.0.2 allows Directory Traversal via a crafted bucket, as demonstrated by a <Key>../ substring in a ListBucketResult element.",
  "repo": "sa7mon/S3Scanner",
  "patch_hash": "fafa30a3bd35b496b3f7db9bfc35b75a8a06bcd1",
  "patch_info": {
    "commit_hash": "fafa30a3bd35b496b3f7db9bfc35b75a8a06bcd1",
    "repo": "sa7mon/S3Scanner",
    "commit_url": "https://github.com/sa7mon/S3Scanner/commit/fafa30a3bd35b496b3f7db9bfc35b75a8a06bcd1",
    "files": [
      "S3Scanner/S3Service.py",
      "S3Scanner/__main__.py",
      "setup.cfg",
      "tests/test_scanner.py",
      "tests/test_service.py"
    ],
    "message": "Merge pull request #121 from sa7mon/relative-file-bug\n\nFix path traversal bug",
    "before_after_code_files": [
      "S3Scanner/S3Service.py||S3Scanner/S3Service.py",
      "S3Scanner/__main__.py||S3Scanner/__main__.py",
      "setup.cfg||setup.cfg",
      "tests/test_scanner.py||tests/test_scanner.py",
      "tests/test_service.py||tests/test_service.py"
    ]
  },
  "patch_diff": {
    "S3Scanner/S3Service.py||S3Scanner/S3Service.py": [
      "File: S3Scanner/S3Service.py -> S3Scanner/S3Service.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "10: from botocore.client import Config",
      "11: import datetime",
      "12: from S3Scanner.exceptions import AccessDeniedException, InvalidEndpointException, BucketMightNotExistException",
      "14: import pathlib",
      "15: from concurrent.futures import ThreadPoolExecutor, as_completed",
      "16: from functools import partial",
      "17: from urllib3 import disable_warnings",
      "19: ALL_USERS_URI = 'uri=http://acs.amazonaws.com/groups/global/AllUsers'",
      "20: AUTH_USERS_URI = 'uri=http://acs.amazonaws.com/groups/global/AuthenticatedUsers'",
      "",
      "[Removed Lines]",
      "13: from os.path import normpath",
      "",
      "[Added Lines]",
      "17: import os",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "285:             for future in as_completed(futures):",
      "286:                 if future.exception():",
      "289:         print(f\"{bucket.name} | Dumping completed\")",
      "",
      "[Removed Lines]",
      "287:                     print(f\"{bucket.name} | Download failed: {futures[future]}\")",
      "",
      "[Added Lines]",
      "288:                     print(f\"{bucket.name} | Download failed: {futures[future]} | {future.exception()}\")",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "292:         \"\"\"",
      "293:         Download `obj` from `bucket` into `dest_directory`",
      "296:         :param S3Bucket bucket: Bucket to download the object from",
      "297:         :param bool verbose: Output verbose messages to the user",
      "298:         :param S3BucketObject obj: Object to downlaod",
      "299:         :return: None",
      "300:         \"\"\"",
      "302:         if dest_file_path.exists():",
      "303:             if dest_file_path.stat().st_size == obj.size:",
      "304:                 if verbose:",
      "",
      "[Removed Lines]",
      "295:         :param str dest_directory: Directory to store the object into",
      "301:         dest_file_path = pathlib.Path(normpath(dest_directory + obj.key))",
      "",
      "[Added Lines]",
      "296:         :param str dest_directory: Directory to store the object into. _Must_ end in a slash",
      "302:         dest_file_path = pathlib.Path(os.path.normpath(os.path.join(dest_directory, obj.key)))",
      "304:         if not self.is_safe_file_to_download(obj.key, dest_directory):",
      "305:             print(f\"{bucket.name} | Skipping file {obj.key}. File references a parent directory.\")",
      "306:             return",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "342:                 raise AccessDeniedException(\"AccessDenied while enumerating bucket objects\")",
      "343:         bucket.objects_enumerated = True",
      "345:     def parse_found_acl(self, bucket):",
      "346:         \"\"\"",
      "347:         Translate ACL grants into permission properties. If we were able to read the ACLs, we should be able to skip",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "350:     def is_safe_file_to_download(self, file_to_check, dest_directory):",
      "351:         \"\"\"",
      "352:         Check if bucket object would be saved outside of `dest_directory` if downloaded.",
      "353:         AWS allows object keys to include relative path characters like '../' which can lead to a",
      "354:         path traversal-like issue where objects get saved outside of the intended directory.",
      "356:         :param string file_to_check: Bucket object key",
      "357:         :param string dest_directory: Path to directory to save file in",
      "358:         :return: bool",
      "359:         \"\"\"",
      "360:         file_to_check = os.path.abspath(os.path.join(dest_directory, file_to_check))",
      "361:         safe_dir = os.path.abspath(dest_directory)",
      "362:         return os.path.commonpath([safe_dir]) == os.path.commonpath([safe_dir, file_to_check])",
      "",
      "---------------"
    ],
    "S3Scanner/__main__.py||S3Scanner/__main__.py": [
      "File: S3Scanner/__main__.py -> S3Scanner/__main__.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "16: from concurrent.futures import ThreadPoolExecutor, as_completed",
      "17: from .exceptions import InvalidEndpointException",
      "20: AWS_ENDPOINT = 'https://s3.amazonaws.com'",
      "",
      "[Removed Lines]",
      "19: CURRENT_VERSION = '2.0.1'",
      "",
      "[Added Lines]",
      "19: CURRENT_VERSION = '2.0.2'",
      "",
      "---------------"
    ],
    "setup.cfg||setup.cfg": [
      "File: setup.cfg -> setup.cfg",
      "--- Hunk 1 ---",
      "[Context before]",
      "1: [metadata]",
      "2: name = S3Scanner",
      "4: author = Dan Salmon",
      "5: author_email = dan@salmon.cat",
      "6: description = Scan for open S3 buckets and dump the contents",
      "",
      "[Removed Lines]",
      "3: version = 2.0.1",
      "",
      "[Added Lines]",
      "3: version = 2.0.2",
      "",
      "---------------"
    ],
    "tests/test_scanner.py||tests/test_scanner.py": [
      "File: tests/test_scanner.py -> tests/test_scanner.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "11:     s = S3Service()",
      "13:     a = subprocess.run([sys.executable, '-m', 'S3Scanner', '--version'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)",
      "16:     b = subprocess.run([sys.executable, '-m', 'S3Scanner', 'scan', '--bucket', 'flaws.cloud'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)",
      "17:     assert_scanner_output(s, 'flaws.cloud | bucket_exists | AuthUsers: [], AllUsers: [Read]', b.stdout.decode('utf-8').strip())",
      "",
      "[Removed Lines]",
      "14:     assert a.stdout.decode('utf-8').strip() == '2.0.1'",
      "",
      "[Added Lines]",
      "14:     assert a.stdout.decode('utf-8').strip() == '2.0.2'",
      "",
      "---------------"
    ],
    "tests/test_service.py||tests/test_service.py": [
      "File: tests/test_service.py -> tests/test_service.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "545:     b = S3Bucket(\"bucket-no-existo\")",
      "546:     s.download_file(os.path.join(dest_folder, ''), b, True, o)",
      "549: def test_validate_endpoint_url_nonaws():",
      "550:     disable_warnings()",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "548: def test_is_safe_file_to_download():",
      "549:     test_setup_new()",
      "550:     s = S3Service()",
      "552:     # Check a good file name",
      "553:     assert s.is_safe_file_to_download(\"file.txt\", \"./bucket_dir/\") == True",
      "554:     assert s.is_safe_file_to_download(\"file.txt\", \"./bucket_dir\") == True",
      "556:     # Check file with relative name",
      "557:     assert s.is_safe_file_to_download(\"../file.txt\", \"./buckets/\") == False",
      "558:     assert s.is_safe_file_to_download(\"../\", \"./buckets/\") == False",
      "559:     assert s.is_safe_file_to_download(\"/file.txt\", \"./buckets/\") == False",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "2807176ba92caedcd88b2e0d322da529536c7195",
      "candidate_info": {
        "commit_hash": "2807176ba92caedcd88b2e0d322da529536c7195",
        "repo": "sa7mon/S3Scanner",
        "commit_url": "https://github.com/sa7mon/S3Scanner/commit/2807176ba92caedcd88b2e0d322da529536c7195",
        "files": [
          "S3Scanner/S3Service.py"
        ],
        "message": "Fix issue with no trailing slash in dump dir",
        "before_after_code_files": [
          "S3Scanner/S3Service.py||S3Scanner/S3Service.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/sa7mon/S3Scanner/pull/121"
        ],
        "olp_code_files": {
          "patch": [
            "S3Scanner/S3Service.py||S3Scanner/S3Service.py"
          ],
          "candidate": [
            "S3Scanner/S3Service.py||S3Scanner/S3Service.py"
          ]
        }
      },
      "candidate_diff": {
        "S3Scanner/S3Service.py||S3Scanner/S3Service.py": [
          "File: S3Scanner/S3Service.py -> S3Scanner/S3Service.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "293:         \"\"\"",
          "294:         Download `obj` from `bucket` into `dest_directory`",
          "297:         :param S3Bucket bucket: Bucket to download the object from",
          "298:         :param bool verbose: Output verbose messages to the user",
          "299:         :param S3BucketObject obj: Object to downlaod",
          "300:         :return: None",
          "301:         \"\"\"",
          "304:         if not self.is_safe_file_to_download(obj.key, dest_directory):",
          "305:             print(f\"{bucket.name} | Skipping file {obj.key}. File references a parent directory.\")",
          "",
          "[Removed Lines]",
          "296:         :param str dest_directory: Directory to store the object into",
          "302:         dest_file_path = pathlib.Path(os.path.normpath(dest_directory + obj.key))",
          "",
          "[Added Lines]",
          "296:         :param str dest_directory: Directory to store the object into. _Must_ end in a slash",
          "302:         dest_file_path = pathlib.Path(os.path.normpath(os.path.join(dest_directory, obj.key)))",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "125cb908e8f4c79716fae6e0cd51a822eb828947",
      "candidate_info": {
        "commit_hash": "125cb908e8f4c79716fae6e0cd51a822eb828947",
        "repo": "sa7mon/S3Scanner",
        "commit_url": "https://github.com/sa7mon/S3Scanner/commit/125cb908e8f4c79716fae6e0cd51a822eb828947",
        "files": [
          "tests/test_service.py"
        ],
        "message": "Add tests for new check method",
        "before_after_code_files": [
          "tests/test_service.py||tests/test_service.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/sa7mon/S3Scanner/pull/121"
        ],
        "olp_code_files": {
          "patch": [
            "tests/test_service.py||tests/test_service.py"
          ],
          "candidate": [
            "tests/test_service.py||tests/test_service.py"
          ]
        }
      },
      "candidate_diff": {
        "tests/test_service.py||tests/test_service.py": [
          "File: tests/test_service.py -> tests/test_service.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "545:     b = S3Bucket(\"bucket-no-existo\")",
          "546:     s.download_file(os.path.join(dest_folder, ''), b, True, o)",
          "549: def test_validate_endpoint_url_nonaws():",
          "550:     disable_warnings()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "548: def test_is_safe_file_to_download():",
          "549:     test_setup_new()",
          "550:     s = S3Service()",
          "552:     # Check a good file name",
          "553:     assert s.is_safe_file_to_download(\"file.txt\", \"./bucket_dir/\") == True",
          "554:     assert s.is_safe_file_to_download(\"file.txt\", \"./bucket_dir\") == True",
          "556:     # Check file with relative name",
          "557:     assert s.is_safe_file_to_download(\"../file.txt\", \"./buckets/\") == False",
          "558:     assert s.is_safe_file_to_download(\"../\", \"./buckets/\") == False",
          "559:     assert s.is_safe_file_to_download(\"/file.txt\", \"./buckets/\") == False",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "f03c8ee6673b6d5335b8be2354a611d5be407f4c",
      "candidate_info": {
        "commit_hash": "f03c8ee6673b6d5335b8be2354a611d5be407f4c",
        "repo": "sa7mon/S3Scanner",
        "commit_url": "https://github.com/sa7mon/S3Scanner/commit/f03c8ee6673b6d5335b8be2354a611d5be407f4c",
        "files": [
          "S3Scanner/S3Service.py"
        ],
        "message": "Verify object will land in output dir when downloading",
        "before_after_code_files": [
          "S3Scanner/S3Service.py||S3Scanner/S3Service.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/sa7mon/S3Scanner/pull/121"
        ],
        "olp_code_files": {
          "patch": [
            "S3Scanner/S3Service.py||S3Scanner/S3Service.py"
          ],
          "candidate": [
            "S3Scanner/S3Service.py||S3Scanner/S3Service.py"
          ]
        }
      },
      "candidate_diff": {
        "S3Scanner/S3Service.py||S3Scanner/S3Service.py": [
          "File: S3Scanner/S3Service.py -> S3Scanner/S3Service.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "10: from botocore.client import Config",
          "11: import datetime",
          "12: from S3Scanner.exceptions import AccessDeniedException, InvalidEndpointException, BucketMightNotExistException",
          "14: import pathlib",
          "15: from concurrent.futures import ThreadPoolExecutor, as_completed",
          "16: from functools import partial",
          "17: from urllib3 import disable_warnings",
          "19: ALL_USERS_URI = 'uri=http://acs.amazonaws.com/groups/global/AllUsers'",
          "20: AUTH_USERS_URI = 'uri=http://acs.amazonaws.com/groups/global/AuthenticatedUsers'",
          "",
          "[Removed Lines]",
          "13: from os.path import normpath",
          "",
          "[Added Lines]",
          "17: import os",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "285:             for future in as_completed(futures):",
          "286:                 if future.exception():",
          "289:         print(f\"{bucket.name} | Dumping completed\")",
          "",
          "[Removed Lines]",
          "287:                     print(f\"{bucket.name} | Download failed: {futures[future]}\")",
          "",
          "[Added Lines]",
          "288:                     print(f\"{bucket.name} | Download failed: {futures[future]} | {future.exception()}\")",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "298:         :param S3BucketObject obj: Object to downlaod",
          "299:         :return: None",
          "300:         \"\"\"",
          "302:         if dest_file_path.exists():",
          "303:             if dest_file_path.stat().st_size == obj.size:",
          "304:                 if verbose:",
          "",
          "[Removed Lines]",
          "301:         dest_file_path = pathlib.Path(normpath(dest_directory + obj.key))",
          "",
          "[Added Lines]",
          "302:         dest_file_path = pathlib.Path(os.path.normpath(dest_directory + obj.key))",
          "304:         if not self.is_safe_file_to_download(obj.key, dest_directory):",
          "305:             print(f\"{bucket.name} | Skipping file {obj.key}. File references a parent directory.\")",
          "306:             return",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "342:                 raise AccessDeniedException(\"AccessDenied while enumerating bucket objects\")",
          "343:         bucket.objects_enumerated = True",
          "345:     def parse_found_acl(self, bucket):",
          "346:         \"\"\"",
          "347:         Translate ACL grants into permission properties. If we were able to read the ACLs, we should be able to skip",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "350:     def is_safe_file_to_download(self, file_to_check, dest_directory):",
          "351:         \"\"\"",
          "352:         Check if bucket object would be saved outside of `dest_directory` if downloaded.",
          "353:         AWS allows object keys to include relative path characters like '../' which can lead to a",
          "354:         path traversal-like issue where objects get saved outside of the intended directory.",
          "356:         :param string file_to_check: Bucket object key",
          "357:         :param string dest_directory: Path to directory to save file in",
          "358:         :return: bool",
          "359:         \"\"\"",
          "360:         file_to_check = os.path.abspath(os.path.join(dest_directory, file_to_check))",
          "361:         safe_dir = os.path.abspath(dest_directory)",
          "362:         return os.path.commonpath([safe_dir]) == os.path.commonpath([safe_dir, file_to_check])",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "37421e7f4f7a50f14bcf6635849a71089ebff19b",
      "candidate_info": {
        "commit_hash": "37421e7f4f7a50f14bcf6635849a71089ebff19b",
        "repo": "sa7mon/S3Scanner",
        "commit_url": "https://github.com/sa7mon/S3Scanner/commit/37421e7f4f7a50f14bcf6635849a71089ebff19b",
        "files": [
          "S3Scanner/__main__.py",
          "setup.cfg",
          "tests/test_scanner.py"
        ],
        "message": "Bump version to 2.0.2",
        "before_after_code_files": [
          "S3Scanner/__main__.py||S3Scanner/__main__.py",
          "setup.cfg||setup.cfg",
          "tests/test_scanner.py||tests/test_scanner.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/sa7mon/S3Scanner/pull/121"
        ],
        "olp_code_files": {
          "patch": [
            "S3Scanner/__main__.py||S3Scanner/__main__.py",
            "setup.cfg||setup.cfg",
            "tests/test_scanner.py||tests/test_scanner.py"
          ],
          "candidate": [
            "S3Scanner/__main__.py||S3Scanner/__main__.py",
            "setup.cfg||setup.cfg",
            "tests/test_scanner.py||tests/test_scanner.py"
          ]
        }
      },
      "candidate_diff": {
        "S3Scanner/__main__.py||S3Scanner/__main__.py": [
          "File: S3Scanner/__main__.py -> S3Scanner/__main__.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "16: from concurrent.futures import ThreadPoolExecutor, as_completed",
          "17: from .exceptions import InvalidEndpointException",
          "20: AWS_ENDPOINT = 'https://s3.amazonaws.com'",
          "",
          "[Removed Lines]",
          "19: CURRENT_VERSION = '2.0.1'",
          "",
          "[Added Lines]",
          "19: CURRENT_VERSION = '2.0.2'",
          "",
          "---------------"
        ],
        "setup.cfg||setup.cfg": [
          "File: setup.cfg -> setup.cfg",
          "--- Hunk 1 ---",
          "[Context before]",
          "1: [metadata]",
          "2: name = S3Scanner",
          "4: author = Dan Salmon",
          "5: author_email = dan@salmon.cat",
          "6: description = Scan for open S3 buckets and dump the contents",
          "",
          "[Removed Lines]",
          "3: version = 2.0.1",
          "",
          "[Added Lines]",
          "3: version = 2.0.2",
          "",
          "---------------"
        ],
        "tests/test_scanner.py||tests/test_scanner.py": [
          "File: tests/test_scanner.py -> tests/test_scanner.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "11:     s = S3Service()",
          "13:     a = subprocess.run([sys.executable, '-m', 'S3Scanner', '--version'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)",
          "16:     b = subprocess.run([sys.executable, '-m', 'S3Scanner', 'scan', '--bucket', 'flaws.cloud'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)",
          "17:     assert_scanner_output(s, 'flaws.cloud | bucket_exists | AuthUsers: [], AllUsers: [Read]', b.stdout.decode('utf-8').strip())",
          "",
          "[Removed Lines]",
          "14:     assert a.stdout.decode('utf-8').strip() == '2.0.1'",
          "",
          "[Added Lines]",
          "14:     assert a.stdout.decode('utf-8').strip() == '2.0.2'",
          "",
          "---------------"
        ]
      }
    }
  ]
}