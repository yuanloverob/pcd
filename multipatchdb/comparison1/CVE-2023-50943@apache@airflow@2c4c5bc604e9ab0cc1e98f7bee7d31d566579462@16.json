{
  "cve_id": "CVE-2023-50943",
  "cve_desc": "Apache Airflow, versions before 2.8.1, have a vulnerability that allows a potential attacker to poison the XCom data by bypassing the protection of \"enable_xcom_pickling=False\" configuration setting resulting in poisoned data after XCom deserialization. This vulnerability is considered low since it requires a DAG author to exploit it. Users are recommended to upgrade to version 2.8.1 or later, which fixes this issue.",
  "repo": "apache/airflow",
  "patch_hash": "2c4c5bc604e9ab0cc1e98f7bee7d31d566579462",
  "patch_info": {
    "commit_hash": "2c4c5bc604e9ab0cc1e98f7bee7d31d566579462",
    "repo": "apache/airflow",
    "commit_url": "https://github.com/apache/airflow/commit/2c4c5bc604e9ab0cc1e98f7bee7d31d566579462",
    "files": [
      "airflow/models/xcom.py",
      "tests/api_connexion/schemas/test_xcom_schema.py",
      "tests/models/test_xcom.py"
    ],
    "message": "Stop deserializing pickle when enable_xcom_pickling is False (#36255)\n\n* Stop deserializing pickle when enable_xcom_pickling is False\n\n* Fix unit tests\n\n(cherry picked from commit 63e97abec5d56bc62a293c93f5227f364561e51c)",
    "before_after_code_files": [
      "airflow/models/xcom.py||airflow/models/xcom.py",
      "tests/api_connexion/schemas/test_xcom_schema.py||tests/api_connexion/schemas/test_xcom_schema.py",
      "tests/models/test_xcom.py||tests/models/test_xcom.py"
    ]
  },
  "patch_diff": {
    "airflow/models/xcom.py||airflow/models/xcom.py": [
      "File: airflow/models/xcom.py -> airflow/models/xcom.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "685:             except pickle.UnpicklingError:",
      "686:                 return json.loads(result.value.decode(\"UTF-8\"), cls=XComDecoder, object_hook=object_hook)",
      "687:         else:",
      "693:     @staticmethod",
      "694:     def deserialize_value(result: XCom) -> Any:",
      "",
      "[Removed Lines]",
      "688:             try:",
      "689:                 return json.loads(result.value.decode(\"UTF-8\"), cls=XComDecoder, object_hook=object_hook)",
      "690:             except (json.JSONDecodeError, UnicodeDecodeError):",
      "691:                 return pickle.loads(result.value)",
      "",
      "[Added Lines]",
      "688:             # Since xcom_pickling is disabled, we should only try to deserialize with JSON",
      "689:             return json.loads(result.value.decode(\"UTF-8\"), cls=XComDecoder, object_hook=object_hook)",
      "",
      "---------------"
    ],
    "tests/api_connexion/schemas/test_xcom_schema.py||tests/api_connexion/schemas/test_xcom_schema.py": [
      "File: tests/api_connexion/schemas/test_xcom_schema.py -> tests/api_connexion/schemas/test_xcom_schema.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "30: from airflow.models import DagRun, XCom",
      "31: from airflow.utils.dates import parse_execution_date",
      "32: from airflow.utils.session import create_session",
      "34: pytestmark = pytest.mark.db_test",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "33: from tests.test_utils.config import conf_vars",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "188:     default_time = \"2016-04-02T21:00:00+00:00\"",
      "189:     default_time_parsed = parse_execution_date(default_time)",
      "191:     def test_serialize(self, create_xcom, session):",
      "192:         create_xcom(",
      "193:             dag_id=\"test_dag\",",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "192:     @conf_vars({(\"core\", \"enable_xcom_pickling\"): \"True\"})",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "208:             \"map_index\": -1,",
      "209:         }",
      "211:     def test_deserialize(self):",
      "212:         xcom_dump = {",
      "213:             \"key\": \"test_key\",",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "213:     @conf_vars({(\"core\", \"enable_xcom_pickling\"): \"True\"})",
      "",
      "---------------"
    ],
    "tests/models/test_xcom.py||tests/models/test_xcom.py": [
      "File: tests/models/test_xcom.py -> tests/models/test_xcom.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "140:             ret_value = XCom.get_value(key=\"xcom_test3\", ti_key=ti_key, session=session)",
      "141:         assert ret_value == {\"key\": \"value\"}",
      "144:         with conf_vars({(\"core\", \"enable_xcom_pickling\"): \"True\"}):",
      "145:             XCom.set(",
      "146:                 key=\"xcom_test3\",",
      "",
      "[Removed Lines]",
      "143:     def test_xcom_deserialize_with_pickle_to_json_switch(self, task_instance, session):",
      "",
      "[Added Lines]",
      "143:     def test_xcom_deserialize_pickle_when_xcom_pickling_is_disabled(self, task_instance, session):",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "151:                 session=session,",
      "152:             )",
      "153:         with conf_vars({(\"core\", \"enable_xcom_pickling\"): \"False\"}):",
      "163:     @conf_vars({(\"core\", \"xcom_enable_pickling\"): \"False\"})",
      "164:     def test_xcom_disable_pickle_type_fail_on_non_json(self, task_instance, session):",
      "",
      "[Removed Lines]",
      "154:             ret_value = XCom.get_one(",
      "155:                 key=\"xcom_test3\",",
      "156:                 dag_id=task_instance.dag_id,",
      "157:                 task_id=task_instance.task_id,",
      "158:                 run_id=task_instance.run_id,",
      "159:                 session=session,",
      "160:             )",
      "161:         assert ret_value == {\"key\": \"value\"}",
      "",
      "[Added Lines]",
      "154:             with pytest.raises(UnicodeDecodeError):",
      "155:                 XCom.get_one(",
      "156:                     key=\"xcom_test3\",",
      "157:                     dag_id=task_instance.dag_id,",
      "158:                     task_id=task_instance.task_id,",
      "159:                     run_id=task_instance.run_id,",
      "160:                     session=session,",
      "161:                 )",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "21a411d58ffb08638817acf958c3119198860c0f",
      "candidate_info": {
        "commit_hash": "21a411d58ffb08638817acf958c3119198860c0f",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/21a411d58ffb08638817acf958c3119198860c0f",
        "files": [
          "dev/breeze/src/airflow_breeze/global_constants.py"
        ],
        "message": "Add utkarsharma2 to committers list (#36474)\n\n(cherry picked from commit e3fb20d358646d276d4e275fa67d34b4fc13b73a)",
        "before_after_code_files": [
          "dev/breeze/src/airflow_breeze/global_constants.py||dev/breeze/src/airflow_breeze/global_constants.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "dev/breeze/src/airflow_breeze/global_constants.py||dev/breeze/src/airflow_breeze/global_constants.py": [
          "File: dev/breeze/src/airflow_breeze/global_constants.py -> dev/breeze/src/airflow_breeze/global_constants.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "338:     \"sekikn\",",
          "339:     \"turbaszek\",",
          "340:     \"uranusjr\",",
          "341:     \"vikramkoka\",",
          "342:     \"vincbeck\",",
          "343:     \"xinbinhuang\",",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "341:     \"utkarsharma2\",",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "5da2e0a4fd368e7cd520627e049d67b405c3b36f",
      "candidate_info": {
        "commit_hash": "5da2e0a4fd368e7cd520627e049d67b405c3b36f",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/5da2e0a4fd368e7cd520627e049d67b405c3b36f",
        "files": [
          "Dockerfile",
          "docker_tests/test_prod_image.py",
          "docs/docker-stack/changelog.rst"
        ],
        "message": "Use `mariadb` by default when build final prod image (#36716)\n\n(cherry picked from commit 11ec4100b3ffb86e15b43a8dde5f53f07d404508)",
        "before_after_code_files": [
          "docker_tests/test_prod_image.py||docker_tests/test_prod_image.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "docker_tests/test_prod_image.py||docker_tests/test_prod_image.py": [
          "File: docker_tests/test_prod_image.py -> docker_tests/test_prod_image.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "158:         \"grpc\": [\"grpc\", \"google.auth\", \"google_auth_httplib2\"],",
          "159:         \"hashicorp\": [\"hvac\"],",
          "160:         \"ldap\": [\"ldap\"],",
          "161:         \"postgres\": [\"psycopg2\"],",
          "162:         \"pyodbc\": [\"pyodbc\"],",
          "163:         \"redis\": [\"redis\"],",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "161:         \"mysql\": [\"MySQLdb\", *([\"mysql\"] if bool(find_spec(\"mysql\")) else [])],",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "167:         \"statsd\": [\"statsd\"],",
          "168:         \"virtualenv\": [\"virtualenv\"],",
          "169:     }",
          "173:     @pytest.mark.skipif(os.environ.get(\"TEST_SLIM_IMAGE\") == \"true\", reason=\"Skipped with slim image\")",
          "174:     @pytest.mark.parametrize(\"package_name,import_names\", PACKAGE_IMPORTS.items())",
          "",
          "[Removed Lines]",
          "170:     if bool(find_spec(\"mysql\")):",
          "171:         PACKAGE_IMPORTS[\"mysql\"] = [\"mysql\"]",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "1180255fccfef46db485adfd7afdb5a5ae63f00b",
      "candidate_info": {
        "commit_hash": "1180255fccfef46db485adfd7afdb5a5ae63f00b",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/1180255fccfef46db485adfd7afdb5a5ae63f00b",
        "files": [
          "airflow/www/static/js/dag/details/taskInstance/taskActions/MarkInstanceAs.tsx"
        ],
        "message": "enable mark task as failed/success always (#36254)\n\n(cherry picked from commit 20d547ecd886087cd89bcdf0015ce71dd0a12cef)",
        "before_after_code_files": [
          "airflow/www/static/js/dag/details/taskInstance/taskActions/MarkInstanceAs.tsx||airflow/www/static/js/dag/details/taskInstance/taskActions/MarkInstanceAs.tsx"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/www/static/js/dag/details/taskInstance/taskActions/MarkInstanceAs.tsx||airflow/www/static/js/dag/details/taskInstance/taskActions/MarkInstanceAs.tsx": [
          "File: airflow/www/static/js/dag/details/taskInstance/taskActions/MarkInstanceAs.tsx -> airflow/www/static/js/dag/details/taskInstance/taskActions/MarkInstanceAs.tsx",
          "--- Hunk 1 ---",
          "[Context before]",
          "296:           </Flex>",
          "297:         </MenuButton>",
          "298:         <MenuList>",
          "303:             <SimpleStatus state=\"failed\" mr={2} />",
          "304:             failed",
          "305:           </MenuItem>",
          "310:             <SimpleStatus state=\"success\" mr={2} />",
          "311:             success",
          "312:           </MenuItem>",
          "",
          "[Removed Lines]",
          "299:           <MenuItem",
          "300:             onClick={markAsFailed}",
          "301:             isDisabled={!isMappedSummary && currentState === \"failed\"}",
          "302:           >",
          "306:           <MenuItem",
          "307:             onClick={markAsSuccess}",
          "308:             isDisabled={!isMappedSummary && currentState === \"success\"}",
          "309:           >",
          "",
          "[Added Lines]",
          "299:           <MenuItem onClick={markAsFailed}>",
          "303:           <MenuItem onClick={markAsSuccess}>",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "5dad650b526374365681d72613a73475cdecf127",
      "candidate_info": {
        "commit_hash": "5dad650b526374365681d72613a73475cdecf127",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/5dad650b526374365681d72613a73475cdecf127",
        "files": [
          "airflow/auth/managers/base_auth_manager.py",
          "tests/api_connexion/endpoints/test_dag_run_endpoint.py"
        ],
        "message": "Bugfix: Webserver returns 500 for POST requests to api/dag/*/dagrun from anonymous user (#36275)\n\n* airflow#36110 -  bugfix\n\n* return type fixed\n\n* airflow#36110 -  bugfix\n\n* airflow#36110 -  fixes\n\n* airflow#36110 -  fixes\n\n* airflow#36110 -  adding test\n\n* airflow#36110 -  adding test\n\n* Fix unit test\n\n* Don't call get_id twice\n\n* Update app configuration after initialization\n\n---------\n\nCo-authored-by: hussein-awala <hussein@awala.fr>\nCo-authored-by: Tzu-ping Chung <uranusjr@gmail.com>\n(cherry picked from commit 71bc871d35cd3b562a49ce8f209098e2e24c1ef8)",
        "before_after_code_files": [
          "airflow/auth/managers/base_auth_manager.py||airflow/auth/managers/base_auth_manager.py",
          "tests/api_connexion/endpoints/test_dag_run_endpoint.py||tests/api_connexion/endpoints/test_dag_run_endpoint.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/auth/managers/base_auth_manager.py||airflow/auth/managers/base_auth_manager.py": [
          "File: airflow/auth/managers/base_auth_manager.py -> airflow/auth/managers/base_auth_manager.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "99:     def get_user(self) -> BaseUser | None:",
          "100:         \"\"\"Return the user associated to the user in session.\"\"\"",
          "103:         \"\"\"Return the user ID associated to the user in session.\"\"\"",
          "104:         user = self.get_user()",
          "105:         if not user:",
          "106:             self.log.error(\"Calling 'get_user_id()' but the user is not signed in.\")",
          "107:             raise AirflowException(\"The user must be signed in.\")",
          "110:     def init(self) -> None:",
          "111:         \"\"\"",
          "",
          "[Removed Lines]",
          "102:     def get_user_id(self) -> str:",
          "108:         return str(user.get_id())",
          "",
          "[Added Lines]",
          "102:     def get_user_id(self) -> str | None:",
          "108:         if user_id := user.get_id():",
          "109:             return str(user_id)",
          "110:         return None",
          "",
          "---------------"
        ],
        "tests/api_connexion/endpoints/test_dag_run_endpoint.py||tests/api_connexion/endpoints/test_dag_run_endpoint.py": [
          "File: tests/api_connexion/endpoints/test_dag_run_endpoint.py -> tests/api_connexion/endpoints/test_dag_run_endpoint.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1861:             environ_overrides={\"REMOTE_USER\": \"test\"},",
          "1862:         )",
          "1863:         assert response.status_code == 404",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1865:     @conf_vars(",
          "1866:         {",
          "1867:             (\"api\", \"auth_backends\"): \"airflow.api.auth.backend.default\",",
          "1868:         }",
          "1869:     )",
          "1870:     def test_should_respond_200_with_anonymous_user(self, dag_maker, session):",
          "1871:         from airflow.www import app as application",
          "1873:         app = application.create_app(testing=True)",
          "1874:         app.config[\"AUTH_ROLE_PUBLIC\"] = \"Admin\"",
          "1875:         dag_runs = self._create_test_dag_run(DagRunState.SUCCESS)",
          "1876:         session.add_all(dag_runs)",
          "1877:         session.commit()",
          "1878:         created_dr = dag_runs[0]",
          "1879:         response = app.test_client().patch(",
          "1880:             f\"api/v1/dags/{created_dr.dag_id}/dagRuns/TEST_DAG_RUN_ID_1/setNote\",",
          "1881:             json={\"note\": \"I am setting a note with anonymous user\"},",
          "1882:         )",
          "1883:         assert response.status_code == 200",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "21b58ecac36bcf81d24f9a79e02d88e4d04cc94d",
      "candidate_info": {
        "commit_hash": "21b58ecac36bcf81d24f9a79e02d88e4d04cc94d",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/21b58ecac36bcf81d24f9a79e02d88e4d04cc94d",
        "files": [
          "airflow/cli/commands/dag_command.py",
          "tests/cli/commands/test_dag_command.py"
        ],
        "message": "Raise error when ``DagRun`` fails while running ``dag test`` (#36517)\n\n**Motivation**:\n\nCurrently, when using `airflow dags test`, there is no easy way to know programmatically if a DagRun fails since the state is not stored in DB. The way to do know relies on log lines as below:\n\n```bash\nstate=$(airflow dags test exception_dag | grep \"DagRun Finished\" | awk -F, '{for(i=1;i<=NF;i++) if ($i ~ / state=/) print $i}' | awk -F= '{print $2}') if [[ $state == \"failed\" ]]; then exit 1 else exit 0 fi\n```\n\nThis PR adds will return an exit code 1 when `airflow dags test` command if DagRun fails and makes it easy to integrate in CI for testing.\n\n(cherry picked from commit 383ad31c76411fb0a9f7d4243729d7bb0640ff0c)",
        "before_after_code_files": [
          "airflow/cli/commands/dag_command.py||airflow/cli/commands/dag_command.py",
          "tests/cli/commands/test_dag_command.py||tests/cli/commands/test_dag_command.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/cli/commands/dag_command.py||airflow/cli/commands/dag_command.py": [
          "File: airflow/cli/commands/dag_command.py -> airflow/cli/commands/dag_command.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "515:             raise SystemExit(f\"Configuration {args.conf!r} is not valid JSON. Error: {e}\")",
          "516:     execution_date = args.execution_date or timezone.utcnow()",
          "517:     dag = dag or get_dag(subdir=args.subdir, dag_id=args.dag_id)",
          "519:     show_dagrun = args.show_dagrun",
          "520:     imgcat = args.imgcat_dagrun",
          "521:     filename = args.save_dagrun",
          "",
          "[Removed Lines]",
          "518:     dag.test(execution_date=execution_date, run_conf=run_conf, session=session)",
          "",
          "[Added Lines]",
          "518:     dr: DagRun = dag.test(execution_date=execution_date, run_conf=run_conf, session=session)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "536:         if show_dagrun:",
          "537:             print(dot_graph.source)",
          "540: @cli_utils.action_cli",
          "541: @providers_configuration_loaded",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "539:     if dr and dr.state == DagRunState.FAILED:",
          "540:         raise SystemExit(\"DagRun failed\")",
          "",
          "---------------"
        ],
        "tests/cli/commands/test_dag_command.py||tests/cli/commands/test_dag_command.py": [
          "File: tests/cli/commands/test_dag_command.py -> tests/cli/commands/test_dag_command.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "43: from airflow.triggers.temporal import DateTimeTrigger, TimeDeltaTrigger",
          "44: from airflow.utils import timezone",
          "45: from airflow.utils.session import create_session",
          "46: from airflow.utils.types import DagRunType",
          "47: from tests.models import TEST_DAGS_FOLDER",
          "48: from tests.test_utils.config import conf_vars",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "46: from airflow.utils.state import DagRunState",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "747:             ]",
          "748:         )",
          "750:     @mock.patch(\"airflow.cli.commands.dag_command.get_dag\")",
          "751:     @mock.patch(\"airflow.utils.timezone.utcnow\")",
          "752:     def test_dag_test_no_execution_date(self, mock_utcnow, mock_get_dag):",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "751:     @mock.patch(\"airflow.cli.commands.dag_command.get_dag\")",
          "752:     def test_dag_test_fail_raise_error(self, mock_get_dag):",
          "753:         execution_date_str = DEFAULT_DATE.isoformat()",
          "754:         mock_get_dag.return_value.test.return_value = DagRun(",
          "755:             dag_id=\"example_bash_operator\", execution_date=DEFAULT_DATE, state=DagRunState.FAILED",
          "756:         )",
          "757:         cli_args = self.parser.parse_args([\"dags\", \"test\", \"example_bash_operator\", execution_date_str])",
          "758:         with pytest.raises(SystemExit, match=r\"DagRun failed\"):",
          "759:             dag_command.dag_test(cli_args)",
          "",
          "---------------"
        ]
      }
    }
  ]
}