{
  "cve_id": "CVE-2021-45456",
  "cve_desc": "Apache kylin checks the legitimacy of the project before executing some commands with the project name passed in by the user. There is a mismatch between what is being checked and what is being used as the shell command argument in DiagnosisService. This may cause an illegal project name to pass the check and perform the following steps, resulting in a command injection vulnerability. This issue affects Apache Kylin 4.0.0.",
  "repo": "apache/kylin",
  "patch_hash": "f4daf14dde99b934c92ce2c832509f24342bc845",
  "patch_info": {
    "commit_hash": "f4daf14dde99b934c92ce2c832509f24342bc845",
    "repo": "apache/kylin",
    "commit_url": "https://github.com/apache/kylin/commit/f4daf14dde99b934c92ce2c832509f24342bc845",
    "files": [
      "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
      "core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java",
      "core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java",
      "server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java",
      "server/src/main/webapp/WEB-INF/web.xml"
    ],
    "message": "test fix",
    "before_after_code_files": [
      "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
      "core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java||core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java",
      "core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java||core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java",
      "server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java||server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java"
    ]
  },
  "patch_diff": {
    "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java": [
      "File: core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java -> core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "3403:     public String getKerberosPrincipal() {",
      "3404:         return getOptional(\"kylin.kerberos.principal\");",
      "3405:     }",
      "3406: }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "3407:     public String getEncryptCipherIvSpec() {",
      "3408:         return getOptional(\"kylin.security.encrypt.cipher.ivSpec\", \"AAAAAAAAAAAAAAAA\");",
      "3409:     }",
      "",
      "---------------"
    ],
    "core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java||core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java": [
      "File: core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java -> core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "25: import java.security.NoSuchAlgorithmException;",
      "27: import org.apache.commons.codec.binary.Base64;",
      "29: import javax.crypto.Cipher;",
      "30: import javax.crypto.NoSuchPaddingException;",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "28: import org.apache.kylin.common.KylinConfig;",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "42:             InvalidKeyException, NoSuchPaddingException, NoSuchAlgorithmException, UnsupportedEncodingException {",
      "43:         Cipher cipher = Cipher.getInstance(\"AES/CFB/PKCS5Padding\");",
      "44:         final SecretKeySpec secretKey = new SecretKeySpec(key, \"AES\");",
      "46:         cipher.init(cipherMode, secretKey, ivSpec);",
      "47:         return cipher;",
      "48:     }",
      "",
      "[Removed Lines]",
      "45:         IvParameterSpec ivSpec = new IvParameterSpec(\"AAAAAAAAAAAAAAAA\".getBytes(\"UTF-8\"));",
      "",
      "[Added Lines]",
      "46:         IvParameterSpec ivSpec = new IvParameterSpec(KylinConfig.getInstanceFromEnv().getEncryptCipherIvSpec().getBytes(\"UTF-8\"));",
      "",
      "---------------"
    ],
    "core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java||core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java": [
      "File: core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java -> core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "19: package org.apache.kylin.common.util;",
      "21: import org.junit.Assert;",
      "22: import org.junit.Test;",
      "26:     @Test",
      "27:     public void testAESEncrypt(){",
      "",
      "[Removed Lines]",
      "24: public class EncryptUtilTest {",
      "",
      "[Added Lines]",
      "21: import org.junit.After;",
      "23: import org.junit.Before;",
      "26: public class EncryptUtilTest extends LocalFileMetadataTestCase {",
      "27:     @Before",
      "28:     public void setUp() throws Exception {",
      "29:         this.createTestMetadata();",
      "30:     }",
      "32:     @After",
      "33:     public void after() throws Exception {",
      "34:         this.cleanupTestMetadata();",
      "35:     }",
      "",
      "---------------"
    ],
    "server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java||server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java": [
      "File: server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java -> server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "87:     public String dumpProjectDiagnosisInfo(String project, File exportPath) throws IOException {",
      "88:         Message msg = MsgPicker.getMsg();",
      "89:         ProjectInstance projectInstance =",
      "90:                 ProjectManager.getInstance(KylinConfig.getInstanceFromEnv())",
      "92:         if (null == projectInstance) {",
      "93:             throw new BadRequestException(",
      "95:         }",
      "96:         aclEvaluate.checkProjectOperationPermission(projectInstance);",
      "98:         runDiagnosisCLI(args);",
      "99:         return getDiagnosisPackageName(exportPath);",
      "100:     }",
      "",
      "[Removed Lines]",
      "91:                         .getProject(ValidateUtil.convertStringToBeAlphanumericUnderscore(project));",
      "94:                     String.format(Locale.ROOT, msg.getDIAG_PROJECT_NOT_FOUND(), project));",
      "97:         String[] args = { project, exportPath.getAbsolutePath() };",
      "",
      "[Added Lines]",
      "89:         String projectName = ValidateUtil.convertStringToBeAlphanumericUnderscore(project);",
      "92:                         .getProject(projectName);",
      "95:                     String.format(Locale.ROOT, msg.getDIAG_PROJECT_NOT_FOUND(), projectName));",
      "98:         String[] args = { projectName, exportPath.getAbsolutePath() };",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "c29b8f5b5ffa4d33ea2120a4efe261a6fbab1b01",
      "candidate_info": {
        "commit_hash": "c29b8f5b5ffa4d33ea2120a4efe261a6fbab1b01",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/c29b8f5b5ffa4d33ea2120a4efe261a6fbab1b01",
        "files": [
          "kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/job/NSparkExecutable.java"
        ],
        "message": "KYLIN-5160 Fix driver extra classpath",
        "before_after_code_files": [
          "kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/job/NSparkExecutable.java||kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/job/NSparkExecutable.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/job/NSparkExecutable.java||kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/job/NSparkExecutable.java": [
          "File: kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/job/NSparkExecutable.java -> kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/job/NSparkExecutable.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "408:             appendSparkConf(sb, \"spark.executor.extraClassPath\", Paths.get(kylinJobJar).getFileName().toString());",
          "409:         }",
          "412:                 String.format(Locale.ROOT, \"%s:%s\", APP_JAR_NAME,",
          "415:         String sparkUploadFiles = config.sparkUploadFiles(isLocalMaster(sparkConfs), isYarnCluster);",
          "416:         if (StringUtils.isNotBlank(sparkUploadFiles)) {",
          "",
          "[Removed Lines]",
          "411:         appendSparkConf(sb, \"spark.driver.extraClassPath\", isYarnCluster ? //",
          "413:                         Paths.get(kylinJobJar).getFileName().toString()) : kylinJobJar);",
          "",
          "[Added Lines]",
          "411:         String extraClassPath = sparkConfs.getOrDefault(\"spark.driver.extraClassPath\", \"\");",
          "412:         String parquetJarPath = isYarnCluster ? //",
          "414:                         Paths.get(kylinJobJar).getFileName().toString()) : kylinJobJar;",
          "415:         extraClassPath = extraClassPath.equals(\"\") ? parquetJarPath : String.format(Locale.ROOT, \"%s:%s\", parquetJarPath, extraClassPath);",
          "416:         appendSparkConf(sb, \"spark.driver.extraClassPath\", extraClassPath);",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "9d671222709827ccc3d8f1052625f357c788dc85",
      "candidate_info": {
        "commit_hash": "9d671222709827ccc3d8f1052625f357c788dc85",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/9d671222709827ccc3d8f1052625f357c788dc85",
        "files": [
          "core-metrics/pom.xml",
          "core-metrics/src/main/java/org/apache/kylin/metrics/lib/impl/RecordEvent.java",
          "core-metrics/src/main/java/org/apache/kylin/metrics/lib/impl/TimePropertyEnum.java",
          "core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/BlockingReservoirTest.java",
          "core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/InstantReservoirTest.java",
          "core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/MetricsSystemTest.java",
          "core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/RecordEventTest.java",
          "core-metrics/src/test/java/org/apache/kylin/metrics/property/MetricsPropertyEnumTest.java"
        ],
        "message": "KYLIN-4508 Add more unit tests for core-metrics module\n\nSigned-off-by: shaofengshi <shaofengshi@apache.org>\n\n(cherry picked from commit 2d718c83db2abd91d053b77a44ed4a98648adcdc)",
        "before_after_code_files": [
          "core-metrics/src/main/java/org/apache/kylin/metrics/lib/impl/RecordEvent.java||core-metrics/src/main/java/org/apache/kylin/metrics/lib/impl/RecordEvent.java",
          "core-metrics/src/main/java/org/apache/kylin/metrics/lib/impl/TimePropertyEnum.java||core-metrics/src/main/java/org/apache/kylin/metrics/lib/impl/TimePropertyEnum.java",
          "core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/BlockingReservoirTest.java||core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/BlockingReservoirTest.java",
          "core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/InstantReservoirTest.java||core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/InstantReservoirTest.java",
          "core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/MetricsSystemTest.java||core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/MetricsSystemTest.java",
          "core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/RecordEventTest.java||core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/RecordEventTest.java",
          "core-metrics/src/test/java/org/apache/kylin/metrics/property/MetricsPropertyEnumTest.java||core-metrics/src/test/java/org/apache/kylin/metrics/property/MetricsPropertyEnumTest.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "core-metrics/src/main/java/org/apache/kylin/metrics/lib/impl/RecordEvent.java||core-metrics/src/main/java/org/apache/kylin/metrics/lib/impl/RecordEvent.java": [
          "File: core-metrics/src/main/java/org/apache/kylin/metrics/lib/impl/RecordEvent.java -> core-metrics/src/main/java/org/apache/kylin/metrics/lib/impl/RecordEvent.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "66:         this(eventType, LOCAL_HOSTNAME);",
          "67:     }",
          "69:     public RecordEvent(String eventType, String host) {",
          "70:         this(eventType, host, System.currentTimeMillis());",
          "71:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "69:     public RecordEvent(String eventType, long time) {",
          "70:         this(eventType, LOCAL_HOSTNAME, time);",
          "71:     }",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "268:             return reserveKey;",
          "269:         }",
          "272:             for (RecordReserveKeyEnum reserveKey : RecordReserveKeyEnum.values()) {",
          "273:                 if (reserveKey.reserveKey.equalsIgnoreCase(key)) {",
          "274:                     return reserveKey;",
          "",
          "[Removed Lines]",
          "271:         public RecordReserveKeyEnum getByKey(String key) {",
          "",
          "[Added Lines]",
          "275:         public static RecordReserveKeyEnum getByKey(String key) {",
          "",
          "---------------"
        ],
        "core-metrics/src/main/java/org/apache/kylin/metrics/lib/impl/TimePropertyEnum.java||core-metrics/src/main/java/org/apache/kylin/metrics/lib/impl/TimePropertyEnum.java": [
          "File: core-metrics/src/main/java/org/apache/kylin/metrics/lib/impl/TimePropertyEnum.java -> core-metrics/src/main/java/org/apache/kylin/metrics/lib/impl/TimePropertyEnum.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "38:         this.propertyName = propertyName;",
          "39:     }",
          "42:         if (Strings.isNullOrEmpty(propertyName)) {",
          "43:             return null;",
          "44:         }",
          "",
          "[Removed Lines]",
          "41:     public static TimePropertyEnum getByPropertyName(String propertyName) {",
          "",
          "[Added Lines]",
          "41:     public static TimePropertyEnum getByKey(String propertyName) {",
          "",
          "---------------"
        ],
        "core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/BlockingReservoirTest.java||core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/BlockingReservoirTest.java": [
          "File: core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/BlockingReservoirTest.java -> core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/BlockingReservoirTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19: package org.apache.kylin.metrics.lib.impl;",
          "21: import static org.junit.Assert.assertEquals;",
          "23: import org.apache.kylin.common.util.LocalFileMetadataTestCase;",
          "24: import org.apache.kylin.metrics.lib.Record;",
          "25: import org.junit.After;",
          "26: import org.junit.Assert;",
          "27: import org.junit.Before;",
          "28: import org.junit.Test;",
          "30: public class BlockingReservoirTest extends LocalFileMetadataTestCase {",
          "32:     @Before",
          "33:     public void setUp() throws Exception {",
          "34:         this.createTestMetadata();",
          "35:     }",
          "37:     @After",
          "38:     public void after() throws Exception {",
          "39:         this.cleanupTestMetadata();",
          "40:     }",
          "42:     @Test",
          "43:     public void testUpdate() {",
          "44:         BlockingReservoir reservoir = new BlockingReservoir();",
          "46:         Record record = new RecordEvent(\"TEST\");",
          "47:         reservoir.update(record);",
          "48:         assertEquals(0, reservoir.size());",
          "50:         reservoir.start();",
          "51:         reservoir.update(record);",
          "52:         assertEquals(1, reservoir.size());",
          "54:         reservoir.stop();",
          "55:         assertEquals(0, reservoir.size());",
          "56:     }",
          "58:     @Test",
          "59:     public void testBatchSize() {",
          "60:         BlockingReservoir reservoir = new BlockingReservoir(5, 12);",
          "61:         reservoir.setReady();",
          "63:         for (int i = 0; i < 30; i++) {",
          "64:             Record record = new RecordEvent(\"TEST\" + i);",
          "65:             reservoir.update(record);",
          "66:         }",
          "67:         reservoir.notifyUpdate();",
          "68:         Assert.assertEquals(18, reservoir.size());",
          "70:         reservoir.notifyUpdate();",
          "71:         Assert.assertEquals(6, reservoir.size());",
          "73:         reservoir.notifyUpdate();",
          "74:         Assert.assertEquals(0, reservoir.size());",
          "75:     }",
          "76: }",
          "",
          "---------------"
        ],
        "core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/InstantReservoirTest.java||core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/InstantReservoirTest.java": [
          "File: core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/InstantReservoirTest.java -> core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/InstantReservoirTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19: package org.apache.kylin.metrics.lib.impl;",
          "21: import static org.junit.Assert.assertEquals;",
          "22: import static org.junit.Assert.assertTrue;",
          "24: import org.apache.kylin.common.util.LocalFileMetadataTestCase;",
          "25: import org.apache.kylin.metrics.lib.ActiveReservoirListener;",
          "26: import org.apache.kylin.metrics.lib.Record;",
          "27: import org.junit.After;",
          "28: import org.junit.Before;",
          "29: import org.junit.Test;",
          "31: import com.google.common.collect.Lists;",
          "33: public class InstantReservoirTest extends LocalFileMetadataTestCase {",
          "35:     @Before",
          "36:     public void setUp() throws Exception {",
          "37:         this.createTestMetadata();",
          "38:     }",
          "40:     @After",
          "41:     public void after() throws Exception {",
          "42:         this.cleanupTestMetadata();",
          "43:     }",
          "45:     @Test",
          "46:     public void testUpdate() {",
          "47:         InstantReservoir reservoir = new InstantReservoir();",
          "48:         ActiveReservoirListener listener = new StubReservoirReporter().listener;",
          "49:         reservoir.addListener(listener);",
          "51:         Record record = new RecordEvent(\"TEST\");",
          "52:         assertTrue(listener.onRecordUpdate(Lists.newArrayList(record)));",
          "54:         reservoir.update(record);",
          "55:         assertEquals(0, reservoir.size());",
          "57:         reservoir.start();",
          "58:         reservoir.update(record);",
          "59:         assertEquals(0, reservoir.size());",
          "61:         reservoir.stop();",
          "62:         assertEquals(0, reservoir.size());",
          "63:     }",
          "64: }",
          "",
          "---------------"
        ],
        "core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/MetricsSystemTest.java||core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/MetricsSystemTest.java": [
          "File: core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/MetricsSystemTest.java -> core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/MetricsSystemTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19: package org.apache.kylin.metrics.lib.impl;",
          "21: import static org.apache.kylin.metrics.lib.impl.MetricsSystem.Metrics;",
          "22: import static org.junit.Assert.assertEquals;",
          "23: import static org.junit.Assert.assertFalse;",
          "24: import static org.junit.Assert.assertTrue;",
          "26: import org.apache.kylin.metrics.lib.ActiveReservoir;",
          "27: import org.apache.kylin.metrics.lib.ActiveReservoirRecordFilter;",
          "28: import org.junit.Test;",
          "30: public class MetricsSystemTest {",
          "32:     @Test(expected = IllegalArgumentException.class)",
          "33:     public void testDuplicateRegister() {",
          "34:         String name = \"test1\";",
          "35:         Metrics.register(name, new StubReservoir());",
          "36:         Metrics.register(name, new StubReservoir());",
          "37:     }",
          "39:     @Test(expected = IllegalArgumentException.class)",
          "40:     public void testNullRegister1() {",
          "41:         Metrics.register(null, new StubReservoir());",
          "42:     }",
          "44:     @Test",
          "45:     public void testActiveReservoir() {",
          "47:         Metrics.removeActiveReservoirMatching(ActiveReservoirRecordFilter.ALL);",
          "48:         assertEquals(0, Metrics.getActiveReservoirs().size());",
          "51:         int n = 10;",
          "52:         for (int i = 0; i < n; i++) {",
          "53:             Metrics.register(\"ActiveReservoir-\" + i, new StubReservoir());",
          "54:         }",
          "55:         assertEquals(n, Metrics.getActiveReservoirs().size());",
          "57:         String name = \"test2\";",
          "58:         ActiveReservoir activeReservoir = new StubReservoir();",
          "59:         Metrics.register(name, activeReservoir);",
          "62:         assertEquals(activeReservoir, Metrics.activeReservoir(name));",
          "64:         assertTrue(Metrics.removeActiveReservoir(name));",
          "65:         assertFalse(Metrics.removeActiveReservoir(name));",
          "66:     }",
          "67: }",
          "",
          "---------------"
        ],
        "core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/RecordEventTest.java||core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/RecordEventTest.java": [
          "File: core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/RecordEventTest.java -> core-metrics/src/test/java/org/apache/kylin/metrics/lib/impl/RecordEventTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19: package org.apache.kylin.metrics.lib.impl;",
          "21: import static org.junit.Assert.assertEquals;",
          "22: import static org.junit.Assert.assertNull;",
          "23: import static org.junit.Assert.assertTrue;",
          "25: import java.io.IOException;",
          "26: import java.net.InetAddress;",
          "27: import java.net.UnknownHostException;",
          "28: import java.util.Map;",
          "30: import org.apache.kylin.common.util.JsonUtil;",
          "31: import org.junit.Test;",
          "33: import com.google.common.collect.Maps;",
          "35: public class RecordEventTest {",
          "37:     @Test(expected = IllegalArgumentException.class)",
          "38:     public void testSetEventType() {",
          "39:         new RecordEvent(null, System.currentTimeMillis());",
          "40:     }",
          "42:     @Test",
          "43:     public void testBasic() throws IOException {",
          "44:         String type = \"TEST\";",
          "45:         String localHostname;",
          "46:         try {",
          "47:             InetAddress addr = InetAddress.getLocalHost();",
          "48:             localHostname = addr.getHostName() + \":\" + addr.getHostAddress();",
          "49:         } catch (UnknownHostException e) {",
          "50:             localHostname = \"Unknown\";",
          "51:         }",
          "52:         long time = System.currentTimeMillis();",
          "53:         RecordEvent event = new RecordEvent(type, localHostname, time);",
          "55:         assertEquals(type, event.getEventType());",
          "56:         assertEquals(localHostname, event.getHost());",
          "57:         assertTrue(time == event.getTime());",
          "59:         String key = \"PROJECT\";",
          "60:         String value = \"test\";",
          "61:         event.put(key, value);",
          "62:         assertEquals(value, event.remove(key));",
          "64:         int len1 = event.size();",
          "65:         Map<String, Object> entryMap = Maps.newHashMap();",
          "66:         for (int i = 0; i < 5; i++) {",
          "67:             entryMap.put(key + \"-\" + i, value + \"-\" + i);",
          "68:         }",
          "69:         event.putAll(entryMap);",
          "70:         assertEquals(entryMap.size(), event.size() - len1);",
          "72:         assertTrue(event.clone().equals(event));",
          "74:         Map<String, Object> rawValue = JsonUtil.readValue(event.getValue(), Map.class);",
          "75:         assertEquals(event.size() - 1, rawValue.size());",
          "77:         assertNull(rawValue.get(RecordEvent.RecordReserveKeyEnum.EVENT_SUBJECT.toString()));",
          "79:         event.clear();",
          "80:         assertTrue(event.isEmpty());",
          "81:     }",
          "82: }",
          "",
          "---------------"
        ],
        "core-metrics/src/test/java/org/apache/kylin/metrics/property/MetricsPropertyEnumTest.java||core-metrics/src/test/java/org/apache/kylin/metrics/property/MetricsPropertyEnumTest.java": [
          "File: core-metrics/src/test/java/org/apache/kylin/metrics/property/MetricsPropertyEnumTest.java -> core-metrics/src/test/java/org/apache/kylin/metrics/property/MetricsPropertyEnumTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19: package org.apache.kylin.metrics.property;",
          "21: import static org.junit.Assert.assertEquals;",
          "22: import static org.junit.Assert.assertNull;",
          "24: import org.apache.kylin.metrics.lib.impl.RecordEvent;",
          "25: import org.apache.kylin.metrics.lib.impl.TimePropertyEnum;",
          "26: import org.junit.Test;",
          "28: public class MetricsPropertyEnumTest {",
          "30:     @Test",
          "31:     public void testJobPropertyEnum() {",
          "32:         assertEquals(JobPropertyEnum.ID_CODE, JobPropertyEnum.getByName(\"JOB_ID\"));",
          "33:         assertEquals(JobPropertyEnum.USER, JobPropertyEnum.getByName(\"KUSER\"));",
          "34:         assertEquals(JobPropertyEnum.PROJECT, JobPropertyEnum.getByName(\"PROJECT\"));",
          "35:         assertEquals(JobPropertyEnum.CUBE, JobPropertyEnum.getByName(\"CUBE_NAME\"));",
          "36:         assertEquals(JobPropertyEnum.TYPE, JobPropertyEnum.getByName(\"JOB_TYPE\"));",
          "37:         assertEquals(JobPropertyEnum.ALGORITHM, JobPropertyEnum.getByName(\"CUBING_TYPE\"));",
          "38:         assertEquals(JobPropertyEnum.STATUS, JobPropertyEnum.getByName(\"JOB_STATUS\"));",
          "39:         assertEquals(JobPropertyEnum.EXCEPTION, JobPropertyEnum.getByName(\"EXCEPTION\"));",
          "40:         assertEquals(JobPropertyEnum.SOURCE_SIZE, JobPropertyEnum.getByName(\"TABLE_SIZE\"));",
          "41:         assertEquals(JobPropertyEnum.CUBE_SIZE, JobPropertyEnum.getByName(\"CUBE_SIZE\"));",
          "42:         assertEquals(JobPropertyEnum.BUILD_DURATION, JobPropertyEnum.getByName(\"DURATION\"));",
          "43:         assertEquals(JobPropertyEnum.WAIT_RESOURCE_TIME, JobPropertyEnum.getByName(\"WAIT_RESOURCE_TIME\"));",
          "44:         assertEquals(JobPropertyEnum.PER_BYTES_TIME_COST, JobPropertyEnum.getByName(\"PER_BYTES_TIME_COST\"));",
          "45:         assertEquals(JobPropertyEnum.STEP_DURATION_DISTINCT_COLUMNS,",
          "46:                 JobPropertyEnum.getByName(\"STEP_DURATION_DISTINCT_COLUMNS\"));",
          "47:         assertEquals(JobPropertyEnum.STEP_DURATION_DICTIONARY, JobPropertyEnum.getByName(\"STEP_DURATION_DICTIONARY\"));",
          "48:         assertEquals(JobPropertyEnum.STEP_DURATION_INMEM_CUBING,",
          "49:                 JobPropertyEnum.getByName(\"STEP_DURATION_INMEM_CUBING\"));",
          "50:         assertEquals(JobPropertyEnum.STEP_DURATION_HFILE_CONVERT,",
          "51:                 JobPropertyEnum.getByName(\"STEP_DURATION_HFILE_CONVERT\"));",
          "52:         assertNull(RecordEvent.RecordReserveKeyEnum.getByKey(null));",
          "53:     }",
          "55:     @Test",
          "56:     public void testQueryPropertyEnum() {",
          "57:         assertEquals(QueryPropertyEnum.ID_CODE, QueryPropertyEnum.getByName(\"QUERY_HASH_CODE\"));",
          "58:         assertEquals(QueryPropertyEnum.TYPE, QueryPropertyEnum.getByName(\"QUERY_TYPE\"));",
          "59:         assertEquals(QueryPropertyEnum.USER, QueryPropertyEnum.getByName(\"KUSER\"));",
          "60:         assertEquals(QueryPropertyEnum.PROJECT, QueryPropertyEnum.getByName(\"PROJECT\"));",
          "61:         assertEquals(QueryPropertyEnum.REALIZATION, QueryPropertyEnum.getByName(\"REALIZATION\"));",
          "62:         assertEquals(QueryPropertyEnum.REALIZATION_TYPE, QueryPropertyEnum.getByName(\"REALIZATION_TYPE\"));",
          "63:         assertEquals(QueryPropertyEnum.EXCEPTION, QueryPropertyEnum.getByName(\"EXCEPTION\"));",
          "64:         assertEquals(QueryPropertyEnum.TIME_COST, QueryPropertyEnum.getByName(\"QUERY_TIME_COST\"));",
          "65:         assertEquals(QueryPropertyEnum.CALCITE_RETURN_COUNT, QueryPropertyEnum.getByName(\"CALCITE_COUNT_RETURN\"));",
          "66:         assertEquals(QueryPropertyEnum.STORAGE_RETURN_COUNT, QueryPropertyEnum.getByName(\"STORAGE_COUNT_RETURN\"));",
          "67:         assertEquals(QueryPropertyEnum.AGGR_FILTER_COUNT,",
          "68:                 QueryPropertyEnum.getByName(\"CALCITE_COUNT_AGGREGATE_FILTER\"));",
          "69:         assertNull(RecordEvent.RecordReserveKeyEnum.getByKey(null));",
          "70:     }",
          "72:     @Test",
          "73:     public void testQueryCubePropertyEnum() {",
          "74:         assertEquals(QueryCubePropertyEnum.PROJECT, QueryCubePropertyEnum.getByName(\"PROJECT\"));",
          "75:         assertEquals(QueryCubePropertyEnum.CUBE, QueryCubePropertyEnum.getByName(\"CUBE_NAME\"));",
          "76:         assertEquals(QueryCubePropertyEnum.SEGMENT, QueryCubePropertyEnum.getByName(\"SEGMENT_NAME\"));",
          "77:         assertEquals(QueryCubePropertyEnum.CUBOID_SOURCE, QueryCubePropertyEnum.getByName(\"CUBOID_SOURCE\"));",
          "78:         assertEquals(QueryCubePropertyEnum.CUBOID_TARGET, QueryCubePropertyEnum.getByName(\"CUBOID_TARGET\"));",
          "79:         assertEquals(QueryCubePropertyEnum.IF_MATCH, QueryCubePropertyEnum.getByName(\"IF_MATCH\"));",
          "80:         assertEquals(QueryCubePropertyEnum.FILTER_MASK, QueryCubePropertyEnum.getByName(\"FILTER_MASK\"));",
          "81:         assertEquals(QueryCubePropertyEnum.IF_SUCCESS, QueryCubePropertyEnum.getByName(\"IF_SUCCESS\"));",
          "82:         assertEquals(QueryCubePropertyEnum.TIME_SUM, QueryCubePropertyEnum.getByName(\"STORAGE_CALL_TIME_SUM\"));",
          "83:         assertEquals(QueryCubePropertyEnum.TIME_MAX, QueryCubePropertyEnum.getByName(\"STORAGE_CALL_TIME_MAX\"));",
          "84:         assertEquals(QueryCubePropertyEnum.WEIGHT_PER_HIT, QueryCubePropertyEnum.getByName(\"WEIGHT_PER_HIT\"));",
          "85:         assertEquals(QueryCubePropertyEnum.CALL_COUNT, QueryCubePropertyEnum.getByName(\"STORAGE_CALL_COUNT\"));",
          "86:         assertEquals(QueryCubePropertyEnum.SKIP_COUNT, QueryCubePropertyEnum.getByName(\"STORAGE_COUNT_SKIP\"));",
          "87:         assertEquals(QueryCubePropertyEnum.SCAN_COUNT, QueryCubePropertyEnum.getByName(\"STORAGE_COUNT_SCAN\"));",
          "88:         assertEquals(QueryCubePropertyEnum.RETURN_COUNT, QueryCubePropertyEnum.getByName(\"STORAGE_COUNT_RETURN\"));",
          "89:         assertEquals(QueryCubePropertyEnum.AGGR_FILTER_COUNT,",
          "90:                 QueryCubePropertyEnum.getByName(\"STORAGE_COUNT_AGGREGATE_FILTER\"));",
          "91:         assertEquals(QueryCubePropertyEnum.AGGR_COUNT, QueryCubePropertyEnum.getByName(\"STORAGE_COUNT_AGGREGATE\"));",
          "92:         assertNull(RecordEvent.RecordReserveKeyEnum.getByKey(null));",
          "93:     }",
          "95:     @Test",
          "96:     public void testQueryRPCPropertyEnum() {",
          "97:         assertEquals(QueryRPCPropertyEnum.PROJECT, QueryRPCPropertyEnum.getByName(\"PROJECT\"));",
          "98:         assertEquals(QueryRPCPropertyEnum.REALIZATION, QueryRPCPropertyEnum.getByName(\"REALIZATION\"));",
          "99:         assertEquals(QueryRPCPropertyEnum.RPC_SERVER, QueryRPCPropertyEnum.getByName(\"RPC_SERVER\"));",
          "100:         assertEquals(QueryRPCPropertyEnum.EXCEPTION, QueryRPCPropertyEnum.getByName(\"EXCEPTION\"));",
          "101:         assertEquals(QueryRPCPropertyEnum.CALL_TIME, QueryRPCPropertyEnum.getByName(\"CALL_TIME\"));",
          "102:         assertEquals(QueryRPCPropertyEnum.SKIP_COUNT, QueryRPCPropertyEnum.getByName(\"COUNT_SKIP\"));",
          "103:         assertEquals(QueryRPCPropertyEnum.SCAN_COUNT, QueryRPCPropertyEnum.getByName(\"COUNT_SCAN\"));",
          "104:         assertEquals(QueryRPCPropertyEnum.RETURN_COUNT, QueryRPCPropertyEnum.getByName(\"COUNT_RETURN\"));",
          "105:         assertEquals(QueryRPCPropertyEnum.AGGR_FILTER_COUNT, QueryRPCPropertyEnum.getByName(\"COUNT_AGGREGATE_FILTER\"));",
          "106:         assertEquals(QueryRPCPropertyEnum.AGGR_COUNT, QueryRPCPropertyEnum.getByName(\"COUNT_AGGREGATE\"));",
          "107:         assertNull(RecordEvent.RecordReserveKeyEnum.getByKey(null));",
          "108:     }",
          "110:     @Test",
          "111:     public void testTimePropertyEnum() {",
          "112:         assertEquals(TimePropertyEnum.YEAR, TimePropertyEnum.getByKey(\"KYEAR_BEGIN_DATE\"));",
          "113:         assertEquals(TimePropertyEnum.MONTH, TimePropertyEnum.getByKey(\"KMONTH_BEGIN_DATE\"));",
          "114:         assertEquals(TimePropertyEnum.WEEK_BEGIN_DATE, TimePropertyEnum.getByKey(\"KWEEK_BEGIN_DATE\"));",
          "115:         assertEquals(TimePropertyEnum.DAY_DATE, TimePropertyEnum.getByKey(\"KDAY_DATE\"));",
          "116:         assertEquals(TimePropertyEnum.DAY_TIME, TimePropertyEnum.getByKey(\"KDAY_TIME\"));",
          "117:         assertEquals(TimePropertyEnum.TIME_HOUR, TimePropertyEnum.getByKey(\"KTIME_HOUR\"));",
          "118:         assertEquals(TimePropertyEnum.TIME_MINUTE, TimePropertyEnum.getByKey(\"KTIME_MINUTE\"));",
          "119:         assertEquals(TimePropertyEnum.TIME_SECOND, TimePropertyEnum.getByKey(\"KTIME_SECOND\"));",
          "120:         assertNull(RecordEvent.RecordReserveKeyEnum.getByKey(null));",
          "121:     }",
          "123:     @Test",
          "124:     public void testRecordReserveKeyEnum() {",
          "125:         assertEquals(RecordEvent.RecordReserveKeyEnum.EVENT_SUBJECT,",
          "126:                 RecordEvent.RecordReserveKeyEnum.getByKey(\"EVENT_TYPE\"));",
          "127:         assertEquals(RecordEvent.RecordReserveKeyEnum.ID, RecordEvent.RecordReserveKeyEnum.getByKey(\"EVENT_ID\"));",
          "128:         assertEquals(RecordEvent.RecordReserveKeyEnum.HOST, RecordEvent.RecordReserveKeyEnum.getByKey(\"HOST\"));",
          "129:         assertEquals(RecordEvent.RecordReserveKeyEnum.TIME, RecordEvent.RecordReserveKeyEnum.getByKey(\"KTIMESTAMP\"));",
          "130:         assertNull(RecordEvent.RecordReserveKeyEnum.getByKey(null));",
          "131:     }",
          "132: }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "6f4e3562d9061bee4ef3288f35e9e53133a9e9cd",
      "candidate_info": {
        "commit_hash": "6f4e3562d9061bee4ef3288f35e9e53133a9e9cd",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/6f4e3562d9061bee4ef3288f35e9e53133a9e9cd",
        "files": [
          "build/bin/find-hive-dependency.sh",
          "build/bin/kylin.sh",
          "build/bin/replace-jars-under-spark.sh"
        ],
        "message": "KYLIN-4858 Support Kylin4 deployment on CDH 6.X (#1535)\n\n* KYLIN-4858 Support Kylin4 deployment on CDH 6.X\n\n* KYLIN-4858 Support Kylin4 deployment on CDH 6.X",
        "before_after_code_files": [
          "build/bin/find-hive-dependency.sh||build/bin/find-hive-dependency.sh",
          "build/bin/kylin.sh||build/bin/kylin.sh",
          "build/bin/replace-jars-under-spark.sh||build/bin/replace-jars-under-spark.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "build/bin/find-hive-dependency.sh||build/bin/find-hive-dependency.sh": [
          "File: build/bin/find-hive-dependency.sh -> build/bin/find-hive-dependency.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "197:     fi",
          "198:     hive_lib_dir=\"$HIVE_LIB\"",
          "199: fi",
          "202: validateDirectory ${hive_conf_path}",
          "203: checkFileExist hive_lib ${hive_lib}",
          "",
          "[Removed Lines]",
          "200: hive_lib=`find -L ${hive_lib_dir} -name '*.jar' ! -name '*druid*' ! -name '*slf4j*' ! -name '*avatica*' ! -name '*calcite*' ! -name '*jackson-datatype-joda*' ! -name '*derby*' -printf '%p:' | sed 's/:$//'`",
          "",
          "[Added Lines]",
          "201: hive_lib=`find -L ${hive_lib_dir} -name '*.jar' ! -name '*druid*' ! -name '*slf4j*' ! -name '*avatica*' ! -name '*calcite*' \\",
          "202:     ! -name '*jackson-datatype-joda*' ! -name '*derby*'  ! -name \"*jetty*\" ! -name \"*jsp*\" ! -name \"*servlet*\" ! -name \"*hbase*\" ! -name \"*websocket*\" \\",
          "203:     -printf '%p:' | sed 's/:$//'`",
          "",
          "---------------"
        ],
        "build/bin/kylin.sh||build/bin/kylin.sh": [
          "File: build/bin/kylin.sh -> build/bin/kylin.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "62:         # source ${dir}/find-flink-dependency.sh",
          "63:     fi",
          "65:     # get hdp_version",
          "66:     if [ -z \"${hdp_version}\" ]; then",
          "67:         hdp_version=`/bin/bash -x hadoop 2>&1 | sed -n \"s/\\(.*\\)export HDP_VERSION=\\(.*\\)/\\2/\"p`",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "65:     # Replace jars for different hadoop dist",
          "66:     bash ${dir}/replace-jars-under-spark.sh",
          "",
          "---------------"
        ],
        "build/bin/replace-jars-under-spark.sh||build/bin/replace-jars-under-spark.sh": [
          "File: build/bin/replace-jars-under-spark.sh -> build/bin/replace-jars-under-spark.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: #!/bin/bash",
          "3: #",
          "4: # Licensed to the Apache Software Foundation (ASF) under one or more",
          "5: # contributor license agreements.  See the NOTICE file distributed with",
          "6: # this work for additional information regarding copyright ownership.",
          "7: # The ASF licenses this file to You under the Apache License, Version 2.0",
          "8: # (the \"License\"); you may not use this file except in compliance with",
          "9: # the License.  You may obtain a copy of the License at",
          "10: #",
          "11: #    http://www.apache.org/licenses/LICENSE-2.0",
          "12: #",
          "13: # Unless required by applicable law or agreed to in writing, software",
          "14: # distributed under the License is distributed on an \"AS IS\" BASIS,",
          "15: # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
          "16: # See the License for the specific language governing permissions and",
          "17: # limitations under the License.",
          "18: #",
          "20: BYPASS=${KYLIN_HOME}/spark/jars/replace-jars-bypass",
          "21: cdh_mapreduce_path=\"/opt/cloudera/parcels/CDH/lib/hadoop-mapreduce\"",
          "22: hadoop_lib_path=\"/usr/lib/hadoop\"",
          "24: if [ -f ${BYPASS} ]; then",
          "25:   exit 0",
          "26: fi",
          "28: if [ ! -d \"$KYLIN_HOME/spark\" ]; then",
          "29:   echo \"Skip spark which not owned by kylin. SPARK_HOME is $SPARK_HOME and KYLIN_HOME is $KYLIN_HOME .\"",
          "30:   exit 0",
          "31: fi",
          "33: echo \"Start replacing hadoop jars under ${SPARK_HOME}/jars.\"",
          "35: function check_cdh_hadoop() {",
          "36:   # hadoop-common-3.0.0-cdh6.2.0.jar",
          "37:   hadoop_common_file=$(find ${cdh_mapreduce_path}/../hadoop/ -maxdepth 1 -name \"hadoop-common-*.jar\" -not -name \"*test*\" | tail -1)",
          "38:   cdh_version=${hadoop_common_file##*-}",
          "39:   if [[ \"${cdh_version}\" == cdh6.* ]]; then",
          "40:     export is_cdh6=1",
          "41:   else",
          "42:     export is_cdh6=0",
          "43:   fi",
          "44:   if [[ \"${cdh_version}\" == cdh5.* ]]; then",
          "45:     export is_cdh5=1",
          "46:   else",
          "47:     export is_cdh5=0",
          "48:   fi",
          "49: }",
          "51: function check_aws_emr() {",
          "52:   if [ ! -d $hadoop_lib_path ]; then",
          "53:     return 0",
          "54:   fi",
          "56:   # hadoop-common-3.2.1-amzn-0.jar",
          "57:   hadoop_common_file=$(find $hadoop_lib_path -maxdepth 1 -name \"hadoop-common-*.jar\" -not -name \"*test*\" | tail -1)",
          "58:   emr_version_1=${hadoop_common_file##*common-}",
          "59:   echo $emr_version_1",
          "60:   arrVersion=(${emr_version_1//-/ })",
          "62:   if [[ \"${arrVersion[0]}\" == 3.* && \"${arrVersion[1]}\" == *amzn* ]]; then",
          "63:     export is_emr6=1",
          "64:   else",
          "65:     export is_emr6=0",
          "66:   fi",
          "68:   if [[ \"${arrVersion[0]}\" == 2.* && \"${arrVersion[1]}\" == *amzn* ]]; then",
          "69:     export is_emr5=1",
          "70:   else",
          "71:     export is_emr5=0",
          "72:   fi",
          "73: }",
          "75: check_cdh_hadoop",
          "76: check_aws_emr",
          "78: common_jars=",
          "79: hdfs_jars=",
          "80: mr_jars=",
          "81: yarn_jars=",
          "82: other_jars=",
          "84: if [ $is_cdh6 == 1 ]; then",
          "85:   common_jars=$(find $cdh_mapreduce_path/../hadoop -maxdepth 2 \\",
          "86:     -name \"hadoop-annotations-*.jar\" -not -name \"*test*\" \\",
          "87:     -o -name \"hadoop-auth-*.jar\" -not -name \"*test*\" \\",
          "88:     -o -name \"hadoop-common-*.jar\" -not -name \"*test*\")",
          "90:   hdfs_jars=$(find $cdh_mapreduce_path/../hadoop-hdfs -maxdepth 1 -name \"hadoop-hdfs-*\" -not -name \"*test*\" -not -name \"*nfs*\")",
          "92:   mr_jars=$(find $cdh_mapreduce_path -maxdepth 1 \\",
          "93:     -name \"hadoop-mapreduce-client-app-*.jar\" -not -name \"*test*\" \\",
          "94:     -o -name \"hadoop-mapreduce-client-common-*.jar\" -not -name \"*test*\" \\",
          "95:     -o -name \"hadoop-mapreduce-client-jobclient-*.jar\" -not -name \"*test*\" \\",
          "96:     -o -name \"hadoop-mapreduce-client-shuffle-*.jar\" -not -name \"*test*\" \\",
          "97:     -o -name \"hadoop-mapreduce-client-core-*.jar\" -not -name \"*test*\")",
          "99:   yarn_jars=$(find $cdh_mapreduce_path/../hadoop-yarn -maxdepth 1 \\",
          "100:     -name \"hadoop-yarn-api-*.jar\" -not -name \"*test*\" \\",
          "101:     -o -name \"hadoop-yarn-client-*.jar\" -not -name \"*test*\" \\",
          "102:     -o -name \"hadoop-yarn-common-*.jar\" -not -name \"*test*\" \\",
          "103:     -o -name \"hadoop-yarn-server-common-*.jar\" -not -name \"*test*\" \\",
          "104:     -o -name \"hadoop-yarn-server-web-proxy-*.jar\" -not -name \"*test*\")",
          "106:   other_jars=$(find $cdh_mapreduce_path/../../jars -maxdepth 1 -name \"htrace-core4*\" || find $cdh_mapreduce_path/../hadoop -maxdepth 2 -name \"htrace-core4*\")",
          "108:   if [[ $is_cdh6 == 1 ]]; then",
          "109:     cdh6_jars=$(find ${cdh_mapreduce_path}/../../jars -maxdepth 1 \\",
          "110:       -name \"woodstox-core-*.jar\" -o -name \"commons-configuration2-*.jar\" -o -name \"re2j-*.jar\")",
          "111:   fi",
          "112: fi",
          "114: jar_list=\"${common_jars} ${hdfs_jars} ${mr_jars} ${yarn_jars} ${other_jars} ${cdh6_jars}\"",
          "116: echo \"Find platform specific jars:${jar_list}, will replace with these jars under ${SPARK_HOME}/jars.\"",
          "118: if [ $is_cdh6 == 1 ]; then",
          "119:   find ${KYLIN_HOME}/spark/jars -name \"hadoop-hdfs-*.jar\" -exec rm -f {} \\;",
          "120:   find ${KYLIN_HOME}/spark/jars -name \"hadoop-yarn-*.jar\" -exec rm -f {} \\;",
          "121:   find ${KYLIN_HOME}/spark/jars -name \"hadoop-mapreduce-*.jar\" -exec rm -f {} \\;",
          "122:   find ${KYLIN_HOME}/spark/jars -name \"hive-exec-*.jar\" -exec rm -f {} \\;",
          "123: #  cp ${KYLIN_HOME}/bin/hadoop3_jars/cdh6/*.jar ${SPARK_HOME}/jars",
          "124: fi",
          "126: for jar_file in ${jar_list}; do",
          "127:   $(cp ${jar_file} ${KYLIN_HOME}/spark/jars)",
          "128: done",
          "130: # Remove all spaces",
          "131: jar_list=${jar_list// /}",
          "133: if [ -z \"${jar_list}\" ]; then",
          "134:   echo \"Please confirm that the corresponding hadoop jars have been replaced. The automatic replacement program cannot be executed correctly.\"",
          "135: else",
          "136:   echo \"Replace jars under SPARK_HOME/jars finished.\"",
          "137:   touch ${BYPASS}",
          "138: fi",
          "140: echo \"Done hadoop jars replacement under ${SPARK_HOME}/jars.\"",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "bf02b8c2d33bfd27cc29d4ce8fd5faff92be9c77",
      "candidate_info": {
        "commit_hash": "bf02b8c2d33bfd27cc29d4ce8fd5faff92be9c77",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/bf02b8c2d33bfd27cc29d4ce8fd5faff92be9c77",
        "files": [
          "core-metadata/src/main/java/org/apache/kylin/measure/percentile/PercentileCounter.java",
          "core-metadata/src/main/java/org/apache/kylin/measure/percentile/PercentileSerializer.java",
          "kylin-it/src/test/resources/query/sql_exactly_agg/query11.sql",
          "kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/KylinFunctions.scala",
          "kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/catalyst/expressions/KylinExpresssions.scala",
          "kylin-spark-project/kylin-spark-common/src/main/spark24/org/apache/spark/sql/catalyst/expressions/ExpressionUtils.scala",
          "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/AggregatePlan.scala"
        ],
        "message": "KYLIN-5082,exactly match for percentile",
        "before_after_code_files": [
          "core-metadata/src/main/java/org/apache/kylin/measure/percentile/PercentileCounter.java||core-metadata/src/main/java/org/apache/kylin/measure/percentile/PercentileCounter.java",
          "core-metadata/src/main/java/org/apache/kylin/measure/percentile/PercentileSerializer.java||core-metadata/src/main/java/org/apache/kylin/measure/percentile/PercentileSerializer.java",
          "kylin-it/src/test/resources/query/sql_exactly_agg/query11.sql||kylin-it/src/test/resources/query/sql_exactly_agg/query11.sql",
          "kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/KylinFunctions.scala||kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/KylinFunctions.scala",
          "kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/catalyst/expressions/KylinExpresssions.scala||kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/catalyst/expressions/KylinExpresssions.scala",
          "kylin-spark-project/kylin-spark-common/src/main/spark24/org/apache/spark/sql/catalyst/expressions/ExpressionUtils.scala||kylin-spark-project/kylin-spark-common/src/main/spark24/org/apache/spark/sql/catalyst/expressions/ExpressionUtils.scala",
          "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/AggregatePlan.scala||kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/AggregatePlan.scala"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "core-metadata/src/main/java/org/apache/kylin/measure/percentile/PercentileCounter.java||core-metadata/src/main/java/org/apache/kylin/measure/percentile/PercentileCounter.java": [
          "File: core-metadata/src/main/java/org/apache/kylin/measure/percentile/PercentileCounter.java -> core-metadata/src/main/java/org/apache/kylin/measure/percentile/PercentileCounter.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "64:         return registers.quantile(quantileRatio);",
          "65:     }",
          "67:     public void writeRegisters(ByteBuffer out) {",
          "68:         registers.compress();",
          "69:         registers.asSmallBytes(out);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "67:     public Double getResultEstimateWithQuantileRatio(double quantileRatio) {",
          "68:         if (registers.size() == 0) {",
          "69:             return null;",
          "70:         }",
          "71:         return registers.quantile(quantileRatio);",
          "72:     }",
          "",
          "---------------"
        ],
        "core-metadata/src/main/java/org/apache/kylin/measure/percentile/PercentileSerializer.java||core-metadata/src/main/java/org/apache/kylin/measure/percentile/PercentileSerializer.java": [
          "File: core-metadata/src/main/java/org/apache/kylin/measure/percentile/PercentileSerializer.java -> core-metadata/src/main/java/org/apache/kylin/measure/percentile/PercentileSerializer.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "33:         this.compression = type.getPrecision();",
          "34:     }",
          "36:     @Override",
          "37:     public int peekLength(ByteBuffer in) {",
          "38:         return current().peekLength(in);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "36:     public PercentileSerializer(int precision) {",
          "37:         this.compression = precision;",
          "38:     }",
          "",
          "---------------"
        ],
        "kylin-it/src/test/resources/query/sql_exactly_agg/query11.sql||kylin-it/src/test/resources/query/sql_exactly_agg/query11.sql": [
          "File: kylin-it/src/test/resources/query/sql_exactly_agg/query11.sql -> kylin-it/src/test/resources/query/sql_exactly_agg/query11.sql",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: --",
          "2: -- Licensed to the Apache Software Foundation (ASF) under one",
          "3: -- or more contributor license agreements.  See the NOTICE file",
          "4: -- distributed with this work for additional information",
          "5: -- regarding copyright ownership.  The ASF licenses this file",
          "6: -- to you under the Apache License, Version 2.0 (the",
          "7: -- \"License\"); you may not use this file except in compliance",
          "8: -- with the License.  You may obtain a copy of the License at",
          "9: --",
          "10: --     http://www.apache.org/licenses/LICENSE-2.0",
          "11: --",
          "12: -- Unless required by applicable law or agreed to in writing, software",
          "13: -- distributed under the License is distributed on an \"AS IS\" BASIS,",
          "14: -- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
          "15: -- See the License for the specific language governing permissions and",
          "16: -- limitations under the License.",
          "17: --",
          "19: SELECT percentile(price, 0.6) from test_kylin_fact",
          "20: group by LSTG_FORMAT_NAME, LSTG_SITE_ID, SLR_SEGMENT_CD",
          "21: ;{\"scanRowCount\":300,\"scanBytes\":0,\"scanFiles\":1,\"cuboidId\":[14336],\"exactlyMatched\":[true]}",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/KylinFunctions.scala||kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/KylinFunctions.scala": [
          "File: kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/KylinFunctions.scala -> kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/KylinFunctions.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: import org.apache.spark.sql.catalyst.analysis.FunctionRegistry.FunctionBuilder",
          "23: import org.apache.spark.sql.catalyst.expressions.codegen.{CodegenContext, ExprCode}",
          "24: import org.apache.spark.sql.types._",
          "29: import org.apache.spark.sql.catalyst.expressions.aggregate.AggregateFunction",
          "30: import org.apache.spark.sql.udaf.{ApproxCountDistinct, IntersectCount, PreciseCountDistinct}",
          "",
          "[Removed Lines]",
          "25: import org.apache.spark.sql.catalyst.expressions.{ApproxCountDistinctDecode, BinaryExpression,",
          "26:   DictEncode, Expression, ExpressionInfo, ExpressionUtils, ImplicitCastInputTypes, In,",
          "27:   KylinAddMonths, Like, Literal, PreciseCountDistinctDecode, RoundBase, ScatterSkewData, SplitPart, Sum0,",
          "28:   TimestampAdd, TimestampDiff, Truncate, UnaryExpression}",
          "",
          "[Added Lines]",
          "25: import org.apache.spark.sql.catalyst.expressions.{ApproxCountDistinctDecode, BinaryExpression, DictEncode, Expression, ExpressionInfo, ExpressionUtils, ImplicitCastInputTypes, In, KylinAddMonths, Like, Literal, PercentileDecode, PreciseCountDistinctDecode, RoundBase, ScatterSkewData, SplitPart, Sum0, TimestampAdd, TimestampDiff, Truncate, UnaryExpression}",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "75:   def approx_count_distinct_decode(column: Column, precision: Int): Column =",
          "76:     Column(ApproxCountDistinctDecode(column.expr, Literal(precision)))",
          "78:   def precise_count_distinct(column: Column): Column =",
          "79:     Column(PreciseCountDistinct(column.expr).toAggregateExpression())",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "75:   def k_percentile_decode(column: Column, p: Column, precision: Int): Column =",
          "76:     Column(PercentileDecode(column.expr, p.expr, Literal(precision)))",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/catalyst/expressions/KylinExpresssions.scala||kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/catalyst/expressions/KylinExpresssions.scala": [
          "File: kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/catalyst/expressions/KylinExpresssions.scala -> kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/catalyst/expressions/KylinExpresssions.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: import com.esotericsoftware.kryo.io.{Input, KryoDataInput}",
          "21: import org.apache.kylin.engine.spark.common.util.KylinDateTimeUtils",
          "22: import org.apache.kylin.measure.hllc.HLLCounter",
          "23: import org.apache.spark.dict.{NBucketDictionary, NGlobalDictionary}",
          "24: import org.apache.spark.sql.catalyst.InternalRow",
          "25: import org.apache.spark.sql.catalyst.expressions.aggregate.DeclarativeAggregate",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "23: import org.apache.kylin.measure.percentile.PercentileSerializer",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "543:   override def dataType: DataType = StringType",
          "545:   override def inputTypes: Seq[AbstractDataType] = Seq(AnyDataType, AnyDataType)",
          "546: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "547: }",
          "549: case class PercentileDecode(bytes: Expression, quantile: Expression, precision: Expression) extends TernaryExpression with ExpectsInputTypes {",
          "551:   override def inputTypes: Seq[AbstractDataType] = Seq(BinaryType, DecimalType, IntegerType)",
          "553:   override protected def doGenCode(ctx: CodegenContext, ev: ExprCode): ExprCode = {",
          "554:     val expressionUtils = ExpressionUtils.getClass.getName.stripSuffix(\"$\")",
          "555:     defineCodeGen(ctx, ev, (bytes, quantile, precision) => {",
          "556:       s\"\"\"$expressionUtils.percentileDecodeHelper($bytes, $quantile, $precision)\"\"\"",
          "557:     })",
          "558:   }",
          "560:   override protected def nullSafeEval(bytes: Any, quantile: Any, precision: Any): Any = {",
          "561:     val arrayBytes = bytes.asInstanceOf[Array[Byte]]",
          "562:     val serializer = new PercentileSerializer(precision.asInstanceOf[Int]);",
          "563:     val counter = serializer.deserialize(ByteBuffer.wrap(arrayBytes))",
          "564:     counter.getResultEstimateWithQuantileRatio(quantile.asInstanceOf[Decimal].toDouble)",
          "565:   }",
          "567:   override def dataType: DataType = DoubleType",
          "569:   override def prettyName: String = \"percentile_decode\"",
          "571:   override def nullable: Boolean = false",
          "573:   override def children: Seq[Expression] = Seq(bytes, quantile, precision)",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-common/src/main/spark24/org/apache/spark/sql/catalyst/expressions/ExpressionUtils.scala||kylin-spark-project/kylin-spark-common/src/main/spark24/org/apache/spark/sql/catalyst/expressions/ExpressionUtils.scala": [
          "File: kylin-spark-project/kylin-spark-common/src/main/spark24/org/apache/spark/sql/catalyst/expressions/ExpressionUtils.scala -> kylin-spark-project/kylin-spark-common/src/main/spark24/org/apache/spark/sql/catalyst/expressions/ExpressionUtils.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: package org.apache.spark.sql.catalyst.expressions",
          "21: import scala.util.{Failure, Success, Try}",
          "22: import scala.reflect.ClassTag",
          "23: import org.apache.spark.sql.AnalysisException",
          "24: import org.apache.spark.sql.catalyst.analysis.FunctionRegistry.{FunctionBuilder, expressions}",
          "25: import org.apache.spark.sql.execution.datasources.DataSourceStrategy",
          "26: import org.apache.spark.sql.sources.Filter",
          "30:   def expression[T <: Expression](name: String)",
          "31:     (implicit tag: ClassTag[T]): (String, (ExpressionInfo, FunctionBuilder)) = {",
          "",
          "[Removed Lines]",
          "28: object",
          "29: ExpressionUtils {",
          "",
          "[Added Lines]",
          "21: import org.apache.kylin.measure.percentile.PercentileSerializer",
          "28: import org.apache.spark.sql.types.Decimal",
          "29: import java.nio.ByteBuffer",
          "31: object ExpressionUtils {",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "109:       new ExpressionInfo(clazz.getCanonicalName, name)",
          "110:     }",
          "111:   }",
          "112: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "115:   def percentileDecodeHelper(bytes: Any, quantile: Any, precision: Any): Double = {",
          "116:     val arrayBytes = bytes.asInstanceOf[Array[Byte]]",
          "117:     val serializer = new PercentileSerializer(precision.asInstanceOf[Int]);",
          "118:     val counter = serializer.deserialize(ByteBuffer.wrap(arrayBytes))",
          "119:     counter.getResultEstimateWithQuantileRatio(quantile.asInstanceOf[Decimal].toDouble)",
          "120:   }",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/AggregatePlan.scala||kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/AggregatePlan.scala": [
          "File: kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/AggregatePlan.scala -> kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/AggregatePlan.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "60:       val hash = System.identityHashCode(rel).toString",
          "61:       val aggCols = rel.getRewriteAggCalls.asScala.zipWithIndex.map {",
          "64:           val dataType = call.getFunc.getReturnDataType",
          "65:           val funcName = OLAPAggregateRel.getAggrFuncName(call)",
          "66:           val argNames = call.getArgList.asScala.map(dataFrame.schema.names.apply(_))",
          "67:           val columnName = argNames.map(col)",
          "68:           val aggName = SchemaProcessor.replaceToAggravateSchemaName(index, funcName, hash, argNames: _*)",
          "79:           }",
          "80:         case (call: Any, index: Int) =>",
          "81:           col(schemaNames.apply(call.getArgList.get(0)))",
          "",
          "[Removed Lines]",
          "62:         case (call: KylinAggregateCall, index: Int)",
          "63:           if OLAPAggregateRel.getAggrFuncName(call).equals(\"COUNT_DISTINCT\") =>",
          "69:           if (call.isHllCountDistinctFunc) {",
          "70:             KylinFunctions",
          "71:               .approx_count_distinct_decode(columnName.head, dataType.getPrecision)",
          "72:               .alias(aggName)",
          "73:           } else if (call.isBitmapCountDistinctFunc) {",
          "75:             KylinFunctions.precise_count_distinct_decode(columnName.head).alias(aggName)",
          "76:           } else {",
          "77:             throw new IllegalArgumentException(",
          "78:               s\"\"\"Unsupported function name $funcName\"\"\")",
          "",
          "[Added Lines]",
          "62:         case (call: KylinAggregateCall, index: Int) =>",
          "68:           funcName match {",
          "69:             case FunctionDesc.FUNC_COUNT_DISTINCT =>",
          "70:               if (call.isHllCountDistinctFunc) {",
          "71:                 KylinFunctions",
          "72:                   .approx_count_distinct_decode(columnName.head, dataType.getPrecision)",
          "73:                   .alias(aggName)",
          "74:               } else if (call.isBitmapCountDistinctFunc) {",
          "76:                 KylinFunctions.precise_count_distinct_decode(columnName.head).alias(aggName)",
          "77:               } else {",
          "78:                 throw new IllegalArgumentException(",
          "79:                   s\"\"\"Unsupported function name $funcName\"\"\")",
          "80:               }",
          "81:             case FunctionDesc.FUNC_PERCENTILE =>",
          "82:               val aggName = SchemaProcessor.replaceToAggravateSchemaName(index, \"PERCENTILE_DECODE\", hash, argNames: _*)",
          "83:               KylinFunctions.k_percentile_decode(columnName.head, columnName(1), dataType.getPrecision).alias(aggName)",
          "84:             case _ =>",
          "85:               col(schemaNames.apply(call.getArgList.get(0)))",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "223:       .isSum0",
          "224:   }",
          "228:   def isExactlyCuboidMatched(rel: OLAPAggregateRel, groupByList: List[Column]): Boolean = {",
          "229:     val olapContext = rel.getContext",
          "",
          "[Removed Lines]",
          "226:   val exactlyMatchSupportedFunctions = List(\"SUM\", \"MIN\", \"MAX\", \"COUNT_DISTINCT\")",
          "",
          "[Added Lines]",
          "233:   val exactlyMatchSupportedFunctions = List(\"SUM\", \"MIN\", \"MAX\", \"COUNT_DISTINCT\", \"PERCENTILE\", \"PERCENTILE_APPROX\")",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "241:         return false",
          "242:       }",
          "245:     }",
          "246:     val groupByCols = rel.getGroups.asScala.map(_.getIdentity).toSet",
          "247:     if (groupByCols.isEmpty) return false",
          "",
          "[Removed Lines]",
          "244:       if (call.getArgList.size() > 1) return false",
          "",
          "[Added Lines]",
          "251:       if (call.getArgList.size() > 1 && !OLAPAggregateRel.getAggrFuncName(call).startsWith(\"PERCENTILE\")) {",
          "252:         return false",
          "253:       }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "19dd0b8406dc6370f6df6e5cc76b0c854785a787",
      "candidate_info": {
        "commit_hash": "19dd0b8406dc6370f6df6e5cc76b0c854785a787",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/19dd0b8406dc6370f6df6e5cc76b0c854785a787",
        "files": [
          "query/src/main/java/org/apache/kylin/query/routing/RealizationChooser.java"
        ],
        "message": "KYLIN-4634 Fail to specify cube in model of low priority to query\n\n(cherry picked from commit 8ebe41818a93eb782eca4d614755ea69c9e189d5)",
        "before_after_code_files": [
          "query/src/main/java/org/apache/kylin/query/routing/RealizationChooser.java||query/src/main/java/org/apache/kylin/query/routing/RealizationChooser.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "query/src/main/java/org/apache/kylin/query/routing/RealizationChooser.java||query/src/main/java/org/apache/kylin/query/routing/RealizationChooser.java": [
          "File: query/src/main/java/org/apache/kylin/query/routing/RealizationChooser.java -> query/src/main/java/org/apache/kylin/query/routing/RealizationChooser.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "185:             }",
          "187:             RealizationCost cost = new RealizationCost(real);",
          "188:             DataModelDesc m = real.getModel();",
          "189:             Set<IRealization> set = models.get(m);",
          "190:             if (set == null) {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "188:             if (BackdoorToggles.getForceHitCube() != null && BackdoorToggles.getForceHitCube().equalsIgnoreCase(real.getName())) {",
          "189:                 logger.info(\"Force choose {} as selected model for specific purpose.\", real.getModel());",
          "190:                 cost = new RealizationCost(-1, 0);",
          "191:             }",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "238:         final public int priority;",
          "239:         final public int cost;",
          "241:         public RealizationCost(IRealization real) {",
          "243:             this.priority = Candidate.PRIORITIES.get(real.getType());",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "245:         public RealizationCost(int priority, int cost) {",
          "246:             this.priority = priority;",
          "247:             this.cost = cost;",
          "248:         }",
          "",
          "---------------"
        ]
      }
    }
  ]
}