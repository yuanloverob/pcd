{
  "cve_id": "CVE-2023-42780",
  "cve_desc": "Apache Airflow, versions prior to 2.7.2, contains a security vulnerability that allows authenticated users of Airflow to list warnings for all DAGs, even if the user had no permission to see those DAGs. It would reveal the dag_ids and the stack-traces of import errors for those DAGs with import errors.\nUsers of Apache Airflow are advised to upgrade to version 2.7.2 or newer to mitigate the risk associated with this vulnerability.\n\n",
  "repo": "apache/airflow",
  "patch_hash": "cf4eb3fb9b5cf4a8369b890e39523d4c05eed161",
  "patch_info": {
    "commit_hash": "cf4eb3fb9b5cf4a8369b890e39523d4c05eed161",
    "repo": "apache/airflow",
    "commit_url": "https://github.com/apache/airflow/commit/cf4eb3fb9b5cf4a8369b890e39523d4c05eed161",
    "files": [
      "airflow/api_connexion/endpoints/dag_warning_endpoint.py",
      "tests/api_connexion/endpoints/test_dag_warning_endpoint.py"
    ],
    "message": "Fix dag warning endpoint permissions (#34355)\n\n* Fix dag warning endpoint permissions\n\n* update the query to have an accurate result for total entries and pagination\n\n* add unit tests\n\n* Update test_dag_warning_endpoint.py\n\nCo-authored-by: Tzu-ping Chung <uranusjr@gmail.com>\n\n---------\n\nCo-authored-by: Tzu-ping Chung <uranusjr@gmail.com>\n(cherry picked from commit 3570bbfbea69e2965f91b9964ce28bc268c68129)",
    "before_after_code_files": [
      "airflow/api_connexion/endpoints/dag_warning_endpoint.py||airflow/api_connexion/endpoints/dag_warning_endpoint.py",
      "tests/api_connexion/endpoints/test_dag_warning_endpoint.py||tests/api_connexion/endpoints/test_dag_warning_endpoint.py"
    ]
  },
  "patch_diff": {
    "airflow/api_connexion/endpoints/dag_warning_endpoint.py||airflow/api_connexion/endpoints/dag_warning_endpoint.py": [
      "File: airflow/api_connexion/endpoints/dag_warning_endpoint.py -> airflow/api_connexion/endpoints/dag_warning_endpoint.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "16: # under the License.",
      "17: from __future__ import annotations",
      "19: from sqlalchemy import select",
      "20: from sqlalchemy.orm import Session",
      "22: from airflow.api_connexion import security",
      "23: from airflow.api_connexion.parameters import apply_sorting, check_limit, format_parameters",
      "24: from airflow.api_connexion.schemas.dag_warning_schema import (",
      "25:     DagWarningCollection,",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "19: from flask import g",
      "24: from airflow.api_connexion.exceptions import PermissionDenied",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "28: from airflow.api_connexion.types import APIResponse",
      "29: from airflow.models.dagwarning import DagWarning as DagWarningModel",
      "30: from airflow.security import permissions",
      "31: from airflow.utils.db import get_query_count",
      "32: from airflow.utils.session import NEW_SESSION, provide_session",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "33: from airflow.utils.airflow_flask_app import get_airflow_app",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "52:     allowed_filter_attrs = [\"dag_id\", \"warning_type\", \"message\", \"timestamp\"]",
      "53:     query = select(DagWarningModel)",
      "54:     if dag_id:",
      "55:         query = query.where(DagWarningModel.dag_id == dag_id)",
      "56:     if warning_type:",
      "57:         query = query.where(DagWarningModel.warning_type == warning_type)",
      "58:     total_entries = get_query_count(query, session=session)",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "58:         if not get_airflow_app().appbuilder.sm.can_read_dag(dag_id, g.user):",
      "59:             raise PermissionDenied(detail=f\"User not allowed to access this DAG: {dag_id}\")",
      "61:     else:",
      "62:         readable_dags = get_airflow_app().appbuilder.sm.get_accessible_dag_ids(g.user)",
      "63:         query = query.where(DagWarningModel.dag_id.in_(readable_dags))",
      "",
      "---------------"
    ],
    "tests/api_connexion/endpoints/test_dag_warning_endpoint.py||tests/api_connexion/endpoints/test_dag_warning_endpoint.py": [
      "File: tests/api_connexion/endpoints/test_dag_warning_endpoint.py -> tests/api_connexion/endpoints/test_dag_warning_endpoint.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "35:         app,  # type:ignore",
      "36:         username=\"test\",",
      "37:         role_name=\"Test\",",
      "39:     )",
      "40:     create_user(app, username=\"test_no_permissions\", role_name=\"TestNoPermissions\")  # type: ignore",
      "42:     yield minimal_app_for_api",
      "44:     delete_user(app, username=\"test\")  # type: ignore",
      "45:     delete_user(app, username=\"test_no_permissions\")  # type: ignore",
      "48: class TestBaseDagWarning:",
      "",
      "[Removed Lines]",
      "38:         permissions=[(permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG_WARNING)],  # type: ignore",
      "",
      "[Added Lines]",
      "38:         permissions=[",
      "39:             (permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG_WARNING),",
      "40:             (permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG),",
      "41:         ],  # type: ignore",
      "44:     create_user(",
      "45:         app,  # type:ignore",
      "46:         username=\"test_with_dag2_read\",",
      "47:         role_name=\"TestWithDag2Read\",",
      "48:         permissions=[",
      "49:             (permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG_WARNING),",
      "50:             (permissions.ACTION_CAN_READ, f\"{permissions.RESOURCE_DAG_PREFIX}dag2\"),",
      "51:         ],  # type: ignore",
      "52:     )",
      "58:     delete_user(app, username=\"test_with_dag2_read\")  # type: ignore",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "147:             \"/api/v1/dagWarnings\", environ_overrides={\"REMOTE_USER\": \"test_no_permissions\"}",
      "148:         )",
      "149:         assert response.status_code == 403",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "164:     def test_should_raise_403_forbidden_when_user_has_no_dag_read_permission(self):",
      "165:         response = self.client.get(",
      "166:             \"/api/v1/dagWarnings\",",
      "167:             environ_overrides={\"REMOTE_USER\": \"test_with_dag2_read\"},",
      "168:             query_string={\"dag_id\": \"dag1\"},",
      "169:         )",
      "170:         assert response.status_code == 403",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "7232953b22eff615a6ff94772f770fa50fcc7c01",
      "candidate_info": {
        "commit_hash": "7232953b22eff615a6ff94772f770fa50fcc7c01",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/7232953b22eff615a6ff94772f770fa50fcc7c01",
        "files": [
          "airflow/www/static/js/dag/grid/dagRuns/Bar.tsx"
        ],
        "message": "correcting wrong time showing in grid view (#34179)\n\n* correcting wrong time showing in grid view\n\n* lint errors resolved\n\n* lint errors resolved\n\n(cherry picked from commit 8871f9591cc164f7692bd3fa0088f5e565d7d498)",
        "before_after_code_files": [
          "airflow/www/static/js/dag/grid/dagRuns/Bar.tsx||airflow/www/static/js/dag/grid/dagRuns/Bar.tsx"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/34775"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/www/static/js/dag/grid/dagRuns/Bar.tsx||airflow/www/static/js/dag/grid/dagRuns/Bar.tsx": [
          "File: airflow/www/static/js/dag/grid/dagRuns/Bar.tsx -> airflow/www/static/js/dag/grid/dagRuns/Bar.tsx",
          "--- Hunk 1 ---",
          "[Context before]",
          "26: import { useContainerRef } from \"src/context/containerRef\";",
          "27: import Time from \"src/components/Time\";",
          "28: import type { SelectionProps } from \"src/dag/useSelection\";",
          "30: import RunTypeIcon from \"src/components/RunTypeIcon\";",
          "32: import DagRunTooltip from \"./Tooltip\";",
          "33: import type { RunWithDuration } from \".\";",
          "",
          "[Removed Lines]",
          "29: import { hoverDelay, getStatusBackgroundColor } from \"src/utils\";",
          "",
          "[Added Lines]",
          "29: import {",
          "30:   hoverDelay,",
          "31:   getStatusBackgroundColor,",
          "32:   getDagRunLabel,",
          "33: } from \"src/utils\";",
          "36: import { useGridData } from \"src/api\";",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "51:   isSelected,",
          "52:   onSelect,",
          "53: }: Props) => {",
          "55:   const containerRef = useContainerRef();",
          "56:   const { colors } = useTheme();",
          "57:   const hoverBlue = `${colors.blue[100]}50`;",
          "",
          "[Removed Lines]",
          "54:   const { runType, runId, duration, state, executionDate } = run;",
          "",
          "[Added Lines]",
          "59:   const { runType, runId, duration, state } = run;",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "86:     inverseIndex === 4 || (inverseIndex > 4 && (inverseIndex - 4) % 10 === 0);",
          "88:   const color = stateColors[state];",
          "90:   return (",
          "91:     <Box",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "94:   const {",
          "95:     data: { ordering },",
          "96:   } = useGridData();",
          "97:   const dagRun = run;",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "159:             transform=\"rotate(-30deg) translateX(28px)\"",
          "160:             mt=\"-23px !important\"",
          "161:           >",
          "163:           </Text>",
          "164:           <Box borderLeftWidth={1} opacity={0.7} height=\"100px\" zIndex={0} />",
          "165:         </VStack>",
          "",
          "[Removed Lines]",
          "162:             <Time dateTime={executionDate} format=\"MMM DD, HH:mm\" />",
          "",
          "[Added Lines]",
          "171:             <Time",
          "172:               dateTime={getDagRunLabel({ dagRun, ordering })}",
          "173:               format=\"MMM DD, HH:mm\"",
          "174:             />",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "4230098a59d1ed77a51289a100caa32d3c482532",
      "candidate_info": {
        "commit_hash": "4230098a59d1ed77a51289a100caa32d3c482532",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/4230098a59d1ed77a51289a100caa32d3c482532",
        "files": [
          "airflow/www/static/js/dag/grid/index.tsx"
        ],
        "message": "Change two whitespaces to one (#34519)\n\n(cherry picked from commit a1bd8719581f2ef1fb25aeaa89e3520e8bc81172)",
        "before_after_code_files": [
          "airflow/www/static/js/dag/grid/index.tsx||airflow/www/static/js/dag/grid/index.tsx"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/34775"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/www/static/js/dag/grid/index.tsx||airflow/www/static/js/dag/grid/index.tsx": [
          "File: airflow/www/static/js/dag/grid/index.tsx -> airflow/www/static/js/dag/grid/index.tsx",
          "--- Hunk 1 ---",
          "[Context before]",
          "153:           zIndex={2}",
          "154:           top={-8}",
          "155:           onClick={onPanelToggle}",
          "157:           aria-label={isPanelOpen ? \"Show Details\" : \"Hide Details\"}",
          "158:           icon={<MdDoubleArrow />}",
          "159:           transform={isPanelOpen ? undefined : \"rotateZ(180deg)\"}",
          "",
          "[Removed Lines]",
          "156:           title={`${isPanelOpen ? \"Hide \" : \"Show \"} Details Panel`}",
          "",
          "[Added Lines]",
          "156:           title={`${isPanelOpen ? \"Hide\" : \"Show\"} Details Panel`}",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "5b28c4515380bfbec1ced61cee374164c208a944",
      "candidate_info": {
        "commit_hash": "5b28c4515380bfbec1ced61cee374164c208a944",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/5b28c4515380bfbec1ced61cee374164c208a944",
        "files": [
          "airflow/utils/state.py",
          "docs/apache-airflow/public-airflow-interface.rst",
          "docs/conf.py"
        ],
        "message": "Add state utils to Public Airflow Interface (#34059)\n\n(cherry picked from commit c44e5b5ccc439fbe9a50afcb3d12c6a335518bb3)",
        "before_after_code_files": [
          "airflow/utils/state.py||airflow/utils/state.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/34775"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/utils/state.py||airflow/utils/state.py": [
          "File: airflow/utils/state.py -> airflow/utils/state.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "82: class State:",
          "85:     # Backwards-compat constants for code that does not yet use the enum",
          "86:     # These first three are shared by DagState and TaskState",
          "",
          "[Removed Lines]",
          "83:     \"\"\"Static class with task instance state constants and color methods to avoid hardcoding.\"\"\"",
          "",
          "[Added Lines]",
          "83:     \"\"\"Static class with task instance state constants and color methods to avoid hard-coding.\"\"\"",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "e868785d561ee2747b7b081b3e0558af7504e8d0",
      "candidate_info": {
        "commit_hash": "e868785d561ee2747b7b081b3e0558af7504e8d0",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/e868785d561ee2747b7b081b3e0558af7504e8d0",
        "files": [
          "dev/breeze/src/airflow_breeze/utils/docker_command_utils.py",
          "scripts/ci/docker-compose/_docker.env",
          "scripts/ci/docker-compose/base.yml",
          "scripts/ci/docker-compose/devcontainer.env",
          "scripts/in_container/_in_container_utils.sh"
        ],
        "message": "Support rootless mode for docker. (#34537)\n\nIn case docker is run in rootless mode, the host UID is mapped to root\nuser automatically and host user id is mapped to 100999 (unknown) so\nchanging ownership for created files in rootless mode is problematic\nas it makes the generated files inaccessible\n\n(cherry picked from commit 0631af86525ad98e90cdc0bf120df7192ea2e912)",
        "before_after_code_files": [
          "dev/breeze/src/airflow_breeze/utils/docker_command_utils.py||dev/breeze/src/airflow_breeze/utils/docker_command_utils.py",
          "scripts/ci/docker-compose/_docker.env||scripts/ci/docker-compose/_docker.env",
          "scripts/ci/docker-compose/devcontainer.env||scripts/ci/docker-compose/devcontainer.env",
          "scripts/in_container/_in_container_utils.sh||scripts/in_container/_in_container_utils.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/34775"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "dev/breeze/src/airflow_breeze/utils/docker_command_utils.py||dev/breeze/src/airflow_breeze/utils/docker_command_utils.py": [
          "File: dev/breeze/src/airflow_breeze/utils/docker_command_utils.py -> dev/breeze/src/airflow_breeze/utils/docker_command_utils.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "143:     return extra_docker_flags",
          "146: def check_docker_resources(airflow_image_name: str) -> RunCommandResult:",
          "147:     \"\"\"",
          "148:     Check if we have enough resources to run docker. This is done via running script embedded in our image.",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "146: def is_docker_rootless():",
          "147:     response = run_command(",
          "148:         [\"docker\", \"info\", \"-f\", \"{{println .SecurityOptions}}\"], capture_output=True, check=True, text=True",
          "149:     )",
          "150:     if \"rootless\" in response.stdout.strip():",
          "151:         get_console().print(\"[info]Docker is running in rootless mode.[/]\\n\")",
          "152:         return True",
          "153:     return False",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "569:     set_value_to_default_if_not_set(env, \"COLLECT_ONLY\", \"false\")",
          "570:     set_value_to_default_if_not_set(env, \"DB_RESET\", \"false\")",
          "571:     set_value_to_default_if_not_set(env, \"DEFAULT_BRANCH\", AIRFLOW_BRANCH)",
          "572:     set_value_to_default_if_not_set(env, \"ENABLED_SYSTEMS\", \"\")",
          "573:     set_value_to_default_if_not_set(env, \"ENABLE_TEST_COVERAGE\", \"false\")",
          "574:     set_value_to_default_if_not_set(env, \"HELM_TEST_PACKAGE\", \"\")",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "582:     set_value_to_default_if_not_set(env, \"DOCKER_IS_ROOTLESS\", \"false\")",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "704: def perform_environment_checks():",
          "705:     check_docker_is_running()",
          "706:     check_docker_version()",
          "707:     check_docker_compose_version()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "718:     if is_docker_rootless():",
          "719:         os.environ[\"DOCKER_IS_ROOTLESS\"] = \"true\"",
          "",
          "---------------"
        ],
        "scripts/ci/docker-compose/_docker.env||scripts/ci/docker-compose/_docker.env": [
          "File: scripts/ci/docker-compose/_docker.env -> scripts/ci/docker-compose/_docker.env",
          "--- Hunk 1 ---",
          "[Context before]",
          "37: DEFAULT_BRANCH",
          "38: DEFAULT_CONSTRAINTS_BRANCH",
          "39: DEV_MODE",
          "40: ENABLED_SYSTEMS",
          "41: ENABLE_TEST_COVERAGE",
          "42: GITHUB_ACTIONS",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "40: DOCKER_IS_ROOTLESS",
          "",
          "---------------"
        ],
        "scripts/ci/docker-compose/devcontainer.env||scripts/ci/docker-compose/devcontainer.env": [
          "File: scripts/ci/docker-compose/devcontainer.env -> scripts/ci/docker-compose/devcontainer.env",
          "--- Hunk 1 ---",
          "[Context before]",
          "35: DEFAULT_BRANCH=\"main\"",
          "36: DEFAULT_CONSTRAINTS_BRANCH=\"constraints-main\"",
          "37: DEV_MODE=\"true\"",
          "38: ENABLED_SYSTEMS=",
          "39: ENABLE_TEST_COVERAGE=\"false\"",
          "40: GITHUB_ACTIONS=\"false\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "38: DOCKER_IS_ROOTLESS=\"false\"",
          "",
          "---------------"
        ],
        "scripts/in_container/_in_container_utils.sh||scripts/in_container/_in_container_utils.sh": [
          "File: scripts/in_container/_in_container_utils.sh -> scripts/in_container/_in_container_utils.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "66: #",
          "67: function in_container_fix_ownership() {",
          "68:     if [[ ${HOST_OS:=} == \"linux\" ]]; then",
          "69:         DIRECTORIES_TO_FIX=(",
          "70:             \"/dist\"",
          "71:             \"/files\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "69:         if [[ ${DOCKER_IS_ROOTLESS=} == \"true\" ]]; then",
          "70:              echo \"${COLOR_YELLOW}Skip fixing ownership of generated files: Docker is rootless${COLOR_RESET}\"",
          "71:              return",
          "72:         fi",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "784d162256293466d99da00db06ff1ec8f5d86c8",
      "candidate_info": {
        "commit_hash": "784d162256293466d99da00db06ff1ec8f5d86c8",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/784d162256293466d99da00db06ff1ec8f5d86c8",
        "files": [
          "airflow/configuration.py"
        ],
        "message": "Fix some whitespace (#34632)\n\n(cherry picked from commit 97de019995185cba1e7e63ea525d099ff5c94ea7)",
        "before_after_code_files": [
          "airflow/configuration.py||airflow/configuration.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/34775"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/configuration.py||airflow/configuration.py": [
          "File: airflow/configuration.py -> airflow/configuration.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1852:                     raise AirflowConfigException(",
          "1853:                         f\"The provider {provider} is attempting to contribute \"",
          "1854:                         f\"configuration section {provider_section} that \"",
          "1857:                         \"cannot contribute options to existing sections or override other \"",
          "1858:                         \"provider's configuration.\",",
          "1859:                         UserWarning,",
          "",
          "[Removed Lines]",
          "1855:                         f\"has already been added before. The source of it: {section_source}.\"",
          "1856:                         \"This is forbidden. A provider can only add new sections. It\"",
          "",
          "[Added Lines]",
          "1855:                         f\"has already been added before. The source of it: {section_source}. \"",
          "1856:                         \"This is forbidden. A provider can only add new sections. It \"",
          "",
          "---------------"
        ]
      }
    }
  ]
}