{
  "cve_id": "CVE-2023-50944",
  "cve_desc": "Apache Airflow, versions before 2.8.1, have a vulnerability that allows an authenticated user to access the source code of a DAG to which they don't have access.\u00a0This vulnerability is considered low since it requires an authenticated user to exploit it. Users are recommended to upgrade to version 2.8.1, which fixes this issue.",
  "repo": "apache/airflow",
  "patch_hash": "8d76538d6e105947272b000581c6fabec20146b1",
  "patch_info": {
    "commit_hash": "8d76538d6e105947272b000581c6fabec20146b1",
    "repo": "apache/airflow",
    "commit_url": "https://github.com/apache/airflow/commit/8d76538d6e105947272b000581c6fabec20146b1",
    "files": [
      "airflow/api_connexion/endpoints/dag_source_endpoint.py",
      "airflow/models/dagcode.py",
      "tests/api_connexion/endpoints/test_dag_source_endpoint.py"
    ],
    "message": "Check DAG read permission before accessing DAG code (#36257)\n\n(cherry picked from commit 30ea37e0d247ce54c2d25b115e807fdb0074d795)",
    "before_after_code_files": [
      "airflow/api_connexion/endpoints/dag_source_endpoint.py||airflow/api_connexion/endpoints/dag_source_endpoint.py",
      "airflow/models/dagcode.py||airflow/models/dagcode.py",
      "tests/api_connexion/endpoints/test_dag_source_endpoint.py||tests/api_connexion/endpoints/test_dag_source_endpoint.py"
    ]
  },
  "patch_diff": {
    "airflow/api_connexion/endpoints/dag_source_endpoint.py||airflow/api_connexion/endpoints/dag_source_endpoint.py": [
      "File: airflow/api_connexion/endpoints/dag_source_endpoint.py -> airflow/api_connexion/endpoints/dag_source_endpoint.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "17: from __future__ import annotations",
      "19: from http import HTTPStatus",
      "21: from flask import Response, current_app, request",
      "22: from itsdangerous import BadSignature, URLSafeSerializer",
      "24: from airflow.api_connexion import security",
      "26: from airflow.api_connexion.schemas.dag_source_schema import dag_source_schema",
      "27: from airflow.auth.managers.models.resource_details import DagAccessEntity",
      "28: from airflow.models.dagcode import DagCode",
      "31: @security.requires_access_dag(\"GET\", DagAccessEntity.CODE)",
      "33:     \"\"\"Get source code using file token.\"\"\"",
      "34:     secret_key = current_app.config[\"SECRET_KEY\"]",
      "35:     auth_s = URLSafeSerializer(secret_key)",
      "36:     try:",
      "37:         path = auth_s.loads(file_token)",
      "39:     except (BadSignature, FileNotFoundError):",
      "40:         raise NotFound(\"Dag source not found\")",
      "",
      "[Removed Lines]",
      "25: from airflow.api_connexion.exceptions import NotFound",
      "32: def get_dag_source(*, file_token: str) -> Response:",
      "38:         dag_source = DagCode.code(path)",
      "",
      "[Added Lines]",
      "20: from typing import TYPE_CHECKING",
      "26: from airflow.api_connexion.exceptions import NotFound, PermissionDenied",
      "28: from airflow.api_connexion.security import get_readable_dags",
      "30: from airflow.models.dag import DagModel",
      "32: from airflow.utils.session import NEW_SESSION, provide_session",
      "34: if TYPE_CHECKING:",
      "35:     from sqlalchemy.orm import Session",
      "39: @provide_session",
      "40: def get_dag_source(*, file_token: str, session: Session = NEW_SESSION) -> Response:",
      "46:         dag_ids = session.query(DagModel.dag_id).filter(DagModel.fileloc == path).all()",
      "47:         readable_dags = get_readable_dags()",
      "48:         # Check if user has read access to all the DAGs defined in the file",
      "49:         if any(dag_id[0] not in readable_dags for dag_id in dag_ids):",
      "50:             raise PermissionDenied()",
      "51:         dag_source = DagCode.code(path, session=session)",
      "",
      "---------------"
    ],
    "airflow/models/dagcode.py||airflow/models/dagcode.py": [
      "File: airflow/models/dagcode.py -> airflow/models/dagcode.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "177:         return cls.code(fileloc)",
      "179:     @classmethod",
      "181:         \"\"\"Return source code for this DagCode object.",
      "183:         :return: source code as string",
      "184:         \"\"\"",
      "187:     @staticmethod",
      "188:     def _get_code_from_file(fileloc):",
      "",
      "[Removed Lines]",
      "180:     def code(cls, fileloc) -> str:",
      "185:         return cls._get_code_from_db(fileloc)",
      "",
      "[Added Lines]",
      "180:     @provide_session",
      "181:     def code(cls, fileloc, session: Session = NEW_SESSION) -> str:",
      "186:         return cls._get_code_from_db(fileloc, session)",
      "",
      "---------------"
    ],
    "tests/api_connexion/endpoints/test_dag_source_endpoint.py||tests/api_connexion/endpoints/test_dag_source_endpoint.py": [
      "File: tests/api_connexion/endpoints/test_dag_source_endpoint.py -> tests/api_connexion/endpoints/test_dag_source_endpoint.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "35: ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir, os.pardir))",
      "36: EXAMPLE_DAG_FILE = os.path.join(\"airflow\", \"example_dags\", \"example_bash_operator.py\")",
      "39: @pytest.fixture(scope=\"module\")",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "37: EXAMPLE_DAG_ID = \"example_bash_operator\"",
      "38: TEST_DAG_ID = \"latest_only\"",
      "39: NOT_READABLE_DAG_ID = \"latest_only_with_trigger\"",
      "40: TEST_MULTIPLE_DAGS_ID = \"dataset_produces_1\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "45:         role_name=\"Test\",",
      "46:         permissions=[(permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG_CODE)],  # type: ignore",
      "47:     )",
      "48:     create_user(app, username=\"test_no_permissions\", role_name=\"TestNoPermissions\")  # type: ignore",
      "50:     yield app",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "52:     app.appbuilder.sm.sync_perm_for_dag(  # type: ignore",
      "53:         TEST_DAG_ID,",
      "54:         access_control={\"Test\": [permissions.ACTION_CAN_READ]},",
      "55:     )",
      "56:     app.appbuilder.sm.sync_perm_for_dag(  # type: ignore",
      "57:         EXAMPLE_DAG_ID,",
      "58:         access_control={\"Test\": [permissions.ACTION_CAN_READ]},",
      "59:     )",
      "60:     app.appbuilder.sm.sync_perm_for_dag(  # type: ignore",
      "61:         TEST_MULTIPLE_DAGS_ID,",
      "62:         access_control={\"Test\": [permissions.ACTION_CAN_READ]},",
      "63:     )",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "80:     def test_should_respond_200_text(self, url_safe_serializer):",
      "81:         dagbag = DagBag(dag_folder=EXAMPLE_DAG_FILE)",
      "82:         dagbag.sync_to_db()",
      "87:         response = self.client.get(",
      "88:             url, headers={\"Accept\": \"text/plain\"}, environ_overrides={\"REMOTE_USER\": \"test\"}",
      "89:         )",
      "",
      "[Removed Lines]",
      "83:         first_dag: DAG = next(iter(dagbag.dags.values()))",
      "84:         dag_docstring = self._get_dag_file_docstring(first_dag.fileloc)",
      "86:         url = f\"/api/v1/dagSources/{url_safe_serializer.dumps(first_dag.fileloc)}\"",
      "",
      "[Added Lines]",
      "99:         test_dag: DAG = dagbag.dags[TEST_DAG_ID]",
      "100:         dag_docstring = self._get_dag_file_docstring(test_dag.fileloc)",
      "102:         url = f\"/api/v1/dagSources/{url_safe_serializer.dumps(test_dag.fileloc)}\"",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "95:     def test_should_respond_200_json(self, url_safe_serializer):",
      "96:         dagbag = DagBag(dag_folder=EXAMPLE_DAG_FILE)",
      "97:         dagbag.sync_to_db()",
      "102:         response = self.client.get(",
      "103:             url, headers={\"Accept\": \"application/json\"}, environ_overrides={\"REMOTE_USER\": \"test\"}",
      "104:         )",
      "",
      "[Removed Lines]",
      "98:         first_dag: DAG = next(iter(dagbag.dags.values()))",
      "99:         dag_docstring = self._get_dag_file_docstring(first_dag.fileloc)",
      "101:         url = f\"/api/v1/dagSources/{url_safe_serializer.dumps(first_dag.fileloc)}\"",
      "",
      "[Added Lines]",
      "114:         test_dag: DAG = dagbag.dags[TEST_DAG_ID]",
      "115:         dag_docstring = self._get_dag_file_docstring(test_dag.fileloc)",
      "117:         url = f\"/api/v1/dagSources/{url_safe_serializer.dumps(test_dag.fileloc)}\"",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "110:     def test_should_respond_406(self, url_safe_serializer):",
      "111:         dagbag = DagBag(dag_folder=EXAMPLE_DAG_FILE)",
      "112:         dagbag.sync_to_db()",
      "116:         response = self.client.get(",
      "117:             url, headers={\"Accept\": \"image/webp\"}, environ_overrides={\"REMOTE_USER\": \"test\"}",
      "118:         )",
      "",
      "[Removed Lines]",
      "113:         first_dag: DAG = next(iter(dagbag.dags.values()))",
      "115:         url = f\"/api/v1/dagSources/{url_safe_serializer.dumps(first_dag.fileloc)}\"",
      "",
      "[Added Lines]",
      "129:         test_dag: DAG = dagbag.dags[TEST_DAG_ID]",
      "131:         url = f\"/api/v1/dagSources/{url_safe_serializer.dumps(test_dag.fileloc)}\"",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "151:             environ_overrides={\"REMOTE_USER\": \"test_no_permissions\"},",
      "152:         )",
      "153:         assert response.status_code == 403",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "171:     def test_should_respond_403_not_readable(self, url_safe_serializer):",
      "172:         dagbag = DagBag(dag_folder=EXAMPLE_DAG_FILE)",
      "173:         dagbag.sync_to_db()",
      "174:         dag: DAG = dagbag.dags[NOT_READABLE_DAG_ID]",
      "176:         response = self.client.get(",
      "177:             f\"/api/v1/dagSources/{url_safe_serializer.dumps(dag.fileloc)}\",",
      "178:             headers={\"Accept\": \"text/plain\"},",
      "179:             environ_overrides={\"REMOTE_USER\": \"test\"},",
      "180:         )",
      "181:         read_dag = self.client.get(",
      "182:             f\"/api/v1/dags/{NOT_READABLE_DAG_ID}\",",
      "183:             environ_overrides={\"REMOTE_USER\": \"test\"},",
      "184:         )",
      "185:         assert response.status_code == 403",
      "186:         assert read_dag.status_code == 403",
      "188:     def test_should_respond_403_some_dags_not_readable_in_the_file(self, url_safe_serializer):",
      "189:         dagbag = DagBag(dag_folder=EXAMPLE_DAG_FILE)",
      "190:         dagbag.sync_to_db()",
      "191:         dag: DAG = dagbag.dags[TEST_MULTIPLE_DAGS_ID]",
      "193:         response = self.client.get(",
      "194:             f\"/api/v1/dagSources/{url_safe_serializer.dumps(dag.fileloc)}\",",
      "195:             headers={\"Accept\": \"text/plain\"},",
      "196:             environ_overrides={\"REMOTE_USER\": \"test\"},",
      "197:         )",
      "199:         read_dag = self.client.get(",
      "200:             f\"/api/v1/dags/{TEST_MULTIPLE_DAGS_ID}\",",
      "201:             environ_overrides={\"REMOTE_USER\": \"test\"},",
      "202:         )",
      "203:         assert response.status_code == 403",
      "204:         assert read_dag.status_code == 200",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "d79f7a4027fd9b252005fa98f4a31d171f65c45b",
      "candidate_info": {
        "commit_hash": "d79f7a4027fd9b252005fa98f4a31d171f65c45b",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/d79f7a4027fd9b252005fa98f4a31d171f65c45b",
        "files": [
          "dev/breeze/src/airflow_breeze/utils/selective_checks.py",
          "dev/breeze/tests/test_selective_checks.py"
        ],
        "message": "Fix problems with missing selective checks on new types of unit tests (#36372)\n\nWhen the DB/NonDB tests were introduced (#35160) new test types have\nbeen added (separating various Python test types from generic\nOperator test type). However we have not added matching of the python\noperator and test files into the right selective unit test type. This\ncaused that when only `operators/python.py` and `tests/test_python` were\nchanged, then `Operators` test type was run but the specific Python *\ntest types were not run.\n\nThis PR fixes it for current test type (including also separated\nSerialization test type) and for the future - instead of matching\nselected test type we match all of them except the few that we\nnow are \"special\" (\"Always, Core, Other, PlainAsserts\").\n\n(cherry picked from commit b0db1f94ede7d316b3f63a924176e5e1eefa89c1)",
        "before_after_code_files": [
          "dev/breeze/src/airflow_breeze/utils/selective_checks.py||dev/breeze/src/airflow_breeze/utils/selective_checks.py",
          "dev/breeze/tests/test_selective_checks.py||dev/breeze/tests/test_selective_checks.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "dev/breeze/src/airflow_breeze/utils/selective_checks.py||dev/breeze/src/airflow_breeze/utils/selective_checks.py": [
          "File: dev/breeze/src/airflow_breeze/utils/selective_checks.py -> dev/breeze/src/airflow_breeze/utils/selective_checks.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "223:     }",
          "224: )",
          "226: TEST_TYPE_MATCHES = HashableDict(",
          "227:     {",
          "228:         SelectiveUnitTestTypes.API: [",
          "233:         ],",
          "234:         SelectiveUnitTestTypes.CLI: [",
          "237:         ],",
          "238:         SelectiveUnitTestTypes.OPERATORS: [",
          "241:         ],",
          "242:         SelectiveUnitTestTypes.PROVIDERS: [",
          "243:             r\"^airflow/providers/\",",
          "244:             r\"^tests/system/providers/\",",
          "245:             r\"^tests/providers/\",",
          "246:         ],",
          "252:         ],",
          "253:         SelectiveUnitTestTypes.WWW: [r\"^airflow/www\", r\"^tests/www\"],",
          "254:     }",
          "255: )",
          "",
          "[Removed Lines]",
          "229:             r\"^airflow/api\",",
          "230:             r\"^airflow/api_connexion\",",
          "231:             r\"^tests/api\",",
          "232:             r\"^tests/api_connexion\",",
          "235:             r\"^airflow/cli\",",
          "236:             r\"^tests/cli\",",
          "239:             r\"^airflow/operators\",",
          "240:             r\"^tests/operators\",",
          "247:         SelectiveUnitTestTypes.PYTHON_VENV: [",
          "248:             r\"^tests/operators/test_python.py\",",
          "249:         ],",
          "250:         SelectiveUnitTestTypes.BRANCH_PYTHON_VENV: [",
          "251:             r\"^tests/operators/test_python.py\",",
          "",
          "[Added Lines]",
          "226: PYTHON_OPERATOR_FILES = [",
          "227:     r\"^airflow/operators/python.py\",",
          "228:     r\"^tests/operators/test_python.py\",",
          "229: ]",
          "234:             r\"^airflow/api/\",",
          "235:             r\"^airflow/api_connexion/\",",
          "236:             r\"^airflow/api_internal/\",",
          "237:             r\"^tests/api/\",",
          "238:             r\"^tests/api_connexion/\",",
          "239:             r\"^tests/api_internal/\",",
          "242:             r\"^airflow/cli/\",",
          "243:             r\"^tests/cli/\",",
          "246:             r\"^airflow/operators/\",",
          "247:             r\"^tests/operators/\",",
          "254:         SelectiveUnitTestTypes.SERIALIZATION: [",
          "255:             r\"^airflow/serialization/\",",
          "256:             r\"^tests/serialization/\",",
          "258:         SelectiveUnitTestTypes.PYTHON_VENV: PYTHON_OPERATOR_FILES,",
          "259:         SelectiveUnitTestTypes.BRANCH_PYTHON_VENV: PYTHON_OPERATOR_FILES,",
          "260:         SelectiveUnitTestTypes.EXTERNAL_PYTHON: PYTHON_OPERATOR_FILES,",
          "261:         SelectiveUnitTestTypes.EXTERNAL_BRANCH_PYTHON: PYTHON_OPERATOR_FILES,",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "653:         candidate_test_types: set[str] = {\"Always\"}",
          "654:         matched_files: set[str] = set()",
          "671:         kubernetes_files = self._matching_files(",
          "672:             FileGroupForCi.KUBERNETES_FILES, CI_FILE_GROUP_MATCHES, CI_FILE_GROUP_EXCLUDES",
          "",
          "[Removed Lines]",
          "655:         matched_files.update(",
          "656:             self._select_test_type_if_matching(candidate_test_types, SelectiveUnitTestTypes.WWW)",
          "657:         )",
          "658:         matched_files.update(",
          "659:             self._select_test_type_if_matching(candidate_test_types, SelectiveUnitTestTypes.PROVIDERS)",
          "660:         )",
          "661:         matched_files.update(",
          "662:             self._select_test_type_if_matching(candidate_test_types, SelectiveUnitTestTypes.CLI)",
          "663:         )",
          "664:         matched_files.update(",
          "665:             self._select_test_type_if_matching(candidate_test_types, SelectiveUnitTestTypes.OPERATORS)",
          "666:         )",
          "667:         matched_files.update(",
          "668:             self._select_test_type_if_matching(candidate_test_types, SelectiveUnitTestTypes.API)",
          "669:         )",
          "",
          "[Added Lines]",
          "664:         for test_type in SelectiveUnitTestTypes:",
          "665:             if test_type not in [",
          "666:                 SelectiveUnitTestTypes.ALWAYS,",
          "667:                 SelectiveUnitTestTypes.CORE,",
          "668:                 SelectiveUnitTestTypes.OTHER,",
          "669:                 SelectiveUnitTestTypes.PLAIN_ASSERTS,",
          "670:             ]:",
          "671:                 matched_files.update(self._select_test_type_if_matching(candidate_test_types, test_type))",
          "",
          "---------------"
        ],
        "dev/breeze/tests/test_selective_checks.py||dev/breeze/tests/test_selective_checks.py": [
          "File: dev/breeze/tests/test_selective_checks.py -> dev/breeze/tests/test_selective_checks.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "161:                 id=\"Only Operator tests and DOCS should run\",",
          "162:             )",
          "163:         ),",
          "164:         (",
          "165:             pytest.param(",
          "166:                 (",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "164:         (",
          "165:             pytest.param(",
          "166:                 (\"airflow/operators/python.py\",),",
          "167:                 {",
          "168:                     \"affected-providers-list-as-string\": None,",
          "169:                     \"all-python-versions\": \"['3.8']\",",
          "170:                     \"all-python-versions-list-as-string\": \"3.8\",",
          "171:                     \"python-versions\": \"['3.8']\",",
          "172:                     \"python-versions-list-as-string\": \"3.8\",",
          "173:                     \"ci-image-build\": \"true\",",
          "174:                     \"prod-image-build\": \"false\",",
          "175:                     \"needs-helm-tests\": \"false\",",
          "176:                     \"run-tests\": \"true\",",
          "177:                     \"run-amazon-tests\": \"false\",",
          "178:                     \"docs-build\": \"true\",",
          "179:                     \"skip-pre-commits\": \"check-provider-yaml-valid,identity,lint-helm-chart,mypy-dev,\"",
          "180:                     \"mypy-docs,mypy-providers,ts-compile-format-lint-www\",",
          "181:                     \"upgrade-to-newer-dependencies\": \"false\",",
          "182:                     \"parallel-test-types-list-as-string\": \"Always BranchExternalPython BranchPythonVenv \"",
          "183:                     \"ExternalPython Operators PythonVenv\",",
          "184:                 },",
          "185:                 id=\"Only Python tests\",",
          "186:             )",
          "187:         ),",
          "188:         (",
          "189:             pytest.param(",
          "190:                 (\"airflow/serialization/python.py\",),",
          "191:                 {",
          "192:                     \"affected-providers-list-as-string\": None,",
          "193:                     \"all-python-versions\": \"['3.8']\",",
          "194:                     \"all-python-versions-list-as-string\": \"3.8\",",
          "195:                     \"python-versions\": \"['3.8']\",",
          "196:                     \"python-versions-list-as-string\": \"3.8\",",
          "197:                     \"ci-image-build\": \"true\",",
          "198:                     \"prod-image-build\": \"false\",",
          "199:                     \"needs-helm-tests\": \"false\",",
          "200:                     \"run-tests\": \"true\",",
          "201:                     \"run-amazon-tests\": \"false\",",
          "202:                     \"docs-build\": \"true\",",
          "203:                     \"skip-pre-commits\": \"check-provider-yaml-valid,identity,lint-helm-chart,mypy-dev,\"",
          "204:                     \"mypy-docs,mypy-providers,ts-compile-format-lint-www\",",
          "205:                     \"upgrade-to-newer-dependencies\": \"false\",",
          "206:                     \"parallel-test-types-list-as-string\": \"Always Serialization\",",
          "207:                 },",
          "208:                 id=\"Only Serialization tests\",",
          "209:             )",
          "210:         ),",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "cff4394256da40028adbe9fa0300288b582e8245",
      "candidate_info": {
        "commit_hash": "cff4394256da40028adbe9fa0300288b582e8245",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/cff4394256da40028adbe9fa0300288b582e8245",
        "files": [
          ".github/workflows/recheck-old-bug-report.yml",
          ".github/workflows/stale.yml",
          "airflow/auth/managers/fab/security_manager/override.py",
          "airflow/providers/google/cloud/hooks/dataflow.py",
          "generated/provider_dependencies.json",
          "scripts/in_container/run_provider_yaml_files_check.py",
          "scripts/in_container/verify_providers.py"
        ],
        "message": "Bump stalebot to version 9 (#36494)\n\n(cherry picked from commit 13e4905a60011e162f34e86a77acfcb4af874685)",
        "before_after_code_files": [
          "airflow/auth/managers/fab/security_manager/override.py||airflow/auth/managers/fasecurity_manager/override.py",
          "airflow/providers/google/cloud/hooks/dataflow.py||airflow/providers/google/cloud/hooks/dataflow.py",
          "scripts/in_container/run_provider_yaml_files_check.py||scripts/in_container/run_provider_yaml_files_check.py",
          "scripts/in_container/verify_providers.py||scripts/in_container/verify_providers.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/auth/managers/fab/security_manager/override.py||airflow/auth/managers/fasecurity_manager/override.py": [
          "File: airflow/auth/managers/fab/security_manager/override.py -> airflow/auth/managers/fasecurity_manager/override.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "2088:             @appbuilder.sm.oauth_user_info_getter",
          "2089:             def my_oauth_user_info(sm, provider, response=None):",
          "2093:                 return {}",
          "2094:         \"\"\"",
          "",
          "[Removed Lines]",
          "2090:                 if provider == 'github':",
          "2091:                     me = sm.oauth_remotes[provider].get('user')",
          "2092:                     return {'username': me.data.get('login')}",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "airflow/providers/google/cloud/hooks/dataflow.py||airflow/providers/google/cloud/hooks/dataflow.py": [
          "File: airflow/providers/google/cloud/hooks/dataflow.py -> airflow/providers/google/cloud/hooks/dataflow.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "57: def process_line_and_extract_dataflow_job_id_callback(",
          "59: ) -> Callable[[str], None]:",
          "60:     \"\"\"Build callback that triggers the specified function.",
          "",
          "[Removed Lines]",
          "58:     on_new_job_id_callback: Callable[[str], None] | None",
          "",
          "[Added Lines]",
          "58:     on_new_job_id_callback: Callable[[str], None] | None,",
          "",
          "---------------"
        ],
        "scripts/in_container/run_provider_yaml_files_check.py||scripts/in_container/run_provider_yaml_files_check.py": [
          "File: scripts/in_container/run_provider_yaml_files_check.py -> scripts/in_container/run_provider_yaml_files_check.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "314: @run_check(\"Checking completeness of list of {sensors, hooks, operators, triggers}\")",
          "315: def check_correctness_of_list_of_sensors_operators_hook_trigger_modules(",
          "317: ) -> tuple[int, int]:",
          "318:     num_errors = 0",
          "319:     num_modules = 0",
          "",
          "[Removed Lines]",
          "316:     yaml_files: dict[str, dict]",
          "",
          "[Added Lines]",
          "316:     yaml_files: dict[str, dict],",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "355: @run_check(\"Checking for duplicates in list of {sensors, hooks, operators, triggers}\")",
          "356: def check_duplicates_in_integrations_names_of_hooks_sensors_operators(",
          "358: ) -> tuple[int, int]:",
          "359:     num_errors = 0",
          "360:     num_integrations = 0",
          "",
          "[Removed Lines]",
          "357:     yaml_files: dict[str, dict]",
          "",
          "[Added Lines]",
          "357:     yaml_files: dict[str, dict],",
          "",
          "---------------"
        ],
        "scripts/in_container/verify_providers.py||scripts/in_container/verify_providers.py": [
          "File: scripts/in_container/verify_providers.py -> scripts/in_container/verify_providers.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "580: def check_if_classes_are_properly_named(",
          "582: ) -> tuple[int, int]:",
          "583:     \"\"\"Check if all entities in the dictionary are named properly.",
          "",
          "[Removed Lines]",
          "581:     entity_summary: dict[EntityType, EntityTypeSummary]",
          "",
          "[Added Lines]",
          "581:     entity_summary: dict[EntityType, EntityTypeSummary],",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "cdca4cae474cdf57fd0f567b26c1c91ac97d0876",
      "candidate_info": {
        "commit_hash": "cdca4cae474cdf57fd0f567b26c1c91ac97d0876",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/cdca4cae474cdf57fd0f567b26c1c91ac97d0876",
        "files": [
          "airflow/utils/log/file_task_handler.py"
        ],
        "message": "Add log lookup exception for empty op subtypes (#35536)\n\n* Add log lookup exception for empty op subtypes\n\n* Use exception catching approach instead to preserve tests\n\n(cherry picked from commit ddcaef45593a5411859327ab2d16ed648073b986)",
        "before_after_code_files": [
          "airflow/utils/log/file_task_handler.py||airflow/utils/log/file_task_handler.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/utils/log/file_task_handler.py||airflow/utils/log/file_task_handler.py": [
          "File: airflow/utils/log/file_task_handler.py -> airflow/utils/log/file_task_handler.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "29: from typing import TYPE_CHECKING, Any, Callable, Iterable",
          "30: from urllib.parse import urljoin",
          "32: import pendulum",
          "34: from airflow.configuration import conf",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "32: import httpx",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "80: def _fetch_logs_from_service(url, log_relative_path):",
          "83:     from airflow.utils.jwt_signer import JWTSigner",
          "85:     timeout = conf.getint(\"webserver\", \"log_fetch_timeout_sec\", fallback=None)",
          "",
          "[Removed Lines]",
          "81:     import httpx",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "170:     \"\"\"",
          "172:     trigger_should_wrap = True",
          "174:     def __init__(self, base_log_folder: str, filename_template: str | None = None):",
          "175:         super().__init__()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "172:     inherits_from_empty_operator_log_message = (",
          "173:         \"Operator inherits from empty operator and thus does not have logs\"",
          "174:     )",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "555:                 messages.append(f\"Found logs served from host {url}\")",
          "556:                 logs.append(response.text)",
          "557:         except Exception as e:",
          "560:         return messages, logs",
          "562:     def _read_remote_logs(self, ti, try_number, metadata=None) -> tuple[list[str], list[str]]:",
          "",
          "[Removed Lines]",
          "558:             messages.append(f\"Could not read served logs: {e}\")",
          "559:             logger.exception(\"Could not read served logs\")",
          "",
          "[Added Lines]",
          "560:             if isinstance(e, httpx.UnsupportedProtocol) and ti.task.inherits_from_empty_operator is True:",
          "561:                 messages.append(self.inherits_from_empty_operator_log_message)",
          "562:             else:",
          "563:                 messages.append(f\"Could not read served logs: {e}\")",
          "564:                 logger.exception(\"Could not read served logs\")",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "bf935545adbfeb24fe9449b21316c9c4024767bc",
      "candidate_info": {
        "commit_hash": "bf935545adbfeb24fe9449b21316c9c4024767bc",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/bf935545adbfeb24fe9449b21316c9c4024767bc",
        "files": [
          "airflow/decorators/base.py",
          "tests/decorators/test_python.py"
        ],
        "message": "Fix check on subclass for `typing.Union` in `_infer_multiple_outputs` for Python 3.10+ (#36728)\n\n* Fix check on subclass for `typing.Union` in `_infer_multiple_outputs` for Python 3.10+\n\n* Limit PEP 604 test by Python 3.10\n\n(cherry picked from commit f1d82971053287c27c83e1b945b774a6a37a8552)",
        "before_after_code_files": [
          "airflow/decorators/base.py||airflow/decorators/base.py",
          "tests/decorators/test_python.py||tests/decorators/test_python.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/decorators/base.py||airflow/decorators/base.py": [
          "File: airflow/decorators/base.py -> airflow/decorators/base.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "350:         except TypeError:  # Can't evaluate return type.",
          "351:             return False",
          "352:         ttype = getattr(return_type, \"__origin__\", return_type)",
          "355:     def __attrs_post_init__(self):",
          "356:         if \"self\" in self.function_signature.parameters:",
          "",
          "[Removed Lines]",
          "353:         return issubclass(ttype, Mapping)",
          "",
          "[Added Lines]",
          "353:         return isinstance(ttype, type) and issubclass(ttype, Mapping)",
          "",
          "---------------"
        ],
        "tests/decorators/test_python.py||tests/decorators/test_python.py": [
          "File: tests/decorators/test_python.py -> tests/decorators/test_python.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "98:         assert identity_dict_with_decorator_call(5, 5).operator.multiple_outputs is True",
          "101:     def test_infer_multiple_outputs_typed_dict(self):",
          "102:         from typing import TypedDict",
          "",
          "[Removed Lines]",
          "100:     @pytest.mark.skipif(sys.version_info < (3, 8), reason=\"PEP 589 is implemented in Python 3.8\")",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "111:         assert t1().operator.multiple_outputs is True",
          "113:     def test_infer_multiple_outputs_forward_annotation(self):",
          "114:         if TYPE_CHECKING:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "112:     # We do not enable `from __future__ import annotations` for particular this test module,",
          "113:     # that mean `str | None` annotation would raise TypeError in Python 3.9 and below",
          "114:     @pytest.mark.skipif(sys.version_info < (3, 10), reason=\"PEP 604 is implemented in Python 3.10\")",
          "115:     def test_infer_multiple_outputs_pep_604_union_type(self):",
          "116:         @task_decorator",
          "117:         def t1() -> str | None:",
          "118:             # Before PEP 604 which are implemented in Python 3.10 `str | None`",
          "119:             # returns `types.UnionType` which are class and could be check in `issubclass()`.",
          "120:             # However in Python 3.10+ this construction returns object `typing.Union`",
          "121:             # which can not be used in `issubclass()`",
          "122:             return \"foo\"",
          "124:         assert t1().operator.multiple_outputs is False",
          "126:     def test_infer_multiple_outputs_union_type(self):",
          "127:         @task_decorator",
          "128:         def t1() -> Union[str, None]:",
          "129:             return \"foo\"",
          "131:         assert t1().operator.multiple_outputs is False",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "0dba06d66064edab2144bfcb70cd253a31ce6bc7",
      "candidate_info": {
        "commit_hash": "0dba06d66064edab2144bfcb70cd253a31ce6bc7",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/0dba06d66064edab2144bfcb70cd253a31ce6bc7",
        "files": [
          "airflow/models/dag.py"
        ],
        "message": "fix datetime reference in DAG.is_fixed_time_schedule (#36370)\n\n(cherry picked from commit 547ddf6317b3fc93e766b61daf11308b552e6d6b)",
        "before_after_code_files": [
          "airflow/models/dag.py||airflow/models/dag.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/models/dag.py||airflow/models/dag.py": [
          "File: airflow/models/dag.py -> airflow/models/dag.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "874:         from croniter import croniter",
          "876:         cron = croniter(self.timetable._expression)",
          "879:         return next_b.minute == next_a.minute and next_b.hour == next_a.hour",
          "881:     def following_schedule(self, dttm):",
          "",
          "[Removed Lines]",
          "877:         next_a = cron.get_next(datetime.datetime)",
          "878:         next_b = cron.get_next(datetime.datetime)",
          "",
          "[Added Lines]",
          "877:         next_a = cron.get_next(datetime)",
          "878:         next_b = cron.get_next(datetime)",
          "",
          "---------------"
        ]
      }
    }
  ]
}