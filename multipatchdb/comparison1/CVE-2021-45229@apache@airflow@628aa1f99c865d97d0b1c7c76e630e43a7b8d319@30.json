{
  "cve_id": "CVE-2021-45229",
  "cve_desc": "It was discovered that the \"Trigger DAG with config\" screen was susceptible to XSS attacks via the `origin` query argument. This issue affects Apache Airflow versions 2.2.3 and below.",
  "repo": "apache/airflow",
  "patch_hash": "628aa1f99c865d97d0b1c7c76e630e43a7b8d319",
  "patch_info": {
    "commit_hash": "628aa1f99c865d97d0b1c7c76e630e43a7b8d319",
    "repo": "apache/airflow",
    "commit_url": "https://github.com/apache/airflow/commit/628aa1f99c865d97d0b1c7c76e630e43a7b8d319",
    "files": [
      "airflow/www/templates/airflow/trigger.html",
      "tests/www/views/test_views_trigger_dag.py"
    ],
    "message": "Simplify trigger cancel button (#21591)\n\nCo-authored-by: Jed Cunningham <jedcunningham@apache.org>\n(cherry picked from commit 65297673a318660fba76797e50d0c06804dfcafc)",
    "before_after_code_files": [
      "airflow/www/templates/airflow/trigger.html||airflow/www/templates/airflow/trigger.html",
      "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py"
    ]
  },
  "patch_diff": {
    "airflow/www/templates/airflow/trigger.html||airflow/www/templates/airflow/trigger.html": [
      "File: airflow/www/templates/airflow/trigger.html -> airflow/www/templates/airflow/trigger.html",
      "--- Hunk 1 ---",
      "[Context before]",
      "63:       </label>",
      "64:     </div>",
      "65:     <button type=\"submit\" class=\"btn btn-primary\">Trigger</button>",
      "67:   </form>",
      "68: {% endblock %}",
      "",
      "[Removed Lines]",
      "66:     <button type=\"button\" class=\"btn\" onclick=\"location.href = '{{ origin }}'; return false\">Cancel</button>",
      "",
      "[Added Lines]",
      "66:     <a class=\"btn\" href=\"{{ origin }}\">Cancel</a>",
      "",
      "---------------"
    ],
    "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py": [
      "File: tests/www/views/test_views_trigger_dag.py -> tests/www/views/test_views_trigger_dag.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "133:         (\"javascript:alert(1)\", \"/home\"),",
      "134:         (\"http://google.com\", \"/home\"),",
      "135:         (\"36539'%3balert(1)%2f%2f166\", \"/home\"),",
      "136:         (",
      "137:             \"%2Ftree%3Fdag_id%3Dexample_bash_operator';alert(33)//\",",
      "138:             \"/home\",",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "136:         (",
      "137:             '\"><script>alert(99)</script><a href=\"',",
      "138:             \"&#34;&gt;&lt;script&gt;alert(99)&lt;/script&gt;&lt;a href=&#34;\",",
      "139:         ),",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "145:     test_dag_id = \"example_bash_operator\"",
      "147:     resp = admin_client.get(f'trigger?dag_id={test_dag_id}&origin={test_origin}')",
      "156: @pytest.mark.parametrize(",
      "",
      "[Removed Lines]",
      "148:     check_content_in_response(",
      "149:         '<button type=\"button\" class=\"btn\" onclick=\"location.href = \\'{}\\'; return false\">'.format(",
      "150:             expected_origin",
      "151:         ),",
      "152:         resp,",
      "153:     )",
      "",
      "[Added Lines]",
      "152:     check_content_in_response(f'<a class=\"btn\" href=\"{expected_origin}\">Cancel</a>', resp)",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "dda864d585431c1c46c2705c40ed27ab9c43be72",
      "candidate_info": {
        "commit_hash": "dda864d585431c1c46c2705c40ed27ab9c43be72",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/dda864d585431c1c46c2705c40ed27ab9c43be72",
        "files": [
          "airflow/models/xcom.py",
          "airflow/settings.py",
          "airflow/utils/session.py"
        ],
        "message": "Helper for provide_session-decorated functions (#20104)\n\n* Helper for provide_session-decorated functions\n\n* Apply NEW_SESSION trick on XCom\n\n(cherry picked from commit a80ac1eecc0ea187de7984510b4ef6f981b97196)",
        "before_after_code_files": [
          "airflow/models/xcom.py||airflow/models/xcom.py",
          "airflow/settings.py||airflow/settings.py",
          "airflow/utils/session.py||airflow/utils/session.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/models/xcom.py||airflow/models/xcom.py": [
          "File: airflow/models/xcom.py -> airflow/models/xcom.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "32: from airflow.utils import timezone",
          "33: from airflow.utils.helpers import is_container",
          "34: from airflow.utils.log.logging_mixin import LoggingMixin",
          "36: from airflow.utils.sqlalchemy import UtcDateTime",
          "38: log = logging.getLogger(__name__)",
          "",
          "[Removed Lines]",
          "35: from airflow.utils.session import provide_session",
          "",
          "[Added Lines]",
          "35: from airflow.utils.session import NEW_SESSION, provide_session",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "90:         dag_id: str,",
          "91:         task_id: str,",
          "92:         run_id: str,",
          "94:     ) -> None:",
          "95:         \"\"\"Store an XCom value.",
          "",
          "[Removed Lines]",
          "93:         session: Optional[Session] = None,",
          "",
          "[Added Lines]",
          "93:         session: Session = NEW_SESSION,",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "116:         task_id: str,",
          "117:         dag_id: str,",
          "118:         execution_date: datetime.datetime,",
          "120:     ) -> None:",
          "121:         \"\"\":sphinx-autoapi-skip:\"\"\"",
          "",
          "[Removed Lines]",
          "119:         session: Optional[Session] = None,",
          "",
          "[Added Lines]",
          "119:         session: Session = NEW_SESSION,",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "129:         task_id: str,",
          "130:         dag_id: str,",
          "131:         execution_date: Optional[datetime.datetime] = None,",
          "134:         run_id: Optional[str] = None,",
          "135:     ) -> None:",
          "",
          "[Removed Lines]",
          "132:         session: Session = None,",
          "",
          "[Added Lines]",
          "132:         session: Session = NEW_SESSION,",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "170:         task_id: Optional[str] = None,",
          "171:         dag_id: Optional[str] = None,",
          "172:         include_prior_dates: bool = False,",
          "174:     ) -> Optional[Any]:",
          "175:         \"\"\"Retrieve an XCom value, optionally meeting certain criteria.",
          "",
          "[Removed Lines]",
          "173:         session: Optional[Session] = None,",
          "",
          "[Added Lines]",
          "173:         session: Session = NEW_SESSION,",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "207:         task_id: Optional[str] = None,",
          "208:         dag_id: Optional[str] = None,",
          "209:         include_prior_dates: bool = False,",
          "211:     ) -> Optional[Any]:",
          "212:         \"\"\":sphinx-autoapi-skip:\"\"\"",
          "",
          "[Removed Lines]",
          "210:         session: Optional[Session] = None,",
          "",
          "[Added Lines]",
          "210:         session: Session = NEW_SESSION,",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "220:         task_id: Optional[Union[str, Iterable[str]]] = None,",
          "221:         dag_id: Optional[Union[str, Iterable[str]]] = None,",
          "222:         include_prior_dates: bool = False,",
          "225:         run_id: Optional[str] = None,",
          "226:     ) -> Optional[Any]:",
          "",
          "[Removed Lines]",
          "223:         session: Session = None,",
          "",
          "[Added Lines]",
          "223:         session: Session = NEW_SESSION,",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "265:         dag_ids: Union[str, Iterable[str], None] = None,",
          "266:         include_prior_dates: bool = False,",
          "267:         limit: Optional[int] = None,",
          "269:     ) -> Query:",
          "270:         \"\"\"Composes a query to get one or more XCom entries.",
          "",
          "[Removed Lines]",
          "268:         session: Optional[Session] = None,",
          "",
          "[Added Lines]",
          "268:         session: Session = NEW_SESSION,",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "300:         dag_ids: Union[str, Iterable[str], None] = None,",
          "301:         include_prior_dates: bool = False,",
          "302:         limit: Optional[int] = None,",
          "304:     ) -> Query:",
          "305:         \"\"\":sphinx-autoapi-skip:\"\"\"",
          "",
          "[Removed Lines]",
          "303:         session: Optional[Session] = None,",
          "",
          "[Added Lines]",
          "303:         session: Session = NEW_SESSION,",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "314:         dag_ids: Optional[Union[str, Iterable[str]]] = None,",
          "315:         include_prior_dates: bool = False,",
          "316:         limit: Optional[int] = None,",
          "319:         run_id: Optional[str] = None,",
          "320:     ) -> Query:",
          "",
          "[Removed Lines]",
          "317:         session: Session = None,",
          "",
          "[Added Lines]",
          "317:         session: Session = NEW_SESSION,",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "397:         execution_date: pendulum.DateTime,",
          "398:         dag_id: str,",
          "399:         task_id: str,",
          "401:     ) -> None:",
          "402:         \"\"\":sphinx-autoapi-skip:\"\"\"",
          "",
          "[Removed Lines]",
          "400:         session: Optional[Session] = None,",
          "",
          "[Added Lines]",
          "400:         session: Session = NEW_SESSION,",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "409:         dag_id: Optional[str] = None,",
          "410:         task_id: Optional[str] = None,",
          "411:         run_id: Optional[str] = None,",
          "413:     ) -> None:",
          "414:         \"\"\":sphinx-autoapi-skip:\"\"\"",
          "415:         # Given the historic order of this function (execution_date was first argument) to add a new optional",
          "",
          "[Removed Lines]",
          "412:         session: Session = None,",
          "",
          "[Added Lines]",
          "412:         session: Session = NEW_SESSION,",
          "",
          "---------------"
        ],
        "airflow/settings.py||airflow/settings.py": [
          "File: airflow/settings.py -> airflow/settings.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: import os",
          "23: import sys",
          "24: import warnings",
          "27: import pendulum",
          "28: import sqlalchemy",
          "",
          "[Removed Lines]",
          "25: from typing import Optional",
          "",
          "[Added Lines]",
          "25: from typing import TYPE_CHECKING, Callable, List, Optional",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "37: from airflow.logging_config import configure_logging",
          "38: from airflow.utils.orm_event_handlers import setup_event_handlers",
          "40: log = logging.getLogger(__name__)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "40: if TYPE_CHECKING:",
          "41:     from airflow.www.utils import UIAlert",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "77: DAGS_FOLDER: str = os.path.expanduser(conf.get('core', 'DAGS_FOLDER'))",
          "79: engine: Optional[Engine] = None",
          "82: # The JSON library to use for DAG Serialization and De-Serialization",
          "83: json = json",
          "",
          "[Removed Lines]",
          "80: Session: Optional[SASession] = None",
          "",
          "[Added Lines]",
          "83: Session: Callable[..., SASession]",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "563: #       UIAlert('Visit <a href=\"http://airflow.apache.org\">airflow.apache.org</a>', html=True),",
          "564: #   ]",
          "565: #",
          "569: # Prefix used to identify tables holding data moved during migration.",
          "570: AIRFLOW_MOVED_TABLE_PREFIX = \"_airflow_moved\"",
          "",
          "[Removed Lines]",
          "566: # DASHBOARD_UIALERTS: List[\"UIAlert\"]",
          "567: DASHBOARD_UIALERTS = []",
          "",
          "[Added Lines]",
          "569: DASHBOARD_UIALERTS: List[\"UIAlert\"] = []",
          "",
          "---------------"
        ],
        "airflow/utils/session.py||airflow/utils/session.py": [
          "File: airflow/utils/session.py -> airflow/utils/session.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: import contextlib",
          "19: from functools import wraps",
          "20: from inspect import signature",
          "23: from airflow import settings",
          "",
          "[Removed Lines]",
          "21: from typing import Callable, Iterator, TypeVar",
          "",
          "[Added Lines]",
          "21: from typing import Callable, Iterator, TypeVar, cast",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "26: @contextlib.contextmanager",
          "27: def create_session() -> Iterator[settings.SASession]:",
          "28:     \"\"\"Contextmanager that will create and teardown a session.\"\"\"",
          "30:     try:",
          "31:         yield session",
          "32:         session.commit()",
          "",
          "[Removed Lines]",
          "29:     session: settings.SASession = settings.Session()",
          "",
          "[Added Lines]",
          "29:     session = settings.Session()",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "105:         if dialect.name == 'mssql':",
          "106:             # TODO: make locking works for MSSQL",
          "107:             pass",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "110: # A fake session to use in functions decorated by provide_session. This allows",
          "111: # the 'session' argument to be of type Session instead of Optional[Session],",
          "112: # making it easier to type hint the function body without dealing with the None",
          "113: # case that can never happen at runtime.",
          "114: NEW_SESSION: settings.SASession = cast(settings.SASession, None)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "1c2340558b96cde92390bf1b4dc9483236675e18",
      "candidate_info": {
        "commit_hash": "1c2340558b96cde92390bf1b4dc9483236675e18",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/1c2340558b96cde92390bf1b4dc9483236675e18",
        "files": [
          "airflow/operators/trigger_dagrun.py",
          "tests/operators/test_trigger_dagrun.py"
        ],
        "message": "Fix mismatch in generated run_id and logical date of DAG run (#18707)\n\nCo-authored-by: Tzu-ping Chung <tp@astronomer.io>\nCo-authored-by: Jed Cunningham <jedcunningham@apache.org>\n(cherry picked from commit 1f08d281632670aef1de8dfc62c9f63aeec18760)",
        "before_after_code_files": [
          "airflow/operators/trigger_dagrun.py||airflow/operators/trigger_dagrun.py",
          "tests/operators/test_trigger_dagrun.py||tests/operators/test_trigger_dagrun.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/operators/trigger_dagrun.py||airflow/operators/trigger_dagrun.py": [
          "File: airflow/operators/trigger_dagrun.py -> airflow/operators/trigger_dagrun.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "115:         self.allowed_states = allowed_states or [State.SUCCESS]",
          "116:         self.failed_states = failed_states or [State.FAILED]",
          "119:             raise TypeError(",
          "120:                 \"Expected str or datetime.datetime type for execution_date.\"",
          "121:                 \"Got {}\".format(type(execution_date))",
          "122:             )",
          "126:         try:",
          "127:             json.dumps(self.conf)",
          "",
          "[Removed Lines]",
          "118:         if not isinstance(execution_date, (str, datetime.datetime, type(None))):",
          "124:         self.execution_date: Optional[datetime.datetime] = execution_date  # type: ignore",
          "",
          "[Added Lines]",
          "118:         if execution_date is not None and not isinstance(execution_date, (str, datetime.datetime)):",
          "124:         self.execution_date = execution_date",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "131:     def execute(self, context: Dict):",
          "132:         if isinstance(self.execution_date, datetime.datetime):",
          "134:         elif isinstance(self.execution_date, str):",
          "137:         else:",
          "140:         if self.trigger_run_id:",
          "141:             run_id = self.trigger_run_id",
          "142:         else:",
          "145:         try:",
          "146:             dag_run = trigger_dag(",
          "147:                 dag_id=self.trigger_dag_id,",
          "148:                 run_id=run_id,",
          "149:                 conf=self.conf,",
          "151:                 replace_microseconds=False,",
          "152:             )",
          "154:         except DagRunAlreadyExists as e:",
          "155:             if self.reset_dag_run:",
          "158:                 # Get target dag object and call clear()",
          "",
          "[Removed Lines]",
          "133:             execution_date = self.execution_date",
          "135:             execution_date = timezone.parse(self.execution_date)",
          "136:             self.execution_date = execution_date",
          "138:             execution_date = timezone.utcnow()",
          "143:             run_id = DagRun.generate_run_id(DagRunType.MANUAL, execution_date)",
          "150:                 execution_date=self.execution_date,",
          "156:                 self.log.info(\"Clearing %s on %s\", self.trigger_dag_id, self.execution_date)",
          "",
          "[Added Lines]",
          "133:             parsed_execution_date = self.execution_date",
          "135:             parsed_execution_date = timezone.parse(self.execution_date)",
          "137:             parsed_execution_date = timezone.utcnow()",
          "142:             run_id = DagRun.generate_run_id(DagRunType.MANUAL, parsed_execution_date)",
          "148:                 execution_date=parsed_execution_date,",
          "154:                 self.log.info(\"Clearing %s on %s\", self.trigger_dag_id, parsed_execution_date)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "164:                 dag_bag = DagBag(dag_folder=dag_model.fileloc, read_dags_from_db=True)",
          "165:                 dag = dag_bag.get_dag(self.trigger_dag_id)",
          "167:                 dag_run = DagRun.find(dag_id=dag.dag_id, run_id=run_id)[0]",
          "168:             else:",
          "169:                 raise e",
          "",
          "[Removed Lines]",
          "166:                 dag.clear(start_date=self.execution_date, end_date=self.execution_date)",
          "",
          "[Added Lines]",
          "164:                 dag.clear(start_date=parsed_execution_date, end_date=parsed_execution_date)",
          "",
          "---------------"
        ],
        "tests/operators/test_trigger_dagrun.py||tests/operators/test_trigger_dagrun.py": [
          "File: tests/operators/test_trigger_dagrun.py -> tests/operators/test_trigger_dagrun.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "30: from airflow.utils import timezone",
          "31: from airflow.utils.session import create_session",
          "32: from airflow.utils.state import State",
          "34: DEFAULT_DATE = datetime(2019, 1, 1, tzinfo=timezone.utc)",
          "35: TEST_DAG_ID = \"testdag\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "33: from airflow.utils.types import DagRunType",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "101:         task.run(start_date=DEFAULT_DATE, end_date=DEFAULT_DATE, ignore_ti_state=True)",
          "103:         with create_session() as session:",
          "110:     def test_trigger_dagrun_custom_run_id(self):",
          "111:         task = TriggerDagRunOperator(",
          "",
          "[Removed Lines]",
          "104:             dagruns = session.query(DagRun).filter(DagRun.dag_id == TRIGGERED_DAG_ID).all()",
          "105:             assert len(dagruns) == 1",
          "106:             triggered_dag_run = dagruns[0]",
          "107:             assert triggered_dag_run.external_trigger",
          "108:             self.assert_extra_link(DEFAULT_DATE, triggered_dag_run, task)",
          "",
          "[Added Lines]",
          "105:             dagrun = session.query(DagRun).filter(DagRun.dag_id == TRIGGERED_DAG_ID).one()",
          "106:             assert dagrun.external_trigger",
          "107:             assert dagrun.run_id == DagRun.generate_run_id(DagRunType.MANUAL, dagrun.execution_date)",
          "108:             self.assert_extra_link(DEFAULT_DATE, dagrun, task)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "124:     def test_trigger_dagrun_with_execution_date(self):",
          "125:         \"\"\"Test TriggerDagRunOperator with custom execution_date.\"\"\"",
          "127:         task = TriggerDagRunOperator(",
          "128:             task_id=\"test_trigger_dagrun_with_execution_date\",",
          "129:             trigger_dag_id=TRIGGERED_DAG_ID,",
          "131:             dag=self.dag,",
          "132:         )",
          "133:         task.run(start_date=DEFAULT_DATE, end_date=DEFAULT_DATE, ignore_ti_state=True)",
          "135:         with create_session() as session:",
          "143:     def test_trigger_dagrun_twice(self):",
          "144:         \"\"\"Test TriggerDagRunOperator with custom execution_date.\"\"\"",
          "",
          "[Removed Lines]",
          "126:         utc_now = timezone.utcnow()",
          "130:             execution_date=utc_now,",
          "136:             dagruns = session.query(DagRun).filter(DagRun.dag_id == TRIGGERED_DAG_ID).all()",
          "137:             assert len(dagruns) == 1",
          "138:             triggered_dag_run = dagruns[0]",
          "139:             assert triggered_dag_run.external_trigger",
          "140:             assert triggered_dag_run.execution_date == utc_now",
          "141:             self.assert_extra_link(DEFAULT_DATE, triggered_dag_run, task)",
          "",
          "[Added Lines]",
          "126:         custom_execution_date = timezone.datetime(2021, 1, 2, 3, 4, 5)",
          "130:             execution_date=custom_execution_date,",
          "136:             dagrun = session.query(DagRun).filter(DagRun.dag_id == TRIGGERED_DAG_ID).one()",
          "137:             assert dagrun.external_trigger",
          "138:             assert dagrun.execution_date == custom_execution_date",
          "139:             assert dagrun.run_id == DagRun.generate_run_id(DagRunType.MANUAL, custom_execution_date)",
          "140:             self.assert_extra_link(DEFAULT_DATE, dagrun, task)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "deb953d9b3c1cf450aee9dfe92f81e9ffa768f06",
      "candidate_info": {
        "commit_hash": "deb953d9b3c1cf450aee9dfe92f81e9ffa768f06",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/deb953d9b3c1cf450aee9dfe92f81e9ffa768f06",
        "files": [
          "tests/test_utils/www.py",
          "tests/www/test_views.py",
          "tests/www/views/conftest.py",
          "tests/www/views/test_views.py",
          "tests/www/views/test_views_connection.py",
          "tests/www/views/test_views_dagrun.py",
          "tests/www/views/test_views_decorators.py",
          "tests/www/views/test_views_extra_links.py",
          "tests/www/views/test_views_mount.py",
          "tests/www/views/test_views_pool.py",
          "tests/www/views/test_views_rendered.py",
          "tests/www/views/test_views_trigger_dag.py",
          "tests/www/views/test_views_variable.py"
        ],
        "message": "Refactor tests/www/test_views.py (#15666)\n\n* Move out www connection tests\n\n* Move out www variable tests\n\n* Move out www plugin tests\n\n* Move out www pool tests\n\n* Move out mount point tests\n\n* Move out www configuration tests\n\n* Move out www redoc tests\n\nAlso merge some side-effect-less tests into one file so we don't get too\nmany tiny files.\n\n* Move out task instance list tests\n\n* Make sure base view init is in app context\n\n* Move out www helper function tests\n\n* Move out www dagrun tests\n\n* Move out www extra link tests\n\n* Move out www trigger DAG tests\n\n* Move out www rendered field tests\n\n* Always load example DAGs before running view tests\n\n* Properly handle test sessions so new tests work\n\n* Remove 'checker' in favor of plain functions",
        "before_after_code_files": [
          "tests/test_utils/www.py||tests/test_utils/www.py",
          "tests/www/test_views.py||tests/www/test_views.py",
          "tests/www/views/conftest.py||tests/www/views/conftest.py",
          "tests/www/views/test_views.py||tests/www/views/test_views.py",
          "tests/www/views/test_views_connection.py||tests/www/views/test_views_connection.py",
          "tests/www/views/test_views_dagrun.py||tests/www/views/test_views_dagrun.py",
          "tests/www/views/test_views_decorators.py||tests/www/views/test_views_decorators.py",
          "tests/www/views/test_views_extra_links.py||tests/www/views/test_views_extra_links.py",
          "tests/www/views/test_views_mount.py||tests/www/views/test_views_mount.py",
          "tests/www/views/test_views_pool.py||tests/www/views/test_views_pool.py",
          "tests/www/views/test_views_rendered.py||tests/www/views/test_views_rendered.py",
          "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py",
          "tests/www/views/test_views_variable.py||tests/www/views/test_views_variable.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py"
          ],
          "candidate": [
            "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py"
          ]
        }
      },
      "candidate_diff": {
        "tests/test_utils/www.py||tests/test_utils/www.py": [
          "File: tests/test_utils/www.py -> tests/test_utils/www.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: # Licensed to the Apache Software Foundation (ASF) under one",
          "2: # or more contributor license agreements.  See the NOTICE file",
          "3: # distributed with this work for additional information",
          "4: # regarding copyright ownership.  The ASF licenses this file",
          "5: # to you under the Apache License, Version 2.0 (the",
          "6: # \"License\"); you may not use this file except in compliance",
          "7: # with the License.  You may obtain a copy of the License at",
          "8: #",
          "9: #   http://www.apache.org/licenses/LICENSE-2.0",
          "10: #",
          "11: # Unless required by applicable law or agreed to in writing,",
          "12: # software distributed under the License is distributed on an",
          "13: # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
          "14: # KIND, either express or implied.  See the License for the",
          "15: # specific language governing permissions and limitations",
          "16: # under the License.",
          "17: from unittest import mock",
          "20: def client_with_login(app, **kwargs):",
          "21:     patch_path = \"flask_appbuilder.security.manager.check_password_hash\"",
          "22:     with mock.patch(patch_path) as check_password_hash:",
          "23:         check_password_hash.return_value = True",
          "24:         client = app.test_client()",
          "25:         resp = client.post(\"/login/\", data=kwargs)",
          "26:         assert resp.status_code == 302",
          "27:     return client",
          "30: def check_content_in_response(text, resp, resp_code=200):",
          "31:     resp_html = resp.data.decode('utf-8')",
          "32:     assert resp_code == resp.status_code",
          "33:     if isinstance(text, list):",
          "34:         for line in text:",
          "35:             assert line in resp_html",
          "36:     else:",
          "37:         assert text in resp_html",
          "40: def check_content_not_in_response(text, resp, resp_code=200):",
          "41:     resp_html = resp.data.decode('utf-8')",
          "42:     assert resp_code == resp.status_code",
          "43:     if isinstance(text, list):",
          "44:         for line in text:",
          "45:             assert line not in resp_html",
          "46:     else:",
          "47:         assert text not in resp_html",
          "",
          "---------------"
        ],
        "tests/www/test_views.py||tests/www/test_views.py": [
          "File: tests/www/test_views.py -> tests/www/test_views.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: # under the License.",
          "18: import copy",
          "19: import html",
          "21: import json",
          "22: import logging.config",
          "23: import os",
          "",
          "[Removed Lines]",
          "20: import io",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "35: from urllib.parse import quote_plus",
          "37: import jinja2",
          "40: from parameterized import parameterized",
          "44: from airflow import models, settings, version",
          "45: from airflow.config_templates.airflow_local_settings import DEFAULT_LOGGING_CONFIG",
          "47: from airflow.executors.celery_executor import CeleryExecutor",
          "48: from airflow.jobs.base_job import BaseJob",
          "54: from airflow.operators.dummy import DummyOperator",
          "56: from airflow.security import permissions",
          "57: from airflow.ti_deps.dependencies_states import QUEUEABLE_STATES, RUNNABLE_STATES",
          "58: from airflow.utils import dates, timezone",
          "",
          "[Removed Lines]",
          "38: import pytest",
          "39: from flask import Markup, session as flask_session, template_rendered, url_for",
          "41: from werkzeug.test import Client",
          "42: from werkzeug.wrappers import BaseResponse",
          "46: from airflow.configuration import conf, initialize_config",
          "49: from airflow.models import DAG, Connection, DagRun, TaskInstance",
          "50: from airflow.models.baseoperator import BaseOperator, BaseOperatorLink",
          "51: from airflow.models.renderedtifields import RenderedTaskInstanceFields as RTIF",
          "52: from airflow.models.serialized_dag import SerializedDagModel",
          "53: from airflow.operators.bash import BashOperator",
          "55: from airflow.plugins_manager import AirflowPlugin, EntryPointSource",
          "",
          "[Added Lines]",
          "37: from flask import session as flask_session, template_rendered",
          "42: from airflow.configuration import conf",
          "45: from airflow.models import DAG, DagRun, TaskInstance",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "64: from airflow.www import app as application",
          "65: from airflow.www.extensions import init_views",
          "66: from airflow.www.extensions.init_appbuilder_links import init_appbuilder_links",
          "68: from tests.test_utils import api_connexion_utils",
          "69: from tests.test_utils.asserts import assert_queries_count",
          "70: from tests.test_utils.config import conf_vars",
          "71: from tests.test_utils.db import clear_db_runs",
          "72: from tests.test_utils.decorators import dont_initialize_flask_app_submodules",
          "76: class TemplateWithContext(NamedTuple):",
          "",
          "[Removed Lines]",
          "67: from airflow.www.views import ConnectionModelView, get_safe_url, truncate_task_duration",
          "73: from tests.test_utils.mock_plugins import mock_plugin_manager",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "239:         self.login(username=username, password=username)",
          "471: class TestAirflowBaseViews(TestBase):",
          "472:     EXAMPLE_DAG_DEFAULT_DATE = dates.days_ago(2)",
          "",
          "[Removed Lines]",
          "242: class TestConnectionModelView(TestBase):",
          "243:     def setUp(self):",
          "244:         super().setUp()",
          "246:         self.connection = {",
          "247:             'conn_id': 'test_conn',",
          "248:             'conn_type': 'http',",
          "249:             'description': 'description',",
          "250:             'host': 'localhost',",
          "251:             'port': 8080,",
          "252:             'username': 'root',",
          "253:             'password': 'admin',",
          "254:         }",
          "256:     def tearDown(self):",
          "257:         self.clear_table(Connection)",
          "258:         super().tearDown()",
          "260:     def test_create_connection(self):",
          "261:         init_views.init_connection_form()",
          "262:         resp = self.client.post('/connection/add', data=self.connection, follow_redirects=True)",
          "263:         self.check_content_in_response('Added Row', resp)",
          "265:     def test_prefill_form_null_extra(self):",
          "266:         mock_form = mock.Mock()",
          "267:         mock_form.data = {\"conn_id\": \"test\", \"extra\": None}",
          "269:         cmv = ConnectionModelView()",
          "270:         cmv.prefill_form(form=mock_form, pk=1)",
          "273: class TestVariableModelView(TestBase):",
          "274:     def setUp(self):",
          "275:         super().setUp()",
          "276:         self.variable = {",
          "277:             'key': 'test_key',",
          "278:             'val': 'text_val',",
          "279:             'description': 'test_description',",
          "280:             'is_encrypted': True,",
          "281:         }",
          "283:     def tearDown(self):",
          "284:         self.clear_table(models.Variable)",
          "285:         super().tearDown()",
          "287:     def test_can_handle_error_on_decrypt(self):",
          "289:         # create valid variable",
          "290:         self.client.post('/variable/add', data=self.variable, follow_redirects=True)",
          "292:         # update the variable with a wrong value, given that is encrypted",
          "293:         Var = models.Variable  # pylint: disable=invalid-name",
          "294:         (",
          "295:             self.session.query(Var)",
          "296:             .filter(Var.key == self.variable['key'])",
          "297:             .update({'val': 'failed_value_not_encrypted'}, synchronize_session=False)",
          "298:         )",
          "299:         self.session.commit()",
          "301:         # retrieve Variables page, should not fail and contain the Invalid",
          "302:         # label for the variable",
          "303:         resp = self.client.get('/variable/list', follow_redirects=True)",
          "304:         self.check_content_in_response('<span class=\"label label-danger\">Invalid</span>', resp)",
          "306:     def test_xss_prevention(self):",
          "307:         xss = \"/variable/list/<img%20src=''%20onerror='alert(1);'>\"",
          "309:         resp = self.client.get(",
          "310:             xss,",
          "311:             follow_redirects=True,",
          "312:         )",
          "313:         assert resp.status_code == 404",
          "314:         assert \"<img src='' onerror='alert(1);'>\" not in resp.data.decode(\"utf-8\")",
          "316:     def test_import_variables_no_file(self):",
          "317:         resp = self.client.post('/variable/varimport', follow_redirects=True)",
          "318:         self.check_content_in_response('Missing file or syntax error.', resp)",
          "320:     def test_import_variables_failed(self):",
          "321:         content = '{\"str_key\": \"str_value\"}'",
          "323:         with mock.patch('airflow.models.Variable.set') as set_mock:",
          "324:             set_mock.side_effect = UnicodeEncodeError",
          "325:             assert self.session.query(models.Variable).count() == 0",
          "327:             bytes_content = io.BytesIO(bytes(content, encoding='utf-8'))",
          "329:             resp = self.client.post(",
          "330:                 '/variable/varimport', data={'file': (bytes_content, 'test.json')}, follow_redirects=True",
          "331:             )",
          "332:             self.check_content_in_response('1 variable(s) failed to be updated.', resp)",
          "334:     def test_import_variables_success(self):",
          "335:         assert self.session.query(models.Variable).count() == 0",
          "337:         content = (",
          "338:             '{\"str_key\": \"str_value\", \"int_key\": 60, \"list_key\": [1, 2], \"dict_key\": {\"k_a\": 2, \"k_b\": 3}}'",
          "339:         )",
          "340:         bytes_content = io.BytesIO(bytes(content, encoding='utf-8'))",
          "342:         resp = self.client.post(",
          "343:             '/variable/varimport', data={'file': (bytes_content, 'test.json')}, follow_redirects=True",
          "344:         )",
          "345:         self.check_content_in_response('4 variable(s) successfully updated.', resp)",
          "347:     def test_description_retrieval(self):",
          "348:         # create valid variable",
          "349:         self.client.post('/variable/add', data=self.variable, follow_redirects=True)",
          "351:         row = self.session.query(models.Variable.key, models.Variable.description).first()",
          "352:         assert row.key == 'test_key' and row.description == 'test_description'",
          "355: class PluginOperator(BaseOperator):",
          "356:     pass",
          "359: class TestPluginView(TestBase):",
          "360:     def test_should_list_plugins_on_page_with_details(self):",
          "361:         resp = self.client.get('/plugin')",
          "362:         self.check_content_in_response(\"test_plugin\", resp)",
          "363:         self.check_content_in_response(\"Airflow Plugins\", resp)",
          "364:         self.check_content_in_response(\"source\", resp)",
          "365:         self.check_content_in_response(\"<em>$PLUGINS_FOLDER/</em>test_plugin.py\", resp)",
          "367:     def test_should_list_entrypoint_plugins_on_page_with_details(self):",
          "369:         mock_plugin = AirflowPlugin()",
          "370:         mock_plugin.name = \"test_plugin\"",
          "371:         mock_plugin.source = EntryPointSource(",
          "372:             mock.Mock(), mock.Mock(version='1.0.0', metadata={'name': 'test-entrypoint-testpluginview'})",
          "373:         )",
          "374:         with mock_plugin_manager(plugins=[mock_plugin]):",
          "375:             resp = self.client.get('/plugin')",
          "377:         self.check_content_in_response(\"test_plugin\", resp)",
          "378:         self.check_content_in_response(\"Airflow Plugins\", resp)",
          "379:         self.check_content_in_response(\"source\", resp)",
          "380:         self.check_content_in_response(\"<em>test-entrypoint-testpluginview==1.0.0:</em> <Mock id=\", resp)",
          "382:     def test_endpoint_should_not_be_unauthenticated(self):",
          "383:         self.logout()",
          "384:         resp = self.client.get('/plugin', follow_redirects=True)",
          "385:         self.check_content_not_in_response(\"test_plugin\", resp)",
          "386:         self.check_content_in_response(\"Sign In - Airflow\", resp)",
          "389: class TestPoolModelView(TestBase):",
          "390:     def setUp(self):",
          "391:         super().setUp()",
          "392:         self.pool = {",
          "393:             'pool': 'test-pool',",
          "394:             'slots': 777,",
          "395:             'description': 'test-pool-description',",
          "396:         }",
          "398:     def tearDown(self):",
          "399:         self.clear_table(models.Pool)",
          "400:         super().tearDown()",
          "402:     def test_create_pool_with_same_name(self):",
          "403:         # create test pool",
          "404:         resp = self.client.post('/pool/add', data=self.pool, follow_redirects=True)",
          "405:         self.check_content_in_response('Added Row', resp)",
          "407:         # create pool with the same name",
          "408:         resp = self.client.post('/pool/add', data=self.pool, follow_redirects=True)",
          "409:         self.check_content_in_response('Already exists.', resp)",
          "411:     def test_create_pool_with_empty_name(self):",
          "412:         self.pool['pool'] = ''",
          "413:         resp = self.client.post('/pool/add', data=self.pool, follow_redirects=True)",
          "414:         self.check_content_in_response('This field is required.', resp)",
          "416:     def test_odd_name(self):",
          "417:         self.pool['pool'] = 'test-pool<script></script>'",
          "418:         self.session.add(models.Pool(**self.pool))",
          "419:         self.session.commit()",
          "420:         resp = self.client.get('/pool/list/')",
          "421:         self.check_content_in_response('test-pool&lt;script&gt;', resp)",
          "422:         self.check_content_not_in_response('test-pool<script>', resp)",
          "424:     def test_list(self):",
          "425:         self.pool['pool'] = 'test-pool'",
          "426:         self.session.add(models.Pool(**self.pool))",
          "427:         self.session.commit()",
          "428:         resp = self.client.get('/pool/list/')",
          "429:         # We should see this link",
          "430:         with self.app.test_request_context():",
          "431:             url = url_for('TaskInstanceModelView.list', _flt_3_pool='test-pool', _flt_3_state='running')",
          "432:             used_tag = Markup(\"<a href='{url}'>{slots}</a>\").format(url=url, slots=0)",
          "434:             url = url_for('TaskInstanceModelView.list', _flt_3_pool='test-pool', _flt_3_state='queued')",
          "435:             queued_tag = Markup(\"<a href='{url}'>{slots}</a>\").format(url=url, slots=0)",
          "436:         self.check_content_in_response(used_tag, resp)",
          "437:         self.check_content_in_response(queued_tag, resp)",
          "440: class TestMountPoint(unittest.TestCase):",
          "441:     @classmethod",
          "442:     @conf_vars({(\"webserver\", \"base_url\"): \"http://localhost/test\"})",
          "443:     def setUpClass(cls):",
          "444:         application.app = None",
          "445:         application.appbuilder = None",
          "446:         app = application.create_app(testing=True)",
          "447:         app.config['WTF_CSRF_ENABLED'] = False",
          "448:         cls.client = Client(app, BaseResponse)",
          "450:     @classmethod",
          "451:     def tearDownClass(cls):",
          "452:         application.app = None",
          "453:         application.appbuilder = None",
          "455:     def test_mount(self):",
          "456:         # Test an endpoint that doesn't need auth!",
          "457:         resp = self.client.get('/test/health')",
          "458:         assert resp.status_code == 200",
          "459:         assert b\"healthy\" in resp.data",
          "461:     def test_not_found(self):",
          "462:         resp = self.client.get('/', follow_redirects=True)",
          "463:         assert resp.status_code == 404",
          "465:     def test_index(self):",
          "466:         resp = self.client.get('/test/')",
          "467:         assert resp.status_code == 302",
          "468:         assert resp.headers['Location'] == 'http://localhost/test/home'",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "477:         models.DagBag(include_examples=True).sync_to_db()",
          "478:         cls.dagbag = models.DagBag(include_examples=True, read_dags_from_db=True)",
          "479:         cls.app.dag_bag = cls.dagbag",
          "484:     def setUp(self):",
          "485:         super().setUp()",
          "",
          "[Removed Lines]",
          "480:         init_views.init_api_connexion(cls.app)",
          "481:         init_views.init_plugins(cls.app)",
          "482:         init_appbuilder_links(cls.app)",
          "",
          "[Added Lines]",
          "240:         with cls.app.app_context():",
          "241:             init_views.init_api_connexion(cls.app)",
          "242:             init_views.init_plugins(cls.app)",
          "243:             init_appbuilder_links(cls.app)",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "1434:             self.check_content_not_in_response(xss_string, resp)",
          "1481: class TestLogView(TestBase):",
          "1482:     DAG_ID = 'dag_for_testing_log_view'",
          "1483:     DAG_ID_REMOVED = 'removed_dag_for_testing_log_view'",
          "",
          "[Removed Lines]",
          "1437: class TestConfigurationView(TestBase):",
          "1438:     def setUp(self):",
          "1439:         super().setUp()",
          "1440:         with mock.patch.dict(os.environ, {\"AIRFLOW__CORE__UNIT_TEST_MODE\": \"False\"}):",
          "1441:             initialize_config()",
          "1443:     def test_configuration_do_not_expose_config(self):",
          "1444:         self.logout()",
          "1445:         self.login()",
          "1446:         with conf_vars({('webserver', 'expose_config'): 'False'}):",
          "1447:             resp = self.client.get('configuration', follow_redirects=True)",
          "1448:         self.check_content_in_response(",
          "1449:             [",
          "1450:                 'Airflow Configuration',",
          "1451:                 '# Your Airflow administrator chose not to expose the configuration, '",
          "1452:                 'most likely for security reasons.',",
          "1453:             ],",
          "1454:             resp,",
          "1455:         )",
          "1457:     def test_configuration_expose_config(self):",
          "1458:         self.logout()",
          "1459:         self.login()",
          "1460:         with conf_vars({('webserver', 'expose_config'): 'True'}):",
          "1461:             resp = self.client.get('configuration', follow_redirects=True)",
          "1462:         self.check_content_in_response(['Airflow Configuration', 'Running Configuration'], resp)",
          "1465: class TestRedocView(TestBase):",
          "1466:     @classmethod",
          "1467:     def setUpClass(cls):",
          "1468:         super().setUpClass()",
          "1469:         init_views.init_api_connexion(cls.app)",
          "1471:     def test_should_render_template(self):",
          "1472:         with self.capture_templates() as templates:",
          "1473:             resp = self.client.get('redoc')",
          "1474:             self.check_content_in_response('Redoc', resp)",
          "1476:         assert len(templates) == 1",
          "1477:         assert templates[0].name == 'airflow/redoc.html'",
          "1478:         assert templates[0].local_context == {'openapi_spec_url': '/api/v1/openapi.yaml'}",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "2899:         self.login(username='test_viewer', password='test_viewer')",
          "2900:         resp = self.client.post('refresh?dag_id=example_bash_operator')",
          "2901:         self.check_content_in_response('Redirecting', resp, resp_code=302)",
          "",
          "[Removed Lines]",
          "2904: class TestTaskInstanceView(TestBase):",
          "2905:     TI_ENDPOINT = '/taskinstance/list/?_flt_0_execution_date={}'",
          "2907:     def test_start_date_filter(self):",
          "2908:         resp = self.client.get(self.TI_ENDPOINT.format(self.percent_encode('2018-10-09 22:44:31')))",
          "2909:         # We aren't checking the logic of the date filter itself (that is built",
          "2910:         # in to FAB) but simply that our UTC conversion was run - i.e. it",
          "2911:         # doesn't blow up!",
          "2912:         self.check_content_in_response('List Task Instance', resp)",
          "2915: class TestTaskRescheduleView(TestBase):",
          "2916:     TI_ENDPOINT = '/taskreschedule/list/?_flt_0_execution_date={}'",
          "2918:     def test_start_date_filter(self):",
          "2919:         resp = self.client.get(self.TI_ENDPOINT.format(self.percent_encode('2018-10-09 22:44:31')))",
          "2920:         # We aren't checking the logic of the date filter itself (that is built",
          "2921:         # in to FAB) but simply that our UTC conversion was run - i.e. it",
          "2922:         # doesn't blow up!",
          "2923:         self.check_content_in_response('List Task Reschedule', resp)",
          "2926: class TestRenderedView(TestBase):",
          "2927:     def setUp(self):",
          "2929:         self.default_date = datetime(2020, 3, 1)",
          "2930:         self.dag = DAG(",
          "2931:             \"testdag\",",
          "2932:             start_date=self.default_date,",
          "2933:             user_defined_filters={\"hello\": lambda name: f'Hello {name}'},",
          "2934:             user_defined_macros={\"fullname\": lambda fname, lname: f'{fname} {lname}'},",
          "2935:         )",
          "2936:         self.task1 = BashOperator(task_id='task1', bash_command='{{ task_instance_key_str }}', dag=self.dag)",
          "2937:         self.task2 = BashOperator(",
          "2938:             task_id='task2', bash_command='echo {{ fullname(\"Apache\", \"Airflow\") | hello }}', dag=self.dag",
          "2939:         )",
          "2940:         SerializedDagModel.write_dag(self.dag)",
          "2941:         with create_session() as session:",
          "2942:             session.query(RTIF).delete()",
          "2944:         self.app.dag_bag = mock.MagicMock(**{'get_dag.return_value': self.dag})",
          "2945:         super().setUp()",
          "2947:     def tearDown(self) -> None:",
          "2948:         super().tearDown()",
          "2949:         with create_session() as session:",
          "2950:             session.query(RTIF).delete()",
          "2952:     def test_rendered_template_view(self):",
          "2953:         \"\"\"",
          "2954:         Test that the Rendered View contains the values from RenderedTaskInstanceFields",
          "2955:         \"\"\"",
          "2956:         assert self.task1.bash_command == '{{ task_instance_key_str }}'",
          "2957:         ti = TaskInstance(self.task1, self.default_date)",
          "2959:         with create_session() as session:",
          "2960:             session.add(RTIF(ti))",
          "2962:         url = 'rendered-templates?task_id=task1&dag_id=testdag&execution_date={}'.format(",
          "2963:             self.percent_encode(self.default_date)",
          "2964:         )",
          "2966:         resp = self.client.get(url, follow_redirects=True)",
          "2967:         self.check_content_in_response(\"testdag__task1__20200301\", resp)",
          "2969:     def test_rendered_template_view_for_unexecuted_tis(self):",
          "2970:         \"\"\"",
          "2971:         Test that the Rendered View is able to show rendered values",
          "2972:         even for TIs that have not yet executed",
          "2973:         \"\"\"",
          "2974:         assert self.task1.bash_command == '{{ task_instance_key_str }}'",
          "2976:         url = 'rendered-templates?task_id=task1&dag_id=task1&execution_date={}'.format(",
          "2977:             self.percent_encode(self.default_date)",
          "2978:         )",
          "2980:         resp = self.client.get(url, follow_redirects=True)",
          "2981:         self.check_content_in_response(\"testdag__task1__20200301\", resp)",
          "2983:     def test_user_defined_filter_and_macros_raise_error(self):",
          "2984:         \"\"\"",
          "2985:         Test that the Rendered View is able to show rendered values",
          "2986:         even for TIs that have not yet executed",
          "2987:         \"\"\"",
          "2988:         self.app.dag_bag = mock.MagicMock(",
          "2990:         )",
          "2991:         assert self.task2.bash_command == 'echo {{ fullname(\"Apache\", \"Airflow\") | hello }}'",
          "2993:         url = 'rendered-templates?task_id=task2&dag_id=testdag&execution_date={}'.format(",
          "2994:             self.percent_encode(self.default_date)",
          "2995:         )",
          "2997:         resp = self.client.get(url, follow_redirects=True)",
          "2998:         self.check_content_not_in_response(\"echo Hello Apache Airflow\", resp)",
          "2999:         self.check_content_in_response(",
          "3000:             \"Webserver does not have access to User-defined Macros or Filters \"",
          "3001:             \"when Dag Serialization is enabled. Hence for the task that have not yet \"",
          "3002:             \"started running, please use &#39;airflow tasks render&#39; for debugging the \"",
          "3003:             \"rendering of template_fields.<br><br>OriginalError: no filter named &#39;hello&#39\",",
          "3004:             resp,",
          "3005:         )",
          "3008: class TestTriggerDag(TestBase):",
          "3009:     def setUp(self):",
          "3010:         super().setUp()",
          "3011:         models.DagBag().get_dag(\"example_bash_operator\").sync_to_db(session=self.session)",
          "3012:         self.session.commit()",
          "3014:     def test_trigger_dag_button_normal_exist(self):",
          "3015:         resp = self.client.get('/', follow_redirects=True)",
          "3016:         assert '/trigger?dag_id=example_bash_operator' in resp.data.decode('utf-8')",
          "3017:         assert \"return confirmDeleteDag(this, 'example_bash_operator')\" in resp.data.decode('utf-8')",
          "3019:     @pytest.mark.quarantined",
          "3020:     def test_trigger_dag_button(self):",
          "3022:         test_dag_id = \"example_bash_operator\"",
          "3024:         DR = models.DagRun  # pylint: disable=invalid-name",
          "3025:         self.session.query(DR).delete()",
          "3026:         self.session.commit()",
          "3028:         self.client.post(f'trigger?dag_id={test_dag_id}')",
          "3030:         run = self.session.query(DR).filter(DR.dag_id == test_dag_id).first()",
          "3031:         assert run is not None",
          "3032:         assert DagRunType.MANUAL in run.run_id",
          "3033:         assert run.run_type == DagRunType.MANUAL",
          "3035:     @pytest.mark.quarantined",
          "3036:     def test_trigger_dag_conf(self):",
          "3038:         test_dag_id = \"example_bash_operator\"",
          "3039:         conf_dict = {'string': 'Hello, World!'}",
          "3041:         DR = models.DagRun  # pylint: disable=invalid-name",
          "3042:         self.session.query(DR).delete()",
          "3043:         self.session.commit()",
          "3045:         self.client.post(f'trigger?dag_id={test_dag_id}', data={'conf': json.dumps(conf_dict)})",
          "3047:         run = self.session.query(DR).filter(DR.dag_id == test_dag_id).first()",
          "3048:         assert run is not None",
          "3049:         assert DagRunType.MANUAL in run.run_id",
          "3050:         assert run.run_type == DagRunType.MANUAL",
          "3051:         assert run.conf == conf_dict",
          "3053:     def test_trigger_dag_conf_malformed(self):",
          "3054:         test_dag_id = \"example_bash_operator\"",
          "3056:         DR = models.DagRun  # pylint: disable=invalid-name",
          "3057:         self.session.query(DR).delete()",
          "3058:         self.session.commit()",
          "3060:         response = self.client.post(f'trigger?dag_id={test_dag_id}', data={'conf': '{\"a\": \"b\"'})",
          "3061:         self.check_content_in_response('Invalid JSON configuration', response)",
          "3063:         run = self.session.query(DR).filter(DR.dag_id == test_dag_id).first()",
          "3064:         assert run is None",
          "3066:     def test_trigger_dag_form(self):",
          "3067:         test_dag_id = \"example_bash_operator\"",
          "3068:         resp = self.client.get(f'trigger?dag_id={test_dag_id}')",
          "3069:         self.check_content_in_response(f'Trigger DAG: {test_dag_id}', resp)",
          "3071:     @parameterized.expand(",
          "3072:         [",
          "3073:             (\"javascript:alert(1)\", \"/home\"),",
          "3074:             (\"http://google.com\", \"/home\"),",
          "3075:             (\"36539'%3balert(1)%2f%2f166\", \"/home\"),",
          "3076:             (",
          "3077:                 \"%2Ftree%3Fdag_id%3Dexample_bash_operator';alert(33)//\",",
          "3078:                 \"/home\",",
          "3079:             ),",
          "3080:             (\"%2Ftree%3Fdag_id%3Dexample_bash_operator\", \"/tree?dag_id=example_bash_operator\"),",
          "3081:             (\"%2Fgraph%3Fdag_id%3Dexample_bash_operator\", \"/graph?dag_id=example_bash_operator\"),",
          "3082:         ]",
          "3083:     )",
          "3084:     def test_trigger_dag_form_origin_url(self, test_origin, expected_origin):",
          "3085:         test_dag_id = \"example_bash_operator\"",
          "3087:         resp = self.client.get(f'trigger?dag_id={test_dag_id}&origin={test_origin}')",
          "3088:         self.check_content_in_response(",
          "3089:             '<button type=\"button\" class=\"btn\" onclick=\"location.href = \\'{}\\'; return false\">'.format(",
          "3090:                 expected_origin",
          "3091:             ),",
          "3092:             resp,",
          "3093:         )",
          "3095:     @parameterized.expand(",
          "3096:         [",
          "3097:             (None, {\"example_key\": \"example_value\"}),",
          "3098:             ({\"other\": \"test_data\", \"key\": 12}, {\"other\": \"test_data\", \"key\": 12}),",
          "3099:         ]",
          "3100:     )",
          "3101:     def test_trigger_dag_params_conf(self, request_conf, expected_conf):",
          "3102:         \"\"\"",
          "3103:         Test that textarea in Trigger DAG UI is pre-populated",
          "3104:         with json config when the conf URL parameter is passed,",
          "3105:         or if a params dict is passed in the DAG",
          "3107:             1. Conf is not included in URL parameters -> DAG.conf is in textarea",
          "3108:             2. Conf is passed as a URL parameter -> passed conf json is in textarea",
          "3109:         \"\"\"",
          "3110:         test_dag_id = \"example_bash_operator\"",
          "3111:         doc_md = \"Example Bash Operator\"",
          "3113:         if not request_conf:",
          "3114:             resp = self.client.get(f'trigger?dag_id={test_dag_id}')",
          "3115:         else:",
          "3116:             test_request_conf = json.dumps(request_conf, indent=4)",
          "3117:             resp = self.client.get(f'trigger?dag_id={test_dag_id}&conf={test_request_conf}&doc_md={doc_md}')",
          "3119:         expected_dag_conf = json.dumps(expected_conf, indent=4).replace(\"\\\"\", \"&#34;\")",
          "3121:         self.check_content_in_response(",
          "3122:             f'<textarea class=\"form-control\" name=\"conf\" id=\"json\">{expected_dag_conf}</textarea>',",
          "3123:             resp,",
          "3124:         )",
          "3126:     def test_trigger_endpoint_uses_existing_dagbag(self):",
          "3127:         \"\"\"",
          "3128:         Test that Trigger Endpoint uses the DagBag already created in views.py",
          "3129:         instead of creating a new one.",
          "3130:         \"\"\"",
          "3131:         url = 'trigger?dag_id=example_bash_operator'",
          "3132:         resp = self.client.post(url, data={}, follow_redirects=True)",
          "3133:         self.check_content_in_response('example_bash_operator', resp)",
          "3135:     def test_viewer_cant_trigger_dag(self):",
          "3136:         \"\"\"",
          "3137:         Test that the test_viewer user can't trigger DAGs.",
          "3138:         \"\"\"",
          "3139:         self.logout()",
          "3140:         self.create_user_and_login(",
          "3141:             username='test_viewer_cant_trigger_dag_user',",
          "3142:             role_name='test_viewer_cant_trigger_dag_user',",
          "3143:             perms=[",
          "3144:                 (permissions.ACTION_CAN_READ, permissions.RESOURCE_WEBSITE),",
          "3145:                 (permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG),",
          "3146:                 (permissions.ACTION_CAN_CREATE, permissions.RESOURCE_DAG_RUN),",
          "3147:             ],",
          "3148:         )",
          "3149:         url = 'trigger?dag_id=example_bash_operator'",
          "3150:         resp = self.client.get(url, follow_redirects=True)",
          "3151:         response_data = resp.data.decode()",
          "3152:         assert \"Access is Denied\" in response_data",
          "3155: class TestExtraLinks(TestBase):",
          "3156:     def setUp(self):",
          "3157:         from tests.test_utils.mock_operators import Dummy2TestOperator, Dummy3TestOperator",
          "3159:         self.endpoint = \"extra_links\"",
          "3160:         self.default_date = datetime(2017, 1, 1)",
          "3162:         class RaiseErrorLink(BaseOperatorLink):",
          "3163:             name = 'raise_error'",
          "3165:             def get_link(self, operator, dttm):",
          "3166:                 raise ValueError('This is an error')",
          "3168:         class NoResponseLink(BaseOperatorLink):",
          "3169:             name = 'no_response'",
          "3171:             def get_link(self, operator, dttm):  # pylint: disable=unused-argument",
          "3172:                 return None",
          "3174:         class FooBarLink(BaseOperatorLink):",
          "3175:             name = 'foo-bar'",
          "3177:             def get_link(self, operator, dttm):",
          "3178:                 return f\"http://www.example.com/{operator.task_id}/foo-bar/{dttm}\"",
          "3180:         class AirflowLink(BaseOperatorLink):",
          "3181:             name = 'airflow'",
          "3183:             def get_link(self, operator, dttm):  # pylint: disable=unused-argument",
          "3184:                 return 'https://airflow.apache.org'",
          "3186:         class DummyTestOperator(BaseOperator):",
          "3188:             operator_extra_links = (",
          "3189:                 RaiseErrorLink(),",
          "3190:                 NoResponseLink(),",
          "3191:                 FooBarLink(),",
          "3192:                 AirflowLink(),",
          "3193:             )",
          "3195:         self.dag = DAG('dag', start_date=self.default_date)",
          "3196:         self.task = DummyTestOperator(task_id=\"some_dummy_task\", dag=self.dag)",
          "3197:         self.task_2 = Dummy2TestOperator(task_id=\"some_dummy_task_2\", dag=self.dag)",
          "3198:         self.task_3 = Dummy3TestOperator(task_id=\"some_dummy_task_3\", dag=self.dag)",
          "3200:         self.app.dag_bag = mock.MagicMock(**{'get_dag.return_value': self.dag})",
          "3201:         super().setUp()",
          "3202:         self.logout()",
          "3203:         self.login('test_viewer', 'test_viewer')",
          "3205:     def test_extra_links_works(self):",
          "3206:         response = self.client.get(",
          "3207:             \"{}?dag_id={}&task_id={}&execution_date={}&link_name=foo-bar\".format(",
          "3208:                 self.endpoint, self.dag.dag_id, self.task.task_id, self.default_date",
          "3209:             ),",
          "3210:             follow_redirects=True,",
          "3211:         )",
          "3213:         assert response.status_code == 200",
          "3214:         response_str = response.data",
          "3215:         if isinstance(response.data, bytes):",
          "3216:             response_str = response_str.decode()",
          "3217:         assert json.loads(response_str) == {",
          "3218:             'url': 'http://www.example.com/some_dummy_task/foo-bar/2017-01-01T00:00:00+00:00',",
          "3219:             'error': None,",
          "3220:         }",
          "3222:     def test_global_extra_links_works(self):",
          "3223:         response = self.client.get(",
          "3224:             \"{}?dag_id={}&task_id={}&execution_date={}&link_name=github\".format(",
          "3225:                 self.endpoint, self.dag.dag_id, self.task.task_id, self.default_date",
          "3226:             ),",
          "3227:             follow_redirects=True,",
          "3228:         )",
          "3230:         assert response.status_code == 200",
          "3231:         response_str = response.data",
          "3232:         if isinstance(response.data, bytes):",
          "3233:             response_str = response_str.decode()",
          "3234:         assert json.loads(response_str) == {'url': 'https://github.com/apache/airflow', 'error': None}",
          "3236:     def test_extra_link_in_gantt_view(self):",
          "3237:         exec_date = dates.days_ago(2)",
          "3238:         start_date = datetime(2020, 4, 10, 2, 0, 0)",
          "3239:         end_date = exec_date + timedelta(seconds=30)",
          "3241:         with create_session() as session:",
          "3242:             for task in self.dag.tasks:",
          "3243:                 ti = TaskInstance(task=task, execution_date=exec_date, state=\"success\")",
          "3244:                 ti.start_date = start_date",
          "3245:                 ti.end_date = end_date",
          "3246:                 session.add(ti)",
          "3248:         url = f'gantt?dag_id={self.dag.dag_id}&execution_date={exec_date}'",
          "3249:         resp = self.client.get(url, follow_redirects=True)",
          "3251:         self.check_content_in_response('\"extraLinks\":', resp)",
          "3253:         extra_links_grps = re.search(r'extraLinks\\\": \\[(\\\".*?\\\")\\]', resp.get_data(as_text=True))",
          "3254:         extra_links = extra_links_grps.group(0)",
          "3255:         assert 'airflow' in extra_links",
          "3256:         assert 'github' in extra_links",
          "3258:     def test_operator_extra_link_override_global_extra_link(self):",
          "3259:         response = self.client.get(",
          "3260:             \"{}?dag_id={}&task_id={}&execution_date={}&link_name=airflow\".format(",
          "3261:                 self.endpoint, self.dag.dag_id, self.task.task_id, self.default_date",
          "3262:             ),",
          "3263:             follow_redirects=True,",
          "3264:         )",
          "3266:         assert response.status_code == 200",
          "3267:         response_str = response.data",
          "3268:         if isinstance(response.data, bytes):",
          "3269:             response_str = response_str.decode()",
          "3270:         assert json.loads(response_str) == {'url': 'https://airflow.apache.org', 'error': None}",
          "3272:     def test_extra_links_error_raised(self):",
          "3273:         response = self.client.get(",
          "3274:             \"{}?dag_id={}&task_id={}&execution_date={}&link_name=raise_error\".format(",
          "3275:                 self.endpoint, self.dag.dag_id, self.task.task_id, self.default_date",
          "3276:             ),",
          "3277:             follow_redirects=True,",
          "3278:         )",
          "3280:         assert 404 == response.status_code",
          "3281:         response_str = response.data",
          "3282:         if isinstance(response.data, bytes):",
          "3283:             response_str = response_str.decode()",
          "3284:         assert json.loads(response_str) == {'url': None, 'error': 'This is an error'}",
          "3286:     def test_extra_links_no_response(self):",
          "3287:         response = self.client.get(",
          "3288:             \"{}?dag_id={}&task_id={}&execution_date={}&link_name=no_response\".format(",
          "3289:                 self.endpoint, self.dag.dag_id, self.task.task_id, self.default_date",
          "3290:             ),",
          "3291:             follow_redirects=True,",
          "3292:         )",
          "3294:         assert response.status_code == 404",
          "3295:         response_str = response.data",
          "3296:         if isinstance(response.data, bytes):",
          "3297:             response_str = response_str.decode()",
          "3298:         assert json.loads(response_str) == {'url': None, 'error': 'No URL found for no_response'}",
          "3300:     def test_operator_extra_link_override_plugin(self):",
          "3301:         \"\"\"",
          "3302:         This tests checks if Operator Link (AirflowLink) defined in the Dummy2TestOperator",
          "3303:         is overridden by Airflow Plugin (AirflowLink2).",
          "3305:         AirflowLink returns 'https://airflow.apache.org/' link",
          "3306:         AirflowLink2 returns 'https://airflow.apache.org/1.10.5/' link",
          "3307:         \"\"\"",
          "3308:         response = self.client.get(",
          "3309:             \"{}?dag_id={}&task_id={}&execution_date={}&link_name=airflow\".format(",
          "3310:                 self.endpoint, self.dag.dag_id, self.task_2.task_id, self.default_date",
          "3311:             ),",
          "3312:             follow_redirects=True,",
          "3313:         )",
          "3315:         assert response.status_code == 200",
          "3316:         response_str = response.data",
          "3317:         if isinstance(response.data, bytes):",
          "3318:             response_str = response_str.decode()",
          "3319:         assert json.loads(response_str) == {'url': 'https://airflow.apache.org/1.10.5/', 'error': None}",
          "3321:     def test_operator_extra_link_multiple_operators(self):",
          "3322:         \"\"\"",
          "3323:         This tests checks if Operator Link (AirflowLink2) defined in",
          "3324:         Airflow Plugin (AirflowLink2) is attached to all the list of",
          "3325:         operators defined in the AirflowLink2().operators property",
          "3327:         AirflowLink2 returns 'https://airflow.apache.org/1.10.5/' link",
          "3328:         GoogleLink returns 'https://www.google.com'",
          "3329:         \"\"\"",
          "3330:         response = self.client.get(",
          "3331:             \"{}?dag_id={}&task_id={}&execution_date={}&link_name=airflow\".format(",
          "3332:                 self.endpoint, self.dag.dag_id, self.task_2.task_id, self.default_date",
          "3333:             ),",
          "3334:             follow_redirects=True,",
          "3335:         )",
          "3337:         assert response.status_code == 200",
          "3338:         response_str = response.data",
          "3339:         if isinstance(response.data, bytes):",
          "3340:             response_str = response_str.decode()",
          "3341:         assert json.loads(response_str) == {'url': 'https://airflow.apache.org/1.10.5/', 'error': None}",
          "3343:         response = self.client.get(",
          "3344:             \"{}?dag_id={}&task_id={}&execution_date={}&link_name=airflow\".format(",
          "3345:                 self.endpoint, self.dag.dag_id, self.task_3.task_id, self.default_date",
          "3346:             ),",
          "3347:             follow_redirects=True,",
          "3348:         )",
          "3350:         assert response.status_code == 200",
          "3351:         response_str = response.data",
          "3352:         if isinstance(response.data, bytes):",
          "3353:             response_str = response_str.decode()",
          "3354:         assert json.loads(response_str) == {'url': 'https://airflow.apache.org/1.10.5/', 'error': None}",
          "3356:         # Also check that the other Operator Link defined for this operator exists",
          "3357:         response = self.client.get(",
          "3358:             \"{}?dag_id={}&task_id={}&execution_date={}&link_name=google\".format(",
          "3359:                 self.endpoint, self.dag.dag_id, self.task_3.task_id, self.default_date",
          "3360:             ),",
          "3361:             follow_redirects=True,",
          "3362:         )",
          "3364:         assert response.status_code == 200",
          "3365:         response_str = response.data",
          "3366:         if isinstance(response.data, bytes):",
          "3367:             response_str = response_str.decode()",
          "3368:         assert json.loads(response_str) == {'url': 'https://www.google.com', 'error': None}",
          "3371: class TestDagRunModelView(TestBase):",
          "3372:     @classmethod",
          "3373:     def setUpClass(cls):",
          "3374:         super().setUpClass()",
          "3375:         models.DagBag().get_dag(\"example_bash_operator\").sync_to_db(session=cls.session)",
          "3376:         cls.session.commit()",
          "3377:         cls.clear_table(models.DagRun)",
          "3378:         cls.clear_table(models.TaskInstance)",
          "3380:     def tearDown(self):",
          "3381:         self.clear_table(models.DagRun)",
          "3382:         self.clear_table(models.TaskInstance)",
          "3384:     def test_create_dagrun_execution_date_with_timezone_utc(self):",
          "3385:         data = {",
          "3386:             \"state\": \"running\",",
          "3387:             \"dag_id\": \"example_bash_operator\",",
          "3388:             \"execution_date\": \"2018-07-06 05:04:03Z\",",
          "3389:             \"run_id\": \"test_create_dagrun\",",
          "3390:         }",
          "3391:         resp = self.client.post('/dagrun/add', data=data, follow_redirects=True)",
          "3392:         self.check_content_in_response('Added Row', resp)",
          "3394:         dr = self.session.query(models.DagRun).one()",
          "3396:         assert dr.execution_date == timezone.datetime(2018, 7, 6, 5, 4, 3)",
          "3398:     def test_create_dagrun_execution_date_with_timezone_edt(self):",
          "3399:         data = {",
          "3400:             \"state\": \"running\",",
          "3401:             \"dag_id\": \"example_bash_operator\",",
          "3402:             \"execution_date\": \"2018-07-06 05:04:03-04:00\",",
          "3403:             \"run_id\": \"test_create_dagrun\",",
          "3404:         }",
          "3405:         resp = self.client.post('/dagrun/add', data=data, follow_redirects=True)",
          "3406:         self.check_content_in_response('Added Row', resp)",
          "3408:         dr = self.session.query(models.DagRun).one()",
          "3410:         assert dr.execution_date == timezone.datetime(2018, 7, 6, 9, 4, 3)",
          "3412:     def test_create_dagrun_execution_date_with_timezone_pst(self):",
          "3413:         data = {",
          "3414:             \"state\": \"running\",",
          "3415:             \"dag_id\": \"example_bash_operator\",",
          "3416:             \"execution_date\": \"2018-07-06 05:04:03-08:00\",",
          "3417:             \"run_id\": \"test_create_dagrun\",",
          "3418:         }",
          "3419:         resp = self.client.post('/dagrun/add', data=data, follow_redirects=True)",
          "3420:         self.check_content_in_response('Added Row', resp)",
          "3422:         dr = self.session.query(models.DagRun).one()",
          "3424:         assert dr.execution_date == timezone.datetime(2018, 7, 6, 13, 4, 3)",
          "3426:     @conf_vars({(\"core\", \"default_timezone\"): \"America/Toronto\"})",
          "3427:     def test_create_dagrun_execution_date_without_timezone_default_edt(self):",
          "3428:         data = {",
          "3429:             \"state\": \"running\",",
          "3430:             \"dag_id\": \"example_bash_operator\",",
          "3431:             \"execution_date\": \"2018-07-06 05:04:03\",",
          "3432:             \"run_id\": \"test_create_dagrun\",",
          "3433:         }",
          "3434:         resp = self.client.post('/dagrun/add', data=data, follow_redirects=True)",
          "3435:         self.check_content_in_response('Added Row', resp)",
          "3437:         dr = self.session.query(models.DagRun).one()",
          "3439:         assert dr.execution_date == timezone.datetime(2018, 7, 6, 9, 4, 3)",
          "3441:     def test_create_dagrun_execution_date_without_timezone_default_utc(self):",
          "3442:         data = {",
          "3443:             \"state\": \"running\",",
          "3444:             \"dag_id\": \"example_bash_operator\",",
          "3445:             \"execution_date\": \"2018-07-06 05:04:03\",",
          "3446:             \"run_id\": \"test_create_dagrun\",",
          "3447:         }",
          "3448:         resp = self.client.post('/dagrun/add', data=data, follow_redirects=True)",
          "3449:         self.check_content_in_response('Added Row', resp)",
          "3451:         dr = self.session.query(models.DagRun).one()",
          "3453:         assert dr.execution_date == dt(2018, 7, 6, 5, 4, 3, tzinfo=timezone.TIMEZONE)",
          "3455:     def test_create_dagrun_valid_conf(self):",
          "3456:         conf_value = dict(Valid=True)",
          "3457:         data = {",
          "3458:             \"state\": \"running\",",
          "3459:             \"dag_id\": \"example_bash_operator\",",
          "3460:             \"execution_date\": \"2018-07-06 05:05:03-02:00\",",
          "3461:             \"run_id\": \"test_create_dagrun_valid_conf\",",
          "3462:             \"conf\": json.dumps(conf_value),",
          "3463:         }",
          "3465:         resp = self.client.post('/dagrun/add', data=data, follow_redirects=True)",
          "3466:         self.check_content_in_response('Added Row', resp)",
          "3467:         dr = self.session.query(models.DagRun).one()",
          "3468:         assert dr.conf == conf_value",
          "3470:     def test_create_dagrun_invalid_conf(self):",
          "3471:         data = {",
          "3472:             \"state\": \"running\",",
          "3473:             \"dag_id\": \"example_bash_operator\",",
          "3474:             \"execution_date\": \"2018-07-06 05:06:03\",",
          "3475:             \"run_id\": \"test_create_dagrun_invalid_conf\",",
          "3476:             \"conf\": \"INVALID: [JSON\",",
          "3477:         }",
          "3479:         resp = self.client.post('/dagrun/add', data=data, follow_redirects=True)",
          "3480:         self.check_content_in_response('JSON Validation Error:', resp)",
          "3481:         dr = self.session.query(models.DagRun).all()",
          "3482:         assert not dr",
          "3484:     def test_list_dagrun_includes_conf(self):",
          "3485:         data = {",
          "3486:             \"state\": \"running\",",
          "3487:             \"dag_id\": \"example_bash_operator\",",
          "3488:             \"execution_date\": \"2018-07-06 05:06:03\",",
          "3489:             \"run_id\": \"test_list_dagrun_includes_conf\",",
          "3490:             \"conf\": '{\"include\": \"me\"}',",
          "3491:         }",
          "3492:         self.client.post('/dagrun/add', data=data, follow_redirects=True)",
          "3493:         dr = self.session.query(models.DagRun).one()",
          "3494:         assert dr.execution_date == timezone.convert_to_utc(datetime(2018, 7, 6, 5, 6, 3))",
          "3495:         assert dr.conf == {\"include\": \"me\"}",
          "3497:         resp = self.client.get('/dagrun/list', follow_redirects=True)",
          "3498:         self.check_content_in_response(\"{&#34;include&#34;: &#34;me&#34;}\", resp)",
          "3500:     def test_clear_dag_runs_action(self):",
          "3501:         dag = models.DagBag().get_dag(\"example_bash_operator\")",
          "3502:         task0 = dag.get_task(\"runme_0\")",
          "3503:         task1 = dag.get_task(\"runme_1\")",
          "3504:         execution_date = datetime(2016, 1, 9)",
          "3505:         tis = [",
          "3506:             models.TaskInstance(task0, execution_date, state=\"success\"),",
          "3507:             models.TaskInstance(task1, execution_date, state=\"failed\"),",
          "3508:         ]",
          "3509:         self.session.bulk_save_objects(tis)",
          "3510:         dr = dag.create_dagrun(",
          "3511:             state=\"running\",",
          "3512:             execution_date=execution_date,",
          "3513:             run_id=\"test_clear_dag_runs_action\",",
          "3514:             session=self.session,",
          "3515:         )",
          "3517:         data = {\"action\": \"clear\", \"rowid\": [dr.id]}",
          "3518:         resp = self.client.post(\"/dagrun/action_post\", data=data, follow_redirects=True)",
          "3519:         self.check_content_in_response(\"1 dag runs and 2 task instances were cleared\", resp)",
          "3520:         assert [ti.state for ti in self.session.query(models.TaskInstance).all()] == [None, None]",
          "3522:     def test_clear_dag_runs_action_fails(self):",
          "3523:         data = {\"action\": \"clear\", \"rowid\": [\"0\"]}",
          "3524:         resp = self.client.post(\"/dagrun/action_post\", data=data, follow_redirects=True)",
          "3525:         self.check_content_in_response(\"Failed to clear state\", resp)",
          "3528: class TestDecorators(TestBase):",
          "3529:     EXAMPLE_DAG_DEFAULT_DATE = dates.days_ago(2)",
          "3531:     @classmethod",
          "3532:     def setUpClass(cls):",
          "3533:         super().setUpClass()",
          "3534:         models.DagBag(include_examples=True, read_dags_from_db=False).sync_to_db()",
          "3535:         dagbag = models.DagBag(include_examples=True, read_dags_from_db=True)",
          "3536:         cls.bash_dag = dagbag.get_dag('example_bash_operator')",
          "3537:         cls.sub_dag = dagbag.get_dag('example_subdag_operator')",
          "3538:         cls.xcom_dag = dagbag.get_dag('example_xcom')",
          "3540:     def setUp(self):",
          "3541:         super().setUp()",
          "3542:         self.logout()",
          "3543:         self.login()",
          "3544:         clear_db_runs()",
          "3545:         self.prepare_dagruns()",
          "3547:     def prepare_dagruns(self):",
          "3548:         self.bash_dagrun = self.bash_dag.create_dagrun(",
          "3549:             run_type=DagRunType.SCHEDULED,",
          "3550:             execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,",
          "3551:             start_date=timezone.utcnow(),",
          "3552:             state=State.RUNNING,",
          "3553:         )",
          "3555:         self.sub_dagrun = self.sub_dag.create_dagrun(",
          "3556:             run_type=DagRunType.SCHEDULED,",
          "3557:             execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,",
          "3558:             start_date=timezone.utcnow(),",
          "3559:             state=State.RUNNING,",
          "3560:         )",
          "3562:         self.xcom_dagrun = self.xcom_dag.create_dagrun(",
          "3563:             run_type=DagRunType.SCHEDULED,",
          "3564:             execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,",
          "3565:             start_date=timezone.utcnow(),",
          "3566:             state=State.RUNNING,",
          "3567:         )",
          "3569:     def check_last_log(self, dag_id, event, execution_date=None):",
          "3570:         from airflow.models import Log",
          "3572:         qry = self.session.query(Log.dag_id, Log.task_id, Log.event, Log.execution_date, Log.owner, Log.extra)",
          "3573:         qry = qry.filter(Log.dag_id == dag_id, Log.event == event)",
          "3574:         if execution_date:",
          "3575:             qry = qry.filter(Log.execution_date == execution_date)",
          "3576:         logs = qry.order_by(Log.dttm.desc()).limit(5).all()",
          "3577:         assert len(logs) >= 1",
          "3578:         assert logs[0].extra",
          "3580:     def test_action_logging_get(self):",
          "3581:         url = 'graph?dag_id=example_bash_operator&execution_date={}'.format(",
          "3582:             self.percent_encode(self.EXAMPLE_DAG_DEFAULT_DATE)",
          "3583:         )",
          "3584:         resp = self.client.get(url, follow_redirects=True)",
          "3585:         self.check_content_in_response('runme_1', resp)",
          "3587:         # In mysql backend, this commit() is needed to write down the logs",
          "3588:         self.session.commit()",
          "3589:         self.check_last_log(",
          "3590:             \"example_bash_operator\", event=\"graph\", execution_date=self.EXAMPLE_DAG_DEFAULT_DATE",
          "3591:         )",
          "3593:     def test_action_logging_post(self):",
          "3594:         form = dict(",
          "3595:             task_id=\"runme_1\",",
          "3596:             dag_id=\"example_bash_operator\",",
          "3597:             execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,",
          "3598:             upstream=\"false\",",
          "3599:             downstream=\"false\",",
          "3600:             future=\"false\",",
          "3601:             past=\"false\",",
          "3602:             only_failed=\"false\",",
          "3603:         )",
          "3604:         resp = self.client.post(\"clear\", data=form)",
          "3605:         self.check_content_in_response(['example_bash_operator', 'Wait a minute'], resp)",
          "3606:         # In mysql backend, this commit() is needed to write down the logs",
          "3607:         self.session.commit()",
          "3608:         self.check_last_log(",
          "3609:             \"example_bash_operator\", event=\"clear\", execution_date=self.EXAMPLE_DAG_DEFAULT_DATE",
          "3610:         )",
          "3613: class TestHelperFunctions(TestBase):",
          "3614:     @parameterized.expand(",
          "3615:         [",
          "3616:             (\"\", \"/home\"),",
          "3617:             (\"http://google.com\", \"/home\"),",
          "3618:             (\"36539'%3balert(1)%2f%2f166\", \"/home\"),",
          "3619:             (",
          "3620:                 \"http://localhost:8080/trigger?dag_id=test&origin=36539%27%3balert(1)%2f%2f166&abc=2\",",
          "3621:                 \"/home\",",
          "3622:             ),",
          "3623:             (",
          "3624:                 \"http://localhost:8080/trigger?dag_id=test_dag&origin=%2Ftree%3Fdag_id%test_dag';alert(33)//\",",
          "3625:                 \"/home\",",
          "3626:             ),",
          "3627:             (",
          "3628:                 \"http://localhost:8080/trigger?dag_id=test_dag&origin=%2Ftree%3Fdag_id%3Dtest_dag\",",
          "3629:                 \"http://localhost:8080/trigger?dag_id=test_dag&origin=%2Ftree%3Fdag_id%3Dtest_dag\",",
          "3630:             ),",
          "3631:         ]",
          "3632:     )",
          "3633:     @mock.patch(\"airflow.www.views.url_for\")",
          "3634:     def test_get_safe_url(self, test_url, expected_url, mock_url_for):",
          "3635:         mock_url_for.return_value = \"/home\"",
          "3636:         with self.app.test_request_context(base_url=\"http://localhost:8080\"):",
          "3637:             assert get_safe_url(test_url) == expected_url",
          "3639:     @parameterized.expand(",
          "3640:         [",
          "3641:             (0.12345, 0.123),",
          "3642:             (0.12355, 0.124),",
          "3643:             (3.12, 3.12),",
          "3644:             (9.99999, 10.0),",
          "3645:             (10.01232, 10),",
          "3646:         ]",
          "3647:     )",
          "3648:     def test_truncate_task_duration(self, test_duration, expected_duration):",
          "3649:         assert truncate_task_duration(test_duration) == expected_duration",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "tests/www/views/conftest.py||tests/www/views/conftest.py": [
          "File: tests/www/views/conftest.py -> tests/www/views/conftest.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: #",
          "2: # Licensed to the Apache Software Foundation (ASF) under one",
          "3: # or more contributor license agreements.  See the NOTICE file",
          "4: # distributed with this work for additional information",
          "5: # regarding copyright ownership.  The ASF licenses this file",
          "6: # to you under the Apache License, Version 2.0 (the",
          "7: # \"License\"); you may not use this file except in compliance",
          "8: # with the License.  You may obtain a copy of the License at",
          "9: #",
          "10: #   http://www.apache.org/licenses/LICENSE-2.0",
          "11: #",
          "12: # Unless required by applicable law or agreed to in writing,",
          "13: # software distributed under the License is distributed on an",
          "14: # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
          "15: # KIND, either express or implied.  See the License for the",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "18: from contextlib import contextmanager",
          "19: from typing import Any, Dict, Generator, List, NamedTuple",
          "21: import flask",
          "22: import jinja2",
          "23: import pytest",
          "25: from airflow import settings",
          "26: from airflow.models import DagBag",
          "27: from airflow.www.app import create_app",
          "28: from tests.test_utils.api_connexion_utils import create_user, delete_roles",
          "29: from tests.test_utils.decorators import dont_initialize_flask_app_submodules",
          "30: from tests.test_utils.www import client_with_login",
          "33: @pytest.fixture(autouse=True, scope=\"module\")",
          "34: def session():",
          "35:     settings.configure_orm()",
          "36:     yield settings.Session",
          "39: @pytest.fixture(autouse=True, scope=\"module\")",
          "40: def examples_dag_bag(session):",
          "41:     DagBag(include_examples=True).sync_to_db()",
          "42:     dag_bag = DagBag(include_examples=True, read_dags_from_db=True)",
          "43:     session.commit()",
          "44:     yield dag_bag",
          "47: @pytest.fixture(scope=\"module\")",
          "48: def app(examples_dag_bag):",
          "49:     @dont_initialize_flask_app_submodules(",
          "50:         skip_all_except=[",
          "51:             \"init_api_connexion\",",
          "52:             \"init_appbuilder\",",
          "53:             \"init_appbuilder_links\",",
          "54:             \"init_appbuilder_views\",",
          "55:             \"init_flash_views\",",
          "56:             \"init_jinja_globals\",",
          "57:             \"init_plugins\",",
          "58:         ]",
          "59:     )",
          "60:     def factory():",
          "61:         return create_app(testing=True)",
          "63:     app = factory()",
          "64:     app.config[\"WTF_CSRF_ENABLED\"] = False",
          "65:     app.dag_bag = examples_dag_bag",
          "66:     app.jinja_env.undefined = jinja2.StrictUndefined",
          "68:     security_manager = app.appbuilder.sm  # pylint: disable=no-member",
          "69:     if not security_manager.find_user(username='test'):",
          "70:         security_manager.add_user(",
          "71:             username='test',",
          "72:             first_name='test',",
          "73:             last_name='test',",
          "74:             email='test@fab.org',",
          "75:             role=security_manager.find_role('Admin'),",
          "76:             password='test',",
          "77:         )",
          "78:     if not security_manager.find_user(username='test_user'):",
          "79:         security_manager.add_user(",
          "80:             username='test_user',",
          "81:             first_name='test_user',",
          "82:             last_name='test_user',",
          "83:             email='test_user@fab.org',",
          "84:             role=security_manager.find_role('User'),",
          "85:             password='test_user',",
          "86:         )",
          "87:     if not security_manager.find_user(username='test_viewer'):",
          "88:         security_manager.add_user(",
          "89:             username='test_viewer',",
          "90:             first_name='test_viewer',",
          "91:             last_name='test_viewer',",
          "92:             email='test_viewer@fab.org',",
          "93:             role=security_manager.find_role('Viewer'),",
          "94:             password='test_viewer',",
          "95:         )",
          "97:     yield app",
          "99:     delete_roles(app)",
          "102: @pytest.fixture()",
          "103: def admin_client(app):",
          "104:     return client_with_login(app, username=\"test\", password=\"test\")",
          "107: @pytest.fixture()",
          "108: def viewer_client(app):",
          "109:     return client_with_login(app, username=\"test_viewer\", password=\"test_viewer\")",
          "112: @pytest.fixture(scope=\"module\")",
          "113: def client_factory(app):",
          "114:     def factory(name, role_name, permissions):",
          "115:         create_user(app, name, role_name, permissions)",
          "116:         client = app.test_client()",
          "117:         resp = client.post(\"/login/\", data={\"username\": name, \"password\": name})",
          "118:         assert resp.status_code == 302",
          "119:         return client",
          "121:     return factory",
          "124: class _TemplateWithContext(NamedTuple):",
          "125:     template: jinja2.environment.Template",
          "126:     context: Dict[str, Any]",
          "128:     @property",
          "129:     def name(self):",
          "130:         return self.template.name",
          "132:     @property",
          "133:     def local_context(self):",
          "134:         \"\"\"Returns context without global arguments\"\"\"",
          "135:         result = self.context.copy()",
          "136:         keys_to_delete = [",
          "137:             # flask.templating._default_template_ctx_processor",
          "138:             'g',",
          "139:             'request',",
          "140:             'session',",
          "141:             # flask_wtf.csrf.CSRFProtect.init_app",
          "142:             'csrf_token',",
          "143:             # flask_login.utils._user_context_processor",
          "144:             'current_user',",
          "145:             # flask_appbuilder.baseviews.BaseView.render_template",
          "146:             'appbuilder',",
          "147:             'base_template',",
          "148:             # airflow.www.app.py.create_app (inner method - jinja_globals)",
          "149:             'server_timezone',",
          "150:             'default_ui_timezone',",
          "151:             'hostname',",
          "152:             'navbar_color',",
          "153:             'log_fetch_delay_sec',",
          "154:             'log_auto_tailing_offset',",
          "155:             'log_animation_speed',",
          "156:             'state_color_mapping',",
          "157:             'airflow_version',",
          "158:             'git_version',",
          "159:             'k8s_or_k8scelery_executor',",
          "160:             # airflow.www.static_config.configure_manifest_files",
          "161:             'url_for_asset',",
          "162:             # airflow.www.views.AirflowBaseView.render_template",
          "163:             'scheduler_job',",
          "164:             # airflow.www.views.AirflowBaseView.extra_args",
          "165:             'macros',",
          "166:         ]",
          "167:         for key in keys_to_delete:",
          "168:             del result[key]",
          "170:         return result",
          "173: @pytest.fixture(scope=\"module\")",
          "174: def capture_templates(app):",
          "175:     @contextmanager",
          "176:     def manager() -> Generator[List[_TemplateWithContext], None, None]:",
          "177:         recorded = []",
          "179:         def record(sender, template, context, **extra):  # pylint: disable=unused-argument",
          "180:             recorded.append(_TemplateWithContext(template, context))",
          "182:         flask.template_rendered.connect(record, app)  # type: ignore",
          "183:         try:",
          "184:             yield recorded",
          "185:         finally:",
          "186:             flask.template_rendered.disconnect(record, app)  # type: ignore",
          "188:         assert recorded, \"Failed to catch the templates\"",
          "190:     return manager",
          "",
          "---------------"
        ],
        "tests/www/views/test_views.py||tests/www/views/test_views.py": [
          "File: tests/www/views/test_views.py -> tests/www/views/test_views.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: #",
          "2: # Licensed to the Apache Software Foundation (ASF) under one",
          "3: # or more contributor license agreements.  See the NOTICE file",
          "4: # distributed with this work for additional information",
          "5: # regarding copyright ownership.  The ASF licenses this file",
          "6: # to you under the Apache License, Version 2.0 (the",
          "7: # \"License\"); you may not use this file except in compliance",
          "8: # with the License.  You may obtain a copy of the License at",
          "9: #",
          "10: #   http://www.apache.org/licenses/LICENSE-2.0",
          "11: #",
          "12: # Unless required by applicable law or agreed to in writing,",
          "13: # software distributed under the License is distributed on an",
          "14: # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
          "15: # KIND, either express or implied.  See the License for the",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "18: from unittest import mock",
          "20: import pytest",
          "22: from airflow.plugins_manager import AirflowPlugin, EntryPointSource",
          "23: from airflow.www.views import get_safe_url, truncate_task_duration",
          "24: from tests.test_utils.config import conf_vars",
          "25: from tests.test_utils.mock_plugins import mock_plugin_manager",
          "26: from tests.test_utils.www import check_content_in_response, check_content_not_in_response",
          "29: def test_configuration_do_not_expose_config(admin_client):",
          "30:     with conf_vars({('webserver', 'expose_config'): 'False'}):",
          "31:         resp = admin_client.get('configuration', follow_redirects=True)",
          "32:     check_content_in_response(",
          "33:         [",
          "34:             'Airflow Configuration',",
          "35:             '# Your Airflow administrator chose not to expose the configuration, '",
          "36:             'most likely for security reasons.',",
          "37:         ],",
          "38:         resp,",
          "39:     )",
          "42: def test_configuration_expose_config(admin_client):",
          "43:     with conf_vars({('webserver', 'expose_config'): 'True'}):",
          "44:         resp = admin_client.get('configuration', follow_redirects=True)",
          "45:     check_content_in_response(['Airflow Configuration', 'Running Configuration'], resp)",
          "48: def test_redoc_should_render_template(capture_templates, admin_client):",
          "49:     with capture_templates() as templates:",
          "50:         resp = admin_client.get('redoc')",
          "51:         check_content_in_response('Redoc', resp)",
          "53:     assert len(templates) == 1",
          "54:     assert templates[0].name == 'airflow/redoc.html'",
          "55:     assert templates[0].local_context == {'openapi_spec_url': '/api/v1/openapi.yaml'}",
          "58: def test_plugin_should_list_on_page_with_details(admin_client):",
          "59:     resp = admin_client.get('/plugin')",
          "60:     check_content_in_response(\"test_plugin\", resp)",
          "61:     check_content_in_response(\"Airflow Plugins\", resp)",
          "62:     check_content_in_response(\"source\", resp)",
          "63:     check_content_in_response(\"<em>$PLUGINS_FOLDER/</em>test_plugin.py\", resp)",
          "66: def test_plugin_should_list_entrypoint_on_page_with_details(admin_client):",
          "67:     mock_plugin = AirflowPlugin()",
          "68:     mock_plugin.name = \"test_plugin\"",
          "69:     mock_plugin.source = EntryPointSource(",
          "70:         mock.Mock(), mock.Mock(version='1.0.0', metadata={'name': 'test-entrypoint-testpluginview'})",
          "71:     )",
          "72:     with mock_plugin_manager(plugins=[mock_plugin]):",
          "73:         resp = admin_client.get('/plugin')",
          "75:     check_content_in_response(\"test_plugin\", resp)",
          "76:     check_content_in_response(\"Airflow Plugins\", resp)",
          "77:     check_content_in_response(\"source\", resp)",
          "78:     check_content_in_response(\"<em>test-entrypoint-testpluginview==1.0.0:</em> <Mock id=\", resp)",
          "81: def test_plugin_endpoint_should_not_be_unauthenticated(app):",
          "82:     resp = app.test_client().get('/plugin', follow_redirects=True)",
          "83:     check_content_not_in_response(\"test_plugin\", resp)",
          "84:     check_content_in_response(\"Sign In - Airflow\", resp)",
          "87: @pytest.mark.parametrize(",
          "88:     \"url, content\",",
          "89:     [",
          "90:         (",
          "91:             \"/taskinstance/list/?_flt_0_execution_date=2018-10-09+22:44:31\",",
          "92:             \"List Task Instance\",",
          "93:         ),",
          "94:         (",
          "95:             \"/taskreschedule/list/?_flt_0_execution_date=2018-10-09+22:44:31\",",
          "96:             \"List Task Reschedule\",",
          "97:         ),",
          "98:     ],",
          "99:     ids=[\"instance\", \"reschedule\"],",
          "100: )",
          "101: def test_task_start_date_filter(admin_client, url, content):",
          "102:     resp = admin_client.get(url)",
          "103:     # We aren't checking the logic of the date filter itself (that is built",
          "104:     # in to FAB) but simply that our UTC conversion was run - i.e. it",
          "105:     # doesn't blow up!",
          "106:     check_content_in_response(content, resp)",
          "109: @pytest.mark.parametrize(",
          "110:     \"test_url, expected_url\",",
          "111:     [",
          "112:         (\"\", \"/home\"),",
          "113:         (\"http://google.com\", \"/home\"),",
          "114:         (\"36539'%3balert(1)%2f%2f166\", \"/home\"),",
          "115:         (",
          "116:             \"http://localhost:8080/trigger?dag_id=test&origin=36539%27%3balert(1)%2f%2f166&abc=2\",",
          "117:             \"/home\",",
          "118:         ),",
          "119:         (",
          "120:             \"http://localhost:8080/trigger?dag_id=test_dag&origin=%2Ftree%3Fdag_id%test_dag';alert(33)//\",",
          "121:             \"/home\",",
          "122:         ),",
          "123:         (",
          "124:             \"http://localhost:8080/trigger?dag_id=test_dag&origin=%2Ftree%3Fdag_id%3Dtest_dag\",",
          "125:             \"http://localhost:8080/trigger?dag_id=test_dag&origin=%2Ftree%3Fdag_id%3Dtest_dag\",",
          "126:         ),",
          "127:     ],",
          "128: )",
          "129: @mock.patch(\"airflow.www.views.url_for\")",
          "130: def test_get_safe_url(mock_url_for, app, test_url, expected_url):",
          "131:     mock_url_for.return_value = \"/home\"",
          "132:     with app.test_request_context(base_url=\"http://localhost:8080\"):",
          "133:         assert get_safe_url(test_url) == expected_url",
          "136: @pytest.mark.parametrize(",
          "137:     \"test_duration, expected_duration\",",
          "138:     [",
          "139:         (0.12345, 0.123),",
          "140:         (0.12355, 0.124),",
          "141:         (3.12, 3.12),",
          "142:         (9.99999, 10.0),",
          "143:         (10.01232, 10),",
          "144:     ],",
          "145: )",
          "146: def test_truncate_task_duration(test_duration, expected_duration):",
          "147:     assert truncate_task_duration(test_duration) == expected_duration",
          "",
          "---------------"
        ],
        "tests/www/views/test_views_connection.py||tests/www/views/test_views_connection.py": [
          "File: tests/www/views/test_views_connection.py -> tests/www/views/test_views_connection.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: #",
          "2: # Licensed to the Apache Software Foundation (ASF) under one",
          "3: # or more contributor license agreements.  See the NOTICE file",
          "4: # distributed with this work for additional information",
          "5: # regarding copyright ownership.  The ASF licenses this file",
          "6: # to you under the Apache License, Version 2.0 (the",
          "7: # \"License\"); you may not use this file except in compliance",
          "8: # with the License.  You may obtain a copy of the License at",
          "9: #",
          "10: #   http://www.apache.org/licenses/LICENSE-2.0",
          "11: #",
          "12: # Unless required by applicable law or agreed to in writing,",
          "13: # software distributed under the License is distributed on an",
          "14: # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
          "15: # KIND, either express or implied.  See the License for the",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "18: from unittest import mock",
          "20: import pytest",
          "22: from airflow.models import Connection",
          "23: from airflow.utils.session import create_session",
          "24: from airflow.www.extensions import init_views",
          "25: from airflow.www.views import ConnectionModelView",
          "26: from tests.test_utils.www import check_content_in_response",
          "28: CONNECTION = {",
          "29:     'conn_id': 'test_conn',",
          "30:     'conn_type': 'http',",
          "31:     'description': 'description',",
          "32:     'host': 'localhost',",
          "33:     'port': 8080,",
          "34:     'username': 'root',",
          "35:     'password': 'admin',",
          "36: }",
          "39: @pytest.fixture(autouse=True)",
          "40: def clear_connections():",
          "41:     with create_session() as session:",
          "42:         session.query(Connection).delete()",
          "45: def test_create_connection(admin_client):",
          "46:     init_views.init_connection_form()",
          "47:     resp = admin_client.post('/connection/add', data=CONNECTION, follow_redirects=True)",
          "48:     check_content_in_response('Added Row', resp)",
          "51: def test_prefill_form_null_extra():",
          "52:     mock_form = mock.Mock()",
          "53:     mock_form.data = {\"conn_id\": \"test\", \"extra\": None}",
          "55:     cmv = ConnectionModelView()",
          "56:     cmv.prefill_form(form=mock_form, pk=1)",
          "",
          "---------------"
        ],
        "tests/www/views/test_views_dagrun.py||tests/www/views/test_views_dagrun.py": [
          "File: tests/www/views/test_views_dagrun.py -> tests/www/views/test_views_dagrun.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: #",
          "2: # Licensed to the Apache Software Foundation (ASF) under one",
          "3: # or more contributor license agreements.  See the NOTICE file",
          "4: # distributed with this work for additional information",
          "5: # regarding copyright ownership.  The ASF licenses this file",
          "6: # to you under the Apache License, Version 2.0 (the",
          "7: # \"License\"); you may not use this file except in compliance",
          "8: # with the License.  You may obtain a copy of the License at",
          "9: #",
          "10: #   http://www.apache.org/licenses/LICENSE-2.0",
          "11: #",
          "12: # Unless required by applicable law or agreed to in writing,",
          "13: # software distributed under the License is distributed on an",
          "14: # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
          "15: # KIND, either express or implied.  See the License for the",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "18: import json",
          "20: import pytest",
          "22: from airflow.models import DagBag, DagRun, TaskInstance",
          "23: from airflow.utils import timezone",
          "24: from airflow.utils.session import create_session",
          "25: from tests.test_utils.config import conf_vars",
          "26: from tests.test_utils.www import check_content_in_response",
          "29: @pytest.fixture(scope=\"module\", autouse=True)",
          "30: def init_blank_dagrun():",
          "31:     \"\"\"Make sure there are no runs before we test anything.",
          "33:     This really shouldn't be needed, but tests elsewhere leave the db dirty.",
          "34:     \"\"\"",
          "35:     with create_session() as session:",
          "36:         session.query(DagRun).delete()",
          "37:         session.query(TaskInstance).delete()",
          "40: @pytest.fixture(autouse=True)",
          "41: def reset_dagrun():",
          "42:     yield",
          "43:     with create_session() as session:",
          "44:         session.query(DagRun).delete()",
          "45:         session.query(TaskInstance).delete()",
          "48: @pytest.mark.parametrize(",
          "49:     \"post_date, expected\",",
          "50:     [",
          "51:         (\"2018-07-06 05:04:03Z\", timezone.datetime(2018, 7, 6, 5, 4, 3)),",
          "52:         (\"2018-07-06 05:04:03-04:00\", timezone.datetime(2018, 7, 6, 9, 4, 3)),",
          "53:         (\"2018-07-06 05:04:03-08:00\", timezone.datetime(2018, 7, 6, 13, 4, 3)),",
          "54:         (\"2018-07-06 05:04:03\", timezone.datetime(2018, 7, 6, 5, 4, 3)),",
          "55:     ],",
          "56:     ids=[\"UTC\", \"EDT\", \"PST\", \"naive\"],",
          "57: )",
          "58: def test_create_dagrun(session, admin_client, post_date, expected):",
          "59:     data = {",
          "60:         \"state\": \"running\",",
          "61:         \"dag_id\": \"example_bash_operator\",",
          "62:         \"execution_date\": post_date,",
          "63:         \"run_id\": \"test_create_dagrun\",",
          "64:     }",
          "65:     resp = admin_client.post('/dagrun/add', data=data, follow_redirects=True)",
          "66:     check_content_in_response('Added Row', resp)",
          "68:     dr = session.query(DagRun).one()",
          "70:     assert dr.execution_date == expected",
          "73: @conf_vars({(\"core\", \"default_timezone\"): \"America/Toronto\"})",
          "74: def test_create_dagrun_without_timezone_default(session, admin_client):",
          "75:     data = {",
          "76:         \"state\": \"running\",",
          "77:         \"dag_id\": \"example_bash_operator\",",
          "78:         \"execution_date\": \"2018-07-06 05:04:03\",",
          "79:         \"run_id\": \"test_create_dagrun\",",
          "80:     }",
          "81:     resp = admin_client.post('/dagrun/add', data=data, follow_redirects=True)",
          "82:     check_content_in_response('Added Row', resp)",
          "84:     dr = session.query(DagRun).one()",
          "86:     assert dr.execution_date == timezone.datetime(2018, 7, 6, 9, 4, 3)",
          "89: def test_create_dagrun_valid_conf(session, admin_client):",
          "90:     conf_value = dict(Valid=True)",
          "91:     data = {",
          "92:         \"state\": \"running\",",
          "93:         \"dag_id\": \"example_bash_operator\",",
          "94:         \"execution_date\": \"2018-07-06 05:05:03-02:00\",",
          "95:         \"run_id\": \"test_create_dagrun_valid_conf\",",
          "96:         \"conf\": json.dumps(conf_value),",
          "97:     }",
          "99:     resp = admin_client.post('/dagrun/add', data=data, follow_redirects=True)",
          "100:     check_content_in_response('Added Row', resp)",
          "101:     dr = session.query(DagRun).one()",
          "102:     assert dr.conf == conf_value",
          "105: def test_create_dagrun_invalid_conf(session, admin_client):",
          "106:     data = {",
          "107:         \"state\": \"running\",",
          "108:         \"dag_id\": \"example_bash_operator\",",
          "109:         \"execution_date\": \"2018-07-06 05:06:03\",",
          "110:         \"run_id\": \"test_create_dagrun_invalid_conf\",",
          "111:         \"conf\": \"INVALID: [JSON\",",
          "112:     }",
          "114:     resp = admin_client.post('/dagrun/add', data=data, follow_redirects=True)",
          "115:     check_content_in_response('JSON Validation Error:', resp)",
          "116:     dr = session.query(DagRun).all()",
          "117:     assert not dr",
          "120: def test_list_dagrun_includes_conf(session, admin_client):",
          "121:     data = {",
          "122:         \"state\": \"running\",",
          "123:         \"dag_id\": \"example_bash_operator\",",
          "124:         \"execution_date\": \"2018-07-06 05:06:03\",",
          "125:         \"run_id\": \"test_list_dagrun_includes_conf\",",
          "126:         \"conf\": '{\"include\": \"me\"}',",
          "127:     }",
          "128:     admin_client.post('/dagrun/add', data=data, follow_redirects=True)",
          "129:     dr = session.query(DagRun).one()",
          "131:     expect_date = timezone.convert_to_utc(timezone.datetime(2018, 7, 6, 5, 6, 3))",
          "132:     assert dr.execution_date == expect_date",
          "133:     assert dr.conf == {\"include\": \"me\"}",
          "135:     resp = admin_client.get('/dagrun/list', follow_redirects=True)",
          "136:     check_content_in_response(\"{&#34;include&#34;: &#34;me&#34;}\", resp)",
          "139: def test_clear_dag_runs_action(session, admin_client):",
          "140:     dag = DagBag().get_dag(\"example_bash_operator\")",
          "141:     task0 = dag.get_task(\"runme_0\")",
          "142:     task1 = dag.get_task(\"runme_1\")",
          "143:     execution_date = timezone.datetime(2016, 1, 9)",
          "144:     tis = [",
          "145:         TaskInstance(task0, execution_date, state=\"success\"),",
          "146:         TaskInstance(task1, execution_date, state=\"failed\"),",
          "147:     ]",
          "148:     session.bulk_save_objects(tis)",
          "149:     dr = dag.create_dagrun(",
          "150:         state=\"running\",",
          "151:         execution_date=execution_date,",
          "152:         run_id=\"test_clear_dag_runs_action\",",
          "153:         session=session,",
          "154:     )",
          "156:     data = {\"action\": \"clear\", \"rowid\": [dr.id]}",
          "157:     resp = admin_client.post(\"/dagrun/action_post\", data=data, follow_redirects=True)",
          "158:     check_content_in_response(\"1 dag runs and 2 task instances were cleared\", resp)",
          "159:     assert [ti.state for ti in session.query(TaskInstance).all()] == [None, None]",
          "162: def test_clear_dag_runs_action_fails(admin_client):",
          "163:     data = {\"action\": \"clear\", \"rowid\": [\"0\"]}",
          "164:     resp = admin_client.post(\"/dagrun/action_post\", data=data, follow_redirects=True)",
          "165:     check_content_in_response(\"Failed to clear state\", resp)",
          "",
          "---------------"
        ],
        "tests/www/views/test_views_decorators.py||tests/www/views/test_views_decorators.py": [
          "File: tests/www/views/test_views_decorators.py -> tests/www/views/test_views_decorators.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: #",
          "2: # Licensed to the Apache Software Foundation (ASF) under one",
          "3: # or more contributor license agreements.  See the NOTICE file",
          "4: # distributed with this work for additional information",
          "5: # regarding copyright ownership.  The ASF licenses this file",
          "6: # to you under the Apache License, Version 2.0 (the",
          "7: # \"License\"); you may not use this file except in compliance",
          "8: # with the License.  You may obtain a copy of the License at",
          "9: #",
          "10: #   http://www.apache.org/licenses/LICENSE-2.0",
          "11: #",
          "12: # Unless required by applicable law or agreed to in writing,",
          "13: # software distributed under the License is distributed on an",
          "14: # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
          "15: # KIND, either express or implied.  See the License for the",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "18: from urllib.parse import quote_plus",
          "20: import pytest",
          "22: from airflow.models import DagBag, Log",
          "23: from airflow.utils import dates, timezone",
          "24: from airflow.utils.state import State",
          "25: from airflow.utils.types import DagRunType",
          "26: from tests.test_utils.db import clear_db_runs",
          "27: from tests.test_utils.www import check_content_in_response",
          "29: EXAMPLE_DAG_DEFAULT_DATE = dates.days_ago(2)",
          "32: @pytest.fixture(scope=\"module\")",
          "33: def dagbag():",
          "34:     DagBag(include_examples=True, read_dags_from_db=False).sync_to_db()",
          "35:     return DagBag(include_examples=True, read_dags_from_db=True)",
          "38: @pytest.fixture(scope=\"module\")",
          "39: def bash_dag(dagbag):",
          "40:     return dagbag.get_dag('example_bash_operator')",
          "43: @pytest.fixture(scope=\"module\")",
          "44: def sub_dag(dagbag):",
          "45:     return dagbag.get_dag('example_subdag_operator')",
          "48: @pytest.fixture(scope=\"module\")",
          "49: def xcom_dag(dagbag):",
          "50:     return dagbag.get_dag('example_xcom')",
          "53: @pytest.fixture(autouse=True)",
          "54: def reset_runs(bash_dag, sub_dag, xcom_dag):",
          "55:     bash_dagrun = bash_dag.create_dagrun(",
          "56:         run_type=DagRunType.SCHEDULED,",
          "57:         execution_date=EXAMPLE_DAG_DEFAULT_DATE,",
          "58:         start_date=timezone.utcnow(),",
          "59:         state=State.RUNNING,",
          "60:     )",
          "62:     sub_dagrun = sub_dag.create_dagrun(",
          "63:         run_type=DagRunType.SCHEDULED,",
          "64:         execution_date=EXAMPLE_DAG_DEFAULT_DATE,",
          "65:         start_date=timezone.utcnow(),",
          "66:         state=State.RUNNING,",
          "67:     )",
          "69:     xcom_dagrun = xcom_dag.create_dagrun(",
          "70:         run_type=DagRunType.SCHEDULED,",
          "71:         execution_date=EXAMPLE_DAG_DEFAULT_DATE,",
          "72:         start_date=timezone.utcnow(),",
          "73:         state=State.RUNNING,",
          "74:     )",
          "76:     yield bash_dagrun, sub_dagrun, xcom_dagrun",
          "78:     clear_db_runs()",
          "81: def _check_last_log(session, dag_id, event, execution_date):",
          "82:     logs = (",
          "83:         session.query(",
          "84:             Log.dag_id,",
          "85:             Log.task_id,",
          "86:             Log.event,",
          "87:             Log.execution_date,",
          "88:             Log.owner,",
          "89:             Log.extra,",
          "90:         )",
          "91:         .filter(",
          "92:             Log.dag_id == dag_id,",
          "93:             Log.event == event,",
          "94:             Log.execution_date == execution_date,",
          "95:         )",
          "96:         .order_by(Log.dttm.desc())",
          "97:         .limit(5)",
          "98:         .all()",
          "99:     )",
          "100:     assert len(logs) >= 1",
          "101:     assert logs[0].extra",
          "104: def test_action_logging_get(session, admin_client):",
          "105:     url = 'graph?dag_id=example_bash_operator&execution_date={}'.format(",
          "106:         quote_plus(str(EXAMPLE_DAG_DEFAULT_DATE))",
          "107:     )",
          "108:     resp = admin_client.get(url, follow_redirects=True)",
          "109:     check_content_in_response('runme_1', resp)",
          "111:     # In mysql backend, this commit() is needed to write down the logs",
          "112:     session.commit()",
          "113:     _check_last_log(",
          "114:         session,",
          "115:         dag_id=\"example_bash_operator\",",
          "116:         event=\"graph\",",
          "117:         execution_date=EXAMPLE_DAG_DEFAULT_DATE,",
          "118:     )",
          "121: def test_action_logging_post(session, admin_client):",
          "122:     form = dict(",
          "123:         task_id=\"runme_1\",",
          "124:         dag_id=\"example_bash_operator\",",
          "125:         execution_date=EXAMPLE_DAG_DEFAULT_DATE,",
          "126:         upstream=\"false\",",
          "127:         downstream=\"false\",",
          "128:         future=\"false\",",
          "129:         past=\"false\",",
          "130:         only_failed=\"false\",",
          "131:     )",
          "132:     resp = admin_client.post(\"clear\", data=form)",
          "133:     check_content_in_response(['example_bash_operator', 'Wait a minute'], resp)",
          "134:     # In mysql backend, this commit() is needed to write down the logs",
          "135:     session.commit()",
          "136:     _check_last_log(",
          "137:         session,",
          "138:         dag_id=\"example_bash_operator\",",
          "139:         event=\"clear\",",
          "140:         execution_date=EXAMPLE_DAG_DEFAULT_DATE,",
          "141:     )",
          "",
          "---------------"
        ],
        "tests/www/views/test_views_extra_links.py||tests/www/views/test_views_extra_links.py": [
          "File: tests/www/views/test_views_extra_links.py -> tests/www/views/test_views_extra_links.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: #",
          "2: # Licensed to the Apache Software Foundation (ASF) under one",
          "3: # or more contributor license agreements.  See the NOTICE file",
          "4: # distributed with this work for additional information",
          "5: # regarding copyright ownership.  The ASF licenses this file",
          "6: # to you under the Apache License, Version 2.0 (the",
          "7: # \"License\"); you may not use this file except in compliance",
          "8: # with the License.  You may obtain a copy of the License at",
          "9: #",
          "10: #   http://www.apache.org/licenses/LICENSE-2.0",
          "11: #",
          "12: # Unless required by applicable law or agreed to in writing,",
          "13: # software distributed under the License is distributed on an",
          "14: # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
          "15: # KIND, either express or implied.  See the License for the",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "18: import datetime",
          "19: import json",
          "20: import re",
          "21: from unittest import mock",
          "23: import pytest",
          "25: from airflow.models import DAG, TaskInstance",
          "26: from airflow.models.baseoperator import BaseOperator, BaseOperatorLink",
          "27: from airflow.utils import dates, timezone",
          "28: from airflow.utils.session import create_session",
          "29: from tests.test_utils.mock_operators import Dummy2TestOperator, Dummy3TestOperator",
          "30: from tests.test_utils.www import check_content_in_response",
          "32: DEFAULT_DATE = timezone.datetime(2017, 1, 1)",
          "34: ENDPOINT = \"extra_links\"",
          "37: class RaiseErrorLink(BaseOperatorLink):",
          "38:     name = 'raise_error'",
          "40:     def get_link(self, operator, dttm):",
          "41:         raise ValueError('This is an error')",
          "44: class NoResponseLink(BaseOperatorLink):",
          "45:     name = 'no_response'",
          "47:     def get_link(self, operator, dttm):  # pylint: disable=unused-argument",
          "48:         return None",
          "51: class FooBarLink(BaseOperatorLink):",
          "52:     name = 'foo-bar'",
          "54:     def get_link(self, operator, dttm):",
          "55:         return f\"http://www.example.com/{operator.task_id}/foo-bar/{dttm}\"",
          "58: class AirflowLink(BaseOperatorLink):",
          "59:     name = 'airflow'",
          "61:     def get_link(self, operator, dttm):  # pylint: disable=unused-argument",
          "62:         return 'https://airflow.apache.org'",
          "65: class DummyTestOperator(BaseOperator):",
          "66:     operator_extra_links = (",
          "67:         RaiseErrorLink(),",
          "68:         NoResponseLink(),",
          "69:         FooBarLink(),",
          "70:         AirflowLink(),",
          "71:     )",
          "74: @pytest.fixture(scope=\"module\")",
          "75: def dag():",
          "76:     return DAG(\"dag\", start_date=DEFAULT_DATE)",
          "79: @pytest.fixture(scope=\"module\", autouse=True)",
          "80: def patched_app(app, dag):",
          "81:     with mock.patch.object(app, \"dag_bag\") as mock_dag_bag:",
          "82:         mock_dag_bag.get_dag.return_value = dag",
          "83:         yield",
          "86: @pytest.fixture(scope=\"module\", autouse=True)",
          "87: def task_1(dag):",
          "88:     return DummyTestOperator(task_id=\"some_dummy_task\", dag=dag)",
          "91: @pytest.fixture(scope=\"module\", autouse=True)",
          "92: def task_2(dag):",
          "93:     return Dummy2TestOperator(task_id=\"some_dummy_task_2\", dag=dag)",
          "96: @pytest.fixture(scope=\"module\", autouse=True)",
          "97: def task_3(dag):",
          "98:     return Dummy3TestOperator(task_id=\"some_dummy_task_3\", dag=dag)",
          "101: @pytest.fixture(scope=\"module\", autouse=True)",
          "102: def init_blank_task_instances():",
          "103:     \"\"\"Make sure there are no runs before we test anything.",
          "105:     This really shouldn't be needed, but tests elsewhere leave the db dirty.",
          "106:     \"\"\"",
          "107:     with create_session() as session:",
          "108:         session.query(TaskInstance).delete()",
          "111: @pytest.fixture(autouse=True)",
          "112: def reset_task_instances():",
          "113:     yield",
          "114:     with create_session() as session:",
          "115:         session.query(TaskInstance).delete()",
          "118: def test_extra_links_works(dag, task_1, viewer_client):",
          "119:     response = viewer_client.get(",
          "120:         \"{}?dag_id={}&task_id={}&execution_date={}&link_name=foo-bar\".format(",
          "121:             ENDPOINT,",
          "122:             dag.dag_id,",
          "123:             task_1.task_id,",
          "124:             DEFAULT_DATE,",
          "125:         ),",
          "126:         follow_redirects=True,",
          "127:     )",
          "129:     assert response.status_code == 200",
          "130:     assert json.loads(response.data.decode()) == {",
          "131:         'url': 'http://www.example.com/some_dummy_task/foo-bar/2017-01-01T00:00:00+00:00',",
          "132:         'error': None,",
          "133:     }",
          "136: def test_global_extra_links_works(dag, task_1, viewer_client):",
          "137:     response = viewer_client.get(",
          "138:         \"{}?dag_id={}&task_id={}&execution_date={}&link_name=github\".format(",
          "139:             ENDPOINT,",
          "140:             dag.dag_id,",
          "141:             task_1.task_id,",
          "142:             DEFAULT_DATE,",
          "143:         ),",
          "144:         follow_redirects=True,",
          "145:     )",
          "147:     assert response.status_code == 200",
          "148:     assert json.loads(response.data.decode()) == {",
          "149:         'url': 'https://github.com/apache/airflow',",
          "150:         'error': None,",
          "151:     }",
          "154: def test_extra_link_in_gantt_view(dag, viewer_client):",
          "155:     exec_date = dates.days_ago(2)",
          "156:     start_date = timezone.datetime(2020, 4, 10, 2, 0, 0)",
          "157:     end_date = exec_date + datetime.timedelta(seconds=30)",
          "159:     with create_session() as session:",
          "160:         for task in dag.tasks:",
          "161:             ti = TaskInstance(task=task, execution_date=exec_date, state=\"success\")",
          "162:             ti.start_date = start_date",
          "163:             ti.end_date = end_date",
          "164:             session.add(ti)",
          "166:     url = f'gantt?dag_id={dag.dag_id}&execution_date={exec_date}'",
          "167:     resp = viewer_client.get(url, follow_redirects=True)",
          "169:     check_content_in_response('\"extraLinks\":', resp)",
          "171:     extra_links_grps = re.search(r'extraLinks\\\": \\[(\\\".*?\\\")\\]', resp.get_data(as_text=True))",
          "172:     extra_links = extra_links_grps.group(0)",
          "173:     assert 'airflow' in extra_links",
          "174:     assert 'github' in extra_links",
          "177: def test_operator_extra_link_override_global_extra_link(dag, task_1, viewer_client):",
          "178:     response = viewer_client.get(",
          "179:         \"{}?dag_id={}&task_id={}&execution_date={}&link_name=airflow\".format(",
          "180:             ENDPOINT,",
          "181:             dag.dag_id,",
          "182:             task_1.task_id,",
          "183:             DEFAULT_DATE,",
          "184:         ),",
          "185:         follow_redirects=True,",
          "186:     )",
          "188:     assert response.status_code == 200",
          "189:     response_str = response.data",
          "190:     if isinstance(response.data, bytes):",
          "191:         response_str = response_str.decode()",
          "192:     assert json.loads(response_str) == {'url': 'https://airflow.apache.org', 'error': None}",
          "195: def test_extra_links_error_raised(dag, task_1, viewer_client):",
          "196:     response = viewer_client.get(",
          "197:         \"{}?dag_id={}&task_id={}&execution_date={}&link_name=raise_error\".format(",
          "198:             ENDPOINT,",
          "199:             dag.dag_id,",
          "200:             task_1.task_id,",
          "201:             DEFAULT_DATE,",
          "202:         ),",
          "203:         follow_redirects=True,",
          "204:     )",
          "206:     assert 404 == response.status_code",
          "207:     response_str = response.data",
          "208:     if isinstance(response.data, bytes):",
          "209:         response_str = response_str.decode()",
          "210:     assert json.loads(response_str) == {'url': None, 'error': 'This is an error'}",
          "213: def test_extra_links_no_response(dag, task_1, viewer_client):",
          "214:     response = viewer_client.get(",
          "215:         \"{}?dag_id={}&task_id={}&execution_date={}&link_name=no_response\".format(",
          "216:             ENDPOINT,",
          "217:             dag.dag_id,",
          "218:             task_1.task_id,",
          "219:             DEFAULT_DATE,",
          "220:         ),",
          "221:         follow_redirects=True,",
          "222:     )",
          "224:     assert response.status_code == 404",
          "225:     response_str = response.data",
          "226:     if isinstance(response.data, bytes):",
          "227:         response_str = response_str.decode()",
          "228:     assert json.loads(response_str) == {'url': None, 'error': 'No URL found for no_response'}",
          "231: def test_operator_extra_link_override_plugin(dag, task_2, viewer_client):",
          "232:     \"\"\"",
          "233:     This tests checks if Operator Link (AirflowLink) defined in the Dummy2TestOperator",
          "234:     is overridden by Airflow Plugin (AirflowLink2).",
          "236:     AirflowLink returns 'https://airflow.apache.org/' link",
          "237:     AirflowLink2 returns 'https://airflow.apache.org/1.10.5/' link",
          "238:     \"\"\"",
          "239:     response = viewer_client.get(",
          "240:         \"{}?dag_id={}&task_id={}&execution_date={}&link_name=airflow\".format(",
          "241:             ENDPOINT,",
          "242:             dag.dag_id,",
          "243:             task_2.task_id,",
          "244:             DEFAULT_DATE,",
          "245:         ),",
          "246:         follow_redirects=True,",
          "247:     )",
          "249:     assert response.status_code == 200",
          "250:     response_str = response.data",
          "251:     if isinstance(response.data, bytes):",
          "252:         response_str = response_str.decode()",
          "253:     assert json.loads(response_str) == {'url': 'https://airflow.apache.org/1.10.5/', 'error': None}",
          "256: def test_operator_extra_link_multiple_operators(dag, task_2, task_3, viewer_client):",
          "257:     \"\"\"",
          "258:     This tests checks if Operator Link (AirflowLink2) defined in",
          "259:     Airflow Plugin (AirflowLink2) is attached to all the list of",
          "260:     operators defined in the AirflowLink2().operators property",
          "262:     AirflowLink2 returns 'https://airflow.apache.org/1.10.5/' link",
          "263:     GoogleLink returns 'https://www.google.com'",
          "264:     \"\"\"",
          "265:     response = viewer_client.get(",
          "266:         \"{}?dag_id={}&task_id={}&execution_date={}&link_name=airflow\".format(",
          "267:             ENDPOINT,",
          "268:             dag.dag_id,",
          "269:             task_2.task_id,",
          "270:             DEFAULT_DATE,",
          "271:         ),",
          "272:         follow_redirects=True,",
          "273:     )",
          "275:     assert response.status_code == 200",
          "276:     response_str = response.data",
          "277:     if isinstance(response.data, bytes):",
          "278:         response_str = response_str.decode()",
          "279:     assert json.loads(response_str) == {'url': 'https://airflow.apache.org/1.10.5/', 'error': None}",
          "281:     response = viewer_client.get(",
          "282:         \"{}?dag_id={}&task_id={}&execution_date={}&link_name=airflow\".format(",
          "283:             ENDPOINT,",
          "284:             dag.dag_id,",
          "285:             task_3.task_id,",
          "286:             DEFAULT_DATE,",
          "287:         ),",
          "288:         follow_redirects=True,",
          "289:     )",
          "291:     assert response.status_code == 200",
          "292:     response_str = response.data",
          "293:     if isinstance(response.data, bytes):",
          "294:         response_str = response_str.decode()",
          "295:     assert json.loads(response_str) == {'url': 'https://airflow.apache.org/1.10.5/', 'error': None}",
          "297:     # Also check that the other Operator Link defined for this operator exists",
          "298:     response = viewer_client.get(",
          "299:         \"{}?dag_id={}&task_id={}&execution_date={}&link_name=google\".format(",
          "300:             ENDPOINT,",
          "301:             dag.dag_id,",
          "302:             task_3.task_id,",
          "303:             DEFAULT_DATE,",
          "304:         ),",
          "305:         follow_redirects=True,",
          "306:     )",
          "308:     assert response.status_code == 200",
          "309:     response_str = response.data",
          "310:     if isinstance(response.data, bytes):",
          "311:         response_str = response_str.decode()",
          "312:     assert json.loads(response_str) == {'url': 'https://www.google.com', 'error': None}",
          "",
          "---------------"
        ],
        "tests/www/views/test_views_mount.py||tests/www/views/test_views_mount.py": [
          "File: tests/www/views/test_views_mount.py -> tests/www/views/test_views_mount.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: #",
          "2: # Licensed to the Apache Software Foundation (ASF) under one",
          "3: # or more contributor license agreements.  See the NOTICE file",
          "4: # distributed with this work for additional information",
          "5: # regarding copyright ownership.  The ASF licenses this file",
          "6: # to you under the Apache License, Version 2.0 (the",
          "7: # \"License\"); you may not use this file except in compliance",
          "8: # with the License.  You may obtain a copy of the License at",
          "9: #",
          "10: #   http://www.apache.org/licenses/LICENSE-2.0",
          "11: #",
          "12: # Unless required by applicable law or agreed to in writing,",
          "13: # software distributed under the License is distributed on an",
          "14: # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
          "15: # KIND, either express or implied.  See the License for the",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "18: import pytest",
          "19: import werkzeug.test",
          "20: import werkzeug.wrappers",
          "22: from airflow.www.app import create_app",
          "23: from tests.test_utils.config import conf_vars",
          "26: @pytest.fixture(scope=\"module\")",
          "27: def app():",
          "28:     @conf_vars({(\"webserver\", \"base_url\"): \"http://localhost/test\"})",
          "29:     def factory():",
          "30:         return create_app(testing=True)",
          "32:     app = factory()",
          "33:     app.config['WTF_CSRF_ENABLED'] = False",
          "34:     return app",
          "37: @pytest.fixture()",
          "38: def client(app):",
          "39:     return werkzeug.test.Client(app, werkzeug.wrappers.BaseResponse)",
          "42: def test_mount(client):",
          "43:     # Test an endpoint that doesn't need auth!",
          "44:     resp = client.get('/test/health')",
          "45:     assert resp.status_code == 200",
          "46:     assert b\"healthy\" in resp.data",
          "49: def test_not_found(client):",
          "50:     resp = client.get('/', follow_redirects=True)",
          "51:     assert resp.status_code == 404",
          "54: def test_index(client):",
          "55:     resp = client.get('/test/')",
          "56:     assert resp.status_code == 302",
          "57:     assert resp.headers['Location'] == 'http://localhost/test/home'",
          "",
          "---------------"
        ],
        "tests/www/views/test_views_pool.py||tests/www/views/test_views_pool.py": [
          "File: tests/www/views/test_views_pool.py -> tests/www/views/test_views_pool.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: #",
          "2: # Licensed to the Apache Software Foundation (ASF) under one",
          "3: # or more contributor license agreements.  See the NOTICE file",
          "4: # distributed with this work for additional information",
          "5: # regarding copyright ownership.  The ASF licenses this file",
          "6: # to you under the Apache License, Version 2.0 (the",
          "7: # \"License\"); you may not use this file except in compliance",
          "8: # with the License.  You may obtain a copy of the License at",
          "9: #",
          "10: #   http://www.apache.org/licenses/LICENSE-2.0",
          "11: #",
          "12: # Unless required by applicable law or agreed to in writing,",
          "13: # software distributed under the License is distributed on an",
          "14: # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
          "15: # KIND, either express or implied.  See the License for the",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "18: import flask",
          "19: import pytest",
          "21: from airflow.models import Pool",
          "22: from airflow.utils.session import create_session",
          "23: from tests.test_utils.www import check_content_in_response, check_content_not_in_response",
          "26: @pytest.fixture(autouse=True)",
          "27: def clear_pools():",
          "28:     with create_session() as session:",
          "29:         session.query(Pool).delete()",
          "32: @pytest.fixture()",
          "33: def pool():",
          "34:     return {",
          "35:         'pool': 'test-pool',",
          "36:         'slots': 777,",
          "37:         'description': 'test-pool-description',",
          "38:     }",
          "41: def test_create_pool_with_same_name(admin_client, pool):",
          "42:     # create test pool",
          "43:     resp = admin_client.post('/pool/add', data=pool, follow_redirects=True)",
          "44:     check_content_in_response('Added Row', resp)",
          "46:     # create pool with the same name",
          "47:     resp = admin_client.post('/pool/add', data=pool, follow_redirects=True)",
          "48:     check_content_in_response('Already exists.', resp)",
          "51: def test_create_pool_with_empty_name(admin_client, pool):",
          "52:     pool['pool'] = ''",
          "53:     resp = admin_client.post('/pool/add', data=pool, follow_redirects=True)",
          "54:     check_content_in_response('This field is required.', resp)",
          "57: def test_odd_name(session, admin_client, pool):",
          "58:     pool['pool'] = 'test-pool<script></script>'",
          "59:     session.add(Pool(**pool))",
          "60:     session.commit()",
          "61:     resp = admin_client.get('/pool/list/')",
          "62:     check_content_in_response('test-pool&lt;script&gt;', resp)",
          "63:     check_content_not_in_response('test-pool<script>', resp)",
          "66: def test_list(app, session, admin_client, pool):",
          "67:     pool['pool'] = 'test-pool'",
          "68:     session.add(Pool(**pool))",
          "69:     session.commit()",
          "70:     resp = admin_client.get('/pool/list/')",
          "71:     # We should see this link",
          "72:     with app.test_request_context():",
          "73:         url = flask.url_for('TaskInstanceModelView.list', _flt_3_pool='test-pool', _flt_3_state='running')",
          "74:         used_tag = flask.Markup(\"<a href='{url}'>{slots}</a>\").format(url=url, slots=0)",
          "76:         url = flask.url_for('TaskInstanceModelView.list', _flt_3_pool='test-pool', _flt_3_state='queued')",
          "77:         queued_tag = flask.Markup(\"<a href='{url}'>{slots}</a>\").format(url=url, slots=0)",
          "78:     check_content_in_response(used_tag, resp)",
          "79:     check_content_in_response(queued_tag, resp)",
          "",
          "---------------"
        ],
        "tests/www/views/test_views_rendered.py||tests/www/views/test_views_rendered.py": [
          "File: tests/www/views/test_views_rendered.py -> tests/www/views/test_views_rendered.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: #",
          "2: # Licensed to the Apache Software Foundation (ASF) under one",
          "3: # or more contributor license agreements.  See the NOTICE file",
          "4: # distributed with this work for additional information",
          "5: # regarding copyright ownership.  The ASF licenses this file",
          "6: # to you under the Apache License, Version 2.0 (the",
          "7: # \"License\"); you may not use this file except in compliance",
          "8: # with the License.  You may obtain a copy of the License at",
          "9: #",
          "10: #   http://www.apache.org/licenses/LICENSE-2.0",
          "11: #",
          "12: # Unless required by applicable law or agreed to in writing,",
          "13: # software distributed under the License is distributed on an",
          "14: # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
          "15: # KIND, either express or implied.  See the License for the",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "18: from unittest import mock",
          "19: from urllib.parse import quote_plus",
          "21: import pytest",
          "23: from airflow.models import DAG, RenderedTaskInstanceFields, TaskInstance",
          "24: from airflow.models.serialized_dag import SerializedDagModel",
          "25: from airflow.operators.bash import BashOperator",
          "26: from airflow.utils import timezone",
          "27: from airflow.utils.session import create_session",
          "28: from tests.test_utils.www import check_content_in_response, check_content_not_in_response",
          "30: DEFAULT_DATE = timezone.datetime(2020, 3, 1)",
          "33: @pytest.fixture()",
          "34: def dag():",
          "35:     return DAG(",
          "36:         \"testdag\",",
          "37:         start_date=DEFAULT_DATE,",
          "38:         user_defined_filters={\"hello\": lambda name: f'Hello {name}'},",
          "39:         user_defined_macros={\"fullname\": lambda fname, lname: f'{fname} {lname}'},",
          "40:     )",
          "43: @pytest.fixture()",
          "44: def task1(dag):",
          "45:     return BashOperator(",
          "46:         task_id='task1',",
          "47:         bash_command='{{ task_instance_key_str }}',",
          "48:         dag=dag,",
          "49:     )",
          "52: @pytest.fixture()",
          "53: def task2(dag):",
          "54:     return BashOperator(",
          "55:         task_id='task2',",
          "56:         bash_command='echo {{ fullname(\"Apache\", \"Airflow\") | hello }}',",
          "57:         dag=dag,",
          "58:     )",
          "61: @pytest.fixture(autouse=True)",
          "62: def reset_db(dag, task1, task2):  # pylint: disable=unused-argument",
          "63:     \"\"\"Reset DB for each test.",
          "65:     This writes the DAG to the DB, and clears rendered fields so we have a clean",
          "66:     slate for each test. Note that task1 and task2 are included in the argument",
          "67:     to make sure they are registered to the DAG for serialization.",
          "69:     The pre-test cleanup really shouldn't be necessary, but the test DB was not",
          "70:     initialized in a clean state to begin with :(",
          "71:     \"\"\"",
          "72:     with create_session() as session:",
          "73:         SerializedDagModel.write_dag(dag)",
          "74:         session.query(RenderedTaskInstanceFields).delete()",
          "75:     yield",
          "76:     with create_session() as session:",
          "77:         session.query(RenderedTaskInstanceFields).delete()",
          "78:         session.query(SerializedDagModel).delete()",
          "81: @pytest.fixture()",
          "82: def patch_app(app, dag):",
          "83:     with mock.patch.object(app, \"dag_bag\") as mock_dag_bag:",
          "84:         mock_dag_bag.get_dag.return_value = dag",
          "85:         yield app",
          "88: @pytest.mark.usefixtures(\"patch_app\")",
          "89: def test_rendered_template_view(admin_client, task1):",
          "90:     \"\"\"",
          "91:     Test that the Rendered View contains the values from RenderedTaskInstanceFields",
          "92:     \"\"\"",
          "93:     assert task1.bash_command == '{{ task_instance_key_str }}'",
          "94:     ti = TaskInstance(task1, DEFAULT_DATE)",
          "96:     with create_session() as session:",
          "97:         session.add(RenderedTaskInstanceFields(ti))",
          "99:     url = f'rendered-templates?task_id=task1&dag_id=testdag&execution_date={quote_plus(str(DEFAULT_DATE))}'",
          "101:     resp = admin_client.get(url, follow_redirects=True)",
          "102:     check_content_in_response(\"testdag__task1__20200301\", resp)",
          "105: @pytest.mark.usefixtures(\"patch_app\")",
          "106: def test_rendered_template_view_for_unexecuted_tis(admin_client, task1):",
          "107:     \"\"\"",
          "108:     Test that the Rendered View is able to show rendered values",
          "109:     even for TIs that have not yet executed",
          "110:     \"\"\"",
          "111:     assert task1.bash_command == '{{ task_instance_key_str }}'",
          "113:     url = f'rendered-templates?task_id=task1&dag_id=task1&execution_date={quote_plus(str(DEFAULT_DATE))}'",
          "115:     resp = admin_client.get(url, follow_redirects=True)",
          "116:     check_content_in_response(\"testdag__task1__20200301\", resp)",
          "119: def test_user_defined_filter_and_macros_raise_error(app, admin_client, dag, task2):",
          "120:     \"\"\"",
          "121:     Test that the Rendered View is able to show rendered values",
          "122:     even for TIs that have not yet executed",
          "123:     \"\"\"",
          "124:     dag = SerializedDagModel.get(dag.dag_id).dag",
          "125:     with mock.patch.object(app, \"dag_bag\") as mock_dag_bag:",
          "126:         mock_dag_bag.get_dag.return_value = dag",
          "128:         assert task2.bash_command == 'echo {{ fullname(\"Apache\", \"Airflow\") | hello }}'",
          "130:         url = (",
          "131:             f'rendered-templates?task_id=task2&dag_id=testdag&'",
          "132:             f'execution_date={quote_plus(str(DEFAULT_DATE))}'",
          "133:         )",
          "135:         resp = admin_client.get(url, follow_redirects=True)",
          "137:         check_content_not_in_response(\"echo Hello Apache Airflow\", resp)",
          "138:         check_content_in_response(",
          "139:             \"Webserver does not have access to User-defined Macros or Filters when \"",
          "140:             \"Dag Serialization is enabled. Hence for the task that have not yet \"",
          "141:             \"started running, please use &#39;airflow tasks render&#39; for \"",
          "142:             \"debugging the rendering of template_fields.<br><br>OriginalError: no \"",
          "143:             \"filter named &#39;hello&#39\",",
          "144:             resp,",
          "145:         )",
          "",
          "---------------"
        ],
        "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py": [
          "File: tests/www/views/test_views_trigger_dag.py -> tests/www/views/test_views_trigger_dag.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: #",
          "2: # Licensed to the Apache Software Foundation (ASF) under one",
          "3: # or more contributor license agreements.  See the NOTICE file",
          "4: # distributed with this work for additional information",
          "5: # regarding copyright ownership.  The ASF licenses this file",
          "6: # to you under the Apache License, Version 2.0 (the",
          "7: # \"License\"); you may not use this file except in compliance",
          "8: # with the License.  You may obtain a copy of the License at",
          "9: #",
          "10: #   http://www.apache.org/licenses/LICENSE-2.0",
          "11: #",
          "12: # Unless required by applicable law or agreed to in writing,",
          "13: # software distributed under the License is distributed on an",
          "14: # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
          "15: # KIND, either express or implied.  See the License for the",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "18: import json",
          "20: import pytest",
          "22: from airflow.models import DagBag, DagRun",
          "23: from airflow.security import permissions",
          "24: from airflow.utils.session import create_session",
          "25: from airflow.utils.types import DagRunType",
          "26: from tests.test_utils.www import check_content_in_response",
          "29: @pytest.fixture(scope=\"module\", autouse=True)",
          "30: def initialize_one_dag():",
          "31:     with create_session() as session:",
          "32:         DagBag().get_dag(\"example_bash_operator\").sync_to_db(session=session)",
          "33:     yield",
          "34:     with create_session() as session:",
          "35:         session.query(DagRun).delete()",
          "38: def test_trigger_dag_button_normal_exist(admin_client):",
          "39:     resp = admin_client.get('/', follow_redirects=True)",
          "40:     assert '/trigger?dag_id=example_bash_operator' in resp.data.decode('utf-8')",
          "41:     assert \"return confirmDeleteDag(this, 'example_bash_operator')\" in resp.data.decode('utf-8')",
          "44: @pytest.mark.quarantined",
          "45: def test_trigger_dag_button(admin_client):",
          "46:     test_dag_id = \"example_bash_operator\"",
          "47:     admin_client.post(f'trigger?dag_id={test_dag_id}')",
          "48:     with create_session() as session:",
          "49:         run = session.query(DagRun).filter(DagRun.dag_id == test_dag_id).first()",
          "50:     assert run is not None",
          "51:     assert DagRunType.MANUAL in run.run_id",
          "52:     assert run.run_type == DagRunType.MANUAL",
          "55: @pytest.mark.quarantined",
          "56: def test_trigger_dag_conf(admin_client):",
          "57:     test_dag_id = \"example_bash_operator\"",
          "58:     conf_dict = {'string': 'Hello, World!'}",
          "60:     admin_client.post(f'trigger?dag_id={test_dag_id}', data={'conf': json.dumps(conf_dict)})",
          "62:     with create_session() as session:",
          "63:         run = session.query(DagRun).filter(DagRun.dag_id == test_dag_id).first()",
          "64:     assert run is not None",
          "65:     assert DagRunType.MANUAL in run.run_id",
          "66:     assert run.run_type == DagRunType.MANUAL",
          "67:     assert run.conf == conf_dict",
          "70: def test_trigger_dag_conf_malformed(admin_client):",
          "71:     test_dag_id = \"example_bash_operator\"",
          "73:     response = admin_client.post(f'trigger?dag_id={test_dag_id}', data={'conf': '{\"a\": \"b\"'})",
          "74:     check_content_in_response('Invalid JSON configuration', response)",
          "76:     with create_session() as session:",
          "77:         run = session.query(DagRun).filter(DagRun.dag_id == test_dag_id).first()",
          "78:     assert run is None",
          "81: def test_trigger_dag_form(admin_client):",
          "82:     test_dag_id = \"example_bash_operator\"",
          "83:     resp = admin_client.get(f'trigger?dag_id={test_dag_id}')",
          "84:     check_content_in_response(f'Trigger DAG: {test_dag_id}', resp)",
          "87: @pytest.mark.parametrize(",
          "88:     \"test_origin, expected_origin\",",
          "89:     [",
          "90:         (\"javascript:alert(1)\", \"/home\"),",
          "91:         (\"http://google.com\", \"/home\"),",
          "92:         (\"36539'%3balert(1)%2f%2f166\", \"/home\"),",
          "93:         (",
          "94:             \"%2Ftree%3Fdag_id%3Dexample_bash_operator';alert(33)//\",",
          "95:             \"/home\",",
          "96:         ),",
          "97:         (\"%2Ftree%3Fdag_id%3Dexample_bash_operator\", \"/tree?dag_id=example_bash_operator\"),",
          "98:         (\"%2Fgraph%3Fdag_id%3Dexample_bash_operator\", \"/graph?dag_id=example_bash_operator\"),",
          "99:     ],",
          "100: )",
          "101: def test_trigger_dag_form_origin_url(admin_client, test_origin, expected_origin):",
          "102:     test_dag_id = \"example_bash_operator\"",
          "104:     resp = admin_client.get(f'trigger?dag_id={test_dag_id}&origin={test_origin}')",
          "105:     check_content_in_response(",
          "106:         '<button type=\"button\" class=\"btn\" onclick=\"location.href = \\'{}\\'; return false\">'.format(",
          "107:             expected_origin",
          "108:         ),",
          "109:         resp,",
          "110:     )",
          "113: @pytest.mark.parametrize(",
          "114:     \"request_conf, expected_conf\",",
          "115:     [",
          "116:         (None, {\"example_key\": \"example_value\"}),",
          "117:         ({\"other\": \"test_data\", \"key\": 12}, {\"other\": \"test_data\", \"key\": 12}),",
          "118:     ],",
          "119: )",
          "120: def test_trigger_dag_params_conf(admin_client, request_conf, expected_conf):",
          "121:     \"\"\"",
          "122:     Test that textarea in Trigger DAG UI is pre-populated",
          "123:     with json config when the conf URL parameter is passed,",
          "124:     or if a params dict is passed in the DAG",
          "126:         1. Conf is not included in URL parameters -> DAG.conf is in textarea",
          "127:         2. Conf is passed as a URL parameter -> passed conf json is in textarea",
          "128:     \"\"\"",
          "129:     test_dag_id = \"example_bash_operator\"",
          "130:     doc_md = \"Example Bash Operator\"",
          "132:     if not request_conf:",
          "133:         resp = admin_client.get(f'trigger?dag_id={test_dag_id}')",
          "134:     else:",
          "135:         test_request_conf = json.dumps(request_conf, indent=4)",
          "136:         resp = admin_client.get(f'trigger?dag_id={test_dag_id}&conf={test_request_conf}&doc_md={doc_md}')",
          "138:     expected_dag_conf = json.dumps(expected_conf, indent=4).replace(\"\\\"\", \"&#34;\")",
          "140:     check_content_in_response(",
          "141:         f'<textarea class=\"form-control\" name=\"conf\" id=\"json\">{expected_dag_conf}</textarea>',",
          "142:         resp,",
          "143:     )",
          "146: def test_trigger_endpoint_uses_existing_dagbag(admin_client):",
          "147:     \"\"\"",
          "148:     Test that Trigger Endpoint uses the DagBag already created in views.py",
          "149:     instead of creating a new one.",
          "150:     \"\"\"",
          "151:     url = 'trigger?dag_id=example_bash_operator'",
          "152:     resp = admin_client.post(url, data={}, follow_redirects=True)",
          "153:     check_content_in_response('example_bash_operator', resp)",
          "156: def test_viewer_cant_trigger_dag(client_factory):",
          "157:     \"\"\"",
          "158:     Test that the test_viewer user can't trigger DAGs.",
          "159:     \"\"\"",
          "160:     client = client_factory(",
          "161:         name=\"test_viewer_cant_trigger_dag_user\",",
          "162:         role_name=\"test_viewer_cant_trigger_dag_user\",",
          "163:         permissions=[",
          "164:             (permissions.ACTION_CAN_READ, permissions.RESOURCE_WEBSITE),",
          "165:             (permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG),",
          "166:             (permissions.ACTION_CAN_CREATE, permissions.RESOURCE_DAG_RUN),",
          "167:         ],",
          "168:     )",
          "170:     url = 'trigger?dag_id=example_bash_operator'",
          "171:     resp = client.get(url, follow_redirects=True)",
          "172:     response_data = resp.data.decode()",
          "173:     assert \"Access is Denied\" in response_data",
          "",
          "---------------"
        ],
        "tests/www/views/test_views_variable.py||tests/www/views/test_views_variable.py": [
          "File: tests/www/views/test_views_variable.py -> tests/www/views/test_views_variable.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: #",
          "2: # Licensed to the Apache Software Foundation (ASF) under one",
          "3: # or more contributor license agreements.  See the NOTICE file",
          "4: # distributed with this work for additional information",
          "5: # regarding copyright ownership.  The ASF licenses this file",
          "6: # to you under the Apache License, Version 2.0 (the",
          "7: # \"License\"); you may not use this file except in compliance",
          "8: # with the License.  You may obtain a copy of the License at",
          "9: #",
          "10: #   http://www.apache.org/licenses/LICENSE-2.0",
          "11: #",
          "12: # Unless required by applicable law or agreed to in writing,",
          "13: # software distributed under the License is distributed on an",
          "14: # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
          "15: # KIND, either express or implied.  See the License for the",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "18: import io",
          "19: from unittest import mock",
          "21: import pytest",
          "23: from airflow.models import Variable",
          "24: from airflow.utils.session import create_session",
          "25: from tests.test_utils.www import check_content_in_response, check_content_not_in_response",
          "27: VARIABLE = {",
          "28:     'key': 'test_key',",
          "29:     'val': 'text_val',",
          "30:     'description': 'test_description',",
          "31:     'is_encrypted': True,",
          "32: }",
          "35: @pytest.fixture(autouse=True)",
          "36: def clear_variables():",
          "37:     with create_session() as session:",
          "38:         session.query(Variable).delete()",
          "41: def test_can_handle_error_on_decrypt(session, admin_client):",
          "42:     # create valid variable",
          "43:     admin_client.post('/variable/add', data=VARIABLE, follow_redirects=True)",
          "45:     # update the variable with a wrong value, given that is encrypted",
          "46:     session.query(Variable).filter(Variable.key == VARIABLE['key']).update(",
          "47:         {'val': 'failed_value_not_encrypted'},",
          "48:         synchronize_session=False,",
          "49:     )",
          "50:     session.commit()",
          "52:     # retrieve Variables page, should not fail and contain the Invalid",
          "53:     # label for the variable",
          "54:     resp = admin_client.get('/variable/list', follow_redirects=True)",
          "55:     check_content_in_response(",
          "56:         '<span class=\"label label-danger\">Invalid</span>',",
          "57:         resp,",
          "58:     )",
          "61: def test_xss_prevention(admin_client):",
          "62:     xss = \"/variable/list/<img%20src=''%20onerror='alert(1);'>\"",
          "63:     resp = admin_client.get(xss, follow_redirects=True)",
          "64:     check_content_not_in_response(\"<img src='' onerror='alert(1);'>\", resp, resp_code=404)",
          "67: def test_import_variables_no_file(admin_client):",
          "68:     resp = admin_client.post('/variable/varimport', follow_redirects=True)",
          "69:     check_content_in_response('Missing file or syntax error.', resp)",
          "72: def test_import_variables_failed(session, admin_client):",
          "73:     content = '{\"str_key\": \"str_value\"}'",
          "75:     with mock.patch('airflow.models.Variable.set') as set_mock:",
          "76:         set_mock.side_effect = UnicodeEncodeError",
          "77:         assert session.query(Variable).count() == 0",
          "79:         bytes_content = io.BytesIO(bytes(content, encoding='utf-8'))",
          "81:         resp = admin_client.post(",
          "82:             '/variable/varimport', data={'file': (bytes_content, 'test.json')}, follow_redirects=True",
          "83:         )",
          "84:         check_content_in_response('1 variable(s) failed to be updated.', resp)",
          "87: def test_import_variables_success(session, admin_client):",
          "88:     assert session.query(Variable).count() == 0",
          "90:     content = '{\"str_key\": \"str_value\", \"int_key\": 60, \"list_key\": [1, 2], \"dict_key\": {\"k_a\": 2, \"k_b\": 3}}'",
          "91:     bytes_content = io.BytesIO(bytes(content, encoding='utf-8'))",
          "93:     resp = admin_client.post(",
          "94:         '/variable/varimport', data={'file': (bytes_content, 'test.json')}, follow_redirects=True",
          "95:     )",
          "96:     check_content_in_response('4 variable(s) successfully updated.', resp)",
          "99: def test_description_retrieval(session, admin_client):",
          "100:     # create valid variable",
          "101:     admin_client.post('/variable/add', data=VARIABLE, follow_redirects=True)",
          "103:     row = session.query(Variable.key, Variable.description).first()",
          "104:     assert row.key == 'test_key' and row.description == 'test_description'",
          "",
          "---------------"
        ]
      }
    }
  ]
}