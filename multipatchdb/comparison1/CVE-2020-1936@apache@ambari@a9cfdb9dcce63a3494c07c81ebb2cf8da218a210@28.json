{
  "cve_id": "CVE-2020-1936",
  "cve_desc": "A cross-site scripting issue was found in Apache Ambari Views. This was addressed in Apache Ambari 2.7.4.",
  "repo": "apache/ambari",
  "patch_hash": "a9cfdb9dcce63a3494c07c81ebb2cf8da218a210",
  "patch_info": {
    "commit_hash": "a9cfdb9dcce63a3494c07c81ebb2cf8da218a210",
    "repo": "apache/ambari",
    "commit_url": "https://github.com/apache/ambari/pull/3040/commits/a9cfdb9dcce63a3494c07c81ebb2cf8da218a210",
    "files": [
      "ambari-web/app/views/common/breadcrumbs_view.js"
    ],
    "message": "AMBARI-25329. Ambari breadcrumbs xss vulnerability",
    "before_after_code_files": [
      "ambari-web/app/views/common/breadcrumbs_view.js||ambari-web/app/views/common/breadcrumbs_view.js"
    ]
  },
  "patch_diff": {
    "ambari-web/app/views/common/breadcrumbs_view.js||ambari-web/app/views/common/breadcrumbs_view.js": [
      "File: ambari-web/app/views/common/breadcrumbs_view.js -> ambari-web/app/views/common/breadcrumbs_view.js",
      "--- Hunk 1 ---",
      "[Context before]",
      "149:   createLabel() {",
      "150:     let label = this.get('label');",
      "151:     let labelBindingPath = this.get('labelBindingPath');",
      "154:     this.set('formattedLabel', this.labelPostFormat(formattedLabel));",
      "155:   },",
      "",
      "[Removed Lines]",
      "153:     let formattedLabel = labelBindingPath ? App.get(_getLabelPathWithoutApp(labelBindingPath)) : label;",
      "",
      "[Added Lines]",
      "152:     let formattedLabel;",
      "154:     if (labelBindingPath) {",
      "155:       formattedLabel = Ember.Handlebars.Utils.escapeExpression(App.get(_getLabelPathWithoutApp(labelBindingPath)));",
      "156:     } else{",
      "157:       formattedLabel = label;",
      "158:     }",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "216:       }",
      "217:       currentState = currentState.get('parentState');",
      "218:     }",
      "220:     if (items.length) {",
      "221:       items.get('lastObject').setProperties({",
      "222:         disabled: true,",
      "",
      "[Removed Lines]",
      "219:     items = items.reverse().map(item => App.BreadcrumbItem.extend(item).create());",
      "",
      "[Added Lines]",
      "227:     items.reverse();",
      "228:     items.slice(1).forEach(item => item.label = Ember.Handlebars.Utils.escapeExpression(item.label));",
      "229:     items = items.map(item => App.BreadcrumbItem.extend(item).create());",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "6228ba98820bbd98aaecc275376e06fd380705db",
      "candidate_info": {
        "commit_hash": "6228ba98820bbd98aaecc275376e06fd380705db",
        "repo": "apache/ambari",
        "commit_url": "https://github.com/apache/ambari/commit/6228ba98820bbd98aaecc275376e06fd380705db",
        "files": [
          "ambari-server/src/main/resources/common-services/HIVE/0.12.0.2.0/package/scripts/pre_upgrade.py"
        ],
        "message": "AMBARI-24304. Fix convert table classpath (on behalf of mgergely) (#1907)",
        "before_after_code_files": [
          "ambari-server/src/main/resources/common-services/HIVE/0.12.0.2.0/package/scripts/pre_upgrade.py||ambari-server/src/main/resources/common-services/HIVE/0.12.0.2.0/package/scripts/pre_upgrade.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/ambari/pull/3633",
          "https://github.com/apache/ambari/pull/3631",
          "https://github.com/apache/ambari/pull/3637",
          "https://github.com/apache/ambari/pull/3632",
          "https://github.com/apache/ambari/pull/3634",
          "https://github.com/apache/ambari/pull/3635"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "ambari-server/src/main/resources/common-services/HIVE/0.12.0.2.0/package/scripts/pre_upgrade.py||ambari-server/src/main/resources/common-services/HIVE/0.12.0.2.0/package/scripts/pre_upgrade.py": [
          "File: ambari-server/src/main/resources/common-services/HIVE/0.12.0.2.0/package/scripts/pre_upgrade.py -> ambari-server/src/main/resources/common-services/HIVE/0.12.0.2.0/package/scripts/pre_upgrade.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "99:       hive_kinit_cmd = format(\"{kinit_path_local} -kt {hive_server2_keytab} {hive_principal}; \")",
          "100:       Execute(hive_kinit_cmd, user = params.hive_user)",
          "103:     cmd = format(\"{java64_home}/bin/java -Djavax.security.auth.useSubjectCredsOnly=false -cp {classpath} org.apache.hadoop.hive.upgrade.acid.PreUpgradeTool -execute\")",
          "104:     Execute(cmd, user = params.hive_user)",
          "",
          "[Removed Lines]",
          "102:     classpath = format(\"{source_dir}/hive2/lib/*:{source_dir}/hadoop/*:{source_dir}/hadoop/lib/*:{source_dir}/hadoop-mapreduce/*:{source_dir}/hadoop-mapreduce/lib/*:{target_dir}/hive/lib/hive-pre-upgrade.jar:{source_dir}/hive/conf\")",
          "",
          "[Added Lines]",
          "102:     classpath = format(\"{source_dir}/hive2/lib/*:{source_dir}/hadoop/*:{source_dir}/hadoop/lib/*:{source_dir}/hadoop-mapreduce/*:{source_dir}/hadoop-mapreduce/lib/*:{source_dir}/hadoop-hdfs/*:{source_dir}/hadoop-hdfs/lib/*:{source_dir}/hadoop/etc/hadoop/:{target_dir}/hive/lib/hive-pre-upgrade.jar:{source_dir}/hive/conf/conf.server\")",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "499bdc0aeadbc4b5a1223e8c9ae9bc4f38edc447",
      "candidate_info": {
        "commit_hash": "499bdc0aeadbc4b5a1223e8c9ae9bc4f38edc447",
        "repo": "apache/ambari",
        "commit_url": "https://github.com/apache/ambari/commit/499bdc0aeadbc4b5a1223e8c9ae9bc4f38edc447",
        "files": [
          "ambari-web/app/data/configs/services/ranger_properties.js"
        ],
        "message": "AMBARI-24794 Adding Ranger Password configs in Admin Settings section under Advanced config (mugdha) (#2498)",
        "before_after_code_files": [
          "ambari-web/app/data/configs/services/ranger_properties.js||ambari-web/app/data/configs/services/ranger_properties.js"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/ambari/pull/3633",
          "https://github.com/apache/ambari/pull/3631",
          "https://github.com/apache/ambari/pull/3637",
          "https://github.com/apache/ambari/pull/3632",
          "https://github.com/apache/ambari/pull/3634",
          "https://github.com/apache/ambari/pull/3635"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "ambari-web/app/data/configs/services/ranger_properties.js||ambari-web/app/data/configs/services/ranger_properties.js": [
          "File: ambari-web/app/data/configs/services/ranger_properties.js -> ambari-web/app/data/configs/services/ranger_properties.js",
          "--- Hunk 1 ---",
          "[Context before]",
          "33:   },",
          "34:   {",
          "35:     \"category\": \"RANGER_ADMIN\",",
          "37:     \"index\": 2,",
          "39:     \"serviceName\": \"RANGER\"",
          "40:   },",
          "41:   {",
          "",
          "[Removed Lines]",
          "36:     \"filename\": \"admin-properties.xml\",",
          "38:     \"name\": \"SQL_CONNECTOR_JAR\",",
          "",
          "[Added Lines]",
          "36:     \"filename\": \"ranger-env.xml\",",
          "38:     \"name\": \"rangerusersync_user_password\",",
          "39:     \"serviceName\": \"RANGER\"",
          "40:   },",
          "41:   {",
          "42:     \"category\": \"RANGER_ADMIN\",",
          "43:     \"filename\": \"ranger-env.xml\",",
          "44:     \"index\": 3,",
          "45:     \"name\": \"rangertagsync_user_password\",",
          "46:     \"serviceName\": \"RANGER\"",
          "47:   },",
          "48:   {",
          "49:     \"category\": \"RANGER_ADMIN\",",
          "50:     \"filename\": \"ranger-env.xml\",",
          "51:     \"index\": 4,",
          "52:     \"name\": \"keyadmin_user_password\",",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "5d1fa9d11f856a7460734244c22900dcbf314db3",
      "candidate_info": {
        "commit_hash": "5d1fa9d11f856a7460734244c22900dcbf314db3",
        "repo": "apache/ambari",
        "commit_url": "https://github.com/apache/ambari/commit/5d1fa9d11f856a7460734244c22900dcbf314db3",
        "files": [
          "ambari-common/src/main/python/ambari_commons/credential_store_helper.py"
        ],
        "message": "[AMBARI-24264] Suppress log messages from the credential_store_helper",
        "before_after_code_files": [
          "ambari-common/src/main/python/ambari_commons/credential_store_helper.py||ambari-common/src/main/python/ambari_commons/credential_store_helper.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/ambari/pull/3633",
          "https://github.com/apache/ambari/pull/3631",
          "https://github.com/apache/ambari/pull/3637",
          "https://github.com/apache/ambari/pull/3632",
          "https://github.com/apache/ambari/pull/3634",
          "https://github.com/apache/ambari/pull/3635"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "ambari-common/src/main/python/ambari_commons/credential_store_helper.py||ambari-common/src/main/python/ambari_commons/credential_store_helper.py": [
          "File: ambari-common/src/main/python/ambari_commons/credential_store_helper.py -> ambari-common/src/main/python/ambari_commons/credential_store_helper.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "50:     # Execute a get command on the CredentialUtil CLI to get the password for the specified alias",
          "51:     java_bin = '{java_home}/bin/java'.format(java_home=java_home)",
          "52:     cmd = (java_bin, '-cp', cs_lib_path, credential_util_cmd, 'get', alias, '-provider', provider_path)",
          "54:     std_out_lines = std_out_msg.split('\\n')",
          "55:     return(std_out_lines[-1]) # Get the last line of the output, to skip warnings if any.",
          "",
          "[Removed Lines]",
          "53:     cmd_result, std_out_msg  = checked_call(cmd)",
          "",
          "[Added Lines]",
          "53:     cmd_result, std_out_msg  = checked_call(cmd, quiet=True)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "61:     # Execute a get command on the CredentialUtil CLI to list all the aliases",
          "62:     java_bin = '{java_home}/bin/java'.format(java_home=java_home)",
          "63:     cmd = (java_bin, '-cp', cs_lib_path, credential_util_cmd, 'list', '-provider', provider_path)",
          "65:     std_out_lines = std_out_msg.split('\\n')",
          "66:     return(removeloglines(std_out_lines)[1:]) # Get the last line of the output, to skip warnings if any.",
          "",
          "[Removed Lines]",
          "64:     cmd_result, std_out_msg  = checked_call(cmd)",
          "",
          "[Added Lines]",
          "64:     cmd_result, std_out_msg  = checked_call(cmd, quiet=True)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "d4e80e52cea2b9e24eaae98f3448c9042dab134e",
      "candidate_info": {
        "commit_hash": "d4e80e52cea2b9e24eaae98f3448c9042dab134e",
        "repo": "apache/ambari",
        "commit_url": "https://github.com/apache/ambari/commit/d4e80e52cea2b9e24eaae98f3448c9042dab134e",
        "files": [
          "ambari-common/src/main/python/resource_management/libraries/functions/hive_check.py",
          "ambari-server/src/test/python/stacks/2.0.6/HIVE/test_hive_service_check.py"
        ],
        "message": "AMBARI-25269. Hive Server Interactive process alert triggered in HA setup (#2958)",
        "before_after_code_files": [
          "ambari-common/src/main/python/resource_management/libraries/functions/hive_check.py||ambari-common/src/main/python/resource_management/libraries/functions/hive_check.py",
          "ambari-server/src/test/python/stacks/2.0.6/HIVE/test_hive_service_check.py||ambari-server/src/test/python/stacks/2.0.6/HIVE/test_hive_service_check.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/ambari/pull/3633",
          "https://github.com/apache/ambari/pull/3631",
          "https://github.com/apache/ambari/pull/3637",
          "https://github.com/apache/ambari/pull/3632",
          "https://github.com/apache/ambari/pull/3634",
          "https://github.com/apache/ambari/pull/3635"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "ambari-common/src/main/python/resource_management/libraries/functions/hive_check.py||ambari-common/src/main/python/resource_management/libraries/functions/hive_check.py": [
          "File: ambari-common/src/main/python/resource_management/libraries/functions/hive_check.py -> ambari-common/src/main/python/resource_management/libraries/functions/hive_check.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "75:   # -n the user to connect as (ignored when using the hive principal in the URL, can be different from the user running the beeline command)",
          "76:   # -e ';' executes a SQL commmand of NOOP",
          "78:         (format(hive_user), format(\";\".join(beeline_url)), format(credential_str))",
          "80:   Execute(cmd,",
          "",
          "[Removed Lines]",
          "77:   cmd = \"beeline -n %s -u '%s' %s -e ';' 2>&1 | awk '{print}' | grep -i -e 'Connected to:' -e 'Transaction isolation:'\" % \\",
          "",
          "[Added Lines]",
          "77:   cmd = (\"beeline -n %s -u '%s' %s -e ';' 2>&1 | awk '{print}' | grep -i \" + \\",
          "78:          \"-e 'Connected to:' -e 'Transaction isolation:' -e 'inactive HS2 instance; use service discovery'\") % \\",
          "",
          "---------------"
        ],
        "ambari-server/src/test/python/stacks/2.0.6/HIVE/test_hive_service_check.py||ambari-server/src/test/python/stacks/2.0.6/HIVE/test_hive_service_check.py": [
          "File: ambari-server/src/test/python/stacks/2.0.6/HIVE/test_hive_service_check.py -> ambari-server/src/test/python/stacks/2.0.6/HIVE/test_hive_service_check.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "46:                         stack_version = self.STACK_VERSION,",
          "47:                         target = RMFTestCase.TARGET_COMMON_SERVICES",
          "48:     )",
          "50:                               path = ['/bin/', '/usr/bin/', '/usr/lib/hive/bin/', '/usr/sbin/'],",
          "51:                               user = 'ambari-qa',",
          "52:                               timeout = 30,",
          "",
          "[Removed Lines]",
          "49:     self.assertResourceCalled('Execute', \"beeline -n hive -u 'jdbc:hive2://c6402.ambari.apache.org:10000/;transportMode=binary;auth=noSasl'  -e ';' 2>&1 | awk '{print}' | grep -i -e 'Connected to:' -e 'Transaction isolation:'\",",
          "",
          "[Added Lines]",
          "49:     self.assertResourceCalled('Execute', \"beeline -n hive -u 'jdbc:hive2://c6402.ambari.apache.org:10000/;transportMode=binary;auth=noSasl'  -e ';' 2>&1 | awk '{print}' | grep -i -e 'Connected to:' -e 'Transaction isolation:' -e 'inactive HS2 instance; use service discovery'\",",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "165:     self.assertResourceCalled('Execute', '/usr/bin/kinit -kt /etc/security/keytabs/smokeuser.headless.keytab ambari-qa@EXAMPLE.COM; ',",
          "166:                               user = 'ambari-qa',",
          "167:                               )",
          "169:                               path = ['/bin/', '/usr/bin/', '/usr/lib/hive/bin/', '/usr/sbin/'],",
          "170:                               user = 'ambari-qa',",
          "171:                               timeout = 30,",
          "",
          "[Removed Lines]",
          "168:     self.assertResourceCalled('Execute', \"beeline -n hive -u 'jdbc:hive2://c6402.ambari.apache.org:10000/;transportMode=binary;principal=hive/_HOST@EXAMPLE.COM'  -e ';' 2>&1 | awk '{print}' | grep -i -e 'Connected to:' -e 'Transaction isolation:'\",",
          "",
          "[Added Lines]",
          "168:     self.assertResourceCalled('Execute', \"beeline -n hive -u 'jdbc:hive2://c6402.ambari.apache.org:10000/;transportMode=binary;principal=hive/_HOST@EXAMPLE.COM'  -e ';' 2>&1 | awk '{print}' | grep -i -e 'Connected to:' -e 'Transaction isolation:' -e 'inactive HS2 instance; use service discovery'\",",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "283:       stack_version = self.STACK_VERSION,",
          "284:       target = RMFTestCase.TARGET_COMMON_SERVICES)",
          "287:       path = ['/bin/', '/usr/bin/', '/usr/lib/hive/bin/', '/usr/sbin/'],",
          "288:       timeout = 30,",
          "289:       user = 'ambari-qa',",
          "",
          "[Removed Lines]",
          "286:     self.assertResourceCalled('Execute', \"beeline -n hive -u 'jdbc:hive2://c6402.ambari.apache.org:10010/;transportMode=binary'  -e ';' 2>&1 | awk '{print}' | grep -i -e 'Connected to:' -e 'Transaction isolation:'\",",
          "",
          "[Added Lines]",
          "286:     self.assertResourceCalled('Execute', \"beeline -n hive -u 'jdbc:hive2://c6402.ambari.apache.org:10010/;transportMode=binary'  -e ';' 2>&1 | awk '{print}' | grep -i -e 'Connected to:' -e 'Transaction isolation:' -e 'inactive HS2 instance; use service discovery'\",",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "322:       target = RMFTestCase.TARGET_COMMON_SERVICES)",
          "324:     self.assertResourceCalled('Execute',",
          "326:       path = ['/bin/', '/usr/bin/', '/usr/lib/hive/bin/', '/usr/sbin/'],",
          "327:       timeout = 30,",
          "328:       user = 'ambari-qa',",
          "",
          "[Removed Lines]",
          "325:       \"beeline -n hive -u 'jdbc:hive2://c6402.ambari.apache.org:10010/;transportMode=binary'  -e ';' 2>&1 | awk '{print}' | grep -i -e 'Connected to:' -e 'Transaction isolation:'\",",
          "",
          "[Added Lines]",
          "325:       \"beeline -n hive -u 'jdbc:hive2://c6402.ambari.apache.org:10010/;transportMode=binary'  -e ';' 2>&1 | awk '{print}' | grep -i -e 'Connected to:' -e 'Transaction isolation:' -e 'inactive HS2 instance; use service discovery'\",",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "330:     )",
          "332:     self.assertResourceCalled('Execute',",
          "334:       path = ['/bin/', '/usr/bin/', '/usr/lib/hive/bin/', '/usr/sbin/'],",
          "335:       timeout = 30,",
          "336:       user = 'ambari-qa',",
          "",
          "[Removed Lines]",
          "333:       \"beeline -n hive -u 'jdbc:hive2://c6402.ambari.apache.org:10500/;transportMode=binary'  -e ';' 2>&1 | awk '{print}' | grep -i -e 'Connected to:' -e 'Transaction isolation:'\",",
          "",
          "[Added Lines]",
          "333:       \"beeline -n hive -u 'jdbc:hive2://c6402.ambari.apache.org:10500/;transportMode=binary'  -e ';' 2>&1 | awk '{print}' | grep -i -e 'Connected to:' -e 'Transaction isolation:' -e 'inactive HS2 instance; use service discovery'\",",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "ae93e6e5004f23f18e04434283371772ca4cedb6",
      "candidate_info": {
        "commit_hash": "ae93e6e5004f23f18e04434283371772ca4cedb6",
        "repo": "apache/ambari",
        "commit_url": "https://github.com/apache/ambari/commit/ae93e6e5004f23f18e04434283371772ca4cedb6",
        "files": [
          "contrib/management-packs/isilon-onefs-mpack/src/main/tools/hdfs_to_onefs_convert.py"
        ],
        "message": "AMBARI-25205. hdfs_to_onefs_convert.py script missing HDP3.1 + upgrade logic (amagyar) (#2940) (#2951)\n\n* AMBARI-25205. hdfs_to_onefs_convert.py script missing HDP3.1 + upgrade logic (amagyar)",
        "before_after_code_files": [
          "contrib/management-packs/isilon-onefs-mpack/src/main/tools/hdfs_to_onefs_convert.py||contrib/management-packs/isilon-onefs-mpack/src/main/tools/hdfs_to_onefs_convert.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/ambari/pull/3633",
          "https://github.com/apache/ambari/pull/3631",
          "https://github.com/apache/ambari/pull/3637",
          "https://github.com/apache/ambari/pull/3632",
          "https://github.com/apache/ambari/pull/3634",
          "https://github.com/apache/ambari/pull/3635"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "contrib/management-packs/isilon-onefs-mpack/src/main/tools/hdfs_to_onefs_convert.py||contrib/management-packs/isilon-onefs-mpack/src/main/tools/hdfs_to_onefs_convert.py": [
          "File: contrib/management-packs/isilon-onefs-mpack/src/main/tools/hdfs_to_onefs_convert.py -> contrib/management-packs/isilon-onefs-mpack/src/main/tools/hdfs_to_onefs_convert.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "370:   def __init__(self, cluster, storage):",
          "371:     self.cluster = cluster",
          "372:     self.storage = storage",
          "375:   def check_prerequisites(self):",
          "376:     print 'Checking %s' % self.cluster",
          "377:     ver = self.cluster.version()",
          "378:     print 'Found stack %s' % ver",
          "381:       return False",
          "382:     if not self.cluster.installed_stack().has_service('ONEFS'):",
          "383:       print 'ONEFS management pack is not installed.'",
          "",
          "[Removed Lines]",
          "373:     self.supported_stacks = ['HDP-3.0']",
          "379:     if ver not in self.supported_stacks:",
          "380:       print 'Only %s stacks are supported.' % self.supported_stacks",
          "",
          "[Added Lines]",
          "378:     if not ver.startswith('HDP-3.'):",
          "379:       print 'Only HDP-3.x stacks are supported.'",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "522:   print 'The following prerequisites are required:'",
          "523:   print '  * ONEFS management package must be installed'",
          "524:   print '  * Ambari must be upgraded to >=v2.7.0'",
          "526:   print '  * Is highly recommended to backup ambari database before you proceed.'",
          "527:   conversion = Conversion(cluster, FsStorage())",
          "528:   if not conversion.check_prerequisites():",
          "",
          "[Removed Lines]",
          "525:   print '  * Stack must be upgraded to HDP-3.0'",
          "",
          "[Added Lines]",
          "524:   print '  * Stack must be upgraded to >=HDP-3.0'",
          "",
          "---------------"
        ]
      }
    }
  ]
}