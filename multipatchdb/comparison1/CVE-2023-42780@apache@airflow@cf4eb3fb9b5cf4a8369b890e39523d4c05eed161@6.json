{
  "cve_id": "CVE-2023-42780",
  "cve_desc": "Apache Airflow, versions prior to 2.7.2, contains a security vulnerability that allows authenticated users of Airflow to list warnings for all DAGs, even if the user had no permission to see those DAGs. It would reveal the dag_ids and the stack-traces of import errors for those DAGs with import errors.\nUsers of Apache Airflow are advised to upgrade to version 2.7.2 or newer to mitigate the risk associated with this vulnerability.\n\n",
  "repo": "apache/airflow",
  "patch_hash": "cf4eb3fb9b5cf4a8369b890e39523d4c05eed161",
  "patch_info": {
    "commit_hash": "cf4eb3fb9b5cf4a8369b890e39523d4c05eed161",
    "repo": "apache/airflow",
    "commit_url": "https://github.com/apache/airflow/commit/cf4eb3fb9b5cf4a8369b890e39523d4c05eed161",
    "files": [
      "airflow/api_connexion/endpoints/dag_warning_endpoint.py",
      "tests/api_connexion/endpoints/test_dag_warning_endpoint.py"
    ],
    "message": "Fix dag warning endpoint permissions (#34355)\n\n* Fix dag warning endpoint permissions\n\n* update the query to have an accurate result for total entries and pagination\n\n* add unit tests\n\n* Update test_dag_warning_endpoint.py\n\nCo-authored-by: Tzu-ping Chung <uranusjr@gmail.com>\n\n---------\n\nCo-authored-by: Tzu-ping Chung <uranusjr@gmail.com>\n(cherry picked from commit 3570bbfbea69e2965f91b9964ce28bc268c68129)",
    "before_after_code_files": [
      "airflow/api_connexion/endpoints/dag_warning_endpoint.py||airflow/api_connexion/endpoints/dag_warning_endpoint.py",
      "tests/api_connexion/endpoints/test_dag_warning_endpoint.py||tests/api_connexion/endpoints/test_dag_warning_endpoint.py"
    ]
  },
  "patch_diff": {
    "airflow/api_connexion/endpoints/dag_warning_endpoint.py||airflow/api_connexion/endpoints/dag_warning_endpoint.py": [
      "File: airflow/api_connexion/endpoints/dag_warning_endpoint.py -> airflow/api_connexion/endpoints/dag_warning_endpoint.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "16: # under the License.",
      "17: from __future__ import annotations",
      "19: from sqlalchemy import select",
      "20: from sqlalchemy.orm import Session",
      "22: from airflow.api_connexion import security",
      "23: from airflow.api_connexion.parameters import apply_sorting, check_limit, format_parameters",
      "24: from airflow.api_connexion.schemas.dag_warning_schema import (",
      "25:     DagWarningCollection,",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "19: from flask import g",
      "24: from airflow.api_connexion.exceptions import PermissionDenied",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "28: from airflow.api_connexion.types import APIResponse",
      "29: from airflow.models.dagwarning import DagWarning as DagWarningModel",
      "30: from airflow.security import permissions",
      "31: from airflow.utils.db import get_query_count",
      "32: from airflow.utils.session import NEW_SESSION, provide_session",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "33: from airflow.utils.airflow_flask_app import get_airflow_app",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "52:     allowed_filter_attrs = [\"dag_id\", \"warning_type\", \"message\", \"timestamp\"]",
      "53:     query = select(DagWarningModel)",
      "54:     if dag_id:",
      "55:         query = query.where(DagWarningModel.dag_id == dag_id)",
      "56:     if warning_type:",
      "57:         query = query.where(DagWarningModel.warning_type == warning_type)",
      "58:     total_entries = get_query_count(query, session=session)",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "58:         if not get_airflow_app().appbuilder.sm.can_read_dag(dag_id, g.user):",
      "59:             raise PermissionDenied(detail=f\"User not allowed to access this DAG: {dag_id}\")",
      "61:     else:",
      "62:         readable_dags = get_airflow_app().appbuilder.sm.get_accessible_dag_ids(g.user)",
      "63:         query = query.where(DagWarningModel.dag_id.in_(readable_dags))",
      "",
      "---------------"
    ],
    "tests/api_connexion/endpoints/test_dag_warning_endpoint.py||tests/api_connexion/endpoints/test_dag_warning_endpoint.py": [
      "File: tests/api_connexion/endpoints/test_dag_warning_endpoint.py -> tests/api_connexion/endpoints/test_dag_warning_endpoint.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "35:         app,  # type:ignore",
      "36:         username=\"test\",",
      "37:         role_name=\"Test\",",
      "39:     )",
      "40:     create_user(app, username=\"test_no_permissions\", role_name=\"TestNoPermissions\")  # type: ignore",
      "42:     yield minimal_app_for_api",
      "44:     delete_user(app, username=\"test\")  # type: ignore",
      "45:     delete_user(app, username=\"test_no_permissions\")  # type: ignore",
      "48: class TestBaseDagWarning:",
      "",
      "[Removed Lines]",
      "38:         permissions=[(permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG_WARNING)],  # type: ignore",
      "",
      "[Added Lines]",
      "38:         permissions=[",
      "39:             (permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG_WARNING),",
      "40:             (permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG),",
      "41:         ],  # type: ignore",
      "44:     create_user(",
      "45:         app,  # type:ignore",
      "46:         username=\"test_with_dag2_read\",",
      "47:         role_name=\"TestWithDag2Read\",",
      "48:         permissions=[",
      "49:             (permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG_WARNING),",
      "50:             (permissions.ACTION_CAN_READ, f\"{permissions.RESOURCE_DAG_PREFIX}dag2\"),",
      "51:         ],  # type: ignore",
      "52:     )",
      "58:     delete_user(app, username=\"test_with_dag2_read\")  # type: ignore",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "147:             \"/api/v1/dagWarnings\", environ_overrides={\"REMOTE_USER\": \"test_no_permissions\"}",
      "148:         )",
      "149:         assert response.status_code == 403",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "164:     def test_should_raise_403_forbidden_when_user_has_no_dag_read_permission(self):",
      "165:         response = self.client.get(",
      "166:             \"/api/v1/dagWarnings\",",
      "167:             environ_overrides={\"REMOTE_USER\": \"test_with_dag2_read\"},",
      "168:             query_string={\"dag_id\": \"dag1\"},",
      "169:         )",
      "170:         assert response.status_code == 403",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "0389e6a3e98b948ae81fa8ff21d98f0c63856b16",
      "candidate_info": {
        "commit_hash": "0389e6a3e98b948ae81fa8ff21d98f0c63856b16",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/0389e6a3e98b948ae81fa8ff21d98f0c63856b16",
        "files": [
          ".pre-commit-config.yaml",
          "STATIC_CODE_CHECKS.rst",
          "dev/breeze/src/airflow_breeze/pre_commit_ids.py",
          "images/breeze/output-commands-hash.txt",
          "images/breeze/output_static-checks.svg",
          "pyproject.toml"
        ],
        "message": "Remove [project] section from `pyproject.toml` (#34014)\n\n* Add name and version of project into 'pyproject.toml'\n\n* Remove [project] section from `pyproject.toml`\n\n* Remove regex for update pyproject [project] version\n\n* Fight agains static checks\n\n(cherry picked from commit ba8ee909e4532318649df9c2d5a7ed70b357913d)",
        "before_after_code_files": [
          "dev/breeze/src/airflow_breeze/pre_commit_ids.py||dev/breeze/src/airflow_breeze/pre_commit_ids.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/34775"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "dev/breeze/src/airflow_breeze/pre_commit_ids.py||dev/breeze/src/airflow_breeze/pre_commit_ids.py": [
          "File: dev/breeze/src/airflow_breeze/pre_commit_ids.py -> dev/breeze/src/airflow_breeze/pre_commit_ids.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "124:     \"update-supported-versions\",",
          "125:     \"update-vendored-in-k8s-json-schema\",",
          "126:     \"update-version\",",
          "127:     \"yamllint\",",
          "128: ]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "127:     \"validate-pyproject\",",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "2a59e40a1220ffb037c8de112785bc7a4f2e03dc",
      "candidate_info": {
        "commit_hash": "2a59e40a1220ffb037c8de112785bc7a4f2e03dc",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/2a59e40a1220ffb037c8de112785bc7a4f2e03dc",
        "files": [
          "airflow/utils/dot_renderer.py",
          "airflow/www/views.py"
        ],
        "message": "Merge multiple isintance calls for the same object in a single call (#33767)\n\n(cherry picked from commit 5a1889a7e70114317b96fefa4b1e3f47ae15cc10)",
        "before_after_code_files": [
          "airflow/utils/dot_renderer.py||airflow/utils/dot_renderer.py",
          "airflow/www/views.py||airflow/www/views.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/34775"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/utils/dot_renderer.py||airflow/utils/dot_renderer.py": [
          "File: airflow/utils/dot_renderer.py -> airflow/utils/dot_renderer.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "120:     node: DependencyMixin, parent_graph: graphviz.Digraph, states_by_task_id: dict[str, str] | None",
          "121: ) -> None:",
          "122:     \"\"\"Draw the node and its children on the given parent_graph recursively.\"\"\"",
          "124:         _draw_task(node, parent_graph, states_by_task_id)",
          "125:     else:",
          "126:         if not isinstance(node, TaskGroup):",
          "",
          "[Removed Lines]",
          "123:     if isinstance(node, BaseOperator) or isinstance(node, MappedOperator):",
          "",
          "[Added Lines]",
          "123:     if isinstance(node, (BaseOperator, MappedOperator)):",
          "",
          "---------------"
        ],
        "airflow/www/views.py||airflow/www/views.py": [
          "File: airflow/www/views.py -> airflow/www/views.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "4256:             dag_ids: set[str] = set()",
          "4257:         elif isinstance(items, list):",
          "4258:             dag_ids = {item.dag_id for item in items if item is not None}",
          "4260:             dag_ids = {items.dag_id}",
          "4261:         else:",
          "4262:             raise ValueError(",
          "",
          "[Removed Lines]",
          "4259:         elif isinstance(items, TaskInstance) or isinstance(items, DagRun):",
          "",
          "[Added Lines]",
          "4259:         elif isinstance(items, (TaskInstance, DagRun)):",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "b2b603f47efa721de572222005c6968ce9ff3413",
      "candidate_info": {
        "commit_hash": "b2b603f47efa721de572222005c6968ce9ff3413",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/b2b603f47efa721de572222005c6968ce9ff3413",
        "files": [
          "airflow/settings.py"
        ],
        "message": "Move default timezone to except block (#34245)\n\n(cherry picked from commit 7efc68c8e351c9aa1f9fa66bc67f325749396b6b)",
        "before_after_code_files": [
          "airflow/settings.py||airflow/settings.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/34775"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/settings.py||airflow/settings.py": [
          "File: airflow/settings.py -> airflow/settings.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "48: log = logging.getLogger(__name__)",
          "52: try:",
          "53:     tz = conf.get_mandatory_value(\"core\", \"default_timezone\")",
          "54:     if tz == \"system\":",
          "",
          "[Removed Lines]",
          "51: TIMEZONE = pendulum.tz.timezone(\"UTC\")",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "56:     else:",
          "57:         TIMEZONE = pendulum.tz.timezone(tz)",
          "58: except Exception:",
          "60: log.info(\"Configured default timezone %s\", TIMEZONE)",
          "",
          "[Removed Lines]",
          "59:     pass",
          "",
          "[Added Lines]",
          "57:     TIMEZONE = pendulum.tz.timezone(\"UTC\")",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "4ff30e37f0784f8e3ca896e104a4873655894743",
      "candidate_info": {
        "commit_hash": "4ff30e37f0784f8e3ca896e104a4873655894743",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/4ff30e37f0784f8e3ca896e104a4873655894743",
        "files": [
          "airflow/www/templates/airflow/cluster_activity.html"
        ],
        "message": "Fix www cluster_activity view not loading due to standaloneDagProcessor templating (#34274)\n\n(cherry picked from commit 3d8ea7926517cf2aa54f8daad8ea122a7f6efe9a)",
        "before_after_code_files": [
          "airflow/www/templates/airflow/cluster_activity.html||airflow/www/templates/airflow/cluster_activity.html"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/34775"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/www/templates/airflow/cluster_activity.html||airflow/www/templates/airflow/cluster_activity.html": [
          "File: airflow/www/templates/airflow/cluster_activity.html -> airflow/www/templates/airflow/cluster_activity.html",
          "--- Hunk 1 ---",
          "[Context before]",
          "43:   <script>",
          "44:     const stateColors = {{ state_color_mapping|tojson }};",
          "45:     const autoRefreshInterval = {{ auto_refresh_interval }};",
          "47:   </script>",
          "48:   <script src=\"{{ url_for_asset('clusterActivity.js') }}\"></script>",
          "49: {% endblock %}",
          "",
          "[Removed Lines]",
          "46:     const standaloneDagProcessor = {{ standalone_dag_processor }} === 'True' ;",
          "",
          "[Added Lines]",
          "46:     const standaloneDagProcessor = {{ standalone_dag_processor|tojson }} === true ;",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "c5542335c6bac2fdc94ed973e365b522e56aaaf5",
      "candidate_info": {
        "commit_hash": "c5542335c6bac2fdc94ed973e365b522e56aaaf5",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/c5542335c6bac2fdc94ed973e365b522e56aaaf5",
        "files": [
          "airflow/decorators/base.py"
        ],
        "message": "Replace assert by if...raise in decorators package (#34250)\n\n(cherry picked from commit 0470f3af6ddeda0917cd3a0616fa3206bad00236)",
        "before_after_code_files": [
          "airflow/decorators/base.py||airflow/decorators/base.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/34775"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/decorators/base.py||airflow/decorators/base.py": [
          "File: airflow/decorators/base.py -> airflow/decorators/base.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "524:     def _expand_mapped_kwargs(self, context: Context, session: Session) -> tuple[Mapping[str, Any], set[int]]:",
          "525:         # We only use op_kwargs_expand_input so this must always be empty.",
          "527:         op_kwargs, resolved_oids = super()._expand_mapped_kwargs(context, session)",
          "528:         return {\"op_kwargs\": op_kwargs}, resolved_oids",
          "",
          "[Removed Lines]",
          "526:         assert self.expand_input is EXPAND_INPUT_EMPTY",
          "",
          "[Added Lines]",
          "526:         if self.expand_input is not EXPAND_INPUT_EMPTY:",
          "527:             raise AssertionError(f\"unexpected expand_input: {self.expand_input}\")",
          "",
          "---------------"
        ]
      }
    }
  ]
}