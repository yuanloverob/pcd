{
  "cve_id": "CVE-2021-45229",
  "cve_desc": "It was discovered that the \"Trigger DAG with config\" screen was susceptible to XSS attacks via the `origin` query argument. This issue affects Apache Airflow versions 2.2.3 and below.",
  "repo": "apache/airflow",
  "patch_hash": "628aa1f99c865d97d0b1c7c76e630e43a7b8d319",
  "patch_info": {
    "commit_hash": "628aa1f99c865d97d0b1c7c76e630e43a7b8d319",
    "repo": "apache/airflow",
    "commit_url": "https://github.com/apache/airflow/commit/628aa1f99c865d97d0b1c7c76e630e43a7b8d319",
    "files": [
      "airflow/www/templates/airflow/trigger.html",
      "tests/www/views/test_views_trigger_dag.py"
    ],
    "message": "Simplify trigger cancel button (#21591)\n\nCo-authored-by: Jed Cunningham <jedcunningham@apache.org>\n(cherry picked from commit 65297673a318660fba76797e50d0c06804dfcafc)",
    "before_after_code_files": [
      "airflow/www/templates/airflow/trigger.html||airflow/www/templates/airflow/trigger.html",
      "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py"
    ]
  },
  "patch_diff": {
    "airflow/www/templates/airflow/trigger.html||airflow/www/templates/airflow/trigger.html": [
      "File: airflow/www/templates/airflow/trigger.html -> airflow/www/templates/airflow/trigger.html",
      "--- Hunk 1 ---",
      "[Context before]",
      "63:       </label>",
      "64:     </div>",
      "65:     <button type=\"submit\" class=\"btn btn-primary\">Trigger</button>",
      "67:   </form>",
      "68: {% endblock %}",
      "",
      "[Removed Lines]",
      "66:     <button type=\"button\" class=\"btn\" onclick=\"location.href = '{{ origin }}'; return false\">Cancel</button>",
      "",
      "[Added Lines]",
      "66:     <a class=\"btn\" href=\"{{ origin }}\">Cancel</a>",
      "",
      "---------------"
    ],
    "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py": [
      "File: tests/www/views/test_views_trigger_dag.py -> tests/www/views/test_views_trigger_dag.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "133:         (\"javascript:alert(1)\", \"/home\"),",
      "134:         (\"http://google.com\", \"/home\"),",
      "135:         (\"36539'%3balert(1)%2f%2f166\", \"/home\"),",
      "136:         (",
      "137:             \"%2Ftree%3Fdag_id%3Dexample_bash_operator';alert(33)//\",",
      "138:             \"/home\",",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "136:         (",
      "137:             '\"><script>alert(99)</script><a href=\"',",
      "138:             \"&#34;&gt;&lt;script&gt;alert(99)&lt;/script&gt;&lt;a href=&#34;\",",
      "139:         ),",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "145:     test_dag_id = \"example_bash_operator\"",
      "147:     resp = admin_client.get(f'trigger?dag_id={test_dag_id}&origin={test_origin}')",
      "156: @pytest.mark.parametrize(",
      "",
      "[Removed Lines]",
      "148:     check_content_in_response(",
      "149:         '<button type=\"button\" class=\"btn\" onclick=\"location.href = \\'{}\\'; return false\">'.format(",
      "150:             expected_origin",
      "151:         ),",
      "152:         resp,",
      "153:     )",
      "",
      "[Added Lines]",
      "152:     check_content_in_response(f'<a class=\"btn\" href=\"{expected_origin}\">Cancel</a>', resp)",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "b96093d08f672b08d43236dfaeca6ccfc9b485ca",
      "candidate_info": {
        "commit_hash": "b96093d08f672b08d43236dfaeca6ccfc9b485ca",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/b96093d08f672b08d43236dfaeca6ccfc9b485ca",
        "files": [
          "tests/dag_processing/test_manager.py",
          "tests/task/task_runner/test_standard_task_runner.py"
        ],
        "message": "Fix OOM error in tests when using public Github Runners. (#19809)\n\nThere was a side effect caused by th TestStandardRunner\ntest that caused broken logging configuration,\nwhich in turn created OutOfMemory condition for our Public\nGitHubRunners.\n\nThe problem was that the test overrode the configuration of\nlogging with some simple test configuration, but never restored\nthe default configuration, which resulted in airflow.processor\nlogger that was created before contain empty handlers. Since\nthe airflow.processor logger has \"propagate\" set to False,\nempty handlers normally cause a lastResort handler call, which\nby default redirects everything to Stderr and this is what\nhappened in DagFile Processor tests. However, DagFileProcessor\nuses stderr_redirect which replaces sys.stderr with provided\nstream. In this case however the stream set (StreamLogWriter)\nredirected the output to \"airflow.processor\" logger - which in\nturn (as last resort) redirected everything to sys.stderr which\nin turn redirected everything to \"airflow.processor\" logger etc.\n\nThis resulted in:\n\n* OOM condition in Public GitHub Runners\n* DagFileProcessor failing with exceeded recursion depth when\n  there was enough memory to get there.\n\nThe condition was triggered by two preceding tests:\n\n1) First test_plugins_manger.py initialized logging for\n   airflow.processor and stored it in logging manager\n2) The TestStandardTaskRunner test applied simpler configuration\n   but the way configure() works - it did not remove the\n   \"airflow.processor\" logger, but it REMOVED all handlers\n   registered for it - and never restored the default configuration\n3) The DagFileProcessor logs caused infinite recursion\n\nThe fix is two-fold:\n\n* the TestStandardTaskRunner restores default config after test\n* the DagFileProcessor sets default config before starting\n\n(cherry picked from commit 14bff79bf271cd63cc6e3b98dc4aa232001472cb)",
        "before_after_code_files": [
          "tests/dag_processing/test_manager.py||tests/dag_processing/test_manager.py",
          "tests/task/task_runner/test_standard_task_runner.py||tests/task/task_runner/test_standard_task_runner.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "tests/dag_processing/test_manager.py||tests/dag_processing/test_manager.py": [
          "File: tests/dag_processing/test_manager.py -> tests/dag_processing/test_manager.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "26: import threading",
          "27: import unittest",
          "28: from datetime import datetime, timedelta",
          "29: from tempfile import TemporaryDirectory",
          "30: from textwrap import dedent",
          "31: from unittest import mock",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "29: from logging.config import dictConfig",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "34: import pytest",
          "35: from freezegun import freeze_time",
          "37: from airflow.configuration import conf",
          "38: from airflow.dag_processing.manager import (",
          "39:     DagFileProcessorAgent,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "38: from airflow.config_templates.airflow_local_settings import DEFAULT_LOGGING_CONFIG",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "112: class TestDagFileProcessorManager:",
          "113:     def setup_method(self):",
          "114:         clear_db_runs()",
          "115:         clear_db_serialized_dags()",
          "116:         clear_db_dags()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "116:         dictConfig(DEFAULT_LOGGING_CONFIG)",
          "",
          "---------------"
        ],
        "tests/task/task_runner/test_standard_task_runner.py||tests/task/task_runner/test_standard_task_runner.py": [
          "File: tests/task/task_runner/test_standard_task_runner.py -> tests/task/task_runner/test_standard_task_runner.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "24: import psutil",
          "25: import pytest",
          "27: from airflow.jobs.local_task_job import LocalTaskJob",
          "28: from airflow.models.dagbag import DagBag",
          "29: from airflow.models.taskinstance import TaskInstance",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "27: from airflow.config_templates.airflow_local_settings import DEFAULT_LOGGING_CONFIG",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "70:         airflow_logger = logging.getLogger('airflow')",
          "71:         airflow_logger.handlers = []",
          "72:         clear_db_runs()",
          "74:     def test_start_and_terminate(self):",
          "75:         local_task_job = mock.Mock()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "74:         dictConfig(DEFAULT_LOGGING_CONFIG)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "70c58699f17612ecb02ae713d92a58e2748827cb",
      "candidate_info": {
        "commit_hash": "70c58699f17612ecb02ae713d92a58e2748827cb",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/70c58699f17612ecb02ae713d92a58e2748827cb",
        "files": [
          ".pre-commit-config.yaml",
          "scripts/ci/pre_commit/pre_commit_flake8.sh",
          "scripts/ci/pre_commit/pre_commit_mypy.sh"
        ],
        "message": "Temporarily remove mypy checks to stop PRs from failing (#19345)\n\nAfter we moved to Python 3.7 as default, it had a ripple effect\nthat MyPy checks started failing. We aim to fix it\npermanently in #19334 but this needs a bit more changes, so for\nthe moment we skip the checks.\n\n(cherry picked from commit 1f0db2885c338d51fe9b8d39b56d74cc376a6c8f)",
        "before_after_code_files": [
          "scripts/ci/pre_commit/pre_commit_flake8.sh||scripts/ci/pre_commit/pre_commit_flake8.sh",
          "scripts/ci/pre_commit/pre_commit_mypy.sh||scripts/ci/pre_commit/pre_commit_mypy.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "scripts/ci/pre_commit/pre_commit_flake8.sh||scripts/ci/pre_commit/pre_commit_flake8.sh": [
          "File: scripts/ci/pre_commit/pre_commit_flake8.sh -> scripts/ci/pre_commit/pre_commit_flake8.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "15: # KIND, either express or implied.  See the License for the",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "19: export FORCE_ANSWER_TO_QUESTIONS=${FORCE_ANSWER_TO_QUESTIONS:=\"quit\"}",
          "20: export REMEMBER_LAST_ANSWER=\"true\"",
          "21: export PRINT_INFO_FROM_SCRIPTS=\"false\"",
          "",
          "[Removed Lines]",
          "18: export PYTHON_MAJOR_MINOR_VERSION=\"3.6\"",
          "",
          "[Added Lines]",
          "18: export PYTHON_MAJOR_MINOR_VERSION=\"3.7\"",
          "",
          "---------------"
        ],
        "scripts/ci/pre_commit/pre_commit_mypy.sh||scripts/ci/pre_commit/pre_commit_mypy.sh": [
          "File: scripts/ci/pre_commit/pre_commit_mypy.sh -> scripts/ci/pre_commit/pre_commit_mypy.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "15: # KIND, either express or implied.  See the License for the",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "19: export FORCE_ANSWER_TO_QUESTIONS=${FORCE_ANSWER_TO_QUESTIONS:=\"quit\"}",
          "20: export REMEMBER_LAST_ANSWER=\"true\"",
          "21: export PRINT_INFO_FROM_SCRIPTS=\"false\"",
          "23: # shellcheck source=scripts/ci/static_checks/mypy.sh",
          "24: . \"$( dirname \"${BASH_SOURCE[0]}\" )/../static_checks/mypy.sh\" \"${@}\"",
          "",
          "[Removed Lines]",
          "18: export PYTHON_MAJOR_MINOR_VERSION=\"3.6\"",
          "",
          "[Added Lines]",
          "18: export PYTHON_MAJOR_MINOR_VERSION=\"3.7\"",
          "23: # Temporarily remove mypy checks until we fix them for Python 3.7",
          "24: exit 0",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "84082d3fdb56a07c641709d8327261eb8718e0b1",
      "candidate_info": {
        "commit_hash": "84082d3fdb56a07c641709d8327261eb8718e0b1",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/84082d3fdb56a07c641709d8327261eb8718e0b1",
        "files": [
          "dev/retag_docker_images.py"
        ],
        "message": "Add retagging images accross repos (#19778)\n\nUseful to refresh cache images to a different repository - in\norder to speed up builds there.\n\n(cherry picked from commit bccb45f5fe067ffa64f5f303bfbb6e8c1b552add)",
        "before_after_code_files": [
          "dev/retag_docker_images.py||dev/retag_docker_images.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "dev/retag_docker_images.py||dev/retag_docker_images.py": [
          "File: dev/retag_docker_images.py -> dev/retag_docker_images.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "34: PYTHON_VERSIONS = [\"3.6\", \"3.7\", \"3.8\", \"3.9\"]",
          "38: GHCR_IO_IMAGES = [",
          "44: ]",
          "47: # noinspection StrFormat",
          "48: def pull_push_all_images(",
          "50: ):",
          "51:     for python_version in PYTHON_VERSIONS:",
          "52:         for image in images:",
          "53:             source_image = image.format(",
          "55:             )",
          "56:             target_image = image.format(",
          "58:             )",
          "59:             print(f\"Copying image: {source_image} -> {target_image}\")",
          "60:             subprocess.run([\"docker\", \"pull\", source_image], check=True)",
          "",
          "[Removed Lines]",
          "36: GHCR_IO_PREFIX = \"ghcr.io/apache/airflow\"",
          "39:     \"{prefix}/{branch}/ci-manifest/python{python_version}:latest\",",
          "40:     \"{prefix}/{branch}/ci/python{python_version}:latest\",",
          "41:     \"{prefix}/{branch}/prod-build/python{python_version}-build:latest\",",
          "42:     \"{prefix}/{branch}/prod/python{python_version}-build:latest\",",
          "43:     \"{prefix}/{branch}/python:{python_version}-slim-buster\",",
          "49:     source_prefix: str, target_prefix: str, images: List[str], source_branch: str, target_branch: str",
          "54:                 prefix=source_prefix, branch=source_branch, python_version=python_version",
          "57:                 prefix=target_prefix, branch=target_branch, python_version=python_version",
          "",
          "[Added Lines]",
          "36: GHCR_IO_PREFIX = \"ghcr.io\"",
          "40:     \"{prefix}/{repo}/{branch}/ci-manifest/python{python_version}:latest\",",
          "41:     \"{prefix}/{repo}/{branch}/ci/python{python_version}:latest\",",
          "42:     \"{prefix}/{repo}/{branch}/prod-build/python{python_version}:latest\",",
          "43:     \"{prefix}/{repo}/{branch}/prod/python{python_version}:latest\",",
          "44:     \"{prefix}/{repo}/{branch}/python:{python_version}-slim-buster\",",
          "50:     source_prefix: str,",
          "51:     target_prefix: str,",
          "52:     images: List[str],",
          "53:     source_branch: str,",
          "54:     source_repo: str,",
          "55:     target_branch: str,",
          "56:     target_repo: str,",
          "61:                 prefix=source_prefix, branch=source_branch, repo=source_repo, python_version=python_version",
          "64:                 prefix=target_prefix, branch=target_branch, repo=target_repo, python_version=python_version",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "65: @click.group(invoke_without_command=True)",
          "66: @click.option(\"--source-branch\", type=str, default=\"main\", help=\"Source branch name [main]\")",
          "67: @click.option(\"--target-branch\", type=str, default=\"main\", help=\"Target branch name [main]\")",
          "68: def main(",
          "69:     source_branch: str,",
          "70:     target_branch: str,",
          "71: ):",
          "75: if __name__ == \"__main__\":",
          "",
          "[Removed Lines]",
          "72:     pull_push_all_images(GHCR_IO_PREFIX, GHCR_IO_PREFIX, GHCR_IO_IMAGES, source_branch, target_branch)",
          "",
          "[Added Lines]",
          "75: @click.option(\"--source-repo\", type=str, default=\"apache/airflow\", help=\"Source repo\")",
          "76: @click.option(\"--target-repo\", type=str, default=\"apache/airflow\", help=\"Target repo\")",
          "80:     source_repo: str,",
          "81:     target_repo: str,",
          "83:     pull_push_all_images(",
          "84:         GHCR_IO_PREFIX, GHCR_IO_PREFIX, GHCR_IO_IMAGES, source_branch, source_repo, target_branch, target_repo",
          "85:     )",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "ef817be1346d28490f85e53ecabf8e938579cd03",
      "candidate_info": {
        "commit_hash": "ef817be1346d28490f85e53ecabf8e938579cd03",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/ef817be1346d28490f85e53ecabf8e938579cd03",
        "files": [
          "scripts/ci/libraries/_initialization.sh"
        ],
        "message": "Fix comparision of docker versions (#18902)\n\nIn some shells the comparable string with version was too long.\nThe number leading with 0 was interpreted as octal number and\nit had too many digits for octal number to handle.\n\nThis change;\n\n1) decreases the length of the string by using 3-digit numbers\n2) strips leading 0s during comparision making comparision work\n   in decimal\n\n(cherry picked from commit a05f0c37951a222c4764b4c910f78733eee0556f)",
        "before_after_code_files": [
          "scripts/ci/libraries/_initialization.sh||scripts/ci/libraries/_initialization.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "scripts/ci/libraries/_initialization.sh||scripts/ci/libraries/_initialization.sh": [
          "File: scripts/ci/libraries/_initialization.sh -> scripts/ci/libraries/_initialization.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "925:         echo \"${1}=${2}\" >>\"${GITHUB_ENV}\"",
          "926:     fi",
          "927: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "929: function initialization::ver() {",
          "930:   # convert SemVer number to comparable string (strips pre-release version)",
          "931:   # shellcheck disable=SC2086,SC2183",
          "932:   printf \"%03d%03d%03d%.0s\" ${1//[.-]/}",
          "933: }",
          "935: function initialization::check_docker_version() {",
          "936:     local docker_version",
          "937:     # In GitHub Code QL, the version of docker has +azure suffix which we should remove",
          "938:     docker_version=$(docker version --format '{{.Client.Version}}' | sed 's/\\+.*$//' || true)",
          "939:     if [ \"${docker_version}\" == \"\" ]; then",
          "940:         echo",
          "941:         echo \"${COLOR_YELLOW}Your version of docker is unknown. If the scripts faill, please make sure to install docker at least: ${min_docker_version} version.${COLOR_RESET}\"",
          "942:         echo",
          "943:         return",
          "944:     fi",
          "945:     local comparable_docker_version",
          "946:     comparable_docker_version=$(initialization::ver \"${docker_version}\")",
          "947:     local min_docker_version=\"20.10.0\"",
          "948:     local min_comparable_docker_version",
          "949:     min_comparable_docker_version=$(initialization::ver \"${min_docker_version}\")",
          "950:     # The #0 Strips leading zeros",
          "951:     if [[ ${comparable_docker_version#0} -lt ${min_comparable_docker_version#0} ]]; then",
          "952:         echo",
          "953:         echo \"${COLOR_RED}Your version of docker is too old: ${docker_version}. Please upgrade to at least ${min_docker_version}.${COLOR_RESET}\"",
          "954:         echo",
          "955:         exit 1",
          "956:     else",
          "957:         if [[ ${PRINT_INFO_FROM_SCRIPTS} != \"false\" ]]; then",
          "958:             echo \"${COLOR_GREEN}Good version of docker ${docker_version}.${COLOR_RESET}\"",
          "959:         fi",
          "960:     fi",
          "961: }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "371ae8f542d48b18d02d1d85b0949882c67c0d07",
      "candidate_info": {
        "commit_hash": "371ae8f542d48b18d02d1d85b0949882c67c0d07",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/371ae8f542d48b18d02d1d85b0949882c67c0d07",
        "files": [
          "scripts/ci/testing/ci_run_single_airflow_test_in_docker.sh"
        ],
        "message": "Fix dumping container logs on error (#19645)\n\nWhen we optimized tests for memory use we added cleanup of all\ncontainers after each test suite. Unfortunately it caused\ndumping container logs to stop working because this dumping was\ndone only only when the script was exiting.\n\nThis PR moves dumping container logs to between the test run and\ncleanup, so that we can see the logs when there is a test failure.\n\nRelated to: #19633 where the logs were not dumped and it made the\nanalysis much more difficult.\n\n(cherry picked from commit 7cda7d4b5e413925bf639976e77ebf2442b4bff9)",
        "before_after_code_files": [
          "scripts/ci/testing/ci_run_single_airflow_test_in_docker.sh||scripts/ci/testing/ci_run_single_airflow_test_in_docker.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "scripts/ci/testing/ci_run_single_airflow_test_in_docker.sh||scripts/ci/testing/ci_run_single_airflow_test_in_docker.sh": [
          "File: scripts/ci/testing/ci_run_single_airflow_test_in_docker.sh -> scripts/ci/testing/ci_run_single_airflow_test_in_docker.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "127:          run airflow \"${@}\"",
          "128:     docker ps",
          "129:     exit_code=$?",
          "131:     if [[ ${exit_code} != \"0\" && ${CI} == \"true\" ]]; then",
          "132:         docker ps --all",
          "133:         local container",
          "",
          "[Removed Lines]",
          "130:     docker ps",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ]
      }
    }
  ]
}