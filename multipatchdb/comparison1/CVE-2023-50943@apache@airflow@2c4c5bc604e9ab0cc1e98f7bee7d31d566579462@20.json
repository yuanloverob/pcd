{
  "cve_id": "CVE-2023-50943",
  "cve_desc": "Apache Airflow, versions before 2.8.1, have a vulnerability that allows a potential attacker to poison the XCom data by bypassing the protection of \"enable_xcom_pickling=False\" configuration setting resulting in poisoned data after XCom deserialization. This vulnerability is considered low since it requires a DAG author to exploit it. Users are recommended to upgrade to version 2.8.1 or later, which fixes this issue.",
  "repo": "apache/airflow",
  "patch_hash": "2c4c5bc604e9ab0cc1e98f7bee7d31d566579462",
  "patch_info": {
    "commit_hash": "2c4c5bc604e9ab0cc1e98f7bee7d31d566579462",
    "repo": "apache/airflow",
    "commit_url": "https://github.com/apache/airflow/commit/2c4c5bc604e9ab0cc1e98f7bee7d31d566579462",
    "files": [
      "airflow/models/xcom.py",
      "tests/api_connexion/schemas/test_xcom_schema.py",
      "tests/models/test_xcom.py"
    ],
    "message": "Stop deserializing pickle when enable_xcom_pickling is False (#36255)\n\n* Stop deserializing pickle when enable_xcom_pickling is False\n\n* Fix unit tests\n\n(cherry picked from commit 63e97abec5d56bc62a293c93f5227f364561e51c)",
    "before_after_code_files": [
      "airflow/models/xcom.py||airflow/models/xcom.py",
      "tests/api_connexion/schemas/test_xcom_schema.py||tests/api_connexion/schemas/test_xcom_schema.py",
      "tests/models/test_xcom.py||tests/models/test_xcom.py"
    ]
  },
  "patch_diff": {
    "airflow/models/xcom.py||airflow/models/xcom.py": [
      "File: airflow/models/xcom.py -> airflow/models/xcom.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "685:             except pickle.UnpicklingError:",
      "686:                 return json.loads(result.value.decode(\"UTF-8\"), cls=XComDecoder, object_hook=object_hook)",
      "687:         else:",
      "693:     @staticmethod",
      "694:     def deserialize_value(result: XCom) -> Any:",
      "",
      "[Removed Lines]",
      "688:             try:",
      "689:                 return json.loads(result.value.decode(\"UTF-8\"), cls=XComDecoder, object_hook=object_hook)",
      "690:             except (json.JSONDecodeError, UnicodeDecodeError):",
      "691:                 return pickle.loads(result.value)",
      "",
      "[Added Lines]",
      "688:             # Since xcom_pickling is disabled, we should only try to deserialize with JSON",
      "689:             return json.loads(result.value.decode(\"UTF-8\"), cls=XComDecoder, object_hook=object_hook)",
      "",
      "---------------"
    ],
    "tests/api_connexion/schemas/test_xcom_schema.py||tests/api_connexion/schemas/test_xcom_schema.py": [
      "File: tests/api_connexion/schemas/test_xcom_schema.py -> tests/api_connexion/schemas/test_xcom_schema.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "30: from airflow.models import DagRun, XCom",
      "31: from airflow.utils.dates import parse_execution_date",
      "32: from airflow.utils.session import create_session",
      "34: pytestmark = pytest.mark.db_test",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "33: from tests.test_utils.config import conf_vars",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "188:     default_time = \"2016-04-02T21:00:00+00:00\"",
      "189:     default_time_parsed = parse_execution_date(default_time)",
      "191:     def test_serialize(self, create_xcom, session):",
      "192:         create_xcom(",
      "193:             dag_id=\"test_dag\",",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "192:     @conf_vars({(\"core\", \"enable_xcom_pickling\"): \"True\"})",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "208:             \"map_index\": -1,",
      "209:         }",
      "211:     def test_deserialize(self):",
      "212:         xcom_dump = {",
      "213:             \"key\": \"test_key\",",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "213:     @conf_vars({(\"core\", \"enable_xcom_pickling\"): \"True\"})",
      "",
      "---------------"
    ],
    "tests/models/test_xcom.py||tests/models/test_xcom.py": [
      "File: tests/models/test_xcom.py -> tests/models/test_xcom.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "140:             ret_value = XCom.get_value(key=\"xcom_test3\", ti_key=ti_key, session=session)",
      "141:         assert ret_value == {\"key\": \"value\"}",
      "144:         with conf_vars({(\"core\", \"enable_xcom_pickling\"): \"True\"}):",
      "145:             XCom.set(",
      "146:                 key=\"xcom_test3\",",
      "",
      "[Removed Lines]",
      "143:     def test_xcom_deserialize_with_pickle_to_json_switch(self, task_instance, session):",
      "",
      "[Added Lines]",
      "143:     def test_xcom_deserialize_pickle_when_xcom_pickling_is_disabled(self, task_instance, session):",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "151:                 session=session,",
      "152:             )",
      "153:         with conf_vars({(\"core\", \"enable_xcom_pickling\"): \"False\"}):",
      "163:     @conf_vars({(\"core\", \"xcom_enable_pickling\"): \"False\"})",
      "164:     def test_xcom_disable_pickle_type_fail_on_non_json(self, task_instance, session):",
      "",
      "[Removed Lines]",
      "154:             ret_value = XCom.get_one(",
      "155:                 key=\"xcom_test3\",",
      "156:                 dag_id=task_instance.dag_id,",
      "157:                 task_id=task_instance.task_id,",
      "158:                 run_id=task_instance.run_id,",
      "159:                 session=session,",
      "160:             )",
      "161:         assert ret_value == {\"key\": \"value\"}",
      "",
      "[Added Lines]",
      "154:             with pytest.raises(UnicodeDecodeError):",
      "155:                 XCom.get_one(",
      "156:                     key=\"xcom_test3\",",
      "157:                     dag_id=task_instance.dag_id,",
      "158:                     task_id=task_instance.task_id,",
      "159:                     run_id=task_instance.run_id,",
      "160:                     session=session,",
      "161:                 )",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "8986f8f3beba11cf568e0f014883b997e4042f7b",
      "candidate_info": {
        "commit_hash": "8986f8f3beba11cf568e0f014883b997e4042f7b",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/8986f8f3beba11cf568e0f014883b997e4042f7b",
        "files": [
          "dev/breeze/src/airflow_breeze/params/shell_params.py",
          "dev/breeze/src/airflow_breeze/utils/docker_command_utils.py",
          "scripts/in_container/install_airflow_and_providers.py"
        ],
        "message": "Fix using extras when `--use-airflow-version` is used in Breeze (#36280)\n\nWhen we are installing a released version of Airflow in Breeze, we can\npass additional extras to install (For example, we need to pass celery\nextra in order to start airflow with celery executor.\n\nThe extras could be specified as:\n\n```\nbreeze start-airflow --use-airflow-version 2.8.0rc4  \\\n  --executor CeleryExecutor --airflow-extras \"celery\"\n\n```\n\nHowever recent refactors caused a problem that the extras added were\nspecified after version (which is rejected by newer versions of `pip`).\n\nThis PR fixes it and also moves the place where CeleryExecutor use\ntriggers adding celery extra when`--use-airflow-version` is used.\n\nThe warning about this is better visible when moving to Shell Params.\n\n(cherry picked from commit 329780649543ab7b9d593a2e2428073fbd4cf274)",
        "before_after_code_files": [
          "dev/breeze/src/airflow_breeze/params/shell_params.py||dev/breeze/src/airflow_breeze/params/shell_params.py",
          "dev/breeze/src/airflow_breeze/utils/docker_command_utils.py||dev/breeze/src/airflow_breeze/utils/docker_command_utils.py",
          "scripts/in_container/install_airflow_and_providers.py||scripts/in_container/install_airflow_and_providers.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "dev/breeze/src/airflow_breeze/params/shell_params.py||dev/breeze/src/airflow_breeze/params/shell_params.py": [
          "File: dev/breeze/src/airflow_breeze/params/shell_params.py -> dev/breeze/src/airflow_breeze/params/shell_params.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "329:         if self.executor == \"CeleryExecutor\":",
          "330:             compose_file_list.append(DOCKER_COMPOSE_DIR / \"integration-celery.yml\")",
          "332:         compose_file_list.append(DOCKER_COMPOSE_DIR / \"base.yml\")",
          "333:         self.add_docker_in_docker(compose_file_list)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "331:             if self.use_airflow_version:",
          "332:                 current_extras = self.airflow_extras",
          "333:                 if \"celery\" not in current_extras.split(\",\"):",
          "334:                     get_console().print(",
          "335:                         \"[warning]Adding `celery` extras as it is implicitly needed by celery executor\"",
          "336:                     )",
          "337:                     self.airflow_extras = \",\".join(current_extras.split(\",\") + [\"celery\"])",
          "",
          "---------------"
        ],
        "dev/breeze/src/airflow_breeze/utils/docker_command_utils.py||dev/breeze/src/airflow_breeze/utils/docker_command_utils.py": [
          "File: dev/breeze/src/airflow_breeze/utils/docker_command_utils.py -> dev/breeze/src/airflow_breeze/utils/docker_command_utils.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "751:             f\"Changing the executor to {SEQUENTIAL_EXECUTOR}.\\n\"",
          "752:         )",
          "753:         shell_params.executor = SEQUENTIAL_EXECUTOR",
          "768:     if shell_params.restart:",
          "769:         bring_compose_project_down(preserve_volumes=False, shell_params=shell_params)",
          "770:     if shell_params.include_mypy_volume:",
          "",
          "[Removed Lines]",
          "755:     if shell_params.executor == \"CeleryExecutor\" and shell_params.use_airflow_version:",
          "756:         if shell_params.airflow_extras and \"celery\" not in shell_params.airflow_extras.split():",
          "757:             get_console().print(",
          "758:                 f\"\\n[warning]CeleryExecutor requires airflow_extras: celery. \"",
          "759:                 f\"Adding celery to extras: '{shell_params.airflow_extras}'.\\n\"",
          "760:             )",
          "761:             shell_params.airflow_extras += \",celery\"",
          "762:         elif not shell_params.airflow_extras:",
          "763:             get_console().print(",
          "764:                 \"\\n[warning]CeleryExecutor requires airflow_extras: celery. \"",
          "765:                 \"Setting airflow extras to 'celery'.\\n\"",
          "766:             )",
          "767:             shell_params.airflow_extras = \"celery\"",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "scripts/in_container/install_airflow_and_providers.py||scripts/in_container/install_airflow_and_providers.py": [
          "File: scripts/in_container/install_airflow_and_providers.py -> scripts/in_container/install_airflow_and_providers.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "253:         )",
          "254:     else:",
          "255:         console.print(f\"\\nInstalling airflow via apache-airflow=={use_airflow_version}\")",
          "257:         airflow_constraints_location = get_airflow_constraints_location(",
          "258:             airflow_skip_constraints=airflow_skip_constraints,",
          "259:             airflow_constraints_mode=airflow_constraints_mode,",
          "",
          "[Removed Lines]",
          "256:         airflow_package_spec = f\"apache-airflow=={use_airflow_version}{airflow_extras}\"",
          "",
          "[Added Lines]",
          "256:         airflow_package_spec = f\"apache-airflow{airflow_extras}=={use_airflow_version}\"",
          "",
          "---------------"
        ]
      }
    }
  ]
}