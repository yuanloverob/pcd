{
  "cve_id": "CVE-2021-45456",
  "cve_desc": "Apache kylin checks the legitimacy of the project before executing some commands with the project name passed in by the user. There is a mismatch between what is being checked and what is being used as the shell command argument in DiagnosisService. This may cause an illegal project name to pass the check and perform the following steps, resulting in a command injection vulnerability. This issue affects Apache Kylin 4.0.0.",
  "repo": "apache/kylin",
  "patch_hash": "f4daf14dde99b934c92ce2c832509f24342bc845",
  "patch_info": {
    "commit_hash": "f4daf14dde99b934c92ce2c832509f24342bc845",
    "repo": "apache/kylin",
    "commit_url": "https://github.com/apache/kylin/commit/f4daf14dde99b934c92ce2c832509f24342bc845",
    "files": [
      "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
      "core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java",
      "core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java",
      "server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java",
      "server/src/main/webapp/WEB-INF/web.xml"
    ],
    "message": "test fix",
    "before_after_code_files": [
      "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
      "core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java||core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java",
      "core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java||core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java",
      "server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java||server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java"
    ]
  },
  "patch_diff": {
    "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java": [
      "File: core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java -> core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "3403:     public String getKerberosPrincipal() {",
      "3404:         return getOptional(\"kylin.kerberos.principal\");",
      "3405:     }",
      "3406: }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "3407:     public String getEncryptCipherIvSpec() {",
      "3408:         return getOptional(\"kylin.security.encrypt.cipher.ivSpec\", \"AAAAAAAAAAAAAAAA\");",
      "3409:     }",
      "",
      "---------------"
    ],
    "core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java||core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java": [
      "File: core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java -> core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "25: import java.security.NoSuchAlgorithmException;",
      "27: import org.apache.commons.codec.binary.Base64;",
      "29: import javax.crypto.Cipher;",
      "30: import javax.crypto.NoSuchPaddingException;",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "28: import org.apache.kylin.common.KylinConfig;",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "42:             InvalidKeyException, NoSuchPaddingException, NoSuchAlgorithmException, UnsupportedEncodingException {",
      "43:         Cipher cipher = Cipher.getInstance(\"AES/CFB/PKCS5Padding\");",
      "44:         final SecretKeySpec secretKey = new SecretKeySpec(key, \"AES\");",
      "46:         cipher.init(cipherMode, secretKey, ivSpec);",
      "47:         return cipher;",
      "48:     }",
      "",
      "[Removed Lines]",
      "45:         IvParameterSpec ivSpec = new IvParameterSpec(\"AAAAAAAAAAAAAAAA\".getBytes(\"UTF-8\"));",
      "",
      "[Added Lines]",
      "46:         IvParameterSpec ivSpec = new IvParameterSpec(KylinConfig.getInstanceFromEnv().getEncryptCipherIvSpec().getBytes(\"UTF-8\"));",
      "",
      "---------------"
    ],
    "core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java||core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java": [
      "File: core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java -> core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "19: package org.apache.kylin.common.util;",
      "21: import org.junit.Assert;",
      "22: import org.junit.Test;",
      "26:     @Test",
      "27:     public void testAESEncrypt(){",
      "",
      "[Removed Lines]",
      "24: public class EncryptUtilTest {",
      "",
      "[Added Lines]",
      "21: import org.junit.After;",
      "23: import org.junit.Before;",
      "26: public class EncryptUtilTest extends LocalFileMetadataTestCase {",
      "27:     @Before",
      "28:     public void setUp() throws Exception {",
      "29:         this.createTestMetadata();",
      "30:     }",
      "32:     @After",
      "33:     public void after() throws Exception {",
      "34:         this.cleanupTestMetadata();",
      "35:     }",
      "",
      "---------------"
    ],
    "server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java||server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java": [
      "File: server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java -> server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "87:     public String dumpProjectDiagnosisInfo(String project, File exportPath) throws IOException {",
      "88:         Message msg = MsgPicker.getMsg();",
      "89:         ProjectInstance projectInstance =",
      "90:                 ProjectManager.getInstance(KylinConfig.getInstanceFromEnv())",
      "92:         if (null == projectInstance) {",
      "93:             throw new BadRequestException(",
      "95:         }",
      "96:         aclEvaluate.checkProjectOperationPermission(projectInstance);",
      "98:         runDiagnosisCLI(args);",
      "99:         return getDiagnosisPackageName(exportPath);",
      "100:     }",
      "",
      "[Removed Lines]",
      "91:                         .getProject(ValidateUtil.convertStringToBeAlphanumericUnderscore(project));",
      "94:                     String.format(Locale.ROOT, msg.getDIAG_PROJECT_NOT_FOUND(), project));",
      "97:         String[] args = { project, exportPath.getAbsolutePath() };",
      "",
      "[Added Lines]",
      "89:         String projectName = ValidateUtil.convertStringToBeAlphanumericUnderscore(project);",
      "92:                         .getProject(projectName);",
      "95:                     String.format(Locale.ROOT, msg.getDIAG_PROJECT_NOT_FOUND(), projectName));",
      "98:         String[] args = { projectName, exportPath.getAbsolutePath() };",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "124dd054923b9e41f37c725494ff1cadac496eee",
      "candidate_info": {
        "commit_hash": "124dd054923b9e41f37c725494ff1cadac496eee",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/124dd054923b9e41f37c725494ff1cadac496eee",
        "files": [
          "core-common/src/main/java/org/apache/kylin/common/persistence/ResourceStore.java",
          "core-cube/src/main/java/org/apache/kylin/cube/CubeSegment.java",
          "kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/utils/UpdateMetadataUtil.java",
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java",
          "metastore-hbase/src/main/java/org/apache/kylin/storage/hbase/HBaseResourceStore.java"
        ],
        "message": "KYLIN-4818 Not store HLL binary file into RDBMS directly",
        "before_after_code_files": [
          "core-common/src/main/java/org/apache/kylin/common/persistence/ResourceStore.java||core-common/src/main/java/org/apache/kylin/common/persistence/ResourceStore.java",
          "core-cube/src/main/java/org/apache/kylin/cube/CubeSegment.java||core-cube/src/main/java/org/apache/kylin/cube/CubeSegment.java",
          "kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/utils/UpdateMetadataUtil.java||kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/utils/UpdateMetadataUtil.java",
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java",
          "metastore-hbase/src/main/java/org/apache/kylin/storage/hbase/HBaseResourceStore.java||metastore-hbase/src/main/java/org/apache/kylin/storage/hbase/HBaseResourceStore.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "core-common/src/main/java/org/apache/kylin/common/persistence/ResourceStore.java||core-common/src/main/java/org/apache/kylin/common/persistence/ResourceStore.java": [
          "File: core-common/src/main/java/org/apache/kylin/common/persistence/ResourceStore.java -> core-common/src/main/java/org/apache/kylin/common/persistence/ResourceStore.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "138:                     StringEntity.serializer);",
          "139:         }",
          "140:         StringEntity entity = getResource(ResourceStore.METASTORE_UUID_TAG, StringEntity.serializer);",
          "142:     }",
          "",
          "[Removed Lines]",
          "141:         return entity == null ? \"\":entity.toString();",
          "",
          "[Added Lines]",
          "141:         return entity == null ? \"\" : entity.toString();",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "361:         return writer.bytesWritten();",
          "362:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "364:     final public void putBigResource(String resPath, InputStream content, long ts) throws IOException {",
          "365:         resPath = norm(resPath);",
          "366:         ContentWriter writer = ContentWriter.create(content);",
          "367:         writer.markBigContent();",
          "368:         putResourceCheckpoint(resPath, writer, ts);",
          "369:     }",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "447:             throws IOException, WriteConflictException;",
          "449:     private long checkAndPutResourceWithRetry(final String resPath, final byte[] content, final long oldTS,",
          "451:         ExponentialBackoffRetry retry = new ExponentialBackoffRetry(this);",
          "452:         return retry.doWithRetry(() -> checkAndPutResourceImpl(resPath, content, oldTS, newTS));",
          "453:     }",
          "",
          "[Removed Lines]",
          "450:             final long newTS) throws IOException, WriteConflictException {",
          "",
          "[Added Lines]",
          "457:                                               final long newTS) throws IOException, WriteConflictException {",
          "",
          "---------------"
        ],
        "core-cube/src/main/java/org/apache/kylin/cube/CubeSegment.java||core-cube/src/main/java/org/apache/kylin/cube/CubeSegment.java": [
          "File: core-cube/src/main/java/org/apache/kylin/cube/CubeSegment.java -> core-cube/src/main/java/org/apache/kylin/cube/CubeSegment.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "541:     }",
          "543:     public String getPreciseStatisticsResourcePath() {",
          "545:     }",
          "547:     public static String getStatisticsResourcePath(String cubeName, String cubeSegmentId) {",
          "",
          "[Removed Lines]",
          "544:         return getStatisticsResourcePath(this.getCubeInstance().getName(), this.getUuid(), \"json\");",
          "",
          "[Added Lines]",
          "544:         return getStatisticsResourcePath(this.getCubeInstance().getName(), this.getUuid(), \"\");",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/utils/UpdateMetadataUtil.java||kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/utils/UpdateMetadataUtil.java": [
          "File: kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/utils/UpdateMetadataUtil.java -> kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/utils/UpdateMetadataUtil.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "40: import org.apache.kylin.cube.CubeSegment;",
          "41: import org.apache.kylin.cube.CubeUpdate;",
          "42: import org.apache.kylin.cube.model.CubeBuildTypeEnum;",
          "44: import org.apache.kylin.engine.mr.common.BatchConstants;",
          "45: import org.apache.kylin.engine.mr.steps.CubingExecutableUtil;",
          "46: import org.apache.kylin.engine.spark.job.NSparkExecutable;",
          "",
          "[Removed Lines]",
          "43: import org.apache.kylin.engine.mr.JobBuilderSupport;",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "50: import org.slf4j.Logger;",
          "51: import org.slf4j.LoggerFactory;",
          "55: public class UpdateMetadataUtil {",
          "57:     protected static final Logger logger = LoggerFactory.getLogger(UpdateMetadataUtil.class);",
          "",
          "[Removed Lines]",
          "53: import static org.apache.kylin.engine.mr.common.BatchConstants.CFG_OUTPUT_STATISTICS;",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "80:                             currentInstanceCopy.toString(), toUpdateSeg.toString(), tobeSegments.toString()));",
          "82:         String resKey = toUpdateSeg.getStatisticsResourcePath();",
          "85:         FileSystem fs = HadoopUtil.getWorkingFileSystem();",
          "86:         if (fs.exists(statisticsFile)) {",
          "87:             FSDataInputStream is = fs.open(statisticsFile);",
          "89:         }",
          "91:         CubeUpdate update = new CubeUpdate(currentInstanceCopy);",
          "",
          "[Removed Lines]",
          "83:         String jobWorkingDirPath = JobBuilderSupport.getJobWorkingDir(currentInstanceCopy.getConfig().getHdfsWorkingDirectory(), nsparkExecutable.getParam(MetadataConstants.P_JOB_ID));",
          "84:         Path statisticsFile = new Path(jobWorkingDirPath + \"/\" + segmentId + \"/\" + CFG_OUTPUT_STATISTICS + \"/\" + BatchConstants.CFG_STATISTICS_CUBOID_ESTIMATION_FILENAME);",
          "88:             ResourceStore.getStore(config).putResource(resKey, is, System.currentTimeMillis());",
          "",
          "[Added Lines]",
          "80:         String jobTmpDir = config.getJobTmpDir(currentInstanceCopy.getProject()) + \"/\" + nsparkExecutable.getParam(MetadataConstants.P_JOB_ID);",
          "81:         Path statisticsFile = new Path(jobTmpDir + \"/\" + ResourceStore.CUBE_STATISTICS_ROOT + \"/\" + cubeId + \"/\" + segmentId + \"/\" + BatchConstants.CFG_STATISTICS_CUBOID_ESTIMATION_FILENAME);",
          "85:             ResourceStore.getStore(config).putBigResource(resKey, is, System.currentTimeMillis());",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java": [
          "File: kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java -> kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "47: import org.apache.hadoop.fs.FileSystem;",
          "48: import org.apache.hadoop.fs.Path;",
          "49: import org.apache.hadoop.util.StringUtils;",
          "51: import org.apache.kylin.common.util.HadoopUtil;",
          "52: import org.apache.kylin.cube.CubeInstance;",
          "53: import org.apache.kylin.cube.CubeManager;",
          "",
          "[Removed Lines]",
          "50: import org.apache.kylin.common.KylinConfig;",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "85: import scala.Tuple2;",
          "86: import scala.collection.JavaConversions;",
          "90: public class CubeBuildJob extends SparkApplication {",
          "91:     protected static final Logger logger = LoggerFactory.getLogger(CubeBuildJob.class);",
          "92:     protected static String TEMP_DIR_SUFFIX = \"_temp\";",
          "",
          "[Removed Lines]",
          "88: import static org.apache.kylin.engine.mr.common.BatchConstants.CFG_OUTPUT_STATISTICS;",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "119:         cubeManager = CubeManager.getInstance(config);",
          "120:         cubeInstance = cubeManager.getCubeByUuid(cubeName);",
          "121:         CubeSegment newSegment = cubeInstance.getSegmentById(firstSegmentId);",
          "123:         ParentSourceChooser sourceChooser;",
          "",
          "[Removed Lines]",
          "122:         SpanningTree spanningTree ;",
          "",
          "[Added Lines]",
          "119:         SpanningTree spanningTree;",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "140:             logger.info(\"Cuboid statistics return {} records and cost {} ms.\", hllMap.size(), (System.currentTimeMillis() - startMills));",
          "145:             Optional<HLLCounter> hll = hllMap.values().stream().max(Comparator.comparingLong(HLLCounter::getCountEstimate));",
          "146:             long rc = hll.map(HLLCounter::getCountEstimate).orElse(1L);",
          "147:             CubeStatsWriter.writeCuboidStatistics(HadoopUtil.getCurrentConfiguration(), statisticsDir, hllMap, 1, rc);",
          "",
          "[Removed Lines]",
          "143:             String jobWorkingDirPath = JobBuilderSupport.getJobWorkingDir(cubeInstance.getConfig().getHdfsWorkingDirectory(), jobId);",
          "144:             Path statisticsDir = new Path(jobWorkingDirPath + \"/\" + firstSegmentId + \"/\" + CFG_OUTPUT_STATISTICS);",
          "",
          "[Added Lines]",
          "140:             String jobTmpDir = config.getJobTmpDir(project) + \"/\" + jobId;",
          "141:             Path statisticsDir = new Path(jobTmpDir + \"/\" + ResourceStore.CUBE_STATISTICS_ROOT + \"/\" + cubeName + \"/\" + firstSegmentId + \"/\");",
          "",
          "---------------"
        ],
        "metastore-hbase/src/main/java/org/apache/kylin/storage/hbase/HBaseResourceStore.java||metastore-hbase/src/main/java/org/apache/kylin/storage/hbase/HBaseResourceStore.java": [
          "File: metastore-hbase/src/main/java/org/apache/kylin/storage/hbase/HBaseResourceStore.java -> metastore-hbase/src/main/java/org/apache/kylin/storage/hbase/HBaseResourceStore.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "62: import com.google.common.base.Preconditions;",
          "64: public class HBaseResourceStore extends PushdownResourceStore {",
          "66:     private static Logger logger = LoggerFactory.getLogger(HBaseResourceStore.class);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "64: @Deprecated",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "148:     @Override",
          "149:     protected void visitFolderImpl(String folderPath, final boolean recursive, VisitFilter filter,",
          "152:         visitFolder(folderPath, filter, loadContent, new FolderVisitor() {",
          "153:             @Override",
          "",
          "[Removed Lines]",
          "150:             final boolean loadContent, final Visitor visitor) throws IOException {",
          "",
          "[Added Lines]",
          "151:                                    final boolean loadContent, final Visitor visitor) throws IOException {",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "88ad6ec31b1d5ba0308bebd96d9c65d93935d3d8",
      "candidate_info": {
        "commit_hash": "88ad6ec31b1d5ba0308bebd96d9c65d93935d3d8",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/88ad6ec31b1d5ba0308bebd96d9c65d93935d3d8",
        "files": [
          "kylin-spark-project/kylin-spark-common/src/main/java/org/apache/kylin/engine/spark/common/logging/AbstractHdfsLogAppender.java",
          "kylin-spark-project/kylin-spark-common/src/main/java/org/apache/kylin/engine/spark/common/logging/SparkExecutorHdfsAppender.java",
          "server-base/src/main/java/org/apache/kylin/rest/job/StorageCleanupJob.java"
        ],
        "message": "KYLIN-4917 Fix some problem of logger system in kylin4",
        "before_after_code_files": [
          "kylin-spark-project/kylin-spark-common/src/main/java/org/apache/kylin/engine/spark/common/logging/AbstractHdfsLogAppender.java||kylin-spark-project/kylin-spark-common/src/main/java/org/apache/kylin/engine/spark/common/logging/AbstractHdfsLogAppender.java",
          "kylin-spark-project/kylin-spark-common/src/main/java/org/apache/kylin/engine/spark/common/logging/SparkExecutorHdfsAppender.java||kylin-spark-project/kylin-spark-common/src/main/java/org/apache/kylin/engine/spark/common/logging/SparkExecutorHdfsAppender.java",
          "server-base/src/main/java/org/apache/kylin/rest/job/StorageCleanupJob.java||server-base/src/main/java/org/apache/kylin/rest/job/StorageCleanupJob.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "kylin-spark-project/kylin-spark-common/src/main/java/org/apache/kylin/engine/spark/common/logging/AbstractHdfsLogAppender.java||kylin-spark-project/kylin-spark-common/src/main/java/org/apache/kylin/engine/spark/common/logging/AbstractHdfsLogAppender.java": [
          "File: kylin-spark-project/kylin-spark-common/src/main/java/org/apache/kylin/engine/spark/common/logging/AbstractHdfsLogAppender.java -> kylin-spark-project/kylin-spark-common/src/main/java/org/apache/kylin/engine/spark/common/logging/AbstractHdfsLogAppender.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "338:     protected void write(String message) throws IOException {",
          "340:     }",
          "",
          "[Removed Lines]",
          "339:         bufferedWriter.write(message);",
          "",
          "[Added Lines]",
          "339:         if (isWriterInited()) {",
          "340:             bufferedWriter.write(message);",
          "341:         }",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "375:     private void flush() throws IOException {",
          "378:     }",
          "",
          "[Removed Lines]",
          "376:         bufferedWriter.flush();",
          "377:         outStream.hsync();",
          "",
          "[Added Lines]",
          "378:         if (isWriterInited()) {",
          "379:             bufferedWriter.flush();",
          "380:             outStream.hsync();",
          "381:         }",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-common/src/main/java/org/apache/kylin/engine/spark/common/logging/SparkExecutorHdfsAppender.java||kylin-spark-project/kylin-spark-common/src/main/java/org/apache/kylin/engine/spark/common/logging/SparkExecutorHdfsAppender.java": [
          "File: kylin-spark-project/kylin-spark-common/src/main/java/org/apache/kylin/engine/spark/common/logging/SparkExecutorHdfsAppender.java -> kylin-spark-project/kylin-spark-common/src/main/java/org/apache/kylin/engine/spark/common/logging/SparkExecutorHdfsAppender.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "25: import org.apache.hadoop.fs.FileSystem;",
          "26: import org.apache.hadoop.fs.Path;",
          "27: import org.apache.hadoop.security.UserGroupInformation;",
          "28: import org.apache.log4j.helpers.LogLog;",
          "29: import org.apache.log4j.spi.LoggingEvent;",
          "30: import org.apache.spark.SparkEnv;",
          "31: import org.apache.spark.deploy.yarn.YarnSparkHadoopUtil;",
          "33: import java.io.File;",
          "34: import java.io.IOException;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "28: import org.apache.kylin.common.util.HadoopUtil;",
          "32: import org.apache.spark.deploy.SparkHadoopUtil;",
          "34: import scala.runtime.BoxedUnit;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "160:                 String user = System.getenv(\"USER\");",
          "161:                 LogLog.warn(\"login user is \" + UserGroupInformation.getLoginUser() + \" SPARK_USER is \" + sparkuser",
          "162:                         + \" USER is \" + user);",
          "167:             }",
          "169:             transaction.add(loggingEvent);",
          "170:             writeLogEvent(loggingEvent);",
          "171:             size--;",
          "",
          "[Removed Lines]",
          "163:                 if (!initHdfsWriter(file, new Configuration())) {",
          "164:                     LogLog.error(\"Failed to init the hdfs writer!\");",
          "165:                 }",
          "166:                 doRollingClean(loggingEvent);",
          "",
          "[Added Lines]",
          "166:                 SparkHadoopUtil.get().runAsSparkUser(new scala.runtime.AbstractFunction0<scala.runtime.BoxedUnit>() {",
          "167:                     @Override",
          "168:                     public BoxedUnit apply() {",
          "169:                         if (!initHdfsWriter(file, new Configuration())) {",
          "170:                             LogLog.error(\"Failed to init the hdfs writer!\");",
          "171:                         }",
          "172:                         try {",
          "173:                             doRollingClean(loggingEvent);",
          "174:                         } catch (IOException e) {",
          "175:                             e.printStackTrace();",
          "176:                         }",
          "177:                         return null;",
          "178:                     }",
          "179:                 });",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "229:     @VisibleForTesting",
          "230:     String getRootPathName() {",
          "231:         if (\"job\".equals(getCategory())) {",
          "233:         } else if (\"sparder\".equals(getCategory())) {",
          "235:         } else {",
          "236:             throw new IllegalArgumentException(\"illegal category: \" + getCategory());",
          "237:         }",
          "",
          "[Removed Lines]",
          "232:             return parseHdfsWordingDir() + \"/\" + getProject() + \"/spark_logs/executor/\";",
          "234:             return parseHdfsWordingDir() + \"/_sparder_logs\";",
          "",
          "[Added Lines]",
          "244:             return getHdfsWorkingDir() + \"/\" + getProject() + \"/spark_logs/executor/\";",
          "246:             return parseHdfsWorkingDir() + \"/_sparder_logs\";",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "254:         return false;",
          "255:     }",
          "259:     }",
          "260: }",
          "",
          "[Removed Lines]",
          "257:     private String parseHdfsWordingDir() {",
          "258:         return StringUtils.appendIfMissing(getHdfsWorkingDir(), \"/\");",
          "",
          "[Added Lines]",
          "269:     private String parseHdfsWorkingDir() {",
          "270:         String root = getHdfsWorkingDir();",
          "271:         Path path = new Path(root);",
          "272:         if (!path.isAbsolute())",
          "273:             throw new IllegalArgumentException(\"kylin.env.hdfs-working-dir must be absolute, but got \" + root);",
          "275:         try {",
          "276:             FileSystem fs = path.getFileSystem(HadoopUtil.getCurrentConfiguration());",
          "277:             path = fs.makeQualified(path);",
          "278:         } catch (IOException e) {",
          "279:             throw new RuntimeException(e);",
          "280:         }",
          "283:         String metaId = getMetadataIdentifier().replace(':', '-');",
          "285:         if (metaId.startsWith(\"../\")) {",
          "286:             metaId = metaId.replace(\"../\", \"\");",
          "287:             metaId = metaId.replace('/', '-');",
          "288:         }",
          "290:         root = new Path(path, metaId).toString();",
          "292:         if (!root.endsWith(\"/\"))",
          "293:             root += \"/\";",
          "294:         return root;",
          "",
          "---------------"
        ],
        "server-base/src/main/java/org/apache/kylin/rest/job/StorageCleanupJob.java||server-base/src/main/java/org/apache/kylin/rest/job/StorageCleanupJob.java": [
          "File: server-base/src/main/java/org/apache/kylin/rest/job/StorageCleanupJob.java -> server-base/src/main/java/org/apache/kylin/rest/job/StorageCleanupJob.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "83:     protected long storageTimeCut;",
          "86:     protected static PathFilter pathFilter = status -> !protectedDir.contains(status.getName());",
          "88:     public StorageCleanupJob() throws IOException {",
          "",
          "[Removed Lines]",
          "85:     protected static final List<String> protectedDir = Arrays.asList(\"cube_statistics\", \"resources-jdbc\");",
          "",
          "[Added Lines]",
          "85:     protected static final List<String> protectedDir = Arrays.asList(\"cube_statistics\", \"resources-jdbc\", \"_sparder_logs\");",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "6d87071158cb9256552c880c0c29bc995eb2cb54",
      "candidate_info": {
        "commit_hash": "6d87071158cb9256552c880c0c29bc995eb2cb54",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/6d87071158cb9256552c880c0c29bc995eb2cb54",
        "files": [
          "core-job/src/main/java/org/apache/kylin/job/JoinedFormatter.java",
          "core-metadata/src/main/java/org/apache/kylin/metadata/util/ModelUtil.java",
          "server-base/src/main/java/org/apache/kylin/rest/service/ModelService.java",
          "server/src/test/java/org/apache/kylin/rest/service/ModelServiceTest.java"
        ],
        "message": "[KYLIN-4554] validate filter condition on model saving\n\nverify filter condition using the following login\n\n1 select * from tableName where {filterCondition} pass   calcite  parse\n\n2 all column in filter condition must be model table column",
        "before_after_code_files": [
          "core-job/src/main/java/org/apache/kylin/job/JoinedFormatter.java||core-job/src/main/java/org/apache/kylin/job/JoinedFormatter.java",
          "core-metadata/src/main/java/org/apache/kylin/metadata/util/ModelUtil.java||core-metadata/src/main/java/org/apache/kylin/metadata/util/ModelUtil.java",
          "server-base/src/main/java/org/apache/kylin/rest/service/ModelService.java||server-base/src/main/java/org/apache/kylin/rest/service/ModelService.java",
          "server/src/test/java/org/apache/kylin/rest/service/ModelServiceTest.java||server/src/test/java/org/apache/kylin/rest/service/ModelServiceTest.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "core-job/src/main/java/org/apache/kylin/job/JoinedFormatter.java||core-job/src/main/java/org/apache/kylin/job/JoinedFormatter.java": [
          "File: core-job/src/main/java/org/apache/kylin/job/JoinedFormatter.java -> core-job/src/main/java/org/apache/kylin/job/JoinedFormatter.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "56:         setDateEnv(flatDesc);",
          "57:     }",
          "59:     private void setDateEnv(IJoinedFlatTableDesc flatDesc) {",
          "60:         DataModelDesc model = flatDesc.getDataModel();",
          "61:         PartitionDesc partDesc = model.getPartitionDesc();",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "59:     public JoinedFormatter(Boolean validateModel) {",
          "61:         String start = \"20190710\";",
          "62:         String end = \"20190711\";",
          "63:         setKeyValue(START_DATE, start);",
          "64:         setKeyValue(END_DATE, end);",
          "65:     }",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "83:         return value == null ? \"\" : value;",
          "84:     }",
          "87:         String[] cArray = REG_PATTERN.split(sentence);",
          "88:         StringBuilder sbr = new StringBuilder();",
          "89:         List<String> keys = getKeys(sentence);",
          "",
          "[Removed Lines]",
          "86:     String formatSentence(String sentence) {",
          "",
          "[Added Lines]",
          "94:     public String formatSentence(String sentence) {",
          "",
          "---------------"
        ],
        "core-metadata/src/main/java/org/apache/kylin/metadata/util/ModelUtil.java||core-metadata/src/main/java/org/apache/kylin/metadata/util/ModelUtil.java": [
          "File: core-metadata/src/main/java/org/apache/kylin/metadata/util/ModelUtil.java -> core-metadata/src/main/java/org/apache/kylin/metadata/util/ModelUtil.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19: package org.apache.kylin.metadata.util;",
          "21: import java.util.List;",
          "22: import java.util.Locale;",
          "24: import org.apache.calcite.sql.SqlCall;",
          "25: import org.apache.calcite.sql.SqlIdentifier;",
          "26: import org.apache.calcite.sql.SqlNode;",
          "27: import org.apache.calcite.sql.SqlSelect;",
          "28: import org.apache.calcite.sql.parser.SqlParser;",
          "29: import org.apache.calcite.sql.util.SqlBasicVisitor;",
          "30: import org.apache.kylin.metadata.model.TableDesc;",
          "31: import org.slf4j.Logger;",
          "32: import org.slf4j.LoggerFactory;",
          "34: import com.google.common.collect.Lists;",
          "36: public class ModelUtil {",
          "38:     private static final Logger logger = LoggerFactory.getLogger(ModelUtil.class);",
          "40:     public static void verifyFilterCondition(String factTableName, String filterCondition, TableDesc tableDesc)",
          "41:             throws Exception {",
          "42:         StringBuilder checkSql = new StringBuilder();",
          "43:         checkSql.append(\"select * from \").append(factTableName).append(\" where \").append(filterCondition);",
          "45:         SqlCall inputToNode = (SqlCall) parse(doubleQuoteKeywordDefault(checkSql.toString()));",
          "46:         SqlVerify sqlVerify = new SqlVerify(tableDesc);",
          "47:         sqlVerify.visit(inputToNode);",
          "49:     }",
          "51:     public static SqlNode parse(String sql) throws Exception {",
          "52:         SqlParser.ConfigBuilder parserBuilder = SqlParser.configBuilder().setIdentifierMaxLength(300);",
          "53:         SqlParser sqlParser = SqlParser.create(sql, parserBuilder.build());",
          "54:         return sqlParser.parseQuery();",
          "55:     }",
          "57:     private static class SqlVerify extends SqlBasicVisitor {",
          "59:         private TableDesc tableDesc;",
          "61:         SqlVerify(TableDesc tableDesc) {",
          "62:             this.tableDesc = tableDesc;",
          "63:         }",
          "65:         @Override",
          "66:         public Object visit(SqlCall call) {",
          "67:             SqlSelect select = (SqlSelect) call;",
          "68:             WhereColumnVerify.verify(select.getWhere(), tableDesc);",
          "69:             return null;",
          "70:         }",
          "71:     }",
          "73:     private static class WhereColumnVerify extends SqlBasicVisitor {",
          "75:         private List<String> allSqlIdentifier = Lists.newArrayList();",
          "77:         static void verify(SqlNode whereNode, TableDesc tableDesc) {",
          "78:             WhereColumnVerify whereColumnVerify = new WhereColumnVerify();",
          "79:             whereNode.accept(whereColumnVerify);",
          "80:             whereColumnVerify.allSqlIdentifier.stream().forEach(col -> {",
          "81:                 if (tableDesc.findColumnByName(col) == null) {",
          "82:                     String verifyError = String.format(Locale.ROOT,",
          "83:                             \"filter condition col: %s is not a column in the table \", col);",
          "84:                     logger.error(verifyError);",
          "85:                     throw new IllegalArgumentException(verifyError);",
          "86:                 }",
          "87:             });",
          "88:         }",
          "90:         public Object visit(SqlIdentifier id) {",
          "91:             allSqlIdentifier.add(id.names.get(0));",
          "92:             return null;",
          "93:         }",
          "94:     }",
          "96:     public static String doubleQuoteKeywordDefault(String sql) {",
          "97:         sql = sql.replaceAll(\"(?i)default\\\\.\", \"\\\"DEFAULT\\\".\");",
          "98:         sql = sql.replace(\"defaultCatalog.\", \"\");",
          "99:         sql = sql.replace(\"\\\"defaultCatalog\\\".\", \"\");",
          "100:         return sql;",
          "101:     }",
          "103: }",
          "",
          "---------------"
        ],
        "server-base/src/main/java/org/apache/kylin/rest/service/ModelService.java||server-base/src/main/java/org/apache/kylin/rest/service/ModelService.java": [
          "File: server-base/src/main/java/org/apache/kylin/rest/service/ModelService.java -> server-base/src/main/java/org/apache/kylin/rest/service/ModelService.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "31: import org.apache.kylin.common.persistence.RootPersistentEntity;",
          "32: import org.apache.kylin.cube.CubeInstance;",
          "33: import org.apache.kylin.cube.model.CubeDesc;",
          "34: import org.apache.kylin.metadata.ModifiedOrder;",
          "35: import org.apache.kylin.metadata.draft.Draft;",
          "36: import org.apache.kylin.metadata.model.DataModelDesc;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "34: import org.apache.kylin.job.JoinedFormatter;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "39: import org.apache.kylin.metadata.model.ModelDimensionDesc;",
          "40: import org.apache.kylin.metadata.model.TableDesc;",
          "41: import org.apache.kylin.metadata.model.TblColRef;",
          "42: import org.apache.kylin.rest.exception.BadRequestException;",
          "43: import org.apache.kylin.rest.exception.ForbiddenException;",
          "44: import org.apache.kylin.rest.msg.Message;",
          "45: import org.apache.kylin.rest.msg.MsgPicker;",
          "46: import org.apache.kylin.rest.util.AclEvaluate;",
          "47: import org.apache.kylin.rest.util.ValidateUtil;",
          "48: import org.slf4j.Logger;",
          "49: import org.slf4j.LoggerFactory;",
          "50: import org.springframework.beans.factory.annotation.Autowired;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "43: import org.apache.kylin.metadata.util.ModelUtil;",
          "50: import org.apache.kylin.shaded.com.google.common.collect.Maps;",
          "51: import org.apache.kylin.shaded.com.google.common.collect.Sets;",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "53: import org.springframework.security.core.context.SecurityContextHolder;",
          "54: import org.springframework.stereotype.Component;",
          "",
          "[Removed Lines]",
          "56: import org.apache.kylin.shaded.com.google.common.collect.Maps;",
          "57: import org.apache.kylin.shaded.com.google.common.collect.Sets;",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "154:     public void validateModel(String project, DataModelDesc desc) throws IllegalArgumentException {",
          "155:         String factTableName = desc.getRootFactTableName();",
          "156:         TableDesc tableDesc = getTableManager().getTableDesc(factTableName, project);",
          "157:         if ((tableDesc.getSourceType() == ISourceAware.ID_STREAMING || tableDesc.isStreamingTable())",
          "158:                 && (desc.getPartitionDesc() == null || desc.getPartitionDesc().getPartitionDateColumn() == null)) {",
          "159:             throw new IllegalArgumentException(\"Must define a partition column.\");",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "159:         if (!StringUtils.isEmpty(desc.getFilterCondition())) {",
          "160:             try {",
          "161:                 JoinedFormatter formatter = new JoinedFormatter(true);",
          "162:                 ModelUtil.verifyFilterCondition(factTableName, formatter.formatSentence(desc.getFilterCondition()),",
          "163:                         tableDesc);",
          "164:             } catch (Exception e) {",
          "165:                 throw new BadRequestException(e.toString());",
          "166:             }",
          "167:         }",
          "",
          "---------------"
        ],
        "server/src/test/java/org/apache/kylin/rest/service/ModelServiceTest.java||server/src/test/java/org/apache/kylin/rest/service/ModelServiceTest.java": [
          "File: server/src/test/java/org/apache/kylin/rest/service/ModelServiceTest.java -> server/src/test/java/org/apache/kylin/rest/service/ModelServiceTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "64:         Assert.assertTrue(dataModelDesc.getOwner().equals(\"somebody\"));",
          "65:     }",
          "67:     @Test",
          "68:     public void testRevisableModelInCaseOfDeleteMeasure() throws IOException {",
          "69:         List<DataModelDesc> dataModelDescs = modelService.listAllModels(\"ci_left_join_model\", \"default\", true);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "67:     @Test",
          "68:     public void testVerifyFilterCondition() throws IOException {",
          "69:         Serializer<DataModelDesc> serializer = modelService.getDataModelManager()",
          "70:             .getDataModelSerializer();",
          "71:         List<DataModelDesc> dataModelDescs = modelService",
          "72:             .listAllModels(\"ci_inner_join_model\", \"default\", true);",
          "73:         Assert.assertTrue(dataModelDescs.size() == 1);",
          "74:         ByteArrayOutputStream baos = new ByteArrayOutputStream();",
          "75:         serializer.serialize(dataModelDescs.get(0), new DataOutputStream(baos));",
          "76:         ByteArrayInputStream bais = new ByteArrayInputStream(baos.toByteArray());",
          "77:         DataModelDesc deserialize = serializer.deserialize(new DataInputStream(bais));",
          "78:         deserialize.setOwner(\"somebody\");",
          "79:         deserialize.setFilterCondition(\"TRANS_ID = 1\");",
          "80:         modelService.validateModel(\"default\", deserialize);",
          "81:         try {",
          "82:             deserialize.setFilterCondition(\"TRANS_IDD = 1\");",
          "83:             modelService.validateModel(\"default\", deserialize);",
          "84:             Assert.fail(\"should throw an exception\");",
          "85:         } catch (Exception e){",
          "86:             Assert.assertTrue(e.getMessage().equals(\"java.lang.IllegalArgumentException: filter condition col: TRANS_IDD is not a column in the table \"));",
          "87:         }",
          "88:     }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "53d4d2ba9129d6e9297cf00c9d10db0590344ba3",
      "candidate_info": {
        "commit_hash": "53d4d2ba9129d6e9297cf00c9d10db0590344ba3",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/53d4d2ba9129d6e9297cf00c9d10db0590344ba3",
        "files": [
          "webapp/app/js/controllers/cubeSchema.js"
        ],
        "message": "KYLIN-4119 Project ADMIN can not operate the Hybrid model\n\n(cherry picked from commit 85f13e760cb021dec69121becb306eef6366ba73)",
        "before_after_code_files": [
          "webapp/app/js/controllers/cubeSchema.js||webapp/app/js/controllers/cubeSchema.js"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "webapp/app/js/controllers/cubeSchema.js||webapp/app/js/controllers/cubeSchema.js": [
          "File: webapp/app/js/controllers/cubeSchema.js -> webapp/app/js/controllers/cubeSchema.js",
          "--- Hunk 1 ---",
          "[Context before]",
          "160:         }",
          "162:     });",
          "168:     $scope.removeElement = function (arr, element) {",
          "169:         var index = arr.indexOf(element);",
          "",
          "[Removed Lines]",
          "164:     $scope.filterProj = function(project){",
          "165:         return $scope.userService.hasRole('ROLE_ADMIN') || $scope.hasPermission(project,$scope.permissions.ADMINISTRATION.mask);",
          "166:     };",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "d554c762838ddac4bf5e38d294e049788e6b8423",
      "candidate_info": {
        "commit_hash": "d554c762838ddac4bf5e38d294e049788e6b8423",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/d554c762838ddac4bf5e38d294e049788e6b8423",
        "files": [
          "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/BuildLayoutWithUpdate.java",
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java",
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeMergeJob.java"
        ],
        "message": "KYLIN-4903 cache parent datasource to accelerate next layer's cuboid building",
        "before_after_code_files": [
          "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/BuildLayoutWithUpdate.java||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/BuildLayoutWithUpdate.java",
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java",
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeMergeJob.java||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeMergeJob.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [
            "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java"
          ],
          "candidate": [
            "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java"
          ]
        }
      },
      "candidate_diff": {
        "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java": [
          "File: core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java -> core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "3096:     public String getKerberosPrincipal() {",
          "3097:         return getOptional(\"kylin.kerberos.principal\");",
          "3098:     }",
          "3099: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "3100:     public String getParentDatasetStorageLevel() {",
          "3101:         return getOptional(\"kylin.engine.spark.parent-dataset.storage.level\", \"NONE\");",
          "3102:     }",
          "3104:     public int getMaxParentDatasetPersistCount() {",
          "3105:         return Integer.parseInt(getOptional(\"kylin.engine.spark.parent-dataset.max.persist.count\", \"1\"));",
          "3106:     }",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/BuildLayoutWithUpdate.java||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/BuildLayoutWithUpdate.java": [
          "File: kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/BuildLayoutWithUpdate.java -> kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/BuildLayoutWithUpdate.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: package org.apache.kylin.engine.spark.job;",
          "21: import java.io.IOException;",
          "22: import java.util.concurrent.Callable;",
          "23: import java.util.concurrent.CompletionService;",
          "24: import java.util.concurrent.ExecutionException;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "22: import java.util.Map;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "26: import java.util.concurrent.ExecutorService;",
          "27: import java.util.concurrent.Executors;",
          "28: import java.util.concurrent.TimeUnit;",
          "30: import org.apache.kylin.common.KylinConfig;",
          "31: import org.apache.kylin.engine.spark.metadata.SegmentInfo;",
          "32: import org.apache.kylin.engine.spark.metadata.cube.model.LayoutEntity;",
          "33: import org.slf4j.Logger;",
          "34: import org.slf4j.LoggerFactory;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "30: import java.util.concurrent.ConcurrentHashMap;",
          "31: import java.util.concurrent.Semaphore;",
          "32: import java.util.concurrent.atomic.AtomicLong;",
          "35: import org.apache.kylin.engine.spark.builder.NBuildSourceInfo;",
          "38: import org.apache.spark.sql.Dataset;",
          "39: import org.apache.spark.sql.Row;",
          "40: import org.apache.spark.storage.StorageLevel;",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "38:     private ExecutorService pool = Executors.newCachedThreadPool();",
          "39:     private CompletionService<JobResult> completionService = new ExecutorCompletionService<>(pool);",
          "40:     private int currentLayoutsNum = 0;",
          "42:     public void submit(JobEntity job, KylinConfig config) {",
          "43:         completionService.submit(new Callable<JobResult>() {",
          "44:             @Override",
          "45:             public JobResult call() throws Exception {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "49:     private Map<Long, AtomicLong> toBuildCuboidSize = new ConcurrentHashMap<>();",
          "50:     private Semaphore semaphore;",
          "51:     private Map<Long, Dataset<Row>> layout2DataSet = new ConcurrentHashMap<>();",
          "52:     private StorageLevel storageLevel;",
          "53:     private boolean persistParentDataset;",
          "55:     public BuildLayoutWithUpdate(KylinConfig kylinConfig) {",
          "56:         this.storageLevel = StorageLevel.fromString(kylinConfig.getParentDatasetStorageLevel());",
          "57:         this.persistParentDataset = !storageLevel.equals(StorageLevel.NONE());",
          "58:         if (this.persistParentDataset) {",
          "59:             if (kylinConfig.getMaxParentDatasetPersistCount() < 1) {",
          "60:                 throw new IllegalArgumentException(\"max parent dataset persist count should be larger than 1\");",
          "61:             }",
          "62:             this.semaphore = new Semaphore(kylinConfig.getMaxParentDatasetPersistCount());",
          "63:         }",
          "64:     }",
          "66:     public void cacheAndRegister(long layoutId, Dataset<Row> dataset) throws InterruptedException{",
          "67:         if (!persistParentDataset) {",
          "68:             return;",
          "69:         }",
          "70:         logger.info(\"persist dataset of layout: {}\", layoutId);",
          "71:         semaphore.acquire();",
          "72:         layout2DataSet.put(layoutId, dataset);",
          "73:         dataset.persist(storageLevel);",
          "74:     }",
          "79:         if (persistParentDataset && job.getBuildSourceInfo() != null && job.getBuildSourceInfo().getToBuildCuboids().size() > 1) {",
          "81:             if(!layout2DataSet.containsKey(job.getBuildSourceInfo().getLayoutId())){",
          "82:                 logger.error(\"persist parent dataset is enabled, but parent dataset not registered\");",
          "83:                 throw new RuntimeException(\"parent dataset not registered\");",
          "84:             }",
          "85:             if (!toBuildCuboidSize.containsKey(job.getBuildSourceInfo().getLayoutId())) {",
          "86:                 toBuildCuboidSize.put(job.getBuildSourceInfo().getLayoutId(),",
          "87:                         new AtomicLong(job.getBuildSourceInfo().getToBuildCuboids().size()));",
          "88:             }",
          "89:         }",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "52:                 } catch (Throwable t) {",
          "53:                     logger.error(\"Error occurred when run \" + job.getName(), t);",
          "54:                     throwable = t;",
          "55:                 }",
          "56:                 return new JobResult(dataLayouts, throwable);",
          "57:             }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "103:                 } finally {",
          "105:                     if (persistParentDataset && job.getBuildSourceInfo() != null && job.getBuildSourceInfo().getToBuildCuboids().size() > 1) {",
          "106:                         long remain = toBuildCuboidSize.get(job.getBuildSourceInfo().getLayoutId()).decrementAndGet();",
          "107:                         if (remain == 0) {",
          "108:                             toBuildCuboidSize.remove(job.getBuildSourceInfo().getLayoutId());",
          "109:                             layout2DataSet.get(job.getBuildSourceInfo().getLayoutId()).unpersist();",
          "110:                             logger.info(\"dataset of layout: {} released\", job.getBuildSourceInfo().getLayoutId());",
          "111:                             semaphore.release();",
          "112:                         }",
          "113:                     }",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "115:         public abstract String getName();",
          "117:         public abstract LayoutEntity build() throws IOException;",
          "118:     }",
          "119: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "178:         public abstract NBuildSourceInfo getBuildSourceInfo();",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java": [
          "File: kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java -> kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "157:                 logger.info(\"Triggered cube planner phase one .\");",
          "158:         }",
          "161:         List<String> persistedFlatTable = new ArrayList<>();",
          "162:         List<String> persistedViewFactTable = new ArrayList<>();",
          "163:         Path shareDir = config.getJobTmpShareDir(project, jobId);",
          "",
          "[Removed Lines]",
          "160:         buildLayoutWithUpdate = new BuildLayoutWithUpdate();",
          "",
          "[Added Lines]",
          "160:         buildLayoutWithUpdate = new BuildLayoutWithUpdate(config);",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "297:         }",
          "298:     }",
          "302:         List<NBuildSourceInfo> theFirstLevelBuildInfos = buildLayer(buildSourceInfos, seg, st);",
          "303:         LinkedList<List<NBuildSourceInfo>> queue = new LinkedList<>();",
          "",
          "[Removed Lines]",
          "300:     private void build(Collection<NBuildSourceInfo> buildSourceInfos, SegmentInfo seg, SpanningTree st) {",
          "",
          "[Added Lines]",
          "300:     private void build(Collection<NBuildSourceInfo> buildSourceInfos, SegmentInfo seg, SpanningTree st) throws InterruptedException{",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "320:     private List<NBuildSourceInfo> buildLayer(Collection<NBuildSourceInfo> buildSourceInfos, SegmentInfo seg,",
          "322:         int cuboidsNumInLayer = 0;",
          "",
          "[Removed Lines]",
          "321:                                               SpanningTree st) {",
          "",
          "[Added Lines]",
          "321:                                               SpanningTree st) throws InterruptedException{",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "330:             cuboidsNumInLayer += toBuildCuboids.size();",
          "331:             Preconditions.checkState(!toBuildCuboids.isEmpty(), \"To be built cuboids is empty.\");",
          "332:             Dataset<Row> parentDS = info.getParentDS();",
          "334:             if (info.getLayoutId() == ParentSourceChooser.FLAT_TABLE_FLAG()) {",
          "335:                 cuboidsRowCount.putIfAbsent(info.getLayoutId(), parentDS.count());",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "334:             if (toBuildCuboids.size() > 1) {",
          "335:                 buildLayoutWithUpdate.cacheAndRegister(info.getLayoutId(), parentDS);",
          "336:             }",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "347:                     public LayoutEntity build() throws IOException {",
          "348:                         return buildCuboid(seg, index, parentDS, st, info.getLayoutId());",
          "349:                     }",
          "350:                 }, config);",
          "351:                 allIndexesInCurrentLayer.add(index);",
          "352:             }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "356:                     @Override",
          "357:                     public NBuildSourceInfo getBuildSourceInfo() {",
          "358:                         return info;",
          "359:                     }",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeMergeJob.java||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeMergeJob.java": [
          "File: kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeMergeJob.java -> kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeMergeJob.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "28: import org.apache.kylin.cube.CubeManager;",
          "29: import org.apache.kylin.cube.CubeSegment;",
          "30: import org.apache.kylin.cube.CubeUpdate;",
          "31: import org.apache.kylin.engine.spark.metadata.SegmentInfo;",
          "32: import org.apache.kylin.engine.spark.metadata.cube.ManagerHub;",
          "33: import org.apache.kylin.engine.spark.metadata.cube.PathManager;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "31: import org.apache.kylin.engine.spark.builder.NBuildSourceInfo;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "68:     @Override",
          "69:     protected void doExecute() throws Exception {",
          "71:         String cubeId = getParam(MetadataConstants.P_CUBE_ID);",
          "72:         String newSegmentId = getParam(MetadataConstants.P_SEGMENT_IDS);",
          "73:         final CubeManager cubeManager = CubeManager.getInstance(config);",
          "",
          "[Removed Lines]",
          "70:         buildLayoutWithUpdate = new BuildLayoutWithUpdate();",
          "",
          "[Added Lines]",
          "71:         buildLayoutWithUpdate = new BuildLayoutWithUpdate(config);",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "117:                 public LayoutEntity build() throws IOException {",
          "118:                     return saveAndUpdateCuboid(afterSort, mergedSegInfo, layout, assist);",
          "119:                 }",
          "120:             }, config);",
          "122:             buildLayoutWithUpdate.updateLayout(mergedSegInfo, config);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "122:                 @Override",
          "123:                 public NBuildSourceInfo getBuildSourceInfo() {",
          "124:                     return null;",
          "125:                 }",
          "",
          "---------------"
        ]
      }
    }
  ]
}