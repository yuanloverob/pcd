{
  "cve_id": "CVE-2021-45456",
  "cve_desc": "Apache kylin checks the legitimacy of the project before executing some commands with the project name passed in by the user. There is a mismatch between what is being checked and what is being used as the shell command argument in DiagnosisService. This may cause an illegal project name to pass the check and perform the following steps, resulting in a command injection vulnerability. This issue affects Apache Kylin 4.0.0.",
  "repo": "apache/kylin",
  "patch_hash": "f4daf14dde99b934c92ce2c832509f24342bc845",
  "patch_info": {
    "commit_hash": "f4daf14dde99b934c92ce2c832509f24342bc845",
    "repo": "apache/kylin",
    "commit_url": "https://github.com/apache/kylin/commit/f4daf14dde99b934c92ce2c832509f24342bc845",
    "files": [
      "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
      "core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java",
      "core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java",
      "server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java",
      "server/src/main/webapp/WEB-INF/web.xml"
    ],
    "message": "test fix",
    "before_after_code_files": [
      "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
      "core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java||core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java",
      "core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java||core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java",
      "server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java||server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java"
    ]
  },
  "patch_diff": {
    "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java": [
      "File: core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java -> core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "3403:     public String getKerberosPrincipal() {",
      "3404:         return getOptional(\"kylin.kerberos.principal\");",
      "3405:     }",
      "3406: }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "3407:     public String getEncryptCipherIvSpec() {",
      "3408:         return getOptional(\"kylin.security.encrypt.cipher.ivSpec\", \"AAAAAAAAAAAAAAAA\");",
      "3409:     }",
      "",
      "---------------"
    ],
    "core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java||core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java": [
      "File: core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java -> core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "25: import java.security.NoSuchAlgorithmException;",
      "27: import org.apache.commons.codec.binary.Base64;",
      "29: import javax.crypto.Cipher;",
      "30: import javax.crypto.NoSuchPaddingException;",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "28: import org.apache.kylin.common.KylinConfig;",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "42:             InvalidKeyException, NoSuchPaddingException, NoSuchAlgorithmException, UnsupportedEncodingException {",
      "43:         Cipher cipher = Cipher.getInstance(\"AES/CFB/PKCS5Padding\");",
      "44:         final SecretKeySpec secretKey = new SecretKeySpec(key, \"AES\");",
      "46:         cipher.init(cipherMode, secretKey, ivSpec);",
      "47:         return cipher;",
      "48:     }",
      "",
      "[Removed Lines]",
      "45:         IvParameterSpec ivSpec = new IvParameterSpec(\"AAAAAAAAAAAAAAAA\".getBytes(\"UTF-8\"));",
      "",
      "[Added Lines]",
      "46:         IvParameterSpec ivSpec = new IvParameterSpec(KylinConfig.getInstanceFromEnv().getEncryptCipherIvSpec().getBytes(\"UTF-8\"));",
      "",
      "---------------"
    ],
    "core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java||core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java": [
      "File: core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java -> core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "19: package org.apache.kylin.common.util;",
      "21: import org.junit.Assert;",
      "22: import org.junit.Test;",
      "26:     @Test",
      "27:     public void testAESEncrypt(){",
      "",
      "[Removed Lines]",
      "24: public class EncryptUtilTest {",
      "",
      "[Added Lines]",
      "21: import org.junit.After;",
      "23: import org.junit.Before;",
      "26: public class EncryptUtilTest extends LocalFileMetadataTestCase {",
      "27:     @Before",
      "28:     public void setUp() throws Exception {",
      "29:         this.createTestMetadata();",
      "30:     }",
      "32:     @After",
      "33:     public void after() throws Exception {",
      "34:         this.cleanupTestMetadata();",
      "35:     }",
      "",
      "---------------"
    ],
    "server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java||server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java": [
      "File: server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java -> server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "87:     public String dumpProjectDiagnosisInfo(String project, File exportPath) throws IOException {",
      "88:         Message msg = MsgPicker.getMsg();",
      "89:         ProjectInstance projectInstance =",
      "90:                 ProjectManager.getInstance(KylinConfig.getInstanceFromEnv())",
      "92:         if (null == projectInstance) {",
      "93:             throw new BadRequestException(",
      "95:         }",
      "96:         aclEvaluate.checkProjectOperationPermission(projectInstance);",
      "98:         runDiagnosisCLI(args);",
      "99:         return getDiagnosisPackageName(exportPath);",
      "100:     }",
      "",
      "[Removed Lines]",
      "91:                         .getProject(ValidateUtil.convertStringToBeAlphanumericUnderscore(project));",
      "94:                     String.format(Locale.ROOT, msg.getDIAG_PROJECT_NOT_FOUND(), project));",
      "97:         String[] args = { project, exportPath.getAbsolutePath() };",
      "",
      "[Added Lines]",
      "89:         String projectName = ValidateUtil.convertStringToBeAlphanumericUnderscore(project);",
      "92:                         .getProject(projectName);",
      "95:                     String.format(Locale.ROOT, msg.getDIAG_PROJECT_NOT_FOUND(), projectName));",
      "98:         String[] args = { projectName, exportPath.getAbsolutePath() };",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "45a7889eccf8acf7bc14890a7b930a12adebd463",
      "candidate_info": {
        "commit_hash": "45a7889eccf8acf7bc14890a7b930a12adebd463",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/45a7889eccf8acf7bc14890a7b930a12adebd463",
        "files": [
          "kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/dict/NBucketDictionary.java",
          "kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/catalyst/expressions/KylinExpresssions.scala"
        ],
        "message": "KYLIN-5059 Fix error when using different HDFS cluster in cube building (#1721)",
        "before_after_code_files": [
          "kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/dict/NBucketDictionary.java||kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/dict/NBucketDictionary.java",
          "kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/catalyst/expressions/KylinExpresssions.scala||kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/catalyst/expressions/KylinExpresssions.scala"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/dict/NBucketDictionary.java||kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/dict/NBucketDictionary.java": [
          "File: kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/dict/NBucketDictionary.java -> kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/dict/NBucketDictionary.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "57:         }",
          "58:         this.relativeDictMap = new Object2LongOpenHashMap<>();",
          "59:         if (!StringUtils.isEmpty(skewDictStorageFile)) {",
          "62:                 Kryo kryo = new Kryo();",
          "64:                 skewedDictMap = (Object2LongMap<String>) kryo.readClassAndObject(input);",
          "65:                 input.close();",
          "66:             }",
          "",
          "[Removed Lines]",
          "60:             FileSystem fs = FileSystem.get(new Configuration());",
          "61:             if (fs.exists(new Path(skewDictStorageFile))) {",
          "63:                 Input input = new Input(fs.open(new Path(skewDictStorageFile)));",
          "",
          "[Added Lines]",
          "60:             Path skewedDictPath = new Path(skewDictStorageFile);",
          "61:             FileSystem fs = skewedDictPath.getFileSystem(new Configuration());",
          "62:             if (fs.exists(skewedDictPath)) {",
          "64:                 Input input = new Input(fs.open(skewedDictPath));",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/catalyst/expressions/KylinExpresssions.scala||kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/catalyst/expressions/KylinExpresssions.scala": [
          "File: kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/catalyst/expressions/KylinExpresssions.scala -> kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/sql/catalyst/expressions/KylinExpresssions.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "500:          |   ${rand} = new java.util.Random();",
          "501:          |   com.esotericsoftware.kryo.Kryo kryo = new com.esotericsoftware.kryo.Kryo();",
          "502:          |   try {",
          "505:          |           com.esotericsoftware.kryo.io.Input input = new com.esotericsoftware.kryo.io.Input(",
          "507:          |           ${skewData} = (it.unimi.dsi.fastutil.objects.Object2LongOpenHashMap<String>) kryo.readClassAndObject(input);",
          "508:          |           input.close();",
          "509:          |       }",
          "",
          "[Removed Lines]",
          "503:          |       org.apache.hadoop.fs.FileSystem fs = org.apache.hadoop.fs.FileSystem.get(new org.apache.hadoop.conf.Configuration());",
          "504:          |       if (fs.exists(new org.apache.hadoop.fs.Path(\"${skewDataStorage}\"))) {",
          "506:          |               fs.open(new org.apache.hadoop.fs.Path(\"${skewDataStorage}\")));",
          "",
          "[Added Lines]",
          "503:          |       org.apache.hadoop.fs.Path skewDictPath = new org.apache.hadoop.fs.Path(\"${skewDataStorage}\");",
          "504:          |       org.apache.hadoop.fs.FileSystem fs = skewDictPath.getFileSystem(new org.apache.hadoop.conf.Configuration());",
          "505:          |       if (fs.exists(skewDictPath)) {",
          "507:          |               fs.open(skewDictPath));",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "f0c479686f7f3584198f5ce4b485aaf4775e599e",
      "candidate_info": {
        "commit_hash": "f0c479686f7f3584198f5ce4b485aaf4775e599e",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/f0c479686f7f3584198f5ce4b485aaf4775e599e",
        "files": [
          "core-cube/src/main/java/org/apache/kylin/cube/common/SegmentPruner.java",
          "core-cube/src/test/java/org/apache/kylin/cube/common/SegmentPrunerTest.java"
        ],
        "message": "KYLIN-4354 Prune segment not using given filter when using jdbc preparestatement\n\n(cherry picked from commit 0ac14a7203e43c60ca6235f0f44cf3f59a1b97a9)",
        "before_after_code_files": [
          "core-cube/src/main/java/org/apache/kylin/cube/common/SegmentPruner.java||core-cube/src/main/java/org/apache/kylin/cube/common/SegmentPruner.java",
          "core-cube/src/test/java/org/apache/kylin/cube/common/SegmentPrunerTest.java||core-cube/src/test/java/org/apache/kylin/cube/common/SegmentPrunerTest.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "core-cube/src/main/java/org/apache/kylin/cube/common/SegmentPruner.java||core-cube/src/main/java/org/apache/kylin/cube/common/SegmentPruner.java": [
          "File: core-cube/src/main/java/org/apache/kylin/cube/common/SegmentPruner.java -> core-cube/src/main/java/org/apache/kylin/cube/common/SegmentPruner.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "31: import org.apache.kylin.metadata.datatype.DataTypeOrder;",
          "32: import org.apache.kylin.metadata.filter.CompareTupleFilter;",
          "33: import org.apache.kylin.metadata.filter.ConstantTupleFilter;",
          "34: import org.apache.kylin.metadata.filter.TupleFilter;",
          "35: import org.apache.kylin.metadata.model.DataModelDesc;",
          "36: import org.apache.kylin.metadata.model.PartitionDesc;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "34: import org.apache.kylin.metadata.filter.DynamicTupleFilter;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "127:             return true;",
          "131:             return true;",
          "133:         TblColRef col = comp.getColumn();",
          "",
          "[Removed Lines]",
          "130:         if (comp.getChildren().size() > 1 && !(comp.getChildren().get(1) instanceof ConstantTupleFilter))",
          "",
          "[Added Lines]",
          "131:         if (comp.getChildren().size() <= 1 || !isConstantValue(comp.getChildren().get(1)))",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "159:         }",
          "160:     }",
          "162:     private static String toString(Object v) {",
          "163:         return v == null ? null : v.toString();",
          "164:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "163:     private static boolean isConstantValue(TupleFilter tupleFilter) {",
          "164:         return tupleFilter instanceof ConstantTupleFilter || tupleFilter instanceof DynamicTupleFilter;",
          "165:     }",
          "",
          "---------------"
        ],
        "core-cube/src/test/java/org/apache/kylin/cube/common/SegmentPrunerTest.java||core-cube/src/test/java/org/apache/kylin/cube/common/SegmentPrunerTest.java": [
          "File: core-cube/src/test/java/org/apache/kylin/cube/common/SegmentPrunerTest.java -> core-cube/src/test/java/org/apache/kylin/cube/common/SegmentPrunerTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "31: import org.apache.kylin.cube.CubeManager;",
          "32: import org.apache.kylin.cube.CubeSegment;",
          "33: import org.apache.kylin.cube.DimensionRangeInfo;",
          "34: import org.apache.kylin.metadata.filter.ConstantTupleFilter;",
          "35: import org.apache.kylin.metadata.filter.LogicalTupleFilter;",
          "36: import org.apache.kylin.metadata.filter.TupleFilter;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "34: import org.apache.kylin.metadata.filter.DynamicTupleFilter;",
          "35: import org.apache.kylin.metadata.filter.CompareTupleFilter;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "76:         Assert.assertFalse(segmentPruner.check(seg));",
          "77:     }",
          "79:     @Test",
          "80:     public void testDimensionRangeCheck() {",
          "81:         CubeSegment cubeSegment = cube.getSegments().getFirstSegment();",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "81:     @Test",
          "82:     public void testDynamicFilter() {",
          "83:         CubeSegment seg = cube.getFirstSegment();",
          "84:         TblColRef col = cube.getModel().findColumn(\"CUSTOMER.C_NATION\");",
          "87:         {",
          "88:             DynamicTupleFilter dyna = new DynamicTupleFilter(\"$0\");",
          "89:             CompareTupleFilter f = compare(col, FilterOperatorEnum.EQ, dyna);",
          "90:             f.bindVariable(\"$0\", \"CHINA\");",
          "91:             SegmentPruner segmentPruner = new SegmentPruner(f);",
          "92:             Assert.assertTrue(segmentPruner.check(seg));",
          "93:         }",
          "96:         {",
          "97:             DynamicTupleFilter dyna = new DynamicTupleFilter(\"$0\");",
          "98:             CompareTupleFilter f = compare(col, FilterOperatorEnum.EQ, dyna);",
          "99:             f.bindVariable(\"$0\", \"XXXX\");",
          "100:             SegmentPruner segmentPruner = new SegmentPruner(f);",
          "101:             Assert.assertTrue(segmentPruner.check(seg) == false);",
          "102:         }",
          "103:     }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "57f6a272c96af7d5ee8cb2e035376fe452c57c35",
      "candidate_info": {
        "commit_hash": "57f6a272c96af7d5ee8cb2e035376fe452c57c35",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/57f6a272c96af7d5ee8cb2e035376fe452c57c35",
        "files": [
          "README.md",
          "docker/README-standalone.md",
          "docker/build_standalone_image.sh",
          "docker/dockerfile/standalone/Dockerfile",
          "docker/dockerfile/standalone/build_standalone_image.sh",
          "docker/setup_standalone.sh"
        ],
        "message": "KYLIN-5051, minor fix and add quick start about docker in README.md",
        "before_after_code_files": [
          "docker/build_standalone_image.sh||docker/build_standalone_image.sh",
          "docker/dockerfile/standalone/build_standalone_image.sh||docker/dockerfile/standalone/build_standalone_image.sh",
          "docker/setup_standalone.sh||docker/setup_standalone.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "docker/build_standalone_image.sh||docker/build_standalone_image.sh": [
          "File: docker/build_standalone_image.sh -> docker/build_standalone_image.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "docker/dockerfile/standalone/build_standalone_image.sh||docker/dockerfile/standalone/build_standalone_image.sh": [
          "File: docker/dockerfile/standalone/build_standalone_image.sh -> docker/dockerfile/standalone/build_standalone_image.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: echo \"build image in dir \"${DIR}",
          "24: echo \"start build Hadoop docker image\"",
          "26: docker build -f Dockerfile -t apachekylin/apache-kylin-standalone:4.0.0 .",
          "",
          "[Removed Lines]",
          "25: docker build -f Dockerfile_hadoop -t hadoop2.7-all-in-one-for-kylin4 .",
          "",
          "[Added Lines]",
          "25: docker build -f Dockerfile_hadoop -t hadoop2.8-all-in-one-for-kylin4 .",
          "",
          "---------------"
        ],
        "docker/setup_standalone.sh||docker/setup_standalone.sh": [
          "File: docker/setup_standalone.sh -> docker/setup_standalone.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "23: -p 8032:8032 \\",
          "24: -p 8042:8042 \\",
          "25: -p 2181:2181 \\",
          "",
          "[Removed Lines]",
          "26: apachekylin/apache-kylin-standalone:4.0.0-beta",
          "",
          "[Added Lines]",
          "26: --name kylin-4.0.0 \\",
          "27: apachekylin/apache-kylin-standalone:4.0.0",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "a4a8480a05449b7ab19c7eace096dc3e39697dcb",
      "candidate_info": {
        "commit_hash": "a4a8480a05449b7ab19c7eace096dc3e39697dcb",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/a4a8480a05449b7ab19c7eace096dc3e39697dcb",
        "files": [
          "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/CalciteToSparkPlaner.scala",
          "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/SparkEngine.java",
          "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/UnionPlan.scala",
          "query/src/main/java/org/apache/kylin/query/exec/SparkExec.java"
        ],
        "message": "KYLIN-4888, Performance optimization of union query with spark engine",
        "before_after_code_files": [
          "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/CalciteToSparkPlaner.scala||kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/CalciteToSparkPlaner.scala",
          "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/SparkEngine.java||kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/SparkEngine.java",
          "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/UnionPlan.scala||kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/UnionPlan.scala",
          "query/src/main/java/org/apache/kylin/query/exec/SparkExec.java||query/src/main/java/org/apache/kylin/query/exec/SparkExec.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/CalciteToSparkPlaner.scala||kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/CalciteToSparkPlaner.scala": [
          "File: kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/CalciteToSparkPlaner.scala -> kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/CalciteToSparkPlaner.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "23: import org.apache.kylin.shaded.com.google.common.collect.Lists",
          "24: import org.apache.calcite.DataContext",
          "25: import org.apache.calcite.rel.{RelNode, RelVisitor}",
          "28: import org.apache.spark.internal.Logging",
          "29: import org.apache.spark.sql.DataFrame",
          "",
          "[Removed Lines]",
          "26: import org.apache.kylin.query.relnode.{OLAPAggregateRel, OLAPFilterRel, OLAPJoinRel, OLAPLimitRel, OLAPProjectRel, OLAPSortRel, OLAPTableScan, OLAPUnionRel, OLAPValuesRel, OLAPWindowRel}",
          "27: import org.apache.kylin.query.runtime.plans.{AggregatePlan, FilterPlan, LimitPlan, ProjectPlan, SortPlan, TableScanPlan, ValuesPlan, WindowPlan}",
          "",
          "[Added Lines]",
          "26: import org.apache.kylin.query.relnode._",
          "27: import org.apache.kylin.query.runtime.plans._",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "95:           val right = stack.pop()",
          "96:           val left = stack.pop()",
          "97:           logTime(\"join\") {",
          "99:           }",
          "100:         }",
          "101:       case rel: OLAPUnionRel =>",
          "102:         val size = unionStack.pop()",
          "103:         val java = Range(0, stack.size() - size).map(a => stack.pop()).asJava",
          "104:         logTime(\"union\") {",
          "106:         }",
          "107:       case rel: OLAPValuesRel =>",
          "108:         logTime(\"values\") {",
          "",
          "[Removed Lines]",
          "98:             plans.JoinPlan.join(Lists.newArrayList(left, right), rel)",
          "105:           plans.UnionPlan.union(Lists.newArrayList(java), rel, dataContext)",
          "",
          "[Added Lines]",
          "98:             JoinPlan.join(Lists.newArrayList(left, right), rel)",
          "105:           UnionPlan.union(Lists.newArrayList(java), rel, dataContext)",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/SparkEngine.java||kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/SparkEngine.java": [
          "File: kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/SparkEngine.java -> kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/SparkEngine.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "57:         log.trace(\"Begin planning spark plan.\");",
          "58:         long start = System.currentTimeMillis();",
          "59:         CalciteToSparkPlaner calciteToSparkPlaner = new CalciteToSparkPlaner(dataContext);",
          "61:         calciteToSparkPlaner.go(relNode);",
          "62:         long takeTime = System.currentTimeMillis() - start;",
          "63:         log.trace(\"Plan take {} ms\", takeTime);",
          "",
          "[Removed Lines]",
          "60:         long t = System.currentTimeMillis();",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/UnionPlan.scala||kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/UnionPlan.scala": [
          "File: kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/UnionPlan.scala -> kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/plans/UnionPlan.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "31:     dataContext: DataContext): DataFrame = {",
          "32:     var df = inputs.get(0)",
          "33:     val drop = inputs.asScala.drop(1)",
          "42:     }",
          "43:     df",
          "44:   }",
          "",
          "[Removed Lines]",
          "34:     if (rel.all) {",
          "35:       for (other <- drop) {",
          "36:         df = df.union(other)",
          "37:       }",
          "38:     } else {",
          "39:       for (other <- drop) {",
          "40:         df = df.union(other).distinct()",
          "41:       }",
          "",
          "[Added Lines]",
          "34:     for (other <- drop) {",
          "35:       df = df.union(other)",
          "36:     }",
          "37:     if (!rel.all) {",
          "38:       df = df.distinct()",
          "",
          "---------------"
        ],
        "query/src/main/java/org/apache/kylin/query/exec/SparkExec.java||query/src/main/java/org/apache/kylin/query/exec/SparkExec.java": [
          "File: query/src/main/java/org/apache/kylin/query/exec/SparkExec.java -> query/src/main/java/org/apache/kylin/query/exec/SparkExec.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "25: import org.apache.kylin.common.QueryContextFacade;",
          "26: import org.apache.kylin.common.debug.BackdoorToggles;",
          "27: import org.apache.kylin.query.relnode.OLAPRel;",
          "31: public class SparkExec {",
          "35:     public static Enumerable<Object[]> collectToEnumerable(DataContext dataContext) {",
          "36:         if (BackdoorToggles.getPrepareOnly()) {",
          "37:             return Linq4j.emptyEnumerable();",
          "",
          "[Removed Lines]",
          "28: import org.slf4j.Logger;",
          "29: import org.slf4j.LoggerFactory;",
          "33:     private static final Logger logger = LoggerFactory.getLogger(SparkExec.class);",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "1f63a3bd05c1a79102cfa3a13e61aadd6e423aea",
      "candidate_info": {
        "commit_hash": "1f63a3bd05c1a79102cfa3a13e61aadd6e423aea",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/1f63a3bd05c1a79102cfa3a13e61aadd6e423aea",
        "files": [
          "build/bin/kylin.sh",
          "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
          "core-common/src/main/resources/kylin-defaults.properties",
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java",
          "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/spark/sql/SparderContext.scala"
        ],
        "message": "KYLIN-5099 Decrease the default value of 'kylin.cube.cubeplanner.expansion-threshold'",
        "before_after_code_files": [
          "build/bin/kylin.sh||build/bin/kylin.sh",
          "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
          "core-common/src/main/resources/kylin-defaults.properties||core-common/src/main/resources/kylin-defaults.properties",
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java",
          "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/spark/sql/SparderContext.scala||kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/spark/sql/SparderContext.scala"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [
            "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java"
          ],
          "candidate": [
            "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java"
          ]
        }
      },
      "candidate_diff": {
        "build/bin/kylin.sh||build/bin/kylin.sh": [
          "File: build/bin/kylin.sh -> build/bin/kylin.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "140:   <pool name=\"query_pushdown\">",
          "141:     <schedulingMode>FAIR</schedulingMode>",
          "142:     <weight>1</weight>",
          "144:   </pool>",
          "145:   <pool name=\"heavy_tasks\">",
          "146:     <schedulingMode>FAIR</schedulingMode>",
          "",
          "[Removed Lines]",
          "143:     <minShare>0</minShare>",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "155:   <pool name=\"vip_tasks\">",
          "156:     <schedulingMode>FAIR</schedulingMode>",
          "157:     <weight>15</weight>",
          "159:   </pool>",
          "160: </allocations>",
          "161: EOL",
          "",
          "[Removed Lines]",
          "158:     <minShare>0</minShare>",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java": [
          "File: core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java -> core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "796:     }",
          "798:     public double getCubePlannerExpansionRateThreshold() {",
          "800:     }",
          "802:     public int getCubePlannerRecommendCuboidCacheMaxSize() {",
          "",
          "[Removed Lines]",
          "799:         return Double.parseDouble(getOptional(\"kylin.cube.cubeplanner.expansion-threshold\", \"15.0\"));",
          "",
          "[Added Lines]",
          "799:         return Double.parseDouble(getOptional(\"kylin.cube.cubeplanner.expansion-threshold\", \"2.5\"));",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "3312:     @ConfigTag(ConfigTag.Tag.GLOBAL_LEVEL)",
          "3313:     public boolean isSparderCanaryEnabled() {",
          "3315:     }",
          "",
          "[Removed Lines]",
          "3314:         return Boolean.parseBoolean(this.getOptional(\"kylin.canary.sparder-context-canary-enabled\", TRUE));",
          "",
          "[Added Lines]",
          "3314:         return Boolean.parseBoolean(this.getOptional(\"kylin.canary.sparder-context-canary-enabled\", FALSE));",
          "",
          "---------------"
        ],
        "core-common/src/main/resources/kylin-defaults.properties||core-common/src/main/resources/kylin-defaults.properties": [
          "File: core-common/src/main/resources/kylin-defaults.properties -> core-common/src/main/resources/kylin-defaults.properties",
          "--- Hunk 1 ---",
          "[Context before]",
          "125: kylin.cube.cubeplanner.enabled=false",
          "126: kylin.cube.cubeplanner.enabled-for-existing-cube=false",
          "128: kylin.cube.cubeplanner.recommend-cache-max-size=200",
          "129: kylin.cube.cubeplanner.mandatory-rollup-threshold=1000",
          "130: kylin.cube.cubeplanner.algorithm-threshold-greedy=8",
          "",
          "[Removed Lines]",
          "127: kylin.cube.cubeplanner.expansion-threshold=15.0",
          "",
          "[Added Lines]",
          "128: # In kylin3, the default value of 'kylin.cube.cubeplanner.expansion-threshold' is 15.",
          "129: # Because the storage engine in kylin4 changes, the storage size of the same cuboid will become smaller.",
          "130: # Under the same expansion rate, the number of cuboids in kylin4 will be greater than that in kylin3.",
          "131: # In order to keep the pruning result of the phase1 of the cube planner in kylin4 roughly the same as that in kylin3,",
          "132: # the default value of this parameter is adjusted to 2.5.",
          "133: kylin.cube.cubeplanner.expansion-threshold=2.5",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java": [
          "File: kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java -> kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "156:             recommendCuboidMap = StatisticsDecisionUtil.optimizeCubingPlan(newSegment);",
          "159:         }",
          "161:         buildLayoutWithUpdate = new BuildLayoutWithUpdate(config);",
          "",
          "[Removed Lines]",
          "157:             if (!recommendCuboidMap.isEmpty())",
          "158:                 logger.info(\"Triggered cube planner phase one .\");",
          "",
          "[Added Lines]",
          "157:             if (!recommendCuboidMap.isEmpty()) {",
          "158:                 logger.info(\"Triggered cube planner phase one. The number of recommend cuboids is {}. \" +",
          "159:                         \"If there are too many cuboids, \" +",
          "160:                         \"you can reduce the number of recommend cuboids by reducing the value of \" +",
          "161:                         \"'kylin.cube.cubeplanner.expansion-threshold'\", recommendCuboidMap.size());",
          "162:             }",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/spark/sql/SparderContext.scala||kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/spark/sql/SparderContext.scala": [
          "File: kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/spark/sql/SparderContext.scala -> kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/spark/sql/SparderContext.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "127:     getSparkSession.sparkContext.conf.get(key)",
          "128:   }",
          "131:     this.synchronized {",
          "132:       if (initializingThread == null && (spark == null || spark.sparkContext.isStopped)) {",
          "133:         initializingThread = new Thread(new Runnable {",
          "",
          "[Removed Lines]",
          "130:   def initSpark(): Unit =",
          "",
          "[Added Lines]",
          "130:   def initSpark(): Unit = {",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "220:       ShardFileStatusCache.getFileStatusCache(getOriginalSparkSession)",
          "221:     }",
          "223:   def registerListener(sc: SparkContext): Unit = {",
          "224:     val sparkListener = new SparkListener {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "222:   }",
          "",
          "---------------"
        ]
      }
    }
  ]
}