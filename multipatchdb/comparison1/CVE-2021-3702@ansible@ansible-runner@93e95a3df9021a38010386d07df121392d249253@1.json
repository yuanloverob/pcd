{
  "cve_id": "CVE-2021-3702",
  "cve_desc": "A race condition flaw was found in ansible-runner, where an attacker could watch for rapid creation and deletion of a temporary directory, substitute their directory at that name, and then have access to ansible-runner's private_data_dir the next time ansible-runner made use of the private_data_dir. The highest Threat out of this flaw is to integrity and confidentiality.",
  "repo": "ansible/ansible-runner",
  "patch_hash": "93e95a3df9021a38010386d07df121392d249253",
  "patch_info": {
    "commit_hash": "93e95a3df9021a38010386d07df121392d249253",
    "repo": "ansible/ansible-runner",
    "commit_url": "https://github.com/ansible/ansible-runner/commit/93e95a3df9021a38010386d07df121392d249253",
    "files": [
      "ansible_runner/interface.py",
      "ansible_runner/runner.py",
      "ansible_runner/streaming.py"
    ],
    "message": "Successfully runs\n\nStreamController and StreamWorker are now fleshed out.",
    "before_after_code_files": [
      "ansible_runner/interface.py||ansible_runner/interface.py",
      "ansible_runner/runner.py||ansible_runner/runner.py",
      "ansible_runner/streaming.py||ansible_runner/streaming.py"
    ]
  },
  "patch_diff": {
    "ansible_runner/interface.py||ansible_runner/interface.py": [
      "File: ansible_runner/interface.py -> ansible_runner/interface.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "24: from ansible_runner import output",
      "25: from ansible_runner.runner_config import RunnerConfig",
      "26: from ansible_runner.runner import Runner",
      "28: from ansible_runner.utils import (",
      "29:     dump_artifacts,",
      "30:     check_isolation_executable_installed,",
      "",
      "[Removed Lines]",
      "27: from ansible_runner.streaming import StreamWorker",
      "",
      "[Added Lines]",
      "27: from ansible_runner.streaming import StreamController, StreamWorker",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "65:     event_callback_handler = kwargs.pop('event_handler', None)",
      "66:     status_callback_handler = kwargs.pop('status_handler', None)",
      "67:     cancel_callback = kwargs.pop('cancel_callback', None)",
      "69:     finished_callback = kwargs.pop('finished_callback', None)",
      "71:     control_out = kwargs.pop('control_out', None)",
      "78:     rc = RunnerConfig(**kwargs)",
      "79:     rc.prepare()",
      "",
      "[Removed Lines]",
      "68:     artifacts_callback = kwargs.pop('artifacts_callback', None)  # Currently not expected",
      "72:     if control_out is not None:",
      "73:         stream_worker = StreamWorker(control_out)",
      "74:         status_callback_handler = stream_worker.status_handler",
      "75:         event_callback_handler = stream_worker.event_handler",
      "76:         artifacts_callback = stream_worker.artifacts_callback",
      "",
      "[Added Lines]",
      "67:     artifacts_handler = kwargs.pop('artifacts_handler', None)",
      "71:     control_in = kwargs.pop('control_in', None)",
      "73:     worker_in = kwargs.pop('worker_in', None)",
      "74:     worker_out = kwargs.pop('worker_out', None)",
      "76:     if worker_in is not None and worker_out is not None:",
      "77:         stream_worker = StreamWorker(worker_in, worker_out, **kwargs)",
      "78:         return stream_worker",
      "80:     if control_in is not None and control_out is not None:",
      "81:         stream_controller = StreamController(control_in, control_out,",
      "82:                                              event_handler=event_callback_handler,",
      "83:                                              status_handler=status_callback_handler,",
      "84:                                              artifacts_handler=artifacts_handler,",
      "85:                                              cancel_callback=cancel_callback,",
      "86:                                              finished_callback=finished_callback,",
      "88:         return stream_controller",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "81:     return Runner(rc,",
      "82:                   event_handler=event_callback_handler,",
      "83:                   status_handler=status_callback_handler,",
      "84:                   cancel_callback=cancel_callback,",
      "86:                   finished_callback=finished_callback)",
      "",
      "[Removed Lines]",
      "85:                   artifacts_callback=artifacts_callback,",
      "",
      "[Added Lines]",
      "96:                   artifacts_handler=artifacts_handler,",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "124:     :param artifact_dir: The path to the directory where artifacts should live, this defaults to 'artifacts' under the private data dir",
      "125:     :param project_dir: The path to the playbook content, this defaults to 'project' within the private data dir",
      "126:     :param rotate_artifacts: Keep at most n artifact directories, disable with a value of 0 which is the default",
      "128:     :param event_handler: An optional callback that will be invoked any time an event is received by Runner itself, return True to keep the event",
      "129:     :param cancel_callback: An optional callback that can inform runner to cancel (returning True) or not (returning False)",
      "130:     :param finished_callback: An optional callback that will be invoked at shutdown after process cleanup.",
      "131:     :param status_handler: An optional callback that will be invoked any time the status changes (e.g...started, running, failed, successful, timeout)",
      "132:     :param process_isolation: Enable process isolation, using either a container engine (e.g. podman) or a sandbox (e.g. bwrap).",
      "133:     :param process_isolation_executable: Process isolation executable or container engine used to isolate execution. (default: podman)",
      "134:     :param process_isolation_path: Path that an isolated playbook run will use for staging. (default: /tmp)",
      "",
      "[Removed Lines]",
      "127:     :param control_out: A file-like object used for streaming information back to a control instance of Runner",
      "",
      "[Added Lines]",
      "139:     :param control_in: A file object used for receiving streamed data back from a worker instance of Runner",
      "140:     :param control_out: A file object used for streaming project data to a worker instance of Runner",
      "141:     :param worker_in: A file object used for streaming project data to a worker instance of Runner",
      "142:     :param worker_out: A file object used for streaming information back to a control instance of Runner",
      "147:     :param artifacts_handler: An optional callback that will be invoked at the end of the run to deal with the artifacts from the run.",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "170:     :type forks: int",
      "171:     :type quiet: bool",
      "172:     :type verbosity: int",
      "173:     :type control_out: file",
      "174:     :type event_handler: function",
      "175:     :type cancel_callback: function",
      "176:     :type finished_callback: function",
      "177:     :type status_handler: function",
      "178:     :type process_isolation: bool",
      "179:     :type process_isolation_executable: str",
      "180:     :type process_isolation_path: str",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "189:     :type control_in: file",
      "191:     :type worker_in: file",
      "192:     :type worker_out: file",
      "197:     :type artifacts_handler: function",
      "",
      "---------------"
    ],
    "ansible_runner/runner.py||ansible_runner/runner.py": [
      "File: ansible_runner/runner.py -> ansible_runner/runner.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "27: class Runner(object):",
      "29:     def __init__(self, config, cancel_callback=None, remove_partials=True, event_handler=None,",
      "31:         self.config = config",
      "32:         self.cancel_callback = cancel_callback",
      "33:         self.event_handler = event_handler",
      "35:         self.finished_callback = finished_callback",
      "36:         self.status_handler = status_handler",
      "37:         self.canceled = False",
      "",
      "[Removed Lines]",
      "30:                  artifacts_callback=None, finished_callback=None, status_handler=None):",
      "34:         self.artifacts_callback = artifacts_callback",
      "",
      "[Added Lines]",
      "30:                  artifacts_handler=None, finished_callback=None, status_handler=None):",
      "34:         self.artifacts_handler = artifacts_handler",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "284:                 logger.error('Failed to delete cgroup: {}'.format(stderr))",
      "285:                 raise RuntimeError('Failed to delete cgroup: {}'.format(stderr))",
      "288:             try:",
      "290:             except Exception as e:",
      "291:                 raise CallbackError(\"Exception in Artifact Callback: {}\".format(e))",
      "",
      "[Removed Lines]",
      "287:         if self.artifacts_callback is not None:",
      "289:                 self.artifacts_callback(self.config.artifact_dir)",
      "",
      "[Added Lines]",
      "287:         if self.artifacts_handler is not None:",
      "289:                 self.artifacts_handler(self.config.artifact_dir)",
      "",
      "---------------"
    ],
    "ansible_runner/streaming.py||ansible_runner/streaming.py": [
      "File: ansible_runner/streaming.py -> ansible_runner/streaming.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "1: import base64",
      "2: import io",
      "3: import json",
      "4: import os",
      "5: import zipfile",
      "10:         self.control_out = control_out",
      "14:         self.control_out.write(b'\\n')",
      "15:         self.control_out.flush()",
      "17:     def event_handler(self, event_data):",
      "23:         buf = io.BytesIO()",
      "24:         with zipfile.ZipFile(buf, 'w', compression=zipfile.ZIP_DEFLATED, allowZip64=True) as archive:",
      "25:             for dirpath, dirs, files in os.walk(artifact_dir):",
      "",
      "[Removed Lines]",
      "8: class StreamWorker(object):",
      "9:     def __init__(self, control_out):",
      "12:     def status_handler(self, status, runner_config):",
      "13:         self.control_out.write(json.dumps(status).encode('utf-8'))",
      "18:         self.control_out.write(json.dumps(event_data).encode('utf-8'))",
      "19:         self.control_out.write(b'\\n')",
      "20:         self.control_out.flush()",
      "22:     def artifacts_callback(self, artifact_dir):",
      "",
      "[Added Lines]",
      "2: import codecs",
      "6: import stat",
      "7: import tempfile",
      "8: import uuid",
      "11: import ansible_runner",
      "12: import ansible_runner.plugins",
      "15: class UUIDEncoder(json.JSONEncoder):",
      "16:     def default(self, obj):",
      "17:         if isinstance(obj, uuid.UUID):",
      "18:             return obj.hex",
      "19:         return json.JSONEncoder.default(self, obj)",
      "22: # List of kwargs options to the run method that should be sent to the remote executor.",
      "23: remote_run_options = (",
      "24:     'forks',",
      "25:     'host_pattern',",
      "26:     'ident',",
      "27:     'ignore_logging',",
      "28:     'inventory',",
      "29:     'limit',",
      "30:     'module',",
      "31:     'module_args',",
      "32:     'omit_event_data',",
      "33:     'only_failed_event_data',",
      "34:     'playbook',",
      "35:     'verbosity',",
      "36: )",
      "39: class StreamController(object):",
      "40:     def __init__(self, control_in, control_out, status_handler=None, event_handler=None,",
      "41:                  artifacts_handler=None, cancel_callback=None, finished_callback=None, **kwargs):",
      "42:         self.control_in = control_in",
      "45:         self.kwargs = kwargs",
      "46:         self.config = ansible_runner.RunnerConfig(**kwargs)",
      "47:         self.status_handler = status_handler",
      "48:         self.event_handler = event_handler",
      "49:         self.artifacts_handler = artifacts_handler",
      "51:         self.cancel_callback = cancel_callback",
      "52:         self.finished_callback = finished_callback",
      "54:         self.status = \"unstarted\"",
      "55:         self.rc = None",
      "57:     def run(self):",
      "58:         self.send_job()",
      "60:         job_events_path = os.path.join(self.config.artifact_dir, 'job_events')",
      "61:         if not os.path.exists(job_events_path):",
      "62:             os.mkdir(job_events_path, 0o700)",
      "64:         for line in self.control_in:",
      "65:             data = json.loads(line)",
      "66:             if 'status' in data:",
      "67:                 self.status_callback(data)",
      "68:             elif 'artifacts' in data:",
      "69:                 self.artifacts_callback(data)",
      "70:             elif 'eof' in data:",
      "71:                 break",
      "72:             else:",
      "73:                 self.event_callback(data)",
      "75:         if self.finished_callback is not None:",
      "76:             self.finished_callback(self)",
      "77:         return self.status, self.rc",
      "79:     def send_job(self):",
      "80:         self.config.prepare()",
      "81:         remote_options = {key: value for key, value in self.kwargs.items() if key in remote_run_options}",
      "83:         buf = io.BytesIO()",
      "84:         with zipfile.ZipFile(buf, 'w', compression=zipfile.ZIP_DEFLATED, allowZip64=True) as archive:",
      "85:             private_data_dir = self.kwargs.get('private_data_dir', None)",
      "86:             if private_data_dir:",
      "87:                 for dirpath, dirs, files in os.walk(private_data_dir):",
      "88:                     relpath = os.path.relpath(dirpath, private_data_dir)",
      "89:                     if relpath == \".\":",
      "90:                         relpath = \"\"",
      "91:                     for fname in files:",
      "92:                         archive.write(os.path.join(dirpath, fname), arcname=os.path.join(relpath, fname))",
      "94:             kwargs = json.dumps(remote_options, cls=UUIDEncoder)",
      "95:             archive.writestr('kwargs', kwargs)",
      "96:             archive.close()",
      "97:         buf.flush()",
      "99:         data = {",
      "100:             'private_data_dir': True,",
      "101:             'payload': base64.b64encode(buf.getvalue()).decode('ascii'),",
      "102:         }",
      "103:         self.control_out.write(json.dumps(data).encode('utf-8'))",
      "106:         self.control_out.close()",
      "108:     def status_callback(self, status_data):",
      "109:         self.status = status_data['status']",
      "111:         for plugin in ansible_runner.plugins:",
      "112:             ansible_runner.plugins[plugin].status_handler(self.config, status_data)",
      "113:         if self.status_handler is not None:",
      "114:             self.status_handler(status_data, runner_config=self.config)",
      "116:     def event_callback(self, event_data):",
      "117:         full_filename = os.path.join(self.config.artifact_dir,",
      "118:                                      'job_events',",
      "119:                                      '{}-{}.json'.format(event_data['counter'],",
      "120:                                                          event_data['uuid']))",
      "122:         if self.event_handler is not None:",
      "123:             should_write = self.event_handler(event_data)",
      "124:         else:",
      "125:             should_write = True",
      "126:         for plugin in ansible_runner.plugins:",
      "127:             ansible_runner.plugins[plugin].event_handler(self.config, event_data)",
      "128:         if should_write:",
      "129:             with codecs.open(full_filename, 'w', encoding='utf-8') as write_file:",
      "130:                 os.chmod(full_filename, stat.S_IRUSR | stat.S_IWUSR)",
      "131:                 json.dump(event_data, write_file)",
      "133:     def artifacts_callback(self, artifacts_data):  # FIXME",
      "134:         if self.artifacts_handler is not None:",
      "135:             self.artifacts_handler()",
      "138: class StreamWorker(object):",
      "139:     def __init__(self, worker_in, worker_out, **kwargs):",
      "140:         self.worker_in = worker_in",
      "141:         self.worker_out = worker_out",
      "143:         self.kwargs = kwargs",
      "145:         self.private_data_dir = tempfile.TemporaryDirectory().name",
      "147:     def run(self):",
      "148:         for line in self.worker_in:",
      "149:             data = json.loads(line)",
      "150:             if data.get('private_data_dir'):",
      "151:                 buf = io.BytesIO(base64.b64decode(data['payload']))",
      "152:                 with zipfile.ZipFile(buf, 'r') as archive:",
      "153:                     archive.extractall(path=self.private_data_dir)",
      "155:         kwargs_path = os.path.join(self.private_data_dir, 'kwargs')",
      "156:         if os.path.exists(kwargs_path):",
      "157:             with open(kwargs_path, \"r\") as kwf:",
      "158:                 kwargs = json.load(kwf)",
      "159:             if not isinstance(kwargs, dict):",
      "160:                 raise ValueError(\"Invalid kwargs data\")",
      "161:         else:",
      "162:             kwargs = {}",
      "164:         self.kwargs.update(kwargs)",
      "166:         self.kwargs['quiet'] = True",
      "167:         self.kwargs['private_data_dir'] = self.private_data_dir",
      "168:         self.kwargs['status_handler'] = self.status_handler",
      "169:         self.kwargs['event_handler'] = self.event_handler",
      "170:         self.kwargs['artifacts_handler'] = self.artifacts_handler",
      "171:         self.kwargs['finished_callback'] = self.finished_callback",
      "173:         ansible_runner.interface.run(**self.kwargs)",
      "175:         # FIXME: do cleanup on the tempdir",
      "177:     def status_handler(self, status, runner_config):",
      "178:         self.worker_out.write(json.dumps(status).encode('utf-8'))",
      "179:         self.worker_out.write(b'\\n')",
      "180:         self.worker_out.flush()",
      "183:         self.worker_out.write(json.dumps(event_data).encode('utf-8'))",
      "184:         self.worker_out.write(b'\\n')",
      "185:         self.worker_out.flush()",
      "187:     def artifacts_handler(self, artifact_dir):",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "34:             'artifacts': True,",
      "35:             'payload': base64.b64encode(buf.getvalue()).decode('ascii'),",
      "36:         }",
      "",
      "[Removed Lines]",
      "37:         self.control_out.write(json.dumps(data).encode('utf-8'))",
      "38:         self.control_out.write(b'\\n')",
      "39:         self.control_out.flush()",
      "40:         self.control_out.close()",
      "",
      "[Added Lines]",
      "202:         self.worker_out.write(json.dumps(data).encode('utf-8'))",
      "203:         self.worker_out.write(b'\\n')",
      "204:         self.worker_out.flush()",
      "206:     def finished_callback(self, runner_obj):",
      "207:         self.worker_out.write(json.dumps({'eof': True}).encode('utf-8'))",
      "208:         self.worker_out.write(b'\\n')",
      "209:         self.worker_out.flush()",
      "210:         self.worker_out.close()",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "bb1d4a81d5249c1f6281d56c897106e92830353a",
      "candidate_info": {
        "commit_hash": "bb1d4a81d5249c1f6281d56c897106e92830353a",
        "repo": "ansible/ansible-runner",
        "commit_url": "https://github.com/ansible/ansible-runner/commit/bb1d4a81d5249c1f6281d56c897106e92830353a",
        "files": [
          "ansible_runner/__main__.py"
        ],
        "message": "Add command line arguments for the controller and worker streams\n\nThis doesn't quite work yet, since we need to give the worker a command.",
        "before_after_code_files": [
          "ansible_runner/__main__.py||ansible_runner/__main__.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/ansible/ansible-runner/pull/505"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "ansible_runner/__main__.py||ansible_runner/__main__.py": [
          "File: ansible_runner/__main__.py -> ansible_runner/__main__.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "232:             ),",
          "233:         ),",
          "234:     ),",
          "235:     \"roles_group\": (",
          "236:         (",
          "237:             (\"--roles-path\",),",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "235:     \"streaming_group\": (",
          "236:         (",
          "237:             ('--control-in',),",
          "238:             dict(",
          "239:                 help=\"Executes runner in controller-mode, and consumes data piped into this named file or fifo.\"",
          "240:             ),",
          "241:         ),",
          "242:         (",
          "243:             ('--control-out',),",
          "244:             dict(",
          "245:                 help=\"Executes runner in controller-mode, and pipes commands through this named file or fifo.\"",
          "246:             ),",
          "247:         ),",
          "248:         (",
          "249:             ('--worker-in',),",
          "250:             dict(",
          "251:                 help=\"Executes runner in worker-mode, and consumes commands piped into this named file or fifo.\"",
          "252:             ),",
          "253:         ),",
          "254:         (",
          "255:             ('--worker-out',),",
          "256:             dict(",
          "257:                 help=\"Executes runner in worker-mode, and pipes output data through this named file or fifo.\"",
          "258:             ),",
          "259:         ),",
          "260:     ),",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "673:     add_args_to_parser(stop_runner_group, DEFAULT_CLI_ARGS['runner_group'])",
          "674:     add_args_to_parser(isalive_runner_group, DEFAULT_CLI_ARGS['runner_group'])",
          "676:     # mutually exclusive group",
          "677:     run_mutually_exclusive_group = run_subparser.add_mutually_exclusive_group()",
          "678:     start_mutually_exclusive_group = start_subparser.add_mutually_exclusive_group()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "702:     # streaming group",
          "703:     add_args_to_parser(base_runner_group, DEFAULT_CLI_ARGS['streaming_group'])",
          "704:     add_args_to_parser(run_runner_group, DEFAULT_CLI_ARGS['streaming_group'])",
          "705:     add_args_to_parser(start_runner_group, DEFAULT_CLI_ARGS['streaming_group'])",
          "706:     add_args_to_parser(stop_runner_group, DEFAULT_CLI_ARGS['streaming_group'])",
          "707:     add_args_to_parser(isalive_runner_group, DEFAULT_CLI_ARGS['streaming_group'])",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "801:         if not (vargs.get('module') or vargs.get('role')) and not vargs.get('playbook'):",
          "802:             parser.exit(status=1, message=\"The -p option must be specified when not using -m or -r\\n\")",
          "804:     output.configure()",
          "806:     # enable or disable debug mode",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "837:     if (vargs.get('control_in') is None) != (vargs.get('control_out') is None):",
          "838:         parser.exit(status=1, message=\"Both --control-in and --control-out must be specified\\n\")",
          "839:     if (vargs.get('worker_in') is None) != (vargs.get('worker_out') is None):",
          "840:         parser.exit(status=1, message=\"Both --worker-in and --worker-out must be specified\\n\")",
          "841:     if vargs.get('control_in') is not None and vargs.get('worker_in') is not None:",
          "842:         parser.exit(status=1, message=\"Runner may not be run in both control and worker modes.\\n\")",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "886:                     run_options['process_isolation']=True",
          "887:                     run_options['process_isolation_executable']=vargs.get('container_runtime')",
          "889:                 try:",
          "890:                     res = run(**run_options)",
          "891:                 except Exception:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "929:                 if vargs.get('control_in'):",
          "930:                     run_options['control_in'] = open(vargs['control_in'], 'rb')",
          "931:                 if vargs.get('worker_in'):",
          "932:                     run_options['worker_in'] = open(vargs['worker_in'], 'rb')",
          "933:                 if vargs.get('control_in'):",
          "934:                     run_options['control_out'] = open(vargs['control_out'], 'wb')",
          "935:                 if vargs.get('control_in'):",
          "936:                     run_options['worker_out'] = open(vargs['worker_out'], 'wb')",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "4cb8ed2241b66d0db3c56b35e784b0352ee5722d",
      "candidate_info": {
        "commit_hash": "4cb8ed2241b66d0db3c56b35e784b0352ee5722d",
        "repo": "ansible/ansible-runner",
        "commit_url": "https://github.com/ansible/ansible-runner/commit/4cb8ed2241b66d0db3c56b35e784b0352ee5722d",
        "files": [
          "ansible_runner/streaming.py"
        ],
        "message": "Encode the artifacts zip file as base64",
        "before_after_code_files": [
          "ansible_runner/streaming.py||ansible_runner/streaming.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/ansible/ansible-runner/pull/505"
        ],
        "olp_code_files": {
          "patch": [
            "ansible_runner/streaming.py||ansible_runner/streaming.py"
          ],
          "candidate": [
            "ansible_runner/streaming.py||ansible_runner/streaming.py"
          ]
        }
      },
      "candidate_diff": {
        "ansible_runner/streaming.py||ansible_runner/streaming.py": [
          "File: ansible_runner/streaming.py -> ansible_runner/streaming.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1: import io",
          "2: import json",
          "3: import os",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: import base64",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "19:         self.control_out.flush()",
          "21:     def artifacts_callback(self, artifact_dir):",
          "25:         buf = io.BytesIO()",
          "26:         with zipfile.ZipFile(buf, 'w', compression=zipfile.ZIP_DEFLATED, allowZip64=True) as archive:",
          "27:             for dirpath, dirs, files in os.walk(artifact_dir):",
          "",
          "[Removed Lines]",
          "22:         self.control_out.write(json.dumps({'artifacts': True}).encode('utf-8'))",
          "23:         self.control_out.write(b'\\n')",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "32:                     archive.write(os.path.join(dirpath, fname), arcname=os.path.join(relpath, fname))",
          "33:             archive.close()",
          "36:         self.control_out.flush()",
          "37:         self.control_out.close()",
          "",
          "[Removed Lines]",
          "35:         self.control_out.write(buf.getvalue())",
          "",
          "[Added Lines]",
          "33:         data = {",
          "34:             'artifacts': True,",
          "35:             'payload': base64.b64encode(buf.getvalue()).decode('ascii'),",
          "36:         }",
          "37:         self.control_out.write(json.dumps(data).encode('utf-8'))",
          "38:         self.control_out.write(b'\\n')",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "ad28064ba62aa003a755eae56617c2d4a7b45dca",
      "candidate_info": {
        "commit_hash": "ad28064ba62aa003a755eae56617c2d4a7b45dca",
        "repo": "ansible/ansible-runner",
        "commit_url": "https://github.com/ansible/ansible-runner/commit/ad28064ba62aa003a755eae56617c2d4a7b45dca",
        "files": [
          "ansible_runner/__main__.py"
        ],
        "message": "Add an optional --private-data-dir flag to the worker subcommand",
        "before_after_code_files": [
          "ansible_runner/__main__.py||ansible_runner/__main__.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/ansible/ansible-runner/pull/505"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "ansible_runner/__main__.py||ansible_runner/__main__.py": [
          "File: ansible_runner/__main__.py -> ansible_runner/__main__.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "633:         'worker',",
          "634:         help=\"Execute work streamed from a controlling instance\"",
          "635:     )",
          "637:     process_subparser = subparser.add_parser(",
          "638:         'process',",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "636:     worker_subparser.add_argument(",
          "637:         \"--private-data-dir\",",
          "638:         help=\"base directory containing the ansible-runner metadata \"",
          "639:              \"(project, inventory, env, etc)\",",
          "640:     )",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "9abb98d53145e30ceb2cd34508d0fd0ef4250af4",
      "candidate_info": {
        "commit_hash": "9abb98d53145e30ceb2cd34508d0fd0ef4250af4",
        "repo": "ansible/ansible-runner",
        "commit_url": "https://github.com/ansible/ansible-runner/commit/9abb98d53145e30ceb2cd34508d0fd0ef4250af4",
        "files": [
          "ansible_runner/__main__.py",
          "ansible_runner/interface.py",
          "ansible_runner/receptor_plugin.py",
          "setup.py"
        ],
        "message": "Chop out the functionality using the old Python-based Receptor",
        "before_after_code_files": [
          "ansible_runner/__main__.py||ansible_runner/__main__.py",
          "ansible_runner/interface.py||ansible_runner/interface.py",
          "ansible_runner/receptor_plugin.py||ansible_runner/receptor_plugin.py",
          "setup.py||setup.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/ansible/ansible-runner/pull/505"
        ],
        "olp_code_files": {
          "patch": [
            "ansible_runner/interface.py||ansible_runner/interface.py"
          ],
          "candidate": [
            "ansible_runner/interface.py||ansible_runner/interface.py"
          ]
        }
      },
      "candidate_diff": {
        "ansible_runner/__main__.py||ansible_runner/__main__.py": [
          "File: ansible_runner/__main__.py -> ansible_runner/__main__.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "44: from ansible_runner.runner import Runner",
          "45: from ansible_runner.exceptions import AnsibleRunnerException",
          "52: VERSION = pkg_resources.require(\"ansible_runner\")[0].version",
          "54: DEFAULT_ROLES_PATH = os.getenv('ANSIBLE_ROLES_PATH', None)",
          "",
          "[Removed Lines]",
          "47: if sys.version_info >= (3, 0):",
          "48:     from ansible_runner.receptor_plugin import receptor_import",
          "49: else:",
          "50:     receptor_import = False",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "237:             ),",
          "238:         ),",
          "239:     ),",
          "264:     \"roles_group\": (",
          "265:         (",
          "266:             (\"--roles-path\",),",
          "",
          "[Removed Lines]",
          "240:     \"receptor_group\": (",
          "241:         # Receptor options",
          "242:         (",
          "243:             (\"--via-receptor\",),",
          "244:             dict(",
          "245:                 default=None,",
          "246:                 help=\"Run the job on a Receptor node rather than locally\"",
          "247:             ),",
          "248:         ),",
          "249:         (",
          "250:             (\"--receptor-peer\",),",
          "251:             dict(",
          "252:                 default=None,",
          "253:                 help=\"peer connection to use to reach the Receptor network\"",
          "254:             ),",
          "255:         ),",
          "256:         (",
          "257:             (\"--receptor-node-id\",),",
          "258:             dict(",
          "259:                 default=None,",
          "260:                 help=\"Receptor node-id to use for the local node\"",
          "261:             ),",
          "262:         )",
          "263:     ),",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "702:     add_args_to_parser(stop_runner_group, DEFAULT_CLI_ARGS['runner_group'])",
          "703:     add_args_to_parser(isalive_runner_group, DEFAULT_CLI_ARGS['runner_group'])",
          "712:     # mutually exclusive group",
          "713:     run_mutually_exclusive_group = run_subparser.add_mutually_exclusive_group()",
          "714:     start_mutually_exclusive_group = start_subparser.add_mutually_exclusive_group()",
          "",
          "[Removed Lines]",
          "705:     # receptor group (combined with runner help header)",
          "706:     add_args_to_parser(base_runner_group, DEFAULT_CLI_ARGS['receptor_group'])",
          "707:     add_args_to_parser(run_runner_group, DEFAULT_CLI_ARGS['receptor_group'])",
          "708:     add_args_to_parser(start_runner_group, DEFAULT_CLI_ARGS['receptor_group'])",
          "709:     add_args_to_parser(stop_runner_group, DEFAULT_CLI_ARGS['receptor_group'])",
          "710:     add_args_to_parser(isalive_runner_group, DEFAULT_CLI_ARGS['receptor_group'])",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "837:         if not (vargs.get('module') or vargs.get('role')) and not vargs.get('playbook'):",
          "838:             parser.exit(status=1, message=\"The -p option must be specified when not using -m or -r\\n\")",
          "846:     output.configure()",
          "848:     # enable or disable debug mode",
          "",
          "[Removed Lines]",
          "840:     if vargs.get('via_receptor') and not receptor_import:",
          "841:         parser.exit(status=1, message=\"The --via-receptor option requires Receptor to be installed.\\n\")",
          "843:     if vargs.get('via_receptor') and vargs.get('command') != 'run':",
          "844:         parser.exit(status=1, message=\"Only the 'run' command is supported via Receptor.\\n\")",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "921:                                    resource_profiling_pid_poll_interval=vargs.get('resource_profiling_pid_poll_interval'),",
          "922:                                    resource_profiling_results_dir=vargs.get('resource_profiling_results_dir'),",
          "923:                                    limit=vargs.get('limit'),",
          "927:                                    cli_execenv_cmd=cli_execenv_cmd",
          "928:                                    )",
          "929:                 if vargs.get('command') in ('adhoc', 'playbook'):",
          "",
          "[Removed Lines]",
          "924:                                    via_receptor=vargs.get('via_receptor'),",
          "925:                                    receptor_peer=vargs.get('receptor_peer'),",
          "926:                                    receptor_node_id=vargs.get('receptor_node_id'),",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "ansible_runner/interface.py||ansible_runner/interface.py": [
          "File: ansible_runner/interface.py -> ansible_runner/interface.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "29:     check_isolation_executable_installed,",
          "30: )",
          "37: logging.getLogger('ansible-runner').addHandler(logging.NullHandler())",
          "",
          "[Removed Lines]",
          "32: if sys.version_info >= (3, 0):",
          "33:     from ansible_runner.receptor_plugin import run_via_receptor, receptor_import",
          "34: else:",
          "35:     receptor_import = False",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "145:     :param fact_cache_type: A string of the type of fact cache to use.  Defaults to 'jsonfile'.",
          "146:     :param omit_event_data: Omits extra ansible event data from event payload (stdout and event still included)",
          "147:     :param only_failed_event_data: Omits extra ansible event data unless it's a failed event (stdout and event still included)",
          "151:     :param cli_execenv_cmd: Tells Ansible Runner to emulate the CLI of Ansible by prepping an Execution Environment and then passing the user provided cmdline",
          "152:     :type private_data_dir: str",
          "153:     :type ident: str",
          "",
          "[Removed Lines]",
          "148:     :param via_receptor: If set, specifies a Receptor node-id on which the job will be run remotely",
          "149:     :param receptor_peer: Specifies the Receptor listener, in URL format, to use to connect to the Receptor network",
          "150:     :param receptor_node_id: Specifies the node-id to assign to the local Receptor ephemeral node",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "191:     :type fact_cache_type: str",
          "192:     :type omit_event_data: bool",
          "193:     :type only_failed_event_data: bool",
          "197:     :type cli_execenv_cmd: str",
          "199:     :returns: A :py:class:`ansible_runner.runner.Runner` object, or a simple object containing `rc` if run remotely",
          "200:     '''",
          "215: def run_async(**kwargs):",
          "",
          "[Removed Lines]",
          "194:     :type via_receptor: str",
          "195:     :type receptor_peer: str",
          "196:     :type receptor_node_id: str",
          "201:     via_receptor = kwargs.pop('via_receptor', None)",
          "202:     receptor_peer = kwargs.pop('receptor_peer', None)",
          "203:     receptor_node_id = kwargs.pop('receptor_node_id', None)",
          "204:     if via_receptor:",
          "205:         if not receptor_import:",
          "206:             raise RuntimeError('Receptor is not installed or could not be imported')",
          "207:         r = run_via_receptor(via_receptor, receptor_peer, receptor_node_id, kwargs)",
          "208:         return r",
          "209:     else:",
          "210:         r = init_runner(**kwargs)",
          "211:         r.run()",
          "212:         return r",
          "",
          "[Added Lines]",
          "190:     r = init_runner(**kwargs)",
          "191:     r.run()",
          "192:     return r",
          "",
          "---------------"
        ],
        "ansible_runner/receptor_plugin.py||ansible_runner/receptor_plugin.py": [
          "File: ansible_runner/receptor_plugin.py -> ansible_runner/receptor_plugin.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "setup.py||setup.py": [
          "File: setup.py -> setup.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "26:     ],",
          "27:     zip_safe=False,",
          "28:     entry_points={",
          "30:         'console_scripts': [",
          "31:             'ansible-runner = ansible_runner.__main__:main'",
          "32:         ]",
          "",
          "[Removed Lines]",
          "29:         'receptor.worker': 'ansible_runner = ansible_runner.receptor_plugin',",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "ab6e72ed784bcb18a6e0c91ce4a8c29d201b2988",
      "candidate_info": {
        "commit_hash": "ab6e72ed784bcb18a6e0c91ce4a8c29d201b2988",
        "repo": "ansible/ansible-runner",
        "commit_url": "https://github.com/ansible/ansible-runner/commit/ab6e72ed784bcb18a6e0c91ce4a8c29d201b2988",
        "files": [
          "ansible_runner/streaming.py"
        ],
        "message": "Close a race condition with temporary files\n\nThe previous code allowed a race where an attacker could watch for\ncreation of a rapid creation and deletion of a temporary directory,\nsubstitute their own directory at that name, and then have access to\nansible-runner's private_data_dir the next time ansible-runner made\nues of the private_data_dir.\n\nThis code fixes the issue by creating the directory securely using\nmkdtemp() and not deleting it afterwards.",
        "before_after_code_files": [
          "ansible_runner/streaming.py||ansible_runner/streaming.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "ansible_runner/streaming.py||ansible_runner/streaming.py"
          ],
          "candidate": [
            "ansible_runner/streaming.py||ansible_runner/streaming.py"
          ]
        }
      },
      "candidate_diff": {
        "ansible_runner/streaming.py||ansible_runner/streaming.py": [
          "File: ansible_runner/streaming.py -> ansible_runner/streaming.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "74:         private_data_dir = kwargs.get('private_data_dir')",
          "75:         if private_data_dir is None:",
          "77:         self.private_data_dir = private_data_dir",
          "79:         self.status = \"unstarted\"",
          "",
          "[Removed Lines]",
          "76:             private_data_dir = tempfile.TemporaryDirectory().name",
          "",
          "[Added Lines]",
          "76:             private_data_dir = tempfile.mkdtemp()",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "165:         private_data_dir = kwargs.get('private_data_dir')",
          "166:         if private_data_dir is None:",
          "168:         self.private_data_dir = private_data_dir",
          "169:         self._loader = ArtifactLoader(self.private_data_dir)",
          "",
          "[Removed Lines]",
          "167:             private_data_dir = tempfile.TemporaryDirectory().name",
          "",
          "[Added Lines]",
          "167:             private_data_dir = tempfile.mkdtemp()",
          "",
          "---------------"
        ]
      }
    }
  ]
}