{
  "cve_id": "CVE-2018-8009",
  "cve_desc": "Apache Hadoop 3.1.0, 3.0.0-alpha to 3.0.2, 2.9.0 to 2.9.1, 2.8.0 to 2.8.4, 2.0.0-alpha to 2.7.6, 0.23.0 to 0.23.11 is exploitable via the zip slip vulnerability in places that accept a zip file.",
  "repo": "apache/hadoop",
  "patch_hash": "45a1c680c276c4501402f7bc4cebcf85a6fbc7f5",
  "patch_info": {
    "commit_hash": "45a1c680c276c4501402f7bc4cebcf85a6fbc7f5",
    "repo": "apache/hadoop",
    "commit_url": "https://github.com/apache/hadoop/commit/45a1c680c276c4501402f7bc4cebcf85a6fbc7f5",
    "files": [
      "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java",
      "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileUtil.java"
    ],
    "message": "Additional check when unpacking archives. Contributed by Jason Lowe and Akira Ajisaka.",
    "before_after_code_files": [
      "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java||hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java",
      "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileUtil.java||hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileUtil.java"
    ]
  },
  "patch_diff": {
    "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java||hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java": [
      "File: hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java -> hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "587:   public static void unZip(File inFile, File unzipDir) throws IOException {",
      "588:     Enumeration<? extends ZipEntry> entries;",
      "589:     ZipFile zipFile = new ZipFile(inFile);",
      "591:     try {",
      "592:       entries = zipFile.entries();",
      "593:       while (entries.hasMoreElements()) {",
      "594:         ZipEntry entry = entries.nextElement();",
      "595:         if (!entry.isDirectory()) {",
      "596:           InputStream in = zipFile.getInputStream(entry);",
      "597:           try {",
      "600:               if (!file.getParentFile().isDirectory()) {",
      "601:                 throw new IOException(\"Mkdirs failed to create \" +",
      "602:                                       file.getParentFile().toString());",
      "",
      "[Removed Lines]",
      "598:             File file = new File(unzipDir, entry.getName());",
      "599:             if (!file.getParentFile().mkdirs()) {",
      "",
      "[Added Lines]",
      "590:     String targetDirPath = unzipDir.getCanonicalPath() + File.separator;",
      "597:           File file = new File(unzipDir, entry.getName());",
      "598:           if (!file.getCanonicalPath().startsWith(targetDirPath)) {",
      "599:             throw new IOException(\"expanding \" + entry.getName()",
      "600:                 + \" would create file outside of \" + unzipDir);",
      "601:           }",
      "604:             if (!file.getParentFile().mkdirs()) {",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "706:   private static void unpackEntries(TarArchiveInputStream tis,",
      "707:       TarArchiveEntry entry, File outputDir) throws IOException {",
      "708:     if (entry.isDirectory()) {",
      "709:       File subDir = new File(outputDir, entry.getName());",
      "710:       if (!subDir.mkdirs() && !subDir.isDirectory()) {",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "713:     String targetDirPath = outputDir.getCanonicalPath() + File.separator;",
      "714:     File outputFile = new File(outputDir, entry.getName());",
      "715:     if (!outputFile.getCanonicalPath().startsWith(targetDirPath)) {",
      "716:       throw new IOException(\"expanding \" + entry.getName()",
      "717:           + \" would create entry outside of \" + outputDir);",
      "718:     }",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "719:       return;",
      "720:     }",
      "723:     if (!outputFile.getParentFile().exists()) {",
      "724:       if (!outputFile.getParentFile().mkdirs()) {",
      "725:         throw new IOException(\"Mkdirs failed to create tar internal dir \"",
      "",
      "[Removed Lines]",
      "722:     File outputFile = new File(outputDir, entry.getName());",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------"
    ],
    "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileUtil.java||hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileUtil.java": [
      "File: hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileUtil.java -> hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileUtil.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "25: import java.io.FileReader;",
      "26: import java.io.IOException;",
      "27: import java.io.OutputStream;",
      "29: import java.io.PrintWriter;",
      "30: import java.util.ArrayList;",
      "31: import java.util.Arrays;",
      "32: import java.util.Collections;",
      "",
      "[Removed Lines]",
      "28: import java.net.URI;",
      "",
      "[Added Lines]",
      "29: import java.net.URI;",
      "30: import java.nio.charset.StandardCharsets;",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "40: import org.apache.commons.logging.Log;",
      "41: import org.apache.commons.logging.LogFactory;",
      "42: import org.apache.hadoop.conf.Configuration;",
      "43: import org.apache.hadoop.util.Shell;",
      "44: import org.apache.hadoop.util.StringUtils;",
      "45: import org.apache.tools.tar.TarEntry;",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "44: import org.apache.hadoop.test.GenericTestUtils;",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "743:     } catch (IOException ioe) {",
      "745:     }",
      "748:   @Test (timeout = 30000)",
      "",
      "[Removed Lines]",
      "746:   }",
      "",
      "[Added Lines]",
      "746:   }",
      "748:   @Test (timeout = 30000)",
      "749:   public void testUnZip2() throws IOException {",
      "750:     setupDirs();",
      "752:     final File simpleZip = new File(del, FILE);",
      "753:     OutputStream os = new FileOutputStream(simpleZip);",
      "754:     try (ZipOutputStream tos = new ZipOutputStream(os)) {",
      "756:       ZipEntry ze = new ZipEntry(\"../foo\");",
      "757:       byte[] data = \"some-content\".getBytes(StandardCharsets.UTF_8);",
      "758:       ze.setSize(data.length);",
      "759:       tos.putNextEntry(ze);",
      "760:       tos.write(data);",
      "761:       tos.closeEntry();",
      "762:       tos.flush();",
      "763:       tos.finish();",
      "764:     }",
      "767:     try {",
      "768:       FileUtil.unZip(simpleZip, tmp);",
      "769:       Assert.fail(\"unZip should throw IOException.\");",
      "770:     } catch (IOException e) {",
      "771:       GenericTestUtils.assertExceptionContains(",
      "772:           \"would create file outside of\", e);",
      "773:     }",
      "774:   }",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "eaa2b8035b584dfcf7c79a33484eb2dffd3fdb11",
      "candidate_info": {
        "commit_hash": "eaa2b8035b584dfcf7c79a33484eb2dffd3fdb11",
        "repo": "apache/hadoop",
        "commit_url": "https://github.com/apache/hadoop/commit/eaa2b8035b584dfcf7c79a33484eb2dffd3fdb11",
        "files": [
          "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/RunJar.java",
          "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestRunJar.java"
        ],
        "message": "Additional check when unpacking archives. Contributed by Wilfred Spiegelenburg.",
        "before_after_code_files": [
          "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/RunJar.java||hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/RunJar.java",
          "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestRunJar.java||hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestRunJar.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/bcdev/hadoop/pull/2"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/RunJar.java||hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/RunJar.java": [
          "File: hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/RunJar.java -> hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/RunJar.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "93:     throws IOException {",
          "94:     JarFile jar = new JarFile(jarFile);",
          "95:     try {",
          "96:       Enumeration<JarEntry> entries = jar.entries();",
          "97:       while (entries.hasMoreElements()) {",
          "98:         final JarEntry entry = entries.nextElement();",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "96:       String targetDirPath = toDir.getCanonicalPath() + File.separator;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "102:           try {",
          "103:             File file = new File(toDir, entry.getName());",
          "104:             ensureDirectory(file.getParentFile());",
          "105:             OutputStream out = new FileOutputStream(file);",
          "106:             try {",
          "107:               IOUtils.copyBytes(in, out, 8192);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "106:             if (!file.getCanonicalPath().startsWith(targetDirPath)) {",
          "107:               throw new IOException(\"expanding \" + entry.getName()",
          "108:                   + \" would create file outside of \" + toDir);",
          "109:             }",
          "",
          "---------------"
        ],
        "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestRunJar.java||hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestRunJar.java": [
          "File: hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestRunJar.java -> hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestRunJar.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: package org.apache.hadoop.util;",
          "20: import static org.mockito.Mockito.spy;",
          "21: import static org.mockito.Mockito.when;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "20: import static org.junit.Assert.fail;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "25: import java.io.FileOutputStream;",
          "26: import java.io.IOException;",
          "27: import java.io.InputStream;",
          "28: import java.util.jar.JarOutputStream;",
          "29: import java.util.regex.Pattern;",
          "30: import java.util.zip.ZipEntry;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "29: import java.nio.charset.StandardCharsets;",
          "30: import java.util.jar.JarEntry;",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "32: import junit.framework.TestCase;",
          "34: import org.apache.hadoop.fs.FileUtil;",
          "35: import org.junit.After;",
          "36: import org.junit.Before;",
          "37: import org.junit.Test;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "38: import org.apache.hadoop.test.GenericTestUtils;",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "170:     return jarFile;",
          "171:   }",
          "",
          "[Removed Lines]",
          "172: }",
          "",
          "[Added Lines]",
          "178:   public void testUnJar2() throws IOException {",
          "180:     File jarFile = new File(TEST_ROOT_DIR, TEST_JAR_NAME);",
          "181:     JarOutputStream jstream =",
          "182:         new JarOutputStream(new FileOutputStream(jarFile));",
          "183:     JarEntry je = new JarEntry(\"META-INF/MANIFEST.MF\");",
          "184:     byte[] data = \"Manifest-Version: 1.0\\nCreated-By: 1.8.0_1 (Manual)\"",
          "185:         .getBytes(StandardCharsets.UTF_8);",
          "186:     je.setSize(data.length);",
          "187:     jstream.putNextEntry(je);",
          "188:     jstream.write(data);",
          "189:     jstream.closeEntry();",
          "190:     je = new JarEntry(\"../outside.path\");",
          "191:     data = \"any data here\".getBytes(StandardCharsets.UTF_8);",
          "192:     je.setSize(data.length);",
          "193:     jstream.putNextEntry(je);",
          "194:     jstream.write(data);",
          "195:     jstream.closeEntry();",
          "196:     jstream.close();",
          "198:     File unjarDir = new File(TEST_ROOT_DIR, \"unjar-path\");",
          "201:     try {",
          "202:       RunJar.unJar(jarFile, unjarDir);",
          "203:       fail(\"unJar should throw IOException.\");",
          "204:     } catch (IOException e) {",
          "205:       GenericTestUtils.assertExceptionContains(",
          "206:           \"would create file outside of\", e);",
          "207:     }",
          "208:   }",
          "209: }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "04219e55c8983f88573b10205dbca5411e744b35",
      "candidate_info": {
        "commit_hash": "04219e55c8983f88573b10205dbca5411e744b35",
        "repo": "apache/hadoop",
        "commit_url": "https://github.com/apache/hadoop/commit/04219e55c8983f88573b10205dbca5411e744b35",
        "files": [
          "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java",
          "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/UserGroupInformation.java"
        ],
        "message": "Skip the proxy user check if the ugi has not been initialized. Contributed by Daryn Sharp\n\n(cherry picked from commit 73e9120ad79c73703de21e0084591861813f3279)",
        "before_after_code_files": [
          "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java||hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java",
          "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/UserGroupInformation.java||hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/UserGroupInformation.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/bcdev/hadoop/pull/2"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java||hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java": [
          "File: hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java -> hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "234:     }",
          "236:     private static boolean getRestrictParserDefault(Object resource) {",
          "238:         return false;",
          "239:       }",
          "240:       UserGroupInformation user;",
          "",
          "[Removed Lines]",
          "237:       if (resource instanceof String) {",
          "",
          "[Added Lines]",
          "237:       if (resource instanceof String || !UserGroupInformation.isInitialized()) {",
          "",
          "---------------"
        ],
        "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/UserGroupInformation.java||hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/UserGroupInformation.java": [
          "File: hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/UserGroupInformation.java -> hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/UserGroupInformation.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "250:   public static final String HADOOP_TOKEN_FILE_LOCATION =",
          "251:     \"HADOOP_TOKEN_FILE_LOCATION\";",
          "257:   private static void ensureInitialized() {",
          "259:       synchronized(UserGroupInformation.class) {",
          "261:           initialize(new Configuration(), false);",
          "262:         }",
          "263:       }",
          "",
          "[Removed Lines]",
          "258:     if (conf == null) {",
          "260:         if (conf == null) { // someone might have beat us",
          "",
          "[Added Lines]",
          "253:   public static boolean isInitialized() {",
          "254:     return conf != null;",
          "255:   }",
          "262:     if (!isInitialized()) {",
          "264:         if (!isInitialized()) { // someone might have beat us",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "25052fba49455b2e037c46f0c1b0368d017c6905",
      "candidate_info": {
        "commit_hash": "25052fba49455b2e037c46f0c1b0368d017c6905",
        "repo": "apache/hadoop",
        "commit_url": "https://github.com/apache/hadoop/commit/25052fba49455b2e037c46f0c1b0368d017c6905",
        "files": [
          "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
        ],
        "message": "HDFS-13602. Add checkOperation(WRITE) checks in FSNamesystem. Contributed by Chao Sun.\n\n(cherry picked from commit ff013d2c952272f3176dcf624251b05d610503b5)",
        "before_after_code_files": [
          "hadoop-hdfs-project/hadoop-hdfs/src/main/javorg/apache/hadoop/hdfs/server/namenode/FSNamesystem.java||hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/bcdev/hadoop/pull/2"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "hadoop-hdfs-project/hadoop-hdfs/src/main/javorg/apache/hadoop/hdfs/server/namenode/FSNamesystem.java||hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java": [
          "File: hadoop-hdfs-project/hadoop-hdfs/src/main/javorg/apache/hadoop/hdfs/server/namenode/FSNamesystem.java -> hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1745:       checkOperation(OperationCategory.WRITE);",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1900:     checkOperation(OperationCategory.WRITE);",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "6335:     checkOperation(OperationCategory.WRITE);",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "7468:     checkOperation(OperationCategory.WRITE);",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "7508:       checkOperation(OperationCategory.READ);",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "7702:     checkOperation(OperationCategory.WRITE);",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "7734:     checkOperation(OperationCategory.WRITE);",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "7759:     checkOperation(OperationCategory.WRITE);",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "7802:     checkOperation(OperationCategory.WRITE);",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "7827:     checkOperation(OperationCategory.WRITE);",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "7852:     checkOperation(OperationCategory.WRITE);",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "bd98d4e77cf9f7b2f4b1afb4d5e5bad0f6b2fde3",
      "candidate_info": {
        "commit_hash": "bd98d4e77cf9f7b2f4b1afb4d5e5bad0f6b2fde3",
        "repo": "apache/hadoop",
        "commit_url": "https://github.com/apache/hadoop/commit/bd98d4e77cf9f7b2f4b1afb4d5e5bad0f6b2fde3",
        "files": [
          "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java",
          "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileUtil.java"
        ],
        "message": "Additional check when unpacking archives. Contributed by Jason Lowe and Akira Ajisaka.",
        "before_after_code_files": [
          "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java||hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java",
          "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileUtil.java||hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileUtil.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "diff_branch_olp_changes": 1,
        "olp_code_files": {
          "patch": [
            "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java||hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java",
            "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileUtil.java||hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileUtil.java"
          ],
          "candidate": [
            "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java||hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java",
            "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileUtil.java||hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileUtil.java"
          ]
        }
      },
      "candidate_diff": {
        "hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java||hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java": [
          "File: hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java -> hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileUtil.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "585:   public static void unZip(File inFile, File unzipDir) throws IOException {",
          "586:     Enumeration<? extends ZipEntry> entries;",
          "587:     ZipFile zipFile = new ZipFile(inFile);",
          "589:     try {",
          "590:       entries = zipFile.entries();",
          "591:       while (entries.hasMoreElements()) {",
          "592:         ZipEntry entry = entries.nextElement();",
          "593:         if (!entry.isDirectory()) {",
          "594:           InputStream in = zipFile.getInputStream(entry);",
          "595:           try {",
          "597:             if (!file.getParentFile().mkdirs()) {",
          "598:               if (!file.getParentFile().isDirectory()) {",
          "599:                 throw new IOException(\"Mkdirs failed to create \" +",
          "",
          "[Removed Lines]",
          "596:             File file = new File(unzipDir, entry.getName());",
          "",
          "[Added Lines]",
          "588:     String targetDirPath = unzipDir.getCanonicalPath() + File.separator;",
          "595:           File file = new File(unzipDir, entry.getName());",
          "596:           if (!file.getCanonicalPath().startsWith(targetDirPath)) {",
          "597:             throw new IOException(\"expanding \" + entry.getName()",
          "598:                 + \" would create file outside of \" + unzipDir);",
          "599:           }",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "704:   private static void unpackEntries(TarArchiveInputStream tis,",
          "705:       TarArchiveEntry entry, File outputDir) throws IOException {",
          "706:     if (entry.isDirectory()) {",
          "707:       File subDir = new File(outputDir, entry.getName());",
          "708:       if (!subDir.mkdirs() && !subDir.isDirectory()) {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "711:     String targetDirPath = outputDir.getCanonicalPath() + File.separator;",
          "712:     File outputFile = new File(outputDir, entry.getName());",
          "713:     if (!outputFile.getCanonicalPath().startsWith(targetDirPath)) {",
          "714:       throw new IOException(\"expanding \" + entry.getName()",
          "715:           + \" would create entry outside of \" + outputDir);",
          "716:     }",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "717:       return;",
          "718:     }",
          "721:     if (!outputFile.getParentFile().exists()) {",
          "722:       if (!outputFile.getParentFile().mkdirs()) {",
          "723:         throw new IOException(\"Mkdirs failed to create tar internal dir \"",
          "",
          "[Removed Lines]",
          "720:     File outputFile = new File(outputDir, entry.getName());",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileUtil.java||hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileUtil.java": [
          "File: hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileUtil.java -> hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileUtil.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "37: import java.net.URISyntaxException;",
          "38: import java.net.URL;",
          "39: import java.net.UnknownHostException;",
          "40: import java.util.ArrayList;",
          "41: import java.util.Arrays;",
          "42: import java.util.Collections;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "40: import java.nio.charset.StandardCharsets;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "714:     } catch (IOException ioe) {",
          "716:     }",
          "719:   @Test (timeout = 30000)",
          "",
          "[Removed Lines]",
          "717:   }",
          "",
          "[Added Lines]",
          "716:   }",
          "718:   @Test (timeout = 30000)",
          "719:   public void testUnZip2() throws IOException {",
          "720:     setupDirs();",
          "722:     final File simpleZip = new File(del, FILE);",
          "723:     OutputStream os = new FileOutputStream(simpleZip);",
          "724:     try (ZipOutputStream tos = new ZipOutputStream(os)) {",
          "726:       ZipEntry ze = new ZipEntry(\"../foo\");",
          "727:       byte[] data = \"some-content\".getBytes(StandardCharsets.UTF_8);",
          "728:       ze.setSize(data.length);",
          "729:       tos.putNextEntry(ze);",
          "730:       tos.write(data);",
          "731:       tos.closeEntry();",
          "732:       tos.flush();",
          "733:       tos.finish();",
          "734:     }",
          "737:     try {",
          "738:       FileUtil.unZip(simpleZip, tmp);",
          "739:       Assert.fail(\"unZip should throw IOException.\");",
          "740:     } catch (IOException e) {",
          "741:       GenericTestUtils.assertExceptionContains(",
          "742:           \"would create file outside of\", e);",
          "743:     }",
          "744:   }",
          "",
          "---------------"
        ]
      }
    }
  ]
}