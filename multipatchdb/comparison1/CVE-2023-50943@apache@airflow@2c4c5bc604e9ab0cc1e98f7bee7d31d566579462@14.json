{
  "cve_id": "CVE-2023-50943",
  "cve_desc": "Apache Airflow, versions before 2.8.1, have a vulnerability that allows a potential attacker to poison the XCom data by bypassing the protection of \"enable_xcom_pickling=False\" configuration setting resulting in poisoned data after XCom deserialization. This vulnerability is considered low since it requires a DAG author to exploit it. Users are recommended to upgrade to version 2.8.1 or later, which fixes this issue.",
  "repo": "apache/airflow",
  "patch_hash": "2c4c5bc604e9ab0cc1e98f7bee7d31d566579462",
  "patch_info": {
    "commit_hash": "2c4c5bc604e9ab0cc1e98f7bee7d31d566579462",
    "repo": "apache/airflow",
    "commit_url": "https://github.com/apache/airflow/commit/2c4c5bc604e9ab0cc1e98f7bee7d31d566579462",
    "files": [
      "airflow/models/xcom.py",
      "tests/api_connexion/schemas/test_xcom_schema.py",
      "tests/models/test_xcom.py"
    ],
    "message": "Stop deserializing pickle when enable_xcom_pickling is False (#36255)\n\n* Stop deserializing pickle when enable_xcom_pickling is False\n\n* Fix unit tests\n\n(cherry picked from commit 63e97abec5d56bc62a293c93f5227f364561e51c)",
    "before_after_code_files": [
      "airflow/models/xcom.py||airflow/models/xcom.py",
      "tests/api_connexion/schemas/test_xcom_schema.py||tests/api_connexion/schemas/test_xcom_schema.py",
      "tests/models/test_xcom.py||tests/models/test_xcom.py"
    ]
  },
  "patch_diff": {
    "airflow/models/xcom.py||airflow/models/xcom.py": [
      "File: airflow/models/xcom.py -> airflow/models/xcom.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "685:             except pickle.UnpicklingError:",
      "686:                 return json.loads(result.value.decode(\"UTF-8\"), cls=XComDecoder, object_hook=object_hook)",
      "687:         else:",
      "693:     @staticmethod",
      "694:     def deserialize_value(result: XCom) -> Any:",
      "",
      "[Removed Lines]",
      "688:             try:",
      "689:                 return json.loads(result.value.decode(\"UTF-8\"), cls=XComDecoder, object_hook=object_hook)",
      "690:             except (json.JSONDecodeError, UnicodeDecodeError):",
      "691:                 return pickle.loads(result.value)",
      "",
      "[Added Lines]",
      "688:             # Since xcom_pickling is disabled, we should only try to deserialize with JSON",
      "689:             return json.loads(result.value.decode(\"UTF-8\"), cls=XComDecoder, object_hook=object_hook)",
      "",
      "---------------"
    ],
    "tests/api_connexion/schemas/test_xcom_schema.py||tests/api_connexion/schemas/test_xcom_schema.py": [
      "File: tests/api_connexion/schemas/test_xcom_schema.py -> tests/api_connexion/schemas/test_xcom_schema.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "30: from airflow.models import DagRun, XCom",
      "31: from airflow.utils.dates import parse_execution_date",
      "32: from airflow.utils.session import create_session",
      "34: pytestmark = pytest.mark.db_test",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "33: from tests.test_utils.config import conf_vars",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "188:     default_time = \"2016-04-02T21:00:00+00:00\"",
      "189:     default_time_parsed = parse_execution_date(default_time)",
      "191:     def test_serialize(self, create_xcom, session):",
      "192:         create_xcom(",
      "193:             dag_id=\"test_dag\",",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "192:     @conf_vars({(\"core\", \"enable_xcom_pickling\"): \"True\"})",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "208:             \"map_index\": -1,",
      "209:         }",
      "211:     def test_deserialize(self):",
      "212:         xcom_dump = {",
      "213:             \"key\": \"test_key\",",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "213:     @conf_vars({(\"core\", \"enable_xcom_pickling\"): \"True\"})",
      "",
      "---------------"
    ],
    "tests/models/test_xcom.py||tests/models/test_xcom.py": [
      "File: tests/models/test_xcom.py -> tests/models/test_xcom.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "140:             ret_value = XCom.get_value(key=\"xcom_test3\", ti_key=ti_key, session=session)",
      "141:         assert ret_value == {\"key\": \"value\"}",
      "144:         with conf_vars({(\"core\", \"enable_xcom_pickling\"): \"True\"}):",
      "145:             XCom.set(",
      "146:                 key=\"xcom_test3\",",
      "",
      "[Removed Lines]",
      "143:     def test_xcom_deserialize_with_pickle_to_json_switch(self, task_instance, session):",
      "",
      "[Added Lines]",
      "143:     def test_xcom_deserialize_pickle_when_xcom_pickling_is_disabled(self, task_instance, session):",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "151:                 session=session,",
      "152:             )",
      "153:         with conf_vars({(\"core\", \"enable_xcom_pickling\"): \"False\"}):",
      "163:     @conf_vars({(\"core\", \"xcom_enable_pickling\"): \"False\"})",
      "164:     def test_xcom_disable_pickle_type_fail_on_non_json(self, task_instance, session):",
      "",
      "[Removed Lines]",
      "154:             ret_value = XCom.get_one(",
      "155:                 key=\"xcom_test3\",",
      "156:                 dag_id=task_instance.dag_id,",
      "157:                 task_id=task_instance.task_id,",
      "158:                 run_id=task_instance.run_id,",
      "159:                 session=session,",
      "160:             )",
      "161:         assert ret_value == {\"key\": \"value\"}",
      "",
      "[Added Lines]",
      "154:             with pytest.raises(UnicodeDecodeError):",
      "155:                 XCom.get_one(",
      "156:                     key=\"xcom_test3\",",
      "157:                     dag_id=task_instance.dag_id,",
      "158:                     task_id=task_instance.task_id,",
      "159:                     run_id=task_instance.run_id,",
      "160:                     session=session,",
      "161:                 )",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "7237331ee162abaf023e67ebf2b414833d138deb",
      "candidate_info": {
        "commit_hash": "7237331ee162abaf023e67ebf2b414833d138deb",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/7237331ee162abaf023e67ebf2b414833d138deb",
        "files": [
          "airflow/www/auth.py",
          "airflow/www/views.py"
        ],
        "message": "Allow anoymous user edit/show resource when set `AUTH_ROLE_PUBLIC` (#36750)\n\n(cherry picked from commit 512461c74523f8e015b5ccc1cc01184e4fd3960f)",
        "before_after_code_files": [
          "airflow/www/auth.py||airflow/www/auth.py",
          "airflow/www/views.py||airflow/www/views.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/www/auth.py||airflow/www/auth.py": [
          "File: airflow/www/auth.py -> airflow/www/auth.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "107:             _permission_name = self.method_permission_name.get(f.__name__)",
          "108:             if _permission_name:",
          "109:                 permission_str = f\"{PERMISSION_PREFIX}{_permission_name}\"",
          "118:         ):",
          "119:             return f(self, *args, **kwargs)",
          "120:         else:",
          "",
          "[Removed Lines]",
          "110:         if (",
          "111:             get_auth_manager().is_logged_in()",
          "112:             and permission_str in self.base_permissions",
          "113:             and self.appbuilder.sm.has_access(",
          "114:                 action_name=permission_str,",
          "115:                 resource_name=self.class_permission_name,",
          "116:                 resource_pk=kwargs.get(\"pk\"),",
          "117:             )",
          "",
          "[Added Lines]",
          "110:         if permission_str in self.base_permissions and self.appbuilder.sm.has_access(",
          "111:             action_name=permission_str,",
          "112:             resource_name=self.class_permission_name,",
          "113:             resource_pk=kwargs.get(\"pk\"),",
          "",
          "---------------"
        ],
        "airflow/www/views.py||airflow/www/views.py": [
          "File: airflow/www/views.py -> airflow/www/views.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "133: from airflow.utils.timezone import td_format, utcnow",
          "134: from airflow.version import version",
          "135: from airflow.www import auth, utils as wwwutils",
          "137: from airflow.www.decorators import action_logging, gzipped",
          "138: from airflow.www.extensions.init_auth_manager import get_auth_manager",
          "139: from airflow.www.forms import (",
          "",
          "[Removed Lines]",
          "136: from airflow.www.auth import has_access_with_pk",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "4002:         return attribute",
          "4004:     @expose(\"/show/<pk>\", methods=[\"GET\"])",
          "4006:     def show(self, pk):",
          "4007:         \"\"\"",
          "4008:         Show view.",
          "",
          "[Removed Lines]",
          "4005:     @has_access_with_pk",
          "",
          "[Added Lines]",
          "4004:     @auth.has_access_with_pk",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "4024:         )",
          "4026:     @expose(\"/edit/<pk>\", methods=[\"GET\", \"POST\"])",
          "4028:     def edit(self, pk):",
          "4029:         \"\"\"",
          "4030:         Edit view.",
          "",
          "[Removed Lines]",
          "4027:     @has_access_with_pk",
          "",
          "[Added Lines]",
          "4026:     @auth.has_access_with_pk",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "4048:             )",
          "4050:     @expose(\"/delete/<pk>\", methods=[\"GET\", \"POST\"])",
          "4052:     def delete(self, pk):",
          "4053:         \"\"\"",
          "4054:         Delete view.",
          "",
          "[Removed Lines]",
          "4051:     @has_access_with_pk",
          "",
          "[Added Lines]",
          "4050:     @auth.has_access_with_pk",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "4746:         return redirect(self.get_redirect())",
          "4748:     @expose(\"/delete/<pk>\", methods=[\"GET\", \"POST\"])",
          "4750:     def delete(self, pk):",
          "4751:         \"\"\"Single delete.\"\"\"",
          "4752:         if models.Pool.is_default_pool(pk):",
          "",
          "[Removed Lines]",
          "4749:     @has_access_with_pk",
          "",
          "[Added Lines]",
          "4748:     @auth.has_access_with_pk",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "81d1fec83f659c3421a24eeb4d6d8e75d9681f86",
      "candidate_info": {
        "commit_hash": "81d1fec83f659c3421a24eeb4d6d8e75d9681f86",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/81d1fec83f659c3421a24eeb4d6d8e75d9681f86",
        "files": [
          "airflow/www/static/js/components/RunTypeIcon.tsx"
        ],
        "message": "Fix run type icon alignment with run type text (#36616)\n\n(cherry picked from commit 70be78f4e7cea07c759802ed9af51408d36184cf)",
        "before_after_code_files": [
          "airflow/www/static/js/components/RunTypeIcon.tsx||airflow/www/static/js/components/RunTypeIcon.tsx"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/www/static/js/components/RunTypeIcon.tsx||airflow/www/static/js/components/RunTypeIcon.tsx": [
          "File: airflow/www/static/js/components/RunTypeIcon.tsx -> airflow/www/static/js/components/RunTypeIcon.tsx",
          "--- Hunk 1 ---",
          "[Context before]",
          "29:   runType: DagRun[\"runType\"];",
          "30: }",
          "32: const DagRunTypeIcon = ({ runType, ...rest }: Props) => {",
          "33:   switch (runType) {",
          "34:     case \"manual\":",
          "36:     case \"backfill\":",
          "38:     case \"scheduled\":",
          "40:     case \"dataset_triggered\":",
          "42:     default:",
          "43:       return null;",
          "44:   }",
          "",
          "[Removed Lines]",
          "35:       return <MdPlayArrow style={{ display: \"inline\" }} {...rest} />;",
          "37:       return <RiArrowGoBackFill style={{ display: \"inline\" }} {...rest} />;",
          "39:       return <MdOutlineSchedule style={{ display: \"inline\" }} {...rest} />;",
          "41:       return <HiDatabase style={{ display: \"inline\" }} {...rest} />;",
          "",
          "[Added Lines]",
          "32: const iconStyle = {",
          "33:   display: \"inline\",",
          "34:   verticalAlign: \"bottom\",",
          "35: };",
          "40:       return <MdPlayArrow style={iconStyle} {...rest} />;",
          "42:       return <RiArrowGoBackFill style={iconStyle} {...rest} />;",
          "44:       return <MdOutlineSchedule style={iconStyle} {...rest} />;",
          "46:       return <HiDatabase style={iconStyle} {...rest} />;",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "ee12a6d7b67e6027d02217ae1530826311ca2545",
      "candidate_info": {
        "commit_hash": "ee12a6d7b67e6027d02217ae1530826311ca2545",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/ee12a6d7b67e6027d02217ae1530826311ca2545",
        "files": [
          "airflow/cli/commands/scheduler_command.py",
          "tests/cli/commands/test_scheduler_command.py"
        ],
        "message": "Fix airflow-scheduler exiting with code 0 on exceptions (#36800)\n\n* Fix airflow-scheduler exiting with code 0 on exceptions\n\n* Fix static check\n\n(cherry picked from commit 1d5d5022b8fc92f23f9fdc3b61269e5c7acfaf39)",
        "before_after_code_files": [
          "airflow/cli/commands/scheduler_command.py||airflow/cli/commands/scheduler_command.py",
          "tests/cli/commands/test_scheduler_command.py||tests/cli/commands/test_scheduler_command.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/cli/commands/scheduler_command.py||airflow/cli/commands/scheduler_command.py": [
          "File: airflow/cli/commands/scheduler_command.py -> airflow/cli/commands/scheduler_command.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: import logging",
          "21: from argparse import Namespace",
          "23: from multiprocessing import Process",
          "25: from airflow import settings",
          "",
          "[Removed Lines]",
          "22: from contextlib import contextmanager",
          "",
          "[Added Lines]",
          "22: from contextlib import ExitStack, contextmanager",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "44:     ExecutorLoader.validate_database_executor_compatibility(job_runner.job.executor)",
          "45:     InternalApiConfig.force_database_direct_access()",
          "46:     enable_health_check = conf.getboolean(\"scheduler\", \"ENABLE_HEALTH_CHECK\")",
          "48:         try:",
          "49:             run_job(job=job_runner.job, execute_callable=job_runner._execute)",
          "50:         except Exception:",
          "51:             log.exception(\"Exception when running scheduler job\")",
          "54: @cli_utils.action_cli",
          "",
          "[Removed Lines]",
          "47:     with _serve_logs(args.skip_serve_logs), _serve_health_check(enable_health_check):",
          "",
          "[Added Lines]",
          "47:     with ExitStack() as stack:",
          "48:         stack.enter_context(_serve_logs(args.skip_serve_logs))",
          "49:         stack.enter_context(_serve_health_check(enable_health_check))",
          "55:             raise",
          "56:         finally:",
          "57:             # Ensure that the contexts are closed",
          "58:             stack.close()",
          "",
          "---------------"
        ],
        "tests/cli/commands/test_scheduler_command.py||tests/cli/commands/test_scheduler_command.py": [
          "File: tests/cli/commands/test_scheduler_command.py -> tests/cli/commands/test_scheduler_command.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "169:         mock_scheduler_job,",
          "170:     ):",
          "171:         args = self.parser.parse_args([\"scheduler\"])",
          "174:         # Make sure that run_job is called, that the exception has been logged, and that the serve_logs",
          "175:         # sub-process has been terminated",
          "",
          "[Removed Lines]",
          "172:         scheduler_command.scheduler(args)",
          "",
          "[Added Lines]",
          "172:         with pytest.raises(Exception, match=\"run_job failed\"):",
          "173:             scheduler_command.scheduler(args)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "ba3213bb9378185d99fb2141b8423851cbd191e8",
      "candidate_info": {
        "commit_hash": "ba3213bb9378185d99fb2141b8423851cbd191e8",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/ba3213bb9378185d99fb2141b8423851cbd191e8",
        "files": [
          ".github/workflows/ci.yml",
          "Dockerfile",
          "Dockerfile.ci",
          "IMAGES.rst",
          "dev/breeze/src/airflow_breeze/commands/release_management_commands.py",
          "dev/breeze/src/airflow_breeze/global_constants.py",
          "docs/docker-stack/build-arg-ref.rst",
          "scripts/docker/common.sh"
        ],
        "message": "Upgrade to just released `pip` 23.3.2 (#36271)\n\n(cherry picked from commit 41096e0c266e3adb0ac3985d2609701f53aded00)",
        "before_after_code_files": [
          "Dockerfile.ci||Dockerfile.ci",
          "dev/breeze/src/airflow_breeze/commands/release_management_commands.py||dev/breeze/src/airflow_breeze/commands/release_management_commands.py",
          "dev/breeze/src/airflow_breeze/global_constants.py||dev/breeze/src/airflow_breeze/global_constants.py",
          "scripts/docker/common.sh||scripts/docker/common.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "Dockerfile.ci||Dockerfile.ci": [
          "File: Dockerfile.ci -> Dockerfile.ci",
          "--- Hunk 1 ---",
          "[Context before]",
          "491: function common::override_pip_version_if_needed() {",
          "492:     if [[ -n ${AIRFLOW_VERSION} ]]; then",
          "493:         if [[ ${AIRFLOW_VERSION} =~ ^2\\.0.* || ${AIRFLOW_VERSION} =~ ^1\\.* ]]; then",
          "495:         fi",
          "496:     fi",
          "497: }",
          "",
          "[Removed Lines]",
          "494:             export AIRFLOW_PIP_VERSION=\"23.3.1\"",
          "",
          "[Added Lines]",
          "494:             export AIRFLOW_PIP_VERSION=\"23.3.2\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "995: # THE 3 LINES ARE ONLY NEEDED IN ORDER TO MAKE PYMSSQL BUILD WORK WITH LATEST CYTHON",
          "996: # AND SHOULD BE REMOVED WHEN WORKAROUND IN install_mssql.sh IS REMOVED",
          "998: ENV AIRFLOW_PIP_VERSION=${AIRFLOW_PIP_VERSION}",
          "999: COPY --from=scripts common.sh /scripts/docker/",
          "",
          "[Removed Lines]",
          "997: ARG AIRFLOW_PIP_VERSION=23.3.1",
          "",
          "[Added Lines]",
          "997: ARG AIRFLOW_PIP_VERSION=23.3.2",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "1059: ARG AIRFLOW_PRE_CACHED_PIP_PACKAGES=\"true\"",
          "1060: # By default in the image, we are installing all providers when installing from sources",
          "1061: ARG INSTALL_PROVIDERS_FROM_SOURCES=\"true\"",
          "1063: # Setup PIP",
          "1064: # By default PIP install run without cache to make image smaller",
          "1065: ARG PIP_NO_CACHE_DIR=\"true\"",
          "",
          "[Removed Lines]",
          "1062: ARG AIRFLOW_PIP_VERSION=23.3.1",
          "",
          "[Added Lines]",
          "1062: ARG AIRFLOW_PIP_VERSION=23.3.2",
          "",
          "---------------"
        ],
        "dev/breeze/src/airflow_breeze/commands/release_management_commands.py||dev/breeze/src/airflow_breeze/commands/release_management_commands.py": [
          "File: dev/breeze/src/airflow_breeze/commands/release_management_commands.py -> dev/breeze/src/airflow_breeze/commands/release_management_commands.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "205:     comparable_version: Version",
          "209: WHEEL_VERSION = \"0.36.2\"",
          "210: GITPYTHON_VERSION = \"3.1.40\"",
          "211: RICH_VERSION = \"13.7.0\"",
          "",
          "[Removed Lines]",
          "208: AIRFLOW_PIP_VERSION = \"23.3.1\"",
          "",
          "[Added Lines]",
          "208: AIRFLOW_PIP_VERSION = \"23.3.2\"",
          "",
          "---------------"
        ],
        "dev/breeze/src/airflow_breeze/global_constants.py||dev/breeze/src/airflow_breeze/global_constants.py": [
          "File: dev/breeze/src/airflow_breeze/global_constants.py -> dev/breeze/src/airflow_breeze/global_constants.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "121: ALLOWED_MSSQL_VERSIONS = [\"2017-latest\", \"2019-latest\"]",
          "125: # packages that  providers docs",
          "126: REGULAR_DOC_PACKAGES = [",
          "",
          "[Removed Lines]",
          "123: PIP_VERSION = \"23.3.1\"",
          "",
          "[Added Lines]",
          "123: PIP_VERSION = \"23.3.2\"",
          "",
          "---------------"
        ],
        "scripts/docker/common.sh||scripts/docker/common.sh": [
          "File: scripts/docker/common.sh -> scripts/docker/common.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "43: function common::override_pip_version_if_needed() {",
          "44:     if [[ -n ${AIRFLOW_VERSION} ]]; then",
          "45:         if [[ ${AIRFLOW_VERSION} =~ ^2\\.0.* || ${AIRFLOW_VERSION} =~ ^1\\.* ]]; then",
          "47:         fi",
          "48:     fi",
          "49: }",
          "",
          "[Removed Lines]",
          "46:             export AIRFLOW_PIP_VERSION=\"23.3.1\"",
          "",
          "[Added Lines]",
          "46:             export AIRFLOW_PIP_VERSION=\"23.3.2\"",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "c2e6b9a92dcd603c05f3008a7139eff52fe3e1b7",
      "candidate_info": {
        "commit_hash": "c2e6b9a92dcd603c05f3008a7139eff52fe3e1b7",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/c2e6b9a92dcd603c05f3008a7139eff52fe3e1b7",
        "files": [
          "dev/breeze/src/airflow_breeze/utils/kubernetes_utils.py"
        ],
        "message": "Add version check for k8s setup venv command (#36673)\n\nThis command install airflow in k8s venv and in case version of\nPython is not yet supported by Airflow, it might fail.\n\nWe do not have check it lower-bound because breeze supports the\nsame minimum version of Airflow as Airflow itself.\n\nThe command prints instructions on how to reinstall breeze with\ndifferent Python version in such case.\n\n(cherry picked from commit 9264a4b4e21702a2bc71bb77ee3cc4ada9dfd5e7)",
        "before_after_code_files": [
          "dev/breeze/src/airflow_breeze/utils/kubernetes_utils.py||dev/breeze/src/airflow_breeze/utils/kubernetes_utils.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "dev/breeze/src/airflow_breeze/utils/kubernetes_utils.py||dev/breeze/src/airflow_breeze/utils/kubernetes_utils.py": [
          "File: dev/breeze/src/airflow_breeze/utils/kubernetes_utils.py -> dev/breeze/src/airflow_breeze/utils/kubernetes_utils.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "32: from typing import Any, NamedTuple",
          "33: from urllib import request",
          "36: from airflow_breeze.utils.console import Output, get_console",
          "37: from airflow_breeze.utils.host_info_utils import Architecture, get_host_architecture, get_host_os",
          "38: from airflow_breeze.utils.path_utils import AIRFLOW_SOURCES_ROOT, BUILD_CACHE_DIR",
          "",
          "[Removed Lines]",
          "35: from airflow_breeze.global_constants import ALLOWED_ARCHITECTURES, HELM_VERSION, KIND_VERSION, PIP_VERSION",
          "",
          "[Added Lines]",
          "35: from airflow_breeze.global_constants import (",
          "36:     ALLOWED_ARCHITECTURES,",
          "37:     ALLOWED_PYTHON_MAJOR_MINOR_VERSIONS,",
          "38:     HELM_VERSION,",
          "39:     KIND_VERSION,",
          "40:     PIP_VERSION,",
          "41: )",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "330:         get_console().print(f\"[info]Dry run - would be removing {K8S_ENV_PATH}\")",
          "331:     else:",
          "332:         shutil.rmtree(K8S_ENV_PATH, ignore_errors=True)",
          "333:     venv_command_result = run_command(",
          "334:         [sys.executable, \"-m\", \"venv\", str(K8S_ENV_PATH)],",
          "335:         check=False,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "339:     max_python_version = ALLOWED_PYTHON_MAJOR_MINOR_VERSIONS[-1]",
          "340:     max_python_version_tuple = tuple(int(x) for x in max_python_version.split(\".\"))",
          "341:     higher_python_version_tuple = max_python_version_tuple[0], max_python_version_tuple[1] + 1",
          "342:     if sys.version_info >= higher_python_version_tuple:",
          "343:         get_console().print(",
          "344:             f\"[red]This is not supported in Python {higher_python_version_tuple} and above[/]\\n\"",
          "345:         )",
          "346:         get_console().print(f\"[warning]Please use Python version before {higher_python_version_tuple}[/]\\n\")",
          "347:         get_console().print(",
          "348:             \"[info]You can uninstall breeze and install it again with earlier Python \"",
          "349:             \"version. For example:[/]\\n\"",
          "350:         )",
          "351:         get_console().print(\"pipx uninstall apache-airflow-breeze\")",
          "352:         get_console().print(\"pipx install --python PYTHON_PATH -e ./dev/breeze\\n\")",
          "353:         get_console().print(",
          "354:             f\"[info]PYTHON_PATH - path to your Python binary(< {higher_python_version_tuple})[/]\\n\"",
          "355:         )",
          "356:         get_console().print(\"[info]Then recreate your k8s virtualenv with:[/]\\n\")",
          "357:         get_console().print(\"breeze k8s setup-env --force-venv-setup\\n\")",
          "358:         sys.exit(1)",
          "",
          "---------------"
        ]
      }
    }
  ]
}