{
  "cve_id": "CVE-2020-1936",
  "cve_desc": "A cross-site scripting issue was found in Apache Ambari Views. This was addressed in Apache Ambari 2.7.4.",
  "repo": "apache/ambari",
  "patch_hash": "a9cfdb9dcce63a3494c07c81ebb2cf8da218a210",
  "patch_info": {
    "commit_hash": "a9cfdb9dcce63a3494c07c81ebb2cf8da218a210",
    "repo": "apache/ambari",
    "commit_url": "https://github.com/apache/ambari/pull/3040/commits/a9cfdb9dcce63a3494c07c81ebb2cf8da218a210",
    "files": [
      "ambari-web/app/views/common/breadcrumbs_view.js"
    ],
    "message": "AMBARI-25329. Ambari breadcrumbs xss vulnerability",
    "before_after_code_files": [
      "ambari-web/app/views/common/breadcrumbs_view.js||ambari-web/app/views/common/breadcrumbs_view.js"
    ]
  },
  "patch_diff": {
    "ambari-web/app/views/common/breadcrumbs_view.js||ambari-web/app/views/common/breadcrumbs_view.js": [
      "File: ambari-web/app/views/common/breadcrumbs_view.js -> ambari-web/app/views/common/breadcrumbs_view.js",
      "--- Hunk 1 ---",
      "[Context before]",
      "149:   createLabel() {",
      "150:     let label = this.get('label');",
      "151:     let labelBindingPath = this.get('labelBindingPath');",
      "154:     this.set('formattedLabel', this.labelPostFormat(formattedLabel));",
      "155:   },",
      "",
      "[Removed Lines]",
      "153:     let formattedLabel = labelBindingPath ? App.get(_getLabelPathWithoutApp(labelBindingPath)) : label;",
      "",
      "[Added Lines]",
      "152:     let formattedLabel;",
      "154:     if (labelBindingPath) {",
      "155:       formattedLabel = Ember.Handlebars.Utils.escapeExpression(App.get(_getLabelPathWithoutApp(labelBindingPath)));",
      "156:     } else{",
      "157:       formattedLabel = label;",
      "158:     }",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "216:       }",
      "217:       currentState = currentState.get('parentState');",
      "218:     }",
      "220:     if (items.length) {",
      "221:       items.get('lastObject').setProperties({",
      "222:         disabled: true,",
      "",
      "[Removed Lines]",
      "219:     items = items.reverse().map(item => App.BreadcrumbItem.extend(item).create());",
      "",
      "[Added Lines]",
      "227:     items.reverse();",
      "228:     items.slice(1).forEach(item => item.label = Ember.Handlebars.Utils.escapeExpression(item.label));",
      "229:     items = items.map(item => App.BreadcrumbItem.extend(item).create());",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "14c03264d69754c0e2cc6e9dbec66410968f5bc0",
      "candidate_info": {
        "commit_hash": "14c03264d69754c0e2cc6e9dbec66410968f5bc0",
        "repo": "apache/ambari",
        "commit_url": "https://github.com/apache/ambari/commit/14c03264d69754c0e2cc6e9dbec66410968f5bc0",
        "files": [
          "ambari-server/src/main/resources/scripts/Ambaripreupload.py"
        ],
        "message": "AMBARI-24843. Make Ambaripreupload.py more configurable (#2556)",
        "before_after_code_files": [
          "ambari-server/src/main/resources/scripts/Ambaripreupload.py||ambari-server/src/main/resources/scripts/Ambaripreupload.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/ambari/pull/3633",
          "https://github.com/apache/ambari/pull/3631",
          "https://github.com/apache/ambari/pull/3637",
          "https://github.com/apache/ambari/pull/3632",
          "https://github.com/apache/ambari/pull/3634",
          "https://github.com/apache/ambari/pull/3635"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "ambari-server/src/main/resources/scripts/Ambaripreupload.py||ambari-server/src/main/resources/scripts/Ambaripreupload.py": [
          "File: ambari-server/src/main/resources/scripts/Ambaripreupload.py -> ambari-server/src/main/resources/scripts/Ambaripreupload.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "7: to you under the Apache License, Version 2.0 (the",
          "8: \"License\"); you may not use this file except in compliance",
          "9: with the License.  You may obtain a copy of the License at",
          "11:     http://www.apache.org/licenses/LICENSE-2.0",
          "13: Unless required by applicable law or agreed to in writing, software",
          "14: distributed under the License is distributed on an \"AS IS\" BASIS,",
          "15: WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
          "16: See the License for the specific language governing permissions and",
          "17: limitations under the License.",
          "19: \"\"\"",
          "20: import os",
          "21: import sys",
          "22: import tarfile",
          "23: from contextlib import closing",
          "24: from optparse import OptionParser",
          "25: os.environ[\"PATH\"] += os.pathsep + \"/var/lib/ambari-agent\"",
          "26: sys.path.append(\"/usr/lib/ambari-server/lib\")",
          "35: from resource_management.core import File",
          "36: from resource_management.core import shell",
          "",
          "[Removed Lines]",
          "28: import glob",
          "29: import re",
          "30: import tempfile",
          "31: import time",
          "32: import functools",
          "33: from xml.dom import minidom",
          "",
          "[Added Lines]",
          "20: import functools",
          "21: import glob",
          "23: import re",
          "26: import tempfile",
          "27: import time",
          "31: from xml.dom import minidom",
          "36: from ambari_server.serverClassPath import JDBC_DRIVER_PATH_PROPERTY",
          "37: from ambari_server.serverConfiguration import get_value_from_properties, get_ambari_properties",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "44: from resource_management.libraries.functions.oozie_prepare_war import prepare_war",
          "45: from resource_management.libraries.resources.hdfs_resource import HdfsResource",
          "60: with Environment() as env:",
          "61:   def get_stack_version():",
          "",
          "[Removed Lines]",
          "48: SQL_DRIVER_PATH = \"/var/lib/ambari-server/resources/sqljdbc41.jar\"",
          "50: \"\"\"",
          "51: This file provides helper methods needed for the versioning of RPMs. Specifically, it does dynamic variable",
          "52: interpretation to replace strings like {{ stack_version_formatted }}  where the value of the",
          "53: variables cannot be determined ahead of time, but rather, depends on what files are found.",
          "55: It assumes that {{ stack_version_formatted }} is constructed as ${major.minor.patch.rev}-${build_number}",
          "56: E.g., 998.2.2.1.0-998",
          "57: Please note that \"-${build_number}\" is optional.",
          "58: \"\"\"",
          "",
          "[Added Lines]",
          "51: DEFAULT_SQL_DRIVER_PATH = get_value_from_properties(get_ambari_properties(), JDBC_DRIVER_PATH_PROPERTY, \"/var/lib/ambari-server/resources/sqljdbc41.jar\")",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "72:         Logger.warning(\"Could not verify HDP version by calling '%s'. Return Code: %s, Output: %s.\" %",
          "73:                        (get_stack_version_cmd, str(code), str(out)))",
          "74:         return 1",
          "76:       matches = re.findall(r\"([\\d\\.]+\\-\\d+)\", out)",
          "77:       stack_version = matches[0] if matches and len(matches) > 0 else None",
          "79:       if not stack_version:",
          "80:         Logger.error(\"Could not parse HDP version from output of hdp-select: %s\" % str(out))",
          "81:         return 1",
          "82:     else:",
          "83:       stack_version = options.hdp_version",
          "85:     return stack_version",
          "87:   parser = OptionParser()",
          "88:   parser.add_option(\"-v\", \"--hdp-version\", dest=\"hdp_version\", default=\"\",",
          "89:                     help=\"hdp-version used in path of tarballs\")",
          "90:   parser.add_option(\"-u\", \"--upgrade\", dest=\"upgrade\", action=\"store_true\",",
          "92:   (options, args) = parser.parse_args()",
          "95:   # See if hdfs path prefix is provided on the command line. If yes, use that value, if no",
          "96:   # use empty string as default.",
          "97:   hdfs_path_prefix = \"\"",
          "98:   if len(args) > 0:",
          "99:     hdfs_path_prefix = args[0]",
          "101:   stack_version = get_stack_version()",
          "103:   def getPropertyValueFromConfigXMLFile(xmlfile, name, defaultValue=None):",
          "104:     xmldoc = minidom.parse(xmlfile)",
          "105:     propNodes = [node.parentNode for node in xmldoc.getElementsByTagName(\"name\") if node.childNodes[0].nodeValue == name]",
          "",
          "[Removed Lines]",
          "91:                     help=\"flag to indicate script is being run for upgrade\", default=False)",
          "",
          "[Added Lines]",
          "81:   parser.add_option(\"-d\", \"--database-driver\", dest=\"sql_driver_path\", default=DEFAULT_SQL_DRIVER_PATH,",
          "82:                     help=\"Path to JDBC driver\")",
          "83:   parser.add_option(\"-f\", \"--fs-type\", dest=\"fs_type\", default=\"wasb\",",
          "84:                     help=\"Expected protocol of fs.defaultFS\")",
          "88:                     help=\"flag to indicate script is being run for upgrade\", default=False)",
          "91:   if not os.path.exists(options.sql_driver_path):",
          "92:     Logger.error(\"SQL driver file {} does not exist\".format(options.sql_driver_path))",
          "93:     sys.exit(1)",
          "95:   Logger.info(\"Using SQL driver from {}\".format(options.sql_driver_path))",
          "96:   sql_driver_filename = os.path.basename(options.sql_driver_path)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "111:           else:",
          "112:             return defaultValue",
          "113:     return defaultValue",
          "115:   def get_fs_root(fsdefaultName=None):",
          "116:     fsdefaultName = \"fake\"",
          "118:     while True:",
          "119:       fsdefaultName =  getPropertyValueFromConfigXMLFile(\"/etc/hadoop/conf/core-site.xml\", \"fs.defaultFS\")",
          "122:         break",
          "125:       time.sleep(10)",
          "129:     return fsdefaultName",
          "131:   # These values must be the suffix of the properties in cluster-env.xml",
          "132:   TAR_SOURCE_SUFFIX = \"_tar_source\"",
          "133:   TAR_DESTINATION_FOLDER_SUFFIX = \"_tar_destination_folder\"",
          "135:   class params:",
          "136:     hdfs_path_prefix = hdfs_path_prefix",
          "137:     hdfs_user = \"hdfs\"",
          "",
          "[Removed Lines]",
          "121:       if fsdefaultName and fsdefaultName.startswith(\"wasb://\"):",
          "124:       print \"Waiting to read appropriate value of fs.defaultFS from /etc/hadoop/conf/core-site.xml ...\"",
          "126:       pass",
          "128:     print \"Returning fs.defaultFS -> \" + fsdefaultName",
          "",
          "[Added Lines]",
          "120:     expected_fs_protocol = options.fs_type + '://'",
          "125:       if fsdefaultName and fsdefaultName.startswith(expected_fs_protocol):",
          "128:       Logger.info(\"Waiting to read appropriate value of fs.defaultFS from /etc/hadoop/conf/core-site.xml ...\")",
          "131:     Logger.info(\"Returning fs.defaultFS -> \" + fsdefaultName)",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "145:     ambari_libs_dir = \"/var/lib/ambari-agent/lib\"",
          "146:     hdfs_site = ConfigDictionary({'dfs.webhdfs.enabled':False,})",
          "147:     fs_default = get_fs_root()",
          "149:     yarn_home_dir = '/usr/hdp/' + stack_version + '/hadoop-yarn'",
          "150:     yarn_lib_dir = yarn_home_dir + '/lib'",
          "151:     yarn_service_tarball = yarn_lib_dir + '/service-dep.tar.gz'",
          "",
          "[Removed Lines]",
          "148:     dfs_type = \"WASB\"",
          "",
          "[Added Lines]",
          "151:     dfs_type = options.fs_type.upper()",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "250:     return _copy_files(source_and_dest_pairs, file_owner, group_owner, kinit_if_needed)",
          "252:   def createHdfsResources():",
          "254:     params.HdfsResource(format('{hdfs_path_prefix}/atshistory'), user='hdfs', change_permissions_for_parents=True, owner='yarn', group='hadoop', type='directory', action= ['create_on_execute'], mode=0755)",
          "255:     params.HdfsResource(format('{hdfs_path_prefix}/user/hcat'), owner='hcat', type='directory', action=['create_on_execute'], mode=0755)",
          "256:     params.HdfsResource(format('{hdfs_path_prefix}/hive/warehouse'), owner='hive', type='directory', action=['create_on_execute'], mode=0777)",
          "",
          "[Removed Lines]",
          "253:     print \"Creating hdfs directories...\"",
          "",
          "[Added Lines]",
          "256:     Logger.info(\"Creating hdfs directories...\")",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "306:       fp.write(file_content)",
          "308:   def putSQLDriverToOozieShared():",
          "312:   def create_yarn_service_tarball():",
          "313:     \"\"\"",
          "",
          "[Removed Lines]",
          "309:     params.HdfsResource(hdfs_path_prefix + '/user/oozie/share/lib/sqoop/{0}'.format(os.path.basename(SQL_DRIVER_PATH)),",
          "310:                         owner='hdfs', type='file', action=['create_on_execute'], mode=0644, source=SQL_DRIVER_PATH)",
          "",
          "[Added Lines]",
          "312:     params.HdfsResource(hdfs_path_prefix + '/user/oozie/share/lib/sqoop/{0}'.format(sql_driver_filename),",
          "313:                         owner='hdfs', type='file', action=['create_on_execute'], mode=0644, source=options.sql_driver_path)",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "321:     with closing(tarfile.open(params.yarn_service_tarball, \"w:gz\")) as tar:",
          "322:       for folder in folders:",
          "323:         for filepath in glob.glob(format(\"{folder}/*.jar\")):",
          "326:   env.set_params(params)",
          "327:   hadoop_conf_dir = params.hadoop_conf_dir",
          "",
          "[Removed Lines]",
          "324:           tar.add(os.path.realpath(filepath), arcname=os.path.basename(filepath))",
          "",
          "[Added Lines]",
          "327:           if os.path.exists(filepath):",
          "328:             Logger.debug(format(\"Adding {filepath}\"))",
          "329:             tar.add(os.path.realpath(filepath), arcname=os.path.basename(filepath))",
          "330:           else:",
          "331:             Logger.warning(format(\"Skipping broken link {filepath}\"))",
          "332:     Execute((\"chmod\", \"0644\", params.yarn_service_tarball))",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "361:   )",
          "363:   oozie_libext_dir = params.oozie_libext_dir",
          "365:   oozie_home=params.oozie_home",
          "366:   configure_cmds = []",
          "367:   configure_cmds.append(('tar','-xvf', oozie_home + '/oozie-sharelib.tar.gz','-C', oozie_home))",
          "369:   configure_cmds.append(('chown', 'oozie:hadoop', oozie_libext_dir + \"/ext-2.2.zip\", oozie_libext_dir + \"/\" + sql_driver_filename))",
          "371:   no_op_test = \"ls /var/run/oozie/oozie.pid >/dev/null 2>&1 && ps -p `cat /var/run/oozie/oozie.pid` >/dev/null 2>&1\"",
          "",
          "[Removed Lines]",
          "364:   sql_driver_filename = os.path.basename(SQL_DRIVER_PATH)",
          "368:   configure_cmds.append(('cp', \"/usr/share/HDP-oozie/ext-2.2.zip\", SQL_DRIVER_PATH, oozie_libext_dir))",
          "",
          "[Added Lines]",
          "375:   configure_cmds.append(('cp', \"/usr/share/HDP-oozie/ext-2.2.zip\", options.sql_driver_path, oozie_libext_dir))",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "429:         try:",
          "430:           Execute(format(\"rm -f {oozie_shared_lib}/lib/spark/spark-examples*.jar\"))",
          "431:         except:",
          "434:         # Copy /usr/hdp/{stack_version}/spark-client/python/lib/*.zip & *.jar to /usr/hdp/{stack_version}/oozie/share/lib/spark",
          "435:         Execute(format(\"cp -f {spark_client_dir}/python/lib/*.zip {oozie_shared_lib}/lib/spark\"))",
          "",
          "[Removed Lines]",
          "432:           print \"No spark-examples jar files found in Spark client lib.\"",
          "",
          "[Added Lines]",
          "439:           Logger.warning(\"No spark-examples jar files found in Spark client lib.\")",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "437:         try:",
          "438:           Execute(format(\"cp -f {spark_client_dir}/python/lib/*.jar {oozie_shared_lib}/lib/spark\"))",
          "439:         except:",
          "442:         Execute((\"chmod\", \"-R\", \"0755\", format('{oozie_shared_lib}/lib/spark')),",
          "443:                 sudo=True)",
          "",
          "[Removed Lines]",
          "440:           print \"No jar files found in Spark client python lib.\"",
          "",
          "[Added Lines]",
          "447:           Logger.warning(\"No jar files found in Spark client python lib.\")",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "450:         #          format(\"{oozie_shared_lib}/lib_{millis}\")),",
          "451:         #         sudo=True)",
          "452:       except Exception, e:",
          "455:     params.HdfsResource(format(\"{oozie_hdfs_user_dir}/share\"),",
          "456:       action=\"create_on_execute\",",
          "",
          "[Removed Lines]",
          "453:         print 'Exception occurred while preparing oozie share lib: '+ repr(e)",
          "",
          "[Added Lines]",
          "460:         Logger.warning('Exception occurred while preparing oozie share lib: '+ repr(e))",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "461:       source = oozie_shared_lib",
          "462:     )",
          "465:   # TODO, these shouldn't hardcode the stack root or destination stack name.",
          "466:   copy_tarballs_to_hdfs(format(\"/usr/hdp/{stack_version}/hadoop/mapreduce.tar.gz\"), hdfs_path_prefix+\"/hdp/apps/{{ stack_version_formatted }}/mapreduce/\", params.mapred_user, params.hdfs_user, params.user_group)",
          "467:   copy_tarballs_to_hdfs(format(\"/usr/hdp/{stack_version}/tez/lib/tez.tar.gz\"), hdfs_path_prefix+\"/hdp/apps/{{ stack_version_formatted }}/tez/\", params.mapred_user, params.hdfs_user, params.user_group)",
          "",
          "[Removed Lines]",
          "464:   print \"Copying tarballs...\"",
          "",
          "[Added Lines]",
          "471:   Logger.info(\"Copying tarballs...\")",
          "",
          "---------------",
          "--- Hunk 14 ---",
          "[Context before]",
          "473:   copy_tarballs_to_hdfs(format(\"/usr/hdp/{stack_version}/pig/pig.tar.gz\"), hdfs_path_prefix+\"/hdp/apps/{{ stack_version_formatted }}/pig/\", params.mapred_user, params.hdfs_user, params.user_group)",
          "474:   copy_tarballs_to_hdfs(format(\"/usr/hdp/{stack_version}/hadoop-mapreduce/hadoop-streaming.jar\"), hdfs_path_prefix+\"/hdp/apps/{{ stack_version_formatted }}/mapreduce/\", params.mapred_user, params.hdfs_user, params.user_group)",
          "475:   copy_tarballs_to_hdfs(format(\"/usr/hdp/{stack_version}/sqoop/sqoop.tar.gz\"), hdfs_path_prefix+\"/hdp/apps/{{ stack_version_formatted }}/sqoop/\", params.mapred_user, params.hdfs_user, params.user_group)",
          "478:   createHdfsResources()",
          "479:   copy_zeppelin_dependencies_to_hdfs(format(\"/usr/hdp/{stack_version}/zeppelin/interpreter/spark/dep/zeppelin-spark-dependencies*.jar\"))",
          "",
          "[Removed Lines]",
          "476:   copy_tarballs_to_hdfs(format(\"/usr/hdp/{stack_version}/hadoop-yarn/lib/service-dep.tar.gz\"), hdfs_path_prefix+\"/hdp/apps/{{ stack_version_formatted }}/yarn/\", params.hdfs_user, params.hdfs_user, params.user_group)",
          "",
          "[Added Lines]",
          "483:   copy_tarballs_to_hdfs(params.yarn_service_tarball, hdfs_path_prefix+\"/hdp/apps/{{ stack_version_formatted }}/yarn/\", params.hdfs_user, params.hdfs_user, params.user_group)",
          "",
          "---------------",
          "--- Hunk 15 ---",
          "[Context before]",
          "495:   except:",
          "496:     os.remove(\"/var/lib/ambari-agent/data/.hdfs_resource_ignore\")",
          "497:     raise",
          "500:   if not options.upgrade:",
          "502:     Execute(",
          "503:       ('/usr/bin/hdp-select', 'set', 'all', stack_version),",
          "504:       sudo = True",
          "505:     )",
          "",
          "[Removed Lines]",
          "498:   print \"Completed tarball copy.\"",
          "501:     print \"Executing stack-selector-tool for stack {0} ...\".format(stack_version)",
          "507:   print \"Ambari preupload script completed.\"",
          "",
          "[Added Lines]",
          "505:   Logger.info(\"Completed tarball copy.\")",
          "508:     Logger.info(\"Executing stack-selector-tool for stack {0} ...\".format(stack_version))",
          "514:   Logger.info(\"Ambari preupload script completed.\")",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "ee5a90c4aedbf3caca65586108583741c10f159c",
      "candidate_info": {
        "commit_hash": "ee5a90c4aedbf3caca65586108583741c10f159c",
        "repo": "apache/ambari",
        "commit_url": "https://github.com/apache/ambari/commit/ee5a90c4aedbf3caca65586108583741c10f159c",
        "files": [
          "ambari-server/src/main/java/org/apache/ambari/server/controller/ControllerModule.java",
          "ambari-server/src/main/java/org/apache/ambari/server/controller/internal/ClusterResourceProvider.java"
        ],
        "message": "AMBARI-25327 : Prevent NPE for bindNotificationDispatchers and getServiceConfigVersionRequest(backport to branch-2.7) (#3038)\n\n* AMBARI-25327 : Prevent NPE for bindNotificationDispatchers and getServiceConfigVersionRequest(backport to branch-2.7)\n\n* logging null classname instance based on review comments",
        "before_after_code_files": [
          "ambari-server/src/main/java/org/apache/ambari/server/controller/ControllerModule.java||ambari-server/src/main/java/org/apache/ambari/server/controller/ControllerModule.java",
          "ambari-server/src/main/java/org/apache/ambari/server/controller/internal/ClusterResourceProvider.java||ambari-server/src/main/java/org/apache/ambari/server/controller/internal/ClusterResourceProvider.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/ambari/pull/3633",
          "https://github.com/apache/ambari/pull/3631",
          "https://github.com/apache/ambari/pull/3637",
          "https://github.com/apache/ambari/pull/3632",
          "https://github.com/apache/ambari/pull/3634",
          "https://github.com/apache/ambari/pull/3635"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "ambari-server/src/main/java/org/apache/ambari/server/controller/ControllerModule.java||ambari-server/src/main/java/org/apache/ambari/server/controller/ControllerModule.java": [
          "File: ambari-server/src/main/java/org/apache/ambari/server/controller/ControllerModule.java -> ambari-server/src/main/java/org/apache/ambari/server/controller/ControllerModule.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "641:     for (BeanDefinition beanDefinition : beanDefinitions) {",
          "642:       String className = beanDefinition.getBeanClassName();",
          "654:         }",
          "662:       }",
          "663:     }",
          "",
          "[Removed Lines]",
          "643:       Class<?> clazz = ClassUtils.resolveClassName(className,",
          "644:           ClassUtils.getDefaultClassLoader());",
          "646:       try {",
          "647:         NotificationDispatcher dispatcher;",
          "648:         if (clazz.equals(AmbariSNMPDispatcher.class)) {",
          "649:           dispatcher = (NotificationDispatcher) clazz.getConstructor(Integer.class).newInstance(configuration.getAmbariSNMPUdpBindPort());",
          "650:         } else if (clazz.equals(SNMPDispatcher.class)) {",
          "651:           dispatcher = (NotificationDispatcher) clazz.getConstructor(Integer.class).newInstance(configuration.getSNMPUdpBindPort());",
          "652:         } else {",
          "653:           dispatcher = (NotificationDispatcher) clazz.newInstance();",
          "655:         dispatchFactory.register(dispatcher.getType(), dispatcher);",
          "656:         bind((Class<NotificationDispatcher>) clazz).toInstance(dispatcher);",
          "658:         LOG.info(\"Binding and registering notification dispatcher {}\", clazz);",
          "659:       } catch (Exception exception) {",
          "660:         LOG.error(\"Unable to bind and register notification dispatcher {}\",",
          "661:             clazz, exception);",
          "",
          "[Added Lines]",
          "643:       if (className != null) {",
          "644:         Class<?> clazz = ClassUtils.resolveClassName(className,",
          "645:                 ClassUtils.getDefaultClassLoader());",
          "646:         try {",
          "647:           NotificationDispatcher dispatcher;",
          "648:           if (clazz.equals(AmbariSNMPDispatcher.class)) {",
          "649:             dispatcher = (NotificationDispatcher) clazz.getConstructor(Integer.class)",
          "650:                     .newInstance(configuration.getAmbariSNMPUdpBindPort());",
          "651:           } else if (clazz.equals(SNMPDispatcher.class)) {",
          "652:             dispatcher = (NotificationDispatcher) clazz.getConstructor(Integer.class)",
          "653:                     .newInstance(configuration.getSNMPUdpBindPort());",
          "654:           } else {",
          "655:             dispatcher = (NotificationDispatcher) clazz.newInstance();",
          "656:           }",
          "657:           dispatchFactory.register(dispatcher.getType(), dispatcher);",
          "658:           bind((Class<NotificationDispatcher>) clazz).toInstance(dispatcher);",
          "659:           LOG.info(\"Binding and registering notification dispatcher {}\", clazz);",
          "660:         } catch (Exception exception) {",
          "661:           LOG.error(\"Unable to bind and register notification dispatcher {}\",",
          "662:                   clazz, exception);",
          "664:       } else {",
          "665:         LOG.error(\"Binding and registering notification dispatcher is not possible for\" +",
          "666:             \" beanDefinition: {} in the absence of className\", beanDefinition);",
          "",
          "---------------"
        ],
        "ambari-server/src/main/java/org/apache/ambari/server/controller/internal/ClusterResourceProvider.java||ambari-server/src/main/java/org/apache/ambari/server/controller/internal/ClusterResourceProvider.java": [
          "File: ambari-server/src/main/java/org/apache/ambari/server/controller/internal/ClusterResourceProvider.java -> ambari-server/src/main/java/org/apache/ambari/server/controller/internal/ClusterResourceProvider.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "468:       String absCategory = PropertyHelper.getPropertyCategory(entry.getKey());",
          "469:       String propName = PropertyHelper.getPropertyName(entry.getKey());",
          "472:         serviceConfigVersionRequest =",
          "473:             (serviceConfigVersionRequest ==null ) ? new ServiceConfigVersionRequest() : serviceConfigVersionRequest;",
          "481:         }",
          "482:       }",
          "483:     }",
          "",
          "[Removed Lines]",
          "471:       if (absCategory.startsWith(parentCategory + \"/desired_service_config_version\")) {",
          "475:         if (propName.equals(\"service_name\"))",
          "476:           serviceConfigVersionRequest.setServiceName(entry.getValue().toString());",
          "477:         else if (propName.equals(\"service_config_version\"))",
          "478:           serviceConfigVersionRequest.setVersion(Long.valueOf(entry.getValue().toString()));",
          "479:         else if (propName.equals(\"service_config_version_note\")) {",
          "480:           serviceConfigVersionRequest.setNote(entry.getValue().toString());",
          "",
          "[Added Lines]",
          "471:       if (absCategory != null &&",
          "472:               absCategory.startsWith(parentCategory + \"/desired_service_config_version\")) {",
          "476:         if (propName != null) {",
          "477:           switch (propName) {",
          "478:             case \"service_name\": {",
          "479:               serviceConfigVersionRequest.setServiceName(entry.getValue().toString());",
          "480:               break;",
          "481:             }",
          "482:             case \"service_config_version\": {",
          "483:               serviceConfigVersionRequest.setVersion(Long.valueOf(entry.getValue().toString()));",
          "484:               break;",
          "485:             }",
          "486:             case \"service_config_version_note\": {",
          "487:               serviceConfigVersionRequest.setNote(entry.getValue().toString());",
          "488:               break;",
          "489:             }",
          "490:           }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "f72d08875d131ee1c9aff8a7a303e5264a087553",
      "candidate_info": {
        "commit_hash": "f72d08875d131ee1c9aff8a7a303e5264a087553",
        "repo": "apache/ambari",
        "commit_url": "https://github.com/apache/ambari/commit/f72d08875d131ee1c9aff8a7a303e5264a087553",
        "files": [
          "ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog271.java",
          "ambari-server/src/test/java/org/apache/ambari/server/upgrade/UpgradeCatalog271Test.java"
        ],
        "message": "AMBARI-24506. Upgrade: Infra Solr service is not renamed in Upgrade History table (#2120)\n\n* AMBARI-24506. Upgrade: Infra Solr service is not renamed in Upgrade History table.\n\n* AMBARI-24506. Simplify name.",
        "before_after_code_files": [
          "ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog271.java||ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog271.java",
          "ambari-server/src/test/java/org/apache/ambari/server/upgrade/UpgradeCatalog271Test.java||ambari-server/src/test/java/org/apache/ambari/server/upgrade/UpgradeCatalog271Test.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/ambari/pull/3633",
          "https://github.com/apache/ambari/pull/3631",
          "https://github.com/apache/ambari/pull/3637",
          "https://github.com/apache/ambari/pull/3632",
          "https://github.com/apache/ambari/pull/3634",
          "https://github.com/apache/ambari/pull/3635"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog271.java||ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog271.java": [
          "File: ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog271.java -> ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog271.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "37: import org.apache.ambari.server.orm.DBAccessor;",
          "38: import org.apache.ambari.server.orm.dao.DaoUtils;",
          "39: import org.apache.ambari.server.orm.entities.ServiceConfigEntity;",
          "40: import org.apache.ambari.server.state.BlueprintProvisioningState;",
          "41: import org.apache.ambari.server.state.Cluster;",
          "42: import org.apache.ambari.server.state.Clusters;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "40: import org.apache.ambari.server.orm.entities.UpgradeHistoryEntity;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "172:     addNewConfigurationsFromXml();",
          "173:     updateRangerLogDirConfigs();",
          "174:     updateRangerKmsDbUrl();",
          "176:     removeLogSearchPatternConfigs();",
          "177:     updateSolrConfigurations();",
          "178:   }",
          "",
          "[Removed Lines]",
          "175:     renameAmbariInfraInConfigGroups();",
          "",
          "[Added Lines]",
          "176:     renameAmbariInfraService();",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "273:     }",
          "274:   }",
          "277:     LOG.info(\"Renaming service AMBARI_INFRA to AMBARI_INFRA_SOLR in config group records\");",
          "278:     AmbariManagementController ambariManagementController = injector.getInstance(AmbariManagementController.class);",
          "279:     Clusters clusters = ambariManagementController.getClusters();",
          "",
          "[Removed Lines]",
          "276:   protected void renameAmbariInfraInConfigGroups() {",
          "",
          "[Added Lines]",
          "277:   protected void renameAmbariInfraService() {",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "302:       serviceConfigUpdate.executeUpdate();",
          "303:     });",
          "307:     entityManager.getEntityManagerFactory().getCache().evictAll();",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "306:     executeInTransaction(() -> {",
          "307:       TypedQuery<UpgradeHistoryEntity> upgradeHistoryUpdate = entityManager.createQuery(",
          "308:         \"UPDATE UpgradeHistoryEntity SET service_name = :newServiceName WHERE service_name = :oldServiceName\", UpgradeHistoryEntity.class);",
          "309:       upgradeHistoryUpdate.setParameter(\"newServiceName\", AMBARI_INFRA_NEW_NAME);",
          "310:       upgradeHistoryUpdate.setParameter(\"oldServiceName\", AMBARI_INFRA_OLD_NAME);",
          "311:       upgradeHistoryUpdate.executeUpdate();",
          "312:     });",
          "",
          "---------------"
        ],
        "ambari-server/src/test/java/org/apache/ambari/server/upgrade/UpgradeCatalog271Test.java||ambari-server/src/test/java/org/apache/ambari/server/upgrade/UpgradeCatalog271Test.java": [
          "File: ambari-server/src/test/java/org/apache/ambari/server/upgrade/UpgradeCatalog271Test.java -> ambari-server/src/test/java/org/apache/ambari/server/upgrade/UpgradeCatalog271Test.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "92:     Method addNewConfigurationsFromXml = AbstractUpgradeCatalog.class.getDeclaredMethod(\"addNewConfigurationsFromXml\");",
          "93:     Method updateRangerLogDirConfigs = UpgradeCatalog271.class.getDeclaredMethod(\"updateRangerLogDirConfigs\");",
          "94:     Method updateRangerKmsDbUrl = UpgradeCatalog271.class.getDeclaredMethod(\"updateRangerKmsDbUrl\");",
          "96:     Method removeLogSearchPatternConfigs = UpgradeCatalog271.class.getDeclaredMethod(\"removeLogSearchPatternConfigs\");",
          "97:     Method updateSolrConfigurations = UpgradeCatalog271.class.getDeclaredMethod(\"updateSolrConfigurations\");",
          "",
          "[Removed Lines]",
          "95:     Method renameAmbariInfraInConfigGroups = UpgradeCatalog271.class.getDeclaredMethod(\"renameAmbariInfraInConfigGroups\");",
          "",
          "[Added Lines]",
          "95:     Method renameAmbariInfraInConfigGroups = UpgradeCatalog271.class.getDeclaredMethod(\"renameAmbariInfraService\");",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "114:     upgradeCatalog271.updateRangerKmsDbUrl();",
          "115:     expectLastCall().once();",
          "118:     expectLastCall().once();",
          "120:     upgradeCatalog271.removeLogSearchPatternConfigs();",
          "",
          "[Removed Lines]",
          "117:     upgradeCatalog271.renameAmbariInfraInConfigGroups();",
          "",
          "[Added Lines]",
          "117:     upgradeCatalog271.renameAmbariInfraService();",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "0cd1b3693bef25b4d4b4cd336d879545bdc464da",
      "candidate_info": {
        "commit_hash": "0cd1b3693bef25b4d4b4cd336d879545bdc464da",
        "repo": "apache/ambari",
        "commit_url": "https://github.com/apache/ambari/commit/0cd1b3693bef25b4d4b4cd336d879545bdc464da",
        "files": [
          "ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog271.java"
        ],
        "message": "AMBARI-24506 - ADDENDUM - Upgrade: Infra Solr service is not renamed in Upgrade History table (#2138)",
        "before_after_code_files": [
          "ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog271.java||ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog271.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/ambari/pull/3633",
          "https://github.com/apache/ambari/pull/3631",
          "https://github.com/apache/ambari/pull/3637",
          "https://github.com/apache/ambari/pull/3632",
          "https://github.com/apache/ambari/pull/3634",
          "https://github.com/apache/ambari/pull/3635"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog271.java||ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog271.java": [
          "File: ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog271.java -> ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog271.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "36: import org.apache.ambari.server.controller.AmbariManagementController;",
          "37: import org.apache.ambari.server.orm.DBAccessor;",
          "38: import org.apache.ambari.server.orm.dao.DaoUtils;",
          "40: import org.apache.ambari.server.orm.entities.UpgradeHistoryEntity;",
          "41: import org.apache.ambari.server.state.BlueprintProvisioningState;",
          "42: import org.apache.ambari.server.state.Cluster;",
          "",
          "[Removed Lines]",
          "39: import org.apache.ambari.server.orm.entities.ServiceConfigEntity;",
          "",
          "[Added Lines]",
          "39: import org.apache.ambari.server.orm.entities.ConfigGroupEntity;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "288:     EntityManager entityManager = getEntityManagerProvider().get();",
          "290:     executeInTransaction(() -> {",
          "293:       serviceConfigUpdate.setParameter(\"newServiceName\", AMBARI_INFRA_NEW_NAME);",
          "294:       serviceConfigUpdate.setParameter(\"oldServiceName\", AMBARI_INFRA_OLD_NAME);",
          "295:       serviceConfigUpdate.executeUpdate();",
          "296:     });",
          "298:     executeInTransaction(() -> {",
          "301:       serviceConfigUpdate.setParameter(\"newServiceName\", AMBARI_INFRA_NEW_NAME);",
          "302:       serviceConfigUpdate.setParameter(\"oldServiceName\", AMBARI_INFRA_OLD_NAME);",
          "303:       serviceConfigUpdate.executeUpdate();",
          "",
          "[Removed Lines]",
          "291:       TypedQuery<ServiceConfigEntity> serviceConfigUpdate = entityManager.createQuery(",
          "292:               \"UPDATE ConfigGroupEntity SET serviceName = :newServiceName WHERE serviceName = :oldServiceName\", ServiceConfigEntity.class);",
          "299:       TypedQuery<ServiceConfigEntity> serviceConfigUpdate = entityManager.createQuery(",
          "300:               \"UPDATE ConfigGroupEntity SET tag = :newServiceName WHERE tag = :oldServiceName\", ServiceConfigEntity.class);",
          "",
          "[Added Lines]",
          "291:       TypedQuery<ConfigGroupEntity> serviceConfigUpdate = entityManager.createQuery(",
          "292:               \"UPDATE ConfigGroupEntity SET serviceName = :newServiceName WHERE serviceName = :oldServiceName\", ConfigGroupEntity.class);",
          "299:       TypedQuery<ConfigGroupEntity> serviceConfigUpdate = entityManager.createQuery(",
          "300:               \"UPDATE ConfigGroupEntity SET tag = :newServiceName WHERE tag = :oldServiceName\", ConfigGroupEntity.class);",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "306:     executeInTransaction(() -> {",
          "307:       TypedQuery<UpgradeHistoryEntity> upgradeHistoryUpdate = entityManager.createQuery(",
          "309:       upgradeHistoryUpdate.setParameter(\"newServiceName\", AMBARI_INFRA_NEW_NAME);",
          "310:       upgradeHistoryUpdate.setParameter(\"oldServiceName\", AMBARI_INFRA_OLD_NAME);",
          "311:       upgradeHistoryUpdate.executeUpdate();",
          "",
          "[Removed Lines]",
          "308:         \"UPDATE UpgradeHistoryEntity SET service_name = :newServiceName WHERE service_name = :oldServiceName\", UpgradeHistoryEntity.class);",
          "",
          "[Added Lines]",
          "308:         \"UPDATE UpgradeHistoryEntity SET serviceName = :newServiceName WHERE serviceName = :oldServiceName\", UpgradeHistoryEntity.class);",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "b62b4676e8a0b68b171553a37c1ee0c90ce28496",
      "candidate_info": {
        "commit_hash": "b62b4676e8a0b68b171553a37c1ee0c90ce28496",
        "repo": "apache/ambari",
        "commit_url": "https://github.com/apache/ambari/commit/b62b4676e8a0b68b171553a37c1ee0c90ce28496",
        "files": [
          "ambari-web/app/mixins/common/configs/enhanced_configs.js"
        ],
        "message": "AMBARI-25425. Recommendations API error during cluster creation wizard",
        "before_after_code_files": [
          "ambari-web/app/mixins/common/configs/enhanced_configs.js||ambari-web/app/mixins/common/configs/enhanced_configs.js"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/ambari/pull/3633",
          "https://github.com/apache/ambari/pull/3631",
          "https://github.com/apache/ambari/pull/3637",
          "https://github.com/apache/ambari/pull/3632",
          "https://github.com/apache/ambari/pull/3634",
          "https://github.com/apache/ambari/pull/3635"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "ambari-web/app/mixins/common/configs/enhanced_configs.js||ambari-web/app/mixins/common/configs/enhanced_configs.js": [
          "File: ambari-web/app/mixins/common/configs/enhanced_configs.js -> ambari-web/app/mixins/common/configs/enhanced_configs.js",
          "--- Hunk 1 ---",
          "[Context before]",
          "221:     var updateDependencies = Em.isArray(changedConfigs) && changedConfigs.length > 0;",
          "222:     var stepConfigs = this.get('stepConfigs');",
          "223:     var requiredTags = [];",
          "227:     if (updateDependencies || Em.isNone(this.get('recommendationsConfigs'))) {",
          "228:       var recommendations = isAutoComplete ? {} : this.get('hostGroups');",
          "",
          "[Removed Lines]",
          "224:     const isAutoComplete = !updateDependencies;",
          "225:     this.set('isRecommendationsAutoComplete', isAutoComplete);",
          "",
          "[Added Lines]",
          "224:     var isAutoComplete = !updateDependencies && this.get('isRecommendationsAutoComplete') !== undefined;",
          "225:     if (this.get('isRecommendationsAutoComplete') !== undefined) {",
          "226:       this.set('isRecommendationsAutoComplete', isAutoComplete);",
          "227:     }",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "269:   addRecommendationRequestParams: function(recommendations, dataToSend, stepConfigs) {",
          "271:     if (!isAutoComplete) {",
          "272:         recommendations.blueprint.configurations = blueprintUtils.buildConfigsJSON(stepConfigs);",
          "273:     }",
          "",
          "[Removed Lines]",
          "270:     const isAutoComplete = Boolean(this.get('isRecommendationsAutoComplete'));",
          "",
          "[Added Lines]",
          "272:     var isAutoComplete = Boolean(this.get('isRecommendationsAutoComplete'));",
          "",
          "---------------"
        ]
      }
    }
  ]
}