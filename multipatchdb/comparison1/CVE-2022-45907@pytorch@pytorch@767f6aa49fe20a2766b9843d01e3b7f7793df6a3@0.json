{
  "cve_id": "CVE-2022-45907",
  "cve_desc": "In PyTorch before trunk/89695, torch.jit.annotations.parse_type_line can cause arbitrary code execution because eval is used unsafely.",
  "repo": "pytorch/pytorch",
  "patch_hash": "767f6aa49fe20a2766b9843d01e3b7f7793df6a3",
  "patch_info": {
    "commit_hash": "767f6aa49fe20a2766b9843d01e3b7f7793df6a3",
    "repo": "pytorch/pytorch",
    "commit_url": "https://github.com/pytorch/pytorch/commit/767f6aa49fe20a2766b9843d01e3b7f7793df6a3",
    "files": [
      "test/test_jit.py",
      "torch/csrc/jit/frontend/script_type_parser.cpp",
      "torch/jit/annotations.py"
    ],
    "message": "[JIT][Security] Do not blindly eval input string (#89189)\n\nIntroduce `_eval_no_call` method, that evaluates statement only if it\ndoes not contain any calls(done by examining the bytecode), thus preventing command injection exploit\n\nAdded simple unit test to check for that\n`torch.jit.annotations.get_signature` would not result in calling random\ncode.\n\nAlthough, this code path exists for Python-2 compatibility, and perhaps\nshould be simply removed.\n\nFixes https://github.com/pytorch/pytorch/issues/88868\n\nPull Request resolved: https://github.com/pytorch/pytorch/pull/89189\nApproved by: https://github.com/suo",
    "before_after_code_files": [
      "test/test_jit.py||test/test_jit.py",
      "torch/csrc/jit/frontend/script_type_parser.cpp||torch/csrc/jit/frontend/script_type_parser.cpp",
      "torch/jit/annotations.py||torch/jit/annotations.py"
    ]
  },
  "patch_diff": {
    "test/test_jit.py||test/test_jit.py": [
      "File: test/test_jit.py -> test/test_jit.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "3951:                 return a + 2",
      "3952:             torch.jit.script(invalid4)",
      "3954:     def test_is_optional(self):",
      "3955:         ann = Union[List[int], List[float]]",
      "3956:         torch._jit_internal.is_optional(ann)",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "3954:     def test_calls_in_type_annotations(self):",
      "3955:         with self.assertRaisesRegex(RuntimeError, \"Type annotation should not contain calls\"):",
      "3956:             def spooky(a):",
      "3957:                 # type: print(\"Hello\") -> Tensor # noqa: F723",
      "3958:                 return a + 2",
      "3959:             print(torch.__file__)",
      "3960:             torch.jit.annotations.get_signature(spooky, None, 1, True)",
      "",
      "---------------"
    ],
    "torch/csrc/jit/frontend/script_type_parser.cpp||torch/csrc/jit/frontend/script_type_parser.cpp": [
      "File: torch/csrc/jit/frontend/script_type_parser.cpp -> torch/csrc/jit/frontend/script_type_parser.cpp"
    ],
    "torch/jit/annotations.py||torch/jit/annotations.py": [
      "File: torch/jit/annotations.py -> torch/jit/annotations.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "1: import ast",
      "2: import enum",
      "3: import inspect",
      "4: import re",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "2: import dis",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "144:         raise torch.jit.frontend.FrontendError(loc, \"Expected a single top-level function\")",
      "147: def parse_type_line(type_line, rcb, loc):",
      "148:     \"\"\"Parses a type annotation specified as a comment.",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "148: def _eval_no_call(stmt, glob, loc):",
      "149:     \"\"\"Evaluate statement as long as it does not contain any method/function calls\"\"\"",
      "150:     bytecode = compile(stmt, \"\", mode=\"eval\")",
      "151:     for insn in dis.get_instructions(bytecode):",
      "152:         if \"CALL\" in insn.opname:",
      "153:             raise RuntimeError(f\"Type annotation should not contain calls, but '{stmt}' does\")",
      "154:     return eval(bytecode, glob, loc)  # type: ignore[arg-type] # noqa: P204",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "154:     arg_ann_str, ret_ann_str = split_type_line(type_line)",
      "156:     try:",
      "158:     except (NameError, SyntaxError) as e:",
      "159:         raise RuntimeError(\"Failed to parse the argument list of a type annotation\") from e",
      "",
      "[Removed Lines]",
      "157:         arg_ann = eval(arg_ann_str, {}, EvalEnv(rcb))  # type: ignore[arg-type] # noqa: P204",
      "",
      "[Added Lines]",
      "167:         arg_ann = _eval_no_call(arg_ann_str, {}, EvalEnv(rcb))",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "162:         arg_ann = (arg_ann,)",
      "164:     try:",
      "166:     except (NameError, SyntaxError) as e:",
      "167:         raise RuntimeError(\"Failed to parse the return type of a type annotation\") from e",
      "",
      "[Removed Lines]",
      "165:         ret_ann = eval(ret_ann_str, {}, EvalEnv(rcb))  # type: ignore[arg-type] # noqa: P204",
      "",
      "[Added Lines]",
      "175:         ret_ann = _eval_no_call(ret_ann_str, {}, EvalEnv(rcb))",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "fe5d8850e27d98439166c76ccc5e167fd3960df8",
      "candidate_info": {
        "commit_hash": "fe5d8850e27d98439166c76ccc5e167fd3960df8",
        "repo": "pytorch/pytorch",
        "commit_url": "https://github.com/pytorch/pytorch/commit/fe5d8850e27d98439166c76ccc5e167fd3960df8",
        "files": [
          "torch/contrib/_tensorboard_vis.py",
          "torch/jit/__init__.py",
          "torch/jit/_async.py",
          "torch/jit/_await.py",
          "torch/jit/_check.py",
          "torch/jit/_freeze.py",
          "torch/jit/_fuser.py",
          "torch/jit/_monkeytype_config.py",
          "torch/jit/_recursive.py",
          "torch/jit/_script.py",
          "torch/jit/_serialization.py",
          "torch/jit/_state.py",
          "torch/jit/_trace.py",
          "torch/jit/annotations.py",
          "torch/jit/mobile/__init__.py",
          "torch/sparse/__init__.py"
        ],
        "message": "Fixed docstring errors in _fuser.py, _state.py, __init__.py, _freeze.py, _async.py, _recursive.py, _tensorboard_vis.py, _trace.py, _await.py, _check.py, _serialization.py, _script.py, annotations.py, _monkeytype_config.py (#113371)\n\nFixes #113194\n\ndocstrings updated.\n\nHere are the outputs with the number before and after:-\n\n1) torch/sparse/__init__.py\n\nBefore:\n```\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:1 at module level:\n        D104: Missing docstring in public package\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:183 in public function `sum`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:183 in public function `sum`:\n        D400: First line should end with a period (not 'n')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:183 in public function `sum`:\n        D401: First line should be in imperative mood (perhaps 'Return', not 'Returns')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:391 in public class `check_sparse_tensor_invariants`:\n        D207: Docstring is under-indented\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:436 in public method `is_enabled`:\n        D207: Docstring is under-indented\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:436 in public method `is_enabled`:\n        D401: First line should be in imperative mood (perhaps 'Return', not 'Returns')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:448 in public method `enable`:\n        D207: Docstring is under-indented\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:468 in public method `disable`:\n        D207: Docstring is under-indented\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:475 in public method `__init__`:\n        D107: Missing docstring in __init__\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:479 in public method `__enter__`:\n        D105: Missing docstring in magic method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:486 in public method `__exit__`:\n        D105: Missing docstring in magic method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:492 in public method `__call__`:\n        D102: Missing docstring in public method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:502 in public function `as_sparse_gradcheck`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:502 in public function `as_sparse_gradcheck`:\n        D400: First line should end with a period (not 'l')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:502 in public function `as_sparse_gradcheck`:\n        D401: First line should be in imperative mood (perhaps 'Decorate', not 'Decorator')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:518 in private nested function `gradcheck_with_sparse_support`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:518 in private nested function `gradcheck_with_sparse_support`:\n        D400: First line should end with a period (not 's')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:518 in private nested function `gradcheck_with_sparse_support`:\n        D401: First line should be in imperative mood; try rephrasing (found 'Same')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:528 in private nested function `convert_to_strided_representation`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:528 in private nested function `convert_to_strided_representation`:\n        D400: First line should end with a period (not 'n')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:559 in private nested function `restore_from_strided_representation`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:559 in private nested function `restore_from_strided_representation`:\n        D400: First line should end with a period (not 'd')\n23\n```\nAfter:\n```\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:1 at module level:\n        D104: Missing docstring in public package\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:476 in public method `__init__`:\n        D107: Missing docstring in __init__\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:480 in public method `__enter__`:\n        D105: Missing docstring in magic method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:487 in public method `__exit__`:\n        D105: Missing docstring in magic method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/sparse/__init__.py:493 in public method `__call__`:\n        D102: Missing docstring in public method\n5\n```\n2) torch/contrib/_tensorboard_vis.py\n\nBefore:\n```\n/home/ubuntu/Desktop/Docathon/pytorch/torch/contrib/_tensorboard_vis.py:21 in public function `dump_tensorboard_summary`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/contrib/_tensorboard_vis.py:54 in public function `visualize_graph_executor`:\n        D401: First line should be in imperative mood (perhaps 'Append', not 'Appends')\n2\n```\nAfter:\n```\n/home/ubuntu/Desktop/Docathon/pytorch/torch/contrib/_tensorboard_vis.py:21 in public function `dump_tensorboard_summary`:\n        D103: Missing docstring in public function\n1\n```\n3) torch/jit/_state.py\n\nBefore:\n```\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_state.py:1 at module level:\n        D400: First line should end with a period (not 'e')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_state.py:20 in public method `__init__`:\n        D107: Missing docstring in __init__\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_state.py:25 in public method `parse_env`:\n        D102: Missing docstring in public method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_state.py:41 in public method `__bool__`:\n        D105: Missing docstring in magic method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_state.py:48 in public function `disable`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_state.py:52 in public function `enable`:\n        D103: Missing docstring in public function\n6\n```\nAfter:\n```\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_state.py:20 in public method `__init__`:\n        D107: Missing docstring in __init__\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_state.py:25 in public method `parse_env`:\n        D102: Missing docstring in public method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_state.py:41 in public method `__bool__`:\n        D105: Missing docstring in magic method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_state.py:48 in public function `disable`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_state.py:52 in public function `enable`:\n        D103: Missing docstring in public function\n5\n```\n4) torch/jit/_monkeytype_config.py\n\nBefore:\n```\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:27 in public function `is_torch_native_class`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:40 in public function `get_type`:\n        D200: One-line docstring should fit on one line with quotes (found 3)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:40 in public function `get_type`:\n        D401: First line should be in imperative mood; try rephrasing (found 'Helper')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:62 in public function `get_optional_of_element_type`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:62 in public function `get_optional_of_element_type`:\n        D400: First line should end with a period (not 'l')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:62 in public function `get_optional_of_element_type`:\n        D401: First line should be in imperative mood; try rephrasing (found 'Helper')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:75 in public function `get_qualified_name`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:84 in public method `__init__`:\n        D107: Missing docstring in __init__\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:87 in public method `log`:\n        D102: Missing docstring in public method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:90 in public class `JitTypeTraceStore`:\n        D101: Missing docstring in public class\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:91 in public method `__init__`:\n        D107: Missing docstring in __init__\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:98 in public method `add`:\n        D102: Missing docstring in public method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:103 in public method `filter`:\n        D102: Missing docstring in public method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:111 in public method `analyze`:\n        D102: Missing docstring in public method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:122 in public method `consolidate_types`:\n        D102: Missing docstring in public method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:139 in public method `get_args_types`:\n        D102: Missing docstring in public method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:142 in public class `JitTypeTraceConfig`:\n        D101: Missing docstring in public class\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:143 in public method `__init__`:\n        D107: Missing docstring in __init__\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:148 in public method `trace_logger`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:148 in public method `trace_logger`:\n        D400: First line should end with a period (not 'd')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:148 in public method `trace_logger`:\n        D401: First line should be in imperative mood (perhaps 'Return', not 'Returns')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:154 in public method `trace_store`:\n        D102: Missing docstring in public method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:157 in public method `code_filter`:\n        D102: Missing docstring in public method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:163 in public class `JitTypeTraceStoreLogger`:\n        D101: Missing docstring in public class\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:164 in public method `__init__`:\n        D107: Missing docstring in __init__\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:167 in public class `JitTypeTraceStore`:\n        D101: Missing docstring in public class\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:168 in public method `__init__`:\n        D107: Missing docstring in __init__\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:171 in public class `JitTypeTraceConfig`:\n        D101: Missing docstring in public class\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:172 in public method `__init__`:\n        D107: Missing docstring in __init__\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:179 in public function `jit_code_filter`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:179 in public function `jit_code_filter`:\n        D401: First line should be in imperative mood; try rephrasing (found 'Custom')\n31\n```\nAfter:\n```\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:27 in public function `is_torch_native_class`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:74 in public function `get_qualified_name`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:83 in public method `__init__`:\n        D107: Missing docstring in __init__\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:86 in public method `log`:\n        D102: Missing docstring in public method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:89 in public class `JitTypeTraceStore`:\n        D101: Missing docstring in public class\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:90 in public method `__init__`:\n        D107: Missing docstring in __init__\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:97 in public method `add`:\n        D102: Missing docstring in public method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:102 in public method `filter`:\n        D102: Missing docstring in public method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:110 in public method `analyze`:\n        D102: Missing docstring in public method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:121 in public method `consolidate_types`:\n        D102: Missing docstring in public method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:138 in public method `get_args_types`:\n        D102: Missing docstring in public method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:141 in public class `JitTypeTraceConfig`:\n        D101: Missing docstring in public class\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:142 in public method `__init__`:\n        D107: Missing docstring in __init__\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:150 in public method `trace_store`:\n        D102: Missing docstring in public method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:153 in public method `code_filter`:\n        D102: Missing docstring in public method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:159 in public class `JitTypeTraceStoreLogger`:\n        D101: Missing docstring in public class\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:160 in public method `__init__`:\n        D107: Missing docstring in __init__\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:163 in public class `JitTypeTraceStore`:\n        D101: Missing docstring in public class\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:164 in public method `__init__`:\n        D107: Missing docstring in __init__\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:167 in public class `JitTypeTraceConfig`:\n        D101: Missing docstring in public class\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_monkeytype_config.py:168 in public method `__init__`:\n        D107: Missing docstring in __init__\n21\n```\n5) torch/jit/_fuser.py\n\nBefore:\n```\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_fuser.py:9 in public function `optimized_execution`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_fuser.py:9 in public function `optimized_execution`:\n        D400: First line should end with a period (not 'n')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_fuser.py:9 in public function `optimized_execution`:\n        D401: First line should be in imperative mood; try rephrasing (found 'A')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_fuser.py:23 in public function `fuser`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_fuser.py:23 in public function `fuser`:\n        D400: First line should end with a period (not 'n')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_fuser.py:23 in public function `fuser`:\n        D401: First line should be in imperative mood; try rephrasing (found 'A')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_fuser.py:136 in public function `set_fusion_strategy`:\n        D401: First line should be in imperative mood (perhaps 'Set', not 'Sets')\n7\n```\nAfter:\n```\n0\n```\n6) torch/jit/_async.py\n\nBefore:\n```\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_async.py:1 at module level:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_async.py:1 at module level:\n        D400: First line should end with a period (not 'I')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_async.py:20 in public function `fork`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_async.py:20 in public function `fork`:\n        D400: First line should end with a period (not 'e')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_async.py:20 in public function `fork`:\n        D401: First line should be in imperative mood (perhaps 'Create', not 'Creates')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_async.py:88 in public function `wait`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_async.py:88 in public function `wait`:\n        D400: First line should end with a period (not 'e')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_async.py:88 in public function `wait`:\n        D401: First line should be in imperative mood (perhaps 'Force', not 'Forces')\n8\n```\nAfter:\n```\n0\n```\n7) torch/jit/_await.py\n\nBefore:\n```\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_await.py:11 in private function `_awaitable`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_await.py:11 in private function `_awaitable`:\n        D400: First line should end with a period (not ',')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_await.py:11 in private function `_awaitable`:\n        D401: First line should be in imperative mood (perhaps 'Create', not 'Creates')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_await.py:19 in private function `_awaitable_wait`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_await.py:19 in private function `_awaitable_wait`:\n        D400: First line should end with a period (not ',')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_await.py:19 in private function `_awaitable_wait`:\n        D401: First line should be in imperative mood (perhaps 'Request', not 'Requests')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_await.py:27 in private function `_awaitable_nowait`:\n        D200: One-line docstring should fit on one line with quotes (found 3)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_await.py:27 in private function `_awaitable_nowait`:\n        D401: First line should be in imperative mood (perhaps 'Create', not 'Creates')\n8\n```\nAfter:\n```\n0\n```\n8) torch/jit/_check.py\n\nBefore:\n```\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_check.py:10 in public class `AttributeTypeIsSupportedChecker`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_check.py:10 in public class `AttributeTypeIsSupportedChecker`:\n        D400: First line should end with a period (not 'e')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_check.py:10 in public class `AttributeTypeIsSupportedChecker`:\n        D412: No blank lines allowed between a section header and its content ('Example')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_check.py:61 in public method `check`:\n        D102: Missing docstring in public method\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_check.py:110 in public method `visit_Assign`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_check.py:110 in public method `visit_Assign`:\n        D400: First line should end with a period (not 'n')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_check.py:132 in public method `visit_AnnAssign`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_check.py:132 in public method `visit_AnnAssign`:\n        D400: First line should end with a period (not '`')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_check.py:187 in public method `visit_Call`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_check.py:187 in public method `visit_Call`:\n        D400: First line should end with a period (not '`')\n10\n```\nAfter:\n```\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_check.py:58 in public method `check`:\n        D102: Missing docstring in public method\n1\n```\n9) torch/jit/_freeze.py\n\nBefore:\n```\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_freeze.py:1 at module level:\n        D400: First line should end with a period (not 'g')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_freeze.py:16 in public function `freeze`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_freeze.py:16 in public function `freeze`:\n        D400: First line should end with a period (not 'd')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_freeze.py:127 in public function `run_frozen_optimizations`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_freeze.py:127 in public function `run_frozen_optimizations`:\n        D401: First line should be in imperative mood (perhaps 'Run', not 'Runs')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_freeze.py:182 in public function `optimize_for_inference`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_freeze.py:182 in public function `optimize_for_inference`:\n        D400: First line should end with a period (not 'e')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_freeze.py:182 in public function `optimize_for_inference`:\n        D401: First line should be in imperative mood (perhaps 'Perform', not 'Performs')\n8\n```\nAfter:\n```\n0\n```\n10) torch/jit/_recursive.py\n\nBefore:\n```\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:69 in public function `make_stub`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:75 in public function `make_stub_from_method`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:90 in public function `make_stubs_from_exported_methods`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:103 in public function `jit_ignored_properties`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:155 in public class `SourceContext`:\n        D101: Missing docstring in public class\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:156 in public method `__init__`:\n        D107: Missing docstring in __init__\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:160 in public function `get_annotations`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:186 in public function `infer_concrete_type_builder`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:186 in public function `infer_concrete_type_builder`:\n        D400: First line should end with a period (not 's')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:423 in public class `ConcreteTypeStore`:\n        D101: Missing docstring in public class\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:427 in public method `__init__`:\n        D107: Missing docstring in __init__\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:434 in public method `get_or_create_concrete_type`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:434 in public method `get_or_create_concrete_type`:\n        D400: First line should end with a period (not 'T')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:459 in public function `create_methods_and_properties_from_stubs`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:474 in public function `create_hooks_from_stubs`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:485 in public function `get_module_concrete_type`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:485 in public function `get_module_concrete_type`:\n        D400: First line should end with a period (not 'e')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:485 in public function `get_module_concrete_type`:\n        D401: First line should be in imperative mood (perhaps 'Get', not 'Gets')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:539 in public function `create_script_module`:\n        D400: First line should end with a period (not 'e')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:539 in public function `create_script_module`:\n        D401: First line should be in imperative mood (perhaps 'Create', not 'Creates')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:725 in public function `script_model_defines_attr`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:735 in public function `add_python_attr_to_scripted_model`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:740 in public function `get_overload_annotations`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:772 in public function `get_overload_name_mapping`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:797 in public function `make_stubs_for_overloads`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:816 in public function `check_module_initialized`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:842 in public function `infer_methods_to_compile`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:842 in public function `infer_methods_to_compile`:\n        D400: First line should end with a period (not 'g')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:842 in public function `infer_methods_to_compile`:\n        D401: First line should be in imperative mood (perhaps 'Implement', not 'Implements')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:904 in public function `get_hook_stubs`:\n        D200: One-line docstring should fit on one line with quotes (found 3)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:904 in public function `get_hook_stubs`:\n        D400: First line should end with a period (not 's')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:904 in public function `get_hook_stubs`:\n        D401: First line should be in imperative mood (perhaps 'Return', not 'Returns')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:940 in public function `get_property_stubs`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:940 in public function `get_property_stubs`:\n        D400: First line should end with a period (not 'd')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:963 in public function `interface_script`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:963 in public function `interface_script`:\n        D400: First line should end with a period (not 'r')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:963 in public function `interface_script`:\n        D401: First line should be in imperative mood (perhaps 'Make', not 'Makes')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:977 in private nested function `infer_interface_methods_to_compile`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:977 in private nested function `infer_interface_methods_to_compile`:\n        D400: First line should end with a period (not 'h')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:989 in public function `try_compile_fn`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:1014 in public function `wrap_cpp_class`:\n        D200: One-line docstring should fit on one line with quotes (found 3)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:1021 in public function `wrap_cpp_module`:\n        D200: One-line docstring should fit on one line with quotes (found 3)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:1021 in public function `wrap_cpp_module`:\n        D400: First line should end with a period (not 's')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:1040 in public function `compile_unbound_method`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:1052 in public function `lazy_bind`:\n        D205: 1 blank line required between summary line and description (found 0)\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:1052 in public function `lazy_bind`:\n        D400: First line should end with a period (not 'd')\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:1052 in public function `lazy_bind`:\n        D401: First line should be in imperative mood (perhaps 'Return', not 'Returns')\n47\n```\nAfter:\n```\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:69 in public function `make_stub`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:75 in public function `make_stub_from_method`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:90 in public function `make_stubs_from_exported_methods`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:103 in public function `jit_ignored_properties`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:155 in public class `SourceContext`:\n        D101: Missing docstring in public class\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:156 in public method `__init__`:\n        D107: Missing docstring in __init__\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:160 in public function `get_annotations`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:424 in public class `ConcreteTypeStore`:\n        D101: Missing docstring in public class\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:428 in public method `__init__`:\n        D107: Missing docstring in __init__\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:457 in public function `create_methods_and_properties_from_stubs`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:472 in public function `create_hooks_from_stubs`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:724 in public function `script_model_defines_attr`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:734 in public function `add_python_attr_to_scripted_model`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:739 in public function `get_overload_annotations`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:771 in public function `get_overload_name_mapping`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:796 in public function `make_stubs_for_overloads`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:815 in public function `check_module_initialized`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:979 in public function `try_compile_fn`:\n        D103: Missing docstring in public function\n/home/ubuntu/Desktop/Docathon/pytorch/torch/jit/_recursive.py:1026 in public function `compile_unbound_method`:\n        D103: Missing docstring in public function\n19\n```\n\n@svekars\n\nPull Request resolved: https://github.com/pytorch/pytorch/pull/113371\nApproved by: https://github.com/davidberard98",
        "before_after_code_files": [
          "torch/contrib/_tensorboard_vis.py||torch/contri_tensorboard_vis.py",
          "torch/jit/__init__.py||torch/jit/__init__.py",
          "torch/jit/_async.py||torch/jit/_async.py",
          "torch/jit/_await.py||torch/jit/_await.py",
          "torch/jit/_check.py||torch/jit/_check.py",
          "torch/jit/_freeze.py||torch/jit/_freeze.py",
          "torch/jit/_fuser.py||torch/jit/_fuser.py",
          "torch/jit/_monkeytype_config.py||torch/jit/_monkeytype_config.py",
          "torch/jit/_recursive.py||torch/jit/_recursive.py",
          "torch/jit/_script.py||torch/jit/_script.py",
          "torch/jit/_serialization.py||torch/jit/_serialization.py",
          "torch/jit/_state.py||torch/jit/_state.py",
          "torch/jit/_trace.py||torch/jit/_trace.py",
          "torch/jit/annotations.py||torch/jit/annotations.py",
          "torch/jit/mobile/__init__.py||torch/jit/mobile/__init__.py",
          "torch/sparse/__init__.py||torch/sparse/__init__.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "torch/jit/annotations.py||torch/jit/annotations.py"
          ],
          "candidate": [
            "torch/jit/annotations.py||torch/jit/annotations.py"
          ]
        }
      },
      "candidate_diff": {
        "torch/contrib/_tensorboard_vis.py||torch/contri_tensorboard_vis.py": [
          "File: torch/contrib/_tensorboard_vis.py -> torch/contri_tensorboard_vis.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "53: def visualize_graph_executor(state, name_prefix, pb_graph, inline_graph):",
          "56:     Args:",
          "57:         state (GraphExecutor or GraphExecutorState): GraphExecutor to display.",
          "",
          "[Removed Lines]",
          "54:     \"\"\"Appends the state of a given GraphExecutor to the graph protobuf.",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "torch/jit/__init__.py||torch/jit/__init__.py": [
          "File: torch/jit/__init__.py -> torch/jit/__init__.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "105: def export_opnames(m):",
          "106:     r\"\"\"",
          "110:     list of ops call _export_operator_list instead.",
          "111:     \"\"\"",
          "112:     return torch._C._export_opnames(m._c)",
          "",
          "[Removed Lines]",
          "107:     Generates new bytecode for a Script module and returns what the op list",
          "108:     would be for a Script Module based off the current code base. If you",
          "109:     have a LiteScriptModule and want to get the currently present",
          "",
          "[Added Lines]",
          "107:     Generate new bytecode for a Script module.",
          "109:     Returns what the op list would be for a Script Module based off the current code base.",
          "111:     If you have a LiteScriptModule and want to get the currently present",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "123: # for use in python if using annotate",
          "124: def annotate(the_type, the_value):",
          "126:     This method is a pass-through function that returns `the_value`, used to hint TorchScript",
          "127:     compiler the type of `the_value`. It is a no-op when running outside of TorchScript.",
          "",
          "[Removed Lines]",
          "125:     \"\"\"",
          "",
          "[Added Lines]",
          "127:     \"\"\"Use to give type of `the_value` in TorchScript compiler.",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "171: def script_if_tracing(fn):",
          "172:     \"\"\"",
          "175:     lazy-initializations of many compiler builtins. Therefore you should not use",
          "176:     it in library code. However, you may want to have parts of your library work",
          "177:     in tracing even if they use control flow. In these cases, you should use",
          "",
          "[Removed Lines]",
          "173:     Compiles ``fn`` when it is first called during tracing. ``torch.jit.script``",
          "174:     has a non-negligible start up time when it is first called due to",
          "",
          "[Added Lines]",
          "176:     Compiles ``fn`` when it is first called during tracing.",
          "178:     ``torch.jit.script`` has a non-negligible start up time when it is first called due to",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "185:         If called during tracing, a :class:`ScriptFunction` created by `torch.jit.script` is returned.",
          "186:         Otherwise, the original function `fn` is returned.",
          "187:     \"\"\"",
          "189:     return _script_if_tracing(fn)",
          "192: # for torch.jit.isinstance",
          "193: def isinstance(obj, target_type):",
          "194:     \"\"\"",
          "197:     ``Dict[str, List[torch.Tensor]]``, ``Optional[Tuple[int,str,int]]``. It can also",
          "198:     refine basic types such as bools and ints that are available in TorchScript.",
          "",
          "[Removed Lines]",
          "195:     This function provides for container type refinement in TorchScript. It can refine",
          "196:     parameterized containers of the List, Dict, Tuple, and Optional types. E.g. ``List[str]``,",
          "",
          "[Added Lines]",
          "198:     Provide container type refinement in TorchScript.",
          "200:     It can refine parameterized containers of the List, Dict, Tuple, and Optional types. E.g. ``List[str]``,",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "235: class strict_fusion:",
          "236:     \"\"\"",
          "240:     Example:",
          "242:     Forcing fusion of additions.",
          "244:     .. code-block:: python",
          "",
          "[Removed Lines]",
          "237:     This class errors if not all nodes have been fused in",
          "238:     inference, or symbolically differentiated in training.",
          "",
          "[Added Lines]",
          "241:     Give errors if not all nodes have been fused in inference, or symbolically differentiated in training.",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "278: def enable_onednn_fusion(enabled: bool):",
          "283:     torch._C._jit_set_llga_enabled(enabled)",
          "286: def onednn_fusion_enabled():",
          "290:     return torch._C._jit_llga_enabled()",
          "",
          "[Removed Lines]",
          "279:     \"\"\"",
          "280:     Enables or disables onednn JIT fusion based on the parameter `enabled`.",
          "281:     \"\"\"",
          "287:     \"\"\"",
          "288:     Returns whether onednn JIT fusion is enabled",
          "289:     \"\"\"",
          "",
          "[Added Lines]",
          "281:     \"\"\"Enable or disables onednn JIT fusion based on the parameter `enabled`.\"\"\"",
          "286:     \"\"\"Return whether onednn JIT fusion is enabled.\"\"\"",
          "",
          "---------------"
        ],
        "torch/jit/_async.py||torch/jit/_async.py": [
          "File: torch/jit/_async.py -> torch/jit/_async.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "2: This module contains the API for parallelism in TorchScript, notably:",
          "",
          "[Removed Lines]",
          "1: \"\"\"Async API",
          "",
          "[Added Lines]",
          "1: \"\"\"Async API.",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "19: def fork(func, *args, **kwargs):",
          "20:     r\"\"\"",
          "24:     of the task and access the return value invoke `torch.jit.wait` on the Future. `fork` invoked",
          "25:     with a `func` which returns `T` is typed as `torch.jit.Future[T]`. `fork` calls can be arbitrarily",
          "26:     nested, and may be invoked with positional and keyword arguments.",
          "",
          "[Removed Lines]",
          "21:     Creates an asynchronous task executing `func` and a reference to the value",
          "22:     of the result of this execution. `fork` will return immediately,",
          "23:     so the return value of `func` may not have been computed yet. To force completion",
          "",
          "[Added Lines]",
          "22:     Create an asynchronous task executing `func` and a reference to the value of the result of this execution.",
          "24:     `fork` will return immediately, so the return value of `func` may not have been computed yet. To force completion",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "87: def wait(future):",
          "88:     r\"\"\"",
          "91:     Args:",
          "92:         future (torch.jit.Future[T]): an asynchronous task reference, created through `torch.jit.fork`",
          "93:     Returns:",
          "",
          "[Removed Lines]",
          "89:     Forces completion of a `torch.jit.Future[T]` asynchronous task, returning the",
          "90:     result of the task. See :func:`~fork` for docs and examples.",
          "",
          "[Added Lines]",
          "90:     Force completion of a `torch.jit.Future[T]` asynchronous task, returning the result of the task.",
          "92:     See :func:`~fork` for docs and examples.",
          "",
          "---------------"
        ],
        "torch/jit/_await.py||torch/jit/_await.py": [
          "File: torch/jit/_await.py -> torch/jit/_await.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "10: def _awaitable(func, *args, **kwargs):",
          "15:     return torch._C._awaitable(func, *args, **kwargs)",
          "18: def _awaitable_wait(aw):",
          "23:     return torch._C._awaitable_wait(aw)",
          "26: def _awaitable_nowait(o):",
          "30:     return torch._C._awaitable_nowait(o)",
          "",
          "[Removed Lines]",
          "11:     r\"\"\"",
          "12:     Creates Await object that will call specified functioni with specified args,",
          "13:     when it is requested for the result.",
          "14:     \"\"\"",
          "19:     r\"\"\"",
          "20:     Requests await the result of execution, if Await is not completed yet,",
          "21:     the func will be called immediately.",
          "22:     \"\"\"",
          "27:     r\"\"\"",
          "28:     Creates completed Await with specified result.",
          "29:     \"\"\"",
          "",
          "[Added Lines]",
          "11:     r\"\"\"Create Await object that will call specified functioni with specified args, when it is requested for the result.\"\"\"",
          "16:     r\"\"\"Request await the result of execution, if Await is not completed yet, the func will be called immediately.\"\"\"",
          "21:     r\"\"\"Create completed Await with specified result.\"\"\"",
          "",
          "---------------"
        ],
        "torch/jit/_check.py||torch/jit/_check.py": [
          "File: torch/jit/_check.py -> torch/jit/_check.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "9: class AttributeTypeIsSupportedChecker(ast.NodeVisitor):",
          "14:     Specifically, we do type inference based on attribute values...even",
          "15:     if the attribute in question has already been typed using",
          "",
          "[Removed Lines]",
          "10:     \"\"\"",
          "11:     Checks the ``__init__`` method of a given ``nn.Module`` to ensure",
          "12:     that all instance-level attributes can be properly initialized.",
          "",
          "[Added Lines]",
          "10:     \"\"\"Check the ``__init__`` method of a given ``nn.Module``.",
          "12:     It ensures that all instance-level attributes can be properly initialized.",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "107:         return True",
          "109:     def visit_Assign(self, node):",
          "111:         If we're visiting a Call Node (the right-hand side of an",
          "112:         assignment statement), we won't be able to check the variable",
          "113:         that we're assigning to (the left-hand side of an assignment).",
          "",
          "[Removed Lines]",
          "110:         \"\"\"",
          "",
          "[Added Lines]",
          "109:         \"\"\"Store assignment state when assigning to a Call Node.",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "129:         self.visiting_class_level_ann = False",
          "131:     def visit_AnnAssign(self, node):",
          "136:         # If we have a local variable",
          "137:         try:",
          "138:             if node.target.value.id != \"self\":",
          "",
          "[Removed Lines]",
          "132:         \"\"\"",
          "133:         Visit an AnnAssign node in an ``nn.Module``'s ``__init__``",
          "134:         method and see if it conforms to our attribute annotation rules.",
          "135:         \"\"\"",
          "",
          "[Added Lines]",
          "132:         \"\"\"Visit an AnnAssign node in an ``nn.Module``'s ``__init__`` method.",
          "134:         It checks if it conforms to our attribute annotation rules.\"\"\"",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "184:         )",
          "186:     def visit_Call(self, node):",
          "188:         Visit a Call node in an ``nn.Module``'s ``__init__``",
          "189:         method and determine if it's ``torch.jit.annotate``. If so,",
          "190:         see if it conforms to our attribute annotation rules.",
          "",
          "[Removed Lines]",
          "187:         \"\"\"",
          "",
          "[Added Lines]",
          "186:         \"\"\"Determine if a Call node is 'torch.jit.annotate' in __init__.",
          "",
          "---------------"
        ],
        "torch/jit/_freeze.py||torch/jit/_freeze.py": [
          "File: torch/jit/_freeze.py -> torch/jit/_freeze.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "3: This is not intended to be imported directly; please use the exposed",
          "4: functionalities in `torch.jit`.",
          "",
          "[Removed Lines]",
          "1: \"\"\"Freezing",
          "",
          "[Added Lines]",
          "1: \"\"\"Freezing.",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "13: def freeze(",
          "14:     mod, preserved_attrs: Optional[List[str]] = None, optimize_numerics: bool = True",
          "15: ):",
          "17:     Freezing a :class:`ScriptModule` will clone it and attempt to inline the cloned",
          "18:     module's submodules, parameters, and attributes as constants in the TorchScript IR Graph.",
          "19:     By default, `forward` will be preserved, as well as attributes & methods specified in",
          "",
          "[Removed Lines]",
          "16:     r\"\"\"",
          "",
          "[Added Lines]",
          "16:     r\"\"\"Freeze ScriptModule, inline submodules, and attributes as constants.",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "125:     mod, optimize_numerics: bool = True, preserved_methods: Optional[List[str]] = None",
          "126: ):",
          "127:     r\"\"\"",
          "129:     The current set of optimizations includes:",
          "130:         - Dropout Removal",
          "131:         - Pretranspose Linear Layers",
          "",
          "[Removed Lines]",
          "128:     Runs a series of optimizations looking for patterns that occur in frozen graphs.",
          "",
          "[Added Lines]",
          "129:     Run a series of optimizations looking for patterns that occur in frozen graphs.",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "180:     mod: ScriptModule, other_methods: Optional[List[str]] = None",
          "181: ) -> ScriptModule:",
          "182:     \"\"\"",
          "185:     will invoke `torch.jit.freeze` automatically.",
          "187:     In addition to generic optimizations that should speed up your model regardless",
          "",
          "[Removed Lines]",
          "183:     Performs a set of optimization passes to optimize a model for the",
          "184:     purposes of inference. If the model is not already frozen, optimize_for_inference",
          "",
          "[Added Lines]",
          "185:     Perform a set of optimization passes to optimize a model for the purposes of inference.",
          "187:     If the model is not already frozen, optimize_for_inference",
          "",
          "---------------"
        ],
        "torch/jit/_fuser.py||torch/jit/_fuser.py": [
          "File: torch/jit/_fuser.py -> torch/jit/_fuser.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "7: @contextlib.contextmanager",
          "8: def optimized_execution(should_optimize):",
          "13:     stored_flag = torch._C._get_graph_executor_optimize()",
          "14:     torch._C._set_graph_executor_optimize(should_optimize)",
          "15:     try:",
          "",
          "[Removed Lines]",
          "9:     \"\"\"",
          "10:     A context manager that controls whether the JIT's executor will run",
          "11:     optimizations before executing a function.",
          "12:     \"\"\"",
          "",
          "[Added Lines]",
          "9:     \"\"\"Context manager that controls whether the JIT's executor will run optimizations before executing a function.\"\"\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "21: @contextlib.contextmanager",
          "22: def fuser(name):",
          "27:     Valid names:",
          "",
          "[Removed Lines]",
          "23:     \"\"\"",
          "24:     A context manager that facilitates switching between",
          "25:     backend fusers.",
          "",
          "[Added Lines]",
          "20:     \"\"\"Context manager that facilitates switching between backend fusers.",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "135: def set_fusion_strategy(strategy: List[Tuple[str, int]]):",
          "139:     Usage: provide a list of pairs (type, depth) where type is one of \"STATIC\" or \"DYNAMIC\"",
          "140:     and depth is an integer.",
          "",
          "[Removed Lines]",
          "136:     \"\"\"",
          "137:     Sets the type and number of specializations that can occur during fusion.",
          "",
          "[Added Lines]",
          "131:     \"\"\"Set the type and number of specializations that can occur during fusion.",
          "",
          "---------------"
        ],
        "torch/jit/_monkeytype_config.py||torch/jit/_monkeytype_config.py": [
          "File: torch/jit/_monkeytype_config.py -> torch/jit/_monkeytype_config.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "39: def get_type(type):",
          "43:     if isinstance(type, str):",
          "44:         return type",
          "45:     elif inspect.getmodule(type) == typing:",
          "",
          "[Removed Lines]",
          "40:     \"\"\"",
          "41:     Helper function which converts the given type to a torchScript acceptable format.",
          "42:     \"\"\"",
          "",
          "[Added Lines]",
          "40:     \"\"\"Convert the given type to a torchScript acceptable format.\"\"\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "61: def get_optional_of_element_type(types):",
          "63:     Helper function to extracts the type of the element to be annotated to Optional",
          "64:     from the list of consolidated types and returns `Optional[element type]`.",
          "65:     TODO: To remove this check once Union support lands.",
          "",
          "[Removed Lines]",
          "62:     \"\"\"",
          "",
          "[Added Lines]",
          "60:     \"\"\"Extract element type, return as `Optional[element type]` from consolidated types.",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "145:             self.s = s",
          "147:         def trace_logger(self) -> JitTypeTraceStoreLogger:",
          "152:             return JitTypeTraceStoreLogger(self.trace_store())",
          "154:         def trace_store(self) -> CallTraceStore:",
          "",
          "[Removed Lines]",
          "148:             \"\"\"",
          "149:             Returns a JitCallTraceStoreLogger that logs to the configured",
          "150:             trace store.",
          "151:             \"\"\"",
          "",
          "[Added Lines]",
          "147:             \"\"\"Return a JitCallTraceStoreLogger that logs to the configured trace store.\"\"\"",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "178: def jit_code_filter(code: CodeType) -> bool:",
          "181:     The custom CodeFilter is required while scripting a FX Traced forward calls.",
          "182:     FX Traced forward calls have `code.co_filename` start with '<' which is used",
          "183:     to exclude tracing of stdlib and site-packages in the default code filter.",
          "",
          "[Removed Lines]",
          "179:     \"\"\"",
          "180:     Custom CodeFilter for Torchscript to trace forward calls.",
          "",
          "[Added Lines]",
          "175:     \"\"\"Codefilter for Torchscript to trace forward calls.",
          "",
          "---------------"
        ],
        "torch/jit/_recursive.py||torch/jit/_recursive.py": [
          "File: torch/jit/_recursive.py -> torch/jit/_recursive.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "185: def infer_concrete_type_builder(nn_module, share_types=True):",
          "186:     \"\"\"",
          "189:     must be filled in by the caller.",
          "190:     \"\"\"",
          "191:     concrete_type_builder = torch._C.ConcreteModuleTypeBuilder(type(nn_module))",
          "",
          "[Removed Lines]",
          "187:     Build a ConcreteModuleTypeBuilder from an nn.Module. This",
          "188:     ConcreteModuleType doesn't have a JIT type associated with it yet, it",
          "",
          "[Added Lines]",
          "187:     Build a ConcreteModuleTypeBuilder from an nn.Module.",
          "189:     This ConcreteModuleType doesn't have a JIT type associated with it yet, it",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "431:         self.methods_compiled = set()",
          "433:     def get_or_create_concrete_type(self, nn_module):",
          "438:         concrete_type_builder = infer_concrete_type_builder(nn_module)",
          "440:         nn_module_type = type(nn_module)",
          "",
          "[Removed Lines]",
          "434:         \"\"\"",
          "435:         Infer a ConcreteType from this `nn.Module` instance. Underlying JIT",
          "436:         types are re-used if possible.",
          "437:         \"\"\"",
          "",
          "[Added Lines]",
          "435:         \"\"\"Infer a ConcreteType from this `nn.Module` instance. Underlying JIT types are re-used if possible.\"\"\"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "484: def get_module_concrete_type(nn_module, share_types=True):",
          "485:     \"\"\"",
          "490:     Args:",
          "491:         nn_module:  The original Python nn.Module that we are creating a ScriptModule for.",
          "",
          "[Removed Lines]",
          "486:     Gets a concrete type for nn_modules. If share_types is True, the concrete",
          "487:     type is fetched from concrete_type_store. If it is False, a new concrete type",
          "488:     is created without first searching concrete_type_store.",
          "",
          "[Added Lines]",
          "484:     Get a concrete type for nn_modules.",
          "486:     If share_types is True, the concrete type is fetched from concrete_type_store.",
          "487:     If it is False, a new concrete type is created without first searching concrete_type_store.",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "538: def create_script_module(nn_module, stubs_fn, share_types=True, is_tracing=False):",
          "539:     \"\"\"",
          "542:     Args:",
          "543:         nn_module:  The original Python nn.Module that we are creating a ScriptModule for.",
          "",
          "[Removed Lines]",
          "540:     Creates a new ScriptModule from an nn.Module",
          "",
          "[Added Lines]",
          "539:     Create a new ScriptModule from an nn.Module.",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "841: def infer_methods_to_compile(nn_module):",
          "845:     \"\"\"",
          "846:     check_module_initialized(nn_module)",
          "847:     user_annotated_ignored_attributes = getattr(",
          "",
          "[Removed Lines]",
          "842:     \"\"\"",
          "843:     Implements the default rules for which methods should act as starting",
          "844:     points for compilation (TODO add a link when the rules are published).",
          "",
          "[Added Lines]",
          "841:     \"\"\"Implement the default rules for which methods should act as starting points for compilation.",
          "843:     (TODO add a link when the rules are published).",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "903: def get_hook_stubs(nn_module):",
          "907:     check_module_initialized(nn_module)",
          "908:     hook_map: Dict = {}",
          "",
          "[Removed Lines]",
          "904:     \"\"\"",
          "905:     Returns forward hook and pre_hook ScriptModuleStubs",
          "906:     \"\"\"",
          "",
          "[Added Lines]",
          "903:     \"\"\"Return forward hook and pre_hook ScriptModuleStubs.\"\"\"",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "939: def get_property_stubs(nn_module):",
          "944:     module_ty = type(nn_module)",
          "945:     properties_asts = get_class_properties(module_ty, self_name=\"RecursiveScriptModule\")",
          "946:     rcbs = {}",
          "",
          "[Removed Lines]",
          "940:     \"\"\"",
          "941:     Create property stubs for the properties of the module by creating method",
          "942:     stubs for the getter and setter.",
          "943:     \"\"\"",
          "",
          "[Added Lines]",
          "937:     \"\"\"Create property stubs for the properties of the module by creating method stubs for the getter and setter.\"\"\"",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "962: def interface_script(mod_interface, nn_module):",
          "963:     \"\"\"",
          "967:     Args:",
          "968:         mod_interface: the interface type that the module have",
          "",
          "[Removed Lines]",
          "964:     Makes a ScriptModule from an nn.Module, using the interface methods rule for",
          "965:     determining which methods to compile.",
          "",
          "[Added Lines]",
          "958:     Make a ScriptModule from an nn.Module, using the interface methods rule for determining which methods to compile.",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "974:     check_module_initialized(nn_module)",
          "976:     def infer_interface_methods_to_compile(nn_module):",
          "980:         \"\"\"",
          "981:         stubs = []",
          "982:         for method in mod_interface.getMethodNames():",
          "",
          "[Removed Lines]",
          "977:         \"\"\"",
          "978:         Rule to infer the methods from the interface type to know which",
          "979:         methods need to act as starting points for compilation.",
          "",
          "[Added Lines]",
          "970:         \"\"\"Rule to infer the methods from the interface type.",
          "972:         It is used to know which methods need to act as starting points for compilation.",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "1013: def wrap_cpp_class(cpp_class):",
          "1017:     return torch.jit.RecursiveScriptClass(cpp_class)",
          "1020: def wrap_cpp_module(cpp_module):",
          "1025:     def init_fn(script_module):",
          "1026:         for name, cpp_module in torch._C.ModuleDict(script_module._c).items():",
          "",
          "[Removed Lines]",
          "1014:     \"\"\"",
          "1015:     Wrap this torch._C.Object in a Python RecursiveScriptClass.",
          "1016:     \"\"\"",
          "1021:     \"\"\"",
          "1022:     Wrap this torch._C.ScriptModule in a Python ScriptModule, recursively for all submodules",
          "1023:     \"\"\"",
          "",
          "[Added Lines]",
          "1007:     \"\"\"Wrap this torch._C.Object in a Python RecursiveScriptClass.\"\"\"",
          "1012:     \"\"\"Wrap this torch._C.ScriptModule in a Python ScriptModule, recursively for all submodules.\"\"\"",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "1051: def lazy_bind(concrete_type, unbound_method):",
          "1052:     \"\"\"",
          "1057:     \"\"\"",
          "1059:     def lazy_binding_method(cpp_module, *args):",
          "",
          "[Removed Lines]",
          "1053:     Returns a function that lazily binds `unbound_method` to a provided",
          "1054:     Module IValue, then invokes the method. We do this so that any Python",
          "1055:     shenanigans that will poison type sharing are impossible at compile",
          "1056:     time.",
          "",
          "[Added Lines]",
          "1042:     Return a function that lazily binds `unbound_method` to a provided Module IValue, then invokes the method.",
          "1044:     We do this so that any Python shenanigans that",
          "1045:     will poison type sharing are impossible at compile time.",
          "",
          "---------------"
        ],
        "torch/jit/_script.py||torch/jit/_script.py": [
          "File: torch/jit/_script.py -> torch/jit/_script.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "3: This module contains functionality to support the JIT's scripting frontend, notably:",
          "4:     - torch.jit.script",
          "",
          "[Removed Lines]",
          "1: \"\"\"TorchScript",
          "",
          "[Added Lines]",
          "1: \"\"\"TorchScript.",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "374:     importer: PackageImporter, script_module_id: str",
          "375: ) -> torch.nn.Module:",
          "376:     \"\"\"",
          "378:     Performs work of loading and returning a ScriptModule from a ``torch.package`` archive.",
          "379:     \"\"\"",
          "380:     if not isinstance(importer.zip_reader, torch._C.PyTorchFileReader):",
          "",
          "[Removed Lines]",
          "377:     Called by ``torch.package.PackageImporter``'s Pickler's ``persistent_load`` function.",
          "",
          "[Added Lines]",
          "377:     Call by ``torch.package.PackageImporter``'s Pickler's ``persistent_load`` function.",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "426:     ]",
          "428:     class RecursiveScriptClass:",
          "430:         An analogue of RecursiveScriptModule for regular objects that are not modules.",
          "431:         This class is a wrapper around a torch._C.ScriptObject that represents an instance",
          "432:         of a TorchScript class and allows it to be used in Python.",
          "",
          "[Removed Lines]",
          "429:         \"\"\"",
          "",
          "[Added Lines]",
          "430:         \"\"\"Wrapper for a TorchScript class instance for use in Python.",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "503:     # which always throws an exception.",
          "505:     class ScriptModule(Module, metaclass=ScriptMeta):",
          "507:         A wrapper around C++ ``torch::jit::Module``. ``ScriptModule``\\s",
          "508:         contain methods, attributes, parameters, and",
          "509:         constants. These can be accessed the same way as on a normal ``nn.Module``.",
          "510:         \"\"\"",
          "511:         __jit_unused_properties__ = [",
          "512:             \"code\",",
          "513:             \"code_with_constants\",",
          "",
          "[Removed Lines]",
          "506:         r\"\"\"",
          "",
          "[Added Lines]",
          "508:         r\"\"\"Wrapper for C++ torch::jit::Module with methods, attributes, and parameters.",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "572:             return self._actual_script_module._replicate_for_data_parallel()",
          "574:         def __reduce_package__(self, exporter: PackageExporter):",
          "576:             Called by ``torch.package.PackageExporter``'s Pickler's ``persistent_id`` when",
          "577:             saving TorchScript objects. Performs act of saving a ScriptModule inside of",
          "578:             a ``torch.package`` archive.",
          "",
          "[Removed Lines]",
          "575:             \"\"\"",
          "",
          "[Added Lines]",
          "579:             \"\"\"Save a ScriptModule inside of a ``torch.package`` archive.",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "588:         # XXX: RecursiveScriptModule inherits from ScriptModule for the sole",
          "589:         # reason that it retains the existing isinstance(ScriptModule)",
          "590:         # behavior.",
          "592:         The core data structure in TorchScript is the ``ScriptModule``. It is an",
          "593:         analogue of torch's ``nn.Module`` and represents an entire model as a tree of",
          "594:         submodules. Like normal modules, each individual module in a ``ScriptModule`` can",
          "",
          "[Removed Lines]",
          "591:         r\"\"\"",
          "",
          "[Added Lines]",
          "596:         r\"\"\"Retain the existing isinstance(ScriptModule) behavior.",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "624:         @staticmethod",
          "625:         def _construct(cpp_module, init_fn):",
          "626:             \"\"\"",
          "629:             of instead of calling `__init__` directly, as it makes sure the",
          "630:             object is properly finalized (and in the future, we may take",
          "631:             control of how the RecursiveScriptModule instance is created).",
          "",
          "[Removed Lines]",
          "627:             Construct a RecursiveScriptModule that's ready for use. PyTorch",
          "628:             code should use this to construct a RecursiveScriptModule instead",
          "",
          "[Added Lines]",
          "634:             Construct a RecursiveScriptModule that's ready for use.",
          "636:             PyTorch code should use this to construct a RecursiveScriptModule instead",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "691:         @property",
          "692:         def graph(self):",
          "696:             \"\"\"",
          "697:             return self._c._get_method(\"forward\").graph",
          "699:         @property",
          "700:         def inlined_graph(self):",
          "701:             r\"\"\"",
          "704:             See :ref:`interpreting-graphs` for details.",
          "705:             \"\"\"",
          "706:             return self.forward.inlined_graph  # type: ignore[attr-defined]",
          "",
          "[Removed Lines]",
          "693:             r\"\"\"",
          "694:             Returns a string representation of the internal graph for the",
          "695:             ``forward`` method. See :ref:`interpreting-graphs` for details.",
          "702:             Returns a string representation of the internal graph for the",
          "703:             ``forward`` method. This graph will be preprocessed to inline all function and method calls.",
          "",
          "[Added Lines]",
          "701:             r\"\"\"Return a string representation of the internal graph for the ``forward`` method.",
          "703:             See :ref:`interpreting-graphs` for details.",
          "710:             Return a string representation of the internal graph for the ``forward`` method.",
          "712:             This graph will be preprocessed to inline all function and method calls.",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "708:         @property",
          "709:         def code(self):",
          "710:             r\"\"\"",
          "714:             \"\"\"",
          "715:             return self.forward.code  # type: ignore[attr-defined]",
          "717:         @property",
          "718:         def code_with_constants(self):",
          "720:             Returns a tuple of:",
          "722:             [0] a pretty-printed representation (as valid Python syntax) of",
          "",
          "[Removed Lines]",
          "711:             Returns a pretty-printed representation (as valid Python syntax) of",
          "712:             the internal graph for the ``forward`` method. See",
          "713:             :ref:`inspecting-code` for details.",
          "719:             r\"\"\"",
          "",
          "[Added Lines]",
          "720:             Return a pretty-printed representation (as valid Python syntax) of the internal graph for the ``forward`` method.",
          "722:             See :ref:`inspecting-code` for details.",
          "728:             r\"\"\"Return a tuple.",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "730:             return (r[0], ConstMap(r[1]))",
          "732:         def save(self, f, **kwargs):",
          "734:             save(f, _extra_files={})",
          "736:             See :func:`torch.jit.save <torch.jit.save>` witch accepts a file-like object.",
          "",
          "[Removed Lines]",
          "733:             r\"\"\"",
          "",
          "[Added Lines]",
          "743:             r\"\"\"Save with a file-like object.",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "740:             return self._c.save(str(f), **kwargs)",
          "742:         def _save_for_lite_interpreter(self, *args, **kwargs):",
          "744:             _save_for_lite_interpreter(f)",
          "747:             in lite interpreter for mobile applications.",
          "749:             Args:",
          "",
          "[Removed Lines]",
          "743:             r\"\"\"",
          "746:             Add (or update) the bytecode session to the script model. The updated model is used",
          "",
          "[Added Lines]",
          "754:             r\"\"\"Add (or update) the bytecode session to the script model.",
          "758:             The updated model is used",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "1072:     _rcb=None,",
          "1073:     example_inputs: Union[List[Tuple], Dict[Callable, List[Tuple]], None] = None,",
          "1074: ):",
          "1076:     Scripting a function or ``nn.Module`` will inspect the source code, compile",
          "1077:     it as TorchScript code using the TorchScript compiler, and return a :class:`ScriptModule` or",
          "1078:     :class:`ScriptFunction`. TorchScript itself is a subset of the Python language, so not all",
          "",
          "[Removed Lines]",
          "1075:     r\"\"\"",
          "",
          "[Added Lines]",
          "1088:     r\"\"\"Script the function.",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "1470: def interface(obj):",
          "1472:     This decorator can be used to define an interface that can be used to annotate",
          "1473:     classes or modules of different types. This can be used for to annotate a submodule",
          "1474:     or attribute class that could have different types that implement the same",
          "",
          "[Removed Lines]",
          "1471:     r\"\"\"",
          "",
          "[Added Lines]",
          "1485:     r\"\"\"Decorate to annotate classes or modules of different types.",
          "",
          "---------------"
        ],
        "torch/jit/_serialization.py||torch/jit/_serialization.py": [
          "File: torch/jit/_serialization.py -> torch/jit/_serialization.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "3: This module contains functionality for serializing TorchScript modules, notably:",
          "",
          "[Removed Lines]",
          "1: \"\"\"Serialization",
          "",
          "[Added Lines]",
          "1: \"\"\"Serialization.",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "18: def save(m, f, _extra_files=None):",
          "19:     r\"\"\"",
          "22:     attributes of this module. It can be loaded into the C++ API using",
          "23:     ``torch::jit::load(filename)`` or into the Python API with",
          "24:     :func:`torch.jit.load <torch.jit.load>`.",
          "",
          "[Removed Lines]",
          "20:     Save an offline version of this module for use in a separate process. The",
          "21:     saved module serializes all of the methods, submodules, parameters, and",
          "",
          "[Added Lines]",
          "20:     Save an offline version of this module for use in a separate process.",
          "22:     The saved module serializes all of the methods, submodules, parameters, and",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "86: def load(f, map_location=None, _extra_files=None, _restore_shapes=False):",
          "87:     r\"\"\"",
          "91:     All previously saved modules, no matter their device, are first loaded onto CPU,",
          "92:     and then are moved to the devices they were saved from. If this fails (e.g.",
          "",
          "[Removed Lines]",
          "88:     Load a :class:`ScriptModule` or :class:`ScriptFunction` previously",
          "89:     saved with :func:`torch.jit.save <torch.jit.save>`",
          "",
          "[Added Lines]",
          "88:     Load a :class:`ScriptModule` or :class:`ScriptFunction` previously saved with :func:`torch.jit.save <torch.jit.save>`.",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "195: def save_jit_module_to_flatbuffer(m, f, _extra_files=None):",
          "196:     r\"\"\"",
          "199:     attributes of this module. It can be loaded into the C++ API using",
          "200:     ``torch::jit::load_jit_module_from_file(filename)`` or into the Python API with",
          "201:     :func:`torch.jit.jit_module_from_flatbuffer<torch.jit.jit_module_from_flatbuffer>`.",
          "",
          "[Removed Lines]",
          "197:     Save an offline version of this module for use in a separate process. The",
          "198:     saved module serializes all of the methods, submodules, parameters, and",
          "",
          "[Added Lines]",
          "194:     Save an offline version of this module for use in a separate process.",
          "196:     The saved module serializes all of the methods, submodules, parameters, and",
          "",
          "---------------"
        ],
        "torch/jit/_state.py||torch/jit/_state.py": [
          "File: torch/jit/_state.py -> torch/jit/_state.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "3: This module stores various pieces of Python-global state relating to the JIT.",
          "",
          "[Removed Lines]",
          "1: \"\"\"JIT-related state",
          "",
          "[Added Lines]",
          "1: \"\"\"JIT-related state.",
          "",
          "---------------"
        ],
        "torch/jit/_trace.py||torch/jit/_trace.py": [
          "File: torch/jit/_trace.py -> torch/jit/_trace.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "3: This module contains functionality to support the JIT's tracing frontend, notably:",
          "",
          "[Removed Lines]",
          "1: \"\"\"Tracing",
          "",
          "[Added Lines]",
          "1: \"\"\"Tracing.",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "199: def verify(model, args, loss_fn=torch.sum, devices=None):",
          "200:     \"\"\"",
          "204:     the backwards will be computed.",
          "206:     This function has side-effects (e.g., it executes your model / saves and loads",
          "",
          "[Removed Lines]",
          "201:     Verify that a JIT compiled model has the same behavior as its uncompiled",
          "202:     version along with its backwards pass.  If your model returns multiple",
          "203:     outputs, you must also specify a `loss_fn` to produce a loss for which",
          "",
          "[Added Lines]",
          "201:     Verify that a JIT compiled model has the same behavior as its uncompiled version along with its backwards pass.",
          "203:     If your model returns multiple outputs,",
          "204:     you must also specify a `loss_fn` to produce a loss for which",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "636:     example_kwarg_inputs=None,",
          "637:     _store_inputs=True,",
          "638: ):",
          "643:     tuples of ``Tensor``\\\\s.",
          "645:     Using `torch.jit.trace` and `torch.jit.trace_module`, you can turn an",
          "",
          "[Removed Lines]",
          "639:     \"\"\"",
          "640:     Trace a function and return an executable  or :class:`ScriptFunction`",
          "641:     that will be optimized using just-in-time compilation. Tracing is ideal for",
          "642:     code that operates only on ``Tensor``\\\\s and lists, dictionaries, and",
          "",
          "[Added Lines]",
          "640:     r\"\"\"",
          "641:     Trace a function and return an executable  or :class:`ScriptFunction` that will be optimized using just-in-time compilation.",
          "643:     Tracing is ideal for code that operates only on",
          "644:     ``Tensor``\\\\s and lists, dictionaries, and",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "929:     _store_inputs=True,",
          "930: ):",
          "931:     \"\"\"",
          "934:     the ``forward`` method is run and traced. With ``trace_module``, you can specify a dictionary of",
          "935:     method names to example inputs to trace (see the ``inputs``) argument below.",
          "",
          "[Removed Lines]",
          "932:     Trace a module and return an executable :class:`ScriptModule` that will be optimized",
          "933:     using just-in-time compilation. When a module is passed to :func:`torch.jit.trace <torch.jit.trace>`, only",
          "",
          "[Added Lines]",
          "934:     Trace a module and return an executable :class:`ScriptModule` that will be optimized using just-in-time compilation.",
          "936:     When a module is passed to :func:`torch.jit.trace <torch.jit.trace>`, only",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "1116: def is_tracing():",
          "1120:     \"\"\"",
          "1121:     if is_scripting():",
          "1122:         return False",
          "",
          "[Removed Lines]",
          "1117:     \"\"\"",
          "1118:     Returns ``True`` in tracing (if a function is called during the tracing of",
          "1119:     code with ``torch.jit.trace``) and ``False`` otherwise.",
          "",
          "[Added Lines]",
          "1120:     \"\"\"Return a boolean value.",
          "1122:     Returns ``True`` in tracing (if a function is called during the",
          "1123:     tracing of code with ``torch.jit.trace``) and ``False`` otherwise.",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "1253:     return_inputs=False,",
          "1254:     _return_inputs_states=False,",
          "1255: ):",
          "1257:     .. warning::",
          "1258:         This function is internal-only and should only be used by the ONNX",
          "1259:         exporter. If you are trying to get a graph through tracing, please go",
          "",
          "[Removed Lines]",
          "1256:     \"\"\"",
          "",
          "[Added Lines]",
          "1260:     \"\"\"Return a tuple on tracing a function or model.",
          "",
          "---------------"
        ],
        "torch/jit/annotations.py||torch/jit/annotations.py": [
          "File: torch/jit/annotations.py -> torch/jit/annotations.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "200: def _eval_no_call(stmt, glob, loc):",
          "202:     bytecode = compile(stmt, \"\", mode=\"eval\")",
          "203:     for insn in dis.get_instructions(bytecode):",
          "204:         if \"CALL\" in insn.opname:",
          "",
          "[Removed Lines]",
          "201:     \"\"\"Evaluate statement as long as it does not contain any method/function calls\"\"\"",
          "",
          "[Added Lines]",
          "201:     \"\"\"Evaluate statement as long as it does not contain any method/function calls.\"\"\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "211: def parse_type_line(type_line, rcb, loc):",
          "214:     Example inputs:",
          "215:         # type: (Tensor, torch.Tensor) -> Tuple[Tensor]",
          "",
          "[Removed Lines]",
          "212:     \"\"\"Parses a type annotation specified as a comment.",
          "",
          "[Added Lines]",
          "212:     \"\"\"Parse a type annotation specified as a comment.",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "241: def get_type_line(source):",
          "243:     type_comment = \"# type:\"",
          "245:     lines = source.split(\"\\n\")",
          "",
          "[Removed Lines]",
          "242:     \"\"\"Tries to find the line containing a comment with the type annotation.\"\"\"",
          "",
          "[Added Lines]",
          "242:     \"\"\"Try to find the line containing a comment with the type annotation.\"\"\"",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "308: def split_type_line(type_line):",
          "311:     For example, for an input of:",
          "312:         # type: (Tensor, torch.Tensor) -> Tuple[Tensor, Tensor]",
          "",
          "[Removed Lines]",
          "309:     \"\"\"Splits the comment with the type annotation into parts for argument and return types.",
          "",
          "[Added Lines]",
          "309:     \"\"\"Split the comment with the type annotation into parts for argument and return types.",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "328: def try_real_annotations(fn, loc):",
          "330:     try:",
          "331:         # Note: anything annotated as `Optional[T]` will automatically",
          "332:         # be returned as `Union[T, None]` per",
          "",
          "[Removed Lines]",
          "329:     \"\"\"Tries to use the Py3.5+ annotation syntax to get the type.\"\"\"",
          "",
          "[Added Lines]",
          "329:     \"\"\"Try to use the Py3.5+ annotation syntax to get the type.\"\"\"",
          "",
          "---------------"
        ],
        "torch/jit/mobile/__init__.py||torch/jit/mobile/__init__.py": [
          "File: torch/jit/mobile/__init__.py -> torch/jit/mobile/__init__.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "10: def _load_for_lite_interpreter(f, map_location=None):",
          "11:     r\"\"\"",
          "15:     Args:",
          "16:         f: a file-like object (has to implement read, readline, tell, and seek),",
          "",
          "[Removed Lines]",
          "12:     Load a :class:`LiteScriptModule`",
          "13:     saved with :func:`torch.jit._save_for_lite_interpreter`",
          "",
          "[Added Lines]",
          "12:     Load a :class:`LiteScriptModule` saved with :func:`torch.jit._save_for_lite_interpreter`.",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "77: def _export_operator_list(module: LiteScriptModule):",
          "82:     return torch._C._export_operator_list(module._c)",
          "85: def _get_model_bytecode_version(f_input) -> int:",
          "87:     Args:",
          "88:         f_input: a file-like object (has to implement read, readline, tell, and seek),",
          "89:             or a string containing a file name",
          "",
          "[Removed Lines]",
          "78:     r\"\"\"",
          "79:     return a set of root operator names (with overload name) that are used by any method",
          "80:     in this mobile module.",
          "81:     \"\"\"",
          "86:     r\"\"\"",
          "",
          "[Added Lines]",
          "77:     r\"\"\"Return a set of root operator names (with overload name) that are used by any method in this mobile module.\"\"\"",
          "82:     r\"\"\"Take a file-like object to return an integer.",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "117: def _get_mobile_model_contained_types(f_input) -> int:",
          "119:     Args:",
          "120:         f_input: a file-like object (has to implement read, readline, tell, and seek),",
          "121:             or a string containing a file name",
          "",
          "[Removed Lines]",
          "118:     r\"\"\"",
          "",
          "[Added Lines]",
          "114:     r\"\"\"Take a file-like object and return a set of string, like (\"int\", \"Optional\").",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "148: def _backport_for_mobile(f_input, f_output, to_version):",
          "150:     Args:",
          "151:         f_input: a file-like object (has to implement read, readline, tell, and seek),",
          "152:             or a string containing a file name",
          "",
          "[Removed Lines]",
          "149:     r\"\"\"",
          "",
          "[Added Lines]",
          "146:     r\"\"\"Take a input string containing a file name (file-like object) and a new destination to return a boolean.",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "174: def _backport_for_mobile_to_buffer(f_input, to_version):",
          "176:     Args:",
          "177:         f_input: a file-like object (has to implement read, readline, tell, and seek),",
          "178:             or a string containing a file name",
          "",
          "[Removed Lines]",
          "175:     r\"\"\"",
          "",
          "[Added Lines]",
          "173:     r\"\"\"Take a string containing a file name (file-like object).",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "195: def _get_model_ops_and_info(f_input):",
          "199:     a root op can call many different traced ops depending on internal code paths in the root op.",
          "200:     These traced ops are not returned by this function. Those operators are abstracted into the",
          "201:     runtime as an implementation detail (and the traced ops themselves can also call other operators)",
          "",
          "[Removed Lines]",
          "196:     r\"\"\"",
          "197:     A function to retrieve the root (top level) operators of a model and their corresponding",
          "198:     compatibility info. These root operators can call other operators within them (traced ops), and",
          "",
          "[Added Lines]",
          "195:     r\"\"\"Retrieve the root (top level) operators of a model and their corresponding compatibility info.",
          "197:     These root operators can call other operators within them (traced ops), and",
          "",
          "---------------"
        ],
        "torch/sparse/__init__.py||torch/sparse/__init__.py": [
          "File: torch/sparse/__init__.py -> torch/sparse/__init__.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "181: def sum(input: Tensor, dim: DimOrDims = None,",
          "182:         dtype: Optional[DType] = None) -> Tensor:",
          "184:     Returns the sum of each row of the sparse tensor :attr:`input` in the given",
          "185:     dimensions :attr:`dim`. If :attr:`dim` is a list of dimensions,",
          "186:     reduce over all of them. When sum over all ``sparse_dim``, this method",
          "",
          "[Removed Lines]",
          "183:     r\"\"\"",
          "",
          "[Added Lines]",
          "183:     r\"\"\"Return the sum of each row of the given sparse tensor.",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "390: class check_sparse_tensor_invariants:",
          "391:     \"\"\"A tool to control checking sparse tensor invariants.",
          "432:     \"\"\"",
          "434:     @staticmethod",
          "435:     def is_enabled():",
          "443:         \"\"\"",
          "444:         return torch._C._check_sparse_tensor_invariants()",
          "",
          "[Removed Lines]",
          "393: The following options exists to manage sparsr tensor invariants",
          "394: checking in sparse tensor construction:",
          "396: 1. Using a context manager:",
          "398:    .. code:: python",
          "400:        with torch.sparse.check_sparse_tensor_invariants():",
          "401:            run_my_model()",
          "403: 2. Using a procedural approach:",
          "405:    .. code:: python",
          "407:        prev_checks_enabled = torch.sparse.check_sparse_tensor_invariants.is_enabled()",
          "408:        torch.sparse.check_sparse_tensor_invariants.enable()",
          "410:        run_my_model()",
          "412:        if not prev_checks_enabled:",
          "413:            torch.sparse.check_sparse_tensor_invariants.disable()",
          "415: 3. Using function decoration:",
          "417:    .. code:: python",
          "419:        @torch.sparse.check_sparse_tensor_invariants()",
          "420:        def run_my_model():",
          "421:            ...",
          "423:        run_my_model()",
          "425: 4. Using ``check_invariants`` keyword argument in sparse tensor constructor call.",
          "426:    For example:",
          "428:    >>> torch.sparse_csr_tensor([0, 1, 3], [0, 1], [1, 2], check_invariants=True)",
          "429:    Traceback (most recent call last):",
          "430:      File \"<stdin>\", line 1, in <module>",
          "431:    RuntimeError: `crow_indices[..., -1] == nnz` is not satisfied.",
          "436:         r\"\"\"Returns True if the sparse tensor invariants checking is enabled.",
          "438: .. note::",
          "440:     Use :func:`torch.sparse.check_sparse_tensor_invariants.enable` or",
          "441:     :func:`torch.sparse.check_sparse_tensor_invariants.disable` to",
          "442:     manage the state of the sparse tensor invariants checks.",
          "",
          "[Added Lines]",
          "394:     The following options exists to manage sparsr tensor invariants",
          "395:     checking in sparse tensor construction:",
          "397:     1. Using a context manager:",
          "399:        .. code:: python",
          "401:            with torch.sparse.check_sparse_tensor_invariants():",
          "402:                run_my_model()",
          "404:     2. Using a procedural approach:",
          "406:        .. code:: python",
          "408:            prev_checks_enabled = torch.sparse.check_sparse_tensor_invariants.is_enabled()",
          "409:            torch.sparse.check_sparse_tensor_invariants.enable()",
          "411:            run_my_model()",
          "413:            if not prev_checks_enabled:",
          "414:                torch.sparse.check_sparse_tensor_invariants.disable()",
          "416:     3. Using function decoration:",
          "418:        .. code:: python",
          "420:            @torch.sparse.check_sparse_tensor_invariants()",
          "421:            def run_my_model():",
          "422:                ...",
          "424:            run_my_model()",
          "426:     4. Using ``check_invariants`` keyword argument in sparse tensor constructor call.",
          "427:        For example:",
          "429:        >>> torch.sparse_csr_tensor([0, 1, 3], [0, 1], [1, 2], check_invariants=True)",
          "430:        Traceback (most recent call last):",
          "431:          File \"<stdin>\", line 1, in <module>",
          "432:        RuntimeError: `crow_indices[..., -1] == nnz` is not satisfied.",
          "437:         r\"\"\"Return True if the sparse tensor invariants checking is enabled.",
          "439:         .. note::",
          "441:             Use :func:`torch.sparse.check_sparse_tensor_invariants.enable` or",
          "442:             :func:`torch.sparse.check_sparse_tensor_invariants.disable` to",
          "443:             manage the state of the sparse tensor invariants checks.",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "447:     def enable():",
          "448:         r\"\"\"Enable sparse tensor invariants checking in sparse tensor constructors.",
          "463:         \"\"\"",
          "464:         torch._C._set_check_sparse_tensor_invariants(True)",
          "",
          "[Removed Lines]",
          "450: .. note::",
          "452:     By default, the sparse tensor invariants checks are disabled. Use",
          "453:     :func:`torch.sparse.check_sparse_tensor_invariants.is_enabled` to",
          "454:     retrieve the current state of sparse tensor invariants checking.",
          "456: .. note::",
          "458:     The sparse tensor invariants check flag is effective to all sparse",
          "459:     tensor constructors, both in Python and ATen.",
          "461:     The flag can be locally overridden by the ``check_invariants``",
          "462:     optional argument of the sparse tensor constructor functions.",
          "",
          "[Added Lines]",
          "451:         .. note::",
          "453:             By default, the sparse tensor invariants checks are disabled. Use",
          "454:             :func:`torch.sparse.check_sparse_tensor_invariants.is_enabled` to",
          "455:             retrieve the current state of sparse tensor invariants checking.",
          "457:         .. note::",
          "459:             The sparse tensor invariants check flag is effective to all sparse",
          "460:             tensor constructors, both in Python and ATen.",
          "462:         The flag can be locally overridden by the ``check_invariants``",
          "463:         optional argument of the sparse tensor constructor functions.",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "467:     def disable():",
          "468:         r\"\"\"Disable sparse tensor invariants checking in sparse tensor constructors.",
          "471:         \"\"\"",
          "472:         torch._C._set_check_sparse_tensor_invariants(False)",
          "",
          "[Removed Lines]",
          "470: See :func:`torch.sparse.check_sparse_tensor_invariants.enable` for more information.",
          "",
          "[Added Lines]",
          "471:         See :func:`torch.sparse.check_sparse_tensor_invariants.enable` for more information.",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "501: def as_sparse_gradcheck(gradcheck):",
          "503:     variants that extends the gradcheck function with support to input",
          "504:     functions that operate on or/and return sparse tensors.",
          "",
          "[Removed Lines]",
          "502:     \"\"\"Decorator for torch.autograd.gradcheck or its functools.partial",
          "",
          "[Added Lines]",
          "503:     \"\"\"Decorate function, to extend gradcheck for sparse tensors.",
          "505:     Decorator for torch.autograd.gradcheck or its functools.partial",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "515:     \"\"\"",
          "517:     def gradcheck_with_sparse_support(func, inputs, **kwargs):",
          "520:         \"\"\"",
          "521:         masked = kwargs.pop('masked', False)",
          "522:         sparse_layouts = {torch.sparse_coo, torch.sparse_csr, torch.sparse_csc, torch.sparse_bsr, torch.sparse_bsc}",
          "",
          "[Removed Lines]",
          "518:         \"\"\"Same as :func:`torch.autograd.gradcheck` but with sparse tensors",
          "519:         inputs and outputs support.",
          "",
          "[Added Lines]",
          "521:         \"\"\"",
          "522:         Create gradcheck with support for sparse tensors.",
          "524:         Same as :func:`torch.autograd.gradcheck` but with sparse tensors inputs and outputs support.",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "525:         STRIDED_REPRESENTATION = '__STRIDED_REPRESENTATION__'",
          "527:         def convert_to_strided_representation(args):",
          "531:             if not isinstance(args, (list, tuple)):",
          "532:                 args = args,",
          "533:             new_args: List[Any] = []",
          "",
          "[Removed Lines]",
          "528:             \"\"\"Convert differentiable non-strided tensors to a representation",
          "529:             containing differentiable strided tensors.",
          "530:             \"\"\"",
          "",
          "[Added Lines]",
          "533:             \"\"\"Convert differentiable non-strided tensors to a representation containing differentiable strided tensors.\"\"\"",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "556:             return tuple(new_args)",
          "558:         def restore_from_strided_representation(args):",
          "562:             new_args = []",
          "563:             args = list(args)",
          "564:             while args:",
          "",
          "[Removed Lines]",
          "559:             \"\"\"Restore non-strided differentiable tensosr from their strided",
          "560:             representations.",
          "561:             \"\"\"",
          "",
          "[Added Lines]",
          "562:             \"\"\"Restore non-strided differentiable tensosr from their strided representations.\"\"\"",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "74a9ca993bd79f8131829e9c946657fa9a1d05ef",
      "candidate_info": {
        "commit_hash": "74a9ca993bd79f8131829e9c946657fa9a1d05ef",
        "repo": "pytorch/pytorch",
        "commit_url": "https://github.com/pytorch/pytorch/commit/74a9ca993bd79f8131829e9c946657fa9a1d05ef",
        "files": [
          "test/test_jit.py",
          "torch/csrc/jit/frontend/script_type_parser.cpp",
          "torch/jit/annotations.py"
        ],
        "message": "[JIT][Security] Do not blindly eval input string (#89189) (#89925)\n\nIntroduce `_eval_no_call` method, that evaluates statement only if it\ndoes not contain any calls(done by examining the bytecode), thus preventing command injection exploit\n\nAdded simple unit test to check for that\n`torch.jit.annotations.get_signature` would not result in calling random\ncode.\n\nAlthough, this code path exists for Python-2 compatibility, and perhaps\nshould be simply removed.\n\nFixes https://github.com/pytorch/pytorch/issues/88868\n\nPull Request resolved: https://github.com/pytorch/pytorch/pull/89189\nApproved by: https://github.com/suo\n\nCo-authored-by: Nikita Shulga <nshulga@meta.com>",
        "before_after_code_files": [
          "test/test_jit.py||test/test_jit.py",
          "torch/csrc/jit/frontend/script_type_parser.cpp||torch/csrc/jit/frontend/script_type_parser.cpp",
          "torch/jit/annotations.py||torch/jit/annotations.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_olp_changes": 1,
        "olp_code_files": {
          "patch": [
            "test/test_jit.py||test/test_jit.py",
            "torch/csrc/jit/frontend/script_type_parser.cpp||torch/csrc/jit/frontend/script_type_parser.cpp",
            "torch/jit/annotations.py||torch/jit/annotations.py"
          ],
          "candidate": [
            "test/test_jit.py||test/test_jit.py",
            "torch/csrc/jit/frontend/script_type_parser.cpp||torch/csrc/jit/frontend/script_type_parser.cpp",
            "torch/jit/annotations.py||torch/jit/annotations.py"
          ]
        }
      },
      "candidate_diff": {
        "test/test_jit.py||test/test_jit.py": [
          "File: test/test_jit.py -> test/test_jit.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "3912:                 return a + 2",
          "3913:             torch.jit.script(invalid4)",
          "3915:     def test_is_optional(self):",
          "3916:         ann = Union[List[int], List[float]]",
          "3917:         torch._jit_internal.is_optional(ann)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "3915:     def test_calls_in_type_annotations(self):",
          "3916:         with self.assertRaisesRegex(RuntimeError, \"Type annotation should not contain calls\"):",
          "3917:             def spooky(a):",
          "3918:                 # type: print(\"Hello\") -> Tensor # noqa: F723",
          "3919:                 return a + 2",
          "3920:             print(torch.__file__)",
          "3921:             torch.jit.annotations.get_signature(spooky, None, 1, True)",
          "",
          "---------------"
        ],
        "torch/csrc/jit/frontend/script_type_parser.cpp||torch/csrc/jit/frontend/script_type_parser.cpp": [
          "File: torch/csrc/jit/frontend/script_type_parser.cpp -> torch/csrc/jit/frontend/script_type_parser.cpp"
        ],
        "torch/jit/annotations.py||torch/jit/annotations.py": [
          "File: torch/jit/annotations.py -> torch/jit/annotations.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1: import ast",
          "2: import enum",
          "3: import inspect",
          "4: import re",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "2: import dis",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "144:         raise torch.jit.frontend.FrontendError(loc, \"Expected a single top-level function\")",
          "147: def parse_type_line(type_line, rcb, loc):",
          "148:     \"\"\"Parses a type annotation specified as a comment.",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "148: def _eval_no_call(stmt, glob, loc):",
          "149:     \"\"\"Evaluate statement as long as it does not contain any method/function calls\"\"\"",
          "150:     bytecode = compile(stmt, \"\", mode=\"eval\")",
          "151:     for insn in dis.get_instructions(bytecode):",
          "152:         if \"CALL\" in insn.opname:",
          "153:             raise RuntimeError(f\"Type annotation should not contain calls, but '{stmt}' does\")",
          "154:     return eval(bytecode, glob, loc)  # type: ignore[arg-type] # noqa: P204",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "154:     arg_ann_str, ret_ann_str = split_type_line(type_line)",
          "156:     try:",
          "158:     except (NameError, SyntaxError) as e:",
          "159:         raise RuntimeError(\"Failed to parse the argument list of a type annotation\") from e",
          "",
          "[Removed Lines]",
          "157:         arg_ann = eval(arg_ann_str, {}, EvalEnv(rcb))  # type: ignore[arg-type] # noqa: P204",
          "",
          "[Added Lines]",
          "167:         arg_ann = _eval_no_call(arg_ann_str, {}, EvalEnv(rcb))",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "162:         arg_ann = (arg_ann,)",
          "164:     try:",
          "166:     except (NameError, SyntaxError) as e:",
          "167:         raise RuntimeError(\"Failed to parse the return type of a type annotation\") from e",
          "",
          "[Removed Lines]",
          "165:         ret_ann = eval(ret_ann_str, {}, EvalEnv(rcb))  # type: ignore[arg-type] # noqa: P204",
          "",
          "[Added Lines]",
          "175:         ret_ann = _eval_no_call(ret_ann_str, {}, EvalEnv(rcb))",
          "",
          "---------------"
        ]
      }
    }
  ]
}