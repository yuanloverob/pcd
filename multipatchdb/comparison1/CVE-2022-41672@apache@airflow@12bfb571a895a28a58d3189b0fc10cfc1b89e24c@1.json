{
  "cve_id": "CVE-2022-41672",
  "cve_desc": "In Apache Airflow, prior to version 2.4.1, deactivating a user wouldn't prevent an already authenticated user from being able to continue using the UI or API.",
  "repo": "apache/airflow",
  "patch_hash": "12bfb571a895a28a58d3189b0fc10cfc1b89e24c",
  "patch_info": {
    "commit_hash": "12bfb571a895a28a58d3189b0fc10cfc1b89e24c",
    "repo": "apache/airflow",
    "commit_url": "https://github.com/apache/airflow/commit/12bfb571a895a28a58d3189b0fc10cfc1b89e24c",
    "files": [
      "airflow/www/app.py",
      "airflow/www/extensions/init_security.py",
      "tests/test_utils/decorators.py",
      "tests/www/views/conftest.py",
      "tests/www/views/test_session.py",
      "tests/www/views/test_views_base.py"
    ],
    "message": "Check user is active (#26635)\n\n(cherry picked from commit 59707cdf7eacb698ca375b5220af30a39ca1018c)",
    "before_after_code_files": [
      "airflow/www/app.py||airflow/www/app.py",
      "airflow/www/extensions/init_security.py||airflow/www/extensions/init_security.py",
      "tests/test_utils/decorators.py||tests/test_utils/decorators.py",
      "tests/www/views/conftest.py||tests/www/views/conftest.py",
      "tests/www/views/test_session.py||tests/www/views/test_session.py",
      "tests/www/views/test_views_base.py||tests/www/views/test_views_base.py"
    ]
  },
  "patch_diff": {
    "airflow/www/app.py||airflow/www/app.py": [
      "File: airflow/www/app.py -> airflow/www/app.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "39: from airflow.www.extensions.init_jinja_globals import init_jinja_globals",
      "40: from airflow.www.extensions.init_manifest_files import configure_manifest_files",
      "41: from airflow.www.extensions.init_robots import init_robots",
      "43: from airflow.www.extensions.init_session import init_airflow_session_interface",
      "44: from airflow.www.extensions.init_views import (",
      "45:     init_api_connexion,",
      "",
      "[Removed Lines]",
      "42: from airflow.www.extensions.init_security import init_api_experimental_auth, init_xframe_protection",
      "",
      "[Added Lines]",
      "42: from airflow.www.extensions.init_security import (",
      "43:     init_api_experimental_auth,",
      "44:     init_check_user_active,",
      "45:     init_xframe_protection,",
      "46: )",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "152:         init_jinja_globals(flask_app)",
      "153:         init_xframe_protection(flask_app)",
      "154:         init_airflow_session_interface(flask_app)",
      "155:     return flask_app",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "159:         init_check_user_active(flask_app)",
      "",
      "---------------"
    ],
    "airflow/www/extensions/init_security.py||airflow/www/extensions/init_security.py": [
      "File: airflow/www/extensions/init_security.py -> airflow/www/extensions/init_security.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "19: import logging",
      "20: from importlib import import_module",
      "22: from airflow.configuration import conf",
      "23: from airflow.exceptions import AirflowConfigException, AirflowException",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "22: from flask import g, redirect, url_for",
      "23: from flask_login import logout_user",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "60:         except ImportError as err:",
      "61:             log.critical(\"Cannot import %s for API authentication due to: %s\", backend, err)",
      "62:             raise AirflowException(err)",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "68: def init_check_user_active(app):",
      "69:     @app.before_request",
      "70:     def check_user_active():",
      "71:         if g.user is not None and not g.user.is_anonymous and not g.user.is_active:",
      "72:             logout_user()",
      "73:             return redirect(url_for(app.appbuilder.sm.auth_view.endpoint + \".login\"))",
      "",
      "---------------"
    ],
    "tests/test_utils/decorators.py||tests/test_utils/decorators.py": [
      "File: tests/test_utils/decorators.py -> tests/test_utils/decorators.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "45:             \"init_xframe_protection\",",
      "46:             \"init_airflow_session_interface\",",
      "47:             \"init_appbuilder\",",
      "48:         ]",
      "50:         @functools.wraps(f)",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "48:             \"init_check_user_active\",",
      "",
      "---------------"
    ],
    "tests/www/views/conftest.py||tests/www/views/conftest.py": [
      "File: tests/www/views/conftest.py -> tests/www/views/conftest.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "58:             \"init_jinja_globals\",",
      "59:             \"init_plugins\",",
      "60:             \"init_airflow_session_interface\",",
      "61:         ]",
      "62:     )",
      "63:     def factory():",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "61:             \"init_check_user_active\",",
      "",
      "---------------"
    ],
    "tests/www/views/test_session.py||tests/www/views/test_session.py": [
      "File: tests/www/views/test_session.py -> tests/www/views/test_session.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "88:     new_session_cookie = get_session_cookie(user_client)",
      "89:     assert new_session_cookie is not None",
      "90:     assert old_session_cookie.value != new_session_cookie.value",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "93: def test_check_active_user(app, user_client):",
      "94:     user = app.appbuilder.sm.find_user(username=\"test_user\")",
      "95:     user.active = False",
      "96:     resp = user_client.get(\"/home\")",
      "97:     assert resp.status_code == 302",
      "98:     assert \"/login\" in resp.headers.get(\"Location\")",
      "100:     # And they were logged out",
      "101:     user.active = True",
      "102:     resp = user_client.get(\"/home\")",
      "103:     assert resp.status_code == 302",
      "104:     assert \"/login\" in resp.headers.get(\"Location\")",
      "",
      "---------------"
    ],
    "tests/www/views/test_views_base.py||tests/www/views/test_views_base.py": [
      "File: tests/www/views/test_views_base.py -> tests/www/views/test_views_base.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "30: from tests.test_utils.www import check_content_in_response, check_content_not_in_response",
      "34:     with assert_queries_count(16):",
      "36:     check_content_in_response('DAGs', resp)",
      "",
      "[Removed Lines]",
      "33: def test_index(admin_client):",
      "35:         resp = admin_client.get('/', follow_redirects=True)",
      "",
      "[Added Lines]",
      "33: def test_index_redirect(admin_client):",
      "34:     resp = admin_client.get('/')",
      "35:     assert resp.status_code == 302",
      "36:     assert '/home' in resp.headers.get(\"Location\")",
      "38:     resp = admin_client.get('/', follow_redirects=True)",
      "39:     check_content_in_response('DAGs', resp)",
      "42: def test_homepage_query_count(admin_client):",
      "44:         resp = admin_client.get('/home')",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "6c90cea1ab63b925d58cf4949d94ec0e3b37830e",
      "candidate_info": {
        "commit_hash": "6c90cea1ab63b925d58cf4949d94ec0e3b37830e",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/6c90cea1ab63b925d58cf4949d94ec0e3b37830e",
        "files": [
          "airflow/ti_deps/deps/trigger_rule_dep.py",
          "tests/models/test_dagrun.py",
          "tests/models/test_taskinstance.py",
          "tests/ti_deps/deps/test_trigger_rule_dep.py"
        ],
        "message": "Fix deadlock when mapped task with removed upstream is rerun (#26518)\n\nWhen a dag with a mapped downstream tasks that depends on a mapped upstream tasks that have some mapped indexes\nremoved is rerun, we run into a deadlock because the trigger rules evaluation is not accounting for removed\ntask instances.\n\nThe fix for the deadlocks was to account for the removed task instances where possible in the trigger rules\n\nIn this fix, I added a case where if we set flag_upstream_failed, then for the removed task instance, the downstream of that task instance will be removed. That's if the upstream with index 3 is removed, then downstream\nwith index 3 will also be removed if flag_upstream_failed is set to True.\n\n(cherry picked from commit e91637f8894cac19c6b467b6669cbcc13184be70)",
        "before_after_code_files": [
          "airflow/ti_deps/deps/trigger_rule_dep.py||airflow/ti_deps/deps/trigger_rule_dep.py",
          "tests/models/test_dagrun.py||tests/models/test_dagrun.py",
          "tests/models/test_taskinstance.py||tests/models/test_taskinstance.py",
          "tests/ti_deps/deps/test_trigger_rule_dep.py||tests/ti_deps/deps/test_trigger_rule_dep.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/26688"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/ti_deps/deps/trigger_rule_dep.py||airflow/ti_deps/deps/trigger_rule_dep.py": [
          "File: airflow/ti_deps/deps/trigger_rule_dep.py -> airflow/ti_deps/deps/trigger_rule_dep.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "59:             counter.get(State.SKIPPED, 0),",
          "60:             counter.get(State.FAILED, 0),",
          "61:             counter.get(State.UPSTREAM_FAILED, 0),",
          "62:             sum(counter.values()),",
          "63:         )",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "62:             counter.get(State.REMOVED, 0),",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "73:             yield self._passing_status(reason=\"The task had a always trigger rule set.\")",
          "74:             return",
          "75:         # see if the task name is in the task upstream for our task",
          "77:             task=ti.task, finished_tis=dep_context.ensure_finished_tis(ti.get_dagrun(session), session)",
          "78:         )",
          "",
          "[Removed Lines]",
          "76:         successes, skipped, failed, upstream_failed, done = self._get_states_count_upstream_ti(",
          "",
          "[Added Lines]",
          "77:         successes, skipped, failed, upstream_failed, removed, done = self._get_states_count_upstream_ti(",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "83:             skipped=skipped,",
          "84:             failed=failed,",
          "85:             upstream_failed=upstream_failed,",
          "86:             done=done,",
          "87:             flag_upstream_failed=dep_context.flag_upstream_failed,",
          "88:             dep_context=dep_context,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "87:             removed=removed,",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "122:         skipped,",
          "123:         failed,",
          "124:         upstream_failed,",
          "125:         done,",
          "126:         flag_upstream_failed,",
          "127:         dep_context: DepContext,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "127:         removed,",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "152:             \"successes\": successes,",
          "153:             \"skipped\": skipped,",
          "154:             \"failed\": failed,",
          "155:             \"upstream_failed\": upstream_failed,",
          "156:             \"done\": done,",
          "157:         }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "158:             \"removed\": removed,",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "162:                     changed = ti.set_state(State.UPSTREAM_FAILED, session)",
          "163:                 elif skipped:",
          "164:                     changed = ti.set_state(State.SKIPPED, session)",
          "165:             elif trigger_rule == TR.ALL_FAILED:",
          "166:                 if successes or skipped:",
          "167:                     changed = ti.set_state(State.SKIPPED, session)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "169:                 elif removed and successes and ti.map_index > -1:",
          "170:                     if ti.map_index >= successes:",
          "171:                         changed = ti.set_state(State.REMOVED, session)",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "212:                 )",
          "213:         elif trigger_rule == TR.ALL_SUCCESS:",
          "214:             num_failures = upstream - successes",
          "215:             if num_failures > 0:",
          "216:                 yield self._failing_status(",
          "217:                     reason=(",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "223:             if ti.map_index > -1:",
          "224:                 num_failures -= removed",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "223:                 )",
          "224:         elif trigger_rule == TR.ALL_FAILED:",
          "225:             num_successes = upstream - failed - upstream_failed",
          "226:             if num_successes > 0:",
          "227:                 yield self._failing_status(",
          "228:                     reason=(",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "236:             if ti.map_index > -1:",
          "237:                 num_successes -= removed",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "244:                 )",
          "245:         elif trigger_rule == TR.NONE_FAILED:",
          "246:             num_failures = upstream - successes - skipped",
          "247:             if num_failures > 0:",
          "248:                 yield self._failing_status(",
          "249:                     reason=(",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "259:             if ti.map_index > -1:",
          "260:                 num_failures -= removed",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "255:                 )",
          "256:         elif trigger_rule == TR.NONE_FAILED_MIN_ONE_SUCCESS:",
          "257:             num_failures = upstream - successes - skipped",
          "258:             if num_failures > 0:",
          "259:                 yield self._failing_status(",
          "260:                     reason=(",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "272:             if ti.map_index > -1:",
          "273:                 num_failures -= removed",
          "",
          "---------------"
        ],
        "tests/models/test_dagrun.py||tests/models/test_dagrun.py": [
          "File: tests/models/test_dagrun.py -> tests/models/test_dagrun.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1905:     dr.update_state(session=session)",
          "1906:     assert dr.state == DagRunState.SUCCESS",
          "1907:     assert tis['add_one__1'].state == TaskInstanceState.SKIPPED",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1910: def test_schedulable_task_exist_when_rerun_removed_upstream_mapped_task(session, dag_maker):",
          "1911:     from airflow.decorators import task",
          "1913:     @task",
          "1914:     def do_something(i):",
          "1915:         return 1",
          "1917:     @task",
          "1918:     def do_something_else(i):",
          "1919:         return 1",
          "1921:     with dag_maker():",
          "1922:         nums = do_something.expand(i=[i + 1 for i in range(5)])",
          "1923:         do_something_else.expand(i=nums)",
          "1925:     dr = dag_maker.create_dagrun()",
          "1927:     ti = dr.get_task_instance('do_something_else', session=session)",
          "1928:     ti.map_index = 0",
          "1929:     task = ti.task",
          "1930:     for map_index in range(1, 5):",
          "1931:         ti = TI(task, run_id=dr.run_id, map_index=map_index)",
          "1932:         ti.dag_run = dr",
          "1933:         session.add(ti)",
          "1934:     session.flush()",
          "1935:     tis = dr.get_task_instances()",
          "1936:     for ti in tis:",
          "1937:         if ti.task_id == 'do_something':",
          "1938:             if ti.map_index > 2:",
          "1939:                 ti.state = TaskInstanceState.REMOVED",
          "1940:             else:",
          "1941:                 ti.state = TaskInstanceState.SUCCESS",
          "1942:             session.merge(ti)",
          "1943:     session.commit()",
          "1944:     # The Upstream is done with 2 removed tis and 3 success tis",
          "1945:     (tis, _) = dr.update_state()",
          "1946:     assert len(tis)",
          "1947:     assert dr.state != DagRunState.FAILED",
          "",
          "---------------"
        ],
        "tests/models/test_taskinstance.py||tests/models/test_taskinstance.py": [
          "File: tests/models/test_taskinstance.py -> tests/models/test_taskinstance.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1065:     # Parameterized tests to check for the correct firing",
          "1066:     # of the trigger_rule under various circumstances",
          "1067:     # Numeric fields are in order:",
          "1069:     @pytest.mark.parametrize(",
          "1071:         \"flag_upstream_failed,expect_state,expect_completed\",",
          "1072:         [",
          "1073:             #",
          "1074:             # Tests for all_success",
          "1075:             #",
          "1080:             #",
          "1081:             # Tests for one_success",
          "1082:             #",
          "1094:             #",
          "1095:             # Tests for all_failed",
          "1096:             #",
          "1102:             #",
          "1103:             # Tests for one_failed",
          "1104:             #",
          "1110:             #",
          "1111:             # Tests for done",
          "1112:             #",
          "1117:         ],",
          "1118:     )",
          "1119:     def test_check_task_dependencies(",
          "",
          "[Removed Lines]",
          "1068:     #   successes, skipped, failed, upstream_failed, done",
          "1070:         \"trigger_rule,successes,skipped,failed,upstream_failed,done,\"",
          "1076:             ['all_success', 5, 0, 0, 0, 0, True, None, True],",
          "1077:             ['all_success', 2, 0, 0, 0, 0, True, None, False],",
          "1078:             ['all_success', 2, 0, 1, 0, 0, True, State.UPSTREAM_FAILED, False],",
          "1079:             ['all_success', 2, 1, 0, 0, 0, True, State.SKIPPED, False],",
          "1083:             ['one_success', 5, 0, 0, 0, 5, True, None, True],",
          "1084:             ['one_success', 2, 0, 0, 0, 2, True, None, True],",
          "1085:             ['one_success', 2, 0, 1, 0, 3, True, None, True],",
          "1086:             ['one_success', 2, 1, 0, 0, 3, True, None, True],",
          "1087:             ['one_success', 0, 5, 0, 0, 5, True, State.SKIPPED, False],",
          "1088:             ['one_success', 0, 4, 1, 0, 5, True, State.UPSTREAM_FAILED, False],",
          "1089:             ['one_success', 0, 3, 1, 1, 5, True, State.UPSTREAM_FAILED, False],",
          "1090:             ['one_success', 0, 4, 0, 1, 5, True, State.UPSTREAM_FAILED, False],",
          "1091:             ['one_success', 0, 0, 5, 0, 5, True, State.UPSTREAM_FAILED, False],",
          "1092:             ['one_success', 0, 0, 4, 1, 5, True, State.UPSTREAM_FAILED, False],",
          "1093:             ['one_success', 0, 0, 0, 5, 5, True, State.UPSTREAM_FAILED, False],",
          "1097:             ['all_failed', 5, 0, 0, 0, 5, True, State.SKIPPED, False],",
          "1098:             ['all_failed', 0, 0, 5, 0, 5, True, None, True],",
          "1099:             ['all_failed', 2, 0, 0, 0, 2, True, State.SKIPPED, False],",
          "1100:             ['all_failed', 2, 0, 1, 0, 3, True, State.SKIPPED, False],",
          "1101:             ['all_failed', 2, 1, 0, 0, 3, True, State.SKIPPED, False],",
          "1105:             ['one_failed', 5, 0, 0, 0, 0, True, None, False],",
          "1106:             ['one_failed', 2, 0, 0, 0, 0, True, None, False],",
          "1107:             ['one_failed', 2, 0, 1, 0, 0, True, None, True],",
          "1108:             ['one_failed', 2, 1, 0, 0, 3, True, None, False],",
          "1109:             ['one_failed', 2, 3, 0, 0, 5, True, State.SKIPPED, False],",
          "1113:             ['all_done', 5, 0, 0, 0, 5, True, None, True],",
          "1114:             ['all_done', 2, 0, 0, 0, 2, True, None, False],",
          "1115:             ['all_done', 2, 0, 1, 0, 3, True, None, False],",
          "1116:             ['all_done', 2, 1, 0, 0, 3, True, None, False],",
          "",
          "[Added Lines]",
          "1068:     #   successes, skipped, failed, upstream_failed, done, removed",
          "1070:         \"trigger_rule,successes,skipped,failed,upstream_failed,done,removed,\"",
          "1076:             ['all_success', 5, 0, 0, 0, 0, 0, True, None, True],",
          "1077:             ['all_success', 2, 0, 0, 0, 0, 0, True, None, False],",
          "1078:             ['all_success', 2, 0, 1, 0, 0, 0, True, State.UPSTREAM_FAILED, False],",
          "1079:             ['all_success', 2, 1, 0, 0, 0, 0, True, State.SKIPPED, False],",
          "1083:             ['one_success', 5, 0, 0, 0, 5, 0, True, None, True],",
          "1084:             ['one_success', 2, 0, 0, 0, 2, 0, True, None, True],",
          "1085:             ['one_success', 2, 0, 1, 0, 3, 0, True, None, True],",
          "1086:             ['one_success', 2, 1, 0, 0, 3, 0, True, None, True],",
          "1087:             ['one_success', 0, 5, 0, 0, 5, 0, True, State.SKIPPED, False],",
          "1088:             ['one_success', 0, 4, 1, 0, 5, 0, True, State.UPSTREAM_FAILED, False],",
          "1089:             ['one_success', 0, 3, 1, 1, 5, 0, True, State.UPSTREAM_FAILED, False],",
          "1090:             ['one_success', 0, 4, 0, 1, 5, 0, True, State.UPSTREAM_FAILED, False],",
          "1091:             ['one_success', 0, 0, 5, 0, 5, 0, True, State.UPSTREAM_FAILED, False],",
          "1092:             ['one_success', 0, 0, 4, 1, 5, 0, True, State.UPSTREAM_FAILED, False],",
          "1093:             ['one_success', 0, 0, 0, 5, 5, 0, True, State.UPSTREAM_FAILED, False],",
          "1097:             ['all_failed', 5, 0, 0, 0, 5, 0, True, State.SKIPPED, False],",
          "1098:             ['all_failed', 0, 0, 5, 0, 5, 0, True, None, True],",
          "1099:             ['all_failed', 2, 0, 0, 0, 2, 0, True, State.SKIPPED, False],",
          "1100:             ['all_failed', 2, 0, 1, 0, 3, 0, True, State.SKIPPED, False],",
          "1101:             ['all_failed', 2, 1, 0, 0, 3, 0, True, State.SKIPPED, False],",
          "1105:             ['one_failed', 5, 0, 0, 0, 0, 0, True, None, False],",
          "1106:             ['one_failed', 2, 0, 0, 0, 0, 0, True, None, False],",
          "1107:             ['one_failed', 2, 0, 1, 0, 0, 0, True, None, True],",
          "1108:             ['one_failed', 2, 1, 0, 0, 3, 0, True, None, False],",
          "1109:             ['one_failed', 2, 3, 0, 0, 5, 0, True, State.SKIPPED, False],",
          "1113:             ['all_done', 5, 0, 0, 0, 5, 0, True, None, True],",
          "1114:             ['all_done', 2, 0, 0, 0, 2, 0, True, None, False],",
          "1115:             ['all_done', 2, 0, 1, 0, 3, 0, True, None, False],",
          "1116:             ['all_done', 2, 1, 0, 0, 3, 0, True, None, False],",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1122:         successes: int,",
          "1123:         skipped: int,",
          "1124:         failed: int,",
          "1125:         upstream_failed: int,",
          "1126:         done: int,",
          "1127:         flag_upstream_failed: bool,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1125:         removed: int,",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "1144:             successes=successes,",
          "1145:             skipped=skipped,",
          "1146:             failed=failed,",
          "1147:             upstream_failed=upstream_failed,",
          "1148:             done=done,",
          "1149:             dep_context=DepContext(),",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1148:             removed=removed,",
          "1149:             upstream_failed=upstream_failed,",
          "1150:             done=done,",
          "1151:             dep_context=DepContext(),",
          "1152:             flag_upstream_failed=flag_upstream_failed,",
          "1153:         )",
          "1154:         completed = all(dep.passed for dep in dep_results)",
          "1156:         assert completed == expect_completed",
          "1157:         assert ti.state == expect_state",
          "1159:     # Parameterized tests to check for the correct firing",
          "1160:     # of the trigger_rule under various circumstances of mapped task",
          "1161:     # Numeric fields are in order:",
          "1162:     #   successes, skipped, failed, upstream_failed, done,removed",
          "1163:     @pytest.mark.parametrize(",
          "1164:         \"trigger_rule,successes,skipped,failed,upstream_failed,done,removed,\"",
          "1165:         \"flag_upstream_failed,expect_state,expect_completed\",",
          "1166:         [",
          "1167:             #",
          "1168:             # Tests for all_success",
          "1169:             #",
          "1170:             ['all_success', 5, 0, 0, 0, 0, 0, True, None, True],",
          "1171:             ['all_success', 2, 0, 0, 0, 0, 0, True, None, False],",
          "1172:             ['all_success', 2, 0, 1, 0, 0, 0, True, State.UPSTREAM_FAILED, False],",
          "1173:             ['all_success', 2, 1, 0, 0, 0, 0, True, State.SKIPPED, False],",
          "1174:             ['all_success', 3, 0, 0, 0, 0, 2, True, State.REMOVED, True],  # ti.map_index >=successes",
          "1175:             #",
          "1176:             # Tests for one_success",
          "1177:             #",
          "1178:             ['one_success', 5, 0, 0, 0, 5, 0, True, None, True],",
          "1179:             ['one_success', 2, 0, 0, 0, 2, 0, True, None, True],",
          "1180:             ['one_success', 2, 0, 1, 0, 3, 0, True, None, True],",
          "1181:             ['one_success', 2, 1, 0, 0, 3, 0, True, None, True],",
          "1182:             ['one_success', 0, 5, 0, 0, 5, 0, True, State.SKIPPED, False],",
          "1183:             ['one_success', 0, 4, 1, 0, 5, 0, True, State.UPSTREAM_FAILED, False],",
          "1184:             ['one_success', 0, 3, 1, 1, 5, 0, True, State.UPSTREAM_FAILED, False],",
          "1185:             ['one_success', 0, 4, 0, 1, 5, 0, True, State.UPSTREAM_FAILED, False],",
          "1186:             ['one_success', 0, 0, 5, 0, 5, 0, True, State.UPSTREAM_FAILED, False],",
          "1187:             ['one_success', 0, 0, 4, 1, 5, 0, True, State.UPSTREAM_FAILED, False],",
          "1188:             ['one_success', 0, 0, 0, 5, 5, 0, True, State.UPSTREAM_FAILED, False],",
          "1189:             #",
          "1190:             # Tests for all_failed",
          "1191:             #",
          "1192:             ['all_failed', 5, 0, 0, 0, 5, 0, True, State.SKIPPED, False],",
          "1193:             ['all_failed', 0, 0, 5, 0, 5, 0, True, None, True],",
          "1194:             ['all_failed', 2, 0, 0, 0, 2, 0, True, State.SKIPPED, False],",
          "1195:             ['all_failed', 2, 0, 1, 0, 3, 0, True, State.SKIPPED, False],",
          "1196:             ['all_failed', 2, 1, 0, 0, 3, 0, True, State.SKIPPED, False],",
          "1197:             ['all_failed', 2, 1, 0, 0, 4, 1, True, State.SKIPPED, False],  # One removed",
          "1198:             #",
          "1199:             # Tests for one_failed",
          "1200:             #",
          "1201:             ['one_failed', 5, 0, 0, 0, 0, 0, True, None, False],",
          "1202:             ['one_failed', 2, 0, 0, 0, 0, 0, True, None, False],",
          "1203:             ['one_failed', 2, 0, 1, 0, 0, 0, True, None, True],",
          "1204:             ['one_failed', 2, 1, 0, 0, 3, 0, True, None, False],",
          "1205:             ['one_failed', 2, 3, 0, 0, 5, 0, True, State.SKIPPED, False],",
          "1206:             ['one_failed', 2, 2, 0, 0, 5, 1, True, State.SKIPPED, False],  # One removed",
          "1207:             #",
          "1208:             # Tests for done",
          "1209:             #",
          "1210:             ['all_done', 5, 0, 0, 0, 5, 0, True, None, True],",
          "1211:             ['all_done', 2, 0, 0, 0, 2, 0, True, None, False],",
          "1212:             ['all_done', 2, 0, 1, 0, 3, 0, True, None, False],",
          "1213:             ['all_done', 2, 1, 0, 0, 3, 0, True, None, False],",
          "1214:         ],",
          "1215:     )",
          "1216:     def test_check_task_dependencies_for_mapped(",
          "1217:         self,",
          "1218:         trigger_rule: str,",
          "1219:         successes: int,",
          "1220:         skipped: int,",
          "1221:         failed: int,",
          "1222:         removed: int,",
          "1223:         upstream_failed: int,",
          "1224:         done: int,",
          "1225:         flag_upstream_failed: bool,",
          "1226:         expect_state: State,",
          "1227:         expect_completed: bool,",
          "1228:         dag_maker,",
          "1229:         session,",
          "1230:     ):",
          "1231:         from airflow.decorators import task",
          "1233:         @task",
          "1234:         def do_something(i):",
          "1235:             return 1",
          "1237:         @task(trigger_rule=trigger_rule)",
          "1238:         def do_something_else(i):",
          "1239:             return 1",
          "1241:         with dag_maker(dag_id='test_dag'):",
          "1242:             nums = do_something.expand(i=[i + 1 for i in range(5)])",
          "1243:             do_something_else.expand(i=nums)",
          "1245:         dr = dag_maker.create_dagrun()",
          "1247:         ti = dr.get_task_instance('do_something_else', session=session)",
          "1248:         ti.map_index = 0",
          "1249:         for map_index in range(1, 5):",
          "1250:             ti = TaskInstance(ti.task, run_id=dr.run_id, map_index=map_index)",
          "1251:             ti.dag_run = dr",
          "1252:             session.add(ti)",
          "1253:         session.flush()",
          "1254:         downstream = ti.task",
          "1255:         ti = dr.get_task_instance(task_id='do_something_else', map_index=3, session=session)",
          "1256:         ti.task = downstream",
          "1257:         dep_results = TriggerRuleDep()._evaluate_trigger_rule(",
          "1258:             ti=ti,",
          "1259:             successes=successes,",
          "1260:             skipped=skipped,",
          "1261:             failed=failed,",
          "1262:             removed=removed,",
          "",
          "---------------"
        ],
        "tests/ti_deps/deps/test_trigger_rule_dep.py||tests/ti_deps/deps/test_trigger_rule_dep.py": [
          "File: tests/ti_deps/deps/test_trigger_rule_dep.py -> tests/ti_deps/deps/test_trigger_rule_dep.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "25: from airflow import settings",
          "26: from airflow.models import DAG",
          "27: from airflow.models.baseoperator import BaseOperator",
          "28: from airflow.operators.empty import EmptyOperator",
          "29: from airflow.ti_deps.dep_context import DepContext",
          "30: from airflow.ti_deps.deps.trigger_rule_dep import TriggerRuleDep",
          "31: from airflow.utils import timezone",
          "32: from airflow.utils.session import create_session",
          "34: from airflow.utils.trigger_rule import TriggerRule",
          "35: from tests.models import DEFAULT_DATE",
          "36: from tests.test_utils.db import clear_db_runs",
          "",
          "[Removed Lines]",
          "33: from airflow.utils.state import State",
          "",
          "[Added Lines]",
          "28: from airflow.models.taskinstance import TaskInstance",
          "34: from airflow.utils.state import State, TaskInstanceState",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "53:     return _get_task_instance",
          "56: class TestTriggerRuleDep:",
          "57:     def test_no_upstream_tasks(self, get_task_instance):",
          "58:         \"\"\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "57: @pytest.fixture",
          "58: def get_mapped_task_dagrun(session, dag_maker):",
          "59:     def _get_dagrun(trigger_rule=TriggerRule.ALL_SUCCESS, state=State.SUCCESS):",
          "60:         from airflow.decorators import task",
          "62:         @task",
          "63:         def do_something(i):",
          "64:             return 1",
          "66:         @task(trigger_rule=trigger_rule)",
          "67:         def do_something_else(i):",
          "68:             return 1",
          "70:         with dag_maker(dag_id='test_dag'):",
          "71:             nums = do_something.expand(i=[i + 1 for i in range(5)])",
          "72:             do_something_else.expand(i=nums)",
          "74:         dr = dag_maker.create_dagrun()",
          "76:         ti = dr.get_task_instance('do_something_else', session=session)",
          "77:         ti.map_index = 0",
          "78:         for map_index in range(1, 5):",
          "79:             ti = TaskInstance(ti.task, run_id=dr.run_id, map_index=map_index)",
          "80:             ti.dag_run = dr",
          "81:             session.add(ti)",
          "82:         session.flush()",
          "83:         tis = dr.get_task_instances()",
          "84:         for ti in tis:",
          "85:             if ti.task_id == 'do_something':",
          "86:                 if ti.map_index > 2:",
          "87:                     ti.state = TaskInstanceState.REMOVED",
          "88:                 else:",
          "89:                     ti.state = state",
          "90:                 session.merge(ti)",
          "91:         session.commit()",
          "92:         return dr, ti.task",
          "94:     return _get_dagrun",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "79:                 successes=1,",
          "80:                 skipped=2,",
          "81:                 failed=2,",
          "82:                 upstream_failed=2,",
          "83:                 done=2,",
          "84:                 flag_upstream_failed=False,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "123:                 removed=0,",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "99:                 successes=0,",
          "100:                 skipped=2,",
          "101:                 failed=2,",
          "102:                 upstream_failed=2,",
          "103:                 done=2,",
          "104:                 flag_upstream_failed=False,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "144:                 removed=0,",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "120:                 successes=2,",
          "121:                 skipped=0,",
          "122:                 failed=0,",
          "123:                 upstream_failed=0,",
          "124:                 done=2,",
          "125:                 flag_upstream_failed=False,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "166:                 removed=0,",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "141:                 successes=0,",
          "142:                 skipped=2,",
          "143:                 failed=2,",
          "144:                 upstream_failed=0,",
          "145:                 done=2,",
          "146:                 flag_upstream_failed=False,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "188:                 removed=0,",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "156:                 successes=0,",
          "157:                 skipped=2,",
          "158:                 failed=0,",
          "159:                 upstream_failed=2,",
          "160:                 done=2,",
          "161:                 flag_upstream_failed=False,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "204:                 removed=0,",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "176:                 successes=1,",
          "177:                 skipped=0,",
          "178:                 failed=0,",
          "179:                 upstream_failed=0,",
          "180:                 done=1,",
          "181:                 flag_upstream_failed=False,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "225:                 removed=0,",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "196:                 successes=1,",
          "197:                 skipped=0,",
          "198:                 failed=1,",
          "199:                 upstream_failed=0,",
          "200:                 done=2,",
          "201:                 flag_upstream_failed=False,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "246:                 removed=0,",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "217:                 successes=1,",
          "218:                 skipped=1,",
          "219:                 failed=0,",
          "220:                 upstream_failed=0,",
          "221:                 done=2,",
          "222:                 flag_upstream_failed=False,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "268:                 removed=0,",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "239:                 successes=1,",
          "240:                 skipped=1,",
          "241:                 failed=0,",
          "242:                 upstream_failed=0,",
          "243:                 done=2,",
          "244:                 flag_upstream_failed=True,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "291:                 removed=0,",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "261:                 successes=1,",
          "262:                 skipped=1,",
          "263:                 failed=0,",
          "264:                 upstream_failed=0,",
          "265:                 done=2,",
          "266:                 flag_upstream_failed=False,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "314:                 removed=0,",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "281:                 successes=0,",
          "282:                 skipped=2,",
          "283:                 failed=0,",
          "284:                 upstream_failed=0,",
          "285:                 done=2,",
          "286:                 flag_upstream_failed=True,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "335:                 removed=0,",
          "",
          "---------------",
          "--- Hunk 14 ---",
          "[Context before]",
          "304:                 successes=1,",
          "305:                 skipped=1,",
          "306:                 failed=1,",
          "307:                 upstream_failed=0,",
          "308:                 done=3,",
          "309:                 flag_upstream_failed=False,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "359:                 removed=0,",
          "",
          "---------------",
          "--- Hunk 15 ---",
          "[Context before]",
          "327:                 successes=1,",
          "328:                 skipped=1,",
          "329:                 failed=0,",
          "330:                 upstream_failed=0,",
          "331:                 done=2,",
          "332:                 flag_upstream_failed=False,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "383:                 removed=0,",
          "",
          "---------------",
          "--- Hunk 16 ---",
          "[Context before]",
          "349:                 successes=0,",
          "350:                 skipped=2,",
          "351:                 failed=0,",
          "352:                 upstream_failed=0,",
          "353:                 done=2,",
          "354:                 flag_upstream_failed=True,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "406:                 removed=0,",
          "",
          "---------------",
          "--- Hunk 17 ---",
          "[Context before]",
          "373:                 successes=1,",
          "374:                 skipped=1,",
          "375:                 failed=1,",
          "376:                 upstream_failed=0,",
          "377:                 done=3,",
          "378:                 flag_upstream_failed=False,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "431:                 removed=0,",
          "",
          "---------------",
          "--- Hunk 18 ---",
          "[Context before]",
          "394:                 successes=0,",
          "395:                 skipped=0,",
          "396:                 failed=2,",
          "397:                 upstream_failed=0,",
          "398:                 done=2,",
          "399:                 flag_upstream_failed=False,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "453:                 removed=0,",
          "",
          "---------------",
          "--- Hunk 19 ---",
          "[Context before]",
          "414:                 successes=2,",
          "415:                 skipped=0,",
          "416:                 failed=0,",
          "417:                 upstream_failed=0,",
          "418:                 done=2,",
          "419:                 flag_upstream_failed=False,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "474:                 removed=0,",
          "",
          "---------------",
          "--- Hunk 20 ---",
          "[Context before]",
          "435:                 successes=2,",
          "436:                 skipped=0,",
          "437:                 failed=0,",
          "438:                 upstream_failed=0,",
          "439:                 done=2,",
          "440:                 flag_upstream_failed=False,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "496:                 removed=0,",
          "",
          "---------------",
          "--- Hunk 21 ---",
          "[Context before]",
          "455:                 successes=1,",
          "456:                 skipped=0,",
          "457:                 failed=0,",
          "458:                 upstream_failed=0,",
          "459:                 done=1,",
          "460:                 flag_upstream_failed=False,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "517:                 removed=0,",
          "",
          "---------------",
          "--- Hunk 22 ---",
          "[Context before]",
          "479:                     successes=0,",
          "480:                     skipped=3,",
          "481:                     failed=0,",
          "482:                     upstream_failed=0,",
          "483:                     done=3,",
          "484:                     flag_upstream_failed=False,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "542:                     removed=0,",
          "",
          "---------------",
          "--- Hunk 23 ---",
          "[Context before]",
          "495:                     successes=0,",
          "496:                     skipped=3,",
          "497:                     failed=0,",
          "498:                     upstream_failed=0,",
          "499:                     done=3,",
          "500:                     flag_upstream_failed=True,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "559:                     removed=0,",
          "",
          "---------------",
          "--- Hunk 24 ---",
          "[Context before]",
          "515:                 successes=1,",
          "516:                 skipped=0,",
          "517:                 failed=0,",
          "518:                 upstream_failed=0,",
          "519:                 done=1,",
          "520:                 flag_upstream_failed=False,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "580:                 removed=0,",
          "",
          "---------------",
          "--- Hunk 25 ---",
          "[Context before]",
          "539:                     successes=2,",
          "540:                     skipped=0,",
          "541:                     failed=1,",
          "542:                     upstream_failed=0,",
          "543:                     done=3,",
          "544:                     flag_upstream_failed=False,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "605:                     removed=0,",
          "",
          "---------------",
          "--- Hunk 26 ---",
          "[Context before]",
          "555:                     successes=0,",
          "556:                     skipped=0,",
          "557:                     failed=3,",
          "558:                     upstream_failed=0,",
          "559:                     done=3,",
          "560:                     flag_upstream_failed=True,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "622:                     removed=0,",
          "",
          "---------------",
          "--- Hunk 27 ---",
          "[Context before]",
          "577:                     successes=1,",
          "578:                     skipped=1,",
          "579:                     failed=0,",
          "580:                     upstream_failed=0,",
          "581:                     done=2,",
          "582:                     flag_upstream_failed=False,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "645:                     removed=0,",
          "",
          "---------------",
          "--- Hunk 28 ---",
          "[Context before]",
          "594:                     successes=1,",
          "595:                     skipped=1,",
          "596:                     failed=0,",
          "597:                     upstream_failed=0,",
          "598:                     done=2,",
          "599:                     flag_upstream_failed=True,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "663:                     removed=0,",
          "",
          "---------------",
          "--- Hunk 29 ---",
          "[Context before]",
          "611:                     successes=0,",
          "612:                     skipped=0,",
          "613:                     failed=0,",
          "614:                     upstream_failed=0,",
          "615:                     done=0,",
          "616:                     flag_upstream_failed=False,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "681:                     removed=0,",
          "",
          "---------------",
          "--- Hunk 30 ---",
          "[Context before]",
          "633:                 successes=1,",
          "634:                 skipped=0,",
          "635:                 failed=0,",
          "636:                 upstream_failed=0,",
          "637:                 done=1,",
          "638:                 flag_upstream_failed=False,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "704:                 removed=0,",
          "",
          "---------------",
          "--- Hunk 31 ---",
          "[Context before]",
          "694:         # check handling with cases that tasks are triggered from backfill with no finished tasks",
          "695:         finished_tis = DepContext().ensure_finished_tis(ti_op2.dag_run, session)",
          "697:         finished_tis = dr.get_task_instances(state=State.finished, session=session)",
          "701:         dr.update_state()",
          "702:         assert State.SUCCESS == dr.state",
          "",
          "[Removed Lines]",
          "696:         assert get_states_count_upstream_ti(finished_tis=finished_tis, task=op2) == (1, 0, 0, 0, 1)",
          "698:         assert get_states_count_upstream_ti(finished_tis=finished_tis, task=op4) == (1, 0, 1, 0, 2)",
          "699:         assert get_states_count_upstream_ti(finished_tis=finished_tis, task=op5) == (2, 0, 1, 0, 3)",
          "",
          "[Added Lines]",
          "765:         assert get_states_count_upstream_ti(finished_tis=finished_tis, task=op2) == (1, 0, 0, 0, 0, 1)",
          "767:         assert get_states_count_upstream_ti(finished_tis=finished_tis, task=op4) == (1, 0, 1, 0, 0, 2)",
          "768:         assert get_states_count_upstream_ti(finished_tis=finished_tis, task=op5) == (2, 0, 1, 0, 0, 3)",
          "773:     def test_mapped_task_upstream_removed_with_all_success_trigger_rules(",
          "774:         self, session, get_mapped_task_dagrun",
          "775:     ):",
          "776:         \"\"\"",
          "777:         Test ALL_SUCCESS trigger rule with mapped task upstream removed",
          "778:         \"\"\"",
          "779:         dr, task = get_mapped_task_dagrun()",
          "781:         # ti with removed upstream ti",
          "782:         ti = dr.get_task_instance(task_id='do_something_else', map_index=3, session=session)",
          "783:         ti.task = task",
          "785:         dep_statuses = tuple(",
          "786:             TriggerRuleDep()._evaluate_trigger_rule(",
          "787:                 ti=ti,",
          "788:                 successes=3,",
          "789:                 skipped=0,",
          "790:                 failed=0,",
          "791:                 removed=2,",
          "792:                 upstream_failed=0,",
          "793:                 done=5,",
          "794:                 flag_upstream_failed=True,  # marks the task as removed if upstream is removed",
          "795:                 dep_context=DepContext(),",
          "796:                 session=session,",
          "797:             )",
          "798:         )",
          "800:         assert len(dep_statuses) == 0",
          "801:         assert ti.state == TaskInstanceState.REMOVED",
          "803:     def test_mapped_task_upstream_removed_with_all_failed_trigger_rules(",
          "804:         self, session, get_mapped_task_dagrun",
          "805:     ):",
          "806:         \"\"\"",
          "807:         Test ALL_FAILED trigger rule with mapped task upstream removed",
          "808:         \"\"\"",
          "810:         dr, task = get_mapped_task_dagrun(trigger_rule=TriggerRule.ALL_FAILED, state=State.FAILED)",
          "812:         # ti with removed upstream ti",
          "813:         ti = dr.get_task_instance(task_id='do_something_else', map_index=3, session=session)",
          "814:         ti.task = task",
          "816:         dep_statuses = tuple(",
          "817:             TriggerRuleDep()._evaluate_trigger_rule(",
          "818:                 ti=ti,",
          "819:                 successes=0,",
          "820:                 skipped=0,",
          "821:                 failed=3,",
          "822:                 removed=2,",
          "823:                 upstream_failed=0,",
          "824:                 done=5,",
          "825:                 flag_upstream_failed=False,",
          "826:                 dep_context=DepContext(),",
          "827:                 session=session,",
          "828:             )",
          "829:         )",
          "831:         assert len(dep_statuses) == 0",
          "833:     def test_mapped_task_upstream_removed_with_none_failed_trigger_rules(",
          "834:         self, session, get_mapped_task_dagrun",
          "835:     ):",
          "836:         \"\"\"",
          "837:         Test NONE_FAILED trigger rule with mapped task upstream removed",
          "838:         \"\"\"",
          "839:         dr, task = get_mapped_task_dagrun(trigger_rule=TriggerRule.NONE_FAILED)",
          "841:         # ti with removed upstream ti",
          "842:         ti = dr.get_task_instance(task_id='do_something_else', map_index=3, session=session)",
          "843:         ti.task = task",
          "845:         dep_statuses = tuple(",
          "846:             TriggerRuleDep()._evaluate_trigger_rule(",
          "847:                 ti=ti,",
          "848:                 successes=3,",
          "849:                 skipped=0,",
          "850:                 failed=0,",
          "851:                 removed=2,",
          "852:                 upstream_failed=0,",
          "853:                 done=5,",
          "854:                 flag_upstream_failed=False,",
          "855:                 dep_context=DepContext(),",
          "856:                 session=session,",
          "857:             )",
          "858:         )",
          "860:         assert len(dep_statuses) == 0",
          "862:     def test_mapped_task_upstream_removed_with_none_failed_min_one_success_trigger_rules(",
          "863:         self, session, get_mapped_task_dagrun",
          "864:     ):",
          "865:         \"\"\"",
          "866:         Test NONE_FAILED_MIN_ONE_SUCCESS trigger rule with mapped task upstream removed",
          "867:         \"\"\"",
          "868:         dr, task = get_mapped_task_dagrun(trigger_rule=TriggerRule.NONE_FAILED_MIN_ONE_SUCCESS)",
          "870:         # ti with removed upstream ti",
          "871:         ti = dr.get_task_instance(task_id='do_something_else', map_index=3, session=session)",
          "872:         ti.task = task",
          "874:         dep_statuses = tuple(",
          "875:             TriggerRuleDep()._evaluate_trigger_rule(",
          "876:                 ti=ti,",
          "877:                 successes=3,",
          "878:                 skipped=0,",
          "879:                 failed=0,",
          "880:                 removed=2,",
          "881:                 upstream_failed=0,",
          "882:                 done=5,",
          "883:                 flag_upstream_failed=False,",
          "884:                 dep_context=DepContext(),",
          "885:                 session=session,",
          "886:             )",
          "887:         )",
          "889:         assert len(dep_statuses) == 0",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "bff201733864c09ae380abaa47aa00011b5a8c30",
      "candidate_info": {
        "commit_hash": "bff201733864c09ae380abaa47aa00011b5a8c30",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/bff201733864c09ae380abaa47aa00011b5a8c30",
        "files": [
          "airflow/www/static/js/dag/details/taskInstance/Logs/index.test.tsx",
          "airflow/www/static/js/dag/details/taskInstance/Logs/index.tsx"
        ],
        "message": "Fix grid view log try numbers (#26556)\n\n* redo how try numbers are displayed in grid view logs\n\n* rename attempt -> tryNumber\n\n(cherry picked from commit 6a69ad033fdc224aee14b8c83fdc1b672d17ac20)",
        "before_after_code_files": [
          "airflow/www/static/js/dag/details/taskInstance/Logs/index.test.tsx||airflow/www/static/js/dag/details/taskInstance/Logs/index.test.tsx",
          "airflow/www/static/js/dag/details/taskInstance/Logs/index.tsx||airflow/www/static/js/dag/details/taskInstance/Logs/index.tsx"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/26688"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/www/static/js/dag/details/taskInstance/Logs/index.test.tsx||airflow/www/static/js/dag/details/taskInstance/Logs/index.test.tsx": [
          "File: airflow/www/static/js/dag/details/taskInstance/Logs/index.test.tsx -> airflow/www/static/js/dag/details/taskInstance/Logs/index.test.tsx",
          "--- Hunk 1 ---",
          "[Context before]",
          "85:       dagRunId: 'dummyDagRunId',",
          "86:       fullContent: false,",
          "87:       taskId: 'dummyTaskId',",
          "89:     });",
          "90:   });",
          "",
          "[Removed Lines]",
          "88:       taskTryNumber: 1,",
          "",
          "[Added Lines]",
          "88:       taskTryNumber: 2,",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "146:       fullContent: false,",
          "147:       mapIndex: 1,",
          "148:       taskId: 'dummyTaskId',",
          "150:     });",
          "151:   });",
          "",
          "[Removed Lines]",
          "149:       taskTryNumber: 1,",
          "",
          "[Added Lines]",
          "149:       taskTryNumber: 2,",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "172:       dagRunId: 'dummyDagRunId',",
          "173:       fullContent: false,",
          "174:       taskId: 'dummyTaskId',",
          "176:     });",
          "181:     expect(useTaskLogMock).toHaveBeenLastCalledWith({",
          "182:       dagId: 'dummyDagId',",
          "183:       dagRunId: 'dummyDagRunId',",
          "184:       fullContent: false,",
          "185:       taskId: 'dummyTaskId',",
          "187:     });",
          "188:   });",
          "",
          "[Removed Lines]",
          "175:       taskTryNumber: 1,",
          "177:     const attemptButton2 = getByTestId('log-attempt-select-button-2');",
          "179:     fireEvent.click(attemptButton2);",
          "186:       taskTryNumber: 2,",
          "",
          "[Added Lines]",
          "175:       taskTryNumber: 2,",
          "177:     const attemptButton1 = getByTestId('log-attempt-select-button-1');",
          "179:     fireEvent.click(attemptButton1);",
          "186:       taskTryNumber: 1,",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "203:       dagRunId: 'dummyDagRunId',",
          "204:       fullContent: false,",
          "205:       taskId: 'dummyTaskId',",
          "207:     });",
          "208:     const fullContentCheckbox = getByTestId('full-content-checkbox');",
          "",
          "[Removed Lines]",
          "206:       taskTryNumber: 1,",
          "",
          "[Added Lines]",
          "206:       taskTryNumber: 2,",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "214:       dagRunId: 'dummyDagRunId',",
          "215:       fullContent: true,",
          "216:       taskId: 'dummyTaskId',",
          "218:     });",
          "219:   });",
          "220: });",
          "",
          "[Removed Lines]",
          "217:       taskTryNumber: 1,",
          "",
          "[Added Lines]",
          "217:       taskTryNumber: 2,",
          "",
          "---------------"
        ],
        "airflow/www/static/js/dag/details/taskInstance/Logs/index.tsx||airflow/www/static/js/dag/details/taskInstance/Logs/index.tsx": [
          "File: airflow/www/static/js/dag/details/taskInstance/Logs/index.tsx -> airflow/www/static/js/dag/details/taskInstance/Logs/index.tsx",
          "--- Hunk 1 ---",
          "[Context before]",
          "61:   const externalIndexes: Array<number> = [];",
          "63:   if (tryNumber) {",
          "69:       } else {",
          "71:       }",
          "72:     });",
          "73:   }",
          "",
          "[Removed Lines]",
          "64:     [...Array(tryNumber + 1 || 0)].forEach((_, index) => {",
          "65:       if (index === 0 && tryNumber < 2) return;",
          "66:       const isExternal = index !== 0 && showExternalLogRedirect;",
          "67:       if (isExternal) {",
          "68:         externalIndexes.push(index);",
          "70:         internalIndexes.push(index);",
          "",
          "[Added Lines]",
          "64:     [...Array(tryNumber)].forEach((_, index) => {",
          "65:       const tryNum = index + 1;",
          "66:       if (showExternalLogRedirect) {",
          "67:         externalIndexes.push(tryNum);",
          "69:         internalIndexes.push(tryNum);",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "99:   tryNumber,",
          "100: }: Props) => {",
          "101:   const [internalIndexes, externalIndexes] = getLinkIndexes(tryNumber);",
          "103:   const [shouldRequestFullContent, setShouldRequestFullContent] = useState(false);",
          "104:   const [wrap, setWrap] = useState(getMetaValue('default_wrap') === 'True');",
          "105:   const [logLevelFilters, setLogLevelFilters] = useState<Array<LogLevelOption>>([]);",
          "106:   const [fileSourceFilters, setFileSourceFilters] = useState<Array<FileSourceOption>>([]);",
          "107:   const { timezone } = useTimezone();",
          "108:   const { data, isSuccess } = useTaskLog({",
          "109:     dagId,",
          "110:     dagRunId,",
          "111:     taskId,",
          "112:     mapIndex,",
          "114:     fullContent: shouldRequestFullContent,",
          "115:   });",
          "",
          "[Removed Lines]",
          "102:   const [selectedAttempt, setSelectedAttempt] = useState(1);",
          "113:     taskTryNumber: selectedAttempt,",
          "",
          "[Added Lines]",
          "101:   const [selectedTryNumber, setSelectedTryNumber] = useState<number | undefined>();",
          "109:   const taskTryNumber = selectedTryNumber || tryNumber || 1;",
          "115:     taskTryNumber,",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "144:   useEffect(() => {",
          "149:     }",
          "151:     if (data && fileSourceFilters.length > 0",
          "",
          "[Removed Lines]",
          "147:     if (!internalIndexes.includes(selectedAttempt) && internalIndexes.length) {",
          "148:       setSelectedAttempt(internalIndexes[0]);",
          "",
          "[Added Lines]",
          "149:     if (taskTryNumber > (tryNumber || 1)) {",
          "150:       setSelectedTryNumber(undefined);",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "155:       )) {",
          "156:       setFileSourceFilters([]);",
          "157:     }",
          "160:   return (",
          "161:     <>",
          "",
          "[Removed Lines]",
          "158:   }, [data, internalIndexes, fileSourceFilters, fileSources, selectedAttempt]);",
          "",
          "[Added Lines]",
          "160:   }, [data, fileSourceFilters, fileSources, taskTryNumber, tryNumber]);",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "167:               {internalIndexes.map((index) => (",
          "168:                 <Button",
          "169:                   key={index}",
          "171:                   colorScheme=\"blue\"",
          "173:                   data-testid={`log-attempt-select-button-${index}`}",
          "174:                 >",
          "175:                   {index}",
          "",
          "[Removed Lines]",
          "170:                   variant={selectedAttempt === index ? 'solid' : 'ghost'}",
          "172:                   onClick={() => setSelectedAttempt(index)}",
          "",
          "[Added Lines]",
          "172:                   variant={taskTryNumber === index ? 'solid' : 'ghost'}",
          "174:                   onClick={() => setSelectedTryNumber(index)}",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "2297b6b91b116fa26f027e80f4cf7a14854b3ad4",
      "candidate_info": {
        "commit_hash": "2297b6b91b116fa26f027e80f4cf7a14854b3ad4",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/2297b6b91b116fa26f027e80f4cf7a14854b3ad4",
        "files": [
          "airflow/utils/sqlalchemy.py"
        ],
        "message": "ExecutorConfigType should be cacheable (#26498)\n\nApparently the cache_ok attribute must be applied to all subclasses too.  So we must apply it here.  This allows sqlalchemy to use the caching behavior introduced with version 1.4.  See https://docs.sqlalchemy.org/en/14/core/type_api.html#sqlalchemy.types.ExternalType.cache_ok for more info.\n\n(cherry picked from commit ba9edda254a52af6915bd20d569a9f8c8dfb4bf9)",
        "before_after_code_files": [
          "airflow/utils/sqlalchemy.py||airflow/utils/sqlalchemy.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/26688"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/utils/sqlalchemy.py||airflow/utils/sqlalchemy.py": [
          "File: airflow/utils/sqlalchemy.py -> airflow/utils/sqlalchemy.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "161:     Airflow's serializer before pickling.",
          "162:     \"\"\"",
          "164:     def bind_processor(self, dialect):",
          "166:         from airflow.serialization.serialized_objects import BaseSerialization",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "164:     cache_ok = True",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "329f706d9e59d690bd6ff6a3c8c035172668a217",
      "candidate_info": {
        "commit_hash": "329f706d9e59d690bd6ff6a3c8c035172668a217",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/329f706d9e59d690bd6ff6a3c8c035172668a217",
        "files": [
          "airflow/utils/log/file_task_handler.py",
          "tests/utils/test_log_handlers.py"
        ],
        "message": "Add unit test for log retrieval url (#26603)\n\n* Add unit test for log retrieval url\n\nAdded unit test to #26493\n\n(cherry picked from commit 061caff2862d9df078336dc94efa5a6915935b7e)",
        "before_after_code_files": [
          "airflow/utils/log/file_task_handler.py||airflow/utils/log/file_task_handler.py",
          "tests/utils/test_log_handlers.py||tests/utils/test_log_handlers.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/26688"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/utils/log/file_task_handler.py||airflow/utils/log/file_task_handler.py": [
          "File: airflow/utils/log/file_task_handler.py -> airflow/utils/log/file_task_handler.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "197:         else:",
          "198:             import httpx",
          "204:             log += f\"*** Log file does not exist: {location}\\n\"",
          "205:             log += f\"*** Fetching from: {url}\\n\"",
          "206:             try:",
          "",
          "[Removed Lines]",
          "200:             url = urljoin(",
          "201:                 f\"http://{ti.hostname}:{conf.get('logging', 'WORKER_LOG_SERVER_PORT')}/log/\",",
          "202:                 log_relative_path,",
          "203:             )",
          "",
          "[Added Lines]",
          "200:             url = self._get_log_retrieval_url(ti, log_relative_path)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "245:         return log, {'end_of_log': True}",
          "247:     def read(self, task_instance, try_number=None, metadata=None):",
          "248:         \"\"\"",
          "249:         Read logs of given task instance from local machine.",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "244:     @staticmethod",
          "245:     def _get_log_retrieval_url(ti: TaskInstance, log_relative_path: str) -> str:",
          "246:         url = urljoin(",
          "247:             f\"http://{ti.hostname}:{conf.get('logging', 'WORKER_LOG_SERVER_PORT')}/log/\",",
          "248:             log_relative_path,",
          "249:         )",
          "250:         return url",
          "",
          "---------------"
        ],
        "tests/utils/test_log_handlers.py||tests/utils/test_log_handlers.py": [
          "File: tests/utils/test_log_handlers.py -> tests/utils/test_log_handlers.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "251:         fth = FileTaskHandler(\"\")",
          "252:         rendered_filename = fth._render_filename(filename_rendering_ti, 42)",
          "253:         assert expected_filename == rendered_filename",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "256: class TestLogUrl:",
          "257:     def test_log_retrieval_valid(self, create_task_instance):",
          "258:         log_url_ti = create_task_instance(",
          "259:             dag_id=\"dag_for_testing_filename_rendering\",",
          "260:             task_id=\"task_for_testing_filename_rendering\",",
          "261:             run_type=DagRunType.SCHEDULED,",
          "262:             execution_date=DEFAULT_DATE,",
          "263:         )",
          "264:         log_url_ti.hostname = 'hostname'",
          "265:         url = FileTaskHandler._get_log_retrieval_url(log_url_ti, 'DYNAMIC_PATH')",
          "266:         assert url == \"http://hostname:8793/log/DYNAMIC_PATH\"",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "5e990fd549914fde1f40839159becf02a43e704a",
      "candidate_info": {
        "commit_hash": "5e990fd549914fde1f40839159becf02a43e704a",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/5e990fd549914fde1f40839159becf02a43e704a",
        "files": [
          "README.md",
          "airflow/utils/db.py",
          "docs/apache-airflow/installation/supported-versions.rst",
          "docs/docker-stack/README.md",
          "docs/docker-stack/docker-examples/extending/add-apt-packages/Dockerfile",
          "docs/docker-stack/docker-examples/extending/add-build-essential-extend/Dockerfile",
          "docs/docker-stack/docker-examples/extending/add-providers/Dockerfile",
          "docs/docker-stack/docker-examples/extending/add-pypi-packages/Dockerfile",
          "docs/docker-stack/docker-examples/extending/add-requirement-packages/Dockerfile",
          "docs/docker-stack/docker-examples/extending/custom-providers/Dockerfile",
          "docs/docker-stack/docker-examples/extending/embedding-dags/Dockerfile",
          "docs/docker-stack/docker-examples/extending/writable-directory/Dockerfile",
          "docs/docker-stack/entrypoint.rst",
          "scripts/ci/pre_commit/pre_commit_supported_versions.py",
          "setup.py"
        ],
        "message": "Update version to 2.4.1",
        "before_after_code_files": [
          "airflow/utils/db.py||airflow/utils/db.py",
          "scripts/ci/pre_commit/pre_commit_supported_versions.py||scripts/ci/pre_commit/pre_commit_supported_versions.py",
          "setup.py||setup.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/26688"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/utils/db.py||airflow/utils/db.py": [
          "File: airflow/utils/db.py -> airflow/utils/db.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "73:     \"2.3.3\": \"f5fcbda3e651\",",
          "74:     \"2.3.4\": \"f5fcbda3e651\",",
          "75:     \"2.4.0\": \"ecb43d2a1842\",",
          "76: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "76:     \"2.4.1\": \"ecb43d2a1842\",",
          "",
          "---------------"
        ],
        "scripts/ci/pre_commit/pre_commit_supported_versions.py||scripts/ci/pre_commit/pre_commit_supported_versions.py": [
          "File: scripts/ci/pre_commit/pre_commit_supported_versions.py -> scripts/ci/pre_commit/pre_commit_supported_versions.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "27: HEADERS = (\"Version\", \"Current Patch/Minor\", \"State\", \"First Release\", \"Limited Support\", \"EOL/Terminated\")",
          "29: SUPPORTED_VERSIONS = (",
          "31:     (\"1.10\", \"1.10.15\", \"EOL\", \"Aug 27, 2018\", \"Dec 17, 2020\", \"June 17, 2021\"),",
          "32:     (\"1.9\", \"1.9.0\", \"EOL\", \"Jan 03, 2018\", \"Aug 27, 2018\", \"Aug 27, 2018\"),",
          "33:     (\"1.8\", \"1.8.2\", \"EOL\", \"Mar 19, 2017\", \"Jan 03, 2018\", \"Jan 03, 2018\"),",
          "",
          "[Removed Lines]",
          "30:     (\"2\", \"2.4.0\", \"Supported\", \"Dec 17, 2020\", \"TBD\", \"TBD\"),",
          "",
          "[Added Lines]",
          "30:     (\"2\", \"2.4.1\", \"Supported\", \"Dec 17, 2020\", \"TBD\", \"TBD\"),",
          "",
          "---------------"
        ],
        "setup.py||setup.py": [
          "File: setup.py -> setup.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "50: logger = logging.getLogger(__name__)",
          "54: AIRFLOW_SOURCES_ROOT = Path(__file__).parent.resolve()",
          "55: PROVIDERS_ROOT = AIRFLOW_SOURCES_ROOT / \"airflow\" / \"providers\"",
          "",
          "[Removed Lines]",
          "52: version = '2.4.0'",
          "",
          "[Added Lines]",
          "52: version = '2.4.1'",
          "",
          "---------------"
        ]
      }
    }
  ]
}