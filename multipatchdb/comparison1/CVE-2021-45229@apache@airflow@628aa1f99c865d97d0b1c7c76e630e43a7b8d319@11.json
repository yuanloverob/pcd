{
  "cve_id": "CVE-2021-45229",
  "cve_desc": "It was discovered that the \"Trigger DAG with config\" screen was susceptible to XSS attacks via the `origin` query argument. This issue affects Apache Airflow versions 2.2.3 and below.",
  "repo": "apache/airflow",
  "patch_hash": "628aa1f99c865d97d0b1c7c76e630e43a7b8d319",
  "patch_info": {
    "commit_hash": "628aa1f99c865d97d0b1c7c76e630e43a7b8d319",
    "repo": "apache/airflow",
    "commit_url": "https://github.com/apache/airflow/commit/628aa1f99c865d97d0b1c7c76e630e43a7b8d319",
    "files": [
      "airflow/www/templates/airflow/trigger.html",
      "tests/www/views/test_views_trigger_dag.py"
    ],
    "message": "Simplify trigger cancel button (#21591)\n\nCo-authored-by: Jed Cunningham <jedcunningham@apache.org>\n(cherry picked from commit 65297673a318660fba76797e50d0c06804dfcafc)",
    "before_after_code_files": [
      "airflow/www/templates/airflow/trigger.html||airflow/www/templates/airflow/trigger.html",
      "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py"
    ]
  },
  "patch_diff": {
    "airflow/www/templates/airflow/trigger.html||airflow/www/templates/airflow/trigger.html": [
      "File: airflow/www/templates/airflow/trigger.html -> airflow/www/templates/airflow/trigger.html",
      "--- Hunk 1 ---",
      "[Context before]",
      "63:       </label>",
      "64:     </div>",
      "65:     <button type=\"submit\" class=\"btn btn-primary\">Trigger</button>",
      "67:   </form>",
      "68: {% endblock %}",
      "",
      "[Removed Lines]",
      "66:     <button type=\"button\" class=\"btn\" onclick=\"location.href = '{{ origin }}'; return false\">Cancel</button>",
      "",
      "[Added Lines]",
      "66:     <a class=\"btn\" href=\"{{ origin }}\">Cancel</a>",
      "",
      "---------------"
    ],
    "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py": [
      "File: tests/www/views/test_views_trigger_dag.py -> tests/www/views/test_views_trigger_dag.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "133:         (\"javascript:alert(1)\", \"/home\"),",
      "134:         (\"http://google.com\", \"/home\"),",
      "135:         (\"36539'%3balert(1)%2f%2f166\", \"/home\"),",
      "136:         (",
      "137:             \"%2Ftree%3Fdag_id%3Dexample_bash_operator';alert(33)//\",",
      "138:             \"/home\",",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "136:         (",
      "137:             '\"><script>alert(99)</script><a href=\"',",
      "138:             \"&#34;&gt;&lt;script&gt;alert(99)&lt;/script&gt;&lt;a href=&#34;\",",
      "139:         ),",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "145:     test_dag_id = \"example_bash_operator\"",
      "147:     resp = admin_client.get(f'trigger?dag_id={test_dag_id}&origin={test_origin}')",
      "156: @pytest.mark.parametrize(",
      "",
      "[Removed Lines]",
      "148:     check_content_in_response(",
      "149:         '<button type=\"button\" class=\"btn\" onclick=\"location.href = \\'{}\\'; return false\">'.format(",
      "150:             expected_origin",
      "151:         ),",
      "152:         resp,",
      "153:     )",
      "",
      "[Added Lines]",
      "152:     check_content_in_response(f'<a class=\"btn\" href=\"{expected_origin}\">Cancel</a>', resp)",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "f2fe0df6b3caa86a4315322264fad077f03b32e6",
      "candidate_info": {
        "commit_hash": "f2fe0df6b3caa86a4315322264fad077f03b32e6",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/f2fe0df6b3caa86a4315322264fad077f03b32e6",
        "files": [
          "airflow/models/taskinstance.py"
        ],
        "message": "Avoid deadlock when rescheduling task (#21362)\n\nThe scheduler job performs scheduling after locking the \"scheduled\"\nDagRun row for writing. This should prevent from modifying DagRun\nand related task instances by another scheduler or \"mini-scheduler\"\nrun after task is completed.\n\nHowever there is apparently one more case where the DagRun is being\nlocked by \"Task\" processes - namely when task throws\nAirflowRescheduleException. In this case a new \"TaskReschedule\"\nentity is inserted into the database and it also performs lock\non the DagRun (because TaskReschedule has \"DagRun\" relationship.\n\nThis PR modifies handling the AirflowRescheduleException to obtain the\nvery same DagRun lock before it attempts to insert TaskReschedule\nentity.\n\nSeems that TaskReschedule is the only one that has this relationship\nso likely all the misterious SchedulerJob deadlock cases we\nexperienced might be explained (and fixed) by this one.\n\nIt is likely that this one:\n\n* Fixes: #16982\n* Fixes: #19957\n\n(cherry picked from commit 6d110b565a505505351d1ff19592626fb24e4516)",
        "before_after_code_files": [
          "airflow/models/taskinstance.py||airflow/models/taskinstance.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/models/taskinstance.py||airflow/models/taskinstance.py": [
          "File: airflow/models/taskinstance.py -> airflow/models/taskinstance.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "93: from airflow.utils.platform import getuser",
          "94: from airflow.utils.retries import run_with_db_retries",
          "95: from airflow.utils.session import create_session, provide_session",
          "97: from airflow.utils.state import DagRunState, State",
          "98: from airflow.utils.timeout import timeout",
          "",
          "[Removed Lines]",
          "96: from airflow.utils.sqlalchemy import ExtendedJSON, UtcDateTime",
          "",
          "[Added Lines]",
          "96: from airflow.utils.sqlalchemy import ExtendedJSON, UtcDateTime, with_row_locks",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1657:         # Don't record reschedule request in test mode",
          "1658:         if test_mode:",
          "1659:             return",
          "1660:         self.refresh_from_db(session)",
          "1662:         self.end_date = timezone.utcnow()",
          "1663:         self.set_duration()",
          "1665:         # Log reschedule request",
          "1666:         session.add(",
          "1667:             TaskReschedule(",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1661:         from airflow.models.dagrun import DagRun  # Avoid circular import",
          "1668:         # Lock DAG run to be sure not to get into a deadlock situation when trying to insert",
          "1669:         # TaskReschedule which apparently also creates lock on corresponding DagRun entity",
          "1670:         with_row_locks(",
          "1671:             session.query(DagRun).filter_by(",
          "1672:                 dag_id=self.dag_id,",
          "1673:                 run_id=self.run_id,",
          "1674:             ),",
          "1675:             session=session,",
          "1676:         ).one()",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "989e73cd30ed9299a65ca1f5369ebdc8ed150b3b",
      "candidate_info": {
        "commit_hash": "989e73cd30ed9299a65ca1f5369ebdc8ed150b3b",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/989e73cd30ed9299a65ca1f5369ebdc8ed150b3b",
        "files": [
          "scripts/ci/testing/ci_run_airflow_testing.sh"
        ],
        "message": "Remove Integration tests from MSSQL on Public Runners (#20231)\n\nThe Integration tests with MSSQL often fail on Public\nRunners without a reason. The database becomes inaccessible and\nno logs are explaining what's going on. Its very likely however\nthat this is a memory-related issue (Integration tests take a\nlot of memory as they run a lot of extra containers.\n\nThose tests will eventually run on Self-hosted runner after merge\nand they are also run for Postgres/MySQL/SQlite so there is no\nneed to run them also for MSSQL if it causes random failures.\n\n(cherry picked from commit d1848bcf2460fa82cd6c1fc1e9e5f9b103d95479)",
        "before_after_code_files": [
          "scripts/ci/testing/ci_run_airflow_testing.sh||scripts/ci/testing/ci_run_airflow_testing.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "scripts/ci/testing/ci_run_airflow_testing.sh||scripts/ci/testing/ci_run_airflow_testing.sh": [
          "File: scripts/ci/testing/ci_run_airflow_testing.sh -> scripts/ci/testing/ci_run_airflow_testing.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "88:         echo \"${COLOR_YELLOW}Heavy tests will be run sequentially after parallel tests including cleaning up docker between tests${COLOR_RESET}\"",
          "89:         echo \"\"",
          "90:         if [[ ${test_types_to_run} == *\"Integration\"* ]]; then",
          "92:             test_types_to_run=\"${test_types_to_run//Integration/}\"",
          "94:         fi",
          "95:         if [[ ${BACKEND} == \"mssql\" || ${BACKEND} == \"mysql\" ]]; then",
          "96:             # For mssql/mysql - they take far more memory than postgres (or sqlite) - we skip the Provider",
          "",
          "[Removed Lines]",
          "91:             echo \"${COLOR_YELLOW}Remove Integration from tests_types_to_run and add them to sequential tests due to low memory.${COLOR_RESET}\"",
          "93:             sequential_tests+=(\"Integration\")",
          "",
          "[Added Lines]",
          "92:             if [[ ${BACKEND} == \"mssql\" ]]; then",
          "93:                 # Also for mssql we skip Integration tests altogether on Public Runners. Mssql uses far",
          "94:                 # too much memory and often shuts down and similarly as in case of Providers tests,",
          "95:                 # there is no need to run them also for MsSQL engine as those integration tests",
          "96:                 # are not really using any metadata-specific behaviour.",
          "97:                 # Those tests will run in `main` anyway.",
          "98:                 echo \"${COLOR_YELLOW}Do not run integration tests for mssql in small systems due to memory issues.${COLOR_RESET}\"",
          "99:             else",
          "100:                 echo \"${COLOR_YELLOW}Remove Integration from tests_types_to_run and add them to sequential tests due to low memory.${COLOR_RESET}\"",
          "101:                 sequential_tests+=(\"Integration\")",
          "102:             fi",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "a262d9cc84668ab6d3240525b551011fb4dfd98a",
      "candidate_info": {
        "commit_hash": "a262d9cc84668ab6d3240525b551011fb4dfd98a",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/a262d9cc84668ab6d3240525b551011fb4dfd98a",
        "files": [
          "setup.py"
        ],
        "message": "Temporary limit Pandas version (#21045)\n\nThis is likely only for couple of days to avoid test failures\nin `main`. When the 3.4.4 version of Flask Builder gets\nreleased we should be able to relax the limit as it will allow\nus to migrate to sqlalchemy 1.4\n\n(cherry picked from commit eac7cbe39341ef821eca8cb472a1f8e2a3876706)",
        "before_after_code_files": [
          "setup.py||setup.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "setup.py||setup.py": [
          "File: setup.py -> setup.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "176:         file.write(text)",
          "181: # 'Start dependencies group' and 'Start dependencies group' are mark for ./scripts/ci/check_order_setup.py",
          "182: # If you change this mark you should also change ./scripts/ci/check_order_setup.py",
          "",
          "[Removed Lines]",
          "179: pandas_requirement = 'pandas>=0.17.1, <2.0'",
          "",
          "[Added Lines]",
          "179: # We limit Pandas to <1.4 because Pandas 1.4 requires SQLAlchemy 1.4 which",
          "180: # We should remove the limits as soon as Flask App Builder releases version 3.4.4",
          "181: # Release candidate is there: https://pypi.org/project/Flask-AppBuilder/3.4.4rc1/",
          "182: pandas_requirement = 'pandas>=0.17.1, <1.4'",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "4ff0ab16868d7e7b765a4ab1d285088cd1f162fe",
      "candidate_info": {
        "commit_hash": "4ff0ab16868d7e7b765a4ab1d285088cd1f162fe",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/4ff0ab16868d7e7b765a4ab1d285088cd1f162fe",
        "files": [
          "setup.cfg"
        ],
        "message": "Limit SQLAlchemy to < 1.4.0 for 2.2.* line (#21235)\n\nThe recent release of FAB 3.4.4 has unblocked us from upgrading\nSQLAlchemy to 1.4.* version. We wanted to do it for quite some\ntime however upgrading to 1.4.* of sqlalchemy and allowing our\nusers to use it for 2.2.4 is a bit risky.\n\nWe are fixing resulting \"aftermath\" in the main branch and as\nof this commit there are two fixes merged and remaining MsSQL\nproblem. The MSSql problem does not affect 2.2.4 as MsSQL will\nbe available only starting from 2.3.0, however the two other\nproblems have shown that SQLAlchemy has a potential to break\nthings and we might want to test it more thoroughly before\nreleasing 2.3.0.\n\nThe problems in question are #21205 and #21228. Both were only\ntest problems but the indicate that there might be more hidden\nissues involved.\n\nIn order to limit risks, this PR proposes to limit SQLAlchemy\nfor 2.2.* to < 1.4.0. This will allow to upgrade FAB and\nrelated dependencies without opening up Airflow to upgrade to\nSQLAlchemy 1.4 (yet).",
        "before_after_code_files": [
          "setup.cfg||setup.cfg"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "setup.cfg||setup.cfg": [
          "File: setup.cfg -> setup.cfg",
          "--- Hunk 1 ---",
          "[Context before]",
          "145:     python3-openid~=3.2",
          "146:     rich>=9.2.0",
          "147:     setproctitle>=1.1.8, <2",
          "149:     sqlalchemy_jsonfield~=1.0",
          "150:     tabulate>=0.7.5, <0.9",
          "151:     tenacity>=6.2.0",
          "",
          "[Removed Lines]",
          "148:     sqlalchemy>=1.3.18",
          "",
          "[Added Lines]",
          "148:     sqlalchemy>=1.3.18, <1.4.0",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "5c078cda332d42baba72c985532e0060d30a31ef",
      "candidate_info": {
        "commit_hash": "5c078cda332d42baba72c985532e0060d30a31ef",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/5c078cda332d42baba72c985532e0060d30a31ef",
        "files": [
          "airflow/example_dags/example_passing_params_via_test_command.py",
          "airflow/example_dags/tutorial.py",
          "docs/apache-airflow/tutorial.rst",
          "tests/cli/commands/test_task_command.py"
        ],
        "message": "Update example DAGs (#21372)\n\n(cherry picked from commit 7a38ec2ad3b3bd6fda5e1ee9fe9e644ccb8b4c12)",
        "before_after_code_files": [
          "airflow/example_dags/example_passing_params_via_test_command.py||airflow/example_dags/example_passing_params_via_test_command.py",
          "airflow/example_dags/tutorial.py||airflow/example_dags/tutorial.py",
          "tests/cli/commands/test_task_command.py||tests/cli/commands/test_task_command.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/example_dags/example_passing_params_via_test_command.py||airflow/example_dags/example_passing_params_via_test_command.py": [
          "File: airflow/example_dags/example_passing_params_via_test_command.py -> airflow/example_dags/example_passing_params_via_test_command.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "68: ) as dag:",
          "69:     run_this = my_py_command(params={\"miff\": \"agg\"})",
          "72:         \"\"\"",
          "76:     )",
          "78:     also_run_this = BashOperator(",
          "79:         task_id='also_run_this',",
          "81:         params={\"miff\": \"agg\"},",
          "82:     )",
          "84:     env_var_test_task = print_env_vars()",
          "",
          "[Removed Lines]",
          "71:     my_templated_command = dedent(",
          "73:         echo \" 'foo was passed in via Airflow CLI Test command with value {{ params.foo }} \"",
          "74:         echo \" 'miff was passed in via BashOperator with value {{ params.miff }} \"",
          "75:     \"\"\"",
          "80:         bash_command=my_templated_command,",
          "",
          "[Added Lines]",
          "71:     my_command = dedent(",
          "72:         \"\"\"",
          "73:         echo \"'foo' was passed in via Airflow CLI Test command with value '$FOO'\"",
          "74:         echo \"'miff' was passed in via BashOperator with value '$MIFF'\"",
          "80:         bash_command=my_command,",
          "82:         env={\"FOO\": \"{{ params.foo }}\", \"MIFF\": \"{{ params.miff }}\"},",
          "",
          "---------------"
        ],
        "airflow/example_dags/tutorial.py||airflow/example_dags/tutorial.py": [
          "File: airflow/example_dags/tutorial.py -> airflow/example_dags/tutorial.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "109:     {% for i in range(5) %}",
          "110:         echo \"{{ ds }}\"",
          "111:         echo \"{{ macros.ds_add(ds, 7)}}\"",
          "113:     {% endfor %}",
          "114:     \"\"\"",
          "115:     )",
          "",
          "[Removed Lines]",
          "112:         echo \"{{ params.my_param }}\"",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "118:         task_id='templated',",
          "119:         depends_on_past=False,",
          "120:         bash_command=templated_command,",
          "122:     )",
          "123:     # [END jinja_template]",
          "",
          "[Removed Lines]",
          "121:         params={'my_param': 'Parameter I passed in'},",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "tests/cli/commands/test_task_command.py||tests/cli/commands/test_task_command.py": [
          "File: tests/cli/commands/test_task_command.py -> tests/cli/commands/test_task_command.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "264:         assert 'echo \"2016-01-01\"' in output",
          "265:         assert 'echo \"2016-01-08\"' in output",
          "268:     def test_cli_run_when_pickle_and_dag_cli_method_selected(self):",
          "269:         \"\"\"",
          "",
          "[Removed Lines]",
          "266:         assert 'echo \"Parameter I passed in\"' in output",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ]
      }
    }
  ]
}