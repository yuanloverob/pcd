{
  "cve_id": "CVE-2023-45348",
  "cve_desc": "Apache Airflow, versions 2.7.0 and 2.7.1, is affected by a vulnerability that allows an authenticated user to retrieve sensitive configuration information when the \"expose_config\" option is set to \"non-sensitive-only\". The `expose_config` option is False by default.\nIt is recommended to upgrade to a version that is not affected.",
  "repo": "apache/airflow",
  "patch_hash": "a4a0b5dd3d0ce05311c70bb9a32b66a650dbc0b4",
  "patch_info": {
    "commit_hash": "a4a0b5dd3d0ce05311c70bb9a32b66a650dbc0b4",
    "repo": "apache/airflow",
    "commit_url": "https://github.com/apache/airflow/commit/a4a0b5dd3d0ce05311c70bb9a32b66a650dbc0b4",
    "files": [
      "airflow/api_connexion/endpoints/config_endpoint.py",
      "airflow/configuration.py",
      "tests/api_connexion/endpoints/test_config_endpoint.py"
    ],
    "message": "Check if the lower of provided values are sensitives in config endpoint (#34712)\n\n* Check if the lower of provided values are sensitives in config endpoint\n\n* update unit test\n\n* ensure that all values in sensitive dict are in lower characters\n\n(cherry picked from commit f044589b685855a8fce8f5376bea2564c5a001f7)",
    "before_after_code_files": [
      "airflow/api_connexion/endpoints/config_endpoint.py||airflow/api_connexion/endpoints/config_endpoint.py",
      "airflow/configuration.py||airflow/configuration.py",
      "tests/api_connexion/endpoints/test_config_endpoint.py||tests/api_connexion/endpoints/test_config_endpoint.py"
    ]
  },
  "patch_diff": {
    "airflow/api_connexion/endpoints/config_endpoint.py||airflow/api_connexion/endpoints/config_endpoint.py": [
      "File: airflow/api_connexion/endpoints/config_endpoint.py -> airflow/api_connexion/endpoints/config_endpoint.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "123:                 \"Config not found.\", detail=f\"The option [{section}/{option}] is not found in config.\"",
      "124:             )",
      "127:             value = \"< hidden >\"",
      "128:         else:",
      "129:             value = conf.get(section, option)",
      "",
      "[Removed Lines]",
      "126:         if (section, option) in conf.sensitive_config_values:",
      "",
      "[Added Lines]",
      "126:         if (section.lower(), option.lower()) in conf.sensitive_config_values:",
      "",
      "---------------"
    ],
    "airflow/configuration.py||airflow/configuration.py": [
      "File: airflow/configuration.py -> airflow/configuration.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "311:             for s, s_c in self.configuration_description.items()",
      "312:             for k, item in s_c.get(\"options\").items()  # type: ignore[union-attr]",
      "313:         }",
      "315:         depr_option = {self.deprecated_options[x][:-1] for x in sensitive if x in self.deprecated_options}",
      "316:         depr_section = {",
      "317:             (self.deprecated_sections[s][0], k) for s, k in sensitive if s in self.deprecated_sections",
      "",
      "[Removed Lines]",
      "314:         sensitive = {(section, key) for (section, key), v in flattened.items() if v.get(\"sensitive\") is True}",
      "",
      "[Added Lines]",
      "314:         sensitive = {",
      "315:             (section.lower(), key.lower())",
      "316:             for (section, key), v in flattened.items()",
      "317:             if v.get(\"sensitive\") is True",
      "318:         }",
      "",
      "---------------"
    ],
    "tests/api_connexion/endpoints/test_config_endpoint.py||tests/api_connexion/endpoints/test_config_endpoint.py": [
      "File: tests/api_connexion/endpoints/test_config_endpoint.py -> tests/api_connexion/endpoints/test_config_endpoint.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "247:         return_value=MOCK_CONF_WITH_SENSITIVE_VALUE,",
      "248:     )",
      "249:     @conf_vars({(\"webserver\", \"expose_config\"): \"non-sensitive-only\"})",
      "251:         response = self.client.get(",
      "253:             headers={\"Accept\": \"text/plain\"},",
      "254:             environ_overrides={\"REMOTE_USER\": \"test\"},",
      "255:         )",
      "256:         assert response.status_code == 200",
      "257:         expected = textwrap.dedent(",
      "261:         \"\"\"",
      "262:         )",
      "263:         assert expected == response.data.decode()",
      "",
      "[Removed Lines]",
      "250:     def test_should_respond_200_text_plain_with_non_sensitive_only(self, mock_as_dict):",
      "252:             \"/api/v1/config/section/core/option/sql_alchemy_conn\",",
      "258:             \"\"\"\\",
      "259:         [core]",
      "260:         sql_alchemy_conn = < hidden >",
      "",
      "[Added Lines]",
      "250:     @pytest.mark.parametrize(",
      "251:         \"section, option\",",
      "252:         [",
      "253:             (\"core\", \"sql_alchemy_conn\"),",
      "254:             (\"core\", \"SQL_ALCHEMY_CONN\"),",
      "255:             (\"corE\", \"sql_alchemy_conn\"),",
      "256:             (\"CORE\", \"sql_alchemy_conn\"),",
      "257:         ],",
      "258:     )",
      "259:     def test_should_respond_200_text_plain_with_non_sensitive_only(self, mock_as_dict, section, option):",
      "261:             f\"/api/v1/config/section/{section}/option/{option}\",",
      "267:             f\"\"\"\\",
      "268:         [{section}]",
      "269:         {option} = < hidden >",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "2f2d73c9fe79689dac87f3813606552d61f1a48f",
      "candidate_info": {
        "commit_hash": "2f2d73c9fe79689dac87f3813606552d61f1a48f",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/2f2d73c9fe79689dac87f3813606552d61f1a48f",
        "files": [
          "airflow/api/common/experimental/get_lineage.py",
          "airflow/models/dagrun.py",
          "airflow/operators/python.py",
          "airflow/www/decorators.py",
          "airflow/www/views.py"
        ],
        "message": "Replace unnecessary dict comprehension with dict() in core (#33858)\n\nCo-authored-by: Tzu-ping Chung <uranusjr@gmail.com>\n(cherry picked from commit 6a33d058a14cefe054c5aa4a683124220b53f005)",
        "before_after_code_files": [
          "airflow/api/common/experimental/get_lineage.py||airflow/api/common/experimental/get_lineage.py",
          "airflow/models/dagrun.py||airflow/models/dagrun.py",
          "airflow/operators/python.py||airflow/operators/python.py",
          "airflow/www/decorators.py||airflow/www/decorators.py",
          "airflow/www/views.py||airflow/www/views.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/34775"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/api/common/experimental/get_lineage.py||airflow/api/common/experimental/get_lineage.py": [
          "File: airflow/api/common/experimental/get_lineage.py -> airflow/api/common/experimental/get_lineage.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "47:     for meta in outlets:",
          "48:         lineage[meta.task_id][\"outlets\"] = meta.value",
          "",
          "[Removed Lines]",
          "50:     return {\"task_ids\": {k: v for k, v in lineage.items()}}",
          "",
          "[Added Lines]",
          "50:     return {\"task_ids\": dict(lineage)}",
          "",
          "---------------"
        ],
        "airflow/models/dagrun.py||airflow/models/dagrun.py": [
          "File: airflow/models/dagrun.py -> airflow/models/dagrun.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "303:         else:",
          "304:             query = query.where(cls.state.in_((DagRunState.RUNNING, DagRunState.QUEUED)))",
          "305:         query = query.group_by(cls.dag_id)",
          "308:     @classmethod",
          "309:     def next_dagruns_to_examine(",
          "",
          "[Removed Lines]",
          "306:         return {dag_id: count for dag_id, count in session.execute(query)}",
          "",
          "[Added Lines]",
          "306:         return dict(iter(session.execute(query)))",
          "",
          "---------------"
        ],
        "airflow/operators/python.py||airflow/operators/python.py": [
          "File: airflow/operators/python.py -> airflow/operators/python.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "419:         return super().__deepcopy__(memo)",
          "421:     def _execute_python_callable_in_subprocess(self, python_path: Path, tmp_dir: Path):",
          "423:         if self.templates_dict:",
          "424:             op_kwargs[\"templates_dict\"] = self.templates_dict",
          "425:         input_path = tmp_dir / \"script.in\"",
          "",
          "[Removed Lines]",
          "422:         op_kwargs: dict[str, Any] = {k: v for k, v in self.op_kwargs.items()}",
          "",
          "[Added Lines]",
          "422:         op_kwargs: dict[str, Any] = dict(self.op_kwargs)",
          "",
          "---------------"
        ],
        "airflow/www/decorators.py||airflow/www/decorators.py": [
          "File: airflow/www/decorators.py -> airflow/www/decorators.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "102:                 if event and event.startswith(\"connection.\"):",
          "103:                     extra_fields = _mask_connection_fields(extra_fields)",
          "107:                 log = Log(",
          "108:                     event=event or f.__name__,",
          "",
          "[Removed Lines]",
          "105:                 params = {k: v for k, v in itertools.chain(request.values.items(), request.view_args.items())}",
          "",
          "[Added Lines]",
          "105:                 params = {**request.values, **request.view_args}",
          "",
          "---------------"
        ],
        "airflow/www/views.py||airflow/www/views.py": [
          "File: airflow/www/views.py -> airflow/www/views.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "4653:                 select(Connection.conn_id).where(Connection.conn_id.in_(potential_connection_ids))",
          "4654:             )",
          "4658:             possible_conn_id_iter = (",
          "4659:                 connection_id",
          "",
          "[Removed Lines]",
          "4656:             found_conn_id_set = {conn_id for conn_id in query}",
          "",
          "[Added Lines]",
          "4656:             found_conn_id_set = set(query)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "2a47ffbd9f0988356b8b90288c2bbbab792c01cd",
      "candidate_info": {
        "commit_hash": "2a47ffbd9f0988356b8b90288c2bbbab792c01cd",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/2a47ffbd9f0988356b8b90288c2bbbab792c01cd",
        "files": [
          "airflow/utils/state.py",
          "tests/www/views/test_views_cluster_activity.py"
        ],
        "message": "Bring back SHUTDOWN-related constants (#34063)\n\nThis should restore code compatibility to 2.6 and prior. Note that the\nconstants would not appear in documentation since they are deprecated\nand not use in Airflow core anyway anymore.\n\n(cherry picked from commit 1ae29769cea047d01c22089d24772be5e56e3b50)",
        "before_after_code_files": [
          "airflow/utils/state.py||airflow/utils/state.py",
          "tests/www/views/test_views_cluster_activity.py||tests/www/views/test_views_cluster_activity.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/34775"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/utils/state.py||airflow/utils/state.py": [
          "File: airflow/utils/state.py -> airflow/utils/state.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "58:     SKIPPED = \"skipped\"  # Skipped by branching or some other mechanism",
          "59:     DEFERRED = \"deferred\"  # Deferrable operator waiting on a trigger",
          "61:     def __str__(self) -> str:",
          "62:         return self.value",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "61:     # Not used anymore, kept for compatibility.",
          "62:     # TODO: Remove in Airflow 3.0.",
          "63:     SHUTDOWN = \"shutdown\"",
          "64:     \"\"\"The task instance is being shut down.",
          "66:     :meta private:",
          "67:     \"\"\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "100:     SKIPPED = TaskInstanceState.SKIPPED",
          "101:     DEFERRED = TaskInstanceState.DEFERRED",
          "103:     finished_dr_states: frozenset[DagRunState] = frozenset([DagRunState.SUCCESS, DagRunState.FAILED])",
          "104:     unfinished_dr_states: frozenset[DagRunState] = frozenset([DagRunState.QUEUED, DagRunState.RUNNING])",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "111:     # Not used anymore, kept for compatibility.",
          "112:     # TODO: Remove in Airflow 3.0.",
          "113:     SHUTDOWN = TaskInstanceState.SHUTDOWN",
          "114:     \"\"\"The task instance is being shut down.",
          "116:     :meta private:",
          "117:     \"\"\"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "190:     A list of states indicating that a task or dag is a success state.",
          "191:     \"\"\"",
          "193:     adoptable_states = frozenset(",
          "194:         [TaskInstanceState.QUEUED, TaskInstanceState.RUNNING, TaskInstanceState.RESTARTING]",
          "195:     )",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "209:     # Kept for compatibility. DO NOT USE.",
          "210:     # TODO: Remove in Airflow 3.0.",
          "211:     terminating_states = frozenset([TaskInstanceState.SHUTDOWN, TaskInstanceState.RESTARTING])",
          "212:     \"\"\"",
          "213:     A list of states indicating that a task has been terminated.",
          "215:     :meta private:",
          "216:     \"\"\"",
          "",
          "---------------"
        ],
        "tests/www/views/test_views_cluster_activity.py||tests/www/views/test_views_cluster_activity.py": [
          "File: tests/www/views/test_views_cluster_activity.py -> tests/www/views/test_views_cluster_activity.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "115:             \"restarting\": 0,",
          "116:             \"running\": 0,",
          "117:             \"scheduled\": 0,",
          "118:             \"skipped\": 0,",
          "119:             \"success\": 2,",
          "120:             \"up_for_reschedule\": 0,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "118:             \"shutdown\": 0,",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "143:             \"restarting\": 0,",
          "144:             \"running\": 0,",
          "145:             \"scheduled\": 0,",
          "146:             \"skipped\": 0,",
          "147:             \"success\": 0,",
          "148:             \"up_for_reschedule\": 0,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "147:             \"shutdown\": 0,",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "9f369ba41d12409524053dc1c14c9f8e3b5608b1",
      "candidate_info": {
        "commit_hash": "9f369ba41d12409524053dc1c14c9f8e3b5608b1",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/9f369ba41d12409524053dc1c14c9f8e3b5608b1",
        "files": [
          "airflow/www/views.py"
        ],
        "message": "Replace assert by if...raise in www package (#34249)\n\n(cherry picked from commit 7b4fc3933bd1bbcf79acef32f00ba8981ea271b3)",
        "before_after_code_files": [
          "airflow/www/views.py||airflow/www/views.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/34775"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/www/views.py||airflow/www/views.py": [
          "File: airflow/www/views.py -> airflow/www/views.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "2289:         except AirflowException as ex:",
          "2290:             return redirect_or_json(origin, msg=str(ex), status=\"error\", status_code=500)",
          "2293:         details = [str(t) for t in tis]",
          "2295:         if not details:",
          "",
          "[Removed Lines]",
          "2292:         assert isinstance(tis, collections.abc.Iterable)",
          "",
          "[Added Lines]",
          "2292:         if not isinstance(tis, collections.abc.Iterable):",
          "2293:             raise AssertionError(",
          "2294:                 f\"Expected dag.clear() to return an iterable for dry runs, got {tis} instead.\"",
          "2295:             )",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "eb77d9372aaacf81e6444714c9270e7fd384b1b8",
      "candidate_info": {
        "commit_hash": "eb77d9372aaacf81e6444714c9270e7fd384b1b8",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/eb77d9372aaacf81e6444714c9270e7fd384b1b8",
        "files": [
          "airflow/metrics/validators.py",
          "airflow/utils/setup_teardown.py"
        ],
        "message": "Change \"not all\" to \"any\" for ease of readability (#34259)\n\n(cherry picked from commit 21ac3b92d2213b631c918f851974701fa5d55956)",
        "before_after_code_files": [
          "airflow/metrics/validators.py||airflow/metrics/validators.py",
          "airflow/utils/setup_teardown.py||airflow/utils/setup_teardown.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/34775"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/metrics/validators.py||airflow/metrics/validators.py": [
          "File: airflow/metrics/validators.py -> airflow/metrics/validators.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "178:         raise InvalidStatsNameException(",
          "179:             f\"The stat_name ({stat_name}) has to be less than {max_length} characters.\"",
          "180:         )",
          "182:         raise InvalidStatsNameException(",
          "183:             f\"The stat name ({stat_name}) has to be composed of ASCII \"",
          "184:             f\"alphabets, numbers, or the underscore, dot, or dash characters.\"",
          "",
          "[Removed Lines]",
          "181:     if not all((c in allowed_chars) for c in stat_name):",
          "",
          "[Added Lines]",
          "181:     if any(c not in allowed_chars for c in stat_name):",
          "",
          "---------------"
        ],
        "airflow/utils/setup_teardown.py||airflow/utils/setup_teardown.py": [
          "File: airflow/utils/setup_teardown.py -> airflow/utils/setup_teardown.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "168:     @classmethod",
          "169:     def _push_tasks(cls, operator: AbstractOperator | list[AbstractOperator], setup: bool = False):",
          "170:         if isinstance(operator, list):",
          "172:                 cls.error(\"All tasks in the list must be either setup or teardown tasks\")",
          "173:         if setup:",
          "174:             cls.push_context_managed_setup_task(operator)",
          "",
          "[Removed Lines]",
          "171:             if not all(task.is_setup == operator[0].is_setup for task in operator):",
          "",
          "[Added Lines]",
          "171:             if any(task.is_setup != operator[0].is_setup for task in operator):",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "f6e052b7633da4d9b4ec395c9f74500809f1aa53",
      "candidate_info": {
        "commit_hash": "f6e052b7633da4d9b4ec395c9f74500809f1aa53",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/f6e052b7633da4d9b4ec395c9f74500809f1aa53",
        "files": [
          "airflow/providers/amazon/aws/hooks/base_aws.py",
          "airflow/providers/amazon/aws/operators/glue.py",
          "airflow/providers/amazon/aws/transfers/dynamodb_to_s3.py",
          "airflow/providers/ftp/hooks/ftp.py",
          "airflow/providers/google/cloud/example_dags/example_cloud_sql_query.py",
          "airflow/providers/google/cloud/hooks/cloud_sql.py",
          "airflow/providers/google/cloud/hooks/gcs.py",
          "airflow/providers/google/cloud/utils/credentials_provider.py",
          "airflow/www/extensions/init_views.py",
          "dev/provider_packages/prepare_provider_packages.py",
          "docs/exts/exampleinclude.py",
          "scripts/ci/pre_commit/pre_commit_check_order_setup.py",
          "scripts/ci/pre_commit/pre_commit_check_setup_extra_packages_ref.py",
          "scripts/ci/pre_commit/pre_commit_inline_scripts_in_docker.py",
          "scripts/in_container/update_quarantined_test_status.py",
          "setup.py",
          "tests/providers/google/cloud/operators/test_dataprep_system.py",
          "tests/system/providers/amazon/aws/example_google_api_sheets_to_s3.py",
          "tests/system/providers/amazon/aws/utils/__init__.py",
          "tests/utils/test_file.py"
        ],
        "message": "Consolidate importing of os.path.* (#34060)\n\nCo-authored-by: Tzu-ping Chung <uranusjr@gmail.com>\n(cherry picked from commit 907909329195c6655d1e2989b05609466ef50563)",
        "before_after_code_files": [
          "airflow/providers/amazon/aws/hooks/base_aws.py||airflow/providers/amazon/aws/hooks/base_aws.py",
          "airflow/providers/amazon/aws/operators/glue.py||airflow/providers/amazon/aws/operators/glue.py",
          "airflow/providers/amazon/aws/transfers/dynamodb_to_s3.py||airflow/providers/amazon/aws/transfers/dynamodb_to_s3.py",
          "airflow/providers/ftp/hooks/ftp.py||airflow/providers/ftp/hooks/ftp.py",
          "airflow/providers/google/cloud/example_dags/example_cloud_sql_query.py||airflow/providers/google/cloud/example_dags/example_cloud_sql_query.py",
          "airflow/providers/google/cloud/hooks/cloud_sql.py||airflow/providers/google/cloud/hooks/cloud_sql.py",
          "airflow/providers/google/cloud/hooks/gcs.py||airflow/providers/google/cloud/hooks/gcs.py",
          "airflow/providers/google/cloud/utils/credentials_provider.py||airflow/providers/google/cloud/utils/credentials_provider.py",
          "airflow/www/extensions/init_views.py||airflow/www/extensions/init_views.py",
          "dev/provider_packages/prepare_provider_packages.py||dev/provider_packages/prepare_provider_packages.py",
          "scripts/ci/pre_commit/pre_commit_check_order_setup.py||scripts/ci/pre_commit/pre_commit_check_order_setup.py",
          "scripts/ci/pre_commit/pre_commit_check_setup_extra_packages_ref.py||scripts/ci/pre_commit/pre_commit_check_setup_extra_packages_ref.py",
          "scripts/ci/pre_commit/pre_commit_inline_scripts_in_docker.py||scripts/ci/pre_commit/pre_commit_inline_scripts_in_docker.py",
          "scripts/in_container/update_quarantined_test_status.py||scripts/in_container/update_quarantined_test_status.py",
          "setup.py||setup.py",
          "tests/providers/google/cloud/operators/test_dataprep_system.py||tests/providers/google/cloud/operators/test_dataprep_system.py",
          "tests/system/providers/amazon/aws/example_google_api_sheets_to_s3.py||tests/system/providers/amazon/aws/example_google_api_sheets_to_s3.py",
          "tests/system/providers/amazon/aws/utils/__init__.py||tests/system/providers/amazon/aws/utils/__init__.py",
          "tests/utils/test_file.py||tests/utils/test_file.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/34775"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/providers/amazon/aws/hooks/base_aws.py||airflow/providers/amazon/aws/hooks/base_aws.py": [
          "File: airflow/providers/amazon/aws/hooks/base_aws.py -> airflow/providers/amazon/aws/hooks/base_aws.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "33: import warnings",
          "34: from copy import deepcopy",
          "35: from functools import cached_property, wraps",
          "37: from pathlib import Path",
          "38: from typing import TYPE_CHECKING, Any, Callable, Generic, TypeVar, Union",
          "",
          "[Removed Lines]",
          "36: from os import PathLike",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "827:             return False, str(f\"{type(e).__name__!r} error occurred while testing connection: {e}\")",
          "829:     @cached_property",
          "831:         filename = self.client_type if self.client_type else self.resource_type",
          "832:         path = Path(__file__).parents[1].joinpath(f\"waiters/{filename}.json\").resolve()",
          "833:         return path if path.exists() else None",
          "",
          "[Removed Lines]",
          "830:     def waiter_path(self) -> PathLike[str] | None:",
          "",
          "[Added Lines]",
          "829:     def waiter_path(self) -> os.PathLike[str] | None:",
          "",
          "---------------"
        ],
        "airflow/providers/amazon/aws/operators/glue.py||airflow/providers/amazon/aws/operators/glue.py": [
          "File: airflow/providers/amazon/aws/operators/glue.py -> airflow/providers/amazon/aws/operators/glue.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: # under the License.",
          "18: from __future__ import annotations",
          "21: import urllib.parse",
          "22: from functools import cached_property",
          "23: from typing import TYPE_CHECKING, Sequence",
          "",
          "[Removed Lines]",
          "20: import os.path",
          "",
          "[Added Lines]",
          "20: import os",
          "",
          "---------------"
        ],
        "airflow/providers/amazon/aws/transfers/dynamodb_to_s3.py||airflow/providers/amazon/aws/transfers/dynamodb_to_s3.py": [
          "File: airflow/providers/amazon/aws/transfers/dynamodb_to_s3.py -> airflow/providers/amazon/aws/transfers/dynamodb_to_s3.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: from __future__ import annotations",
          "21: import json",
          "22: from copy import copy",
          "23: from datetime import datetime",
          "24: from decimal import Decimal",
          "25: from functools import cached_property",
          "27: from tempfile import NamedTemporaryFile",
          "28: from typing import IO, TYPE_CHECKING, Any, Callable, Sequence",
          "29: from uuid import uuid4",
          "",
          "[Removed Lines]",
          "26: from os.path import getsize",
          "",
          "[Added Lines]",
          "22: import os",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "197:             scan_kwargs[\"ExclusiveStartKey\"] = last_evaluated_key",
          "199:             # Upload the file to S3 if reach file size limit",
          "201:                 _upload_file_to_s3(temp_file, self.s3_bucket_name, self.s3_key_prefix, self.dest_aws_conn_id)",
          "202:                 temp_file.close()",
          "",
          "[Removed Lines]",
          "200:             if getsize(temp_file.name) >= self.file_size:",
          "",
          "[Added Lines]",
          "200:             if os.path.getsize(temp_file.name) >= self.file_size:",
          "",
          "---------------"
        ],
        "airflow/providers/ftp/hooks/ftp.py||airflow/providers/ftp/hooks/ftp.py": [
          "File: airflow/providers/ftp/hooks/ftp.py -> airflow/providers/ftp/hooks/ftp.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: import datetime",
          "21: import ftplib",
          "23: from typing import Any, Callable",
          "25: from airflow.hooks.base import BaseHook",
          "",
          "[Removed Lines]",
          "22: import os.path",
          "",
          "[Added Lines]",
          "22: import os",
          "",
          "---------------"
        ],
        "airflow/providers/google/cloud/example_dags/example_cloud_sql_query.py||airflow/providers/google/cloud/example_dags/example_cloud_sql_query.py": [
          "File: airflow/providers/google/cloud/example_dags/example_cloud_sql_query.py -> airflow/providers/google/cloud/example_dags/example_cloud_sql_query.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "40: import os",
          "41: import subprocess",
          "42: from datetime import datetime",
          "44: from urllib.parse import quote_plus",
          "46: from airflow import models",
          "",
          "[Removed Lines]",
          "43: from os.path import expanduser",
          "",
          "[Added Lines]",
          "43: from pathlib import Path",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "88: # [START howto_operator_cloudsql_query_connections]",
          "93: def get_absolute_path(path):",
          "94:     \"\"\"",
          "95:     Returns absolute path.",
          "96:     \"\"\"",
          "103: postgres_kwargs = dict(",
          "",
          "[Removed Lines]",
          "90: HOME_DIR = expanduser(\"~\")",
          "97:     if path.startswith(\"/\"):",
          "98:         return path",
          "99:     else:",
          "100:         return os.path.join(HOME_DIR, path)",
          "",
          "[Added Lines]",
          "90: HOME_DIR = Path.home()",
          "97:     return os.fspath(HOME_DIR / path)",
          "",
          "---------------"
        ],
        "airflow/providers/google/cloud/hooks/cloud_sql.py||airflow/providers/google/cloud/hooks/cloud_sql.py": [
          "File: airflow/providers/google/cloud/hooks/cloud_sql.py -> airflow/providers/google/cloud/hooks/cloud_sql.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: import errno",
          "22: import json",
          "23: import os",
          "25: import platform",
          "26: import random",
          "27: import re",
          "",
          "[Removed Lines]",
          "24: import os.path",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "airflow/providers/google/cloud/hooks/gcs.py||airflow/providers/google/cloud/hooks/gcs.py": [
          "File: airflow/providers/google/cloud/hooks/gcs.py -> airflow/providers/google/cloud/hooks/gcs.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "29: from datetime import datetime",
          "30: from functools import partial",
          "31: from io import BytesIO",
          "33: from tempfile import NamedTemporaryFile",
          "34: from typing import IO, Any, Callable, Generator, Sequence, TypeVar, cast, overload",
          "35: from urllib.parse import urlsplit",
          "",
          "[Removed Lines]",
          "32: from os import path",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1294:         self, blob: storage.Blob, destination_object: str | None, source_object_prefix_len: int",
          "1295:     ) -> str:",
          "1296:         return (",
          "1298:             if destination_object",
          "1299:             else blob.name[source_object_prefix_len:]",
          "1300:         )",
          "",
          "[Removed Lines]",
          "1297:             path.join(destination_object, blob.name[source_object_prefix_len:])",
          "",
          "[Added Lines]",
          "1296:             os.path.join(destination_object, blob.name[source_object_prefix_len:])",
          "",
          "---------------"
        ],
        "airflow/providers/google/cloud/utils/credentials_provider.py||airflow/providers/google/cloud/utils/credentials_provider.py": [
          "File: airflow/providers/google/cloud/utils/credentials_provider.py -> airflow/providers/google/cloud/utils/credentials_provider.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: import json",
          "23: import logging",
          "25: import tempfile",
          "26: from contextlib import ExitStack, contextmanager",
          "27: from typing import Collection, Generator, Sequence",
          "",
          "[Removed Lines]",
          "24: import os.path",
          "",
          "[Added Lines]",
          "24: import os",
          "",
          "---------------"
        ],
        "airflow/www/extensions/init_views.py||airflow/www/extensions/init_views.py": [
          "File: airflow/www/extensions/init_views.py -> airflow/www/extensions/init_views.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: from __future__ import annotations",
          "19: import logging",
          "20: import warnings",
          "21: from functools import cached_property",
          "23: from typing import TYPE_CHECKING",
          "25: from connexion import FlaskApi, ProblemException, Resolver",
          "",
          "[Removed Lines]",
          "22: from os import path",
          "",
          "[Added Lines]",
          "20: import os",
          "23: from pathlib import Path",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "39: log = logging.getLogger(__name__)",
          "41: # airflow/www/extensions/init_views.py => airflow/",
          "45: def init_flash_views(app):",
          "",
          "[Removed Lines]",
          "42: ROOT_APP_DIR = path.abspath(path.join(path.dirname(__file__), path.pardir, path.pardir))",
          "",
          "[Added Lines]",
          "43: ROOT_APP_DIR = Path(__file__).parents[2].resolve()",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "253:         else:",
          "254:             return views.method_not_allowed(ex)",
          "257:         specification = safe_load(f)",
          "258:     api_bp = FlaskApi(",
          "259:         specification=specification,",
          "",
          "[Removed Lines]",
          "256:     with open(path.join(ROOT_APP_DIR, \"api_connexion\", \"openapi\", \"v1.yaml\")) as f:",
          "",
          "[Added Lines]",
          "257:     with ROOT_APP_DIR.joinpath(\"api_connexion\", \"openapi\", \"v1.yaml\").open() as f:",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "261:         base_path=base_path,",
          "262:         options={",
          "263:             \"swagger_ui\": conf.getboolean(\"webserver\", \"enable_swagger_ui\", fallback=True),",
          "265:         },",
          "266:         strict_validation=True,",
          "267:         validate_responses=True,",
          "",
          "[Removed Lines]",
          "264:             \"swagger_path\": path.join(ROOT_APP_DIR, \"www\", \"static\", \"dist\", \"swagger-ui\"),",
          "",
          "[Added Lines]",
          "265:             \"swagger_path\": os.fspath(ROOT_APP_DIR.joinpath(\"www\", \"static\", \"dist\", \"swagger-ui\")),",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "279:     if not standalone_api and not conf.getboolean(\"webserver\", \"run_internal_api\", fallback=False):",
          "280:         return",
          "283:         specification = safe_load(f)",
          "284:     api_bp = FlaskApi(",
          "285:         specification=specification,",
          "",
          "[Removed Lines]",
          "282:     with open(path.join(ROOT_APP_DIR, \"api_internal\", \"openapi\", \"internal_api_v1.yaml\")) as f:",
          "",
          "[Added Lines]",
          "283:     with ROOT_APP_DIR.joinpath(\"api_internal\", \"openapi\", \"internal_api_v1.yaml\").open() as f:",
          "",
          "---------------"
        ],
        "dev/provider_packages/prepare_provider_packages.py||dev/provider_packages/prepare_provider_packages.py": [
          "File: dev/provider_packages/prepare_provider_packages.py -> dev/provider_packages/prepare_provider_packages.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "37: from datetime import datetime, timedelta",
          "38: from enum import Enum",
          "39: from functools import lru_cache",
          "41: from pathlib import Path",
          "42: from random import choice",
          "43: from shutil import copyfile",
          "",
          "[Removed Lines]",
          "40: from os.path import dirname, relpath",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "262:     :return: the folder path",
          "263:     \"\"\"",
          "267: def get_target_providers_folder() -> str:",
          "",
          "[Removed Lines]",
          "264:     return os.path.abspath(os.path.join(dirname(__file__), os.pardir, os.pardir, \"provider_packages\"))",
          "",
          "[Added Lines]",
          "263:     return os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir, os.pardir, \"provider_packages\"))",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "1156:         \"PIP_REQUIREMENTS_TABLE\": pip_requirements_table,",
          "1157:         \"PIP_REQUIREMENTS_TABLE_RST\": pip_requirements_table_rst,",
          "1158:         \"PROVIDER_INFO\": provider_info,",
          "1160:             provider_details.source_provider_package_path,",
          "1161:             provider_details.documentation_provider_package_path,",
          "1162:         ),",
          "",
          "[Removed Lines]",
          "1159:         \"CHANGELOG_RELATIVE_PATH\": relpath(",
          "",
          "[Added Lines]",
          "1158:         \"CHANGELOG_RELATIVE_PATH\": os.path.relpath(",
          "",
          "---------------"
        ],
        "scripts/ci/pre_commit/pre_commit_check_order_setup.py||scripts/ci/pre_commit/pre_commit_check_order_setup.py": [
          "File: scripts/ci/pre_commit/pre_commit_check_order_setup.py -> scripts/ci/pre_commit/pre_commit_check_order_setup.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "26: import re",
          "27: import sys",
          "28: import textwrap",
          "31: from rich import print",
          "33: errors: list[str] = []",
          "40: class ConsoleDiff(difflib.Differ):",
          "",
          "[Removed Lines]",
          "29: from os.path import abspath, dirname",
          "35: MY_DIR_PATH = os.path.dirname(__file__)",
          "36: SOURCE_DIR_PATH = os.path.abspath(os.path.join(MY_DIR_PATH, os.pardir, os.pardir, os.pardir))",
          "37: sys.path.insert(0, SOURCE_DIR_PATH)",
          "",
          "[Added Lines]",
          "29: from pathlib import Path",
          "35: SOURCE_DIR_PATH = Path(__file__).parents[3].resolve()",
          "36: sys.path.insert(0, os.fspath(SOURCE_DIR_PATH))",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "125:     from setuptools.config import read_configuration",
          "128:     config = read_configuration(path)",
          "130:     pattern_dependent_version = re.compile(\"[~|><=;].*\")",
          "",
          "[Removed Lines]",
          "127:     path = abspath(os.path.join(dirname(__file__), os.pardir, os.pardir, os.pardir, \"setup.cfg\"))",
          "",
          "[Added Lines]",
          "126:     path = os.fspath(SOURCE_DIR_PATH / \"setup.cfg\")",
          "",
          "---------------"
        ],
        "scripts/ci/pre_commit/pre_commit_check_setup_extra_packages_ref.py||scripts/ci/pre_commit/pre_commit_check_setup_extra_packages_ref.py": [
          "File: scripts/ci/pre_commit/pre_commit_check_setup_extra_packages_ref.py -> scripts/ci/pre_commit/pre_commit_check_setup_extra_packages_ref.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "24: import os",
          "25: import re",
          "26: import sys",
          "29: from rich import print",
          "30: from rich.console import Console",
          "31: from rich.table import Table",
          "34: SETUP_PY_FILE = \"setup.py\"",
          "35: DOCS_FILE = os.path.join(\"docs\", \"apache-airflow\", \"extra-packages-ref.rst\")",
          "36: PY_IDENTIFIER = r\"[a-zA-Z_][a-zA-Z0-9_\\.]*\"",
          "40: os.environ[\"_SKIP_PYTHON_VERSION_CHECK\"] = \"true\"",
          "",
          "[Removed Lines]",
          "27: from os.path import dirname",
          "33: AIRFLOW_SOURCES_DIR = os.path.join(dirname(__file__), os.pardir, os.pardir, os.pardir)",
          "38: sys.path.insert(0, AIRFLOW_SOURCES_DIR)",
          "",
          "[Added Lines]",
          "27: from pathlib import Path",
          "33: AIRFLOW_SOURCES_DIR = Path(__file__).parents[3].resolve()",
          "38: sys.path.insert(0, os.fspath(AIRFLOW_SOURCES_DIR))",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "51: def get_file_content(*path_elements: str) -> str:",
          "57: def get_extras_from_setup() -> set[str]:",
          "",
          "[Removed Lines]",
          "52:     file_path = os.path.join(AIRFLOW_SOURCES_DIR, *path_elements)",
          "53:     with open(file_path) as file_to_read:",
          "54:         return file_to_read.read()",
          "",
          "[Added Lines]",
          "52:     file_path = AIRFLOW_SOURCES_DIR.joinpath(*path_elements)",
          "53:     return file_path.read_text()",
          "",
          "---------------"
        ],
        "scripts/ci/pre_commit/pre_commit_inline_scripts_in_docker.py||scripts/ci/pre_commit/pre_commit_inline_scripts_in_docker.py": [
          "File: scripts/ci/pre_commit/pre_commit_inline_scripts_in_docker.py -> scripts/ci/pre_commit/pre_commit_inline_scripts_in_docker.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: # under the License.",
          "18: from __future__ import annotations",
          "21: from pathlib import Path",
          "23: AIRFLOW_SOURCES_DIR = Path(__file__).parents[3].resolve()",
          "",
          "[Removed Lines]",
          "20: from os import listdir",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "45:     SCRIPTS_DOCKER_DIR = AIRFLOW_SOURCES_DIR / \"scripts\" / \"docker\"",
          "47:     for file in [DOCKERFILE_FILE, DOCKERFILE_CI_FILE]:",
          "50:             no_comments_script_content = [",
          "51:                 line for line in script_content if not line.startswith(\"#\") or line.startswith(\"#!\")",
          "52:             ]",
          "54:             insert_content(",
          "55:                 file_path=file,",
          "56:                 content=no_comments_script_content,",
          "57:                 header=\"# The content below is automatically copied from scripts/docker/\",",
          "58:                 footer=\"EOF\",",
          "60:             )",
          "",
          "[Removed Lines]",
          "48:         for script in listdir(SCRIPTS_DOCKER_DIR):",
          "49:             script_content = (SCRIPTS_DOCKER_DIR / script).read_text().splitlines(keepends=True)",
          "53:             no_comments_script_content.insert(0, f'COPY <<\"EOF\" /{script}\\n')",
          "59:                 file_name=script,",
          "",
          "[Added Lines]",
          "47:         for script in SCRIPTS_DOCKER_DIR.iterdir():",
          "48:             script_content = script.read_text().splitlines(keepends=True)",
          "52:             no_comments_script_content.insert(0, f'COPY <<\"EOF\" /{script.name}\\n')",
          "58:                 file_name=script.name,",
          "",
          "---------------"
        ],
        "scripts/in_container/update_quarantined_test_status.py||scripts/in_container/update_quarantined_test_status.py": [
          "File: scripts/in_container/update_quarantined_test_status.py -> scripts/in_container/update_quarantined_test_status.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: import re",
          "22: import sys",
          "23: from datetime import datetime",
          "25: from typing import NamedTuple",
          "26: from urllib.parse import urlsplit",
          "",
          "[Removed Lines]",
          "24: from os.path import dirname, join, realpath",
          "",
          "[Added Lines]",
          "24: from pathlib import Path",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "234:     print()",
          "235:     print(table)",
          "236:     print()",
          "238:         header = jinja2.Template(f.read(), autoescape=True, undefined=StrictUndefined).render(",
          "239:             DATE_UTC_NOW=datetime.utcnow()",
          "240:         )",
          "",
          "[Removed Lines]",
          "237:     with open(join(dirname(realpath(__file__)), \"quarantine_issue_header.md\")) as f:",
          "",
          "[Added Lines]",
          "237:     with Path(__file__).resolve().with_name(\"quarantine_issue_header.md\").open() as f:",
          "",
          "---------------"
        ],
        "setup.py||setup.py": [
          "File: setup.py -> setup.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "30: import sys",
          "31: import unittest",
          "32: from copy import deepcopy",
          "34: from pathlib import Path",
          "35: from textwrap import wrap",
          "36: from typing import Iterable",
          "",
          "[Removed Lines]",
          "33: from os.path import relpath",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "864:             ]",
          "865:             provider_yaml_files = glob.glob(\"airflow/providers/**/provider.yaml\", recursive=True)",
          "866:             for provider_yaml_file in provider_yaml_files:",
          "868:                 self.package_data[\"airflow\"].append(provider_relative_path)",
          "869:         else:",
          "870:             self.install_requires.extend(",
          "",
          "[Removed Lines]",
          "867:                 provider_relative_path = relpath(provider_yaml_file, str(AIRFLOW_SOURCES_ROOT / \"airflow\"))",
          "",
          "[Added Lines]",
          "866:                 provider_relative_path = os.path.relpath(",
          "867:                     provider_yaml_file, str(AIRFLOW_SOURCES_ROOT / \"airflow\")",
          "868:                 )",
          "",
          "---------------"
        ],
        "tests/providers/google/cloud/operators/test_dataprep_system.py||tests/providers/google/cloud/operators/test_dataprep_system.py": [
          "File: tests/providers/google/cloud/operators/test_dataprep_system.py -> tests/providers/google/cloud/operators/test_dataprep_system.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: from __future__ import annotations",
          "20: import json",
          "23: import pytest",
          "",
          "[Removed Lines]",
          "21: from os import environ",
          "",
          "[Added Lines]",
          "21: import os",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "27: from tests.test_utils.db import clear_db_connections",
          "28: from tests.test_utils.gcp_system_helpers import CLOUD_DAG_FOLDER, GoogleSystemTest",
          "31: EXTRA = {\"token\": TOKEN}",
          "",
          "[Removed Lines]",
          "30: TOKEN = environ.get(\"DATAPREP_TOKEN\")",
          "",
          "[Added Lines]",
          "30: TOKEN = os.environ.get(\"DATAPREP_TOKEN\")",
          "",
          "---------------"
        ],
        "tests/system/providers/amazon/aws/example_google_api_sheets_to_s3.py||tests/system/providers/amazon/aws/example_google_api_sheets_to_s3.py": [
          "File: tests/system/providers/amazon/aws/example_google_api_sheets_to_s3.py -> tests/system/providers/amazon/aws/example_google_api_sheets_to_s3.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: \"\"\"",
          "21: from __future__ import annotations",
          "23: from datetime import datetime",
          "26: from airflow import DAG",
          "27: from airflow.models.baseoperator import chain",
          "",
          "[Removed Lines]",
          "24: from os import getenv",
          "",
          "[Added Lines]",
          "23: import os",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "35: DAG_ID = \"example_google_api_sheets_to_s3\"",
          "41: with DAG(",
          "42:     dag_id=DAG_ID,",
          "",
          "[Removed Lines]",
          "37: GOOGLE_SHEET_ID = getenv(\"GOOGLE_SHEET_ID\", \"test-google-sheet-id\")",
          "38: GOOGLE_SHEET_RANGE = getenv(\"GOOGLE_SHEET_RANGE\", \"test-google-sheet-range\")",
          "39: S3_DESTINATION_KEY = getenv(\"S3_DESTINATION_KEY\", \"s3://test-bucket/key.json\")",
          "",
          "[Added Lines]",
          "37: GOOGLE_SHEET_ID = os.getenv(\"GOOGLE_SHEET_ID\", \"test-google-sheet-id\")",
          "38: GOOGLE_SHEET_RANGE = os.getenv(\"GOOGLE_SHEET_RANGE\", \"test-google-sheet-range\")",
          "39: S3_DESTINATION_KEY = os.getenv(\"S3_DESTINATION_KEY\", \"s3://test-bucket/key.json\")",
          "",
          "---------------"
        ],
        "tests/system/providers/amazon/aws/utils/__init__.py||tests/system/providers/amazon/aws/utils/__init__.py": [
          "File: tests/system/providers/amazon/aws/utils/__init__.py -> tests/system/providers/amazon/aws/utils/__init__.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: import json",
          "21: import logging",
          "22: import os",
          "24: from time import sleep",
          "25: from uuid import uuid4",
          "",
          "[Removed Lines]",
          "23: from os.path import basename, splitext",
          "",
          "[Added Lines]",
          "23: from pathlib import Path",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "67:     test_filename: str = next(",
          "68:         frame.filename for frame in inspect.stack() if TEST_FILE_IDENTIFIER in frame.filename",
          "69:     )",
          "73: def _validate_env_id(env_id: str) -> str:",
          "",
          "[Removed Lines]",
          "70:     return splitext(basename(test_filename))[0]",
          "",
          "[Added Lines]",
          "70:     return Path(test_filename).stem",
          "",
          "---------------"
        ],
        "tests/utils/test_file.py||tests/utils/test_file.py": [
          "File: tests/utils/test_file.py -> tests/utils/test_file.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: from __future__ import annotations",
          "20: import os",
          "22: import zipfile",
          "23: from pathlib import Path",
          "24: from unittest import mock",
          "",
          "[Removed Lines]",
          "21: import os.path",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ]
      }
    }
  ]
}