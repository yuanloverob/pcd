{
  "cve_id": "CVE-2021-45229",
  "cve_desc": "It was discovered that the \"Trigger DAG with config\" screen was susceptible to XSS attacks via the `origin` query argument. This issue affects Apache Airflow versions 2.2.3 and below.",
  "repo": "apache/airflow",
  "patch_hash": "628aa1f99c865d97d0b1c7c76e630e43a7b8d319",
  "patch_info": {
    "commit_hash": "628aa1f99c865d97d0b1c7c76e630e43a7b8d319",
    "repo": "apache/airflow",
    "commit_url": "https://github.com/apache/airflow/commit/628aa1f99c865d97d0b1c7c76e630e43a7b8d319",
    "files": [
      "airflow/www/templates/airflow/trigger.html",
      "tests/www/views/test_views_trigger_dag.py"
    ],
    "message": "Simplify trigger cancel button (#21591)\n\nCo-authored-by: Jed Cunningham <jedcunningham@apache.org>\n(cherry picked from commit 65297673a318660fba76797e50d0c06804dfcafc)",
    "before_after_code_files": [
      "airflow/www/templates/airflow/trigger.html||airflow/www/templates/airflow/trigger.html",
      "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py"
    ]
  },
  "patch_diff": {
    "airflow/www/templates/airflow/trigger.html||airflow/www/templates/airflow/trigger.html": [
      "File: airflow/www/templates/airflow/trigger.html -> airflow/www/templates/airflow/trigger.html",
      "--- Hunk 1 ---",
      "[Context before]",
      "63:       </label>",
      "64:     </div>",
      "65:     <button type=\"submit\" class=\"btn btn-primary\">Trigger</button>",
      "67:   </form>",
      "68: {% endblock %}",
      "",
      "[Removed Lines]",
      "66:     <button type=\"button\" class=\"btn\" onclick=\"location.href = '{{ origin }}'; return false\">Cancel</button>",
      "",
      "[Added Lines]",
      "66:     <a class=\"btn\" href=\"{{ origin }}\">Cancel</a>",
      "",
      "---------------"
    ],
    "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py": [
      "File: tests/www/views/test_views_trigger_dag.py -> tests/www/views/test_views_trigger_dag.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "133:         (\"javascript:alert(1)\", \"/home\"),",
      "134:         (\"http://google.com\", \"/home\"),",
      "135:         (\"36539'%3balert(1)%2f%2f166\", \"/home\"),",
      "136:         (",
      "137:             \"%2Ftree%3Fdag_id%3Dexample_bash_operator';alert(33)//\",",
      "138:             \"/home\",",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "136:         (",
      "137:             '\"><script>alert(99)</script><a href=\"',",
      "138:             \"&#34;&gt;&lt;script&gt;alert(99)&lt;/script&gt;&lt;a href=&#34;\",",
      "139:         ),",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "145:     test_dag_id = \"example_bash_operator\"",
      "147:     resp = admin_client.get(f'trigger?dag_id={test_dag_id}&origin={test_origin}')",
      "156: @pytest.mark.parametrize(",
      "",
      "[Removed Lines]",
      "148:     check_content_in_response(",
      "149:         '<button type=\"button\" class=\"btn\" onclick=\"location.href = \\'{}\\'; return false\">'.format(",
      "150:             expected_origin",
      "151:         ),",
      "152:         resp,",
      "153:     )",
      "",
      "[Added Lines]",
      "152:     check_content_in_response(f'<a class=\"btn\" href=\"{expected_origin}\">Cancel</a>', resp)",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "7e019778defa7d59055f2eff2e627c0cd5c74e3c",
      "candidate_info": {
        "commit_hash": "7e019778defa7d59055f2eff2e627c0cd5c74e3c",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/7e019778defa7d59055f2eff2e627c0cd5c74e3c",
        "files": [
          ".github/workflows/ci.yml",
          "docker_tests/command_utils.py",
          "docker_tests/constants.py",
          "docker_tests/docker_tests_utils.py",
          "docker_tests/test_ci_image.py",
          "docker_tests/test_examples_of_prod_image_building.py",
          "docker_tests/test_prod_image.py",
          "docs/docker-stack/build.rst",
          "docs/docker-stack/docker-examples/customizing/add-build-essential-custom.sh",
          "docs/docker-stack/docker-examples/customizing/custom-sources.sh",
          "docs/docker-stack/docker-examples/customizing/github-v2-2-test.sh",
          "docs/docker-stack/docker-examples/customizing/pypi-dev-runtime-deps.sh",
          "docs/docker-stack/docker-examples/customizing/pypi-extras-and-deps.sh",
          "docs/docker-stack/docker-examples/customizing/pypi-selected-version.sh",
          "docs/docker-stack/docker-examples/restricted/restricted_environments.sh",
          "scripts/ci/images/ci_run_docker_tests.py",
          "scripts/ci/images/ci_test_examples_of_prod_image_building.sh",
          "scripts/ci/libraries/_verify_image.sh",
          "scripts/ci/pre_commit/pre_commit_update_versions.py"
        ],
        "message": "Rewrite image building tests to Python (#19819)\n\n(cherry picked from commit 20dc5b9aef66a9f2bed4e3ba652b385fb94b7e24)",
        "before_after_code_files": [
          "docker_tests/command_utils.py||docker_tests/command_utils.py",
          "docker_tests/constants.py||docker_tests/constants.py",
          "docker_tests/docker_tests_utils.py||docker_tests/docker_tests_utils.py",
          "docker_tests/ci_image.py||docker_tests/test_ci_image.py",
          "docker_tests/test_examples_of_prod_image_building.py||docker_tests/test_examples_of_prod_image_building.py",
          "docker_tests/prod_image.py||docker_tests/test_prod_image.py",
          "scripts/ci/images/ci_run_docker_tests.py||scripts/ci/images/ci_run_docker_tests.py",
          "scripts/ci/images/ci_test_examples_of_prod_image_building.sh||scripts/ci/images/ci_test_examples_of_prod_image_building.sh",
          "scripts/ci/libraries/_verify_image.sh||scripts/ci/libraries/_verify_image.sh",
          "scripts/ci/pre_commit/pre_commit_update_versions.py||scripts/ci/pre_commit/pre_commit_update_versions.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "docker_tests/command_utils.py||docker_tests/command_utils.py": [
          "File: docker_tests/command_utils.py -> docker_tests/command_utils.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: # Licensed to the Apache Software Foundation (ASF) under one",
          "2: # or more contributor license agreements.  See the NOTICE file",
          "3: # distributed with this work for additional information",
          "4: # regarding copyright ownership.  The ASF licenses this file",
          "5: # to you under the Apache License, Version 2.0 (the",
          "6: # \"License\"); you may not use this file except in compliance",
          "7: # with the License.  You may obtain a copy of the License at",
          "8: #",
          "9: #   http://www.apache.org/licenses/LICENSE-2.0",
          "10: #",
          "11: # Unless required by applicable law or agreed to in writing,",
          "12: # software distributed under the License is distributed on an",
          "13: # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
          "14: # KIND, either express or implied.  See the License for the",
          "15: # specific language governing permissions and limitations",
          "16: # under the License.",
          "18: import shlex",
          "19: import subprocess",
          "20: from typing import List",
          "23: def run_command(cmd: List[str], *, print_output_on_error: bool = True, return_output: bool = False, **kwargs):",
          "24:     print(f\"$ {' '.join(shlex.quote(c) for c in cmd)}\")",
          "25:     try:",
          "26:         if return_output:",
          "27:             return subprocess.check_output(cmd, **kwargs).decode()",
          "28:         else:",
          "29:             subprocess.run(cmd, check=True, **kwargs)",
          "30:     except subprocess.CalledProcessError as ex:",
          "31:         if print_output_on_error:",
          "32:             print(\"========================= OUTPUT start ============================\")",
          "33:             print(ex.stderr)",
          "34:             print(ex.stdout)",
          "35:             print(\"========================= OUTPUT end ============================\")",
          "36:         raise",
          "",
          "---------------"
        ],
        "docker_tests/constants.py||docker_tests/constants.py": [
          "File: docker_tests/constants.py -> docker_tests/constants.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: # Licensed to the Apache Software Foundation (ASF) under one",
          "2: # or more contributor license agreements.  See the NOTICE file",
          "3: # distributed with this work for additional information",
          "4: # regarding copyright ownership.  The ASF licenses this file",
          "5: # to you under the Apache License, Version 2.0 (the",
          "6: # \"License\"); you may not use this file except in compliance",
          "7: # with the License.  You may obtain a copy of the License at",
          "8: #",
          "9: #   http://www.apache.org/licenses/LICENSE-2.0",
          "10: #",
          "11: # Unless required by applicable law or agreed to in writing,",
          "12: # software distributed under the License is distributed on an",
          "13: # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
          "14: # KIND, either express or implied.  See the License for the",
          "15: # specific language governing permissions and limitations",
          "16: # under the License.",
          "18: from pathlib import Path",
          "20: SOURCE_ROOT = Path(__file__).resolve().parents[1]",
          "",
          "---------------"
        ],
        "docker_tests/docker_tests_utils.py||docker_tests/docker_tests_utils.py": [
          "File: docker_tests/docker_tests_utils.py -> docker_tests/docker_tests_utils.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "16: # under the License.",
          "18: import os",
          "24: docker_image = os.environ.get('DOCKER_IMAGE')",
          "27: if not docker_image:",
          "28:     raise Exception(\"The DOCKER_IMAGE environment variable is required\")",
          "44: def run_bash_in_docker(bash_script, **kwargs):",
          "45:     docker_command = [",
          "46:         \"docker\",",
          "",
          "[Removed Lines]",
          "19: import shlex",
          "20: import subprocess",
          "21: from pathlib import Path",
          "22: from typing import List",
          "25: SOURCE_ROOT = Path(__file__).resolve().parents[1]",
          "31: def run_command(cmd: List[str], print_output_on_error: bool = True, **kwargs):",
          "32:     print(f\"$ {' '.join(shlex.quote(c) for c in cmd)}\")",
          "33:     try:",
          "34:         return subprocess.check_output(cmd, **kwargs).decode()",
          "35:     except subprocess.CalledProcessError as ex:",
          "36:         if print_output_on_error:",
          "37:             print(\"========================= OUTPUT start ============================\")",
          "38:             print(ex.stderr)",
          "39:             print(ex.stdout)",
          "40:             print(\"========================= OUTPUT end ============================\")",
          "41:         raise",
          "",
          "[Added Lines]",
          "20: from docker_tests.command_utils import run_command",
          "",
          "---------------"
        ],
        "docker_tests/ci_image.py||docker_tests/test_ci_image.py": [
          "File: docker_tests/ci_image.py -> docker_tests/test_ci_image.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: import subprocess",
          "20: from docker_tests.docker_tests_utils import (",
          "21:     display_dependency_conflict_message,",
          "22:     docker_image,",
          "23:     run_bash_in_docker,",
          "25: )",
          "",
          "[Removed Lines]",
          "24:     run_command,",
          "",
          "[Added Lines]",
          "20: from docker_tests.command_utils import run_command",
          "",
          "---------------"
        ],
        "docker_tests/test_examples_of_prod_image_building.py||docker_tests/test_examples_of_prod_image_building.py": [
          "File: docker_tests/test_examples_of_prod_image_building.py -> docker_tests/test_examples_of_prod_image_building.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: # Licensed to the Apache Software Foundation (ASF) under one",
          "2: # or more contributor license agreements.  See the NOTICE file",
          "3: # distributed with this work for additional information",
          "4: # regarding copyright ownership.  The ASF licenses this file",
          "5: # to you under the Apache License, Version 2.0 (the",
          "6: # \"License\"); you may not use this file except in compliance",
          "7: # with the License.  You may obtain a copy of the License at",
          "8: #",
          "9: #   http://www.apache.org/licenses/LICENSE-2.0",
          "10: #",
          "11: # Unless required by applicable law or agreed to in writing,",
          "12: # software distributed under the License is distributed on an",
          "13: # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
          "14: # KIND, either express or implied.  See the License for the",
          "15: # specific language governing permissions and limitations",
          "16: # under the License.",
          "18: import glob",
          "19: import os",
          "20: import re",
          "21: from functools import lru_cache",
          "22: from pathlib import Path",
          "24: import pytest",
          "25: import requests",
          "27: from docker_tests.command_utils import run_command",
          "28: from docker_tests.constants import SOURCE_ROOT",
          "30: DOCKER_EXAMPLES_DIR = SOURCE_ROOT / \"docs\" / \"docker-stack\" / \"docker-examples\"",
          "33: @lru_cache(maxsize=None)",
          "34: def get_latest_airflow_version_released():",
          "35:     response = requests.get('https://pypi.org/pypi/apache-airflow/json')",
          "36:     response.raise_for_status()",
          "37:     return response.json()['info']['version']",
          "40: @pytest.mark.skipif(",
          "41:     os.environ.get('CI') == \"true\",",
          "42:     reason=\"Skipping the script builds on CI! They take very long time to build.\",",
          "43: )",
          "44: @pytest.mark.parametrize(\"script_file\", glob.glob(f\"{DOCKER_EXAMPLES_DIR}/**/*.sh\", recursive=True))",
          "45: def test_shell_script_example(script_file):",
          "46:     run_command([\"bash\", script_file])",
          "49: @pytest.mark.parametrize(\"dockerfile\", glob.glob(f\"{DOCKER_EXAMPLES_DIR}/**/Dockerfile\", recursive=True))",
          "50: def test_dockerfile_example(dockerfile):",
          "51:     rel_dockerfile_path = Path(dockerfile).relative_to(DOCKER_EXAMPLES_DIR)",
          "52:     image_name = str(rel_dockerfile_path).lower().replace(\"/\", \"-\")",
          "53:     content = Path(dockerfile).read_text()",
          "54:     new_content = re.sub(",
          "55:         r'FROM apache/airflow:.*', fr'FROM apache/airflow:{get_latest_airflow_version_released()}', content",
          "56:     )",
          "57:     try:",
          "58:         run_command(",
          "59:             [\"docker\", \"build\", \".\", \"--tag\", image_name, '-f', '-'],",
          "60:             cwd=str(Path(dockerfile).parent),",
          "61:             input=new_content.encode(),",
          "62:         )",
          "63:     finally:",
          "64:         run_command([\"docker\", \"rmi\", \"--force\", image_name])",
          "",
          "---------------"
        ],
        "docker_tests/prod_image.py||docker_tests/test_prod_image.py": [
          "File: docker_tests/prod_image.py -> docker_tests/test_prod_image.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "23: import pytest",
          "25: from docker_tests.docker_tests_utils import (",
          "27:     display_dependency_conflict_message,",
          "28:     docker_image,",
          "29:     run_bash_in_docker,",
          "31:     run_python_in_docker,",
          "32: )",
          "",
          "[Removed Lines]",
          "26:     SOURCE_ROOT,",
          "30:     run_command,",
          "",
          "[Added Lines]",
          "25: from docker_tests.command_utils import run_command",
          "26: from docker_tests.constants import SOURCE_ROOT",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "50:     def test_airflow_version(self):",
          "51:         \"\"\"Checking 'airflow version' command  It should return zero exit code.\"\"\"",
          "52:         output = run_command(",
          "54:         )",
          "55:         assert \"2.\" in output",
          "57:     def test_python_version(self):",
          "58:         \"\"\"Checking 'python --version' command  It should return zero exit code.\"\"\"",
          "59:         output = run_command(",
          "61:         )",
          "62:         assert \"Python 3.\" in output",
          "64:     def test_bash_version(self):",
          "65:         \"\"\"Checking 'bash --version' command  It should return zero exit code.\"\"\"",
          "66:         output = run_command(",
          "68:         )",
          "69:         assert \"GNU bash,\" in output",
          "",
          "[Removed Lines]",
          "53:             [\"docker\", \"run\", \"--rm\", \"-e\", \"COLUMNS=180\", docker_image, \"airflow\", \"version\"]",
          "60:             [\"docker\", \"run\", \"--rm\", \"-e\", \"COLUMNS=180\", docker_image, \"python\", \"--version\"]",
          "67:             [\"docker\", \"run\", \"--rm\", \"-e\", \"COLUMNS=180\", docker_image, \"bash\", \"--version\"]",
          "",
          "[Added Lines]",
          "53:             [\"docker\", \"run\", \"--rm\", \"-e\", \"COLUMNS=180\", docker_image, \"airflow\", \"version\"],",
          "54:             return_output=True,",
          "61:             [\"docker\", \"run\", \"--rm\", \"-e\", \"COLUMNS=180\", docker_image, \"python\", \"--version\"],",
          "62:             return_output=True,",
          "69:             [\"docker\", \"run\", \"--rm\", \"-e\", \"COLUMNS=180\", docker_image, \"bash\", \"--version\"],",
          "70:             return_output=True,",
          "",
          "---------------"
        ],
        "scripts/ci/images/ci_run_docker_tests.py||scripts/ci/images/ci_run_docker_tests.py": [
          "File: scripts/ci/images/ci_run_docker_tests.py -> scripts/ci/images/ci_run_docker_tests.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "62:         run_verbose([sys.executable, \"-m\", \"venv\", str(virtualenv_path)])",
          "64:     python_bin = virtualenv_path / \"bin\" / \"python\"",
          "66:     return python_bin",
          "",
          "[Removed Lines]",
          "65:     run_verbose([str(python_bin), \"-m\", \"pip\", \"install\", \"pytest\", \"pytest-xdist\"])",
          "",
          "[Added Lines]",
          "65:     run_verbose([str(python_bin), \"-m\", \"pip\", \"install\", \"pytest\", \"pytest-xdist\", \"requests\"])",
          "",
          "---------------"
        ],
        "scripts/ci/images/ci_test_examples_of_prod_image_building.sh||scripts/ci/images/ci_test_examples_of_prod_image_building.sh": [
          "File: scripts/ci/images/ci_test_examples_of_prod_image_building.sh -> scripts/ci/images/ci_test_examples_of_prod_image_building.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: # shellcheck source=scripts/ci/libraries/_script_init.sh",
          "19: . \"$(dirname \"${BASH_SOURCE[0]}\")/../libraries/_script_init.sh\"",
          "",
          "[Removed Lines]",
          "21: SEMAPHORE_NAME=\"image_tests\"",
          "22: export SEMAPHORE_NAME",
          "24: DOCKER_EXAMPLES_DIR=${AIRFLOW_SOURCES}/docs/docker-stack/docker-examples/",
          "25: export DOCKER_EXAMPLES_DIR",
          "27: # Launches parallel building of images. Redirects output to log set the right directories",
          "28: # $1 - name of the job",
          "29: # $2 - bash file to execute in parallel",
          "30: function run_image_test_job() {",
          "31:     local file=$1",
          "33:     local job_name=$2",
          "34:     mkdir -p \"${PARALLEL_MONITORED_DIR}/${SEMAPHORE_NAME}/${job_name}\"",
          "35:     export JOB_LOG=\"${PARALLEL_MONITORED_DIR}/${SEMAPHORE_NAME}/${job_name}/stdout\"",
          "36:     export PARALLEL_JOB_STATUS=\"${PARALLEL_MONITORED_DIR}/${SEMAPHORE_NAME}/${job_name}/status\"",
          "37:     parallel --ungroup --bg --semaphore --semaphorename \"${SEMAPHORE_NAME}\" \\",
          "38:         --jobs \"${MAX_PARALLEL_IMAGE_JOBS}\" \\",
          "39:             \"$(dirname \"${BASH_SOURCE[0]}\")/ci_run_prod_image_test.sh\" \"${job_name}\" \"${file}\" >\"${JOB_LOG}\" 2>&1",
          "40: }",
          "43: function test_images() {",
          "44:     if [[ ${CI=} == \"true\" ]]; then",
          "45:         echo",
          "46:         echo \"Skipping the script builds on CI! \"",
          "47:         echo \"They take very long time to build.\"",
          "48:         echo",
          "49:     else",
          "50:         local scripts_to_test",
          "51:         scripts_to_test=$(find \"${DOCKER_EXAMPLES_DIR}\" -type f -name '*.sh' )",
          "52:         for file in ${scripts_to_test}",
          "53:         do",
          "54:             local job_name",
          "55:             job_name=$(basename \"${file}\")",
          "56:             run_image_test_job \"${file}\" \"${job_name}\"",
          "57:         done",
          "58:     fi",
          "59:     local dockerfiles_to_test",
          "60:     dockerfiles_to_test=$(find \"${DOCKER_EXAMPLES_DIR}\" -type f -name 'Dockerfile' )",
          "61:     for file in ${dockerfiles_to_test}",
          "62:     do",
          "63:         local job_name",
          "64:         job_name=\"$(basename \"$(dirname \"${file}\")\")\"",
          "65:         run_image_test_job \"${file}\" \"${job_name}\"",
          "66:     done",
          "68: }",
          "70: cd \"${AIRFLOW_SOURCES}\" || exit 1",
          "72: # Building max for images in parallel helps to conserve docker image space",
          "73: MAX_PARALLEL_IMAGE_JOBS=4",
          "74: export MAX_PARALLEL_IMAGE_JOBS",
          "76: parallel::make_sure_gnu_parallel_is_installed",
          "77: parallel::kill_stale_semaphore_locks",
          "78: parallel::initialize_monitoring",
          "80: start_end::group_start \"Testing image building\"",
          "82: parallel::monitor_progress",
          "84: test_images",
          "86: parallel --semaphore --semaphorename \"${SEMAPHORE_NAME}\" --wait",
          "87: start_end::group_end",
          "89: parallel::print_job_summary_and_return_status_code",
          "",
          "[Added Lines]",
          "21: python3 \"${SCRIPTS_CI_DIR}/images/ci_run_docker_tests.py\" \"${AIRFLOW_SOURCES}/docker_tests/test_examples_of_prod_image_building.py\"",
          "",
          "---------------"
        ],
        "scripts/ci/libraries/_verify_image.sh||scripts/ci/libraries/_verify_image.sh": [
          "File: scripts/ci/libraries/_verify_image.sh -> scripts/ci/libraries/_verify_image.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: function verify_image::verify_prod_image {",
          "20:     DOCKER_IMAGE=\"${1}\"",
          "21:     export DOCKER_IMAGE",
          "23: }",
          "25: function verify_image::verify_ci_image {",
          "26:     DOCKER_IMAGE=\"${1}\"",
          "27:     export DOCKER_IMAGE",
          "29: }",
          "",
          "[Removed Lines]",
          "22:     python3 \"${SCRIPTS_CI_DIR}/images/ci_run_docker_tests.py\" \"${AIRFLOW_SOURCES}/docker_tests/prod_image.py\"",
          "28:     python3 \"${SCRIPTS_CI_DIR}/images/ci_run_docker_tests.py\" \"${AIRFLOW_SOURCES}/docker_tests/ci_image.py\"",
          "",
          "[Added Lines]",
          "22:     python3 \"${SCRIPTS_CI_DIR}/images/ci_run_docker_tests.py\" \"${AIRFLOW_SOURCES}/docker_tests/test_prod_image.py\"",
          "28:     python3 \"${SCRIPTS_CI_DIR}/images/ci_run_docker_tests.py\" \"${AIRFLOW_SOURCES}/docker_tests/test_ci_image.py\"",
          "",
          "---------------"
        ],
        "scripts/ci/pre_commit/pre_commit_update_versions.py||scripts/ci/pre_commit/pre_commit_update_versions.py": [
          "File: scripts/ci/pre_commit/pre_commit_update_versions.py -> scripts/ci/pre_commit/pre_commit_update_versions.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "29: from setup import version  # isort:skip",
          "33:     print(f\"Replacing {pattern} to {version} in {file_path}\")",
          "34:     with open(file_path, \"r+\") as f:",
          "40:         f.seek(0)",
          "41:         f.truncate()",
          "45: REPLACEMENTS = {",
          "52: }",
          "54: if __name__ == '__main__':",
          "55:     for regexp, p in REPLACEMENTS.items():",
          "57:         files = glob.glob(join(AIRFLOW_SOURCES_DIR, p), recursive=True)",
          "58:         if not files:",
          "59:             print(f\"ERROR! No files matched on {p}\")",
          "",
          "[Removed Lines]",
          "32: def update_version(pattern, v: str, file_path: str):",
          "35:         file_contents = f.read()",
          "36:         lines = file_contents.splitlines(keepends=True)",
          "37:         for i in range(0, len(lines)):",
          "38:             lines[i] = re.sub(pattern, fr'\\g<1>{v}\\g<2>', lines[i])",
          "39:         file_contents = \"\".join(lines)",
          "42:         f.write(file_contents)",
          "46:     r'(FROM apache/airflow:).*($)': \"docs/docker-stack/docker-examples/extending/*/Dockerfile\",",
          "47:     r'(apache/airflow:)[^-]*(\\-)': \"docs/docker-stack/entrypoint.rst\",",
          "48:     r'(/constraints-)[^-]*(/constraints)': \"docs/docker-stack/docker-examples/\"",
          "49:     \"restricted/restricted_environments.sh\",",
          "50:     r'(AIRFLOW_VERSION=\")[^\"]*(\" \\\\)': \"docs/docker-stack/docker-examples/\"",
          "51:     \"restricted/restricted_environments.sh\",",
          "56:         text_pattern = re.compile(regexp)",
          "",
          "[Added Lines]",
          "32: def update_version(pattern: re.Pattern, v: str, file_path: str):",
          "35:         file_content = f.read()",
          "36:         if not pattern.search(file_content):",
          "37:             raise Exception(f\"Pattern {pattern!r} doesn't found in {file_path!r} file\")",
          "38:         new_content = pattern.sub(fr'\\g<1>{v}\\g<2>', file_content)",
          "39:         if file_content == new_content:",
          "40:             return",
          "43:         f.write(new_content)",
          "47:     r'^(FROM apache\\/airflow:).*($)': \"docs/docker-stack/docker-examples/extending/*/Dockerfile\",",
          "48:     r'(apache\\/airflow:)[^-]*(\\-)': \"docs/docker-stack/entrypoint.rst\",",
          "53:         text_pattern = re.compile(regexp, flags=re.MULTILINE)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "6561e7b212a2c4f48a9541240546c75406ad235f",
      "candidate_info": {
        "commit_hash": "6561e7b212a2c4f48a9541240546c75406ad235f",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/6561e7b212a2c4f48a9541240546c75406ad235f",
        "files": [
          "UPDATING.md",
          "airflow/smart_sensor_dags/smart_sensor_group.py",
          "docs/apache-airflow/best-practices.rst",
          "docs/apache-airflow/concepts/dags.rst",
          "docs/apache-airflow/concepts/operators.rst",
          "docs/apache-airflow/dag-run.rst",
          "docs/apache-airflow/lineage.rst",
          "docs/apache-airflow/tutorial.rst",
          "docs/docker-stack/docker-examples/extending/embedding-dags/test_dag.py"
        ],
        "message": "Clean up dynamic `start_date` values from docs (#19607)\n\n(cherry picked from commit 26e4e114683c23e600b7c5b2d062309449c5087c)",
        "before_after_code_files": [
          "airflow/smart_sensor_dags/smart_sensor_group.py||airflow/smart_sensor_dags/smart_sensor_group.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/smart_sensor_dags/smart_sensor_group.py||airflow/smart_sensor_dags/smart_sensor_group.py": [
          "File: airflow/smart_sensor_dags/smart_sensor_group.py -> airflow/smart_sensor_dags/smart_sensor_group.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: # under the License.",
          "19: \"\"\"Smart sensor DAGs managing all smart sensor tasks.\"\"\"",
          "22: from airflow.configuration import conf",
          "23: from airflow.models import DAG",
          "24: from airflow.sensors.smart_sensor import SmartSensorOperator",
          "31: num_smart_sensor_shard = conf.getint(\"smart_sensor\", \"shards\")",
          "32: shard_code_upper_limit = conf.getint('smart_sensor', 'shard_code_upper_limit')",
          "",
          "[Removed Lines]",
          "20: from datetime import timedelta",
          "25: from airflow.utils.dates import days_ago",
          "27: args = {",
          "28:     'owner': 'airflow',",
          "29: }",
          "",
          "[Added Lines]",
          "20: from datetime import datetime, timedelta",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "38:     dag_id = f'smart_sensor_group_shard_{i}'",
          "39:     dag = DAG(",
          "40:         dag_id=dag_id,",
          "42:         schedule_interval=timedelta(minutes=5),",
          "43:         max_active_tasks=1,",
          "44:         max_active_runs=1,",
          "45:         catchup=False,",
          "46:         dagrun_timeout=timedelta(hours=24),",
          "48:     )",
          "50:     SmartSensorOperator(",
          "",
          "[Removed Lines]",
          "41:         default_args=args,",
          "47:         start_date=days_ago(2),",
          "",
          "[Added Lines]",
          "41:         start_date=datetime(2021, 1, 1),",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "33e36225c3c2e202c264e0e78952961768748884",
      "candidate_info": {
        "commit_hash": "33e36225c3c2e202c264e0e78952961768748884",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/33e36225c3c2e202c264e0e78952961768748884",
        "files": [
          "setup.cfg"
        ],
        "message": "Unpin ``cattrs`` (#20872)\n\nThis was pinned because of issue mentioned in https://github.com/apache/airflow/issues/16172 . However this was fixed in 1.8.0 of cattrs by https://github.com/python-attrs/cattrs/issues/151\n\nChangelog entry - https://cattrs.readthedocs.io/en/latest/history.html#id9\n\n(cherry picked from commit 88814587d451be7493e005e4d477609a39caa1d9)",
        "before_after_code_files": [
          "setup.cfg||setup.cfg"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "setup.cfg||setup.cfg": [
          "File: setup.cfg -> setup.cfg",
          "--- Hunk 1 ---",
          "[Context before]",
          "46:    licenses/LICENSE-moment.txt",
          "47:    licenses/LICENSE-normalize.txt",
          "48: # End of licences generated automatically",
          "49: classifiers =",
          "50:     Development Status :: 5 - Production/Stable",
          "51:     Environment :: Console",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "49:    licenses/LICENSES-ui.txt",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "87:     cached_property~=1.5;python_version<=\"3.7\"",
          "88:     # cattrs >= 1.1.0 dropped support for Python 3.6",
          "89:     cattrs>=1.0, <1.1.0;python_version<=\"3.6\"",
          "92:     # Required by vendored-in connexion",
          "93:     clickclick>=1.2",
          "94:     colorlog>=4.0.2, <6.0",
          "",
          "[Removed Lines]",
          "90:     # cattrs >= 1.7.0 break lineage - see https://github.com/apache/airflow/issues/16172",
          "91:     cattrs~=1.1, <1.7.0;python_version>\"3.6\"",
          "",
          "[Added Lines]",
          "91:     cattrs~=1.1, !=1.7.*;python_version>\"3.6\"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "109:     flask-wtf>=0.14.3, <0.15",
          "110:     graphviz>=0.12",
          "111:     gunicorn>=20.1.0",
          "114:     importlib_metadata>=1.7;python_version<\"3.9\"",
          "115:     importlib_resources~=5.2;python_version<\"3.9\"",
          "116:     # Required by vendored-in connexion",
          "",
          "[Removed Lines]",
          "112:     # We need to limit httpx until https://github.com/apache/airflow/issues/20088 is fixed",
          "113:     httpx<0.20.0",
          "",
          "[Added Lines]",
          "112:     httpx",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "118:     iso8601>=0.1.12",
          "119:     # Logging is broken with itsdangerous > 2",
          "120:     itsdangerous>=1.1.0, <2.0",
          "122:     jsonschema~=3.0",
          "123:     lazy-object-proxy",
          "124:     lockfile>=0.12.2",
          "",
          "[Removed Lines]",
          "121:     jinja2>=2.10.1,<4",
          "",
          "[Added Lines]",
          "120:     # Jinja2 3.1 will remove the 'autoescape' and 'with' extensions, which would",
          "121:     # break Flask 1.x, so we limit this for future compatibility. Remove this",
          "122:     # when bumping Flask to >=2.",
          "123:     jinja2>=2.10.1,<3.1",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "64e0c5024b3cb13d2fc53f42b8096c2ae3441553",
      "candidate_info": {
        "commit_hash": "64e0c5024b3cb13d2fc53f42b8096c2ae3441553",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/64e0c5024b3cb13d2fc53f42b8096c2ae3441553",
        "files": [
          "airflow/timetables/interval.py",
          "tests/timetables/test_interval_timetable.py"
        ],
        "message": "Fix the incorrect scheduling time for the first run of dag (#21011)\n\nWhen Catchup_by_default is set to false and start_date in the DAG is the\nprevious day, the first schedule time for this DAG may be incorrect\n\nCo-authored-by: wanlce <who@foxmail.com>\n(cherry picked from commit 0bcca55f4881bacc3fbe86f69e71981f5552b398)",
        "before_after_code_files": [
          "airflow/timetables/interval.py||airflow/timetables/interval.py",
          "tests/timetables/test_interval_timetable.py||tests/timetables/test_interval_timetable.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/timetables/interval.py||airflow/timetables/interval.py": [
          "File: airflow/timetables/interval.py -> airflow/timetables/interval.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "218:             raise AssertionError(\"next schedule shouldn't be earlier\")",
          "219:         if earliest is None:",
          "220:             return new_start",
          "223:     def infer_manual_data_interval(self, *, run_after: DateTime) -> DataInterval:",
          "224:         # Get the last complete period before run_after, e.g. if a DAG run is",
          "",
          "[Removed Lines]",
          "221:         return max(new_start, earliest)",
          "",
          "[Added Lines]",
          "221:         return max(new_start, self._align(earliest))",
          "",
          "---------------"
        ],
        "tests/timetables/test_interval_timetable.py||tests/timetables/test_interval_timetable.py": [
          "File: tests/timetables/test_interval_timetable.py -> tests/timetables/test_interval_timetable.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "35: PREV_DATA_INTERVAL = DataInterval(start=PREV_DATA_INTERVAL_START, end=PREV_DATA_INTERVAL_END)",
          "37: CURRENT_TIME = pendulum.DateTime(2021, 9, 7, tzinfo=TIMEZONE)",
          "39: HOURLY_CRON_TIMETABLE = CronDataIntervalTimetable(\"@hourly\", TIMEZONE)",
          "40: HOURLY_TIMEDELTA_TIMETABLE = DeltaDataIntervalTimetable(datetime.timedelta(hours=1))",
          "41: HOURLY_RELATIVEDELTA_TIMETABLE = DeltaDataIntervalTimetable(dateutil.relativedelta.relativedelta(hours=1))",
          "44: @pytest.mark.parametrize(",
          "45:     \"timetable\",",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "38: YESTERDAY = CURRENT_TIME - datetime.timedelta(days=1)",
          "44: CRON_TIMETABLE = CronDataIntervalTimetable(\"30 16 * * *\", TIMEZONE)",
          "45: DELTA_FROM_MIDNIGHT = datetime.timedelta(minutes=30, hours=16)",
          "48: @pytest.mark.parametrize(",
          "49:     \"last_automated_data_interval\",",
          "50:     [pytest.param(None, id=\"first-run\"), pytest.param(PREV_DATA_INTERVAL, id=\"subsequent\")],",
          "51: )",
          "52: @freezegun.freeze_time(CURRENT_TIME)",
          "53: def test_no_catchup_first_starts_at_current_time(",
          "54:     last_automated_data_interval: Optional[DataInterval],",
          "55: ) -> None:",
          "56:     \"\"\"If ``catchup=False`` and start_date is a day before\"\"\"",
          "57:     next_info = CRON_TIMETABLE.next_dagrun_info(",
          "58:         last_automated_data_interval=last_automated_data_interval,",
          "59:         restriction=TimeRestriction(earliest=YESTERDAY, latest=None, catchup=False),",
          "60:     )",
          "61:     expected_start = YESTERDAY + DELTA_FROM_MIDNIGHT",
          "62:     assert next_info == DagRunInfo.interval(start=expected_start, end=CURRENT_TIME + DELTA_FROM_MIDNIGHT)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "bedf40c43964339f80c83fea5d79f3513156d34b",
      "candidate_info": {
        "commit_hash": "bedf40c43964339f80c83fea5d79f3513156d34b",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/bedf40c43964339f80c83fea5d79f3513156d34b",
        "files": [
          "setup.cfg"
        ],
        "message": "Bump flask-appbuilder to >=3.3.4 (#20628)\n\n(cherry picked from commit 97261c642cbf07db91d252cf6b0b7ff184cd64c6)",
        "before_after_code_files": [
          "setup.cfg||setup.cfg"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "setup.cfg||setup.cfg": [
          "File: setup.cfg -> setup.cfg",
          "--- Hunk 1 ---",
          "[Context before]",
          "103:     #      https://github.com/readthedocs/sphinx_rtd_theme/issues/1115",
          "104:     docutils<0.17",
          "105:     flask>=1.1.0, <2.0",
          "107:     flask-caching>=1.5.0, <2.0.0",
          "108:     flask-login>=0.3, <0.5",
          "109:     flask-wtf>=0.14.3, <0.15",
          "",
          "[Removed Lines]",
          "106:     flask-appbuilder>=3.3.2, <4.0.0",
          "",
          "[Added Lines]",
          "106:     flask-appbuilder>=3.3.4, <4.0.0",
          "",
          "---------------"
        ]
      }
    }
  ]
}