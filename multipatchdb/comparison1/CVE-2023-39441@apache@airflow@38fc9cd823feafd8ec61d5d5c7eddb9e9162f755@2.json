{
  "cve_id": "CVE-2023-39441",
  "cve_desc": "Apache Airflow SMTP Provider before 1.3.0, Apache Airflow IMAP Provider before 3.3.0, and\u00a0Apache Airflow before 2.7.0 are affected by the\u00a0Validation of OpenSSL Certificate vulnerability.\n\nThe default SSL context with SSL library did not check a server's X.509\u00a0certificate.\u00a0 Instead, the code accepted any certificate, which could\u00a0result in the disclosure of mail server credentials or mail contents\u00a0when the client connects to an attacker in a MITM position.\n\nUsers are strongly advised to upgrade to Apache Airflow version 2.7.0 or newer, Apache Airflow IMAP Provider version 3.3.0 or newer, and Apache Airflow SMTP Provider version 1.3.0 or newer to mitigate the risk associated with this vulnerability",
  "repo": "apache/airflow",
  "patch_hash": "38fc9cd823feafd8ec61d5d5c7eddb9e9162f755",
  "patch_info": {
    "commit_hash": "38fc9cd823feafd8ec61d5d5c7eddb9e9162f755",
    "repo": "apache/airflow",
    "commit_url": "https://github.com/apache/airflow/commit/38fc9cd823feafd8ec61d5d5c7eddb9e9162f755",
    "files": [
      "airflow/providers/imap/CHANGELOG.rst",
      "airflow/providers/imap/hooks/imap.py",
      "airflow/providers/imap/provider.yaml",
      "docs/apache-airflow-providers-imap/configurations-ref.rst",
      "docs/apache-airflow-providers-imap/index.rst",
      "docs/apache-airflow/configurations-ref.rst",
      "tests/providers/imap/hooks/test_imap.py"
    ],
    "message": "Allows to choose SSL context for IMAP provider (#33108)\n\n* Allows to choose SSL context for IMAP provider\n\nThis change add two options to choose from when SSL IMAP connection is created:\n\n* default - for balance between compatibility and security\n* none - in case compatibility with existing infrastructure is preferred\n\nThe fallback is:\n\n* The Airflow \"email\", \"ssl_context\"\n* \"default\"\n\nCo-authored-by: Ephraim Anierobi <splendidzigy24@gmail.com>\n(cherry picked from commit 52ca7bfc988f4c9b608f544bc3e9524fd6564639)",
    "before_after_code_files": [
      "airflow/providers/imap/hooks/imap.py||airflow/providers/imap/hooks/imap.py",
      "tests/providers/imap/hooks/test_imap.py||tests/providers/imap/hooks/test_imap.py"
    ]
  },
  "patch_diff": {
    "airflow/providers/imap/hooks/imap.py||airflow/providers/imap/hooks/imap.py": [
      "File: airflow/providers/imap/hooks/imap.py -> airflow/providers/imap/hooks/imap.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "26: import imaplib",
      "27: import os",
      "28: import re",
      "29: from typing import Any, Iterable",
      "31: from airflow.exceptions import AirflowException",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "29: import ssl",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "78:         return self",
      "80:     def _build_client(self, conn: Connection) -> imaplib.IMAP4_SSL | imaplib.IMAP4:",
      "84:         else:",
      "92:         return mail_client",
      "",
      "[Removed Lines]",
      "81:         IMAP: type[imaplib.IMAP4_SSL] | type[imaplib.IMAP4]",
      "82:         if conn.extra_dejson.get(\"use_ssl\", True):",
      "83:             IMAP = imaplib.IMAP4_SSL",
      "85:             IMAP = imaplib.IMAP4",
      "87:         if conn.port:",
      "88:             mail_client = IMAP(conn.host, conn.port)",
      "89:         else:",
      "90:             mail_client = IMAP(conn.host)",
      "",
      "[Added Lines]",
      "82:         mail_client: imaplib.IMAP4_SSL | imaplib.IMAP4",
      "83:         use_ssl = conn.extra_dejson.get(\"use_ssl\", True)",
      "84:         if use_ssl:",
      "85:             from airflow.configuration import conf",
      "87:             ssl_context_string = conf.get(\"imap\", \"SSL_CONTEXT\", fallback=None)",
      "88:             if ssl_context_string is None:",
      "89:                 ssl_context_string = conf.get(\"email\", \"SSL_CONTEXT\", fallback=None)",
      "90:             if ssl_context_string is None:",
      "91:                 ssl_context_string = \"default\"",
      "92:             if ssl_context_string == \"default\":",
      "93:                 ssl_context = ssl.create_default_context()",
      "94:             elif ssl_context_string == \"none\":",
      "95:                 ssl_context = None",
      "96:             else:",
      "97:                 raise RuntimeError(",
      "98:                     f\"The email.ssl_context configuration variable must \"",
      "99:                     f\"be set to 'default' or 'none' and is '{ssl_context_string}'.\"",
      "100:                 )",
      "101:             if conn.port:",
      "102:                 mail_client = imaplib.IMAP4_SSL(conn.host, conn.port, ssl_context=ssl_context)",
      "103:             else:",
      "104:                 mail_client = imaplib.IMAP4_SSL(conn.host, ssl_context=ssl_context)",
      "106:             if conn.port:",
      "107:                 mail_client = imaplib.IMAP4(conn.host, conn.port)",
      "108:             else:",
      "109:                 mail_client = imaplib.IMAP4(conn.host)",
      "",
      "---------------"
    ],
    "tests/providers/imap/hooks/test_imap.py||tests/providers/imap/hooks/test_imap.py": [
      "File: tests/providers/imap/hooks/test_imap.py -> tests/providers/imap/hooks/test_imap.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "27: from airflow.models import Connection",
      "28: from airflow.providers.imap.hooks.imap import ImapHook",
      "29: from airflow.utils import db",
      "31: imaplib_string = \"airflow.providers.imap.hooks.imap.imaplib\"",
      "32: open_string = \"airflow.providers.imap.hooks.imap.open\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "30: from tests.test_utils.config import conf_vars",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "85:         )",
      "87:     @patch(imaplib_string)",
      "89:         mock_conn = _create_fake_imap(mock_imaplib)",
      "91:         with ImapHook():",
      "92:             pass",
      "95:         mock_conn.login.assert_called_once_with(\"imap_user\", \"imap_password\")",
      "96:         assert mock_conn.logout.call_count == 1",
      "",
      "[Removed Lines]",
      "88:     def test_connect_and_disconnect(self, mock_imaplib):",
      "94:         mock_imaplib.IMAP4_SSL.assert_called_once_with(\"imap_server_address\", 1993)",
      "",
      "[Added Lines]",
      "89:     @patch(\"ssl.create_default_context\")",
      "90:     def test_connect_and_disconnect(self, create_default_context, mock_imaplib):",
      "96:         assert create_default_context.called",
      "97:         mock_imaplib.IMAP4_SSL.assert_called_once_with(",
      "98:             \"imap_server_address\", 1993, ssl_context=create_default_context.return_value",
      "99:         )",
      "100:         mock_conn.login.assert_called_once_with(\"imap_user\", \"imap_password\")",
      "101:         assert mock_conn.logout.call_count == 1",
      "103:     @patch(imaplib_string)",
      "104:     @patch(\"ssl.create_default_context\")",
      "105:     def test_connect_and_disconnect_imap_ssl_context_none(self, create_default_context, mock_imaplib):",
      "106:         mock_conn = _create_fake_imap(mock_imaplib)",
      "108:         with conf_vars({(\"imap\", \"ssl_context\"): \"none\"}):",
      "109:             with ImapHook():",
      "110:                 pass",
      "112:         assert not create_default_context.called",
      "113:         mock_imaplib.IMAP4_SSL.assert_called_once_with(\"imap_server_address\", 1993, ssl_context=None)",
      "114:         mock_conn.login.assert_called_once_with(\"imap_user\", \"imap_password\")",
      "115:         assert mock_conn.logout.call_count == 1",
      "117:     @patch(imaplib_string)",
      "118:     @patch(\"ssl.create_default_context\")",
      "119:     def test_connect_and_disconnect_imap_ssl_context_default(self, create_default_context, mock_imaplib):",
      "120:         mock_conn = _create_fake_imap(mock_imaplib)",
      "122:         with conf_vars({(\"imap\", \"ssl_context\"): \"default\"}):",
      "123:             with ImapHook():",
      "124:                 pass",
      "126:         assert create_default_context.called",
      "127:         mock_imaplib.IMAP4_SSL.assert_called_once_with(",
      "128:             \"imap_server_address\", 1993, ssl_context=create_default_context.return_value",
      "129:         )",
      "130:         mock_conn.login.assert_called_once_with(\"imap_user\", \"imap_password\")",
      "131:         assert mock_conn.logout.call_count == 1",
      "133:     @patch(imaplib_string)",
      "134:     @patch(\"ssl.create_default_context\")",
      "135:     def test_connect_and_disconnect_email_ssl_context_none(self, create_default_context, mock_imaplib):",
      "136:         mock_conn = _create_fake_imap(mock_imaplib)",
      "138:         with conf_vars({(\"email\", \"ssl_context\"): \"none\"}):",
      "139:             with ImapHook():",
      "140:                 pass",
      "142:         assert not create_default_context.called",
      "143:         mock_imaplib.IMAP4_SSL.assert_called_once_with(\"imap_server_address\", 1993, ssl_context=None)",
      "144:         mock_conn.login.assert_called_once_with(\"imap_user\", \"imap_password\")",
      "145:         assert mock_conn.logout.call_count == 1",
      "147:     @patch(imaplib_string)",
      "148:     @patch(\"ssl.create_default_context\")",
      "149:     def test_connect_and_disconnect_imap_ssl_context_override(self, create_default_context, mock_imaplib):",
      "150:         mock_conn = _create_fake_imap(mock_imaplib)",
      "152:         with conf_vars({(\"email\", \"ssl_context\"): \"none\", (\"imap\", \"ssl_context\"): \"default\"}):",
      "153:             with ImapHook():",
      "154:                 pass",
      "156:         assert create_default_context.called",
      "157:         mock_imaplib.IMAP4_SSL.assert_called_once_with(",
      "158:             \"imap_server_address\", 1993, ssl_context=create_default_context.return_value",
      "159:         )",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "ba2a2db7bce06906bd460b443545178c24e863bf",
      "candidate_info": {
        "commit_hash": "ba2a2db7bce06906bd460b443545178c24e863bf",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/ba2a2db7bce06906bd460b443545178c24e863bf",
        "files": [
          "airflow/config_templates/config.yml",
          "airflow/dag_processing/manager.py",
          "airflow/models/connection.py",
          "airflow/models/variable.py",
          "airflow/secrets/cache.py",
          "docs/apache-airflow/best-practices.rst",
          "tests/always/test_secrets.py",
          "tests/models/test_variable.py",
          "tests/secrets/test_cache.py"
        ],
        "message": "Add a cache to `Variable` and `Connection` when called at dag parsing time (#30259)\n\n(cherry picked from commit dc8ad0caf4da663daf39305070813d0801ebc147)",
        "before_after_code_files": [
          "airflow/dag_processing/manager.py||airflow/dag_processing/manager.py",
          "airflow/models/connection.py||airflow/models/connection.py",
          "airflow/models/variable.py||airflow/models/variable.py",
          "airflow/secrets/cache.py||airflow/secrets/cache.py",
          "tests/always/test_secrets.py||tests/always/test_secrets.py",
          "tests/models/test_variable.py||tests/models/test_variable.py",
          "tests/secrets/test_cache.py||tests/secrets/test_cache.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/33247"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/dag_processing/manager.py||airflow/dag_processing/manager.py": [
          "File: airflow/dag_processing/manager.py -> airflow/dag_processing/manager.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "51: from airflow.models.dagwarning import DagWarning",
          "52: from airflow.models.db_callback_request import DbCallbackRequest",
          "53: from airflow.models.serialized_dag import SerializedDagModel",
          "54: from airflow.stats import Stats",
          "55: from airflow.utils import timezone",
          "56: from airflow.utils.file import list_py_file_paths, might_contain_dag",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "54: from airflow.secrets.cache import SecretCache",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1074:     def start_new_processes(self):",
          "1075:         \"\"\"Start more processors if we have enough slots and files to process.\"\"\"",
          "1076:         while self._parallelism - len(self._processors) > 0 and self._file_path_queue:",
          "1077:             file_path = self._file_path_queue.popleft()",
          "1078:             # Stop creating duplicate processor i.e. processor with the same filepath",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1077:         # initialize cache to mutualize calls to Variable.get in DAGs",
          "1078:         # needs to be done before this process is forked to create the DAG parsing processes.",
          "1079:         SecretCache.init()",
          "",
          "---------------"
        ],
        "airflow/models/connection.py||airflow/models/connection.py": [
          "File: airflow/models/connection.py -> airflow/models/connection.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "30: from airflow.exceptions import AirflowException, AirflowNotFoundException, RemovedInAirflow3Warning",
          "31: from airflow.models.base import ID_LEN, Base",
          "32: from airflow.models.crypto import get_fernet",
          "33: from airflow.utils.log.logging_mixin import LoggingMixin",
          "34: from airflow.utils.log.secrets_masker import mask_secret",
          "35: from airflow.utils.module_loading import import_string",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "33: from airflow.secrets.cache import SecretCache",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "451:         :param conn_id: connection id",
          "452:         :return: connection",
          "453:         \"\"\"",
          "454:         for secrets_backend in ensure_secrets_loaded():",
          "455:             try:",
          "456:                 conn = secrets_backend.get_connection(conn_id=conn_id)",
          "457:                 if conn:",
          "458:                     return conn",
          "459:             except Exception:",
          "460:                 log.exception(",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "455:         # check cache first",
          "456:         # enabled only if SecretCache.init() has been called first",
          "457:         try:",
          "458:             uri = SecretCache.get_connection_uri(conn_id)",
          "459:             return Connection(conn_id=conn_id, uri=uri)",
          "460:         except SecretCache.NotPresentException:",
          "461:             pass  # continue business",
          "463:         # iterate over backends if not in cache (or expired)",
          "468:                     SecretCache.save_connection_uri(conn_id, conn.get_uri())",
          "",
          "---------------"
        ],
        "airflow/models/variable.py||airflow/models/variable.py": [
          "File: airflow/models/variable.py -> airflow/models/variable.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "29: from airflow.configuration import ensure_secrets_loaded",
          "30: from airflow.models.base import ID_LEN, Base",
          "31: from airflow.models.crypto import get_fernet",
          "32: from airflow.secrets.metastore import MetastoreBackend",
          "33: from airflow.utils.log.logging_mixin import LoggingMixin",
          "34: from airflow.utils.log.secrets_masker import mask_secret",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "32: from airflow.secrets.cache import SecretCache",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "175:         Variable.delete(key, session=session)",
          "176:         session.add(Variable(key=key, val=stored_value, description=description))",
          "177:         session.flush()",
          "179:     @staticmethod",
          "180:     @provide_session",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "179:         # invalidate key in cache for faster propagation",
          "180:         # we cannot save the value set because it's possible that it's shadowed by a custom backend",
          "181:         # (see call to check_for_write_conflict above)",
          "182:         SecretCache.invalidate_variable(key)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "211:         :param key: Variable Keys",
          "212:         \"\"\"",
          "215:     def rotate_fernet_key(self):",
          "216:         \"\"\"Rotate Fernet Key.\"\"\"",
          "",
          "[Removed Lines]",
          "213:         return session.execute(delete(Variable).where(Variable.key == key)).rowcount",
          "",
          "[Added Lines]",
          "218:         rows = session.execute(delete(Variable).where(Variable.key == key)).rowcount",
          "219:         SecretCache.invalidate_variable(key)",
          "220:         return rows",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "256:         :param key: Variable Key",
          "257:         :return: Variable Value",
          "258:         \"\"\"",
          "259:         for secrets_backend in ensure_secrets_loaded():",
          "260:             try:",
          "261:                 var_val = secrets_backend.get_variable(key=key)",
          "262:                 if var_val is not None:",
          "264:             except Exception:",
          "265:                 log.exception(",
          "266:                     \"Unable to retrieve variable from secrets backend (%s). \"",
          "267:                     \"Checking subsequent secrets backend.\",",
          "268:                     type(secrets_backend).__name__,",
          "269:                 )",
          "",
          "[Removed Lines]",
          "263:                     return var_val",
          "270:         return None",
          "",
          "[Added Lines]",
          "266:         # check cache first",
          "267:         # enabled only if SecretCache.init() has been called first",
          "268:         try:",
          "269:             return SecretCache.get_variable(key)",
          "270:         except SecretCache.NotPresentException:",
          "271:             pass  # continue business",
          "273:         var_val = None",
          "274:         # iterate over backends if not in cache (or expired)",
          "279:                     break",
          "287:         SecretCache.save_variable(key, var_val)  # we save None as well",
          "288:         return var_val",
          "",
          "---------------"
        ],
        "airflow/secrets/cache.py||airflow/secrets/cache.py": [
          "File: airflow/secrets/cache.py -> airflow/secrets/cache.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: #",
          "2: # Licensed to the Apache Software Foundation (ASF) under one",
          "3: # or more contributor license agreements.  See the NOTICE file",
          "4: # distributed with this work for additional information",
          "5: # regarding copyright ownership.  The ASF licenses this file",
          "6: # to you under the Apache License, Version 2.0 (the",
          "7: # \"License\"); you may not use this file except in compliance",
          "8: # with the License.  You may obtain a copy of the License at",
          "9: #",
          "10: #   http://www.apache.org/licenses/LICENSE-2.0",
          "11: #",
          "12: # Unless required by applicable law or agreed to in writing,",
          "13: # software distributed under the License is distributed on an",
          "14: # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
          "15: # KIND, either express or implied.  See the License for the",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "18: from __future__ import annotations",
          "20: import datetime",
          "21: import multiprocessing",
          "23: from airflow.configuration import conf",
          "26: class SecretCache:",
          "27:     \"\"\"A static class to manage the global secret cache.\"\"\"",
          "29:     __manager: multiprocessing.managers.SyncManager | None = None",
          "30:     _cache: dict[str, _CacheValue] | None = None",
          "31:     _ttl: datetime.timedelta",
          "33:     class NotPresentException(Exception):",
          "34:         \"\"\"Raised when a key is not present in the cache.\"\"\"",
          "36:     class _CacheValue:",
          "37:         def __init__(self, value: str | None) -> None:",
          "38:             self.value = value",
          "39:             self.date = datetime.datetime.utcnow()",
          "41:         def is_expired(self, ttl: datetime.timedelta) -> bool:",
          "42:             return datetime.datetime.utcnow() - self.date > ttl",
          "44:     _VARIABLE_PREFIX = \"__v_\"",
          "45:     _CONNECTION_PREFIX = \"__c_\"",
          "47:     @classmethod",
          "48:     def init(cls):",
          "49:         \"\"\"Initializes the cache, provided the configuration allows it. Safe to call several times.\"\"\"",
          "50:         if cls._cache is not None:",
          "51:             return",
          "52:         use_cache = conf.getboolean(section=\"secrets\", key=\"use_cache\", fallback=False)",
          "53:         if not use_cache:",
          "54:             return",
          "55:         if cls.__manager is None:",
          "56:             # it is not really necessary to save the manager, but doing so allows to reuse it between tests,",
          "57:             # making them run a lot faster because this operation takes ~300ms each time",
          "58:             cls.__manager = multiprocessing.Manager()",
          "59:         cls._cache = cls.__manager.dict()",
          "60:         ttl_seconds = conf.getint(section=\"secrets\", key=\"cache_ttl_seconds\", fallback=15 * 60)",
          "61:         cls._ttl = datetime.timedelta(seconds=ttl_seconds)",
          "63:     @classmethod",
          "64:     def reset(cls):",
          "65:         \"\"\"For test purposes only.\"\"\"",
          "66:         cls._cache = None",
          "68:     @classmethod",
          "69:     def get_variable(cls, key: str) -> str | None:",
          "70:         \"\"\"",
          "71:         Tries to get the value associated with the key from the cache.",
          "73:         :return: The saved value (which can be None) if present in cache and not expired,",
          "74:             a NotPresent exception otherwise.",
          "75:         \"\"\"",
          "76:         return cls._get(key, cls._VARIABLE_PREFIX)",
          "78:     @classmethod",
          "79:     def get_connection_uri(cls, conn_id: str) -> str:",
          "80:         \"\"\"",
          "81:         Tries to get the uri associated with the conn_id from the cache.",
          "83:         :return: The saved uri if present in cache and not expired,",
          "84:             a NotPresent exception otherwise.",
          "85:         \"\"\"",
          "86:         val = cls._get(conn_id, cls._CONNECTION_PREFIX)",
          "87:         if val:  # there shouldn't be any empty entries in the connections cache, but we enforce it here.",
          "88:             return val",
          "89:         raise cls.NotPresentException",
          "91:     @classmethod",
          "92:     def _get(cls, key: str, prefix: str) -> str | None:",
          "93:         if cls._cache is None:",
          "94:             # using an exception for misses allow to meaningfully cache None values",
          "95:             raise cls.NotPresentException",
          "97:         val = cls._cache.get(f\"{prefix}{key}\")",
          "98:         if val and not val.is_expired(cls._ttl):",
          "99:             return val.value",
          "100:         raise cls.NotPresentException",
          "102:     @classmethod",
          "103:     def save_variable(cls, key: str, value: str | None):",
          "104:         \"\"\"Saves the value for that key in the cache, if initialized.\"\"\"",
          "105:         cls._save(key, value, cls._VARIABLE_PREFIX)",
          "107:     @classmethod",
          "108:     def save_connection_uri(cls, conn_id: str, uri: str):",
          "109:         \"\"\"Saves the uri representation for that connection in the cache, if initialized.\"\"\"",
          "110:         if uri is None:",
          "111:             # connections raise exceptions if not present, so we shouldn't have any None value to save.",
          "112:             return",
          "113:         cls._save(conn_id, uri, cls._CONNECTION_PREFIX)",
          "115:     @classmethod",
          "116:     def _save(cls, key: str, value: str | None, prefix: str):",
          "117:         if cls._cache is not None:",
          "118:             cls._cache[f\"{prefix}{key}\"] = cls._CacheValue(value)",
          "120:     @classmethod",
          "121:     def invalidate_variable(cls, key: str):",
          "122:         \"\"\"Invalidates (actually removes) the value stored in the cache for that Variable.\"\"\"",
          "123:         if cls._cache is not None:",
          "124:             # second arg ensures no exception if key is absent",
          "125:             cls._cache.pop(f\"{cls._VARIABLE_PREFIX}{key}\", None)",
          "",
          "---------------"
        ],
        "tests/always/test_secrets.py||tests/always/test_secrets.py": [
          "File: tests/always/test_secrets.py -> tests/always/test_secrets.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: from airflow.configuration import ensure_secrets_loaded, initialize_secrets_backends",
          "23: from airflow.models import Connection, Variable",
          "24: from tests.test_utils.config import conf_vars",
          "25: from tests.test_utils.db import clear_db_variables",
          "28: class TestConnectionsFromSecrets:",
          "29:     @mock.patch(\"airflow.secrets.metastore.MetastoreBackend.get_connection\")",
          "30:     @mock.patch(\"airflow.secrets.environment_variables.EnvironmentVariablesBackend.get_connection\")",
          "31:     def test_get_connection_second_try(self, mock_env_get, mock_meta_get):",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "24: from airflow.secrets.cache import SecretCache",
          "30:     def setup_method(self) -> None:",
          "31:         SecretCache.reset()",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "114: class TestVariableFromSecrets:",
          "115:     def setup_method(self) -> None:",
          "116:         clear_db_variables()",
          "118:     def teardown_method(self) -> None:",
          "119:         clear_db_variables()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "121:         SecretCache.reset()",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "126:         Metastore DB",
          "127:         \"\"\"",
          "128:         mock_env_get.return_value = None",
          "129:         Variable.get_variable_from_secrets(\"fake_var_key\")",
          "130:         mock_meta_get.assert_called_once_with(key=\"fake_var_key\")",
          "131:         mock_env_get.assert_called_once_with(key=\"fake_var_key\")",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "134:         mock_meta_get.return_value = \"val\"",
          "",
          "---------------"
        ],
        "tests/models/test_variable.py||tests/models/test_variable.py": [
          "File: tests/models/test_variable.py -> tests/models/test_variable.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "27: from airflow import settings",
          "28: from airflow.models import Variable, crypto, variable",
          "29: from airflow.secrets.metastore import MetastoreBackend",
          "30: from tests.test_utils import db",
          "31: from tests.test_utils.config import conf_vars",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "29: from airflow.secrets.cache import SecretCache",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "36:     def setup_test_cases(self):",
          "37:         crypto._fernet = None",
          "38:         db.clear_db_variables()",
          "39:         with mock.patch(\"airflow.models.variable.mask_secret\", autospec=True) as m:",
          "40:             self.mask_secret = m",
          "41:             yield",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "40:         SecretCache.reset()",
          "41:         with conf_vars({(\"secrets\", \"use_cache\"): \"true\"}):",
          "42:             SecretCache.init()",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "102:         caplog.set_level(logging.WARNING, logger=variable.log.name)",
          "103:         Variable.set(\"key\", \"db-value\")",
          "104:         with mock.patch.dict(\"os.environ\", AIRFLOW_VAR_KEY=\"env-value\"):",
          "105:             Variable.set(\"key\", \"new-db-value\")",
          "106:             assert \"env-value\" == Variable.get(\"key\")",
          "107:         assert \"new-db-value\" == Variable.get(\"key\")",
          "109:         assert caplog.messages[0] == (",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "109:             # setting value while shadowed by an env variable will generate a warning",
          "111:             # value set above is not returned because the env variable value takes priority",
          "113:         # invalidate the cache to re-evaluate value",
          "114:         SecretCache.invalidate_variable(\"key\")",
          "115:         # now that env var is not here anymore, we see the value we set before.",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "259:         finally:",
          "260:             session.rollback()",
          "263: @pytest.mark.parametrize(",
          "264:     \"variable_value, deserialize_json, expected_masked_values\",",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "271:     @mock.patch(\"airflow.models.variable.ensure_secrets_loaded\")",
          "272:     def test_caching_caches(self, mock_ensure_secrets: mock.Mock):",
          "273:         mock_backend = mock.Mock()",
          "274:         mock_backend.get_variable.return_value = \"secret_val\"",
          "275:         mock_backend.__class__.__name__ = \"MockSecretsBackend\"",
          "276:         mock_ensure_secrets.return_value = [mock_backend, MetastoreBackend]",
          "278:         key = \"doesn't matter\"",
          "279:         first = Variable.get(key)",
          "280:         second = Variable.get(key)",
          "282:         mock_backend.get_variable.assert_called_once()  # second call was not made because of cache",
          "283:         assert first == second",
          "285:     def test_cache_invalidation_on_set(self):",
          "286:         with mock.patch.dict(\"os.environ\", AIRFLOW_VAR_KEY=\"from_env\"):",
          "287:             a = Variable.get(\"key\")  # value is saved in cache",
          "288:         with mock.patch.dict(\"os.environ\", AIRFLOW_VAR_KEY=\"from_env_two\"):",
          "289:             b = Variable.get(\"key\")  # value from cache is used",
          "290:         assert a == b",
          "292:         # setting a new value invalidates the cache",
          "293:         Variable.set(\"key\", \"new_value\")",
          "295:         c = Variable.get(\"key\")  # cache should not be used",
          "297:         assert c != b",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "272: def test_masking_only_secret_values(variable_value, deserialize_json, expected_masked_values):",
          "273:     from airflow.utils.log.secrets_masker import _secrets_masker",
          "275:     session = settings.Session()",
          "277:     try:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "312:     SecretCache.reset()",
          "",
          "---------------"
        ],
        "tests/secrets/test_cache.py||tests/secrets/test_cache.py": [
          "File: tests/secrets/test_cache.py -> tests/secrets/test_cache.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: # Licensed to the Apache Software Foundation (ASF) under one",
          "2: # or more contributor license agreements.  See the NOTICE file",
          "3: # distributed with this work for additional information",
          "4: # regarding copyright ownership.  The ASF licenses this file",
          "5: # to you under the Apache License, Version 2.0 (the",
          "6: # \"License\"); you may not use this file except in compliance",
          "7: # with the License.  You may obtain a copy of the License at",
          "8: #",
          "9: #   http://www.apache.org/licenses/LICENSE-2.0",
          "10: #",
          "11: # Unless required by applicable law or agreed to in writing,",
          "12: # software distributed under the License is distributed on an",
          "13: # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
          "14: # KIND, either express or implied.  See the License for the",
          "15: # specific language governing permissions and limitations",
          "16: # under the License.",
          "17: from __future__ import annotations",
          "19: import datetime",
          "20: import multiprocessing",
          "22: import pytest",
          "24: from airflow.secrets.cache import SecretCache",
          "25: from tests.test_utils.config import conf_vars",
          "28: def test_cache_disabled_by_default():",
          "29:     SecretCache.init()",
          "30:     SecretCache.save_variable(\"test\", \"not saved\")",
          "31:     with pytest.raises(SecretCache.NotPresentException):",
          "32:         SecretCache.get_variable(\"test\")",
          "33:     assert SecretCache._cache is None",
          "36: class TestSecretCache:",
          "37:     @staticmethod",
          "38:     @conf_vars({(\"secrets\", \"use_cache\"): \"true\"})",
          "39:     def setup_method() -> None:",
          "40:         SecretCache.init()",
          "42:     @staticmethod",
          "43:     def teardown_method(self) -> None:",
          "44:         SecretCache.reset()",
          "46:     def test_cache_accessible_from_other_process(self):",
          "47:         def writer():",
          "48:             SecretCache.save_variable(\"key\", \"secret_val\")",
          "50:         def reader(pipe: multiprocessing.connection.Connection):",
          "51:             v = SecretCache.get_variable(\"key\")",
          "52:             pipe.send(v)",
          "53:             pipe.close()",
          "55:         SecretCache.init()  # init needs to be explicit before creating threads",
          "56:         c = multiprocessing.get_context(\"fork\")",
          "57:         # run first process that's going to set a key in the cache",
          "58:         p1 = c.Process(target=writer)",
          "59:         p1.start()",
          "60:         p1.join()",
          "61:         # setup pipe to receive what second process read (returns reading and writing ends of the pipe)",
          "62:         r, w = c.Pipe(duplex=False)",
          "63:         # start second process that's going to try to get the same key from the cache",
          "64:         p2 = c.Process(target=reader, args=(w,))",
          "65:         p2.start()",
          "66:         w.close()  # close pipe on our end because it's used by the child process",
          "67:         val = r.recv()",
          "68:         p2.join()",
          "70:         assert val is not None",
          "71:         assert val == \"secret_val\"",
          "73:     def test_returns_none_when_not_init(self):",
          "74:         with pytest.raises(SecretCache.NotPresentException):",
          "75:             SecretCache.get_variable(\"whatever\")",
          "77:     def test_cache_saves_none_as_sentinel(self):",
          "78:         SecretCache.save_variable(\"key\", None)",
          "80:         res = SecretCache.get_variable(\"key\")",
          "82:         assert res is None",
          "84:     def test_invalidate(self):",
          "85:         SecretCache.save_variable(\"key\", \"some_value\")",
          "87:         assert SecretCache.get_variable(\"key\") == \"some_value\"",
          "89:         SecretCache.invalidate_variable(\"key\")",
          "91:         # cannot get the value for that key anymore because we invalidated it",
          "92:         with pytest.raises(SecretCache.NotPresentException):",
          "93:             SecretCache.get_variable(\"key\")",
          "95:     def test_invalidate_key_not_present(self):",
          "96:         SecretCache.invalidate_variable(\"not present\")  # simply shouldn't raise any exception.",
          "98:     def test_expiration(self):",
          "99:         SecretCache.save_variable(\"key\", \"some_value\")",
          "101:         assert SecretCache.get_variable(\"key\") == \"some_value\"",
          "103:         SecretCache._ttl = datetime.timedelta(0)  # I don't want to sleep()",
          "105:         # value is now seen as expired",
          "106:         with pytest.raises(SecretCache.NotPresentException):",
          "107:             SecretCache.get_variable(\"key\")",
          "109:     @conf_vars({(\"secrets\", \"use_cache\"): \"0\"})",
          "110:     def test_disabled(self):",
          "111:         # do init to have it read config",
          "112:         SecretCache.reset()",
          "113:         SecretCache.init()",
          "115:         SecretCache.save_variable(\"key\", \"some_value\")  # will be ignored",
          "117:         # cache is disabled, gets will always \"fail\"",
          "118:         with pytest.raises(SecretCache.NotPresentException):",
          "119:             SecretCache.get_variable(\"key\")",
          "121:     def test_independence_variable_connection(self):",
          "122:         SecretCache.save_variable(\"same_key\", \"some_value\")",
          "123:         SecretCache.save_connection_uri(\"same_key\", \"some_other_value\")",
          "125:         assert SecretCache.get_variable(\"same_key\") == \"some_value\"",
          "126:         assert SecretCache.get_connection_uri(\"same_key\") == \"some_other_value\"",
          "128:         SecretCache.save_variable(\"var\", \"some_value\")",
          "129:         SecretCache.save_connection_uri(\"conn\", \"some_other_value\")",
          "131:         # getting the wrong type of thing with a key that exists in the other will not work",
          "132:         with pytest.raises(SecretCache.NotPresentException):",
          "133:             SecretCache.get_connection_uri(\"var\")",
          "134:         with pytest.raises(SecretCache.NotPresentException):",
          "135:             SecretCache.get_variable(\"conn\")",
          "137:     def test_connections_do_not_save_none(self):",
          "138:         # noinspection PyTypeChecker",
          "139:         SecretCache.save_connection_uri(\"key\", None)",
          "141:         with pytest.raises(SecretCache.NotPresentException):",
          "142:             SecretCache.get_connection_uri(\"key\")",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "473452d3b7b0149c89e264dda7b2e5ccf7e0ead0",
      "candidate_info": {
        "commit_hash": "473452d3b7b0149c89e264dda7b2e5ccf7e0ead0",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/473452d3b7b0149c89e264dda7b2e5ccf7e0ead0",
        "files": [
          "airflow/config_templates/pre_2_7_defaults.cfg"
        ],
        "message": "Add elasticsearch group to pre-2.7 defaults (#33166)\n\nThe elasticsearch group is likely to be moved to elasticsearch\nprovider. Anticipating that (see #33135) we need to move it to\npre-2.7 defaults in order to have back-compatibility for providers\nthat assume default values to be there.\n\n(cherry picked from commit 2d7460450dda5cc2f20d1e8cd9ead9e4d1946909)",
        "before_after_code_files": [
          "airflow/config_templates/pre_2_7_defaults.cfg||airflow/config_templates/pre_2_7_defaults.cfg"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/33247"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/config_templates/pre_2_7_defaults.cfg||airflow/config_templates/pre_2_7_defaults.cfg": [
          "File: airflow/config_templates/pre_2_7_defaults.cfg -> airflow/config_templates/pre_2_7_defaults.cfg",
          "--- Hunk 1 ---",
          "[Context before]",
          "65: task_publish_max_retries = 3",
          "66: worker_precheck = False",
          "68: [elasticsearch_configs]",
          "69: use_ssl = False",
          "70: verify_certs = True",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "68: [elasticsearch]",
          "69: host =",
          "70: log_id_template = {dag_id}-{task_id}-{run_id}-{map_index}-{try_number}",
          "71: end_of_log_mark = end_of_log",
          "72: frontend =",
          "73: write_stdout = False",
          "74: json_format = False",
          "75: json_fields = asctime, filename, lineno, levelname, message",
          "76: host_field = host",
          "77: offset_field = offset",
          "78: index_patterns = _all",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "690f3f121699c79dbbd293590d820815a10ba3b1",
      "candidate_info": {
        "commit_hash": "690f3f121699c79dbbd293590d820815a10ba3b1",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/690f3f121699c79dbbd293590d820815a10ba3b1",
        "files": [
          "tests/conftest.py"
        ],
        "message": "Cleanup all sqlalchemy sessions before each test (#33190)\n\nAttempt to solve some of the flakiness we saw recently - this\nchange will run closing all opened sqlalchemy sessions before each\ntest. This should be a little slower than before - especially\nfor the very fast tests, but it provide us with much better\nisolation between the tests - thus avoiding the flakiness\nthat we observe recently - as documented in #33178\n\nHopefully this one\n\nFixes: #33178\n(cherry picked from commit 515179fe67c0c6bd8b693c5ab313f4a0cfbacea7)",
        "before_after_code_files": [
          "tests/conftest.py||tests/conftest.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/33247"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "tests/conftest.py||tests/conftest.py": [
          "File: tests/conftest.py -> tests/conftest.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "942:     from airflow.providers_manager import ProvidersManager",
          "944:     ProvidersManager().initialize_providers_configuration()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "947: @pytest.fixture(autouse=True, scope=\"function\")",
          "948: def close_all_sqlalchemy_sessions():",
          "949:     from sqlalchemy.orm import close_all_sessions",
          "951:     close_all_sessions()",
          "952:     yield",
          "953:     close_all_sessions()",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "c11e81460d03747cdfaabb2af7679a50bad3afb6",
      "candidate_info": {
        "commit_hash": "c11e81460d03747cdfaabb2af7679a50bad3afb6",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/c11e81460d03747cdfaabb2af7679a50bad3afb6",
        "files": [
          "airflow/cli/commands/webserver_command.py",
          "airflow/config_templates/config.yml"
        ],
        "message": "Fix reload gunicorn workers (#32102)\n\n* Toggle gunicorn --preload with reload_on_plugin_change\n\nSince gunicorn can't reload a new code if starts with ``--preload``\nsetting, we need to check ``reload_on_plugin_change`` before set it up.\n\nGunicorn can't reload a new code because the code is preloaded into the\nmaster process and worker are launched with ``fork``, they will still have\nthe old code.\n\n* added warning message\n\n* Improve warning message\n\nCo-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com>\n\n* Improve warning message\n\nCo-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com>\n\n* Improve warning message\n\nCo-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com>\n\n* Minor tweak of warning message\n\n* Mention prod issue in config description\n\n---------\n\nCo-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com>\nCo-authored-by: Tzu-ping Chung <uranusjr@gmail.com>\n(cherry picked from commit f78a8363a6542a4b4c94642434424da7af7fcbbb)",
        "before_after_code_files": [
          "airflow/cli/commands/webserver_command.py||airflow/cli/commands/webserver_command.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/33247"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/cli/commands/webserver_command.py||airflow/cli/commands/webserver_command.py": [
          "File: airflow/cli/commands/webserver_command.py -> airflow/cli/commands/webserver_command.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "423:         run_args += [\"airflow.www.app:cached_app()\"]",
          "431:         gunicorn_master_proc: psutil.Process | subprocess.Popen",
          "",
          "[Removed Lines]",
          "425:         # To prevent different workers creating the web app and",
          "426:         # all writing to the database at the same time, we use the --preload option.",
          "427:         # With the preload option, the app is loaded before the workers are forked, and each worker will",
          "428:         # then have a copy of the app",
          "429:         run_args += [\"--preload\"]",
          "",
          "[Added Lines]",
          "425:         if conf.getboolean(\"webserver\", \"reload_on_plugin_change\", fallback=False):",
          "426:             log.warning(",
          "427:                 \"Setting reload_on_plugin_change = true prevents running Gunicorn with preloading. \"",
          "428:                 \"This means the app cannot be loaded before workers are forked, and each worker has a \"",
          "429:                 \"separate copy of the app. This may cause IntegrityError during webserver startup, and \"",
          "430:                 \"should be avoided in production.\"",
          "431:             )",
          "432:         else:",
          "433:             # To prevent different workers creating the web app and",
          "434:             # all writing to the database at the same time, we use the --preload option.",
          "435:             run_args += [\"--preload\"]",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "28e88f412aa1553133c155420ad064e2a92596bc",
      "candidate_info": {
        "commit_hash": "28e88f412aa1553133c155420ad064e2a92596bc",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/28e88f412aa1553133c155420ad064e2a92596bc",
        "files": [
          "airflow/example_dags/example_python_operator.py",
          "airflow/example_dags/tutorial_taskflow_api_virtualenv.py",
          "airflow/operators/python.py",
          "tests/operators/test_python.py"
        ],
        "message": "Fix venv detection for Python virtualenv operator (#33223)\n\nThis is a follow-up after #32939. It seems that findspec does not\ncover all the cases and the previous check is also faster.\n\nAdding check for the binary first and then falling back to spec\nfinding will make it faster and work in the cases where the\nfindspec does not work (for local development cases).\n\n(cherry picked from commit c4fe5b8b8a3b12750bb2984aca198f7bb16b6785)",
        "before_after_code_files": [
          "airflow/example_dags/example_python_operator.py||airflow/example_dags/example_python_operator.py",
          "airflow/example_dags/tutorial_taskflow_api_virtualenv.py||airflow/example_dags/tutorial_taskflow_api_virtualenv.py",
          "airflow/operators/python.py||airflow/operators/python.py",
          "tests/operators/test_python.py||tests/operators/test_python.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/33247"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/example_dags/example_python_operator.py||airflow/example_dags/example_python_operator.py": [
          "File: airflow/example_dags/example_python_operator.py -> airflow/example_dags/example_python_operator.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: from __future__ import annotations",
          "24: import logging",
          "26: import sys",
          "27: import tempfile",
          "28: import time",
          "",
          "[Removed Lines]",
          "25: import shutil",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "33: from airflow import DAG",
          "34: from airflow.decorators import task",
          "37: log = logging.getLogger(__name__)",
          "",
          "[Removed Lines]",
          "35: from airflow.operators.python import ExternalPythonOperator, PythonVirtualenvOperator",
          "",
          "[Added Lines]",
          "34: from airflow.operators.python import ExternalPythonOperator, PythonVirtualenvOperator, is_venv_installed",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "86:         run_this >> log_the_sql >> sleeping_task",
          "87:     # [END howto_operator_python_kwargs]",
          "90:         log.warning(\"The virtalenv_python example task requires virtualenv, please install it.\")",
          "91:     else:",
          "92:         # [START howto_operator_python_venv]",
          "",
          "[Removed Lines]",
          "89:     if not shutil.which(\"virtualenv\"):",
          "",
          "[Added Lines]",
          "88:     if not is_venv_installed():",
          "",
          "---------------"
        ],
        "airflow/example_dags/tutorial_taskflow_api_virtualenv.py||airflow/example_dags/tutorial_taskflow_api_virtualenv.py": [
          "File: airflow/example_dags/tutorial_taskflow_api_virtualenv.py -> airflow/example_dags/tutorial_taskflow_api_virtualenv.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: from __future__ import annotations",
          "20: import logging",
          "22: from datetime import datetime",
          "24: from airflow.decorators import dag, task",
          "26: log = logging.getLogger(__name__)",
          "29:     log.warning(\"The tutorial_taskflow_api_virtualenv example DAG requires virtualenv, please install it.\")",
          "30: else:",
          "",
          "[Removed Lines]",
          "21: import shutil",
          "28: if not shutil.which(\"virtualenv\"):",
          "",
          "[Added Lines]",
          "24: from airflow.operators.python import is_venv_installed",
          "28: if not is_venv_installed():",
          "",
          "---------------"
        ],
        "airflow/operators/python.py||airflow/operators/python.py": [
          "File: airflow/operators/python.py -> airflow/operators/python.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: import logging",
          "23: import os",
          "24: import pickle",
          "25: import subprocess",
          "26: import sys",
          "27: import types",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "25: import shutil",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "54:     from pendulum.datetime import DateTime",
          "57: def task(python_callable: Callable | None = None, multiple_outputs: bool | None = None, **kwargs):",
          "58:     \"\"\"Deprecated. Use :func:`airflow.decorators.task` instead.",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "58: def is_venv_installed() -> bool:",
          "59:     \"\"\"",
          "60:     Checks if the virtualenv package is installed via checking if it is on the path or installed as package.",
          "62:     :return: True if it is. Whichever way of checking it works, is fine.",
          "63:     \"\"\"",
          "64:     if shutil.which(\"virtualenv\") or importlib.util.find_spec(\"virtualenv\"):",
          "65:         return True",
          "66:     return False",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "540:                 \"major versions for PythonVirtualenvOperator. Please use string_args.\"",
          "541:                 f\"Sys version: {sys.version_info}. Venv version: {python_version}\"",
          "542:             )",
          "544:             raise AirflowException(\"PythonVirtualenvOperator requires virtualenv, please install it.\")",
          "545:         if not requirements:",
          "546:             self.requirements: list[str] | str = []",
          "",
          "[Removed Lines]",
          "543:         if importlib.util.find_spec(\"virtualenv\") is None:",
          "",
          "[Added Lines]",
          "555:         if not is_venv_installed():",
          "",
          "---------------"
        ],
        "tests/operators/test_python.py||tests/operators/test_python.py": [
          "File: tests/operators/test_python.py -> tests/operators/test_python.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "847:         kwargs[\"python_version\"] = python_version",
          "848:         return kwargs",
          "850:     @mock.patch(\"airflow.operators.python.importlib\")",
          "853:         with pytest.raises(AirflowException, match=\"requires virtualenv\"):",
          "855:             def f():",
          "",
          "[Removed Lines]",
          "851:     def test_virtuenv_not_installed(self, importlib):",
          "852:         importlib.util.find_spec.return_value = None",
          "",
          "[Added Lines]",
          "850:     @mock.patch(\"shutil.which\")",
          "852:     def test_virtuenv_not_installed(self, importlib_mock, which_mock):",
          "853:         which_mock.return_value = None",
          "854:         importlib_mock.util.find_spec.return_value = None",
          "",
          "---------------"
        ]
      }
    }
  ]
}