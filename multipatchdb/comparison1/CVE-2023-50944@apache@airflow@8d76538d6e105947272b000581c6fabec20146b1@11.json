{
  "cve_id": "CVE-2023-50944",
  "cve_desc": "Apache Airflow, versions before 2.8.1, have a vulnerability that allows an authenticated user to access the source code of a DAG to which they don't have access.\u00a0This vulnerability is considered low since it requires an authenticated user to exploit it. Users are recommended to upgrade to version 2.8.1, which fixes this issue.",
  "repo": "apache/airflow",
  "patch_hash": "8d76538d6e105947272b000581c6fabec20146b1",
  "patch_info": {
    "commit_hash": "8d76538d6e105947272b000581c6fabec20146b1",
    "repo": "apache/airflow",
    "commit_url": "https://github.com/apache/airflow/commit/8d76538d6e105947272b000581c6fabec20146b1",
    "files": [
      "airflow/api_connexion/endpoints/dag_source_endpoint.py",
      "airflow/models/dagcode.py",
      "tests/api_connexion/endpoints/test_dag_source_endpoint.py"
    ],
    "message": "Check DAG read permission before accessing DAG code (#36257)\n\n(cherry picked from commit 30ea37e0d247ce54c2d25b115e807fdb0074d795)",
    "before_after_code_files": [
      "airflow/api_connexion/endpoints/dag_source_endpoint.py||airflow/api_connexion/endpoints/dag_source_endpoint.py",
      "airflow/models/dagcode.py||airflow/models/dagcode.py",
      "tests/api_connexion/endpoints/test_dag_source_endpoint.py||tests/api_connexion/endpoints/test_dag_source_endpoint.py"
    ]
  },
  "patch_diff": {
    "airflow/api_connexion/endpoints/dag_source_endpoint.py||airflow/api_connexion/endpoints/dag_source_endpoint.py": [
      "File: airflow/api_connexion/endpoints/dag_source_endpoint.py -> airflow/api_connexion/endpoints/dag_source_endpoint.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "17: from __future__ import annotations",
      "19: from http import HTTPStatus",
      "21: from flask import Response, current_app, request",
      "22: from itsdangerous import BadSignature, URLSafeSerializer",
      "24: from airflow.api_connexion import security",
      "26: from airflow.api_connexion.schemas.dag_source_schema import dag_source_schema",
      "27: from airflow.auth.managers.models.resource_details import DagAccessEntity",
      "28: from airflow.models.dagcode import DagCode",
      "31: @security.requires_access_dag(\"GET\", DagAccessEntity.CODE)",
      "33:     \"\"\"Get source code using file token.\"\"\"",
      "34:     secret_key = current_app.config[\"SECRET_KEY\"]",
      "35:     auth_s = URLSafeSerializer(secret_key)",
      "36:     try:",
      "37:         path = auth_s.loads(file_token)",
      "39:     except (BadSignature, FileNotFoundError):",
      "40:         raise NotFound(\"Dag source not found\")",
      "",
      "[Removed Lines]",
      "25: from airflow.api_connexion.exceptions import NotFound",
      "32: def get_dag_source(*, file_token: str) -> Response:",
      "38:         dag_source = DagCode.code(path)",
      "",
      "[Added Lines]",
      "20: from typing import TYPE_CHECKING",
      "26: from airflow.api_connexion.exceptions import NotFound, PermissionDenied",
      "28: from airflow.api_connexion.security import get_readable_dags",
      "30: from airflow.models.dag import DagModel",
      "32: from airflow.utils.session import NEW_SESSION, provide_session",
      "34: if TYPE_CHECKING:",
      "35:     from sqlalchemy.orm import Session",
      "39: @provide_session",
      "40: def get_dag_source(*, file_token: str, session: Session = NEW_SESSION) -> Response:",
      "46:         dag_ids = session.query(DagModel.dag_id).filter(DagModel.fileloc == path).all()",
      "47:         readable_dags = get_readable_dags()",
      "48:         # Check if user has read access to all the DAGs defined in the file",
      "49:         if any(dag_id[0] not in readable_dags for dag_id in dag_ids):",
      "50:             raise PermissionDenied()",
      "51:         dag_source = DagCode.code(path, session=session)",
      "",
      "---------------"
    ],
    "airflow/models/dagcode.py||airflow/models/dagcode.py": [
      "File: airflow/models/dagcode.py -> airflow/models/dagcode.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "177:         return cls.code(fileloc)",
      "179:     @classmethod",
      "181:         \"\"\"Return source code for this DagCode object.",
      "183:         :return: source code as string",
      "184:         \"\"\"",
      "187:     @staticmethod",
      "188:     def _get_code_from_file(fileloc):",
      "",
      "[Removed Lines]",
      "180:     def code(cls, fileloc) -> str:",
      "185:         return cls._get_code_from_db(fileloc)",
      "",
      "[Added Lines]",
      "180:     @provide_session",
      "181:     def code(cls, fileloc, session: Session = NEW_SESSION) -> str:",
      "186:         return cls._get_code_from_db(fileloc, session)",
      "",
      "---------------"
    ],
    "tests/api_connexion/endpoints/test_dag_source_endpoint.py||tests/api_connexion/endpoints/test_dag_source_endpoint.py": [
      "File: tests/api_connexion/endpoints/test_dag_source_endpoint.py -> tests/api_connexion/endpoints/test_dag_source_endpoint.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "35: ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), os.pardir, os.pardir))",
      "36: EXAMPLE_DAG_FILE = os.path.join(\"airflow\", \"example_dags\", \"example_bash_operator.py\")",
      "39: @pytest.fixture(scope=\"module\")",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "37: EXAMPLE_DAG_ID = \"example_bash_operator\"",
      "38: TEST_DAG_ID = \"latest_only\"",
      "39: NOT_READABLE_DAG_ID = \"latest_only_with_trigger\"",
      "40: TEST_MULTIPLE_DAGS_ID = \"dataset_produces_1\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "45:         role_name=\"Test\",",
      "46:         permissions=[(permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG_CODE)],  # type: ignore",
      "47:     )",
      "48:     create_user(app, username=\"test_no_permissions\", role_name=\"TestNoPermissions\")  # type: ignore",
      "50:     yield app",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "52:     app.appbuilder.sm.sync_perm_for_dag(  # type: ignore",
      "53:         TEST_DAG_ID,",
      "54:         access_control={\"Test\": [permissions.ACTION_CAN_READ]},",
      "55:     )",
      "56:     app.appbuilder.sm.sync_perm_for_dag(  # type: ignore",
      "57:         EXAMPLE_DAG_ID,",
      "58:         access_control={\"Test\": [permissions.ACTION_CAN_READ]},",
      "59:     )",
      "60:     app.appbuilder.sm.sync_perm_for_dag(  # type: ignore",
      "61:         TEST_MULTIPLE_DAGS_ID,",
      "62:         access_control={\"Test\": [permissions.ACTION_CAN_READ]},",
      "63:     )",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "80:     def test_should_respond_200_text(self, url_safe_serializer):",
      "81:         dagbag = DagBag(dag_folder=EXAMPLE_DAG_FILE)",
      "82:         dagbag.sync_to_db()",
      "87:         response = self.client.get(",
      "88:             url, headers={\"Accept\": \"text/plain\"}, environ_overrides={\"REMOTE_USER\": \"test\"}",
      "89:         )",
      "",
      "[Removed Lines]",
      "83:         first_dag: DAG = next(iter(dagbag.dags.values()))",
      "84:         dag_docstring = self._get_dag_file_docstring(first_dag.fileloc)",
      "86:         url = f\"/api/v1/dagSources/{url_safe_serializer.dumps(first_dag.fileloc)}\"",
      "",
      "[Added Lines]",
      "99:         test_dag: DAG = dagbag.dags[TEST_DAG_ID]",
      "100:         dag_docstring = self._get_dag_file_docstring(test_dag.fileloc)",
      "102:         url = f\"/api/v1/dagSources/{url_safe_serializer.dumps(test_dag.fileloc)}\"",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "95:     def test_should_respond_200_json(self, url_safe_serializer):",
      "96:         dagbag = DagBag(dag_folder=EXAMPLE_DAG_FILE)",
      "97:         dagbag.sync_to_db()",
      "102:         response = self.client.get(",
      "103:             url, headers={\"Accept\": \"application/json\"}, environ_overrides={\"REMOTE_USER\": \"test\"}",
      "104:         )",
      "",
      "[Removed Lines]",
      "98:         first_dag: DAG = next(iter(dagbag.dags.values()))",
      "99:         dag_docstring = self._get_dag_file_docstring(first_dag.fileloc)",
      "101:         url = f\"/api/v1/dagSources/{url_safe_serializer.dumps(first_dag.fileloc)}\"",
      "",
      "[Added Lines]",
      "114:         test_dag: DAG = dagbag.dags[TEST_DAG_ID]",
      "115:         dag_docstring = self._get_dag_file_docstring(test_dag.fileloc)",
      "117:         url = f\"/api/v1/dagSources/{url_safe_serializer.dumps(test_dag.fileloc)}\"",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "110:     def test_should_respond_406(self, url_safe_serializer):",
      "111:         dagbag = DagBag(dag_folder=EXAMPLE_DAG_FILE)",
      "112:         dagbag.sync_to_db()",
      "116:         response = self.client.get(",
      "117:             url, headers={\"Accept\": \"image/webp\"}, environ_overrides={\"REMOTE_USER\": \"test\"}",
      "118:         )",
      "",
      "[Removed Lines]",
      "113:         first_dag: DAG = next(iter(dagbag.dags.values()))",
      "115:         url = f\"/api/v1/dagSources/{url_safe_serializer.dumps(first_dag.fileloc)}\"",
      "",
      "[Added Lines]",
      "129:         test_dag: DAG = dagbag.dags[TEST_DAG_ID]",
      "131:         url = f\"/api/v1/dagSources/{url_safe_serializer.dumps(test_dag.fileloc)}\"",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "151:             environ_overrides={\"REMOTE_USER\": \"test_no_permissions\"},",
      "152:         )",
      "153:         assert response.status_code == 403",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "171:     def test_should_respond_403_not_readable(self, url_safe_serializer):",
      "172:         dagbag = DagBag(dag_folder=EXAMPLE_DAG_FILE)",
      "173:         dagbag.sync_to_db()",
      "174:         dag: DAG = dagbag.dags[NOT_READABLE_DAG_ID]",
      "176:         response = self.client.get(",
      "177:             f\"/api/v1/dagSources/{url_safe_serializer.dumps(dag.fileloc)}\",",
      "178:             headers={\"Accept\": \"text/plain\"},",
      "179:             environ_overrides={\"REMOTE_USER\": \"test\"},",
      "180:         )",
      "181:         read_dag = self.client.get(",
      "182:             f\"/api/v1/dags/{NOT_READABLE_DAG_ID}\",",
      "183:             environ_overrides={\"REMOTE_USER\": \"test\"},",
      "184:         )",
      "185:         assert response.status_code == 403",
      "186:         assert read_dag.status_code == 403",
      "188:     def test_should_respond_403_some_dags_not_readable_in_the_file(self, url_safe_serializer):",
      "189:         dagbag = DagBag(dag_folder=EXAMPLE_DAG_FILE)",
      "190:         dagbag.sync_to_db()",
      "191:         dag: DAG = dagbag.dags[TEST_MULTIPLE_DAGS_ID]",
      "193:         response = self.client.get(",
      "194:             f\"/api/v1/dagSources/{url_safe_serializer.dumps(dag.fileloc)}\",",
      "195:             headers={\"Accept\": \"text/plain\"},",
      "196:             environ_overrides={\"REMOTE_USER\": \"test\"},",
      "197:         )",
      "199:         read_dag = self.client.get(",
      "200:             f\"/api/v1/dags/{TEST_MULTIPLE_DAGS_ID}\",",
      "201:             environ_overrides={\"REMOTE_USER\": \"test\"},",
      "202:         )",
      "203:         assert response.status_code == 403",
      "204:         assert read_dag.status_code == 200",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "4bad5e4f95990c918e7138c83e900200524ec61f",
      "candidate_info": {
        "commit_hash": "4bad5e4f95990c918e7138c83e900200524ec61f",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/4bad5e4f95990c918e7138c83e900200524ec61f",
        "files": [
          "airflow/providers/apache/hdfs/provider.yaml",
          "airflow/providers/apache/kylin/provider.yaml",
          "dev/breeze/src/airflow_breeze/breeze.py"
        ],
        "message": "Fixes small issues related to suspended/removed providers (#36501)\n\nAfter speeding up breeze in #36499 there are few small fixes needed\nfor suspended/removed providers.",
        "before_after_code_files": [
          "dev/breeze/src/airflow_breeze/breeze.py||dev/breeze/src/airflow_breeze/breeze.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "dev/breeze/src/airflow_breeze/breeze.py||dev/breeze/src/airflow_breeze/breeze.py": [
          "File: dev/breeze/src/airflow_breeze/breeze.py -> dev/breeze/src/airflow_breeze/breeze.py"
        ]
      }
    },
    {
      "candidate_hash": "d80d6a1a0143055598c0b269c015b426d7191b4e",
      "candidate_info": {
        "commit_hash": "d80d6a1a0143055598c0b269c015b426d7191b4e",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/d80d6a1a0143055598c0b269c015b426d7191b4e",
        "files": [
          "airflow/operators/bash.py",
          "tests/operators/test_bash.py"
        ],
        "message": "Fix AirflowSkipException message raised by BashOperator (#36354)\n\n(cherry picked from commit 667a5b2d29c1ce46021d400fa591650855dcf26c)",
        "before_after_code_files": [
          "airflow/operators/bash.py||airflow/operators/bash.py",
          "tests/operators/test_bash.py||tests/operators/test_bash.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/operators/bash.py||airflow/operators/bash.py": [
          "File: airflow/operators/bash.py -> airflow/operators/bash.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "162:             skip_on_exit_code",
          "163:             if isinstance(skip_on_exit_code, Container)",
          "164:             else [skip_on_exit_code]",
          "166:             else []",
          "167:         )",
          "168:         self.cwd = cwd",
          "",
          "[Removed Lines]",
          "165:             if skip_on_exit_code",
          "",
          "[Added Lines]",
          "165:             if skip_on_exit_code is not None",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "206:             output_encoding=self.output_encoding,",
          "207:             cwd=self.cwd,",
          "208:         )",
          "211:         elif result.exit_code != 0:",
          "212:             raise AirflowException(",
          "213:                 f\"Bash command failed. The command returned a non-zero exit code {result.exit_code}.\"",
          "",
          "[Removed Lines]",
          "209:         if self.skip_on_exit_code is not None and result.exit_code in self.skip_on_exit_code:",
          "210:             raise AirflowSkipException(f\"Bash command returned exit code {self.skip_on_exit_code}. Skipping.\")",
          "",
          "[Added Lines]",
          "209:         if result.exit_code in self.skip_on_exit_code:",
          "210:             raise AirflowSkipException(f\"Bash command returned exit code {result.exit_code}. Skipping.\")",
          "",
          "---------------"
        ],
        "tests/operators/test_bash.py||tests/operators/test_bash.py": [
          "File: tests/operators/test_bash.py -> tests/operators/test_bash.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "169:     @pytest.mark.parametrize(",
          "170:         \"extra_kwargs,actual_exit_code,expected_exc\",",
          "171:         [",
          "175:             ({\"skip_on_exit_code\": None}, 99, AirflowException),",
          "176:             ({\"skip_on_exit_code\": [100]}, 100, AirflowSkipException),",
          "181:         ],",
          "182:     )",
          "183:     def test_skip(self, extra_kwargs, actual_exit_code, expected_exc):",
          "",
          "[Removed Lines]",
          "172:             (None, 99, AirflowSkipException),",
          "173:             ({\"skip_on_exit_code\": 100}, 100, AirflowSkipException),",
          "174:             ({\"skip_on_exit_code\": 100}, 101, AirflowException),",
          "177:             ({\"skip_on_exit_code\": (100, 101)}, 100, AirflowSkipException),",
          "178:             ({\"skip_on_exit_code\": 100}, 101, AirflowException),",
          "179:             ({\"skip_on_exit_code\": [100, 102]}, 101, AirflowException),",
          "180:             ({\"skip_on_exit_code\": None}, 0, None),",
          "",
          "[Added Lines]",
          "172:             ({}, 0, None),",
          "173:             ({}, 100, AirflowException),",
          "174:             ({}, 99, AirflowSkipException),",
          "175:             ({\"skip_on_exit_code\": None}, 0, None),",
          "176:             ({\"skip_on_exit_code\": None}, 100, AirflowException),",
          "178:             ({\"skip_on_exit_code\": 100}, 0, None),",
          "179:             ({\"skip_on_exit_code\": 100}, 100, AirflowSkipException),",
          "180:             ({\"skip_on_exit_code\": 100}, 99, AirflowException),",
          "181:             ({\"skip_on_exit_code\": 0}, 0, AirflowSkipException),",
          "182:             ({\"skip_on_exit_code\": [100]}, 0, None),",
          "184:             ({\"skip_on_exit_code\": [100]}, 99, AirflowException),",
          "185:             ({\"skip_on_exit_code\": [100, 102]}, 99, AirflowException),",
          "186:             ({\"skip_on_exit_code\": (100,)}, 0, None),",
          "187:             ({\"skip_on_exit_code\": (100,)}, 100, AirflowSkipException),",
          "188:             ({\"skip_on_exit_code\": (100,)}, 99, AirflowException),",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "2c10e93f6745e9f86c3be901839b89eaac374ce2",
      "candidate_info": {
        "commit_hash": "2c10e93f6745e9f86c3be901839b89eaac374ce2",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/2c10e93f6745e9f86c3be901839b89eaac374ce2",
        "files": [
          "airflow/__init__.py",
          "docs/docker-stack/README.md",
          "docs/docker-stack/docker-examples/extending/add-airflow-configuration/Dockerfile",
          "docs/docker-stack/docker-examples/extending/add-apt-packages/Dockerfile",
          "docs/docker-stack/docker-examples/extending/add-build-essential-extend/Dockerfile",
          "docs/docker-stack/docker-examples/extending/add-providers/Dockerfile",
          "docs/docker-stack/docker-examples/extending/add-pypi-packages/Dockerfile",
          "docs/docker-stack/docker-examples/extending/add-requirement-packages/Dockerfile",
          "docs/docker-stack/docker-examples/extending/custom-providers/Dockerfile",
          "docs/docker-stack/docker-examples/extending/embedding-dags/Dockerfile",
          "docs/docker-stack/docker-examples/extending/writable-directory/Dockerfile",
          "docs/docker-stack/entrypoint.rst"
        ],
        "message": "Update version of airflow to 2.8.1.dev0",
        "before_after_code_files": [
          "airflow/__init__.py||airflow/__init__.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/__init__.py||airflow/__init__.py": [
          "File: airflow/__init__.py -> airflow/__init__.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "26: \"\"\"",
          "27: from __future__ import annotations",
          "31: # flake8: noqa: F401",
          "",
          "[Removed Lines]",
          "29: __version__ = \"2.8.0\"",
          "",
          "[Added Lines]",
          "29: __version__ = \"2.8.1.dev0\"",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "6624adeb01106d73f7c933c4c99edb48d8795e43",
      "candidate_info": {
        "commit_hash": "6624adeb01106d73f7c933c4c99edb48d8795e43",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/6624adeb01106d73f7c933c4c99edb48d8795e43",
        "files": [
          "airflow/api_connexion/endpoints/variable_endpoint.py",
          "tests/api_connexion/endpoints/test_variable_endpoint.py"
        ],
        "message": "Fix the required access for get_variable endpoint (#36396)\n\n(cherry picked from commit 34132e37c691995ff94dd1b8518d1f5c3a2ec998)",
        "before_after_code_files": [
          "airflow/api_connexion/endpoints/variable_endpoint.py||airflow/api_connexion/endpoints/variable_endpoint.py",
          "tests/api_connexion/endpoints/test_variable_endpoint.py||tests/api_connexion/endpoints/test_variable_endpoint.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/api_connexion/endpoints/variable_endpoint.py||airflow/api_connexion/endpoints/variable_endpoint.py": [
          "File: airflow/api_connexion/endpoints/variable_endpoint.py -> airflow/api_connexion/endpoints/variable_endpoint.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "57:     return Response(status=HTTPStatus.NO_CONTENT)",
          "61: @provide_session",
          "62: def get_variable(*, variable_key: str, session: Session = NEW_SESSION) -> Response:",
          "63:     \"\"\"Get a variable by key.\"\"\"",
          "",
          "[Removed Lines]",
          "60: @security.requires_access_variable(\"DELETE\")",
          "",
          "[Added Lines]",
          "60: @security.requires_access_variable(\"GET\")",
          "",
          "---------------"
        ],
        "tests/api_connexion/endpoints/test_variable_endpoint.py||tests/api_connexion/endpoints/test_variable_endpoint.py": [
          "File: tests/api_connexion/endpoints/test_variable_endpoint.py -> tests/api_connexion/endpoints/test_variable_endpoint.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "46:             (permissions.ACTION_CAN_DELETE, permissions.RESOURCE_VARIABLE),",
          "47:         ],",
          "48:     )",
          "49:     create_user(app, username=\"test_no_permissions\", role_name=\"TestNoPermissions\")  # type: ignore",
          "51:     yield app",
          "53:     delete_user(app, username=\"test\")  # type: ignore",
          "54:     delete_user(app, username=\"test_no_permissions\")  # type: ignore",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "49:     create_user(",
          "50:         app,  # type: ignore",
          "51:         username=\"test_read_only\",",
          "52:         role_name=\"TestReadOnly\",",
          "53:         permissions=[",
          "54:             (permissions.ACTION_CAN_READ, permissions.RESOURCE_VARIABLE),",
          "55:         ],",
          "56:     )",
          "57:     create_user(",
          "58:         app,  # type: ignore",
          "59:         username=\"test_delete_only\",",
          "60:         role_name=\"TestDeleteOnly\",",
          "61:         permissions=[",
          "62:             (permissions.ACTION_CAN_DELETE, permissions.RESOURCE_VARIABLE),",
          "63:         ],",
          "64:     )",
          "70:     delete_user(app, username=\"test_read_only\")  # type: ignore",
          "71:     delete_user(app, username=\"test_delete_only\")  # type: ignore",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "111: class TestGetVariable(TestVariableEndpoint):",
          "113:         expected_value = '{\"foo\": 1}'",
          "114:         Variable.set(\"TEST_VARIABLE_KEY\", expected_value)",
          "115:         response = self.client.get(",
          "117:         )",
          "121:     def test_should_respond_404_if_not_found(self):",
          "122:         response = self.client.get(",
          "",
          "[Removed Lines]",
          "112:     def test_should_respond_200(self):",
          "116:             \"/api/v1/variables/TEST_VARIABLE_KEY\", environ_overrides={\"REMOTE_USER\": \"test\"}",
          "118:         assert response.status_code == 200",
          "119:         assert response.json == {\"key\": \"TEST_VARIABLE_KEY\", \"value\": expected_value, \"description\": None}",
          "",
          "[Added Lines]",
          "130:     @pytest.mark.parametrize(",
          "131:         \"user, expected_status_code\",",
          "132:         [",
          "133:             (\"test\", 200),",
          "134:             (\"test_read_only\", 200),",
          "135:             (\"test_delete_only\", 403),",
          "136:             (\"test_no_permissions\", 403),",
          "137:         ],",
          "138:     )",
          "139:     def test_read_variable(self, user, expected_status_code):",
          "143:             \"/api/v1/variables/TEST_VARIABLE_KEY\", environ_overrides={\"REMOTE_USER\": user}",
          "145:         assert response.status_code == expected_status_code",
          "146:         if expected_status_code == 200:",
          "147:             assert response.json == {\"key\": \"TEST_VARIABLE_KEY\", \"value\": expected_value, \"description\": None}",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "fef77f5a2c0a49ac5536c6f9c4e11ca4d001f3ae",
      "candidate_info": {
        "commit_hash": "fef77f5a2c0a49ac5536c6f9c4e11ca4d001f3ae",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/fef77f5a2c0a49ac5536c6f9c4e11ca4d001f3ae",
        "files": [
          "airflow/www/decorators.py",
          "tests/www/views/test_views_paused.py"
        ],
        "message": "Bugfix/logging for pausing (#36182)\n\n---------\n\nCo-authored-by: Aleph Melo <alephmelo@icloud.com>\n(cherry picked from commit c884f3ce3250bb9dd58cf3dd8dde7c2555e664a5)",
        "before_after_code_files": [
          "airflow/www/decorators.py||airflow/www/decorators.py",
          "tests/www/views/test_views_paused.py||tests/www/views/test_views_paused.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/36788"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/www/decorators.py||airflow/www/decorators.py": [
          "File: airflow/www/decorators.py -> airflow/www/decorators.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "93:                     user = get_auth_manager().get_user_name()",
          "94:                     user_display = get_auth_manager().get_user_display_name()",
          "97:                 extra_fields = [",
          "98:                     (k, secrets_masker.redact(v, k))",
          "99:                     for k, v in itertools.chain(request.values.items(multi=True), request.view_args.items())",
          "",
          "[Removed Lines]",
          "96:                 fields_skip_logging = {\"csrf_token\", \"_csrf_token\"}",
          "",
          "[Added Lines]",
          "96:                 fields_skip_logging = {\"csrf_token\", \"_csrf_token\", \"is_paused\"}",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "107:                 params = {**request.values, **request.view_args}",
          "109:                 log = Log(",
          "110:                     event=event or f.__name__,",
          "111:                     task_instance=None,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "109:                 if params and \"is_paused\" in params:",
          "110:                     extra_fields.append((\"is_paused\", params[\"is_paused\"] == \"false\"))",
          "",
          "---------------"
        ],
        "tests/www/views/test_views_paused.py||tests/www/views/test_views_paused.py": [
          "File: tests/www/views/test_views_paused.py -> tests/www/views/test_views_paused.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: # Licensed to the Apache Software Foundation (ASF) under one",
          "2: # or more contributor license agreements.  See the NOTICE file",
          "3: # distributed with this work for additional information",
          "4: # regarding copyright ownership.  The ASF licenses this file",
          "5: # to you under the Apache License, Version 2.0 (the",
          "6: # \"License\"); you may not use this file except in compliance",
          "7: # with the License.  You may obtain a copy of the License at",
          "8: #",
          "9: #   http://www.apache.org/licenses/LICENSE-2.0",
          "10: #",
          "11: # Unless required by applicable law or agreed to in writing,",
          "12: # software distributed under the License is distributed on an",
          "13: # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
          "14: # KIND, either express or implied.  See the License for the",
          "15: # specific language governing permissions and limitations",
          "16: # under the License.",
          "17: from __future__ import annotations",
          "19: import pytest",
          "21: from airflow.models.log import Log",
          "22: from tests.test_utils.db import clear_db_dags",
          "24: pytestmark = pytest.mark.db_test",
          "27: @pytest.fixture(autouse=True)",
          "28: def dags(create_dummy_dag):",
          "29:     paused_dag, _ = create_dummy_dag(dag_id=\"paused_dag\", is_paused_upon_creation=True)",
          "30:     dag, _ = create_dummy_dag(dag_id=\"unpaused_dag\")",
          "32:     yield dag, paused_dag",
          "34:     clear_db_dags()",
          "37: def test_logging_pause_dag(admin_client, dags, session):",
          "38:     dag, _ = dags",
          "39:     # is_paused=false mean pause the dag",
          "40:     admin_client.post(f\"/paused?is_paused=false&dag_id={dag.dag_id}\", follow_redirects=True)",
          "41:     dag_query = session.query(Log).filter(Log.dag_id == dag.dag_id)",
          "42:     assert \"('is_paused', True)\" in dag_query.first().extra",
          "45: def test_logging_unpuase_dag(admin_client, dags, session):",
          "46:     _, paused_dag = dags",
          "47:     # is_paused=true mean unpause the dag",
          "48:     admin_client.post(f\"/paused?is_paused=true&dag_id={paused_dag.dag_id}\", follow_redirects=True)",
          "49:     dag_query = session.query(Log).filter(Log.dag_id == paused_dag.dag_id)",
          "50:     assert \"('is_paused', False)\" in dag_query.first().extra",
          "",
          "---------------"
        ]
      }
    }
  ]
}