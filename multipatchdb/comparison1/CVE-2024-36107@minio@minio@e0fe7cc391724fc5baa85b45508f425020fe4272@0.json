{
  "cve_id": "CVE-2024-36107",
  "cve_desc": "MinIO is a High Performance Object Storage released under GNU Affero General Public License v3.0. `If-Modified-Since` and `If-Unmodified-Since` headers when used with anonymous requests by sending a random object name requests can be used to determine if an object exists or not on the server on a specific bucket and also gain access to some amount of\ninformation such as  `Last-Modified (of the latest version)`, `Etag (of the latest version)`, `x-amz-version-id (of the latest version)`, `Expires (metadata value of the latest version)`, `Cache-Control (metadata value of the latest version)`. This conditional check was being honored before validating if the anonymous access is indeed allowed on the metadata of an object. This issue has been addressed in commit `e0fe7cc3917`. Users must upgrade to RELEASE.2024-05-27T19-17-46Z for the fix. There are no known workarounds for this issue.",
  "repo": "minio/minio",
  "patch_hash": "e0fe7cc391724fc5baa85b45508f425020fe4272",
  "patch_info": {
    "commit_hash": "e0fe7cc391724fc5baa85b45508f425020fe4272",
    "repo": "minio/minio",
    "commit_url": "https://github.com/minio/minio/commit/e0fe7cc391724fc5baa85b45508f425020fe4272",
    "files": [
      ".github/workflows/multipart/migrate.sh",
      ".gitignore",
      "Makefile",
      "buildscripts/rewrite-old-new.sh",
      "buildscripts/verify-healing-empty-erasure-set.sh",
      "buildscripts/verify-healing.sh",
      "cmd/object-handlers.go",
      "docs/bucket/replication/setup_3site_replication.sh",
      "docs/debugging/build.sh",
      "docs/debugging/inspect/go.mod",
      "docs/debugging/pprofgoparser/go.mod",
      "docs/debugging/reorder-disks/go.mod",
      "docs/debugging/reorder-disks/go.sum",
      "docs/debugging/xattr/go.mod",
      "docs/distributed/decom-compressed-sse-s3.sh",
      "docs/distributed/decom-encrypted-kes.sh",
      "docs/distributed/decom-encrypted-sse-s3.sh",
      "docs/distributed/decom-encrypted.sh",
      "docs/distributed/decom.sh"
    ],
    "message": "fix: information disclosure bug in preconditions GET (#19810)\n\nprecondition check was being honored before, validating\nif anonymous access is allowed on the metadata of an\nobject, leading to metadata disclosure of the following\nheaders.\n\n```\nLast-Modified\nEtag\nx-amz-version-id\nExpires:\nCache-Control:\n```\n\nalthough the information presented is minimal in nature,\nand of opaque nature. It still simply discloses that an\nobject by a specific name exists or not without even having\nenough permissions.",
    "before_after_code_files": [
      ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh",
      "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh",
      "buildscripts/verify-healing-empty-erasure-set.sh||buildscripts/verify-healing-empty-erasure-set.sh",
      "buildscripts/verify-healing.sh||buildscripts/verify-healing.sh",
      "cmd/object-handlers.go||cmd/object-handlers.go"
    ]
  },
  "patch_diff": {
    ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh": [
      "File: .github/workflows/multipart/migrate.sh -> .github/workflows/multipart/migrate.sh",
      "--- Hunk 1 ---",
      "[Context before]",
      "24:   chmod +x mc",
      "25: fi",
      "29: export RELEASE=RELEASE.2023-08-29T23-07-35Z",
      "31: docker-compose -f docker-compose-site1.yaml up -d",
      "",
      "[Removed Lines]",
      "27: go install -v github.com/minio/minio/docs/debugging/s3-check-md5@latest",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "46: sleep 5",
      "53: if [ $failed_count_site1 -ne 0 ]; then",
      "54:  echo \"failed with multipart on site1 uploads\"",
      "",
      "[Removed Lines]",
      "48: s3-check-md5 -h",
      "50: failed_count_site1=$(s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site1-nginx:9001 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
      "51: failed_count_site2=$(s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site2-nginx:9002 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
      "",
      "[Added Lines]",
      "46: ./s3-check-md5 -h",
      "48: failed_count_site1=$(./s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site1-nginx:9001 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
      "49: failed_count_site2=$(./s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site2-nginx:9002 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "65: sleep 5",
      "70: ## we do not need to fail here, since we are going to test",
      "71: ## upgrading to master, healing and being able to recover",
      "",
      "[Removed Lines]",
      "67: failed_count_site1=$(s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site1-nginx:9001 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
      "68: failed_count_site2=$(s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site2-nginx:9002 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
      "",
      "[Added Lines]",
      "65: failed_count_site1=$(./s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site1-nginx:9001 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
      "66: failed_count_site2=$(./s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site2-nginx:9002 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "93:  ./mc admin heal -r --remove --json site2/ 2>&1 >/dev/null",
      "94: done",
      "99: if [ $failed_count_site1 -ne 0 ]; then",
      "100:  echo \"failed with multipart on site1 uploads\"",
      "",
      "[Removed Lines]",
      "96: failed_count_site1=$(s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site1-nginx:9001 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
      "97: failed_count_site2=$(s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site2-nginx:9002 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
      "",
      "[Added Lines]",
      "94: failed_count_site1=$(./s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site1-nginx:9001 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
      "95: failed_count_site2=$(./s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site2-nginx:9002 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
      "",
      "---------------"
    ],
    "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh": [
      "File: buildscripts/rewrite-old-new.sh -> buildscripts/rewrite-old-new.sh",
      "--- Hunk 1 ---",
      "[Context before]",
      "45:  \"${MINIO_OLD[@]}\" --address \":$start_port\" \"${WORK_DIR}/xl{1...16}\" >\"${WORK_DIR}/server1.log\" 2>&1 &",
      "46:  pid=$!",
      "47:  disown $pid",
      "50:  if ! ps -p ${pid} 1>&2 >/dev/null; then",
      "51:   echo \"server1 log:\"",
      "",
      "[Removed Lines]",
      "48:  sleep 10",
      "",
      "[Added Lines]",
      "49:  \"${WORK_DIR}/mc\" ready minio/",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "77:  \"${MINIO[@]}\" --address \":$start_port\" \"${WORK_DIR}/xl{1...16}\" >\"${WORK_DIR}/server1.log\" 2>&1 &",
      "78:  pid=$!",
      "79:  disown $pid",
      "82:  if ! ps -p ${pid} 1>&2 >/dev/null; then",
      "83:   echo \"server1 log:\"",
      "",
      "[Removed Lines]",
      "80:  sleep 10",
      "",
      "[Added Lines]",
      "82:  \"${WORK_DIR}/mc\" ready minio/",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "87:   exit 1",
      "88:  fi",
      "93:   -debug \\",
      "94:   -versions \\",
      "95:   -access-key minio \\",
      "96:   -secret-key minio123 \\",
      "98:   echo \"server1 log:\"",
      "99:   cat \"${WORK_DIR}/server1.log\"",
      "100:   echo \"FAILED\"",
      "",
      "[Removed Lines]",
      "90:  go install -v github.com/minio/minio/docs/debugging/s3-check-md5@latest",
      "92:  if ! s3-check-md5 \\",
      "97:   -endpoint http://127.0.0.1:${start_port}/ 2>&1 | grep INTACT; then",
      "",
      "[Added Lines]",
      "92:  if ! ./s3-check-md5 \\",
      "97:   -endpoint \"http://127.0.0.1:${start_port}/\" 2>&1 | grep INTACT; then",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "114:  go run ./buildscripts/heal-manual.go \"127.0.0.1:${start_port}\" \"minio\" \"minio123\"",
      "115:  sleep 1",
      "118:   -debug \\",
      "119:   -versions \\",
      "120:   -access-key minio \\",
      "",
      "[Removed Lines]",
      "117:  if ! s3-check-md5 \\",
      "",
      "[Added Lines]",
      "117:  if ! ./s3-check-md5 \\",
      "",
      "---------------"
    ],
    "buildscripts/verify-healing-empty-erasure-set.sh||buildscripts/verify-healing-empty-erasure-set.sh": [
      "File: buildscripts/verify-healing-empty-erasure-set.sh -> buildscripts/verify-healing-empty-erasure-set.sh",
      "--- Hunk 1 ---",
      "[Context before]",
      "19:  export MINIO_ERASURE_SET_DRIVE_COUNT=6",
      "20:  export MINIO_CI_CD=1",
      "23:  args=\"\"",
      "24:  for i in $(seq 1 3); do",
      "25:   args=\"$args http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/1/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/2/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/3/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/4/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/5/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/6/\"",
      "",
      "[Removed Lines]",
      "22:  start_port=$2",
      "",
      "[Added Lines]",
      "22:  start_port=$1",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "37:  pid3=$!",
      "38:  disown $pid3",
      "42:  if ! ps -p $pid1 1>&2 >/dev/null; then",
      "43:   echo \"server1 log:\"",
      "",
      "[Removed Lines]",
      "40:  sleep \"$1\"",
      "",
      "[Added Lines]",
      "40:  export MC_HOST_myminio=\"http://minio:minio123@127.0.0.1:$((start_port + 1))\"",
      "41:  /tmp/mc ready myminio",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "100:  ## version is purposefully set to '3' for minio to migrate configuration file",
      "101:  echo '{\"version\": \"3\", \"credential\": {\"accessKey\": \"minio\", \"secretKey\": \"minio123\"}, \"region\": \"us-east-1\"}' >\"$MINIO_CONFIG_DIR/config.json\"",
      "102: }",
      "104: function perform_test() {",
      "107:  echo \"Testing Distributed Erasure setup healing of drives\"",
      "108:  echo \"Remove the contents of the disks belonging to '${1}' erasure set\"",
      "",
      "[Removed Lines]",
      "105:  start_minio_3_node 120 $2",
      "",
      "[Added Lines]",
      "104:  if [ ! -f /tmp/mc ]; then",
      "105:   wget --quiet -O /tmp/mc https://dl.minio.io/client/mc/release/linux-amd64/mc &&",
      "106:    chmod +x /tmp/mc",
      "107:  fi",
      "111:  start_minio_3_node $2",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "112:  set -x",
      "115:  rv=$(check_online)",
      "116:  if [ \"$rv\" == \"1\" ]; then",
      "",
      "[Removed Lines]",
      "113:  start_minio_3_node 120 $2",
      "",
      "[Added Lines]",
      "119:  start_minio_3_node $2",
      "",
      "---------------"
    ],
    "buildscripts/verify-healing.sh||buildscripts/verify-healing.sh": [
      "File: buildscripts/verify-healing.sh -> buildscripts/verify-healing.sh",
      "--- Hunk 1 ---",
      "[Context before]",
      "15: GOPATH=/tmp/gopath",
      "17: function start_minio_3_node() {",
      "18:  export MINIO_ROOT_USER=minio",
      "19:  export MINIO_ROOT_PASSWORD=minio123",
      "20:  export MINIO_ERASURE_SET_DRIVE_COUNT=6",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "18:  for i in $(seq 1 3); do",
      "19:   rm \"${WORK_DIR}/dist-minio-server$i.log\"",
      "20:  done",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "23:  first_time=$(find ${WORK_DIR}/ | grep format.json | wc -l)",
      "26:  args=\"\"",
      "27:  for d in $(seq 1 3 5); do",
      "28:   args=\"$args http://127.0.0.1:$((start_port + 1))${WORK_DIR}/1/${d}/ http://127.0.0.1:$((start_port + 2))${WORK_DIR}/2/${d}/ http://127.0.0.1:$((start_port + 3))${WORK_DIR}/3/${d}/ \"",
      "",
      "[Removed Lines]",
      "25:  start_port=$2",
      "",
      "[Added Lines]",
      "29:  start_port=$1",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "42:  pid3=$!",
      "43:  disown $pid3",
      "49:  if ! ps -p $pid1 1>&2 >/dev/null; then",
      "50:   echo \"server1 log:\"",
      "",
      "[Removed Lines]",
      "45:  sleep \"$1\"",
      "47:  [ ${first_time} -eq 0 ] && upload_objects $start_port",
      "",
      "[Added Lines]",
      "49:  export MC_HOST_myminio=\"http://minio:minio123@127.0.0.1:$((start_port + 1))\"",
      "50:  /tmp/mc ready myminio",
      "52:  [ ${first_time} -eq 0 ] && upload_objects",
      "53:  [ ${first_time} -ne 0 ] && sleep 120",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "127: }",
      "129: function upload_objects() {",
      "134:  /tmp/mc mb myminio/testbucket/",
      "135:  for ((i = 0; i < 20; i++)); do",
      "136:   echo \"my content\" | /tmp/mc pipe myminio/testbucket/file-$i",
      "",
      "[Removed Lines]",
      "130:  start_port=$1",
      "132:  /tmp/mc alias set myminio http://127.0.0.1:$((start_port + 1)) minio minio123 --api=s3v4",
      "133:  /tmp/mc ready myminio",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "140: function perform_test() {",
      "141:  start_port=$2",
      "145:  echo \"Testing Distributed Erasure setup healing of drives\"",
      "146:  echo \"Remove the contents of the disks belonging to '${1}' node\"",
      "",
      "[Removed Lines]",
      "143:  start_minio_3_node 120 $start_port",
      "",
      "[Added Lines]",
      "145:  start_minio_3_node $start_port",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "150:  set -x",
      "153:  check_heal ${1}",
      "154:  rv=$?",
      "",
      "[Removed Lines]",
      "151:  start_minio_3_node 120 $start_port",
      "",
      "[Added Lines]",
      "153:  start_minio_3_node $start_port",
      "",
      "---------------"
    ],
    "cmd/object-handlers.go||cmd/object-handlers.go": [
      "File: cmd/object-handlers.go -> cmd/object-handlers.go",
      "--- Hunk 1 ---",
      "[Context before]",
      "476:    return true",
      "477:   }",
      "479:   return checkPreconditions(ctx, w, r, oi, opts)",
      "480:  }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "479:   if oi.UserTags != \"\" {",
      "480:    r.Header.Set(xhttp.AmzObjectTagging, oi.UserTags)",
      "481:   }",
      "483:   if s3Error := authorizeRequest(ctx, r, policy.GetObjectAction); s3Error != ErrNone {",
      "484:    writeErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL)",
      "485:    return true",
      "486:   }",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "548:  objInfo := gr.ObjInfo",
      "559:  if !proxy.Proxy { // apply lifecycle rules only for local requests",
      "561:   if lc, err := globalLifecycleSys.Get(bucket); err == nil {",
      "",
      "[Removed Lines]",
      "550:  if objInfo.UserTags != \"\" {",
      "551:   r.Header.Set(xhttp.AmzObjectTagging, objInfo.UserTags)",
      "552:  }",
      "554:  if s3Error := authorizeRequest(ctx, r, policy.GetObjectAction); s3Error != ErrNone {",
      "555:   writeErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL)",
      "556:   return",
      "557:  }",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "b6e98aed0161bb526aaf11fa1672d30eb89dca4b",
      "candidate_info": {
        "commit_hash": "b6e98aed0161bb526aaf11fa1672d30eb89dca4b",
        "repo": "minio/minio",
        "commit_url": "https://github.com/minio/minio/commit/b6e98aed0161bb526aaf11fa1672d30eb89dca4b",
        "files": [
          ".github/workflows/multipart/migrate.sh",
          "Makefile",
          "buildscripts/rewrite-old-new.sh",
          "cmd/background-newdisks-heal-ops.go",
          "cmd/bucket-replication.go",
          "cmd/metrics-resource.go",
          "cmd/peer-rest-server.go",
          "cmd/peer-s3-server.go",
          "docs/bucket/replication/delete-replication.sh",
          "docs/bucket/replication/setup_3site_replication.sh",
          "docs/debugging/s3-check-md5/main.go",
          "docs/distributed/decom-compressed-sse-s3.sh",
          "docs/distributed/decom-encrypted-sse-s3.sh",
          "docs/distributed/decom-encrypted.sh",
          "docs/distributed/decom.sh",
          "go.mod",
          "go.sum"
        ],
        "message": "fix: found races in accessing globalLocalDrives (#19069)\n\nmake a copy before accessing globalLocalDrives\n\nBonus: update console v0.46.0\n\nSigned-off-by: Harshavardhana <harsha@minio.io>",
        "before_after_code_files": [
          ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh",
          "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh",
          "cmd/background-newdisks-heal-ops.go||cmd/background-newdisks-heal-ops.go",
          "cmd/bucket-replication.go||cmd/bucket-replication.go",
          "cmd/metrics-resource.go||cmd/metrics-resource.go",
          "cmd/peer-rest-server.go||cmd/peer-rest-server.go",
          "cmd/peer-s3-server.go||cmd/peer-s3-server.go",
          "go.mod||go.mod",
          "go.sum||go.sum"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh",
            "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh"
          ],
          "candidate": [
            ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh",
            "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh"
          ]
        }
      },
      "candidate_diff": {
        ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh": [
          "File: .github/workflows/multipart/migrate.sh -> .github/workflows/multipart/migrate.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "25: fi",
          "27: (",
          "30: )",
          "32: export RELEASE=RELEASE.2023-08-29T23-07-35Z",
          "",
          "[Removed Lines]",
          "28:  cd /tmp",
          "29:  go install github.com/minio/minio/docs/debugging/s3-check-md5@master",
          "",
          "[Added Lines]",
          "28:  cd ./docs/debugging/s3-check-md5",
          "29:  go install -v",
          "",
          "---------------"
        ],
        "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh": [
          "File: buildscripts/rewrite-old-new.sh -> buildscripts/rewrite-old-new.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "87:   exit 1",
          "88:  fi",
          "91:  if ! s3-check-md5 \\",
          "92:   -debug \\",
          "93:   -versions \\",
          "",
          "[Removed Lines]",
          "90:  go install github.com/minio/minio/docs/debugging/s3-check-md5@master",
          "",
          "[Added Lines]",
          "90:  (",
          "91:   cd ./docs/debugging/s3-check-md5",
          "92:   go install -v",
          "93:  )",
          "",
          "---------------"
        ],
        "cmd/background-newdisks-heal-ops.go||cmd/background-newdisks-heal-ops.go": [
          "File: cmd/background-newdisks-heal-ops.go -> cmd/background-newdisks-heal-ops.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "354: func getLocalDisksToHeal() (disksToHeal Endpoints) {",
          "355:  globalLocalDrivesMu.RLock()",
          "357:  globalLocalDrivesMu.RUnlock()",
          "358:  for _, disk := range localDrives {",
          "359:   _, err := disk.GetDiskID()",
          "",
          "[Removed Lines]",
          "356:  localDrives := globalLocalDrives",
          "",
          "[Added Lines]",
          "356:  localDrives := cloneDrives(globalLocalDrives)",
          "",
          "---------------"
        ],
        "cmd/bucket-replication.go||cmd/bucket-replication.go": [
          "File: cmd/bucket-replication.go -> cmd/bucket-replication.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "3393:  }",
          "3395:  globalLocalDrivesMu.RLock()",
          "3397:  globalLocalDrivesMu.RUnlock()",
          "3399:  for _, localDrive := range localDrives {",
          "",
          "[Removed Lines]",
          "3396:  localDrives := globalLocalDrives",
          "",
          "[Added Lines]",
          "3396:  localDrives := cloneDrives(globalLocalDrives)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "3460:  }",
          "3462:  globalLocalDrivesMu.RLock()",
          "3464:  globalLocalDrivesMu.RUnlock()",
          "3466:  for _, localDrive := range localDrives {",
          "",
          "[Removed Lines]",
          "3463:  localDrives := globalLocalDrives",
          "",
          "[Added Lines]",
          "3463:  localDrives := cloneDrives(globalLocalDrives)",
          "",
          "---------------"
        ],
        "cmd/metrics-resource.go||cmd/metrics-resource.go": [
          "File: cmd/metrics-resource.go -> cmd/metrics-resource.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "274:  }",
          "276:  globalLocalDrivesMu.RLock()",
          "278:  globalLocalDrivesMu.RUnlock()",
          "280:  for _, d := range localDrives {",
          "",
          "[Removed Lines]",
          "277:  localDrives := globalLocalDrives",
          "",
          "[Added Lines]",
          "277:  localDrives := cloneDrives(globalLocalDrives)",
          "",
          "---------------"
        ],
        "cmd/peer-rest-server.go||cmd/peer-rest-server.go": [
          "File: cmd/peer-rest-server.go -> cmd/peer-rest-server.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "787: func waitingDrivesNode() map[string]madmin.DiskMetrics {",
          "788:  globalLocalDrivesMu.RLock()",
          "790:  globalLocalDrivesMu.RUnlock()",
          "792:  errs := make([]error, len(localDrives))",
          "",
          "[Removed Lines]",
          "789:  localDrives := globalLocalDrives",
          "",
          "[Added Lines]",
          "789:  localDrives := cloneDrives(globalLocalDrives)",
          "",
          "---------------"
        ],
        "cmd/peer-s3-server.go||cmd/peer-s3-server.go": [
          "File: cmd/peer-s3-server.go -> cmd/peer-s3-server.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "83: func healBucketLocal(ctx context.Context, bucket string, opts madmin.HealOpts) (res madmin.HealResultItem, err error) {",
          "84:  globalLocalDrivesMu.RLock()",
          "86:  globalLocalDrivesMu.RUnlock()",
          "",
          "[Removed Lines]",
          "85:  localDrives := globalLocalDrives",
          "",
          "[Added Lines]",
          "85:  localDrives := cloneDrives(globalLocalDrives)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "207: func listBucketsLocal(ctx context.Context, opts BucketOptions) (buckets []BucketInfo, err error) {",
          "208:  globalLocalDrivesMu.RLock()",
          "210:  globalLocalDrivesMu.RUnlock()",
          "212:  quorum := (len(localDrives) / 2)",
          "",
          "[Removed Lines]",
          "209:  localDrives := globalLocalDrives",
          "",
          "[Added Lines]",
          "209:  localDrives := cloneDrives(globalLocalDrives)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "252:  return buckets, nil",
          "253: }",
          "255: func getBucketInfoLocal(ctx context.Context, bucket string, opts BucketOptions) (BucketInfo, error) {",
          "256:  globalLocalDrivesMu.RLock()",
          "258:  globalLocalDrivesMu.RUnlock()",
          "260:  g := errgroup.WithNErrs(len(localDrives)).WithConcurrency(32)",
          "",
          "[Removed Lines]",
          "257:  localDrives := globalLocalDrives",
          "",
          "[Added Lines]",
          "255: func cloneDrives(drives []StorageAPI) []StorageAPI {",
          "256:  newDrives := make([]StorageAPI, len(drives))",
          "257:  copy(newDrives, drives)",
          "258:  return newDrives",
          "259: }",
          "263:  localDrives := cloneDrives(globalLocalDrives)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "304: func deleteBucketLocal(ctx context.Context, bucket string, opts DeleteBucketOptions) error {",
          "305:  globalLocalDrivesMu.RLock()",
          "307:  globalLocalDrivesMu.RUnlock()",
          "309:  g := errgroup.WithNErrs(len(localDrives)).WithConcurrency(32)",
          "",
          "[Removed Lines]",
          "306:  localDrives := globalLocalDrives",
          "",
          "[Added Lines]",
          "312:  localDrives := cloneDrives(globalLocalDrives)",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "342: func makeBucketLocal(ctx context.Context, bucket string, opts MakeBucketOptions) error {",
          "343:  globalLocalDrivesMu.RLock()",
          "345:  globalLocalDrivesMu.RUnlock()",
          "347:  g := errgroup.WithNErrs(len(localDrives)).WithConcurrency(32)",
          "",
          "[Removed Lines]",
          "344:  localDrives := globalLocalDrives",
          "",
          "[Added Lines]",
          "350:  localDrives := cloneDrives(globalLocalDrives)",
          "",
          "---------------"
        ],
        "go.mod||go.mod": [
          "File: go.mod -> go.mod",
          "--- Hunk 1 ---",
          "[Context before]",
          "45:  github.com/lithammer/shortuuid/v4 v4.0.0",
          "46:  github.com/miekg/dns v1.1.58",
          "47:  github.com/minio/cli v1.24.2",
          "49:  github.com/minio/csvparser v1.0.0",
          "50:  github.com/minio/dnscache v0.1.1",
          "51:  github.com/minio/dperf v0.5.3",
          "",
          "[Removed Lines]",
          "48:  github.com/minio/console v0.45.1-0.20240213061721-ee4d7b9b6940",
          "",
          "[Added Lines]",
          "48:  github.com/minio/console v0.46.0",
          "",
          "---------------"
        ],
        "go.sum||go.sum": [
          "File: go.sum -> go.sum",
          "--- Hunk 1 ---",
          "[Context before]",
          "432: github.com/minio/cli v1.24.2/go.mod h1:bYxnK0uS629N3Bq+AOZZ+6lwF77Sodk4+UL9vNuXhOY=",
          "433: github.com/minio/colorjson v1.0.6 h1:m7TUvpvt0u7FBmVIEQNIa0T4NBQlxrcMBp4wJKsg2Ik=",
          "434: github.com/minio/colorjson v1.0.6/go.mod h1:LUXwS5ZGNb6Eh9f+t+3uJiowD3XsIWtsvTriUBeqgYs=",
          "437: github.com/minio/csvparser v1.0.0 h1:xJEHcYK8ZAjeW4hNV9Zu30u+/2o4UyPnYgyjWp8b7ZU=",
          "438: github.com/minio/csvparser v1.0.0/go.mod h1:lKXskSLzPgC5WQyzP7maKH7Sl1cqvANXo9YCto8zbtM=",
          "439: github.com/minio/dnscache v0.1.1 h1:AMYLqomzskpORiUA1ciN9k7bZT1oB3YZN4cEIi88W5o=",
          "",
          "[Removed Lines]",
          "435: github.com/minio/console v0.45.1-0.20240213061721-ee4d7b9b6940 h1:DdXAWKUmiSMFS3pPG351kwYo2YlC0EaKKCNStAmd7xo=",
          "436: github.com/minio/console v0.45.1-0.20240213061721-ee4d7b9b6940/go.mod h1:VvJdNfELVCc2VELF1rJtIPCb3FcWGtNfM/Ktvnu2MZ0=",
          "",
          "[Added Lines]",
          "435: github.com/minio/console v0.46.0 h1:So7y3csQl7m3Llaxmbg5xiTCwlElUol8kUyVOViBRFY=",
          "436: github.com/minio/console v0.46.0/go.mod h1:VvJdNfELVCc2VELF1rJtIPCb3FcWGtNfM/Ktvnu2MZ0=",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "e1e33077e8f56cdc51fe12555fca9bf45b61d3bd",
      "candidate_info": {
        "commit_hash": "e1e33077e8f56cdc51fe12555fca9bf45b61d3bd",
        "repo": "minio/minio",
        "commit_url": "https://github.com/minio/minio/commit/e1e33077e8f56cdc51fe12555fca9bf45b61d3bd",
        "files": [
          "buildscripts/rewrite-old-new.sh",
          "buildscripts/unaligned-healing.sh",
          "cmd/bucket-replication.go",
          "cmd/xl-storage.go",
          "docs/bucket/replication/setup_3site_replication.sh"
        ],
        "message": "fix: tests and resync replication status (#18244)",
        "before_after_code_files": [
          "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh",
          "buildscripts/unaligned-healing.sh||buildscripts/unaligned-healing.sh",
          "cmd/bucket-replication.go||cmd/bucket-replication.go",
          "cmd/xl-storage.go||cmd/xl-storage.go"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh"
          ],
          "candidate": [
            "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh"
          ]
        }
      },
      "candidate_diff": {
        "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh": [
          "File: buildscripts/rewrite-old-new.sh -> buildscripts/rewrite-old-new.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "87:   exit 1",
          "88:  fi",
          "92:   -debug \\",
          "93:   -versions \\",
          "94:   -access-key minio \\",
          "",
          "[Removed Lines]",
          "90:  go build ./docs/debugging/s3-check-md5/",
          "91:  if ! ./s3-check-md5 \\",
          "",
          "[Added Lines]",
          "90:  go install github.com/minio/minio/docs/debugging/s3-check-md5@latest",
          "91:  if ! s3-check-md5 \\",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "113:  go run ./buildscripts/heal-manual.go \"127.0.0.1:${start_port}\" \"minio\" \"minio123\"",
          "114:  sleep 1",
          "117:   -debug \\",
          "118:   -versions \\",
          "119:   -access-key minio \\",
          "",
          "[Removed Lines]",
          "116:  if ! ./s3-check-md5 \\",
          "",
          "[Added Lines]",
          "116:  if ! s3-check-md5 \\",
          "",
          "---------------"
        ],
        "buildscripts/unaligned-healing.sh||buildscripts/unaligned-healing.sh": [
          "File: buildscripts/unaligned-healing.sh -> buildscripts/unaligned-healing.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "82:  rm -rf \"${WORK_DIR}/xl3/healing-shard-bucket/unaligned\"",
          "83:  sleep 10",
          "87:   -debug \\",
          "88:   -access-key minio \\",
          "89:   -secret-key minio123 \\",
          "",
          "[Removed Lines]",
          "85:  go build ./docs/debugging/s3-check-md5/",
          "86:  if ! ./s3-check-md5 \\",
          "",
          "[Added Lines]",
          "85:  go install github.com/minio/minio/docs/debugging/s3-check-md5@latest",
          "86:  if ! s3-check-md5 \\",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "111:   exit 1",
          "112:  fi",
          "115:   -debug \\",
          "116:   -access-key minio \\",
          "117:   -secret-key minio123 \\",
          "",
          "[Removed Lines]",
          "114:  if ! ./s3-check-md5 \\",
          "",
          "[Added Lines]",
          "114:  if ! s3-check-md5 \\",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "135:  \"${WORK_DIR}/mc\" admin heal --quiet --recursive minio/healing-shard-bucket",
          "138:   -debug \\",
          "139:   -access-key minio \\",
          "140:   -secret-key minio123 \\",
          "",
          "[Removed Lines]",
          "137:  if ! ./s3-check-md5 \\",
          "",
          "[Added Lines]",
          "137:  if ! s3-check-md5 \\",
          "",
          "---------------"
        ],
        "cmd/bucket-replication.go||cmd/bucket-replication.go": [
          "File: cmd/bucket-replication.go -> cmd/bucket-replication.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "2487: }",
          "2491:  s.Lock()",
          "2492:  defer s.Unlock()",
          "",
          "[Removed Lines]",
          "2490: func (s *replicationResyncer) markStatus(status ResyncStatusType, opts resyncOpts) {",
          "",
          "[Added Lines]",
          "2490: func (s *replicationResyncer) markStatus(status ResyncStatusType, opts resyncOpts, objAPI ObjectLayer) {",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "2498:  m.TargetsMap[opts.arn] = st",
          "2499:  m.LastUpdate = UTCNow()",
          "2500:  s.statusMap[opts.bucket] = m",
          "2501: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "2502:  ctx, cancel := context.WithTimeout(context.Background(), time.Second)",
          "2503:  defer cancel()",
          "2504:  saveResyncStatus(ctx, opts.bucket, m, objAPI)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "2528:  resyncStatus := ResyncFailed",
          "2529:  defer func() {",
          "2531:   globalSiteResyncMetrics.incBucket(opts, resyncStatus)",
          "2532:   s.workerCh <- struct{}{}",
          "2533:  }()",
          "",
          "[Removed Lines]",
          "2530:   s.markStatus(resyncStatus, opts)",
          "",
          "[Added Lines]",
          "2534:   s.markStatus(resyncStatus, opts, objectAPI)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "2563:  }",
          "2565:  if !heal {",
          "2567:  }",
          "",
          "[Removed Lines]",
          "2566:   s.markStatus(ResyncStarted, opts)",
          "",
          "[Added Lines]",
          "2570:   s.markStatus(ResyncStarted, opts, objectAPI)",
          "",
          "---------------"
        ],
        "cmd/xl-storage.go||cmd/xl-storage.go": [
          "File: cmd/xl-storage.go -> cmd/xl-storage.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "1061:   return s.WriteAll(ctx, volume, pathJoin(path, xlStorageFormatFile), buf)",
          "1062:  }",
          "1070: }",
          "",
          "[Removed Lines]",
          "1065:  err = s.moveToTrash(pathJoin(volumeDir, path, xlStorageFormatFile), false, false)",
          "1066:  if err == nil || err == errFileNotFound {",
          "1067:   s.deleteFile(volumeDir, pathJoin(volumeDir, path), false, false)",
          "1068:  }",
          "1069:  return err",
          "",
          "[Added Lines]",
          "1064:  return s.deleteFile(volumeDir, pathJoin(volumeDir, path), true, false)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "c50627ee3e2df55bd41c68c3d7177991942547b0",
      "candidate_info": {
        "commit_hash": "c50627ee3e2df55bd41c68c3d7177991942547b0",
        "repo": "minio/minio",
        "commit_url": "https://github.com/minio/minio/commit/c50627ee3e2df55bd41c68c3d7177991942547b0",
        "files": [
          ".github/workflows/mint.yml",
          ".github/workflows/mint/minio-compress-encrypt.yaml",
          ".github/workflows/mint/minio-erasure.yaml",
          ".github/workflows/mint/minio-pools.yaml",
          ".github/workflows/multipart/docker-compose-site1.yaml",
          ".github/workflows/multipart/docker-compose-site2.yaml",
          ".github/workflows/multipart/migrate.sh",
          ".github/workflows/multipart/nginx-site1.conf",
          ".github/workflows/multipart/nginx-site2.conf",
          "Makefile"
        ],
        "message": "Add tests for multipart upload overwrites on versioned buckets (#18142)",
        "before_after_code_files": [
          ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh",
          ".github/workflows/multipart/nginx-site1.conf||.github/workflows/multipart/nginx-site1.conf",
          ".github/workflows/multipart/nginx-site2.conf||.github/workflows/multipart/nginx-site2.conf"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh"
          ],
          "candidate": [
            ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh"
          ]
        }
      },
      "candidate_diff": {
        ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh": [
          "File: .github/workflows/multipart/migrate.sh -> .github/workflows/multipart/migrate.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: #!/bin/bash",
          "3: set -x",
          "5: ## change working directory",
          "6: cd .github/workflows/multipart/",
          "8: docker-compose -f docker-compose-site1.yaml rm -s -f",
          "9: docker-compose -f docker-compose-site2.yaml rm -s -f",
          "10: for volume in $(docker volume ls -q | grep minio); do",
          "11:  docker volume rm ${volume}",
          "12: done",
          "14: if [ ! -f ./mc ]; then",
          "15:  wget --quiet -O mc https://dl.minio.io/client/mc/release/linux-amd64/mc &&",
          "16:   chmod +x mc",
          "17: fi",
          "19: (",
          "20:  cd /tmp",
          "21:  go install github.com/minio/minio/docs/debugging/s3-check-md5@latest",
          "22: )",
          "24: export RELEASE=RELEASE.2023-08-29T23-07-35Z",
          "26: docker-compose -f docker-compose-site1.yaml up -d",
          "27: docker-compose -f docker-compose-site2.yaml up -d",
          "29: sleep 30",
          "31: mc alias set site1 http://site1-nginx:9001 minioadmin minioadmin --api s3v4",
          "32: mc alias set site2 http://site2-nginx:9002 minioadmin minioadmin --api s3v4",
          "34: ./mc ready site1/",
          "35: ./mc ready site2/",
          "37: ./mc admin replicate add site1 site2",
          "38: ./mc mb site1/testbucket/",
          "39: ./mc cp -r --quiet /usr/bin site1/testbucket/",
          "41: sleep 5",
          "43: s3-check-md5 -h",
          "45: failed_count_site1=$(s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site1-nginx:9001 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
          "46: failed_count_site2=$(s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site2-nginx:9002 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
          "48: if [ $failed_count_site1 -ne 0 ]; then",
          "49:  echo \"failed with multipart on site1 uploads\"",
          "50:  exit 1",
          "51: fi",
          "53: if [ $failed_count_site2 -ne 0 ]; then",
          "54:  echo \"failed with multipart on site2 uploads\"",
          "55:  exit 1",
          "56: fi",
          "58: ./mc cp -r --quiet /usr/bin site1/testbucket/",
          "60: sleep 5",
          "62: failed_count_site1=$(s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site1-nginx:9001 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
          "63: failed_count_site2=$(s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site2-nginx:9002 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
          "65: ## we do not need to fail here, since we are going to test",
          "66: ## upgrading to master, healing and being able to recover",
          "67: ## the last version.",
          "68: if [ $failed_count_site1 -ne 0 ]; then",
          "69:  echo \"failed with multipart on site1 uploads ${failed_count_site1}\"",
          "70: fi",
          "72: if [ $failed_count_site2 -ne 0 ]; then",
          "73:  echo \"failed with multipart on site2 uploads ${failed_count_site2}\"",
          "74: fi",
          "76: export RELEASE=${1}",
          "78: docker-compose -f docker-compose-site1.yaml up -d",
          "79: docker-compose -f docker-compose-site2.yaml up -d",
          "81: ./mc ready site1/",
          "82: ./mc ready site2/",
          "84: ./mc admin heal -r --remove --json site1/ 2>&1 >/dev/null",
          "85: ./mc admin heal -r --remove --json site2/ 2>&1 >/dev/null",
          "87: failed_count_site1=$(s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site1-nginx:9001 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
          "88: failed_count_site2=$(s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site2-nginx:9002 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
          "90: if [ $failed_count_site1 -ne 0 ]; then",
          "91:  echo \"failed with multipart on site1 uploads\"",
          "92:  exit 1",
          "93: fi",
          "95: if [ $failed_count_site2 -ne 0 ]; then",
          "96:  echo \"failed with multipart on site2 uploads\"",
          "97:  exit 1",
          "98: fi",
          "100: docker-compose -f docker-compose-site1.yaml rm -s -f",
          "101: docker-compose -f docker-compose-site2.yaml rm -s -f",
          "102: for volume in $(docker volume ls -q | grep minio); do",
          "103:  docker volume rm ${volume}",
          "104: done",
          "106: docker system prune -f || true",
          "107: docker volume prune -f || true",
          "108: docker volume rm $(docker volume ls -q -f dangling=true) || true",
          "110: ## change working directory",
          "111: cd ../../../",
          "",
          "---------------"
        ],
        ".github/workflows/multipart/nginx-site1.conf||.github/workflows/multipart/nginx-site1.conf": [
          "File: .github/workflows/multipart/nginx-site1.conf -> .github/workflows/multipart/nginx-site1.conf",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: user  nginx;",
          "2: worker_processes  auto;",
          "4: error_log  /var/log/nginx/error.log warn;",
          "5: pid        /var/run/nginx.pid;",
          "7: events {",
          "8:     worker_connections  4096;",
          "9: }",
          "11: http {",
          "12:     include       /etc/nginx/mime.types;",
          "13:     default_type  application/octet-stream;",
          "15:     log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '",
          "16:                       '$status $body_bytes_sent \"$http_referer\" '",
          "17:                       '\"$http_user_agent\" \"$http_x_forwarded_for\"';",
          "19:     access_log  /var/log/nginx/access.log  main;",
          "20:     sendfile        on;",
          "21:     keepalive_timeout  65;",
          "23:     # include /etc/nginx/conf.d/*.conf;",
          "25:     upstream minio {",
          "26:         server site1-minio1:9000;",
          "27:         server site1-minio2:9000;",
          "28:         server site1-minio3:9000;",
          "29:         server site1-minio4:9000;",
          "30:     }",
          "32:     server {",
          "33:         listen       9001;",
          "34:         listen  [::]:9001;",
          "35:         server_name  localhost;",
          "37:         # To allow special characters in headers",
          "38:         ignore_invalid_headers off;",
          "39:         # Allow any size file to be uploaded.",
          "40:         # Set to a value such as 1000m; to restrict file size to a specific value",
          "41:         client_max_body_size 0;",
          "42:         # To disable buffering",
          "43:         proxy_buffering off;",
          "44:         proxy_request_buffering off;",
          "46:         location / {",
          "47:             proxy_set_header Host $http_host;",
          "48:             proxy_set_header X-Real-IP $remote_addr;",
          "49:             proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;",
          "50:             proxy_set_header X-Forwarded-Proto $scheme;",
          "52:             proxy_connect_timeout 300;",
          "53:             # Default is HTTP/1, keepalive is only enabled in HTTP/1.1",
          "54:             proxy_http_version 1.1;",
          "55:             proxy_set_header Connection \"\";",
          "56:             chunked_transfer_encoding off;",
          "58:             proxy_pass http://minio;",
          "59:         }",
          "60:     }",
          "61: }",
          "",
          "---------------"
        ],
        ".github/workflows/multipart/nginx-site2.conf||.github/workflows/multipart/nginx-site2.conf": [
          "File: .github/workflows/multipart/nginx-site2.conf -> .github/workflows/multipart/nginx-site2.conf",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: user  nginx;",
          "2: worker_processes  auto;",
          "4: error_log  /var/log/nginx/error.log warn;",
          "5: pid        /var/run/nginx.pid;",
          "7: events {",
          "8:     worker_connections  4096;",
          "9: }",
          "11: http {",
          "12:     include       /etc/nginx/mime.types;",
          "13:     default_type  application/octet-stream;",
          "15:     log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '",
          "16:                       '$status $body_bytes_sent \"$http_referer\" '",
          "17:                       '\"$http_user_agent\" \"$http_x_forwarded_for\"';",
          "19:     access_log  /var/log/nginx/access.log  main;",
          "20:     sendfile        on;",
          "21:     keepalive_timeout  65;",
          "23:     # include /etc/nginx/conf.d/*.conf;",
          "25:     upstream minio {",
          "26:         server site2-minio1:9000;",
          "27:         server site2-minio2:9000;",
          "28:         server site2-minio3:9000;",
          "29:         server site2-minio4:9000;",
          "30:     }",
          "32:     server {",
          "33:         listen       9002;",
          "34:         listen  [::]:9002;",
          "35:         server_name  localhost;",
          "37:         # To allow special characters in headers",
          "38:         ignore_invalid_headers off;",
          "39:         # Allow any size file to be uploaded.",
          "40:         # Set to a value such as 1000m; to restrict file size to a specific value",
          "41:         client_max_body_size 0;",
          "42:         # To disable buffering",
          "43:         proxy_buffering off;",
          "44:         proxy_request_buffering off;",
          "46:         location / {",
          "47:             proxy_set_header Host $http_host;",
          "48:             proxy_set_header X-Real-IP $remote_addr;",
          "49:             proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;",
          "50:             proxy_set_header X-Forwarded-Proto $scheme;",
          "52:             proxy_connect_timeout 300;",
          "53:             # Default is HTTP/1, keepalive is only enabled in HTTP/1.1",
          "54:             proxy_http_version 1.1;",
          "55:             proxy_set_header Connection \"\";",
          "56:             chunked_transfer_encoding off;",
          "58:             proxy_pass http://minio;",
          "59:         }",
          "60:     }",
          "61: }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "630963fa6bd0072acd07f7cb3966857b10735107",
      "candidate_info": {
        "commit_hash": "630963fa6bd0072acd07f7cb3966857b10735107",
        "repo": "minio/minio",
        "commit_url": "https://github.com/minio/minio/commit/630963fa6bd0072acd07f7cb3966857b10735107",
        "files": [
          ".github/workflows/multipart/migrate.sh",
          "buildscripts/rewrite-old-new.sh",
          "cmd/admin-heal-ops.go"
        ],
        "message": "protect tracker copy properly to avoid race (#18984)\n\n```\nWARNING: DATA RACE\nWrite at 0x00c000aac1e0 by goroutine 1133:\n  github.com/minio/minio/cmd.(*healingTracker).updateProgress()\n      github.com/minio/minio/cmd/background-newdisks-heal-ops.go:183 +0x117\n  github.com/minio/minio/cmd.(*erasureObjects).healErasureSet.func5()\n      github.com/minio/minio/cmd/global-heal.go:292 +0x1d3\n\nPrevious read at 0x00c000aac1e0 by goroutine 1003:\n  github.com/minio/minio/cmd.(*allHealState).updateHealStatus()\n      github.com/minio/minio/cmd/admin-heal-ops.go:136 +0xcb\n  github.com/minio/minio/cmd.(*healingTracker).save()\n      github.com/minio/minio/cmd/background-newdisks-heal-ops.go:223 +0x424\n```",
        "before_after_code_files": [
          ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh",
          "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh",
          "cmd/admin-heal-ops.go||cmd/admin-heal-ops.go"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh",
            "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh"
          ],
          "candidate": [
            ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh",
            "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh"
          ]
        }
      },
      "candidate_diff": {
        ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh": [
          "File: .github/workflows/multipart/migrate.sh -> .github/workflows/multipart/migrate.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "27: (",
          "28:  cd /tmp",
          "30: )",
          "32: export RELEASE=RELEASE.2023-08-29T23-07-35Z",
          "",
          "[Removed Lines]",
          "29:  go install github.com/minio/minio/docs/debugging/s3-check-md5@latest",
          "",
          "[Added Lines]",
          "29:  go install github.com/minio/minio/docs/debugging/s3-check-md5@master",
          "",
          "---------------"
        ],
        "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh": [
          "File: buildscripts/rewrite-old-new.sh -> buildscripts/rewrite-old-new.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "87:   exit 1",
          "88:  fi",
          "91:  if ! s3-check-md5 \\",
          "92:   -debug \\",
          "93:   -versions \\",
          "",
          "[Removed Lines]",
          "90:  go install github.com/minio/minio/docs/debugging/s3-check-md5@latest",
          "",
          "[Added Lines]",
          "90:  go install github.com/minio/minio/docs/debugging/s3-check-md5@master",
          "",
          "---------------"
        ],
        "cmd/admin-heal-ops.go||cmd/admin-heal-ops.go": [
          "File: cmd/admin-heal-ops.go -> cmd/admin-heal-ops.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "133: func (ahs *allHealState) updateHealStatus(tracker *healingTracker) {",
          "134:  ahs.Lock()",
          "135:  defer ahs.Unlock()",
          "137: }",
          "",
          "[Removed Lines]",
          "136:  ahs.healStatus[tracker.ID] = *tracker",
          "",
          "[Added Lines]",
          "137:  tracker.mu.RLock()",
          "138:  t := *tracker",
          "139:  t.QueuedBuckets = append(make([]string, 0, len(tracker.QueuedBuckets)), tracker.QueuedBuckets...)",
          "140:  t.HealedBuckets = append(make([]string, 0, len(tracker.HealedBuckets)), tracker.HealedBuckets...)",
          "141:  ahs.healStatus[tracker.ID] = t",
          "142:  tracker.mu.RUnlock()",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "9a3c992d7a2729e865940e7031f158fcf831144a",
      "candidate_info": {
        "commit_hash": "9a3c992d7a2729e865940e7031f158fcf831144a",
        "repo": "minio/minio",
        "commit_url": "https://github.com/minio/minio/commit/9a3c992d7a2729e865940e7031f158fcf831144a",
        "files": [
          "Makefile",
          "buildscripts/verify-healing-empty-erasure-set.sh",
          "buildscripts/verify-healing.sh",
          "cmd/global-heal.go"
        ],
        "message": "heal: Fix regression in healing a new fresh drive (#19615)",
        "before_after_code_files": [
          "buildscripts/verify-healing-empty-erasure-set.sh||buildscripts/verify-healing-empty-erasure-set.sh",
          "buildscripts/verify-healing.sh||buildscripts/verify-healing.sh",
          "cmd/global-heal.go||cmd/global-heal.go"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "buildscripts/verify-healing-empty-erasure-set.sh||buildscripts/verify-healing-empty-erasure-set.sh",
            "buildscripts/verify-healing.sh||buildscripts/verify-healing.sh"
          ],
          "candidate": [
            "buildscripts/verify-healing-empty-erasure-set.sh||buildscripts/verify-healing-empty-erasure-set.sh",
            "buildscripts/verify-healing.sh||buildscripts/verify-healing.sh"
          ]
        }
      },
      "candidate_diff": {
        "buildscripts/verify-healing-empty-erasure-set.sh||buildscripts/verify-healing-empty-erasure-set.sh": [
          "File: buildscripts/verify-healing-empty-erasure-set.sh -> buildscripts/verify-healing-empty-erasure-set.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: #!/bin/bash -e",
          "2: #",
          "4: set -E",
          "5: set -o pipefail",
          "7: if [ ! -x \"$PWD/minio\" ]; then",
          "8:  echo \"minio executable binary not found in current directory\"",
          "9:  exit 1",
          "10: fi",
          "12: WORK_DIR=\"$PWD/.verify-$RANDOM\"",
          "13: MINIO_CONFIG_DIR=\"$WORK_DIR/.minio\"",
          "14: MINIO=(\"$PWD/minio\" --config-dir \"$MINIO_CONFIG_DIR\" server)",
          "16: function start_minio_3_node() {",
          "17:  export MINIO_ROOT_USER=minio",
          "18:  export MINIO_ROOT_PASSWORD=minio123",
          "19:  export MINIO_ERASURE_SET_DRIVE_COUNT=6",
          "20:  export MINIO_CI_CD=1",
          "22:  start_port=$2",
          "23:  args=\"\"",
          "24:  for i in $(seq 1 3); do",
          "25:   args=\"$args http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/1/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/2/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/3/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/4/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/5/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/6/\"",
          "26:  done",
          "28:  \"${MINIO[@]}\" --address \":$((start_port + 1))\" $args >\"${WORK_DIR}/dist-minio-server1.log\" 2>&1 &",
          "29:  pid1=$!",
          "30:  disown ${pid1}",
          "32:  \"${MINIO[@]}\" --address \":$((start_port + 2))\" $args >\"${WORK_DIR}/dist-minio-server2.log\" 2>&1 &",
          "33:  pid2=$!",
          "34:  disown $pid2",
          "36:  \"${MINIO[@]}\" --address \":$((start_port + 3))\" $args >\"${WORK_DIR}/dist-minio-server3.log\" 2>&1 &",
          "37:  pid3=$!",
          "38:  disown $pid3",
          "40:  sleep \"$1\"",
          "42:  if ! ps -p $pid1 1>&2 >/dev/null; then",
          "43:   echo \"server1 log:\"",
          "44:   cat \"${WORK_DIR}/dist-minio-server1.log\"",
          "45:   echo \"FAILED\"",
          "46:   purge \"$WORK_DIR\"",
          "47:   exit 1",
          "48:  fi",
          "50:  if ! ps -p $pid2 1>&2 >/dev/null; then",
          "51:   echo \"server2 log:\"",
          "52:   cat \"${WORK_DIR}/dist-minio-server2.log\"",
          "53:   echo \"FAILED\"",
          "54:   purge \"$WORK_DIR\"",
          "55:   exit 1",
          "56:  fi",
          "58:  if ! ps -p $pid3 1>&2 >/dev/null; then",
          "59:   echo \"server3 log:\"",
          "60:   cat \"${WORK_DIR}/dist-minio-server3.log\"",
          "61:   echo \"FAILED\"",
          "62:   purge \"$WORK_DIR\"",
          "63:   exit 1",
          "64:  fi",
          "66:  if ! pkill minio; then",
          "67:   for i in $(seq 1 3); do",
          "68:    echo \"server$i log:\"",
          "69:    cat \"${WORK_DIR}/dist-minio-server$i.log\"",
          "70:   done",
          "71:   echo \"FAILED\"",
          "72:   purge \"$WORK_DIR\"",
          "73:   exit 1",
          "74:  fi",
          "76:  sleep 1",
          "77:  if pgrep minio; then",
          "78:   # forcibly killing, to proceed further properly.",
          "79:   if ! pkill -9 minio; then",
          "80:    echo \"no minio process running anymore, proceed.\"",
          "81:   fi",
          "82:  fi",
          "83: }",
          "85: function check_online() {",
          "86:  if ! grep -q 'Status:' ${WORK_DIR}/dist-minio-*.log; then",
          "87:   echo \"1\"",
          "88:  fi",
          "89: }",
          "91: function purge() {",
          "92:  rm -rf \"$1\"",
          "93: }",
          "95: function __init__() {",
          "96:  echo \"Initializing environment\"",
          "97:  mkdir -p \"$WORK_DIR\"",
          "98:  mkdir -p \"$MINIO_CONFIG_DIR\"",
          "100:  ## version is purposefully set to '3' for minio to migrate configuration file",
          "101:  echo '{\"version\": \"3\", \"credential\": {\"accessKey\": \"minio\", \"secretKey\": \"minio123\"}, \"region\": \"us-east-1\"}' >\"$MINIO_CONFIG_DIR/config.json\"",
          "102: }",
          "104: function perform_test() {",
          "105:  start_minio_3_node 120 $2",
          "107:  echo \"Testing Distributed Erasure setup healing of drives\"",
          "108:  echo \"Remove the contents of the disks belonging to '${1}' erasure set\"",
          "112:  set -x",
          "113:  start_minio_3_node 120 $2",
          "115:  rv=$(check_online)",
          "116:  if [ \"$rv\" == \"1\" ]; then",
          "117:   for i in $(seq 1 3); do",
          "118:    echo \"server$i log:\"",
          "119:    cat \"${WORK_DIR}/dist-minio-server$i.log\"",
          "120:   done",
          "121:   pkill -9 minio",
          "122:   echo \"FAILED\"",
          "123:   purge \"$WORK_DIR\"",
          "124:   exit 1",
          "125:  fi",
          "126: }",
          "128: function main() {",
          "129:  # use same ports for all tests",
          "130:  start_port=$(shuf -i 10000-65000 -n 1)",
          "132:  perform_test \"2\" ${start_port}",
          "133:  perform_test \"1\" ${start_port}",
          "134:  perform_test \"3\" ${start_port}",
          "135: }",
          "137: (__init__ \"$@\" && main \"$@\")",
          "138: rv=$?",
          "139: purge \"$WORK_DIR\"",
          "140: exit \"$rv\"",
          "",
          "---------------"
        ],
        "buildscripts/verify-healing.sh||buildscripts/verify-healing.sh": [
          "File: buildscripts/verify-healing.sh -> buildscripts/verify-healing.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "12: WORK_DIR=\"$PWD/.verify-$RANDOM\"",
          "13: MINIO_CONFIG_DIR=\"$WORK_DIR/.minio\"",
          "14: MINIO=(\"$PWD/minio\" --config-dir \"$MINIO_CONFIG_DIR\" server)",
          "16: function start_minio_3_node() {",
          "17:  export MINIO_ROOT_USER=minio",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "15: GOPATH=/tmp/gopath",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "19:  export MINIO_ERASURE_SET_DRIVE_COUNT=6",
          "20:  export MINIO_CI_CD=1",
          "22:  start_port=$2",
          "23:  args=\"\"",
          "26:  done",
          "28:  \"${MINIO[@]}\" --address \":$((start_port + 1))\" $args >\"${WORK_DIR}/dist-minio-server1.log\" 2>&1 &",
          "",
          "[Removed Lines]",
          "24:  for i in $(seq 1 3); do",
          "25:   args=\"$args http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/1/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/2/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/3/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/4/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/5/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/6/\"",
          "",
          "[Added Lines]",
          "23:  first_time=$(find ${WORK_DIR}/ | grep format.json | wc -l)",
          "27:  for d in $(seq 1 3 5); do",
          "28:   args=\"$args http://127.0.0.1:$((start_port + 1))${WORK_DIR}/1/${d}/ http://127.0.0.1:$((start_port + 2))${WORK_DIR}/2/${d}/ http://127.0.0.1:$((start_port + 3))${WORK_DIR}/3/${d}/ \"",
          "29:   d=$((d + 1))",
          "30:   args=\"$args http://127.0.0.1:$((start_port + 1))${WORK_DIR}/1/${d}/ http://127.0.0.1:$((start_port + 2))${WORK_DIR}/2/${d}/ http://127.0.0.1:$((start_port + 3))${WORK_DIR}/3/${d}/ \"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "40:  sleep \"$1\"",
          "42:  if ! ps -p $pid1 1>&2 >/dev/null; then",
          "43:   echo \"server1 log:\"",
          "44:   cat \"${WORK_DIR}/dist-minio-server1.log\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "47:  [ ${first_time} -eq 0 ] && upload_objects $start_port",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "82:  fi",
          "83: }",
          "86:  if ! grep -q 'Status:' ${WORK_DIR}/dist-minio-*.log; then",
          "88:  fi",
          "89: }",
          "91: function purge() {",
          "",
          "[Removed Lines]",
          "85: function check_online() {",
          "87:   echo \"1\"",
          "",
          "[Added Lines]",
          "92: function check_heal() {",
          "94:   return 1",
          "97:  for ((i = 0; i < 20; i++)); do",
          "98:   test -f ${WORK_DIR}/$1/1/.minio.sys/format.json",
          "99:   v1=$?",
          "100:   nextInES=$(($1 + 1)) && [ $nextInES -gt 3 ] && nextInES=1",
          "101:   foundFiles1=$(find ${WORK_DIR}/$1/1/ | grep -v .minio.sys | grep xl.meta | wc -l)",
          "102:   foundFiles2=$(find ${WORK_DIR}/$nextInES/1/ | grep -v .minio.sys | grep xl.meta | wc -l)",
          "103:   test $foundFiles1 -eq $foundFiles2",
          "104:   v2=$?",
          "105:   [ $v1 == 0 -a $v2 == 0 ] && return 0",
          "106:   sleep 10",
          "107:  done",
          "108:  return 1",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "100:  ## version is purposefully set to '3' for minio to migrate configuration file",
          "101:  echo '{\"version\": \"3\", \"credential\": {\"accessKey\": \"minio\", \"secretKey\": \"minio123\"}, \"region\": \"us-east-1\"}' >\"$MINIO_CONFIG_DIR/config.json\"",
          "102: }",
          "104: function perform_test() {",
          "107:  echo \"Testing Distributed Erasure setup healing of drives\"",
          "112:  set -x",
          "116:  if [ \"$rv\" == \"1\" ]; then",
          "117:   for i in $(seq 1 3); do",
          "118:    echo \"server$i log:\"",
          "",
          "[Removed Lines]",
          "105:  start_minio_3_node 120 $2",
          "108:  echo \"Remove the contents of the disks belonging to '${1}' erasure set\"",
          "113:  start_minio_3_node 120 $2",
          "115:  rv=$(check_online)",
          "",
          "[Added Lines]",
          "123:  if [ ! -f /tmp/mc ]; then",
          "124:   wget --quiet -O /tmp/mc https://dl.minio.io/client/mc/release/linux-amd64/mc &&",
          "125:    chmod +x /tmp/mc",
          "126:  fi",
          "127: }",
          "129: function upload_objects() {",
          "130:  start_port=$1",
          "132:  /tmp/mc alias set myminio http://127.0.0.1:$((start_port + 1)) minio minio123 --api=s3v4",
          "133:  /tmp/mc ready myminio",
          "134:  /tmp/mc mb myminio/testbucket/",
          "135:  for ((i = 0; i < 20; i++)); do",
          "136:   echo \"my content\" | /tmp/mc pipe myminio/testbucket/file-$i",
          "137:  done",
          "141:  start_port=$2",
          "143:  start_minio_3_node 120 $start_port",
          "146:  echo \"Remove the contents of the disks belonging to '${1}' node\"",
          "151:  start_minio_3_node 120 $start_port",
          "153:  check_heal ${1}",
          "154:  rv=$?",
          "",
          "---------------"
        ],
        "cmd/global-heal.go||cmd/global-heal.go": [
          "File: cmd/global-heal.go -> cmd/global-heal.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "29:  \"github.com/dustin/go-humanize\"",
          "30:  \"github.com/minio/madmin-go/v3\"",
          "31:  \"github.com/minio/minio/internal/color\"",
          "32:  \"github.com/minio/minio/internal/config/storageclass\"",
          "33:  xioutil \"github.com/minio/minio/internal/ioutil\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "31:  \"github.com/minio/minio/internal/bucket/lifecycle\"",
          "32:  objectlock \"github.com/minio/minio/internal/bucket/object/lock\"",
          "33:  \"github.com/minio/minio/internal/bucket/replication\"",
          "34:  \"github.com/minio/minio/internal/bucket/versioning\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "214:    continue",
          "215:   }",
          "245:   }",
          "247:   if serverDebugLog {",
          "",
          "[Removed Lines]",
          "217:   vc, err := globalBucketVersioningSys.Get(bucket)",
          "218:   if err != nil {",
          "219:    retErr = err",
          "220:    healingLogIf(ctx, err)",
          "221:    continue",
          "222:   }",
          "225:   lc, err := globalLifecycleSys.Get(bucket)",
          "226:   if err != nil && !errors.Is(err, BucketLifecycleNotFound{Bucket: bucket}) {",
          "227:    retErr = err",
          "228:    healingLogIf(ctx, err)",
          "229:    continue",
          "230:   }",
          "233:   lr, err := globalBucketObjectLockSys.Get(bucket)",
          "234:   if err != nil {",
          "235:    retErr = err",
          "236:    healingLogIf(ctx, err)",
          "237:    continue",
          "238:   }",
          "240:   rcfg, err := getReplicationConfig(ctx, bucket)",
          "241:   if err != nil {",
          "242:    retErr = err",
          "243:    healingLogIf(ctx, err)",
          "244:    continue",
          "",
          "[Added Lines]",
          "221:   var (",
          "222:    vc   *versioning.Versioning",
          "223:    lc   *lifecycle.Lifecycle",
          "224:    lr   objectlock.Retention",
          "225:    rcfg *replication.Config",
          "226:   )",
          "228:   if !isMinioMetaBucketName(bucket) {",
          "229:    vc, err = globalBucketVersioningSys.Get(bucket)",
          "230:    if err != nil {",
          "231:     retErr = err",
          "232:     healingLogIf(ctx, err)",
          "233:     continue",
          "234:    }",
          "236:    lc, err = globalLifecycleSys.Get(bucket)",
          "237:    if err != nil && !errors.Is(err, BucketLifecycleNotFound{Bucket: bucket}) {",
          "238:     retErr = err",
          "239:     healingLogIf(ctx, err)",
          "240:     continue",
          "241:    }",
          "243:    lr, err = globalBucketObjectLockSys.Get(bucket)",
          "244:    if err != nil {",
          "245:     retErr = err",
          "246:     healingLogIf(ctx, err)",
          "247:     continue",
          "248:    }",
          "249:    rcfg, err = getReplicationConfig(ctx, bucket)",
          "250:    if err != nil {",
          "251:     retErr = err",
          "252:     healingLogIf(ctx, err)",
          "253:     continue",
          "254:    }",
          "",
          "---------------"
        ]
      }
    }
  ]
}