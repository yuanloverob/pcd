{
  "cve_id": "CVE-2021-45456",
  "cve_desc": "Apache kylin checks the legitimacy of the project before executing some commands with the project name passed in by the user. There is a mismatch between what is being checked and what is being used as the shell command argument in DiagnosisService. This may cause an illegal project name to pass the check and perform the following steps, resulting in a command injection vulnerability. This issue affects Apache Kylin 4.0.0.",
  "repo": "apache/kylin",
  "patch_hash": "f4daf14dde99b934c92ce2c832509f24342bc845",
  "patch_info": {
    "commit_hash": "f4daf14dde99b934c92ce2c832509f24342bc845",
    "repo": "apache/kylin",
    "commit_url": "https://github.com/apache/kylin/commit/f4daf14dde99b934c92ce2c832509f24342bc845",
    "files": [
      "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
      "core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java",
      "core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java",
      "server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java",
      "server/src/main/webapp/WEB-INF/web.xml"
    ],
    "message": "test fix",
    "before_after_code_files": [
      "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
      "core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java||core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java",
      "core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java||core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java",
      "server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java||server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java"
    ]
  },
  "patch_diff": {
    "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java": [
      "File: core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java -> core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "3403:     public String getKerberosPrincipal() {",
      "3404:         return getOptional(\"kylin.kerberos.principal\");",
      "3405:     }",
      "3406: }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "3407:     public String getEncryptCipherIvSpec() {",
      "3408:         return getOptional(\"kylin.security.encrypt.cipher.ivSpec\", \"AAAAAAAAAAAAAAAA\");",
      "3409:     }",
      "",
      "---------------"
    ],
    "core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java||core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java": [
      "File: core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java -> core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "25: import java.security.NoSuchAlgorithmException;",
      "27: import org.apache.commons.codec.binary.Base64;",
      "29: import javax.crypto.Cipher;",
      "30: import javax.crypto.NoSuchPaddingException;",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "28: import org.apache.kylin.common.KylinConfig;",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "42:             InvalidKeyException, NoSuchPaddingException, NoSuchAlgorithmException, UnsupportedEncodingException {",
      "43:         Cipher cipher = Cipher.getInstance(\"AES/CFB/PKCS5Padding\");",
      "44:         final SecretKeySpec secretKey = new SecretKeySpec(key, \"AES\");",
      "46:         cipher.init(cipherMode, secretKey, ivSpec);",
      "47:         return cipher;",
      "48:     }",
      "",
      "[Removed Lines]",
      "45:         IvParameterSpec ivSpec = new IvParameterSpec(\"AAAAAAAAAAAAAAAA\".getBytes(\"UTF-8\"));",
      "",
      "[Added Lines]",
      "46:         IvParameterSpec ivSpec = new IvParameterSpec(KylinConfig.getInstanceFromEnv().getEncryptCipherIvSpec().getBytes(\"UTF-8\"));",
      "",
      "---------------"
    ],
    "core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java||core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java": [
      "File: core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java -> core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "19: package org.apache.kylin.common.util;",
      "21: import org.junit.Assert;",
      "22: import org.junit.Test;",
      "26:     @Test",
      "27:     public void testAESEncrypt(){",
      "",
      "[Removed Lines]",
      "24: public class EncryptUtilTest {",
      "",
      "[Added Lines]",
      "21: import org.junit.After;",
      "23: import org.junit.Before;",
      "26: public class EncryptUtilTest extends LocalFileMetadataTestCase {",
      "27:     @Before",
      "28:     public void setUp() throws Exception {",
      "29:         this.createTestMetadata();",
      "30:     }",
      "32:     @After",
      "33:     public void after() throws Exception {",
      "34:         this.cleanupTestMetadata();",
      "35:     }",
      "",
      "---------------"
    ],
    "server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java||server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java": [
      "File: server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java -> server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "87:     public String dumpProjectDiagnosisInfo(String project, File exportPath) throws IOException {",
      "88:         Message msg = MsgPicker.getMsg();",
      "89:         ProjectInstance projectInstance =",
      "90:                 ProjectManager.getInstance(KylinConfig.getInstanceFromEnv())",
      "92:         if (null == projectInstance) {",
      "93:             throw new BadRequestException(",
      "95:         }",
      "96:         aclEvaluate.checkProjectOperationPermission(projectInstance);",
      "98:         runDiagnosisCLI(args);",
      "99:         return getDiagnosisPackageName(exportPath);",
      "100:     }",
      "",
      "[Removed Lines]",
      "91:                         .getProject(ValidateUtil.convertStringToBeAlphanumericUnderscore(project));",
      "94:                     String.format(Locale.ROOT, msg.getDIAG_PROJECT_NOT_FOUND(), project));",
      "97:         String[] args = { project, exportPath.getAbsolutePath() };",
      "",
      "[Added Lines]",
      "89:         String projectName = ValidateUtil.convertStringToBeAlphanumericUnderscore(project);",
      "92:                         .getProject(projectName);",
      "95:                     String.format(Locale.ROOT, msg.getDIAG_PROJECT_NOT_FOUND(), projectName));",
      "98:         String[] args = { projectName, exportPath.getAbsolutePath() };",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "de95ab977e700178efd70705ead4edaca272d41f",
      "candidate_info": {
        "commit_hash": "de95ab977e700178efd70705ead4edaca272d41f",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/de95ab977e700178efd70705ead4edaca272d41f",
        "files": [
          "examples/test_case_data/parquet_test/cube/ssb.json",
          "examples/test_case_data/parquet_test/cube_desc/ssb.json",
          "examples/test_case_data/parquet_test/data/SSB.P_LINEORDER.csv",
          "examples/test_case_data/parquet_test/model_desc/ssb.json",
          "examples/test_case_data/parquet_test/project/default.json",
          "examples/test_case_data/parquet_test/table/SSB.P_LINEORDER.json",
          "kylin-it/src/test/resources/query/sql_prune_segment/query00.sql",
          "kylin-it/src/test/resources/query/sql_prune_segment/query01.sql",
          "kylin-spark-project/kylin-spark-test/src/test/java/org/apache/kylin/engine/spark2/NBuildAndQueryTest.java",
          "kylin-spark-project/kylin-spark-test/src/test/java/org/apache/kylin/engine/spark2/NExecAndComp.java"
        ],
        "message": "add test case for interger type partition pruner",
        "before_after_code_files": [
          "kylin-it/src/test/resources/query/sql_prune_segment/query00.sql||kylin-it/src/test/resources/query/sql_prune_segment/query00.sql",
          "kylin-it/src/test/resources/query/sql_prune_segment/query01.sql||kylin-it/src/test/resources/query/sql_prune_segment/query01.sql",
          "kylin-spark-project/kylin-spark-test/src/test/java/org/apache/kylin/engine/spark2/NBuildAndQueryTest.java||kylin-spark-project/kylin-spark-test/src/test/java/org/apache/kylin/engine/spark2/NBuildAndQueryTest.java",
          "kylin-spark-project/kylin-spark-test/src/test/java/org/apache/kylin/engine/spark2/NExecAndComp.java||kylin-spark-project/kylin-spark-test/src/test/java/org/apache/kylin/engine/spark2/NExecAndComp.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "kylin-it/src/test/resources/query/sql_prune_segment/query00.sql||kylin-it/src/test/resources/query/sql_prune_segment/query00.sql": [
          "File: kylin-it/src/test/resources/query/sql_prune_segment/query00.sql -> kylin-it/src/test/resources/query/sql_prune_segment/query00.sql",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: --",
          "2: -- Licensed to the Apache Software Foundation (ASF) under one",
          "3: -- or more contributor license agreements.  See the NOTICE file",
          "4: -- distributed with this work for additional information",
          "5: -- regarding copyright ownership.  The ASF licenses this file",
          "6: -- to you under the Apache License, Version 2.0 (the",
          "7: -- \"License\"); you may not use this file except in compliance",
          "8: -- with the License.  You may obtain a copy of the License at",
          "9: --",
          "10: --     http://www.apache.org/licenses/LICENSE-2.0",
          "11: --",
          "12: -- Unless required by applicable law or agreed to in writing, software",
          "13: -- distributed under the License is distributed on an \"AS IS\" BASIS,",
          "14: -- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
          "15: -- See the License for the specific language governing permissions and",
          "16: -- limitations under the License.",
          "17: --",
          "19: select sum(LO_REVENUE) from SSB.P_LINEORDER where LO_ORDERDATE = 19920906",
          "20: ;{\"scanRowCount\":4,\"scanBytes\":0,\"scanFiles\":1,\"cuboidId\":[7]}",
          "",
          "---------------"
        ],
        "kylin-it/src/test/resources/query/sql_prune_segment/query01.sql||kylin-it/src/test/resources/query/sql_prune_segment/query01.sql": [
          "File: kylin-it/src/test/resources/query/sql_prune_segment/query01.sql -> kylin-it/src/test/resources/query/sql_prune_segment/query01.sql",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: --",
          "2: -- Licensed to the Apache Software Foundation (ASF) under one",
          "3: -- or more contributor license agreements.  See the NOTICE file",
          "4: -- distributed with this work for additional information",
          "5: -- regarding copyright ownership.  The ASF licenses this file",
          "6: -- to you under the Apache License, Version 2.0 (the",
          "7: -- \"License\"); you may not use this file except in compliance",
          "8: -- with the License.  You may obtain a copy of the License at",
          "9: --",
          "10: --     http://www.apache.org/licenses/LICENSE-2.0",
          "11: --",
          "12: -- Unless required by applicable law or agreed to in writing, software",
          "13: -- distributed under the License is distributed on an \"AS IS\" BASIS,",
          "14: -- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
          "15: -- See the License for the specific language governing permissions and",
          "16: -- limitations under the License.",
          "17: --",
          "19: select sum(LO_REVENUE) from SSB.P_LINEORDER where LO_ORDERDATE = '19920906'",
          "20: ;{\"scanRowCount\":4,\"scanBytes\":0,\"scanFiles\":1,\"cuboidId\":[7]}",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-test/src/test/java/org/apache/kylin/engine/spark2/NBuildAndQueryTest.java||kylin-spark-project/kylin-spark-test/src/test/java/org/apache/kylin/engine/spark2/NBuildAndQueryTest.java": [
          "File: kylin-spark-project/kylin-spark-test/src/test/java/org/apache/kylin/engine/spark2/NBuildAndQueryTest.java -> kylin-spark-project/kylin-spark-test/src/test/java/org/apache/kylin/engine/spark2/NBuildAndQueryTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "200:             tasks.add(new QueryCallable(CompareLevel.SAME, joinType, \"sql_unionall\"));",
          "201:             tasks.add(new QueryCallable(CompareLevel.SAME, joinType, \"sql_values\"));",
          "202:             tasks.add(new QueryCallable(CompareLevel.SAME, joinType, \"sql_window\"));",
          "203:             tasks.add(new QueryCallable(CompareLevel.SAME, joinType, \"sql_limit\"));",
          "204:         }",
          "205:         logger.info(\"Total {} tasks.\", tasks.size());",
          "206:         return tasks;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "205:             tasks.add(new QueryCallable(CompareLevel.SAME, joinType, \"sql_prune_segment\"));",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "213:         } else if (Boolean.parseBoolean(System.getProperty(\"isDeveloperMode\", \"false\"))) {",
          "215:             fullBuildCube(\"ci_left_join_cube\");",
          "216:         } else {",
          "218:             buildAndMergeCube(\"ci_left_join_cube\");",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "218:             buildSegments(\"ssb\", new SegmentRange.TSRange(dateToLong(\"1992-09-04\"), dateToLong(\"1992-09-05\")),",
          "219:                     new SegmentRange.TSRange(dateToLong(\"1992-09-05\"), dateToLong(\"1992-09-06\")),",
          "220:                     new SegmentRange.TSRange(dateToLong(\"1992-09-06\"), dateToLong(\"1992-09-07\")),",
          "221:                     new SegmentRange.TSRange(dateToLong(\"1992-09-07\"), dateToLong(\"1992-09-08\")));",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "223:         if (cubeName.equals(\"ci_inner_join_cube\")) {",
          "224:             buildFourSegmentAndMerge(cubeName);",
          "225:         }",
          "226:         if (cubeName.equals(\"ci_left_join_cube\")) {",
          "227:             buildTwoSegmentAndMerge(cubeName);",
          "228:         }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "232:         if (cubeName.equals(\"ssb\")) {",
          "233:             buildSegments(cubeName, new SegmentRange.TSRange(dateToLong(\"1992-0-01\"), dateToLong(\"2015-01-01\")));",
          "234:         }",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "289:         ExecutableState state;",
          "303:         state = mergeSegments(cubeName, dateToLong(\"2010-01-01\"), dateToLong(\"2013-01-01\"), false);",
          "",
          "[Removed Lines]",
          "290:         state = buildCuboid(cubeName, new SegmentRange.TSRange(dateToLong(\"2010-01-01\"), dateToLong(\"2012-06-01\")));",
          "291:         Assert.assertEquals(ExecutableState.SUCCEED, state);",
          "293:         state = buildCuboid(cubeName, new SegmentRange.TSRange(dateToLong(\"2012-06-01\"), dateToLong(\"2013-01-01\")));",
          "294:         Assert.assertEquals(ExecutableState.SUCCEED, state);",
          "296:         state = buildCuboid(cubeName, new SegmentRange.TSRange(dateToLong(\"2013-01-01\"), dateToLong(\"2013-06-01\")));",
          "297:         Assert.assertEquals(ExecutableState.SUCCEED, state);",
          "299:         state = buildCuboid(cubeName, new SegmentRange.TSRange(dateToLong(\"2013-06-01\"), dateToLong(\"2015-01-01\")));",
          "300:         Assert.assertEquals(ExecutableState.SUCCEED, state);",
          "",
          "[Added Lines]",
          "299:         buildSegments(cubeName, new SegmentRange.TSRange(dateToLong(\"2010-01-01\"), dateToLong(\"2012-06-01\")),",
          "300:                 new SegmentRange.TSRange(dateToLong(\"2012-06-01\"), dateToLong(\"2013-01-01\")),",
          "301:                 new SegmentRange.TSRange(dateToLong(\"2013-01-01\"), dateToLong(\"2013-06-01\")),",
          "302:                 new SegmentRange.TSRange(dateToLong(\"2013-06-01\"), dateToLong(\"2015-01-01\")));",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "316:                 secondSegment.getSegRange());",
          "317:     }",
          "319:     class QueryCallable implements Callable<Pair<String, Throwable>> {",
          "321:         private NExecAndComp.CompareLevel compareLevel;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "321:     public void buildSegments(String cubeName, SegmentRange.TSRange ... toBuildRanges) throws Exception{",
          "322:         Assert.assertTrue(config.getHdfsWorkingDirectory().startsWith(\"file:\"));",
          "325:         cleanupSegments(cubeName);",
          "327:         ExecutableState state;",
          "328:         for (SegmentRange.TSRange toBuildRange : toBuildRanges) {",
          "329:             state = buildCuboid(cubeName, toBuildRange);",
          "330:             Assert.assertEquals(ExecutableState.SUCCEED, state);",
          "331:         }",
          "332:     }",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-test/src/test/java/org/apache/kylin/engine/spark2/NExecAndComp.java||kylin-spark-project/kylin-spark-test/src/test/java/org/apache/kylin/engine/spark2/NExecAndComp.java": [
          "File: kylin-spark-project/kylin-spark-test/src/test/java/org/apache/kylin/engine/spark2/NExecAndComp.java -> kylin-spark-project/kylin-spark-test/src/test/java/org/apache/kylin/engine/spark2/NExecAndComp.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "395:                 .replaceAll(\"`TDVT`\\\\.\", \"\") //",
          "396:                 .replaceAll(\"\\\"POPHEALTH_ANALYTICS\\\"\\\\.\", \"\") //",
          "397:                 .replaceAll(\"`POPHEALTH_ANALYTICS`\\\\.\", \"\") //",
          "399:     }",
          "401:     public static List<Pair<String, String>> fetchQueries(String folder) throws IOException {",
          "",
          "[Removed Lines]",
          "398:                 .replaceAll(\"(?i)ISSUES\\\\.\", \"\");",
          "",
          "[Added Lines]",
          "398:                 .replaceAll(\"(?i)ISSUES\\\\.\", \"\")",
          "399:                 .replaceAll(\"SSB\\\\.\", \"\")",
          "400:                 .replaceAll(\"\\\"SSB\\\"\\\\.\", \"\")",
          "401:                 .replaceAll(\"`SSB`\\\\.\", \"\");",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "ba86987e32e572610faf0f690ae9601bd774d55a",
      "candidate_info": {
        "commit_hash": "ba86987e32e572610faf0f690ae9601bd774d55a",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/ba86987e32e572610faf0f690ae9601bd774d55a",
        "files": [
          "webapp/app/js/controllers/sourceMeta.js"
        ],
        "message": "KYLIN-4510 Automatically refresh the page after reload table\n\n(cherry picked from commit fdf0d8f3e5d1574123f8c293f861a58bb35e0f06)",
        "before_after_code_files": [
          "webapp/app/js/controllers/sourceMeta.js||webapp/app/js/controllers/sourceMeta.js"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "webapp/app/js/controllers/sourceMeta.js||webapp/app/js/controllers/sourceMeta.js": [
          "File: webapp/app/js/controllers/sourceMeta.js -> webapp/app/js/controllers/sourceMeta.js",
          "--- Hunk 1 ---",
          "[Context before]",
          "433:         $scope.loadHive();",
          "434:       }",
          "439:         })",
          "440:       }",
          "",
          "[Removed Lines]",
          "436:       $scope.confirmReload = function () {",
          "437:         scope.reloadTable($scope.selectTable, $scope.isCalculate.val).then(function () {",
          "438:           $scope.cancel();",
          "",
          "[Added Lines]",
          "436:       $scope.confirmReload = function() {",
          "437:         $scope.cancel();",
          "438:         scope.reloadTable($scope.selectTable, $scope.isCalculate.val).then(function() {",
          "439:           scope.aceSrcTbLoaded(true);",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "b99ac75e2f2c3285a28918e2d00bb4a401e1f155",
      "candidate_info": {
        "commit_hash": "b99ac75e2f2c3285a28918e2d00bb4a401e1f155",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/b99ac75e2f2c3285a28918e2d00bb4a401e1f155",
        "files": [
          "engine-mr/src/main/java/org/apache/kylin/engine/mr/common/DefaultSslProtocolSocketFactory.java"
        ],
        "message": "KYLIN-4477 Resolve Issue: Use secure TLSv1.3 instead of insecure TLS\n\nSigned-off-by: shaofengshi <shaofengshi@apache.org>\n(cherry picked from commit ecc39ef9624e2aed6787ffe40390a7264310735f)",
        "before_after_code_files": [
          "engine-mr/src/main/java/org/apache/kylin/engine/mr/common/DefaultSslProtocolSocketFactory.java||engine-mr/src/main/java/org/apache/kylin/engine/mr/common/DefaultSslProtocolSocketFactory.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "engine-mr/src/main/java/org/apache/kylin/engine/mr/common/DefaultSslProtocolSocketFactory.java||engine-mr/src/main/java/org/apache/kylin/engine/mr/common/DefaultSslProtocolSocketFactory.java": [
          "File: engine-mr/src/main/java/org/apache/kylin/engine/mr/common/DefaultSslProtocolSocketFactory.java -> engine-mr/src/main/java/org/apache/kylin/engine/mr/common/DefaultSslProtocolSocketFactory.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "131:     private static SSLContext createEasySSLContext() {",
          "132:         try {",
          "134:             context.init(null, new TrustManager[] { new DefaultX509TrustManager(null) }, null);",
          "136:             return context;",
          "",
          "[Removed Lines]",
          "133:             SSLContext context = SSLContext.getInstance(\"TLS\");",
          "",
          "[Added Lines]",
          "133:             SSLContext context = SSLContext.getInstance(\"TLSv1.3\");",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "6153889ce1b1fad2c409364e77ec471166654551",
      "candidate_info": {
        "commit_hash": "6153889ce1b1fad2c409364e77ec471166654551",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/6153889ce1b1fad2c409364e77ec471166654551",
        "files": [
          "kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/utils/SparkVersionUtils.scala",
          "kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/application/SparkApplication.java",
          "kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/job/NSparkExecutable.java",
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeDictionaryBuilder.scala",
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeTableEncoder.scala",
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/utils/Repartitioner.java",
          "kylin-spark-project/kylin-spark-engine/src/test/scala/org/apache/kylin/engine/spark/builder/TestGlobalDictBuild.scala"
        ],
        "message": "KYLIN-4967 Forbid to set 'spark.sql.adaptive.enabled' to true when building cube with Spark 2.X\n\nWith spark 2.X, when set 'spark.sql.adaptive.enabled' to true, it will impact the actually partition count when doing repartition with spark, which will lead to the wrong results for global dict and repartition by shardby column.\n\nFor example, after writing a cuboid data, kylin will repartition the cuboid data with 3 partition if need, but if 'spark.sql.adaptive.enabled' is true, spark will optimize the partition num to 1, which leads to wrong.",
        "before_after_code_files": [
          "kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/utils/SparkVersionUtils.scala||kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/utils/SparkVersionUtils.scala",
          "kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/application/SparkApplication.java||kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/application/SparkApplication.java",
          "kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/job/NSparkExecutable.java||kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/job/NSparkExecutable.java",
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeDictionaryBuilder.scala||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeDictionaryBuilder.scala",
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeTableEncoder.scala||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeTableEncoder.scala",
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/utils/Repartitioner.java||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/utils/Repartitioner.java",
          "kylin-spark-project/kylin-spark-engine/src/test/scala/org/apache/kylin/engine/spark/builder/TestGlobalDictBuild.scala||kylin-spark-project/kylin-spark-engine/src/test/scala/org/apache/kylin/engine/spark/builder/TestGlobalDictBuild.scala"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/utils/SparkVersionUtils.scala||kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/utils/SparkVersionUtils.scala": [
          "File: kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/utils/SparkVersionUtils.scala -> kylin-spark-project/kylin-spark-common/src/main/scala/org/apache/spark/utils/SparkVersionUtils.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19: package org.apache.spark.utils",
          "21: import org.apache.spark.SPARK_VERSION",
          "23: object SparkVersionUtils {",
          "31:   def getSparkVersionAsNumeric(): Float = {",
          "32:     val tmpArray = SPARK_VERSION.split(\"\\\\.\")",
          "34:     if (tmpArray.length >= 2) {",
          "35:       (tmpArray(0) + \".\" + tmpArray(1)).toFloat",
          "36:     } else {",
          "37:       (tmpArray(0) + \".0\").toFloat",
          "38:     }",
          "39:   }",
          "45:   def isEqualToSparkVersion(targetVersion: String): Boolean = {",
          "46:     getSparkVersionAsNumeric == targetVersion.toFloat",
          "47:   }",
          "53:   def isGreaterThanSparkVersion(targetVersion: String, isEqualTo: Boolean = false): Boolean = {",
          "55:     if (isEqualTo) {",
          "56:       getSparkVersionAsNumeric >= targetVersion.toFloat",
          "57:     } else {",
          "58:       getSparkVersionAsNumeric > targetVersion.toFloat",
          "59:     }",
          "60:   }",
          "66:   def isLessThanSparkVersion(targetVersion: String, isEqualTo: Boolean = false): Boolean = {",
          "68:     if (isEqualTo) {",
          "69:       getSparkVersionAsNumeric <= targetVersion.toFloat",
          "70:     } else {",
          "71:       getSparkVersionAsNumeric < targetVersion.toFloat",
          "72:     }",
          "73:   }",
          "74: }",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/application/SparkApplication.java||kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/application/SparkApplication.java": [
          "File: kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/application/SparkApplication.java -> kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/application/SparkApplication.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "60: import org.apache.spark.sql.hive.utils.ResourceDetectUtils;",
          "61: import org.apache.spark.util.Utils;",
          "62: import org.apache.spark.utils.ResourceUtils;",
          "63: import org.apache.spark.utils.YarnInfoFetcherUtils;",
          "64: import org.apache.kylin.engine.spark.common.util.TimeZoneUtils;",
          "65: import org.slf4j.Logger;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "63: import org.apache.spark.utils.SparkVersionUtils;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "247:                     sparkConf.set(\"spark.sql.shuffle.partitions\", \"1\");",
          "248:                 }",
          "249:             }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "259:             if (SparkVersionUtils.isLessThanSparkVersion(\"2.4\", true)) {",
          "260:                 sparkConf.set(\"spark.sql.adaptive.enabled\", \"false\");",
          "261:             }",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/job/NSparkExecutable.java||kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/job/NSparkExecutable.java": [
          "File: kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/job/NSparkExecutable.java -> kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/job/NSparkExecutable.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "64: import org.apache.kylin.job.execution.ExecutableContext;",
          "65: import org.apache.kylin.job.execution.ExecuteResult;",
          "66: import org.apache.kylin.metadata.MetadataConstants;",
          "67: import org.slf4j.Logger;",
          "68: import org.slf4j.LoggerFactory;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "67: import org.apache.spark.utils.SparkVersionUtils;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "290:             sparkConfigOverride.put(\"spark.hadoop.hive.metastore.sasl.enabled\", \"true\");",
          "291:         }",
          "293:         replaceSparkNodeJavaOpsConfIfNeeded(config, sparkConfigOverride);",
          "294:         return sparkConfigOverride;",
          "295:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "302:         if (SparkVersionUtils.isLessThanSparkVersion(\"2.4\", true)) {",
          "303:             sparkConfigOverride.put(\"spark.sql.adaptive.enabled\", \"false\");",
          "304:         }",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeDictionaryBuilder.scala||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeDictionaryBuilder.scala": [
          "File: kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeDictionaryBuilder.scala -> kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeDictionaryBuilder.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "30: import org.apache.spark.sql.functions.{col, expr}",
          "31: import org.apache.spark.sql.types.StringType",
          "32: import org.apache.spark.sql.{Column, Dataset, Row, SparkSession}",
          "34: import scala.collection.JavaConverters._",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "33: import org.apache.spark.utils.SparkVersionUtils",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "44:   @throws[IOException]",
          "45:   def buildDictSet(): Unit = {",
          "52:     }",
          "53:     logInfo(s\"Start building global dictionaries V2 for seg $seg\")",
          "54:     val m = s\"Build global dictionaries V2 for seg $seg succeeded\"",
          "55:     time(m, colRefSet.asScala.foreach(col => safeBuild(col)))",
          "60:   }",
          "62:   @throws[IOException]",
          "",
          "[Removed Lines]",
          "49:     val aeOriginalValue = ss.conf.get(\"spark.sql.adaptive.enabled\", \"false\").toBoolean",
          "50:     if (aeOriginalValue) {",
          "51:       ss.conf.set(\"spark.sql.adaptive.enabled\", false);",
          "56:     if (aeOriginalValue) {",
          "58:       ss.conf.set(\"spark.sql.adaptive.enabled\", aeOriginalValue);",
          "59:     }",
          "",
          "[Added Lines]",
          "47:     if (SparkVersionUtils.isLessThanSparkVersion(\"2.4\", true)) {",
          "48:       assert(!ss.conf.get(\"spark.sql.adaptive.enabled\", \"false\").toBoolean,",
          "49:         \"Parameter 'spark.sql.adaptive.enabled' must be false when building global dictionary.\")",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "77:   @throws[IOException]",
          "78:   private[builder] def build(ref: ColumnDesc, bucketPartitionSize: Int, afterDistinct: Dataset[Row]): Unit = {",
          "81:     val columnName = ref.identity",
          "82:     logInfo(s\"Start building global dictionaries V2 for column $columnName.\")",
          "",
          "[Removed Lines]",
          "79:     assert(!ss.conf.get(\"spark.sql.adaptive.enabled\", \"false\").toBoolean,",
          "80:       \"Parameter 'spark.sql.adaptive.enabled' must be false when building global dictionary.\")",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeTableEncoder.scala||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeTableEncoder.scala": [
          "File: kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeTableEncoder.scala -> kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeTableEncoder.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "28: import org.apache.spark.sql.functions.{col, _}",
          "29: import org.apache.spark.sql.types.StringType",
          "30: import org.apache.spark.sql.{Dataset, Row}",
          "32: import scala.collection.JavaConverters._",
          "33: import scala.collection.mutable._",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "31: import org.apache.spark.utils.SparkVersionUtils",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "35: object CubeTableEncoder extends Logging {",
          "37:   def encodeTable(ds: Dataset[Row], seg: SegmentInfo, cols: util.Set[ColumnDesc]): Dataset[Row] = {",
          "38:     val structType = ds.schema",
          "39:     var partitionedDs = ds",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "39:     if (SparkVersionUtils.isLessThanSparkVersion(\"2.4\", true)) {",
          "40:       assert(!ds.sparkSession.conf.get(\"spark.sql.adaptive.enabled\", \"false\").toBoolean,",
          "41:         \"Parameter 'spark.sql.adaptive.enabled' must be false when encode tables.\")",
          "42:     }",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/utils/Repartitioner.java||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/utils/Repartitioner.java": [
          "File: kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/utils/Repartitioner.java -> kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/utils/Repartitioner.java"
        ],
        "kylin-spark-project/kylin-spark-engine/src/test/scala/org/apache/kylin/engine/spark/builder/TestGlobalDictBuild.scala||kylin-spark-project/kylin-spark-engine/src/test/scala/org/apache/kylin/engine/spark/builder/TestGlobalDictBuild.scala": [
          "File: kylin-spark-project/kylin-spark-engine/src/test/scala/org/apache/kylin/engine/spark/builder/TestGlobalDictBuild.scala -> kylin-spark-project/kylin-spark-engine/src/test/scala/org/apache/kylin/engine/spark/builder/TestGlobalDictBuild.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "106:     val meta6 = buildDict(segInfo, seg, randomDataSet, dictColSet)",
          "107:     Assert.assertEquals(280, meta6.getBucketSize)",
          "108:     Assert.assertEquals(7600, meta6.getDictCount)",
          "112:     randomDataSet = generateOriginData(dictCol, 2000, 26)",
          "113:     val meta7 = buildDict(segInfo, seg, randomDataSet, dictColSet)",
          "114:     Assert.assertEquals(280, meta7.getBucketSize)",
          "115:     Assert.assertEquals(9600, meta7.getDictCount)",
          "117:     DefaultScheduler.destroyInstance()",
          "118:   }",
          "",
          "[Removed Lines]",
          "109:     Assert.assertFalse(spark.conf.get(\"spark.sql.adaptive.enabled\").toBoolean)",
          "111:     spark.conf.set(\"spark.sql.adaptive.enabled\", true)",
          "116:     Assert.assertTrue(spark.conf.get(\"spark.sql.adaptive.enabled\").toBoolean)",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "b2016f915db454e64b7018047b3df5c707d7946c",
      "candidate_info": {
        "commit_hash": "b2016f915db454e64b7018047b3df5c707d7946c",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/b2016f915db454e64b7018047b3df5c707d7946c",
        "files": [
          "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
          "core-job/src/main/java/org/apache/kylin/job/execution/AbstractExecutable.java",
          "kylin-spark-project/kylin-spark-common/src/test/java/org/apache/spark/sql/common/LocalMetadata.scala",
          "kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/job/NSparkExecutable.java",
          "kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/utils/MetaDumpUtil.java",
          "kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/utils/RestService.java",
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/spark/deploy/SparkApplicationClient.scala",
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/spark/deploy/StandaloneAppClient.scala",
          "kylin-spark-project/kylin-spark-engine/src/test/resources/response/application-detail-246.html",
          "kylin-spark-project/kylin-spark-engine/src/test/resources/response/standalone-master-246.json",
          "kylin-spark-project/kylin-spark-engine/src/test/scala/org/apache/spark/deploy/StandaloneAppClientTest.scala"
        ],
        "message": "KYLIN-5023 Support cluster deployMode for Spark App which master is standalone",
        "before_after_code_files": [
          "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
          "core-job/src/main/java/org/apache/kylin/job/execution/AbstractExecutable.java||core-job/src/main/java/org/apache/kylin/job/execution/AbstractExecutable.java",
          "kylin-spark-project/kylin-spark-common/src/test/java/org/apache/spark/sql/common/LocalMetadata.scala||kylin-spark-project/kylin-spark-common/src/test/java/org/apache/spark/sql/common/LocalMetadata.scala",
          "kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/job/NSparkExecutable.java||kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/job/NSparkExecutable.java",
          "kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/utils/MetaDumpUtil.java||kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/utils/MetaDumpUtil.java",
          "kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/utils/RestService.java||kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/utils/RestService.java",
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/spark/deploy/SparkApplicationClient.scala||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/spark/deploy/SparkApplicationClient.scala",
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/spark/deploy/StandaloneAppClient.scala||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/spark/deploy/StandaloneAppClient.scala",
          "kylin-spark-project/kylin-spark-engine/src/test/resources/response/application-detail-246.html||kylin-spark-project/kylin-spark-engine/src/test/resources/response/application-detail-246.html",
          "kylin-spark-project/kylin-spark-engine/src/test/scala/org/apache/spark/deploy/StandaloneAppClientTest.scala||kylin-spark-project/kylin-spark-engine/src/test/scala/org/apache/spark/deploy/StandaloneAppClientTest.scala"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [
            "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java"
          ],
          "candidate": [
            "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java"
          ]
        }
      },
      "candidate_diff": {
        "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java": [
          "File: core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java -> core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "1541:     }",
          "1545:     public String getKylinJobJarPath() {",
          "1546:         final String jobJar = getOptional(KYLIN_ENGINE_MR_JOB_JAR);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1544:     public String getSparkStandaloneMasterWebUI() {",
          "1545:         return getOptional(\"kylin.engine.spark.standalone.master.httpUrl\", \"\");",
          "1546:     }",
          "",
          "---------------"
        ],
        "core-job/src/main/java/org/apache/kylin/job/execution/AbstractExecutable.java||core-job/src/main/java/org/apache/kylin/job/execution/AbstractExecutable.java": [
          "File: core-job/src/main/java/org/apache/kylin/job/execution/AbstractExecutable.java -> core-job/src/main/java/org/apache/kylin/job/execution/AbstractExecutable.java"
        ],
        "kylin-spark-project/kylin-spark-common/src/test/java/org/apache/spark/sql/common/LocalMetadata.scala||kylin-spark-project/kylin-spark-common/src/test/java/org/apache/spark/sql/common/LocalMetadata.scala": [
          "File: kylin-spark-project/kylin-spark-common/src/test/java/org/apache/spark/sql/common/LocalMetadata.scala -> kylin-spark-project/kylin-spark-common/src/test/java/org/apache/spark/sql/common/LocalMetadata.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: package org.apache.spark.sql.common",
          "24: import org.apache.kylin.common.KylinConfig",
          "25: import org.apache.kylin.common.util.{LocalFileMetadataTestCase, TempMetadataBuilder}",
          "26: import org.scalatest.{BeforeAndAfterAll, BeforeAndAfterEach, Suite}",
          "",
          "[Removed Lines]",
          "21: import java.io.{File, IOException}",
          "23: import org.apache.commons.io.FileUtils",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/job/NSparkExecutable.java||kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/job/NSparkExecutable.java": [
          "File: kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/job/NSparkExecutable.java -> kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/job/NSparkExecutable.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "63: import org.apache.kylin.job.execution.ExecutableContext;",
          "64: import org.apache.kylin.job.execution.ExecuteResult;",
          "65: import org.apache.kylin.metadata.MetadataConstants;",
          "66: import org.apache.spark.utils.SparkVersionUtils;",
          "67: import org.slf4j.Logger;",
          "68: import org.slf4j.LoggerFactory;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "66: import org.apache.spark.deploy.SparkApplicationClient;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "83:     private static final String APP_JAR_NAME = \"__app__.jar\";",
          "85:     private volatile boolean isYarnCluster = false;",
          "87:     protected void setSparkSubmitClassName(String className) {",
          "88:         this.setParam(MetadataConstants.P_CLASS_NAME, className);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "87:     private volatile boolean isStandaloneCluster = false;",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "273:             CliCommandExecutor exec = new CliCommandExecutor();",
          "274:             exec.execute(cmd, patternedLogger, jobId);",
          "275:             updateMetaAfterOperation(config);",
          "277:             getManager().addJobInfo(getId(), getJobMetricsInfo(config));",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "280:             if (isStandaloneCluster) {",
          "281:                 SparkApplicationClient.awaitAndCheckAppState(SparkApplicationClient.STANDALONE_CLUSTER(), jobId);",
          "282:             }",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "297:                 && \"cluster\".equals(sparkConfigOverride.get(DEPLOY_MODE)) && !(this instanceof NSparkLocalStep)) {",
          "298:             this.isYarnCluster = true;",
          "299:         }",
          "300:         if (!sparkConfigOverride.containsKey(\"spark.driver.memory\")) {",
          "301:             sparkConfigOverride.put(\"spark.driver.memory\", computeStepDriverMemory() + \"m\");",
          "302:         }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "309:         if (sparkConfigOverride.get(SPARK_MASTER).toLowerCase(Locale.ROOT).startsWith(\"spark\")",
          "310:                 && \"cluster\".equals(sparkConfigOverride.get(DEPLOY_MODE)) && !(this instanceof NSparkLocalStep)) {",
          "311:             this.isStandaloneCluster = true;",
          "312:         }",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "434:     private ExecuteResult runLocalMode(String appArgs, KylinConfig config) {",
          "435:         try {",
          "436:             Class<? extends Object> appClz = ClassUtil.forName(getSparkSubmitClassName(), Object.class);",
          "438:             updateMetaAfterOperation(config);",
          "",
          "[Removed Lines]",
          "437:             appClz.getMethod(\"main\", String[].class).invoke(null, (Object) new String[] { appArgs });",
          "",
          "[Added Lines]",
          "451:             appClz.getMethod(\"main\", String[].class).invoke(null, (Object) new String[]{appArgs});",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/utils/MetaDumpUtil.java||kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/utils/MetaDumpUtil.java": [
          "File: kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/utils/MetaDumpUtil.java -> kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/utils/MetaDumpUtil.java"
        ],
        "kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/utils/RestService.java||kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/utils/RestService.java": [
          "File: kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/utils/RestService.java -> kylin-spark-project/kylin-spark-engine/src/main/java/org/apache/kylin/engine/spark/utils/RestService.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19: package org.apache.kylin.engine.spark.utils;",
          "21: import java.io.IOException;",
          "23: import org.apache.http.HttpResponse;",
          "24: import org.apache.http.client.HttpClient;",
          "25: import org.apache.http.client.methods.HttpGet;",
          "26: import org.apache.http.client.methods.HttpRequestBase;",
          "27: import org.apache.http.impl.client.DefaultHttpClient;",
          "28: import org.apache.http.params.BasicHttpParams;",
          "29: import org.apache.http.params.HttpConnectionParams;",
          "30: import org.apache.http.params.HttpParams;",
          "31: import org.apache.http.util.EntityUtils;",
          "32: import org.slf4j.Logger;",
          "33: import org.slf4j.LoggerFactory;",
          "35: public class RestService {",
          "36:     private static final Logger logger = LoggerFactory.getLogger(RestService.class);",
          "38:     private int connectionTimeout;",
          "39:     private int readTimeout;",
          "41:     public RestService(int connectionTimeout, int readTimeout) {",
          "42:         this.connectionTimeout = connectionTimeout;",
          "43:         this.readTimeout = readTimeout;",
          "45:     }",
          "47:     public String getRequest(String url) throws IOException {",
          "48:         return getRequest(url, connectionTimeout, readTimeout);",
          "49:     }",
          "52:     public String getRequest(String url, int connTimeout, int readTimeout) throws IOException {",
          "53:         HttpGet request = new HttpGet(url);",
          "54:         return execRequest(request, connTimeout, readTimeout);",
          "55:     }",
          "58:     private HttpClient getHttpClient(int connectionTimeout, int readTimeout) {",
          "59:         final HttpParams httpParams = new BasicHttpParams();",
          "60:         HttpConnectionParams.setSoTimeout(httpParams, readTimeout);",
          "61:         HttpConnectionParams.setConnectionTimeout(httpParams, connectionTimeout);",
          "63:         return new DefaultHttpClient(httpParams);",
          "64:     }",
          "66:     public String execRequest(HttpRequestBase request, int connectionTimeout, int readTimeout) throws IOException {",
          "67:         HttpClient httpClient = getHttpClient(connectionTimeout, readTimeout);",
          "68:         try {",
          "69:             HttpResponse response = httpClient.execute(request);",
          "70:             String msg = EntityUtils.toString(response.getEntity());",
          "71:             int code = response.getStatusLine().getStatusCode();",
          "72:             if (logger.isTraceEnabled()) {",
          "73:                 String displayMessage;",
          "74:                 if (msg.length() > 500) {",
          "75:                     displayMessage = msg.substring(0, 500);",
          "76:                 } else {",
          "77:                     displayMessage = msg;",
          "78:                 }",
          "79:                 logger.trace(\"Send request: {}. And receive response[{}] which length is {}, and content is {}.\", code,",
          "80:                         request.getRequestLine(), msg.length(), displayMessage);",
          "81:             }",
          "82:             if (code != 200)",
          "83:                 throw new IOException(\"Invalid http response \" + code + \" when send request: \"",
          "84:                         + request.getURI().toString() + \"\\n\" + msg);",
          "85:             return msg;",
          "86:         } catch (IOException e) {",
          "87:             logger.error(\"error when send http request:\" + request.getURI().toString(), e);",
          "88:             throw e;",
          "89:         } finally {",
          "90:             request.releaseConnection();",
          "91:         }",
          "92:     }",
          "93: }",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/spark/deploy/SparkApplicationClient.scala||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/spark/deploy/SparkApplicationClient.scala": [
          "File: kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/spark/deploy/SparkApplicationClient.scala -> kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/spark/deploy/SparkApplicationClient.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.spark.deploy",
          "20: import org.apache.spark.internal.Logging",
          "25: object SparkApplicationClient extends Logging {",
          "28:   val finalStates = Set(\"FINISHED\", \"FAILED\", \"KILLED\", \"UNKNOWN\")",
          "31:   val STANDALONE_CLUSTER: String = \"standalone_cluster\"",
          "40:   def awaitAndCheckAppState(sparkMaster: String, stepId: String): String = {",
          "41:     logInfo(s\"AwaitAndCheckAppState $stepId{} ...\")",
          "42:     sparkMaster match {",
          "43:       case STANDALONE_CLUSTER =>",
          "44:         var appState = StandaloneAppClient.getAppState(stepId)",
          "45:         while (true) {",
          "46:           logInfo(s\"$stepId state is $appState .\")",
          "47:           if (!finalStates.contains(appState)) {",
          "48:             Thread.sleep(10000)",
          "49:           }",
          "50:           appState = StandaloneAppClient.getAppState(stepId)",
          "51:         }",
          "52:         appState",
          "53:       case m => throw new UnsupportedOperationException(\"waitAndCheckAppState \" + m)",
          "54:     }",
          "55:   }",
          "56: }",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/spark/deploy/StandaloneAppClient.scala||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/spark/deploy/StandaloneAppClient.scala": [
          "File: kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/spark/deploy/StandaloneAppClient.scala -> kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/spark/deploy/StandaloneAppClient.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19: package org.apache.spark.deploy",
          "21: import org.apache.kylin.common.KylinConfig",
          "22: import org.apache.kylin.engine.spark.utils.RestService",
          "23: import org.apache.spark.internal.Logging",
          "25: import java.io.IOException",
          "26: import scala.collection.mutable",
          "27: import scala.util.parsing.json.JSON._",
          "30: object StandaloneAppClient extends Logging {",
          "32:   private val JOB_STEP_PREFIX = \"job_step_\"",
          "35:   private val cachedKylinJobMap: mutable.Map[String, (String, String, Long)] = new mutable.LinkedHashMap[String, (String, String, Long)]()",
          "37:   private var jobInfoUpdateTime = System.currentTimeMillis()",
          "38:   private val cacheTtl = 3600 * 1000 * 24 * 5",
          "39:   private val cacheMaxSize = 30000",
          "42:   private val masterUrlJson: String = KylinConfig.getInstanceFromEnv.getSparkStandaloneMasterWebUI + \"/json\"",
          "44:   private val restService: RestService = new RestService(10000, 10000)",
          "51:   def getRunningJobs: mutable.Map[String, (String, String, Long)] = cachedKylinJobMap.synchronized {",
          "52:     val currMills = System.currentTimeMillis",
          "53:     if (cachedKylinJobMap.isEmpty || currMills - jobInfoUpdateTime >= 10000) {",
          "54:       logDebug(\"Updating app status ...\")",
          "55:       try {",
          "56:         val realResp = restService.getRequest(masterUrlJson)",
          "57:         parseApplicationState(realResp)",
          "58:       } catch {",
          "59:         case ioe: IOException => logError(\"Can not connect to standalone master service.\", ioe)",
          "60:         case e: Exception => logError(\"Error .\", e)",
          "61:       }",
          "62:       jobInfoUpdateTime = currMills",
          "63:     }",
          "64:     cachedKylinJobMap",
          "65:   }",
          "67:   def getAppState(stepId: String): String = {",
          "68:     getRunningJobs",
          "70:     val doNothing: PartialFunction[(String, String, Long), (String, String, Long)] = {",
          "71:       case x => x",
          "72:     }",
          "73:     val res: Iterable[(String, String, Long)] = cachedKylinJobMap.values.filter(app => app._1.contains(stepId)).collect(doNothing)",
          "75:     res.size match {",
          "76:       case 0 => \"SUBMITTED\"",
          "77:       case 1 => res.head._2",
          "78:       case _ =>",
          "80:         res.maxBy(x => x._3)._2",
          "81:     }",
          "82:   }",
          "85:   def parseApplicationState(responseStr: String): Unit = {",
          "86:     val curr = System.currentTimeMillis()",
          "88:     var respJson = Map.empty[String, Any]",
          "89:     val tree = parseFull(responseStr)",
          "90:     respJson = tree match {",
          "91:       case Some(map: Map[String, Any]) => map",
          "92:     }",
          "93:     val app1 = respJson.getOrElse(\"completedapps\", Array())",
          "94:     val completedApps = app1.asInstanceOf[List[Map[String, Any]]]",
          "96:     for (app <- completedApps) {",
          "97:       val name: String = app.getOrElse(\"name\", \"\").asInstanceOf[String]",
          "98:       val id: String = app.getOrElse(\"id\", \"\").asInstanceOf[String]",
          "99:       val state: String = app.getOrElse(\"state\", \"\").asInstanceOf[String]",
          "100:       val startTime: Double = app.getOrElse(\"starttime\", \"0\").asInstanceOf[Double]",
          "101:       if (name.contains(JOB_STEP_PREFIX)) {",
          "102:         cachedKylinJobMap(id) = (name, state, startTime.toLong)",
          "103:       }",
          "104:     }",
          "107:     if (cachedKylinJobMap.size > cacheMaxSize) {",
          "108:       for (id <- cachedKylinJobMap.keys) {",
          "109:         val app = cachedKylinJobMap.get(id)",
          "110:         if (app.isDefined && curr - app.get._3 > cacheTtl) {",
          "111:           cachedKylinJobMap.remove(id)",
          "112:         }",
          "113:       }",
          "114:     }",
          "115:   }",
          "116: }",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-engine/src/test/resources/response/application-detail-246.html||kylin-spark-project/kylin-spark-engine/src/test/resources/response/application-detail-246.html": [
          "File: kylin-spark-project/kylin-spark-engine/src/test/resources/response/application-detail-246.html -> kylin-spark-project/kylin-spark-engine/src/test/resources/response/application-detail-246.html",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: <!DOCTYPE html>",
          "2: <html>",
          "3: <head>",
          "4:     <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\"/>",
          "5:     <link rel=\"stylesheet\" href=\"/static/bootstrap.min.css\" type=\"text/css\"/>",
          "6:     <link rel=\"stylesheet\" href=\"/static/vis-timeline-graph2d.min.css\" type=\"text/css\"/>",
          "7:     <link rel=\"stylesheet\" href=\"/static/webui.css\" type=\"text/css\"/>",
          "8:     <link rel=\"stylesheet\" href=\"/static/timeline-view.css\" type=\"text/css\"/>",
          "9:     <script src=\"/static/sorttable.js\"></script>",
          "10:     <script src=\"/static/jquery-1.12.4.min.js\"></script>",
          "11:     <script src=\"/static/vis-timeline-graph2d.min.js\"></script>",
          "12:     <script src=\"/static/bootstrap-tooltip.js\"></script>",
          "13:     <script src=\"/static/initialize-tooltips.js\"></script>",
          "14:     <script src=\"/static/table.js\"></script>",
          "15:     <script src=\"/static/additional-metrics.js\"></script>",
          "16:     <script src=\"/static/timeline-view.js\"></script>",
          "17:     <script src=\"/static/log-view.js\"></script>",
          "18:     <script src=\"/static/webui.js\"></script>",
          "19:     <script>setUIRoot('')</script>",
          "21:     <link rel=\"shortcut icon\" href=\"/static/spark-logo-77x50px-hd.png\"></link>",
          "22:     <title>Application: job_step_93338927-bbbf-4baf-8a22-b44cb701b57b-01</title>",
          "23: </head>",
          "24: <body>",
          "25: <div class=\"container-fluid\">",
          "26:     <div class=\"row-fluid\">",
          "27:         <div class=\"span12\">",
          "28:             <h3 style=\"vertical-align: middle; display: inline-block;\">",
          "29:                 <a style=\"text-decoration: none\" href=\"/\">",
          "30:                     <img src=\"/static/spark-logo-77x50px-hd.png\"/>",
          "31:                     <span class=\"version\" style=\"margin-right: 15px;\">2.4.6</span>",
          "32:                 </a>",
          "33:                 Application: job_step_93338927-bbbf-4baf-8a22-b44cb701b57b-01",
          "34:             </h3>",
          "35:         </div>",
          "36:     </div>",
          "37:     <div class=\"row-fluid\">",
          "38:         <div class=\"span12\">",
          "39:             <ul class=\"unstyled\">",
          "40:                 <li><strong>ID:</strong> app-20210701234053-0002</li>",
          "41:                 <li><strong>Name:</strong> job_step_93338927-bbbf-4baf-8a22-b44cb701b57b-01</li>",
          "42:                 <li><strong>User:</strong> root</li>",
          "43:                 <li><strong>Cores:</strong>",
          "44:                     Unlimited (4 granted)",
          "45:                 </li>",
          "46:                 <li>",
          "47:               <span data-toggle=\"tooltip\" title=\"Maximum number of executors that this application will use. This limit is finite only when",
          "48:        dynamic allocation is enabled. The number of granted executors may exceed the limit",
          "49:        ephemerally when executors are being killed.",
          "50:     \" data-placement=\"right\">",
          "51:                 <strong>Executor Limit: </strong>",
          "52:                 Unlimited",
          "53:                 (4 granted)",
          "54:               </span>",
          "55:                 </li>",
          "56:                 <li>",
          "57:                     <strong>Executor Memory:</strong>",
          "58:                     1024.0 MB",
          "59:                 </li>",
          "60:                 <li><strong>Submit Date:</strong> 2021/07/01 23:40:53</li>",
          "61:                 <li><strong>State:</strong> FINISHED</li>",
          "63:             </ul>",
          "64:         </div>",
          "65:     </div>",
          "66:     <div class=\"row-fluid\"> <!-- Executors -->",
          "67:         <div class=\"span12\">",
          "68:           <span class=\"collapse-aggregated-executors collapse-table\"",
          "69:                 onClick=\"collapseTable('collapse-aggregated-executors','aggregated-executors')\">",
          "70:             <h4>",
          "71:               <span class=\"collapse-table-arrow arrow-open\"></span>",
          "72:               <a>Executor Summary (4)</a>",
          "73:             </h4>",
          "74:           </span>",
          "75:             <div class=\"aggregated-executors collapsible-table\">",
          "76:                 <table class=\"table table-bordered table-condensed table-striped sortable\">",
          "77:                     <thead>",
          "78:                     <th width=\"\" class=\"\">ExecutorID</th>",
          "79:                     <th width=\"\" class=\"\">Worker</th>",
          "80:                     <th width=\"\" class=\"\">Cores</th>",
          "81:                     <th width=\"\" class=\"\">Memory</th>",
          "82:                     <th width=\"\" class=\"\">State</th>",
          "83:                     <th width=\"\" class=\"\">Logs</th>",
          "84:                     </thead>",
          "85:                     <tbody>",
          "87:                     </tbody>",
          "88:                 </table>",
          "89:             </div>",
          "90:             <span class=\"collapse-aggregated-removedExecutors collapse-table\" onClick=\"collapseTable('collapse-aggregated-removedExecutors',",
          "91:                   'aggregated-removedExecutors')\">",
          "92:                 <h4>",
          "93:                   <span class=\"collapse-table-arrow arrow-open\"></span>",
          "94:                   <a>Removed Executors (4)</a>",
          "95:                 </h4>",
          "96:               </span>",
          "97:             <div class=\"aggregated-removedExecutors collapsible-table\">",
          "98:                 <table class=\"table table-bordered table-condensed table-striped sortable\">",
          "99:                     <thead>",
          "100:                     <th width=\"\" class=\"\">ExecutorID</th>",
          "101:                     <th width=\"\" class=\"\">Worker</th>",
          "102:                     <th width=\"\" class=\"\">Cores</th>",
          "103:                     <th width=\"\" class=\"\">Memory</th>",
          "104:                     <th width=\"\" class=\"\">State</th>",
          "105:                     <th width=\"\" class=\"\">Logs</th>",
          "106:                     </thead>",
          "107:                     <tbody>",
          "108:                     <tr>",
          "109:                         <td>2</td>",
          "110:                         <td>",
          "111:                             <a href=\"http://10.1.3.90:10041\">worker-20210630172110-10.1.3.90-10040</a>",
          "112:                         </td>",
          "113:                         <td>1</td>",
          "114:                         <td>1024</td>",
          "115:                         <td>KILLED</td>",
          "116:                         <td>",
          "117:                             <a href=\"http://10.1.3.90:10041/logPage?appId=app-20210701234053-0002&amp;executorId=2&amp;logType=stdout\">stdout</a>",
          "118:                             <a href=\"http://10.1.3.90:10041/logPage?appId=app-20210701234053-0002&amp;executorId=2&amp;logType=stderr\">stderr</a>",
          "119:                         </td>",
          "120:                     </tr>",
          "121:                     <tr>",
          "122:                         <td>1</td>",
          "123:                         <td>",
          "124:                             <a href=\"http://10.1.3.90:10041\">worker-20210630172110-10.1.3.90-10040</a>",
          "125:                         </td>",
          "126:                         <td>1</td>",
          "127:                         <td>1024</td>",
          "128:                         <td>KILLED</td>",
          "129:                         <td>",
          "130:                             <a href=\"http://10.1.3.90:10041/logPage?appId=app-20210701234053-0002&amp;executorId=1&amp;logType=stdout\">stdout</a>",
          "131:                             <a href=\"http://10.1.3.90:10041/logPage?appId=app-20210701234053-0002&amp;executorId=1&amp;logType=stderr\">stderr</a>",
          "132:                         </td>",
          "133:                     </tr>",
          "134:                     <tr>",
          "135:                         <td>3</td>",
          "136:                         <td>",
          "137:                             <a href=\"http://10.1.3.90:10041\">worker-20210630172110-10.1.3.90-10040</a>",
          "138:                         </td>",
          "139:                         <td>1</td>",
          "140:                         <td>1024</td>",
          "141:                         <td>KILLED</td>",
          "142:                         <td>",
          "143:                             <a href=\"http://10.1.3.90:10041/logPage?appId=app-20210701234053-0002&amp;executorId=3&amp;logType=stdout\">stdout</a>",
          "144:                             <a href=\"http://10.1.3.90:10041/logPage?appId=app-20210701234053-0002&amp;executorId=3&amp;logType=stderr\">stderr</a>",
          "145:                         </td>",
          "146:                     </tr>",
          "147:                     <tr>",
          "148:                         <td>0</td>",
          "149:                         <td>",
          "150:                             <a href=\"http://10.1.3.90:10041\">worker-20210630172110-10.1.3.90-10040</a>",
          "151:                         </td>",
          "152:                         <td>1</td>",
          "153:                         <td>1024</td>",
          "154:                         <td>KILLED</td>",
          "155:                         <td>",
          "156:                             <a href=\"http://10.1.3.90:10041/logPage?appId=app-20210701234053-0002&amp;executorId=0&amp;logType=stdout\">stdout</a>",
          "157:                             <a href=\"http://10.1.3.90:10041/logPage?appId=app-20210701234053-0002&amp;executorId=0&amp;logType=stderr\">stderr</a>",
          "158:                         </td>",
          "159:                     </tr>",
          "160:                     </tbody>",
          "161:                 </table>",
          "162:             </div>",
          "163:         </div>",
          "164:     </div>",
          "165: </div>",
          "166: </body>",
          "167: </html>",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-engine/src/test/scala/org/apache/spark/deploy/StandaloneAppClientTest.scala||kylin-spark-project/kylin-spark-engine/src/test/scala/org/apache/spark/deploy/StandaloneAppClientTest.scala": [
          "File: kylin-spark-project/kylin-spark-engine/src/test/scala/org/apache/spark/deploy/StandaloneAppClientTest.scala -> kylin-spark-project/kylin-spark-engine/src/test/scala/org/apache/spark/deploy/StandaloneAppClientTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: package org.apache.spark.deploy",
          "3: import org.apache.commons.io.IOUtils",
          "4: import org.apache.spark.sql.common.{LocalMetadata, SparderBaseFunSuite}",
          "6: import java.io.{InputStream, StringWriter}",
          "8: class StandaloneAppClientTest extends SparderBaseFunSuite with LocalMetadata {",
          "10:   test(\"Test find state function from HTML and JSON response.\") {",
          "11:     val htmlFile = getClass.getClassLoader.getResourceAsStream(\"response/application-detail-246.html\")",
          "12:     val jsonFile = getClass.getClassLoader.getResourceAsStream(\"response/standalone-master-246.json\")",
          "14:     def readF(f: InputStream): String = {",
          "15:       val writer = new StringWriter()",
          "16:       IOUtils.copy(f, writer, \"UTF-8\")",
          "17:       f.close()",
          "18:       writer.toString",
          "19:     }",
          "21:     val htmlStr = readF(htmlFile)",
          "22:     val jsonStr = readF(jsonFile)",
          "25:     StandaloneAppClient.parseApplicationState(jsonStr)",
          "26:     val res = StandaloneAppClient.getRunningJobs",
          "27:     val state = StandaloneAppClient.getAppState(\"6eb0d430-2882-4699-9915-1154959c2cd8\")",
          "28:     assert(\"FINISHED\".equals(state))",
          "30:     assert(res.size == 3)",
          "31:     assert(res.contains(\"app-20210701232026-0001\"))",
          "32:     assert(\"FINISHED\".equals(res.getOrElse(\"app-20210701232026-0001\", (\"\", \"\", 1L))._2))",
          "33:   }",
          "34: }",
          "",
          "---------------"
        ]
      }
    }
  ]
}