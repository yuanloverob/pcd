{
  "cve_id": "CVE-2021-45229",
  "cve_desc": "It was discovered that the \"Trigger DAG with config\" screen was susceptible to XSS attacks via the `origin` query argument. This issue affects Apache Airflow versions 2.2.3 and below.",
  "repo": "apache/airflow",
  "patch_hash": "628aa1f99c865d97d0b1c7c76e630e43a7b8d319",
  "patch_info": {
    "commit_hash": "628aa1f99c865d97d0b1c7c76e630e43a7b8d319",
    "repo": "apache/airflow",
    "commit_url": "https://github.com/apache/airflow/commit/628aa1f99c865d97d0b1c7c76e630e43a7b8d319",
    "files": [
      "airflow/www/templates/airflow/trigger.html",
      "tests/www/views/test_views_trigger_dag.py"
    ],
    "message": "Simplify trigger cancel button (#21591)\n\nCo-authored-by: Jed Cunningham <jedcunningham@apache.org>\n(cherry picked from commit 65297673a318660fba76797e50d0c06804dfcafc)",
    "before_after_code_files": [
      "airflow/www/templates/airflow/trigger.html||airflow/www/templates/airflow/trigger.html",
      "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py"
    ]
  },
  "patch_diff": {
    "airflow/www/templates/airflow/trigger.html||airflow/www/templates/airflow/trigger.html": [
      "File: airflow/www/templates/airflow/trigger.html -> airflow/www/templates/airflow/trigger.html",
      "--- Hunk 1 ---",
      "[Context before]",
      "63:       </label>",
      "64:     </div>",
      "65:     <button type=\"submit\" class=\"btn btn-primary\">Trigger</button>",
      "67:   </form>",
      "68: {% endblock %}",
      "",
      "[Removed Lines]",
      "66:     <button type=\"button\" class=\"btn\" onclick=\"location.href = '{{ origin }}'; return false\">Cancel</button>",
      "",
      "[Added Lines]",
      "66:     <a class=\"btn\" href=\"{{ origin }}\">Cancel</a>",
      "",
      "---------------"
    ],
    "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py": [
      "File: tests/www/views/test_views_trigger_dag.py -> tests/www/views/test_views_trigger_dag.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "133:         (\"javascript:alert(1)\", \"/home\"),",
      "134:         (\"http://google.com\", \"/home\"),",
      "135:         (\"36539'%3balert(1)%2f%2f166\", \"/home\"),",
      "136:         (",
      "137:             \"%2Ftree%3Fdag_id%3Dexample_bash_operator';alert(33)//\",",
      "138:             \"/home\",",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "136:         (",
      "137:             '\"><script>alert(99)</script><a href=\"',",
      "138:             \"&#34;&gt;&lt;script&gt;alert(99)&lt;/script&gt;&lt;a href=&#34;\",",
      "139:         ),",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "145:     test_dag_id = \"example_bash_operator\"",
      "147:     resp = admin_client.get(f'trigger?dag_id={test_dag_id}&origin={test_origin}')",
      "156: @pytest.mark.parametrize(",
      "",
      "[Removed Lines]",
      "148:     check_content_in_response(",
      "149:         '<button type=\"button\" class=\"btn\" onclick=\"location.href = \\'{}\\'; return false\">'.format(",
      "150:             expected_origin",
      "151:         ),",
      "152:         resp,",
      "153:     )",
      "",
      "[Added Lines]",
      "152:     check_content_in_response(f'<a class=\"btn\" href=\"{expected_origin}\">Cancel</a>', resp)",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "a25d7cef7f10be25b2446abe641c0b5822e9d9dc",
      "candidate_info": {
        "commit_hash": "a25d7cef7f10be25b2446abe641c0b5822e9d9dc",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/a25d7cef7f10be25b2446abe641c0b5822e9d9dc",
        "files": [
          "airflow/models/taskinstance.py",
          "airflow/operators/datetime.py",
          "airflow/operators/python.py",
          "airflow/operators/weekday.py",
          "airflow/providers/http/operators/http.py",
          "airflow/providers/http/sensors/http.py",
          "airflow/sensors/external_task.py",
          "airflow/sensors/weekday.py",
          "airflow/utils/context.py",
          "airflow/utils/context.pyi",
          "airflow/utils/helpers.py",
          "airflow/utils/log/task_handler_with_custom_formatter.py",
          "airflow/utils/operator_helpers.py",
          "scripts/ci/kubernetes/ci_run_kubernetes_tests.sh",
          "scripts/in_container/entrypoint_ci.sh",
          "tests/cli/commands/test_task_command.py",
          "tests/core/test_core.py",
          "tests/operators/test_email.py",
          "tests/operators/test_python.py",
          "tests/operators/test_trigger_dagrun.py",
          "tests/providers/http/sensors/test_http.py",
          "tests/sensors/test_external_task_sensor.py",
          "tests/utils/test_log_handlers.py"
        ],
        "message": "Un-ignore DeprecationWarning (#20322)\n\n(cherry picked from commit 9876e19273cd56dc53d3a4e287db43acbfa65c4b)",
        "before_after_code_files": [
          "airflow/models/taskinstance.py||airflow/models/taskinstance.py",
          "airflow/operators/datetime.py||airflow/operators/datetime.py",
          "airflow/operators/python.py||airflow/operators/python.py",
          "airflow/operators/weekday.py||airflow/operators/weekday.py",
          "airflow/providers/http/operators/http.py||airflow/providers/http/operators/http.py",
          "airflow/providers/http/sensors/http.py||airflow/providers/http/sensors/http.py",
          "airflow/sensors/external_task.py||airflow/sensors/external_task.py",
          "airflow/sensors/weekday.py||airflow/sensors/weekday.py",
          "airflow/utils/context.py||airflow/utils/context.py",
          "airflow/utils/context.pyi||airflow/utils/context.pyi",
          "airflow/utils/helpers.py||airflow/utils/helpers.py",
          "airflow/utils/log/task_handler_with_custom_formatter.py||airflow/utils/log/task_handler_with_custom_formatter.py",
          "airflow/utils/operator_helpers.py||airflow/utils/operator_helpers.py",
          "scripts/ci/kubernetes/ci_run_kubernetes_tests.sh||scripts/ci/kubernetes/ci_run_kubernetes_tests.sh",
          "scripts/in_container/entrypoint_ci.sh||scripts/in_container/entrypoint_ci.sh",
          "tests/cli/commands/test_task_command.py||tests/cli/commands/test_task_command.py",
          "tests/core/test_core.py||tests/core/test_core.py",
          "tests/operators/test_email.py||tests/operators/test_email.py",
          "tests/operators/test_python.py||tests/operators/test_python.py",
          "tests/operators/test_trigger_dagrun.py||tests/operators/test_trigger_dagrun.py",
          "tests/providers/http/sensors/test_http.py||tests/providers/http/sensors/test_http.py",
          "tests/sensors/test_external_task_sensor.py||tests/sensors/test_external_task_sensor.py",
          "tests/utils/test_log_handlers.py||tests/utils/test_log_handlers.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/models/taskinstance.py||airflow/models/taskinstance.py": [
          "File: airflow/models/taskinstance.py -> airflow/models/taskinstance.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "86: from airflow.utils import timezone",
          "87: from airflow.utils.context import ConnectionAccessor, Context, VariableAccessor",
          "88: from airflow.utils.email import send_email",
          "90: from airflow.utils.log.logging_mixin import LoggingMixin",
          "91: from airflow.utils.net import get_hostname",
          "92: from airflow.utils.operator_helpers import context_to_airflow_vars",
          "",
          "[Removed Lines]",
          "89: from airflow.utils.helpers import is_container",
          "",
          "[Added Lines]",
          "89: from airflow.utils.helpers import is_container, render_template_to_string",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "2016:         sanitized_pod = ApiClient().sanitize_for_serialization(pod)",
          "2017:         return sanitized_pod",
          "2020:         \"\"\"Get the email subject content for exceptions.\"\"\"",
          "2021:         # For a ti from DB (without ti.task), return the default value",
          "2022:         # Reuse it for smart sensor to send default email alert",
          "",
          "[Removed Lines]",
          "2019:     def get_email_subject_content(self, exception):",
          "",
          "[Added Lines]",
          "2019:     def get_email_subject_content(self, exception: BaseException) -> Tuple[str, str, str]:",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "2043:             'Mark success: <a href=\"{{ti.mark_success_url}}\">Link</a><br>'",
          "2044:         )",
          "2046:         if use_default:",
          "2058:             jinja_env = jinja2.Environment(",
          "2059:                 loader=jinja2.FileSystemLoader(os.path.dirname(__file__)), autoescape=True",
          "2060:             )",
          "",
          "[Removed Lines]",
          "2047:             jinja_context = {'ti': self}",
          "2048:             # This function is called after changing the state",
          "2049:             # from State.RUNNING so need to subtract 1 from self.try_number.",
          "2050:             jinja_context.update(",
          "2051:                 dict(",
          "2052:                     exception=exception,",
          "2053:                     exception_html=exception_html,",
          "2054:                     try_number=self.try_number - 1,",
          "2055:                     max_tries=self.max_tries,",
          "2056:                 )",
          "2057:             )",
          "",
          "[Added Lines]",
          "2046:         # This function is called after changing the state from State.RUNNING,",
          "2047:         # so we need to subtract 1 from self.try_number here.",
          "2048:         current_try_number = self.try_number - 1",
          "2049:         additional_context = {",
          "2050:             \"exception\": exception,",
          "2051:             \"exception_html\": exception_html,",
          "2052:             \"try_number\": current_try_number,",
          "2053:             \"max_tries\": self.max_tries,",
          "2054:         }",
          "2057:             jinja_context = {\"ti\": self, **additional_context}",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "2065:         else:",
          "2066:             jinja_context = self.get_template_context()",
          "2077:             jinja_env = self.task.get_template_env()",
          "2080:                 if conf.has_option('email', key):",
          "2081:                     path = conf.get('email', key)",
          "2082:                     with open(path) as f:",
          "2083:                         content = f.read()",
          "2086:             subject = render('subject_template', default_subject)",
          "2087:             html_content = render('html_content_template', default_html_content)",
          "",
          "[Removed Lines]",
          "2068:             jinja_context.update(",
          "2069:                 dict(",
          "2070:                     exception=exception,",
          "2071:                     exception_html=exception_html,",
          "2072:                     try_number=self.try_number - 1,",
          "2073:                     max_tries=self.max_tries,",
          "2074:                 )",
          "2075:             )",
          "2079:             def render(key, content):",
          "2084:                 return jinja_env.from_string(content).render(**jinja_context)",
          "",
          "[Added Lines]",
          "2067:             jinja_context.update(additional_context)",
          "2070:             def render(key: str, content: str) -> str:",
          "2075:                 return render_template_to_string(jinja_env.from_string(content), jinja_context)",
          "",
          "---------------"
        ],
        "airflow/operators/datetime.py||airflow/operators/datetime.py": [
          "File: airflow/operators/datetime.py -> airflow/operators/datetime.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "73:     def choose_branch(self, context: Dict) -> Union[str, Iterable[str]]:",
          "74:         if self.use_task_execution_date is True:",
          "76:         else:",
          "77:             now = timezone.make_naive(timezone.utcnow(), self.dag.timezone)",
          "",
          "[Removed Lines]",
          "75:             now = timezone.make_naive(context[\"execution_date\"], self.dag.timezone)",
          "",
          "[Added Lines]",
          "75:             now = timezone.make_naive(context[\"logical_date\"], self.dag.timezone)",
          "",
          "---------------"
        ],
        "airflow/operators/python.py||airflow/operators/python.py": [
          "File: airflow/operators/python.py -> airflow/operators/python.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "24: import warnings",
          "25: from tempfile import TemporaryDirectory",
          "26: from textwrap import dedent",
          "29: import dill",
          "",
          "[Removed Lines]",
          "27: from typing import Callable, Dict, Iterable, List, Optional, Union",
          "",
          "[Added Lines]",
          "27: from typing import Any, Callable, Collection, Dict, Iterable, List, Mapping, Optional, Union",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "33: from airflow.models.skipmixin import SkipMixin",
          "34: from airflow.models.taskinstance import _CURRENT_CONTEXT",
          "35: from airflow.utils.context import Context",
          "37: from airflow.utils.process_utils import execute_in_subprocess",
          "38: from airflow.utils.python_virtualenv import prepare_virtualenv, write_python_script",
          "",
          "[Removed Lines]",
          "36: from airflow.utils.operator_helpers import determine_kwargs",
          "",
          "[Added Lines]",
          "36: from airflow.utils.operator_helpers import KeywordParameters",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "142:         self,",
          "144:         python_callable: Callable,",
          "147:         templates_dict: Optional[Dict] = None,",
          "148:         templates_exts: Optional[List[str]] = None,",
          "",
          "[Removed Lines]",
          "145:         op_args: Optional[List] = None,",
          "146:         op_kwargs: Optional[Dict] = None,",
          "",
          "[Added Lines]",
          "145:         op_args: Optional[Collection[Any]] = None,",
          "146:         op_kwargs: Optional[Mapping[str, Any]] = None,",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "159:         if not callable(python_callable):",
          "160:             raise AirflowException('`python_callable` param must be callable')",
          "161:         self.python_callable = python_callable",
          "163:         self.op_kwargs = op_kwargs or {}",
          "164:         self.templates_dict = templates_dict",
          "165:         if templates_exts:",
          "",
          "[Removed Lines]",
          "162:         self.op_args = op_args or []",
          "",
          "[Added Lines]",
          "162:         self.op_args = op_args or ()",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "169:         context.update(self.op_kwargs)",
          "170:         context['templates_dict'] = self.templates_dict",
          "174:         return_value = self.execute_callable()",
          "175:         self.log.info(\"Done. Returned value was: %s\", return_value)",
          "176:         return return_value",
          "178:     def execute_callable(self):",
          "179:         \"\"\"",
          "180:         Calls the python callable with the given arguments.",
          "",
          "[Removed Lines]",
          "172:         self.op_kwargs = determine_kwargs(self.python_callable, self.op_args, context)",
          "",
          "[Added Lines]",
          "172:         self.op_kwargs = self.determine_kwargs(context)",
          "178:     def determine_kwargs(self, context: Mapping[str, Any]) -> Mapping[str, Any]:",
          "179:         return KeywordParameters.determine(self.python_callable, self.op_args, context).unpacking()",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "242:         self.log.info('Skipping downstream tasks...')",
          "245:         self.log.debug(\"Downstream task_ids %s\", downstream_tasks)",
          "247:         if downstream_tasks:",
          "250:         self.log.info(\"Done.\")",
          "",
          "[Removed Lines]",
          "244:         downstream_tasks = context['task'].get_flat_relatives(upstream=False)",
          "248:             self.skip(context['dag_run'], context['ti'].execution_date, downstream_tasks)",
          "",
          "[Added Lines]",
          "247:         downstream_tasks = context[\"task\"].get_flat_relatives(upstream=False)",
          "251:             self.skip(context[\"dag_run\"], context[\"logical_date\"], downstream_tasks)",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "345:         python_version: Optional[Union[str, int, float]] = None,",
          "346:         use_dill: bool = False,",
          "347:         system_site_packages: bool = True,",
          "350:         string_args: Optional[Iterable[str]] = None,",
          "351:         templates_dict: Optional[Dict] = None,",
          "352:         templates_exts: Optional[List[str]] = None,",
          "",
          "[Removed Lines]",
          "348:         op_args: Optional[List] = None,",
          "349:         op_kwargs: Optional[Dict] = None,",
          "",
          "[Added Lines]",
          "351:         op_args: Optional[Collection[Any]] = None,",
          "352:         op_kwargs: Optional[Mapping[str, Any]] = None,",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "392:         serializable_context = context.copy_only(serializable_keys)",
          "393:         return super().execute(context=serializable_context)",
          "395:     def execute_callable(self):",
          "396:         with TemporaryDirectory(prefix='venv') as tmp_dir:",
          "397:             if self.templates_dict:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "398:     def determine_kwargs(self, context: Mapping[str, Any]) -> Mapping[str, Any]:",
          "399:         return KeywordParameters.determine(self.python_callable, self.op_args, context).serializing()",
          "",
          "---------------"
        ],
        "airflow/operators/weekday.py||airflow/operators/weekday.py": [
          "File: airflow/operators/weekday.py -> airflow/operators/weekday.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "68:     def choose_branch(self, context: Dict) -> Union[str, Iterable[str]]:",
          "69:         if self.use_task_execution_day:",
          "71:         else:",
          "72:             now = timezone.make_naive(timezone.utcnow(), self.dag.timezone)",
          "",
          "[Removed Lines]",
          "70:             now = context[\"execution_date\"]",
          "",
          "[Added Lines]",
          "70:             now = context[\"logical_date\"]",
          "",
          "---------------"
        ],
        "airflow/providers/http/operators/http.py||airflow/providers/http/operators/http.py": [
          "File: airflow/providers/http/operators/http.py -> airflow/providers/http/operators/http.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "104:             raise AirflowException(\"'xcom_push' was deprecated, use 'BaseOperator.do_xcom_push' instead\")",
          "106:     def execute(self, context: Dict[str, Any]) -> Any:",
          "109:         http = HttpHook(self.method, http_conn_id=self.http_conn_id, auth_type=self.auth_type)",
          "",
          "[Removed Lines]",
          "107:         from airflow.utils.operator_helpers import make_kwargs_callable",
          "",
          "[Added Lines]",
          "107:         from airflow.utils.operator_helpers import determine_kwargs",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "114:         if self.log_response:",
          "115:             self.log.info(response.text)",
          "116:         if self.response_check:",
          "119:                 raise AirflowException(\"Response check returned False.\")",
          "120:         if self.response_filter:",
          "123:         return response.text",
          "",
          "[Removed Lines]",
          "117:             kwargs_callable = make_kwargs_callable(self.response_check)",
          "118:             if not kwargs_callable(response, **context):",
          "121:             kwargs_callable = make_kwargs_callable(self.response_filter)",
          "122:             return kwargs_callable(response, **context)",
          "",
          "[Added Lines]",
          "117:             kwargs = determine_kwargs(self.response_check, [response], context)",
          "118:             if not self.response_check(response, **kwargs):",
          "121:             kwargs = determine_kwargs(self.response_filter, [response], context)",
          "122:             return self.response_filter(response, **kwargs)",
          "",
          "---------------"
        ],
        "airflow/providers/http/sensors/http.py||airflow/providers/http/sensors/http.py": [
          "File: airflow/providers/http/sensors/http.py -> airflow/providers/http/sensors/http.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "96:         self.hook = HttpHook(method=method, http_conn_id=http_conn_id)",
          "98:     def poke(self, context: Dict[Any, Any]) -> bool:",
          "101:         self.log.info('Poking: %s', self.endpoint)",
          "102:         try:",
          "",
          "[Removed Lines]",
          "99:         from airflow.utils.operator_helpers import make_kwargs_callable",
          "",
          "[Added Lines]",
          "99:         from airflow.utils.operator_helpers import determine_kwargs",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "107:                 extra_options=self.extra_options,",
          "108:             )",
          "109:             if self.response_check:",
          "113:         except AirflowException as exc:",
          "114:             if str(exc).startswith(\"404\"):",
          "115:                 return False",
          "",
          "[Removed Lines]",
          "110:                 kwargs_callable = make_kwargs_callable(self.response_check)",
          "111:                 return kwargs_callable(response, **context)",
          "",
          "[Added Lines]",
          "110:                 kwargs = determine_kwargs(self.response_check, [response], context)",
          "111:                 return self.response_check(response, **kwargs)",
          "",
          "---------------"
        ],
        "airflow/sensors/external_task.py||airflow/sensors/external_task.py": [
          "File: airflow/sensors/external_task.py -> airflow/sensors/external_task.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "47: class ExternalTaskSensor(BaseSensorOperator):",
          "48:     \"\"\"",
          "49:     Waits for a different DAG or a task in a different DAG to complete for a",
          "52:     :param external_dag_id: The dag_id that contains the task you want to",
          "53:         wait for",
          "",
          "[Removed Lines]",
          "50:     specific execution_date",
          "",
          "[Added Lines]",
          "50:     specific logical date.",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "65:     :param failed_states: Iterable of failed or dis-allowed states, default is ``None``",
          "66:     :type failed_states: Iterable",
          "67:     :param execution_delta: time difference with the previous execution to",
          "69:         For yesterday, use [positive!] datetime.timedelta(days=1). Either",
          "70:         execution_delta or execution_date_fn can be passed to",
          "71:         ExternalTaskSensor, but not both.",
          "72:     :type execution_delta: Optional[datetime.timedelta]",
          "74:         positional argument and optionally any number of keyword arguments available in the",
          "76:         Either execution_delta or execution_date_fn can be passed to ExternalTaskSensor,",
          "77:         but not both.",
          "78:     :type execution_date_fn: Optional[Callable]",
          "",
          "[Removed Lines]",
          "68:         look at, the default is the same execution_date as the current task or DAG.",
          "73:     :param execution_date_fn: function that receives the current execution date as the first",
          "75:         context dictionary, and returns the desired execution dates to query.",
          "",
          "[Added Lines]",
          "68:         look at, the default is the same logical date as the current task or DAG.",
          "73:     :param execution_date_fn: function that receives the current execution's logical date as the first",
          "75:         context dictionary, and returns the desired logical dates to query.",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "157:     @provide_session",
          "158:     def poke(self, context, session=None):",
          "159:         if self.execution_delta:",
          "161:         elif self.execution_date_fn:",
          "162:             dttm = self._handle_execution_date_fn(context=context)",
          "163:         else:",
          "166:         dttm_filter = dttm if isinstance(dttm, list) else [dttm]",
          "167:         serialized_dttm_filter = ','.join(dt.isoformat() for dt in dttm_filter)",
          "",
          "[Removed Lines]",
          "160:             dttm = context['execution_date'] - self.execution_delta",
          "164:             dttm = context['execution_date']",
          "",
          "[Added Lines]",
          "160:             dttm = context['logical_date'] - self.execution_delta",
          "164:             dttm = context['logical_date']",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "260:         \"\"\"",
          "261:         from airflow.utils.operator_helpers import make_kwargs_callable",
          "266:         # Add \"context\" in the kwargs for backward compatibility (because context used to be",
          "267:         # an acceptable argument of execution_date_fn)",
          "268:         kwargs[\"context\"] = context",
          "269:         kwargs_callable = make_kwargs_callable(self.execution_date_fn)",
          "273: class ExternalTaskMarker(DummyOperator):",
          "",
          "[Removed Lines]",
          "263:         # Remove \"execution_date\" because it is already a mandatory positional argument",
          "264:         execution_date = context[\"execution_date\"]",
          "265:         kwargs = {k: v for k, v in context.items() if k != \"execution_date\"}",
          "270:         return kwargs_callable(execution_date, **kwargs)",
          "",
          "[Added Lines]",
          "263:         # Remove \"logical_date\" because it is already a mandatory positional argument",
          "264:         logical_date = context[\"logical_date\"]",
          "265:         kwargs = {k: v for k, v in context.items() if k not in {\"execution_date\", \"logical_date\"}}",
          "270:         return kwargs_callable(logical_date, **kwargs)",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "281:     :type external_dag_id: str",
          "282:     :param external_task_id: The task_id of the dependent task that needs to be cleared.",
          "283:     :type external_task_id: str",
          "285:     :type execution_date: str or datetime.datetime",
          "286:     :param recursion_depth: The maximum level of transitive dependencies allowed. Default is 10.",
          "287:         This is mostly used for preventing cyclic dependencies. It is fine to increase",
          "",
          "[Removed Lines]",
          "284:     :param execution_date: The execution_date of the dependent task that needs to be cleared.",
          "",
          "[Added Lines]",
          "284:     :param execution_date: The logical date of the dependent task execution that needs to be cleared.",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "301:         external_dag_id: str,",
          "302:         external_task_id: str,",
          "304:         recursion_depth: int = 10,",
          "306:     ):",
          "",
          "[Removed Lines]",
          "303:         execution_date: Optional[Union[str, datetime.datetime]] = \"{{ execution_date.isoformat() }}\",",
          "",
          "[Added Lines]",
          "303:         execution_date: Optional[Union[str, datetime.datetime]] = \"{{ logical_date.isoformat() }}\",",
          "",
          "---------------"
        ],
        "airflow/sensors/weekday.py||airflow/sensors/weekday.py": [
          "File: airflow/sensors/weekday.py -> airflow/sensors/weekday.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "84:             WeekDay(timezone.utcnow().isoweekday()).name,",
          "85:         )",
          "86:         if self.use_task_execution_day:",
          "88:         else:",
          "89:             return timezone.utcnow().isoweekday() in self._week_day_num",
          "",
          "[Removed Lines]",
          "87:             return context['execution_date'].isoweekday() in self._week_day_num",
          "",
          "[Added Lines]",
          "87:             return context['logical_date'].isoweekday() in self._week_day_num",
          "",
          "---------------"
        ],
        "airflow/utils/context.py||airflow/utils/context.py": [
          "File: airflow/utils/context.py -> airflow/utils/context.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: import contextlib",
          "22: import copy",
          "23: import warnings",
          "24: from typing import (",
          "25:     AbstractSet,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "23: import functools",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "28:     Dict,",
          "29:     Iterator,",
          "30:     List,",
          "31:     MutableMapping,",
          "32:     Optional,",
          "33:     Tuple,",
          "34:     ValuesView,",
          "35: )",
          "37: _NOT_SET: Any = object()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "32:     Mapping,",
          "39: import lazy_object_proxy",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "194:         new = type(self)({k: v for k, v in self._context.items() if k in keys})",
          "195:         new._deprecation_replacements = self._deprecation_replacements.copy()",
          "196:         return new",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "203: def lazy_mapping_from_context(source: Context) -> Mapping[str, Any]:",
          "204:     \"\"\"Create a mapping that wraps deprecated entries in a lazy object proxy.",
          "206:     This further delays deprecation warning to until when the entry is actually",
          "207:     used, instead of when it's accessed in the context. The result is useful for",
          "208:     passing into a callable with ``**kwargs``, which would unpack the mapping",
          "209:     too eagerly otherwise.",
          "211:     This is implemented as a free function because the ``Context`` type is",
          "212:     \"faked\" as a ``TypedDict`` in ``context.pyi``, which cannot have custom",
          "213:     functions.",
          "215:     :meta private:",
          "216:     \"\"\"",
          "218:     def _deprecated_proxy_factory(k: str, v: Any) -> Any:",
          "219:         replacements = source._deprecation_replacements[k]",
          "220:         warnings.warn(_create_deprecation_warning(k, replacements))",
          "221:         return v",
          "223:     def _create_value(k: str, v: Any) -> Any:",
          "224:         if k not in source._deprecation_replacements:",
          "225:             return v",
          "226:         factory = functools.partial(_deprecated_proxy_factory, k, v)",
          "227:         return lazy_object_proxy.Proxy(factory)",
          "229:     return {k: _create_value(k, v) for k, v in source._context.items()}",
          "",
          "---------------"
        ],
        "airflow/utils/context.pyi||airflow/utils/context.pyi": [
          "File: airflow/utils/context.pyi -> airflow/utils/context.pyi",
          "--- Hunk 1 ---",
          "[Context before]",
          "25: # undefined attribute errors from Mypy. Hopefully there will be a mechanism to",
          "26: # declare \"these are defined, but don't error if others are accessed\" someday.",
          "30: from pendulum import DateTime",
          "",
          "[Removed Lines]",
          "28: from typing import Any, Optional",
          "",
          "[Added Lines]",
          "28: from typing import Any, Mapping, Optional",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "80:     var: _VariableAccessors",
          "81:     yesterday_ds: str",
          "82:     yesterday_ds_nodash: str",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "84: class AirflowContextDeprecationWarning(DeprecationWarning): ...",
          "86: def lazy_mapping_from_context(source: Context) -> Mapping[str, Any]: ...",
          "",
          "---------------"
        ],
        "airflow/utils/helpers.py||airflow/utils/helpers.py": [
          "File: airflow/utils/helpers.py -> airflow/utils/helpers.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "167:     if filename_jinja_template:",
          "168:         jinja_context = ti.get_template_context()",
          "169:         jinja_context['try_number'] = try_number",
          "172:     return filename_template.format(",
          "173:         dag_id=ti.dag_id,",
          "",
          "[Removed Lines]",
          "170:         return filename_jinja_template.render(**jinja_context)",
          "",
          "[Added Lines]",
          "170:         return render_template_to_string(filename_jinja_template, jinja_context)",
          "",
          "---------------"
        ],
        "airflow/utils/log/task_handler_with_custom_formatter.py||airflow/utils/log/task_handler_with_custom_formatter.py": [
          "File: airflow/utils/log/task_handler_with_custom_formatter.py -> airflow/utils/log/task_handler_with_custom_formatter.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: from logging import StreamHandler",
          "22: from airflow.configuration import conf",
          "26: class TaskHandlerWithCustomFormatter(StreamHandler):",
          "",
          "[Removed Lines]",
          "23: from airflow.utils.helpers import parse_template_string",
          "",
          "[Added Lines]",
          "23: from airflow.utils.helpers import parse_template_string, render_template_to_string",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "52:     def _render_prefix(self, ti):",
          "53:         if self.prefix_jinja_template:",
          "54:             jinja_context = ti.get_template_context()",
          "56:         logging.warning(\"'task_log_prefix_template' is in invalid format, ignoring the variable value\")",
          "57:         return \"\"",
          "",
          "[Removed Lines]",
          "55:             return self.prefix_jinja_template.render(**jinja_context)",
          "",
          "[Added Lines]",
          "55:             return render_template_to_string(self.prefix_jinja_template, jinja_context)",
          "",
          "---------------"
        ],
        "airflow/utils/operator_helpers.py||airflow/utils/operator_helpers.py": [
          "File: airflow/utils/operator_helpers.py -> airflow/utils/operator_helpers.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: # under the License.",
          "18: #",
          "19: from datetime import datetime",
          "22: AIRFLOW_VAR_NAME_FORMAT_MAPPING = {",
          "23:     'AIRFLOW_CONTEXT_DAG_ID': {'default': 'airflow.ctx.dag_id', 'env_var_format': 'AIRFLOW_CTX_DAG_ID'},",
          "",
          "[Removed Lines]",
          "20: from typing import Callable, Dict, List, Mapping, Tuple, Union",
          "",
          "[Added Lines]",
          "20: from typing import Any, Callable, Collection, Mapping",
          "22: from airflow.utils.context import Context, lazy_mapping_from_context",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "88:     return params",
          "92:     \"\"\"",
          "93:     Inspect the signature of a given callable to determine which arguments in kwargs need",
          "94:     to be passed to the callable.",
          "",
          "[Removed Lines]",
          "91: def determine_kwargs(func: Callable, args: Union[Tuple, List], kwargs: Mapping) -> Dict:",
          "",
          "[Added Lines]",
          "93: class KeywordParameters:",
          "94:     \"\"\"Wrapper representing ``**kwargs`` to a callable.",
          "96:     The actual ``kwargs`` can be obtained by calling either ``unpacking()`` or",
          "97:     ``serializing()``. They behave almost the same and are only different if",
          "98:     the containing ``kwargs`` is an Airflow Context object, and the calling",
          "99:     function uses ``**kwargs`` in the argument list.",
          "101:     In this particular case, ``unpacking()`` uses ``lazy-object-proxy`` to",
          "102:     prevent the Context from emitting deprecation warnings too eagerly when it's",
          "103:     unpacked by ``**``. ``serializing()`` does not do this, and will allow the",
          "104:     warnings to be emitted eagerly, which is useful when you want to dump the",
          "105:     content and use it somewhere else without needing ``lazy-object-proxy``.",
          "106:     \"\"\"",
          "108:     def __init__(self, kwargs: Mapping[str, Any], *, wildcard: bool) -> None:",
          "109:         self._kwargs = kwargs",
          "110:         self._wildcard = wildcard",
          "112:     @classmethod",
          "113:     def determine(",
          "114:         cls,",
          "115:         func: Callable[..., Any],",
          "116:         args: Collection[Any],",
          "117:         kwargs: Mapping[str, Any],",
          "118:     ) -> \"KeywordParameters\":",
          "119:         import inspect",
          "120:         import itertools",
          "122:         signature = inspect.signature(func)",
          "123:         has_wildcard_kwargs = any(p.kind == p.VAR_KEYWORD for p in signature.parameters.values())",
          "125:         for name in itertools.islice(signature.parameters.keys(), len(args)):",
          "126:             # Check if args conflict with names in kwargs.",
          "127:             if name in kwargs:",
          "128:                 raise ValueError(f\"The key {name!r} in args is a part of kwargs and therefore reserved.\")",
          "130:         if has_wildcard_kwargs:",
          "131:             # If the callable has a **kwargs argument, it's ready to accept all the kwargs.",
          "132:             return cls(kwargs, wildcard=True)",
          "134:         # If the callable has no **kwargs argument, it only wants the arguments it requested.",
          "135:         kwargs = {key: kwargs[key] for key in signature.parameters if key in kwargs}",
          "136:         return cls(kwargs, wildcard=False)",
          "138:     def unpacking(self) -> Mapping[str, Any]:",
          "139:         \"\"\"Dump the kwargs mapping to unpack with ``**`` in a function call.\"\"\"",
          "140:         if self._wildcard and isinstance(self._kwargs, Context):",
          "141:             return lazy_mapping_from_context(self._kwargs)",
          "142:         return self._kwargs",
          "144:     def serializing(self) -> Mapping[str, Any]:",
          "145:         \"\"\"Dump the kwargs mapping for serialization purposes.\"\"\"",
          "146:         return self._kwargs",
          "149: def determine_kwargs(",
          "150:     func: Callable[..., Any],",
          "151:     args: Collection[Any],",
          "152:     kwargs: Mapping[str, Any],",
          "153: ) -> Mapping[str, Any]:",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "99:     :param kwargs: The keyword arguments that need to be filtered before passing to the callable.",
          "100:     :return: A dictionary which contains the keyword arguments that are compatible with the callable.",
          "101:     \"\"\"",
          "121: def make_kwargs_callable(func: Callable) -> Callable:",
          "",
          "[Removed Lines]",
          "102:     import inspect",
          "103:     import itertools",
          "105:     signature = inspect.signature(func)",
          "106:     has_kwargs = any(p.kind == p.VAR_KEYWORD for p in signature.parameters.values())",
          "108:     for name in itertools.islice(signature.parameters.keys(), len(args)):",
          "109:         # Check if args conflict with names in kwargs",
          "110:         if name in kwargs:",
          "111:             raise ValueError(f\"The key {name} in args is part of kwargs and therefore reserved.\")",
          "113:     if has_kwargs:",
          "114:         # If the callable has a **kwargs argument, it's ready to accept all the kwargs.",
          "115:         return kwargs",
          "117:     # If the callable has no **kwargs argument, it only wants the arguments it requested.",
          "118:     return {key: kwargs[key] for key in signature.parameters if key in kwargs}",
          "",
          "[Added Lines]",
          "164:     return KeywordParameters.determine(func, args, kwargs).unpacking()",
          "",
          "---------------"
        ],
        "scripts/ci/kubernetes/ci_run_kubernetes_tests.sh||scripts/ci/kubernetes/ci_run_kubernetes_tests.sh": [
          "File: scripts/ci/kubernetes/ci_run_kubernetes_tests.sh -> scripts/ci/kubernetes/ci_run_kubernetes_tests.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "52:         else",
          "53:             tests_to_run=(\"${@}\")",
          "54:         fi",
          "59:     else",
          "60:         tests_to_run=(\"kubernetes_tests\")",
          "61:         pytest_args=(",
          "",
          "[Removed Lines]",
          "55:         pytest_args=(",
          "56:             \"--pythonwarnings=ignore::DeprecationWarning\"",
          "57:             \"--pythonwarnings=ignore::PendingDeprecationWarning\"",
          "58:         )",
          "",
          "[Added Lines]",
          "55:         pytest_args=()",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "64:             \"--durations=100\"",
          "65:             \"--color=yes\"",
          "66:             \"--maxfail=50\"",
          "69:             )",
          "71:     fi",
          "",
          "[Removed Lines]",
          "67:             \"--pythonwarnings=ignore::DeprecationWarning\"",
          "68:             \"--pythonwarnings=ignore::PendingDeprecationWarning\"",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "scripts/in_container/entrypoint_ci.sh||scripts/in_container/entrypoint_ci.sh": [
          "File: scripts/in_container/entrypoint_ci.sh -> scripts/in_container/entrypoint_ci.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "209:     \"--cov-report=xml:/files/coverage-${TEST_TYPE}-${BACKEND}.xml\"",
          "210:     \"--color=yes\"",
          "211:     \"--maxfail=50\"",
          "214:     \"--junitxml=${RESULT_LOG_FILE}\"",
          "215:     # timeouts in seconds for individual tests",
          "216:     \"--timeouts-order\"",
          "",
          "[Removed Lines]",
          "212:     \"--pythonwarnings=ignore::DeprecationWarning\"",
          "213:     \"--pythonwarnings=ignore::PendingDeprecationWarning\"",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "tests/cli/commands/test_task_command.py||tests/cli/commands/test_task_command.py": [
          "File: tests/cli/commands/test_task_command.py -> tests/cli/commands/test_task_command.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "84:         args = self.parser.parse_args(['tasks', 'list', 'example_bash_operator', '--tree'])",
          "85:         task_command.task_list(args)",
          "87:     def test_test(self):",
          "88:         \"\"\"Test the `airflow test` command\"\"\"",
          "89:         args = self.parser.parse_args(",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "87:     @pytest.mark.filterwarnings(\"ignore::airflow.utils.context.AirflowContextDeprecationWarning\")",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "96:         # Check that prints, and log messages, are shown",
          "97:         assert \"'example_python_operator__print_the_context__20180101'\" in stdout.getvalue()",
          "99:     def test_test_with_existing_dag_run(self):",
          "100:         \"\"\"Test the `airflow test` command\"\"\"",
          "101:         task_id = 'print_the_context'",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "100:     @pytest.mark.filterwarnings(\"ignore::airflow.utils.context.AirflowContextDeprecationWarning\")",
          "",
          "---------------"
        ],
        "tests/core/test_core.py||tests/core/test_core.py": [
          "File: tests/core/test_core.py -> tests/core/test_core.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "218:             op.run(start_date=DEFAULT_DATE, end_date=DEFAULT_DATE, ignore_ti_state=True)",
          "220:     def test_python_op(self, dag_maker):",
          "222:             if not templates_dict['ds'] == ds:",
          "223:                 raise Exception(\"failure\")",
          "",
          "[Removed Lines]",
          "221:         def test_py_op(templates_dict, ds, **kwargs):",
          "",
          "[Added Lines]",
          "221:         def test_py_op(templates_dict, ds):",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "246:         assert context['ds'] == '2015-01-01'",
          "247:         assert context['ds_nodash'] == '20150101'",
          "253:         assert context['ts'] == '2015-01-01T00:00:00+00:00'",
          "254:         assert context['ts_nodash'] == '20150101T000000'",
          "255:         assert context['ts_nodash_with_tz'] == '20150101T000000+0000'",
          "",
          "[Removed Lines]",
          "249:         # next_ds is 2015-01-02 as the dag schedule is daily.",
          "250:         assert context['next_ds'] == '2015-01-02'",
          "251:         assert context['next_ds_nodash'] == '20150102'",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "260:         # Test deprecated fields.",
          "261:         expected_deprecated_fields = [",
          "262:             (\"prev_ds\", \"2014-12-31\"),",
          "263:             (\"prev_ds_nodash\", \"20141231\"),",
          "264:             (\"yesterday_ds\", \"2014-12-31\"),",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "258:             (\"next_ds\", \"2015-01-02\"),",
          "259:             (\"next_ds_nodash\", \"20150102\"),",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "267:             (\"tomorrow_ds_nodash\", \"20150102\"),",
          "268:         ]",
          "269:         for key, expected_value in expected_deprecated_fields:",
          "271:                 f\"Accessing {key!r} from the template is deprecated and \"",
          "272:                 f\"will be removed in a future version.\"",
          "273:             )",
          "274:             with pytest.deprecated_call() as recorder:",
          "275:                 value = str(context[key])  # Simulate template evaluation to trigger warning.",
          "276:             assert value == expected_value",
          "279:     def test_bad_trigger_rule(self, dag_maker):",
          "280:         with pytest.raises(AirflowException):",
          "",
          "[Removed Lines]",
          "270:             message = (",
          "277:             assert [str(m.message) for m in recorder] == [message]",
          "",
          "[Added Lines]",
          "268:             message_beginning = (",
          "276:             recorded_message = [str(m.message) for m in recorder]",
          "277:             assert len(recorded_message) == 1",
          "278:             assert recorded_message[0].startswith(message_beginning)",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "338:         context = ti.get_template_context()",
          "340:         # next_ds should be the execution date for manually triggered runs",
          "344:     def test_dag_params_and_task_params(self, dag_maker):",
          "345:         # This test case guards how params of DAG and Operator work together.",
          "",
          "[Removed Lines]",
          "341:         assert context['next_ds'] == execution_ds",
          "342:         assert context['next_ds_nodash'] == execution_ds_nodash",
          "",
          "[Added Lines]",
          "342:         with pytest.deprecated_call():",
          "343:             assert context['next_ds'] == execution_ds",
          "344:         with pytest.deprecated_call():",
          "345:             assert context['next_ds_nodash'] == execution_ds_nodash",
          "",
          "---------------"
        ],
        "tests/operators/test_email.py||tests/operators/test_email.py": [
          "File: tests/operators/test_email.py -> tests/operators/test_email.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "50:             html_content='The quick brown fox jumps over the lazy dog',",
          "51:             task_id='task',",
          "52:             dag=self.dag,",
          "55:         )",
          "56:         task.run(start_date=DEFAULT_DATE, end_date=DEFAULT_DATE)",
          "",
          "[Removed Lines]",
          "53:             files=[\"/tmp/Report-A-{{ execution_date.strftime('%Y-%m-%d') }}.csv\"],",
          "",
          "[Added Lines]",
          "53:             files=[\"/tmp/Report-A-{{ ds }}.csv\"],",
          "",
          "---------------"
        ],
        "tests/operators/test_python.py||tests/operators/test_python.py": [
          "File: tests/operators/test_python.py -> tests/operators/test_python.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: import logging",
          "20: import sys",
          "21: import unittest.mock",
          "22: from collections import namedtuple",
          "23: from datetime import date, datetime, timedelta",
          "24: from subprocess import CalledProcessError",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "22: import warnings",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "39:     get_current_context,",
          "40: )",
          "41: from airflow.utils import timezone",
          "42: from airflow.utils.dates import days_ago",
          "43: from airflow.utils.session import create_session",
          "44: from airflow.utils.state import State",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "43: from airflow.utils.context import AirflowContextDeprecationWarning",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "850:     # This tests might take longer than default 60 seconds as it is serializing a lot of",
          "851:     # context using dill (which is slow apparently).",
          "852:     @pytest.mark.execution_timeout(120)",
          "853:     def test_airflow_context(self):",
          "854:         def f(",
          "855:             # basic",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "855:     @pytest.mark.filterwarnings(\"ignore::airflow.utils.context.AirflowContextDeprecationWarning\")",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "891:         self._run_as_operator(f, use_dill=True, system_site_packages=True, requirements=None)",
          "893:     def test_pendulum_context(self):",
          "894:         def f(",
          "895:             # basic",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "896:     @pytest.mark.filterwarnings(\"ignore::airflow.utils.context.AirflowContextDeprecationWarning\")",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "924:         self._run_as_operator(f, use_dill=True, system_site_packages=False, requirements=['pendulum'])",
          "926:     def test_base_context(self):",
          "927:         def f(",
          "928:             # basic",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "930:     @pytest.mark.filterwarnings(\"ignore::airflow.utils.context.AirflowContextDeprecationWarning\")",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "1027: def get_all_the_context(**context):",
          "1028:     current_context = get_current_context()",
          "1032: @pytest.fixture()",
          "",
          "[Removed Lines]",
          "1029:     assert context == current_context._context",
          "",
          "[Added Lines]",
          "1034:     with warnings.catch_warnings():",
          "1035:         warnings.simplefilter(\"ignore\", AirflowContextDeprecationWarning)",
          "1036:         assert context == current_context._context",
          "",
          "---------------"
        ],
        "tests/operators/test_trigger_dagrun.py||tests/operators/test_trigger_dagrun.py": [
          "File: tests/operators/test_trigger_dagrun.py -> tests/operators/test_trigger_dagrun.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "152:         task = TriggerDagRunOperator(",
          "153:             task_id=\"test_trigger_dagrun_with_str_execution_date\",",
          "154:             trigger_dag_id=TRIGGERED_DAG_ID,",
          "156:             dag=self.dag,",
          "157:         )",
          "158:         task.run(start_date=DEFAULT_DATE, end_date=DEFAULT_DATE, ignore_ti_state=True)",
          "",
          "[Removed Lines]",
          "155:             execution_date=\"{{ execution_date }}\",",
          "",
          "[Added Lines]",
          "155:             execution_date=\"{{ logical_date }}\",",
          "",
          "---------------"
        ],
        "tests/providers/http/sensors/test_http.py||tests/providers/http/sensors/test_http.py": [
          "File: tests/providers/http/sensors/test_http.py -> tests/providers/http/sensors/test_http.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "125:         response.status_code = 200",
          "126:         mock_session_send.return_value = response",
          "130:                 return True",
          "131:             raise AirflowException('AirflowException raised here!')",
          "",
          "[Removed Lines]",
          "128:         def resp_check(_, execution_date):",
          "129:             if execution_date == DEFAULT_DATE:",
          "",
          "[Added Lines]",
          "128:         def resp_check(_, logical_date):",
          "129:             if logical_date == DEFAULT_DATE:",
          "",
          "---------------"
        ],
        "tests/sensors/test_external_task_sensor.py||tests/sensors/test_external_task_sensor.py": [
          "File: tests/sensors/test_external_task_sensor.py -> tests/sensors/test_external_task_sensor.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "175:     def test_external_task_sensor_fn_multiple_execution_dates(self):",
          "176:         bash_command_code = \"\"\"",
          "178: echo \"second is {{ s }}\"",
          "179: if [[ $(( {{ s }} % 60 )) == 1 ]]",
          "180:     then",
          "",
          "[Removed Lines]",
          "177: {% set s=execution_date.time().second %}",
          "",
          "[Added Lines]",
          "177: {% set s=logical_date.time().second %}",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "292:         self.test_time_sensor()",
          "294:         def my_func(dt, context):",
          "296:             return dt + timedelta(0)",
          "298:         op1 = ExternalTaskSensor(",
          "",
          "[Removed Lines]",
          "295:             assert context['execution_date'] == dt",
          "",
          "[Added Lines]",
          "295:             assert context['logical_date'] == dt",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "541:             task_id=\"task_1\",",
          "542:             external_dag_id=dag_0.dag_id,",
          "543:             external_task_id=task_0.task_id,",
          "545:             mode='reschedule',",
          "546:         )",
          "",
          "[Removed Lines]",
          "544:             execution_date_fn=lambda execution_date: day_1 if execution_date == day_1 else [],",
          "",
          "[Added Lines]",
          "544:             execution_date_fn=lambda logical_date: day_1 if logical_date == day_1 else [],",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "884:             task_id=\"tail\",",
          "885:             external_dag_id=dag.dag_id,",
          "886:             external_task_id=head.task_id,",
          "888:         )",
          "889:         head >> body >> tail",
          "",
          "[Removed Lines]",
          "887:             execution_date=\"{{ tomorrow_ds_nodash }}\",",
          "",
          "[Added Lines]",
          "887:             execution_date=\"{{ macros.ds_add(ds, 1) }}\",",
          "",
          "---------------"
        ],
        "tests/utils/test_log_handlers.py||tests/utils/test_log_handlers.py": [
          "File: tests/utils/test_log_handlers.py -> tests/utils/test_log_handlers.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "62:         assert handler.name == FILE_TASK_HANDLER",
          "64:     def test_file_task_handler_when_ti_value_is_invalid(self):",
          "66:             ti.log.info(\"test\")",
          "68:         dag = DAG('dag_for_testing_file_task_handler', start_date=DEFAULT_DATE)",
          "",
          "[Removed Lines]",
          "65:         def task_callable(ti, **kwargs):",
          "",
          "[Added Lines]",
          "65:         def task_callable(ti):",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "114:         os.remove(log_filename)",
          "116:     def test_file_task_handler(self):",
          "118:             ti.log.info(\"test\")",
          "120:         dag = DAG('dag_for_testing_file_task_handler', start_date=DEFAULT_DATE)",
          "",
          "[Removed Lines]",
          "117:         def task_callable(ti, **kwargs):",
          "",
          "[Added Lines]",
          "117:         def task_callable(ti):",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "168:         os.remove(log_filename)",
          "170:     def test_file_task_handler_running(self):",
          "172:             ti.log.info(\"test\")",
          "174:         dag = DAG('dag_for_testing_file_task_handler', start_date=DEFAULT_DATE)",
          "",
          "[Removed Lines]",
          "171:         def task_callable(ti, **kwargs):",
          "",
          "[Added Lines]",
          "171:         def task_callable(ti):",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "3162de5109f1eb25a8c419654cc9a827983eff1a",
      "candidate_info": {
        "commit_hash": "3162de5109f1eb25a8c419654cc9a827983eff1a",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/3162de5109f1eb25a8c419654cc9a827983eff1a",
        "files": [
          "dev/import_all_classes.py",
          "dev/prepare_release_issue.py",
          "dev/provider_packages/prepare_provider_packages.py",
          "dev/validate_version_added_fields_in_config.py"
        ],
        "message": "Fix MyPy errors in `dev/*` (#20261)\n\n(cherry picked from commit 08e835729b50cac2a68fab24bf2b52a587112776)",
        "before_after_code_files": [
          "dev/import_all_classes.py||dev/import_all_classes.py",
          "dev/prepare_release_issue.py||dev/prepare_release_issue.py",
          "dev/provider_packages/prepare_provider_packages.py||dev/provider_packages/prepare_provider_packages.py",
          "dev/validate_version_added_fields_in_config.py||dev/validate_version_added_fields_in_config.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "dev/import_all_classes.py||dev/import_all_classes.py": [
          "File: dev/import_all_classes.py -> dev/import_all_classes.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: import traceback",
          "23: import warnings",
          "24: from inspect import isclass",
          "26: from warnings import WarningMessage",
          "28: from rich import print",
          "",
          "[Removed Lines]",
          "25: from typing import List, Set, Tuple",
          "",
          "[Added Lines]",
          "25: from typing import List, Optional, Set, Tuple",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "31: def import_all_classes(",
          "32:     paths: List[str],",
          "33:     prefix: str,",
          "35:     print_imports: bool = False,",
          "36:     print_skips: bool = False,",
          "37: ) -> Tuple[List[str], List[WarningMessage]]:",
          "",
          "[Removed Lines]",
          "34:     provider_ids: List[str] = None,",
          "",
          "[Added Lines]",
          "34:     provider_ids: Optional[List[str]] = None,",
          "",
          "---------------"
        ],
        "dev/prepare_release_issue.py||dev/prepare_release_issue.py": [
          "File: dev/prepare_release_issue.py -> dev/prepare_release_issue.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: import subprocess",
          "23: import textwrap",
          "24: from collections import defaultdict",
          "27: import click",
          "28: from github import Github, Issue, PullRequest, UnknownObjectException",
          "",
          "[Removed Lines]",
          "25: from typing import Any, Dict, List, NamedTuple, Optional, Set",
          "",
          "[Added Lines]",
          "25: from typing import Any, Dict, List, NamedTuple, Optional, Set, Union",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "34: console = Console(width=400, color_system=\"standard\")",
          "36: MY_DIR_PATH = os.path.dirname(__file__)",
          "37: SOURCE_DIR_PATH = os.path.abspath(os.path.join(MY_DIR_PATH, os.pardir))",
          "38: PR_PATTERN = re.compile(r\".*\\(#([0-9]+)\\)\")",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "36: PullRequestOrIssue = Union[PullRequest.PullRequest, Issue.Issue]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "184: def print_issue_content(",
          "185:     current_release: str,",
          "187:     linked_issues: Dict[int, List[Issue.Issue]],",
          "188:     users: Dict[int, Set[str]],",
          "189: ):",
          "",
          "[Removed Lines]",
          "186:     pull_requests: Dict[int, PullRequest.PullRequest],",
          "",
          "[Added Lines]",
          "188:     pull_requests: Dict[int, PullRequestOrIssue],",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "231:     else:",
          "232:         excluded_prs = []",
          "233:     changes = get_changes(verbose, previous_release, current_release)",
          "237:     g = Github(github_token)",
          "238:     repo = g.get_repo(\"apache/airflow\")",
          "240:     linked_issues: Dict[int, List[Issue.Issue]] = defaultdict(lambda: [])",
          "241:     users: Dict[int, Set[str]] = defaultdict(lambda: set())",
          "242:     count_prs = len(prs)",
          "",
          "[Removed Lines]",
          "234:     prs = list(",
          "235:         filter(lambda pr: pr is not None and pr not in excluded_prs, [change.pr for change in changes])",
          "236:     )",
          "239:     pull_requests: Dict[int, PullRequest.PullRequest] = {}",
          "",
          "[Added Lines]",
          "236:     change_prs = [change.pr for change in changes]",
          "237:     prs = [pr for pr in change_prs if pr is not None and pr not in excluded_prs]",
          "241:     pull_requests: Dict[int, PullRequestOrIssue] = {}",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "249:             progress.console.print(",
          "250:                 f\"Retrieving PR#{pr_number}: \" f\"https://github.com/apache/airflow/pull/{pr_number}\"",
          "251:             )",
          "252:             try:",
          "253:                 pr = repo.get_pull(pr_number)",
          "254:             except UnknownObjectException:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "255:             pr: PullRequestOrIssue",
          "",
          "---------------"
        ],
        "dev/provider_packages/prepare_provider_packages.py||dev/provider_packages/prepare_provider_packages.py": [
          "File: dev/provider_packages/prepare_provider_packages.py -> dev/provider_packages/prepare_provider_packages.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "40: from os.path import dirname, relpath",
          "41: from pathlib import Path",
          "42: from shutil import copyfile",
          "45: import click",
          "46: import jsonschema",
          "48: from packaging.version import Version",
          "49: from rich.console import Console",
          "50: from rich.progress import Progress",
          "",
          "[Removed Lines]",
          "43: from typing import Any, Dict, Iterable, List, NamedTuple, Optional, Set, Tuple, Type",
          "47: from github import Github, PullRequest, UnknownObjectException",
          "",
          "[Added Lines]",
          "43: from typing import Any, Dict, Iterable, List, NamedTuple, Optional, Set, Tuple, Type, Union",
          "47: from github import Github, Issue, PullRequest, UnknownObjectException",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1286:     provider_package_id: str,",
          "1287:     source_provider_package_path: str,",
          "1288:     verbose: bool,",
          "1290:     \"\"\"",
          "1291:     Retrieves all changes for the package.",
          "1292:     :param versions: list of versions",
          "",
          "[Removed Lines]",
          "1289: ) -> Tuple[bool, Optional[List[List[Change]]], str]:",
          "",
          "[Added Lines]",
          "1289: ) -> Tuple[bool, Optional[Union[List[List[Change]], Change]], str]:",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "1576:             return False",
          "1577:         else:",
          "1578:             if interactive and confirm(\"Are those changes documentation-only?\"):",
          "1580:             return False",
          "1582:     jinja_context[\"DETAILED_CHANGES_RST\"] = changes",
          "",
          "[Removed Lines]",
          "1579:                 mark_latest_changes_as_documentation_only(provider_details, latest_change)",
          "",
          "[Added Lines]",
          "1579:                 if isinstance(latest_change, Change):",
          "1580:                     mark_latest_changes_as_documentation_only(provider_details, latest_change)",
          "1581:                 else:",
          "1582:                     raise ValueError(",
          "1583:                         \"Expected only one change to be present to mark changes \"",
          "1584:                         f\"in provider {provider_package_id} as docs-only. \"",
          "1585:                         f\"Received {len(latest_change)}.\"",
          "1586:                     )",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "1773:     return list(PROVIDERS_REQUIREMENTS.keys())",
          "1777:     \"\"\"",
          "1778:     Verifies if the provider package is good.",
          "1779:     :param provider_package_id: package id to verify",
          "",
          "[Removed Lines]",
          "1776: def verify_provider_package(provider_package_id: str) -> str:",
          "",
          "[Added Lines]",
          "1783: def verify_provider_package(provider_package_id: str) -> None:",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "2383:     return prs",
          "2386: class ProviderPRInfo(NamedTuple):",
          "2387:     provider_details: ProviderPackageDetails",
          "2391: @cli.command()",
          "",
          "[Removed Lines]",
          "2388:     pr_list: List[PullRequest.PullRequest]",
          "",
          "[Added Lines]",
          "2393: PullRequestOrIssue = Union[PullRequest.PullRequest, Issue.Issue]",
          "2398:     pr_list: List[PullRequestOrIssue]",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "2411:             all_prs.update(provider_prs[package_id])",
          "2412:         g = Github(github_token)",
          "2413:         repo = g.get_repo(\"apache/airflow\")",
          "2415:         with Progress(console=console) as progress:",
          "2416:             task = progress.add_task(f\"Retrieving {len(all_prs)} PRs \", total=len(all_prs))",
          "2417:             pr_list = list(all_prs)",
          "",
          "[Removed Lines]",
          "2414:         pull_requests: Dict[int, PullRequest.PullRequest] = {}",
          "",
          "[Added Lines]",
          "2424:         pull_requests: Dict[int, PullRequestOrIssue] = {}",
          "",
          "---------------"
        ],
        "dev/validate_version_added_fields_in_config.py||dev/validate_version_added_fields_in_config.py": [
          "File: dev/validate_version_added_fields_in_config.py -> dev/validate_version_added_fields_in_config.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "71: to_check_versions: List[str] = [d for d in airflow_version if d.startswith(\"2.\")]",
          "73: # 2. Compute expected options set with version added fields",
          "75: for prev_version, curr_version in zip(to_check_versions[:-1], to_check_versions[1:]):",
          "76:     print(\"Processing version:\", curr_version)",
          "77:     options_1 = fetch_config_options_for_version(prev_version)",
          "78:     options_2 = fetch_config_options_for_version(curr_version)",
          "79:     new_options = options_2 - options_1",
          "81:         {(section_name, option_name, curr_version) for section_name, option_name in new_options}",
          "82:     )",
          "85: # 3. Read local options set",
          "86: local_options = read_local_config_options()",
          "",
          "[Removed Lines]",
          "74: computed_options: Set[Tuple[str, str, str]] = set()",
          "80:     computed_options.update(",
          "83: print(\"Computed options count:\", len(computed_options))",
          "",
          "[Added Lines]",
          "74: expected_computed_options: Set[Tuple[str, str, str]] = set()",
          "80:     expected_computed_options.update(",
          "83: print(\"Expected computed options count:\", len(expected_computed_options))",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "92: }",
          "93: computed_options: Set[Tuple[str, str, str]] = {",
          "94:     (section_name, option_name, version_added)",
          "96:     if (section_name, option_name) in local_options_plain",
          "97: }",
          "98: print(\"Visible computed options count:\", len(computed_options))",
          "",
          "[Removed Lines]",
          "95:     for section_name, option_name, version_added in computed_options",
          "",
          "[Added Lines]",
          "95:     for section_name, option_name, version_added in expected_computed_options",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "1b139a77d012971d147bffc74646923514db4b48",
      "candidate_info": {
        "commit_hash": "1b139a77d012971d147bffc74646923514db4b48",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/1b139a77d012971d147bffc74646923514db4b48",
        "files": [
          "airflow/jobs/scheduler_job.py",
          "tests/jobs/test_scheduler_job.py"
        ],
        "message": "Fix Scheduler crash when executing task instances of missing DAG (#20349)\n\nWhen executing task instances, we do not check if the dag is missing in\nthe dagbag. This PR fixes it by ignoring task instances if we can't find\nthe dag in serialized dag table\n\nCloses: #20099\n(cherry picked from commit 98715760f72e5205c291293088b5e79636884491)",
        "before_after_code_files": [
          "airflow/jobs/scheduler_job.py||airflow/jobs/scheduler_job.py",
          "tests/jobs/test_scheduler_job.py||tests/jobs/test_scheduler_job.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/jobs/scheduler_job.py||airflow/jobs/scheduler_job.py": [
          "File: airflow/jobs/scheduler_job.py -> airflow/jobs/scheduler_job.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "375:                     # Many dags don't have a task_concurrency, so where we can avoid loading the full",
          "376:                     # serialized DAG the better.",
          "377:                     serialized_dag = self.dagbag.get_dag(dag_id, session=session)",
          "378:                     if serialized_dag.has_task(task_instance.task_id):",
          "379:                         task_concurrency_limit = serialized_dag.get_task(",
          "380:                             task_instance.task_id",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "378:                     # If the dag is missing, fail the task and continue to the next task.",
          "379:                     if not serialized_dag:",
          "380:                         self.log.error(",
          "381:                             \"DAG '%s' for task instance %s not found in serialized_dag table\",",
          "382:                             dag_id,",
          "383:                             task_instance,",
          "384:                         )",
          "385:                         session.query(TI).filter(TI.dag_id == dag_id, TI.state == State.SCHEDULED).update(",
          "386:                             {TI.state: State.FAILED}, synchronize_session='fetch'",
          "387:                         )",
          "388:                         continue",
          "",
          "---------------"
        ],
        "tests/jobs/test_scheduler_job.py||tests/jobs/test_scheduler_job.py": [
          "File: tests/jobs/test_scheduler_job.py -> tests/jobs/test_scheduler_job.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "610:         session.rollback()",
          "611:         session.close()",
          "613:     def test_nonexistent_pool(self, dag_maker):",
          "614:         dag_id = 'SchedulerJobTest.test_nonexistent_pool'",
          "615:         with dag_maker(dag_id=dag_id, max_active_tasks=16):",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "613:     def test_queued_task_instances_fails_with_missing_dag(self, dag_maker, session):",
          "614:         \"\"\"Check that task instances of missing DAGs are failed\"\"\"",
          "615:         dag_id = 'SchedulerJobTest.test_find_executable_task_instances_not_in_dagbag'",
          "616:         task_id_1 = 'dummy'",
          "617:         task_id_2 = 'dummydummy'",
          "619:         with dag_maker(dag_id=dag_id, session=session, default_args={\"max_active_tis_per_dag\": 1}):",
          "620:             DummyOperator(task_id=task_id_1)",
          "621:             DummyOperator(task_id=task_id_2)",
          "623:         self.scheduler_job = SchedulerJob(subdir=os.devnull)",
          "624:         self.scheduler_job.dagbag = mock.MagicMock()",
          "625:         self.scheduler_job.dagbag.get_dag.return_value = None",
          "627:         dr = dag_maker.create_dagrun(state=DagRunState.RUNNING)",
          "629:         tis = dr.task_instances",
          "630:         for ti in tis:",
          "631:             ti.state = State.SCHEDULED",
          "632:             session.merge(ti)",
          "633:         session.flush()",
          "634:         res = self.scheduler_job._executable_task_instances_to_queued(max_tis=32, session=session)",
          "635:         session.flush()",
          "636:         assert 0 == len(res)",
          "637:         tis = dr.get_task_instances(session=session)",
          "638:         assert len(tis) == 2",
          "639:         assert all(ti.state == State.FAILED for ti in tis)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "84c523d841347f7c4b10ff32869d2792c14077fa",
      "candidate_info": {
        "commit_hash": "84c523d841347f7c4b10ff32869d2792c14077fa",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/84c523d841347f7c4b10ff32869d2792c14077fa",
        "files": [
          "scripts/ci/libraries/_kind.sh"
        ],
        "message": "Speed up webserver start up in Kube tests (#19710)\n\nThanks to a previous change to not load provider hooks too early we can\ntake advantage of the \"preload-app\" feature of Gunicorn to load the\napplication once in the main gunicorn process before the workers are\nforked off.\n\nThis change makes the webserver start up (time to serving first request)\ngo from 20s to 5s.\n\n(The reason we don't just do this blindly everywhere is that it would\nmean plugins are loaded at start only, and is a change in behaviour. But\nin tests this is fine.)\n\n(cherry picked from commit 17d8656a0745a76925a51de6f6e7ce2488d1d2f4)",
        "before_after_code_files": [
          "scripts/ci/libraries/_kind.sh||scripts/ci/libraries/_kind.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "scripts/ci/libraries/_kind.sh||scripts/ci/libraries/_kind.sh": [
          "File: scripts/ci/libraries/_kind.sh -> scripts/ci/libraries/_kind.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "271: COPY airflow/kubernetes_executor_templates/ \\${AIRFLOW_HOME}/pod_templates/",
          "273: EOF",
          "274:     echo \"The ${AIRFLOW_IMAGE_KUBERNETES}:${image_tag} is prepared for test kubernetes deployment.\"",
          "275: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "273: ENV GUNICORN_CMD_ARGS='--preload' AIRFLOW__WEBSERVER__WORKER_REFRESH_INTERVAL=0",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "f1c7f0689b1a4b8d5ef67086177b8c52f6276e9f",
      "candidate_info": {
        "commit_hash": "f1c7f0689b1a4b8d5ef67086177b8c52f6276e9f",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/f1c7f0689b1a4b8d5ef67086177b8c52f6276e9f",
        "files": [
          "airflow/providers/google/cloud/hooks/cloud_sql.py"
        ],
        "message": "switch to follow_redirects on httpx.get call in CloudSQL provider (#20239)\n\n* switch to follow_redirects on httpx.get call in CloudSQL provider\n* sense for parameter as suggested in review\n\n(cherry picked from commit bfd6d45cecbc7714cea8e2ce5d8920bdb4819887)",
        "before_after_code_files": [
          "airflow/providers/google/cloud/hooks/cloud_sql.py||airflow/providers/google/cloud/hooks/cloud_sql.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/providers/google/cloud/hooks/cloud_sql.py||airflow/providers/google/cloud/hooks/cloud_sql.py": [
          "File: airflow/providers/google/cloud/hooks/cloud_sql.py -> airflow/providers/google/cloud/hooks/cloud_sql.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "31: import subprocess",
          "32: import time",
          "33: import uuid",
          "34: from pathlib import Path",
          "35: from subprocess import PIPE, Popen",
          "36: from typing import Any, Dict, List, Optional, Sequence, Union",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "34: from inspect import signature",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "498:             )",
          "499:         proxy_path_tmp = self.sql_proxy_path + \".tmp\"",
          "500:         self.log.info(\"Downloading cloud_sql_proxy from %s to %s\", download_url, proxy_path_tmp)",
          "502:         # Downloading to .tmp file first to avoid case where partially downloaded",
          "503:         # binary is used by parallel operator which uses the same fixed binary path",
          "504:         with open(proxy_path_tmp, 'wb') as file:",
          "",
          "[Removed Lines]",
          "501:         response = httpx.get(download_url, allow_redirects=True)",
          "",
          "[Added Lines]",
          "502:         # httpx has a breaking API change (follow_redirects vs allow_redirects)",
          "503:         # and this should work with both versions (cf. issue #20088)",
          "504:         if \"follow_redirects\" in signature(httpx.get).parameters.keys():",
          "505:             response = httpx.get(download_url, follow_redirects=True)",
          "506:         else:",
          "507:             response = httpx.get(download_url, allow_redirects=True)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "769:     @staticmethod",
          "770:     def _get_bool(val: Any) -> bool:",
          "772:             return False",
          "773:         return True",
          "",
          "[Removed Lines]",
          "771:         if val == 'False':",
          "",
          "[Added Lines]",
          "777:         if val == 'False' or val is False:",
          "",
          "---------------"
        ]
      }
    }
  ]
}