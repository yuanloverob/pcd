{
  "cve_id": "CVE-2023-35005",
  "cve_desc": "In Apache Airflow, some potentially sensitive values were being shown to the user in certain situations.\n\nThis vulnerability is mitigated by the fact configuration is not shown in the UI by default (only if `[webserver] expose_config` is set to `non-sensitive-only`), and not all uncensored values are actually sentitive.\n\n\nThis issue affects Apache Airflow: from 2.5.0 before 2.6.2. Users are recommended to update to version 2.6.2 or later.\n\n\n",
  "repo": "apache/airflow",
  "patch_hash": "f6cda8fb63250fc4700658999739c1c3c5f6625c",
  "patch_info": {
    "commit_hash": "f6cda8fb63250fc4700658999739c1c3c5f6625c",
    "repo": "apache/airflow",
    "commit_url": "https://github.com/apache/airflow/commit/f6cda8fb63250fc4700658999739c1c3c5f6625c",
    "files": [
      "airflow/configuration.py"
    ],
    "message": "Mark `[secrets] backend_kwargs` as a sensitive config (#31788)\n\n(cherry picked from commit 8062756fa9e01eeeee1f2c6df74f376c0a526bd5)",
    "before_after_code_files": [
      "airflow/configuration.py||airflow/configuration.py"
    ]
  },
  "patch_diff": {
    "airflow/configuration.py||airflow/configuration.py": [
      "File: airflow/configuration.py -> airflow/configuration.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "156:     (\"atlas\", \"password\"),",
      "157:     (\"smtp\", \"smtp_password\"),",
      "158:     (\"webserver\", \"secret_key\"),",
      "159:     # The following options are deprecated",
      "160:     (\"core\", \"sql_alchemy_conn\"),",
      "161: }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "159:     (\"secrets\", \"backend_kwargs\"),",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "c3e388a8f5ac93756f978ab1bc22f9478450ed07",
      "candidate_info": {
        "commit_hash": "c3e388a8f5ac93756f978ab1bc22f9478450ed07",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/c3e388a8f5ac93756f978ab1bc22f9478450ed07",
        "files": [
          "airflow/utils/file.py",
          "tests/dag_processing/test_processor.py"
        ],
        "message": "Fix error handling when pre-importing modules in DAGs (#31401)\n\n(cherry picked from commit 24a94bbb603c5308a2e8817dc356492287f7b174)",
        "before_after_code_files": [
          "airflow/utils/file.py||airflow/utils/file.py",
          "tests/dag_processing/test_processor.py||tests/dag_processing/test_processor.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/31796"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/utils/file.py||airflow/utils/file.py": [
          "File: airflow/utils/file.py -> airflow/utils/file.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "387:     \"\"\"Find Airflow modules imported in the given file.\"\"\"",
          "388:     try:",
          "389:         parsed = ast.parse(Path(file_path).read_bytes())",
          "391:         return",
          "392:     for m in _find_imported_modules(parsed):",
          "393:         if m.startswith(\"airflow.\"):",
          "",
          "[Removed Lines]",
          "390:     except (OSError, SyntaxError, UnicodeDecodeError):",
          "",
          "[Added Lines]",
          "390:     except Exception:",
          "",
          "---------------"
        ],
        "tests/dag_processing/test_processor.py||tests/dag_processing/test_processor.py": [
          "File: tests/dag_processing/test_processor.py -> tests/dag_processing/test_processor.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "977:         )",
          "978:         processor.start()",
          "981: class TestProcessorAgent:",
          "982:     @pytest.fixture(autouse=True)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "980:     @mock.patch(\"airflow.dag_processing.processor.settings.dispose_orm\", MagicMock)",
          "981:     @mock.patch.object(DagFileProcessorProcess, \"_get_multiprocessing_context\")",
          "982:     def test_nullbyte_exception_handling_when_preimporting_airflow(self, mock_context, tmpdir):",
          "983:         mock_context.return_value.Pipe.return_value = (MagicMock(), MagicMock())",
          "984:         dag_filename = os.path.join(tmpdir, \"test_dag.py\")",
          "985:         with open(dag_filename, \"wb\") as file:",
          "986:             file.write(b\"hello\\x00world\")",
          "988:         processor = DagFileProcessorProcess(",
          "989:             file_path=dag_filename,",
          "990:             pickle_dags=False,",
          "991:             dag_ids=[],",
          "992:             dag_directory=[],",
          "993:             callback_requests=[],",
          "994:         )",
          "995:         processor.start()",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "0b9ca46fdb940d7973d424f7991f2fa821e2419f",
      "candidate_info": {
        "commit_hash": "0b9ca46fdb940d7973d424f7991f2fa821e2419f",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/0b9ca46fdb940d7973d424f7991f2fa821e2419f",
        "files": [
          "airflow/models/taskinstance.py",
          "tests/models/test_dagrun.py",
          "tests/models/test_taskinstance.py"
        ],
        "message": "Fix crash when clearing run with task from normal to mapped (#31352)\n\nCo-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com>\nCo-authored-by: Tzu-ping Chung <uranusjr@gmail.com>\n(cherry picked from commit f82246abe9491a49701abdb647be001d95db7e9f)",
        "before_after_code_files": [
          "airflow/models/taskinstance.py||airflow/models/taskinstance.py",
          "tests/models/test_dagrun.py||tests/models/test_dagrun.py",
          "tests/models/test_taskinstance.py||tests/models/test_taskinstance.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/31796"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/models/taskinstance.py||airflow/models/taskinstance.py": [
          "File: airflow/models/taskinstance.py -> airflow/models/taskinstance.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "2742:     def clear_db_references(self, session):",
          "2743:         \"\"\"",
          "2746:         :param session: ORM Session",
          "",
          "[Removed Lines]",
          "2744:         Clear DB references to XCom, TaskFail and RenderedTaskInstanceFields.",
          "",
          "[Added Lines]",
          "2744:         Clear db tables that have a reference to this instance.",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "2749:         \"\"\"",
          "2750:         from airflow.models.renderedtifields import RenderedTaskInstanceFields",
          "2753:         for table in tables:",
          "2754:             session.query(table).filter(",
          "2755:                 table.dag_id == self.dag_id,",
          "",
          "[Removed Lines]",
          "2752:         tables = [TaskFail, XCom, RenderedTaskInstanceFields]",
          "",
          "[Added Lines]",
          "2752:         tables = [TaskFail, TaskInstanceNote, TaskReschedule, XCom, RenderedTaskInstanceFields]",
          "",
          "---------------"
        ],
        "tests/models/test_dagrun.py||tests/models/test_dagrun.py": [
          "File: tests/models/test_dagrun.py -> tests/models/test_dagrun.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "40: )",
          "41: from airflow.models.baseoperator import BaseOperator",
          "42: from airflow.models.dagrun import DagRunNote",
          "43: from airflow.models.taskmap import TaskMap",
          "44: from airflow.operators.empty import EmptyOperator",
          "45: from airflow.operators.python import ShortCircuitOperator",
          "46: from airflow.serialization.serialized_objects import SerializedDAG",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "43: from airflow.models.taskinstance import TaskInstanceNote",
          "45: from airflow.models.taskreschedule import TaskReschedule",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "2255: def test_clearing_task_and_moving_from_non_mapped_to_mapped(dag_maker, session):",
          "2256:     \"\"\"",
          "2257:     Test that clearing a task and moving from non-mapped to mapped clears existing",
          "2261:     \"\"\"",
          "2263:     from airflow.models.taskfail import TaskFail",
          "",
          "[Removed Lines]",
          "2258:     references in XCom, TaskFail, and RenderedTaskInstanceFields",
          "2259:     To be able to test this, RenderedTaskInstanceFields was not used in the test",
          "2260:     since it would require that the task is expanded first.",
          "",
          "[Added Lines]",
          "2260:     references in XCom, TaskFail, TaskInstanceNote, TaskReschedule and",
          "2261:     RenderedTaskInstanceFields. To be able to test this, RenderedTaskInstanceFields",
          "2262:     was not used in the test since it would require that the task is expanded first.",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "2273:     dr1: DagRun = dag_maker.create_dagrun(run_type=DagRunType.SCHEDULED)",
          "2274:     ti = dr1.get_task_instances()[0]",
          "2275:     # mimicking a case where task moved from non-mapped to mapped",
          "2276:     # in that case, it would have map_index of -1 even though mapped",
          "2277:     ti.map_index = -1",
          "2278:     session.merge(ti)",
          "2279:     session.flush()",
          "2280:     # Purposely omitted RenderedTaskInstanceFields because the ti need",
          "2281:     # to be expanded but here we are mimicking and made it map_index -1",
          "2282:     session.add(TaskFail(ti))",
          "2283:     XCom.set(key=\"test\", value=\"value\", task_id=ti.task_id, dag_id=dag.dag_id, run_id=ti.run_id)",
          "2284:     session.commit()",
          "2286:         assert session.query(table).count() == 1",
          "2287:     dr1.task_instance_scheduling_decisions(session)",
          "2289:         assert session.query(table).count() == 0",
          "",
          "[Removed Lines]",
          "2285:     for table in [TaskFail, XCom]:",
          "2288:     for table in [TaskFail, XCom]:",
          "",
          "[Added Lines]",
          "2277:     filter_kwargs = dict(dag_id=ti.dag_id, task_id=ti.task_id, run_id=ti.run_id, map_index=ti.map_index)",
          "2278:     ti = session.query(TaskInstance).filter_by(**filter_kwargs).one()",
          "2280:     tr = TaskReschedule(",
          "2281:         task=ti,",
          "2282:         run_id=ti.run_id,",
          "2283:         try_number=ti.try_number,",
          "2284:         start_date=timezone.datetime(2017, 1, 1),",
          "2285:         end_date=timezone.datetime(2017, 1, 2),",
          "2286:         reschedule_date=timezone.datetime(2017, 1, 1),",
          "2287:     )",
          "2292:     ti.note = \"sample note\"",
          "2297:     session.add(tr)",
          "2301:     for table in [TaskFail, TaskInstanceNote, TaskReschedule, XCom]:",
          "2304:     for table in [TaskFail, TaskInstanceNote, TaskReschedule, XCom]:",
          "",
          "---------------"
        ],
        "tests/models/test_taskinstance.py||tests/models/test_taskinstance.py": [
          "File: tests/models/test_taskinstance.py -> tests/models/test_taskinstance.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "2888:     def test_clear_db_references(self, session, create_task_instance):",
          "2889:         tables = [TaskFail, RenderedTaskInstanceFields, XCom]",
          "2890:         ti = create_task_instance()",
          "2891:         session.merge(ti)",
          "2892:         session.commit()",
          "2893:         for table in [TaskFail, RenderedTaskInstanceFields]:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "2891:         ti.note = \"sample note\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "2896:         session.commit()",
          "2897:         for table in tables:",
          "2898:             assert session.query(table).count() == 1",
          "2899:         ti.clear_db_references(session)",
          "2900:         for table in tables:",
          "2901:             assert session.query(table).count() == 0",
          "2904: @pytest.mark.parametrize(\"pool_override\", [None, \"test_pool2\"])",
          "2905: def test_refresh_from_task(pool_override):",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "2902:         filter_kwargs = dict(dag_id=ti.dag_id, task_id=ti.task_id, run_id=ti.run_id, map_index=ti.map_index)",
          "2903:         ti_note = session.query(TaskInstanceNote).filter_by(**filter_kwargs).one()",
          "2904:         assert ti_note.content == \"sample note\"",
          "2910:         assert session.query(TaskInstanceNote).filter_by(**filter_kwargs).one_or_none() is None",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "186df9f1bf1b47c5f3fd1f721f630f137862fdff",
      "candidate_info": {
        "commit_hash": "186df9f1bf1b47c5f3fd1f721f630f137862fdff",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/186df9f1bf1b47c5f3fd1f721f630f137862fdff",
        "files": [
          "tests/utils/test_db.py"
        ],
        "message": "Add back accidentally removed `create_session` in utils/db.py (#31705)\n\nThe create_session function was accidentally removed in commit\nhttps://github.com/apache/airflow/commit/522661b6ad4479e3c8243b2d2c8a793d1af82c17\nand it's a breaking change.\n\n(cherry picked from commit 5f3a46427bd8fca6514b0080270f93600b033851)",
        "before_after_code_files": [
          "tests/utils/test_db.py||tests/utils/test_db.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/31796"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "tests/utils/test_db.py||tests/utils/test_db.py": [
          "File: tests/utils/test_db.py -> tests/utils/test_db.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "40:     compare_server_default,",
          "41:     compare_type,",
          "42:     create_default_connections,",
          "43:     downgrade,",
          "44:     resetdb,",
          "45:     upgradedb,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "43:     # The create_session is not used. It is imported here to",
          "44:     # guard against removing it from utils.db accidentally",
          "45:     create_session,  # noqa: F401",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "d26144bb2071b74920273588dc0c1cb118db8ca3",
      "candidate_info": {
        "commit_hash": "d26144bb2071b74920273588dc0c1cb118db8ca3",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/d26144bb2071b74920273588dc0c1cb118db8ca3",
        "files": [
          "airflow/models/taskmixin.py"
        ],
        "message": "Remove dependency already registered for this task warning (#31502)\n\n(cherry picked from commit abcfc6f76def56c56c0bb15423eab00a837c099a)",
        "before_after_code_files": [
          "airflow/models/taskmixin.py||airflow/models/taskmixin.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/31796"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/models/taskmixin.py||airflow/models/taskmixin.py": [
          "File: airflow/models/taskmixin.py -> airflow/models/taskmixin.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "205:             # If this task does not yet have a dag, add it to the same dag as the other task.",
          "206:             self.dag = dag",
          "215:         for task in task_list:",
          "216:             if dag and not task.has_dag():",
          "217:                 # If the other task does not yet have a dag, add it to the same dag as this task and",
          "218:                 dag.add_task(task)",
          "219:             if upstream:",
          "222:                 if edge_modifier:",
          "223:                     edge_modifier.add_edge_info(self.dag, task.node_id, self.node_id)",
          "224:             else:",
          "227:                 if edge_modifier:",
          "228:                     edge_modifier.add_edge_info(self.dag, self.node_id, task.node_id)",
          "",
          "[Removed Lines]",
          "208:         def add_only_new(obj, item_set: set[str], item: str) -> None:",
          "209:             \"\"\"Adds only new items to item set\"\"\"",
          "210:             if item in item_set:",
          "211:                 self.log.warning(\"Dependency %s, %s already registered for DAG: %s\", obj, item, dag.dag_id)",
          "212:             else:",
          "213:                 item_set.add(item)",
          "220:                 add_only_new(task, task.downstream_task_ids, self.node_id)",
          "221:                 add_only_new(self, self.upstream_task_ids, task.node_id)",
          "225:                 add_only_new(self, self.downstream_task_ids, task.node_id)",
          "226:                 add_only_new(task, task.upstream_task_ids, self.node_id)",
          "",
          "[Added Lines]",
          "213:                 task.downstream_task_ids.add(self.node_id)",
          "214:                 self.upstream_task_ids.add(task.node_id)",
          "218:                 self.downstream_task_ids.add(task.node_id)",
          "219:                 task.upstream_task_ids.add(self.node_id)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "b1e5021c9b256975c249b42cfd659b280a31a359",
      "candidate_info": {
        "commit_hash": "b1e5021c9b256975c249b42cfd659b280a31a359",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/b1e5021c9b256975c249b42cfd659b280a31a359",
        "files": [
          "setup.py"
        ],
        "message": "Rephrase comment in setup.py (#31312)\n\nFollowing up on my late comment in PR #31309, this is a try to rephrase\nthe comment in `setup.py` which indicates how to trigger CI build to use\n\"upgrade to newer dependencies\".\n\n(cherry picked from commit 492acc274b278728069da246c88162f938cb0fb0)",
        "before_after_code_files": [
          "setup.py||setup.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/31796"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "setup.py||setup.py": [
          "File: setup.py -> setup.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "18: \"\"\"Setup.py for the Airflow project.\"\"\"",
          "19: from __future__ import annotations",
          "21: import glob",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19: # To make sure the CI build is using \"upgrade to newer dependencies\", which is useful when you want to check",
          "20: # if the dependencies are still compatible with the latest versions as they seem to break some unrelated",
          "21: # tests in main, you can modify this file. The modification can be simply modifying this particular comment.",
          "22: # e.g. you can modify the following number \"00001\" to something else to trigger it.",
          "",
          "---------------"
        ]
      }
    }
  ]
}