{
  "cve_id": "CVE-2024-36107",
  "cve_desc": "MinIO is a High Performance Object Storage released under GNU Affero General Public License v3.0. `If-Modified-Since` and `If-Unmodified-Since` headers when used with anonymous requests by sending a random object name requests can be used to determine if an object exists or not on the server on a specific bucket and also gain access to some amount of\ninformation such as  `Last-Modified (of the latest version)`, `Etag (of the latest version)`, `x-amz-version-id (of the latest version)`, `Expires (metadata value of the latest version)`, `Cache-Control (metadata value of the latest version)`. This conditional check was being honored before validating if the anonymous access is indeed allowed on the metadata of an object. This issue has been addressed in commit `e0fe7cc3917`. Users must upgrade to RELEASE.2024-05-27T19-17-46Z for the fix. There are no known workarounds for this issue.",
  "repo": "minio/minio",
  "patch_hash": "e0fe7cc391724fc5baa85b45508f425020fe4272",
  "patch_info": {
    "commit_hash": "e0fe7cc391724fc5baa85b45508f425020fe4272",
    "repo": "minio/minio",
    "commit_url": "https://github.com/minio/minio/commit/e0fe7cc391724fc5baa85b45508f425020fe4272",
    "files": [
      ".github/workflows/multipart/migrate.sh",
      ".gitignore",
      "Makefile",
      "buildscripts/rewrite-old-new.sh",
      "buildscripts/verify-healing-empty-erasure-set.sh",
      "buildscripts/verify-healing.sh",
      "cmd/object-handlers.go",
      "docs/bucket/replication/setup_3site_replication.sh",
      "docs/debugging/build.sh",
      "docs/debugging/inspect/go.mod",
      "docs/debugging/pprofgoparser/go.mod",
      "docs/debugging/reorder-disks/go.mod",
      "docs/debugging/reorder-disks/go.sum",
      "docs/debugging/xattr/go.mod",
      "docs/distributed/decom-compressed-sse-s3.sh",
      "docs/distributed/decom-encrypted-kes.sh",
      "docs/distributed/decom-encrypted-sse-s3.sh",
      "docs/distributed/decom-encrypted.sh",
      "docs/distributed/decom.sh"
    ],
    "message": "fix: information disclosure bug in preconditions GET (#19810)\n\nprecondition check was being honored before, validating\nif anonymous access is allowed on the metadata of an\nobject, leading to metadata disclosure of the following\nheaders.\n\n```\nLast-Modified\nEtag\nx-amz-version-id\nExpires:\nCache-Control:\n```\n\nalthough the information presented is minimal in nature,\nand of opaque nature. It still simply discloses that an\nobject by a specific name exists or not without even having\nenough permissions.",
    "before_after_code_files": [
      ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh",
      "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh",
      "buildscripts/verify-healing-empty-erasure-set.sh||buildscripts/verify-healing-empty-erasure-set.sh",
      "buildscripts/verify-healing.sh||buildscripts/verify-healing.sh",
      "cmd/object-handlers.go||cmd/object-handlers.go"
    ]
  },
  "patch_diff": {
    ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh": [
      "File: .github/workflows/multipart/migrate.sh -> .github/workflows/multipart/migrate.sh",
      "--- Hunk 1 ---",
      "[Context before]",
      "24:   chmod +x mc",
      "25: fi",
      "29: export RELEASE=RELEASE.2023-08-29T23-07-35Z",
      "31: docker-compose -f docker-compose-site1.yaml up -d",
      "",
      "[Removed Lines]",
      "27: go install -v github.com/minio/minio/docs/debugging/s3-check-md5@latest",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "46: sleep 5",
      "53: if [ $failed_count_site1 -ne 0 ]; then",
      "54:  echo \"failed with multipart on site1 uploads\"",
      "",
      "[Removed Lines]",
      "48: s3-check-md5 -h",
      "50: failed_count_site1=$(s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site1-nginx:9001 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
      "51: failed_count_site2=$(s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site2-nginx:9002 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
      "",
      "[Added Lines]",
      "46: ./s3-check-md5 -h",
      "48: failed_count_site1=$(./s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site1-nginx:9001 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
      "49: failed_count_site2=$(./s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site2-nginx:9002 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "65: sleep 5",
      "70: ## we do not need to fail here, since we are going to test",
      "71: ## upgrading to master, healing and being able to recover",
      "",
      "[Removed Lines]",
      "67: failed_count_site1=$(s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site1-nginx:9001 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
      "68: failed_count_site2=$(s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site2-nginx:9002 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
      "",
      "[Added Lines]",
      "65: failed_count_site1=$(./s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site1-nginx:9001 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
      "66: failed_count_site2=$(./s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site2-nginx:9002 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "93:  ./mc admin heal -r --remove --json site2/ 2>&1 >/dev/null",
      "94: done",
      "99: if [ $failed_count_site1 -ne 0 ]; then",
      "100:  echo \"failed with multipart on site1 uploads\"",
      "",
      "[Removed Lines]",
      "96: failed_count_site1=$(s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site1-nginx:9001 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
      "97: failed_count_site2=$(s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site2-nginx:9002 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
      "",
      "[Added Lines]",
      "94: failed_count_site1=$(./s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site1-nginx:9001 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
      "95: failed_count_site2=$(./s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site2-nginx:9002 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
      "",
      "---------------"
    ],
    "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh": [
      "File: buildscripts/rewrite-old-new.sh -> buildscripts/rewrite-old-new.sh",
      "--- Hunk 1 ---",
      "[Context before]",
      "45:  \"${MINIO_OLD[@]}\" --address \":$start_port\" \"${WORK_DIR}/xl{1...16}\" >\"${WORK_DIR}/server1.log\" 2>&1 &",
      "46:  pid=$!",
      "47:  disown $pid",
      "50:  if ! ps -p ${pid} 1>&2 >/dev/null; then",
      "51:   echo \"server1 log:\"",
      "",
      "[Removed Lines]",
      "48:  sleep 10",
      "",
      "[Added Lines]",
      "49:  \"${WORK_DIR}/mc\" ready minio/",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "77:  \"${MINIO[@]}\" --address \":$start_port\" \"${WORK_DIR}/xl{1...16}\" >\"${WORK_DIR}/server1.log\" 2>&1 &",
      "78:  pid=$!",
      "79:  disown $pid",
      "82:  if ! ps -p ${pid} 1>&2 >/dev/null; then",
      "83:   echo \"server1 log:\"",
      "",
      "[Removed Lines]",
      "80:  sleep 10",
      "",
      "[Added Lines]",
      "82:  \"${WORK_DIR}/mc\" ready minio/",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "87:   exit 1",
      "88:  fi",
      "93:   -debug \\",
      "94:   -versions \\",
      "95:   -access-key minio \\",
      "96:   -secret-key minio123 \\",
      "98:   echo \"server1 log:\"",
      "99:   cat \"${WORK_DIR}/server1.log\"",
      "100:   echo \"FAILED\"",
      "",
      "[Removed Lines]",
      "90:  go install -v github.com/minio/minio/docs/debugging/s3-check-md5@latest",
      "92:  if ! s3-check-md5 \\",
      "97:   -endpoint http://127.0.0.1:${start_port}/ 2>&1 | grep INTACT; then",
      "",
      "[Added Lines]",
      "92:  if ! ./s3-check-md5 \\",
      "97:   -endpoint \"http://127.0.0.1:${start_port}/\" 2>&1 | grep INTACT; then",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "114:  go run ./buildscripts/heal-manual.go \"127.0.0.1:${start_port}\" \"minio\" \"minio123\"",
      "115:  sleep 1",
      "118:   -debug \\",
      "119:   -versions \\",
      "120:   -access-key minio \\",
      "",
      "[Removed Lines]",
      "117:  if ! s3-check-md5 \\",
      "",
      "[Added Lines]",
      "117:  if ! ./s3-check-md5 \\",
      "",
      "---------------"
    ],
    "buildscripts/verify-healing-empty-erasure-set.sh||buildscripts/verify-healing-empty-erasure-set.sh": [
      "File: buildscripts/verify-healing-empty-erasure-set.sh -> buildscripts/verify-healing-empty-erasure-set.sh",
      "--- Hunk 1 ---",
      "[Context before]",
      "19:  export MINIO_ERASURE_SET_DRIVE_COUNT=6",
      "20:  export MINIO_CI_CD=1",
      "23:  args=\"\"",
      "24:  for i in $(seq 1 3); do",
      "25:   args=\"$args http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/1/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/2/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/3/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/4/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/5/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/6/\"",
      "",
      "[Removed Lines]",
      "22:  start_port=$2",
      "",
      "[Added Lines]",
      "22:  start_port=$1",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "37:  pid3=$!",
      "38:  disown $pid3",
      "42:  if ! ps -p $pid1 1>&2 >/dev/null; then",
      "43:   echo \"server1 log:\"",
      "",
      "[Removed Lines]",
      "40:  sleep \"$1\"",
      "",
      "[Added Lines]",
      "40:  export MC_HOST_myminio=\"http://minio:minio123@127.0.0.1:$((start_port + 1))\"",
      "41:  /tmp/mc ready myminio",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "100:  ## version is purposefully set to '3' for minio to migrate configuration file",
      "101:  echo '{\"version\": \"3\", \"credential\": {\"accessKey\": \"minio\", \"secretKey\": \"minio123\"}, \"region\": \"us-east-1\"}' >\"$MINIO_CONFIG_DIR/config.json\"",
      "102: }",
      "104: function perform_test() {",
      "107:  echo \"Testing Distributed Erasure setup healing of drives\"",
      "108:  echo \"Remove the contents of the disks belonging to '${1}' erasure set\"",
      "",
      "[Removed Lines]",
      "105:  start_minio_3_node 120 $2",
      "",
      "[Added Lines]",
      "104:  if [ ! -f /tmp/mc ]; then",
      "105:   wget --quiet -O /tmp/mc https://dl.minio.io/client/mc/release/linux-amd64/mc &&",
      "106:    chmod +x /tmp/mc",
      "107:  fi",
      "111:  start_minio_3_node $2",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "112:  set -x",
      "115:  rv=$(check_online)",
      "116:  if [ \"$rv\" == \"1\" ]; then",
      "",
      "[Removed Lines]",
      "113:  start_minio_3_node 120 $2",
      "",
      "[Added Lines]",
      "119:  start_minio_3_node $2",
      "",
      "---------------"
    ],
    "buildscripts/verify-healing.sh||buildscripts/verify-healing.sh": [
      "File: buildscripts/verify-healing.sh -> buildscripts/verify-healing.sh",
      "--- Hunk 1 ---",
      "[Context before]",
      "15: GOPATH=/tmp/gopath",
      "17: function start_minio_3_node() {",
      "18:  export MINIO_ROOT_USER=minio",
      "19:  export MINIO_ROOT_PASSWORD=minio123",
      "20:  export MINIO_ERASURE_SET_DRIVE_COUNT=6",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "18:  for i in $(seq 1 3); do",
      "19:   rm \"${WORK_DIR}/dist-minio-server$i.log\"",
      "20:  done",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "23:  first_time=$(find ${WORK_DIR}/ | grep format.json | wc -l)",
      "26:  args=\"\"",
      "27:  for d in $(seq 1 3 5); do",
      "28:   args=\"$args http://127.0.0.1:$((start_port + 1))${WORK_DIR}/1/${d}/ http://127.0.0.1:$((start_port + 2))${WORK_DIR}/2/${d}/ http://127.0.0.1:$((start_port + 3))${WORK_DIR}/3/${d}/ \"",
      "",
      "[Removed Lines]",
      "25:  start_port=$2",
      "",
      "[Added Lines]",
      "29:  start_port=$1",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "42:  pid3=$!",
      "43:  disown $pid3",
      "49:  if ! ps -p $pid1 1>&2 >/dev/null; then",
      "50:   echo \"server1 log:\"",
      "",
      "[Removed Lines]",
      "45:  sleep \"$1\"",
      "47:  [ ${first_time} -eq 0 ] && upload_objects $start_port",
      "",
      "[Added Lines]",
      "49:  export MC_HOST_myminio=\"http://minio:minio123@127.0.0.1:$((start_port + 1))\"",
      "50:  /tmp/mc ready myminio",
      "52:  [ ${first_time} -eq 0 ] && upload_objects",
      "53:  [ ${first_time} -ne 0 ] && sleep 120",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "127: }",
      "129: function upload_objects() {",
      "134:  /tmp/mc mb myminio/testbucket/",
      "135:  for ((i = 0; i < 20; i++)); do",
      "136:   echo \"my content\" | /tmp/mc pipe myminio/testbucket/file-$i",
      "",
      "[Removed Lines]",
      "130:  start_port=$1",
      "132:  /tmp/mc alias set myminio http://127.0.0.1:$((start_port + 1)) minio minio123 --api=s3v4",
      "133:  /tmp/mc ready myminio",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "140: function perform_test() {",
      "141:  start_port=$2",
      "145:  echo \"Testing Distributed Erasure setup healing of drives\"",
      "146:  echo \"Remove the contents of the disks belonging to '${1}' node\"",
      "",
      "[Removed Lines]",
      "143:  start_minio_3_node 120 $start_port",
      "",
      "[Added Lines]",
      "145:  start_minio_3_node $start_port",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "150:  set -x",
      "153:  check_heal ${1}",
      "154:  rv=$?",
      "",
      "[Removed Lines]",
      "151:  start_minio_3_node 120 $start_port",
      "",
      "[Added Lines]",
      "153:  start_minio_3_node $start_port",
      "",
      "---------------"
    ],
    "cmd/object-handlers.go||cmd/object-handlers.go": [
      "File: cmd/object-handlers.go -> cmd/object-handlers.go",
      "--- Hunk 1 ---",
      "[Context before]",
      "476:    return true",
      "477:   }",
      "479:   return checkPreconditions(ctx, w, r, oi, opts)",
      "480:  }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "479:   if oi.UserTags != \"\" {",
      "480:    r.Header.Set(xhttp.AmzObjectTagging, oi.UserTags)",
      "481:   }",
      "483:   if s3Error := authorizeRequest(ctx, r, policy.GetObjectAction); s3Error != ErrNone {",
      "484:    writeErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL)",
      "485:    return true",
      "486:   }",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "548:  objInfo := gr.ObjInfo",
      "559:  if !proxy.Proxy { // apply lifecycle rules only for local requests",
      "561:   if lc, err := globalLifecycleSys.Get(bucket); err == nil {",
      "",
      "[Removed Lines]",
      "550:  if objInfo.UserTags != \"\" {",
      "551:   r.Header.Set(xhttp.AmzObjectTagging, objInfo.UserTags)",
      "552:  }",
      "554:  if s3Error := authorizeRequest(ctx, r, policy.GetObjectAction); s3Error != ErrNone {",
      "555:   writeErrorResponse(ctx, w, errorCodes.ToAPIErr(s3Error), r.URL)",
      "556:   return",
      "557:  }",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "b6e98aed0161bb526aaf11fa1672d30eb89dca4b",
      "candidate_info": {
        "commit_hash": "b6e98aed0161bb526aaf11fa1672d30eb89dca4b",
        "repo": "minio/minio",
        "commit_url": "https://github.com/minio/minio/commit/b6e98aed0161bb526aaf11fa1672d30eb89dca4b",
        "files": [
          ".github/workflows/multipart/migrate.sh",
          "Makefile",
          "buildscripts/rewrite-old-new.sh",
          "cmd/background-newdisks-heal-ops.go",
          "cmd/bucket-replication.go",
          "cmd/metrics-resource.go",
          "cmd/peer-rest-server.go",
          "cmd/peer-s3-server.go",
          "docs/bucket/replication/delete-replication.sh",
          "docs/bucket/replication/setup_3site_replication.sh",
          "docs/debugging/s3-check-md5/main.go",
          "docs/distributed/decom-compressed-sse-s3.sh",
          "docs/distributed/decom-encrypted-sse-s3.sh",
          "docs/distributed/decom-encrypted.sh",
          "docs/distributed/decom.sh",
          "go.mod",
          "go.sum"
        ],
        "message": "fix: found races in accessing globalLocalDrives (#19069)\n\nmake a copy before accessing globalLocalDrives\n\nBonus: update console v0.46.0\n\nSigned-off-by: Harshavardhana <harsha@minio.io>",
        "before_after_code_files": [
          ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh",
          "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh",
          "cmd/background-newdisks-heal-ops.go||cmd/background-newdisks-heal-ops.go",
          "cmd/bucket-replication.go||cmd/bucket-replication.go",
          "cmd/metrics-resource.go||cmd/metrics-resource.go",
          "cmd/peer-rest-server.go||cmd/peer-rest-server.go",
          "cmd/peer-s3-server.go||cmd/peer-s3-server.go",
          "go.mod||go.mod",
          "go.sum||go.sum"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh",
            "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh"
          ],
          "candidate": [
            ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh",
            "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh"
          ]
        }
      },
      "candidate_diff": {
        ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh": [
          "File: .github/workflows/multipart/migrate.sh -> .github/workflows/multipart/migrate.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "25: fi",
          "27: (",
          "30: )",
          "32: export RELEASE=RELEASE.2023-08-29T23-07-35Z",
          "",
          "[Removed Lines]",
          "28:  cd /tmp",
          "29:  go install github.com/minio/minio/docs/debugging/s3-check-md5@master",
          "",
          "[Added Lines]",
          "28:  cd ./docs/debugging/s3-check-md5",
          "29:  go install -v",
          "",
          "---------------"
        ],
        "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh": [
          "File: buildscripts/rewrite-old-new.sh -> buildscripts/rewrite-old-new.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "87:   exit 1",
          "88:  fi",
          "91:  if ! s3-check-md5 \\",
          "92:   -debug \\",
          "93:   -versions \\",
          "",
          "[Removed Lines]",
          "90:  go install github.com/minio/minio/docs/debugging/s3-check-md5@master",
          "",
          "[Added Lines]",
          "90:  (",
          "91:   cd ./docs/debugging/s3-check-md5",
          "92:   go install -v",
          "93:  )",
          "",
          "---------------"
        ],
        "cmd/background-newdisks-heal-ops.go||cmd/background-newdisks-heal-ops.go": [
          "File: cmd/background-newdisks-heal-ops.go -> cmd/background-newdisks-heal-ops.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "354: func getLocalDisksToHeal() (disksToHeal Endpoints) {",
          "355:  globalLocalDrivesMu.RLock()",
          "357:  globalLocalDrivesMu.RUnlock()",
          "358:  for _, disk := range localDrives {",
          "359:   _, err := disk.GetDiskID()",
          "",
          "[Removed Lines]",
          "356:  localDrives := globalLocalDrives",
          "",
          "[Added Lines]",
          "356:  localDrives := cloneDrives(globalLocalDrives)",
          "",
          "---------------"
        ],
        "cmd/bucket-replication.go||cmd/bucket-replication.go": [
          "File: cmd/bucket-replication.go -> cmd/bucket-replication.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "3393:  }",
          "3395:  globalLocalDrivesMu.RLock()",
          "3397:  globalLocalDrivesMu.RUnlock()",
          "3399:  for _, localDrive := range localDrives {",
          "",
          "[Removed Lines]",
          "3396:  localDrives := globalLocalDrives",
          "",
          "[Added Lines]",
          "3396:  localDrives := cloneDrives(globalLocalDrives)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "3460:  }",
          "3462:  globalLocalDrivesMu.RLock()",
          "3464:  globalLocalDrivesMu.RUnlock()",
          "3466:  for _, localDrive := range localDrives {",
          "",
          "[Removed Lines]",
          "3463:  localDrives := globalLocalDrives",
          "",
          "[Added Lines]",
          "3463:  localDrives := cloneDrives(globalLocalDrives)",
          "",
          "---------------"
        ],
        "cmd/metrics-resource.go||cmd/metrics-resource.go": [
          "File: cmd/metrics-resource.go -> cmd/metrics-resource.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "274:  }",
          "276:  globalLocalDrivesMu.RLock()",
          "278:  globalLocalDrivesMu.RUnlock()",
          "280:  for _, d := range localDrives {",
          "",
          "[Removed Lines]",
          "277:  localDrives := globalLocalDrives",
          "",
          "[Added Lines]",
          "277:  localDrives := cloneDrives(globalLocalDrives)",
          "",
          "---------------"
        ],
        "cmd/peer-rest-server.go||cmd/peer-rest-server.go": [
          "File: cmd/peer-rest-server.go -> cmd/peer-rest-server.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "787: func waitingDrivesNode() map[string]madmin.DiskMetrics {",
          "788:  globalLocalDrivesMu.RLock()",
          "790:  globalLocalDrivesMu.RUnlock()",
          "792:  errs := make([]error, len(localDrives))",
          "",
          "[Removed Lines]",
          "789:  localDrives := globalLocalDrives",
          "",
          "[Added Lines]",
          "789:  localDrives := cloneDrives(globalLocalDrives)",
          "",
          "---------------"
        ],
        "cmd/peer-s3-server.go||cmd/peer-s3-server.go": [
          "File: cmd/peer-s3-server.go -> cmd/peer-s3-server.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "83: func healBucketLocal(ctx context.Context, bucket string, opts madmin.HealOpts) (res madmin.HealResultItem, err error) {",
          "84:  globalLocalDrivesMu.RLock()",
          "86:  globalLocalDrivesMu.RUnlock()",
          "",
          "[Removed Lines]",
          "85:  localDrives := globalLocalDrives",
          "",
          "[Added Lines]",
          "85:  localDrives := cloneDrives(globalLocalDrives)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "207: func listBucketsLocal(ctx context.Context, opts BucketOptions) (buckets []BucketInfo, err error) {",
          "208:  globalLocalDrivesMu.RLock()",
          "210:  globalLocalDrivesMu.RUnlock()",
          "212:  quorum := (len(localDrives) / 2)",
          "",
          "[Removed Lines]",
          "209:  localDrives := globalLocalDrives",
          "",
          "[Added Lines]",
          "209:  localDrives := cloneDrives(globalLocalDrives)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "252:  return buckets, nil",
          "253: }",
          "255: func getBucketInfoLocal(ctx context.Context, bucket string, opts BucketOptions) (BucketInfo, error) {",
          "256:  globalLocalDrivesMu.RLock()",
          "258:  globalLocalDrivesMu.RUnlock()",
          "260:  g := errgroup.WithNErrs(len(localDrives)).WithConcurrency(32)",
          "",
          "[Removed Lines]",
          "257:  localDrives := globalLocalDrives",
          "",
          "[Added Lines]",
          "255: func cloneDrives(drives []StorageAPI) []StorageAPI {",
          "256:  newDrives := make([]StorageAPI, len(drives))",
          "257:  copy(newDrives, drives)",
          "258:  return newDrives",
          "259: }",
          "263:  localDrives := cloneDrives(globalLocalDrives)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "304: func deleteBucketLocal(ctx context.Context, bucket string, opts DeleteBucketOptions) error {",
          "305:  globalLocalDrivesMu.RLock()",
          "307:  globalLocalDrivesMu.RUnlock()",
          "309:  g := errgroup.WithNErrs(len(localDrives)).WithConcurrency(32)",
          "",
          "[Removed Lines]",
          "306:  localDrives := globalLocalDrives",
          "",
          "[Added Lines]",
          "312:  localDrives := cloneDrives(globalLocalDrives)",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "342: func makeBucketLocal(ctx context.Context, bucket string, opts MakeBucketOptions) error {",
          "343:  globalLocalDrivesMu.RLock()",
          "345:  globalLocalDrivesMu.RUnlock()",
          "347:  g := errgroup.WithNErrs(len(localDrives)).WithConcurrency(32)",
          "",
          "[Removed Lines]",
          "344:  localDrives := globalLocalDrives",
          "",
          "[Added Lines]",
          "350:  localDrives := cloneDrives(globalLocalDrives)",
          "",
          "---------------"
        ],
        "go.mod||go.mod": [
          "File: go.mod -> go.mod",
          "--- Hunk 1 ---",
          "[Context before]",
          "45:  github.com/lithammer/shortuuid/v4 v4.0.0",
          "46:  github.com/miekg/dns v1.1.58",
          "47:  github.com/minio/cli v1.24.2",
          "49:  github.com/minio/csvparser v1.0.0",
          "50:  github.com/minio/dnscache v0.1.1",
          "51:  github.com/minio/dperf v0.5.3",
          "",
          "[Removed Lines]",
          "48:  github.com/minio/console v0.45.1-0.20240213061721-ee4d7b9b6940",
          "",
          "[Added Lines]",
          "48:  github.com/minio/console v0.46.0",
          "",
          "---------------"
        ],
        "go.sum||go.sum": [
          "File: go.sum -> go.sum",
          "--- Hunk 1 ---",
          "[Context before]",
          "432: github.com/minio/cli v1.24.2/go.mod h1:bYxnK0uS629N3Bq+AOZZ+6lwF77Sodk4+UL9vNuXhOY=",
          "433: github.com/minio/colorjson v1.0.6 h1:m7TUvpvt0u7FBmVIEQNIa0T4NBQlxrcMBp4wJKsg2Ik=",
          "434: github.com/minio/colorjson v1.0.6/go.mod h1:LUXwS5ZGNb6Eh9f+t+3uJiowD3XsIWtsvTriUBeqgYs=",
          "437: github.com/minio/csvparser v1.0.0 h1:xJEHcYK8ZAjeW4hNV9Zu30u+/2o4UyPnYgyjWp8b7ZU=",
          "438: github.com/minio/csvparser v1.0.0/go.mod h1:lKXskSLzPgC5WQyzP7maKH7Sl1cqvANXo9YCto8zbtM=",
          "439: github.com/minio/dnscache v0.1.1 h1:AMYLqomzskpORiUA1ciN9k7bZT1oB3YZN4cEIi88W5o=",
          "",
          "[Removed Lines]",
          "435: github.com/minio/console v0.45.1-0.20240213061721-ee4d7b9b6940 h1:DdXAWKUmiSMFS3pPG351kwYo2YlC0EaKKCNStAmd7xo=",
          "436: github.com/minio/console v0.45.1-0.20240213061721-ee4d7b9b6940/go.mod h1:VvJdNfELVCc2VELF1rJtIPCb3FcWGtNfM/Ktvnu2MZ0=",
          "",
          "[Added Lines]",
          "435: github.com/minio/console v0.46.0 h1:So7y3csQl7m3Llaxmbg5xiTCwlElUol8kUyVOViBRFY=",
          "436: github.com/minio/console v0.46.0/go.mod h1:VvJdNfELVCc2VELF1rJtIPCb3FcWGtNfM/Ktvnu2MZ0=",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "e1e33077e8f56cdc51fe12555fca9bf45b61d3bd",
      "candidate_info": {
        "commit_hash": "e1e33077e8f56cdc51fe12555fca9bf45b61d3bd",
        "repo": "minio/minio",
        "commit_url": "https://github.com/minio/minio/commit/e1e33077e8f56cdc51fe12555fca9bf45b61d3bd",
        "files": [
          "buildscripts/rewrite-old-new.sh",
          "buildscripts/unaligned-healing.sh",
          "cmd/bucket-replication.go",
          "cmd/xl-storage.go",
          "docs/bucket/replication/setup_3site_replication.sh"
        ],
        "message": "fix: tests and resync replication status (#18244)",
        "before_after_code_files": [
          "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh",
          "buildscripts/unaligned-healing.sh||buildscripts/unaligned-healing.sh",
          "cmd/bucket-replication.go||cmd/bucket-replication.go",
          "cmd/xl-storage.go||cmd/xl-storage.go"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh"
          ],
          "candidate": [
            "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh"
          ]
        }
      },
      "candidate_diff": {
        "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh": [
          "File: buildscripts/rewrite-old-new.sh -> buildscripts/rewrite-old-new.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "87:   exit 1",
          "88:  fi",
          "92:   -debug \\",
          "93:   -versions \\",
          "94:   -access-key minio \\",
          "",
          "[Removed Lines]",
          "90:  go build ./docs/debugging/s3-check-md5/",
          "91:  if ! ./s3-check-md5 \\",
          "",
          "[Added Lines]",
          "90:  go install github.com/minio/minio/docs/debugging/s3-check-md5@latest",
          "91:  if ! s3-check-md5 \\",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "113:  go run ./buildscripts/heal-manual.go \"127.0.0.1:${start_port}\" \"minio\" \"minio123\"",
          "114:  sleep 1",
          "117:   -debug \\",
          "118:   -versions \\",
          "119:   -access-key minio \\",
          "",
          "[Removed Lines]",
          "116:  if ! ./s3-check-md5 \\",
          "",
          "[Added Lines]",
          "116:  if ! s3-check-md5 \\",
          "",
          "---------------"
        ],
        "buildscripts/unaligned-healing.sh||buildscripts/unaligned-healing.sh": [
          "File: buildscripts/unaligned-healing.sh -> buildscripts/unaligned-healing.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "82:  rm -rf \"${WORK_DIR}/xl3/healing-shard-bucket/unaligned\"",
          "83:  sleep 10",
          "87:   -debug \\",
          "88:   -access-key minio \\",
          "89:   -secret-key minio123 \\",
          "",
          "[Removed Lines]",
          "85:  go build ./docs/debugging/s3-check-md5/",
          "86:  if ! ./s3-check-md5 \\",
          "",
          "[Added Lines]",
          "85:  go install github.com/minio/minio/docs/debugging/s3-check-md5@latest",
          "86:  if ! s3-check-md5 \\",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "111:   exit 1",
          "112:  fi",
          "115:   -debug \\",
          "116:   -access-key minio \\",
          "117:   -secret-key minio123 \\",
          "",
          "[Removed Lines]",
          "114:  if ! ./s3-check-md5 \\",
          "",
          "[Added Lines]",
          "114:  if ! s3-check-md5 \\",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "135:  \"${WORK_DIR}/mc\" admin heal --quiet --recursive minio/healing-shard-bucket",
          "138:   -debug \\",
          "139:   -access-key minio \\",
          "140:   -secret-key minio123 \\",
          "",
          "[Removed Lines]",
          "137:  if ! ./s3-check-md5 \\",
          "",
          "[Added Lines]",
          "137:  if ! s3-check-md5 \\",
          "",
          "---------------"
        ],
        "cmd/bucket-replication.go||cmd/bucket-replication.go": [
          "File: cmd/bucket-replication.go -> cmd/bucket-replication.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "2487: }",
          "2491:  s.Lock()",
          "2492:  defer s.Unlock()",
          "",
          "[Removed Lines]",
          "2490: func (s *replicationResyncer) markStatus(status ResyncStatusType, opts resyncOpts) {",
          "",
          "[Added Lines]",
          "2490: func (s *replicationResyncer) markStatus(status ResyncStatusType, opts resyncOpts, objAPI ObjectLayer) {",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "2498:  m.TargetsMap[opts.arn] = st",
          "2499:  m.LastUpdate = UTCNow()",
          "2500:  s.statusMap[opts.bucket] = m",
          "2501: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "2502:  ctx, cancel := context.WithTimeout(context.Background(), time.Second)",
          "2503:  defer cancel()",
          "2504:  saveResyncStatus(ctx, opts.bucket, m, objAPI)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "2528:  resyncStatus := ResyncFailed",
          "2529:  defer func() {",
          "2531:   globalSiteResyncMetrics.incBucket(opts, resyncStatus)",
          "2532:   s.workerCh <- struct{}{}",
          "2533:  }()",
          "",
          "[Removed Lines]",
          "2530:   s.markStatus(resyncStatus, opts)",
          "",
          "[Added Lines]",
          "2534:   s.markStatus(resyncStatus, opts, objectAPI)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "2563:  }",
          "2565:  if !heal {",
          "2567:  }",
          "",
          "[Removed Lines]",
          "2566:   s.markStatus(ResyncStarted, opts)",
          "",
          "[Added Lines]",
          "2570:   s.markStatus(ResyncStarted, opts, objectAPI)",
          "",
          "---------------"
        ],
        "cmd/xl-storage.go||cmd/xl-storage.go": [
          "File: cmd/xl-storage.go -> cmd/xl-storage.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "1061:   return s.WriteAll(ctx, volume, pathJoin(path, xlStorageFormatFile), buf)",
          "1062:  }",
          "1070: }",
          "",
          "[Removed Lines]",
          "1065:  err = s.moveToTrash(pathJoin(volumeDir, path, xlStorageFormatFile), false, false)",
          "1066:  if err == nil || err == errFileNotFound {",
          "1067:   s.deleteFile(volumeDir, pathJoin(volumeDir, path), false, false)",
          "1068:  }",
          "1069:  return err",
          "",
          "[Added Lines]",
          "1064:  return s.deleteFile(volumeDir, pathJoin(volumeDir, path), true, false)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "c50627ee3e2df55bd41c68c3d7177991942547b0",
      "candidate_info": {
        "commit_hash": "c50627ee3e2df55bd41c68c3d7177991942547b0",
        "repo": "minio/minio",
        "commit_url": "https://github.com/minio/minio/commit/c50627ee3e2df55bd41c68c3d7177991942547b0",
        "files": [
          ".github/workflows/mint.yml",
          ".github/workflows/mint/minio-compress-encrypt.yaml",
          ".github/workflows/mint/minio-erasure.yaml",
          ".github/workflows/mint/minio-pools.yaml",
          ".github/workflows/multipart/docker-compose-site1.yaml",
          ".github/workflows/multipart/docker-compose-site2.yaml",
          ".github/workflows/multipart/migrate.sh",
          ".github/workflows/multipart/nginx-site1.conf",
          ".github/workflows/multipart/nginx-site2.conf",
          "Makefile"
        ],
        "message": "Add tests for multipart upload overwrites on versioned buckets (#18142)",
        "before_after_code_files": [
          ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh",
          ".github/workflows/multipart/nginx-site1.conf||.github/workflows/multipart/nginx-site1.conf",
          ".github/workflows/multipart/nginx-site2.conf||.github/workflows/multipart/nginx-site2.conf"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh"
          ],
          "candidate": [
            ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh"
          ]
        }
      },
      "candidate_diff": {
        ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh": [
          "File: .github/workflows/multipart/migrate.sh -> .github/workflows/multipart/migrate.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: #!/bin/bash",
          "3: set -x",
          "5: ## change working directory",
          "6: cd .github/workflows/multipart/",
          "8: docker-compose -f docker-compose-site1.yaml rm -s -f",
          "9: docker-compose -f docker-compose-site2.yaml rm -s -f",
          "10: for volume in $(docker volume ls -q | grep minio); do",
          "11:  docker volume rm ${volume}",
          "12: done",
          "14: if [ ! -f ./mc ]; then",
          "15:  wget --quiet -O mc https://dl.minio.io/client/mc/release/linux-amd64/mc &&",
          "16:   chmod +x mc",
          "17: fi",
          "19: (",
          "20:  cd /tmp",
          "21:  go install github.com/minio/minio/docs/debugging/s3-check-md5@latest",
          "22: )",
          "24: export RELEASE=RELEASE.2023-08-29T23-07-35Z",
          "26: docker-compose -f docker-compose-site1.yaml up -d",
          "27: docker-compose -f docker-compose-site2.yaml up -d",
          "29: sleep 30",
          "31: mc alias set site1 http://site1-nginx:9001 minioadmin minioadmin --api s3v4",
          "32: mc alias set site2 http://site2-nginx:9002 minioadmin minioadmin --api s3v4",
          "34: ./mc ready site1/",
          "35: ./mc ready site2/",
          "37: ./mc admin replicate add site1 site2",
          "38: ./mc mb site1/testbucket/",
          "39: ./mc cp -r --quiet /usr/bin site1/testbucket/",
          "41: sleep 5",
          "43: s3-check-md5 -h",
          "45: failed_count_site1=$(s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site1-nginx:9001 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
          "46: failed_count_site2=$(s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site2-nginx:9002 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
          "48: if [ $failed_count_site1 -ne 0 ]; then",
          "49:  echo \"failed with multipart on site1 uploads\"",
          "50:  exit 1",
          "51: fi",
          "53: if [ $failed_count_site2 -ne 0 ]; then",
          "54:  echo \"failed with multipart on site2 uploads\"",
          "55:  exit 1",
          "56: fi",
          "58: ./mc cp -r --quiet /usr/bin site1/testbucket/",
          "60: sleep 5",
          "62: failed_count_site1=$(s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site1-nginx:9001 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
          "63: failed_count_site2=$(s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site2-nginx:9002 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
          "65: ## we do not need to fail here, since we are going to test",
          "66: ## upgrading to master, healing and being able to recover",
          "67: ## the last version.",
          "68: if [ $failed_count_site1 -ne 0 ]; then",
          "69:  echo \"failed with multipart on site1 uploads ${failed_count_site1}\"",
          "70: fi",
          "72: if [ $failed_count_site2 -ne 0 ]; then",
          "73:  echo \"failed with multipart on site2 uploads ${failed_count_site2}\"",
          "74: fi",
          "76: export RELEASE=${1}",
          "78: docker-compose -f docker-compose-site1.yaml up -d",
          "79: docker-compose -f docker-compose-site2.yaml up -d",
          "81: ./mc ready site1/",
          "82: ./mc ready site2/",
          "84: ./mc admin heal -r --remove --json site1/ 2>&1 >/dev/null",
          "85: ./mc admin heal -r --remove --json site2/ 2>&1 >/dev/null",
          "87: failed_count_site1=$(s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site1-nginx:9001 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
          "88: failed_count_site2=$(s3-check-md5 -versions -access-key minioadmin -secret-key minioadmin -endpoint http://site2-nginx:9002 -bucket testbucket 2>&1 | grep FAILED | wc -l)",
          "90: if [ $failed_count_site1 -ne 0 ]; then",
          "91:  echo \"failed with multipart on site1 uploads\"",
          "92:  exit 1",
          "93: fi",
          "95: if [ $failed_count_site2 -ne 0 ]; then",
          "96:  echo \"failed with multipart on site2 uploads\"",
          "97:  exit 1",
          "98: fi",
          "100: docker-compose -f docker-compose-site1.yaml rm -s -f",
          "101: docker-compose -f docker-compose-site2.yaml rm -s -f",
          "102: for volume in $(docker volume ls -q | grep minio); do",
          "103:  docker volume rm ${volume}",
          "104: done",
          "106: docker system prune -f || true",
          "107: docker volume prune -f || true",
          "108: docker volume rm $(docker volume ls -q -f dangling=true) || true",
          "110: ## change working directory",
          "111: cd ../../../",
          "",
          "---------------"
        ],
        ".github/workflows/multipart/nginx-site1.conf||.github/workflows/multipart/nginx-site1.conf": [
          "File: .github/workflows/multipart/nginx-site1.conf -> .github/workflows/multipart/nginx-site1.conf",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: user  nginx;",
          "2: worker_processes  auto;",
          "4: error_log  /var/log/nginx/error.log warn;",
          "5: pid        /var/run/nginx.pid;",
          "7: events {",
          "8:     worker_connections  4096;",
          "9: }",
          "11: http {",
          "12:     include       /etc/nginx/mime.types;",
          "13:     default_type  application/octet-stream;",
          "15:     log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '",
          "16:                       '$status $body_bytes_sent \"$http_referer\" '",
          "17:                       '\"$http_user_agent\" \"$http_x_forwarded_for\"';",
          "19:     access_log  /var/log/nginx/access.log  main;",
          "20:     sendfile        on;",
          "21:     keepalive_timeout  65;",
          "23:     # include /etc/nginx/conf.d/*.conf;",
          "25:     upstream minio {",
          "26:         server site1-minio1:9000;",
          "27:         server site1-minio2:9000;",
          "28:         server site1-minio3:9000;",
          "29:         server site1-minio4:9000;",
          "30:     }",
          "32:     server {",
          "33:         listen       9001;",
          "34:         listen  [::]:9001;",
          "35:         server_name  localhost;",
          "37:         # To allow special characters in headers",
          "38:         ignore_invalid_headers off;",
          "39:         # Allow any size file to be uploaded.",
          "40:         # Set to a value such as 1000m; to restrict file size to a specific value",
          "41:         client_max_body_size 0;",
          "42:         # To disable buffering",
          "43:         proxy_buffering off;",
          "44:         proxy_request_buffering off;",
          "46:         location / {",
          "47:             proxy_set_header Host $http_host;",
          "48:             proxy_set_header X-Real-IP $remote_addr;",
          "49:             proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;",
          "50:             proxy_set_header X-Forwarded-Proto $scheme;",
          "52:             proxy_connect_timeout 300;",
          "53:             # Default is HTTP/1, keepalive is only enabled in HTTP/1.1",
          "54:             proxy_http_version 1.1;",
          "55:             proxy_set_header Connection \"\";",
          "56:             chunked_transfer_encoding off;",
          "58:             proxy_pass http://minio;",
          "59:         }",
          "60:     }",
          "61: }",
          "",
          "---------------"
        ],
        ".github/workflows/multipart/nginx-site2.conf||.github/workflows/multipart/nginx-site2.conf": [
          "File: .github/workflows/multipart/nginx-site2.conf -> .github/workflows/multipart/nginx-site2.conf",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: user  nginx;",
          "2: worker_processes  auto;",
          "4: error_log  /var/log/nginx/error.log warn;",
          "5: pid        /var/run/nginx.pid;",
          "7: events {",
          "8:     worker_connections  4096;",
          "9: }",
          "11: http {",
          "12:     include       /etc/nginx/mime.types;",
          "13:     default_type  application/octet-stream;",
          "15:     log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '",
          "16:                       '$status $body_bytes_sent \"$http_referer\" '",
          "17:                       '\"$http_user_agent\" \"$http_x_forwarded_for\"';",
          "19:     access_log  /var/log/nginx/access.log  main;",
          "20:     sendfile        on;",
          "21:     keepalive_timeout  65;",
          "23:     # include /etc/nginx/conf.d/*.conf;",
          "25:     upstream minio {",
          "26:         server site2-minio1:9000;",
          "27:         server site2-minio2:9000;",
          "28:         server site2-minio3:9000;",
          "29:         server site2-minio4:9000;",
          "30:     }",
          "32:     server {",
          "33:         listen       9002;",
          "34:         listen  [::]:9002;",
          "35:         server_name  localhost;",
          "37:         # To allow special characters in headers",
          "38:         ignore_invalid_headers off;",
          "39:         # Allow any size file to be uploaded.",
          "40:         # Set to a value such as 1000m; to restrict file size to a specific value",
          "41:         client_max_body_size 0;",
          "42:         # To disable buffering",
          "43:         proxy_buffering off;",
          "44:         proxy_request_buffering off;",
          "46:         location / {",
          "47:             proxy_set_header Host $http_host;",
          "48:             proxy_set_header X-Real-IP $remote_addr;",
          "49:             proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;",
          "50:             proxy_set_header X-Forwarded-Proto $scheme;",
          "52:             proxy_connect_timeout 300;",
          "53:             # Default is HTTP/1, keepalive is only enabled in HTTP/1.1",
          "54:             proxy_http_version 1.1;",
          "55:             proxy_set_header Connection \"\";",
          "56:             chunked_transfer_encoding off;",
          "58:             proxy_pass http://minio;",
          "59:         }",
          "60:     }",
          "61: }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "630963fa6bd0072acd07f7cb3966857b10735107",
      "candidate_info": {
        "commit_hash": "630963fa6bd0072acd07f7cb3966857b10735107",
        "repo": "minio/minio",
        "commit_url": "https://github.com/minio/minio/commit/630963fa6bd0072acd07f7cb3966857b10735107",
        "files": [
          ".github/workflows/multipart/migrate.sh",
          "buildscripts/rewrite-old-new.sh",
          "cmd/admin-heal-ops.go"
        ],
        "message": "protect tracker copy properly to avoid race (#18984)\n\n```\nWARNING: DATA RACE\nWrite at 0x00c000aac1e0 by goroutine 1133:\n  github.com/minio/minio/cmd.(*healingTracker).updateProgress()\n      github.com/minio/minio/cmd/background-newdisks-heal-ops.go:183 +0x117\n  github.com/minio/minio/cmd.(*erasureObjects).healErasureSet.func5()\n      github.com/minio/minio/cmd/global-heal.go:292 +0x1d3\n\nPrevious read at 0x00c000aac1e0 by goroutine 1003:\n  github.com/minio/minio/cmd.(*allHealState).updateHealStatus()\n      github.com/minio/minio/cmd/admin-heal-ops.go:136 +0xcb\n  github.com/minio/minio/cmd.(*healingTracker).save()\n      github.com/minio/minio/cmd/background-newdisks-heal-ops.go:223 +0x424\n```",
        "before_after_code_files": [
          ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh",
          "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh",
          "cmd/admin-heal-ops.go||cmd/admin-heal-ops.go"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh",
            "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh"
          ],
          "candidate": [
            ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh",
            "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh"
          ]
        }
      },
      "candidate_diff": {
        ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh": [
          "File: .github/workflows/multipart/migrate.sh -> .github/workflows/multipart/migrate.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "27: (",
          "28:  cd /tmp",
          "30: )",
          "32: export RELEASE=RELEASE.2023-08-29T23-07-35Z",
          "",
          "[Removed Lines]",
          "29:  go install github.com/minio/minio/docs/debugging/s3-check-md5@latest",
          "",
          "[Added Lines]",
          "29:  go install github.com/minio/minio/docs/debugging/s3-check-md5@master",
          "",
          "---------------"
        ],
        "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh": [
          "File: buildscripts/rewrite-old-new.sh -> buildscripts/rewrite-old-new.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "87:   exit 1",
          "88:  fi",
          "91:  if ! s3-check-md5 \\",
          "92:   -debug \\",
          "93:   -versions \\",
          "",
          "[Removed Lines]",
          "90:  go install github.com/minio/minio/docs/debugging/s3-check-md5@latest",
          "",
          "[Added Lines]",
          "90:  go install github.com/minio/minio/docs/debugging/s3-check-md5@master",
          "",
          "---------------"
        ],
        "cmd/admin-heal-ops.go||cmd/admin-heal-ops.go": [
          "File: cmd/admin-heal-ops.go -> cmd/admin-heal-ops.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "133: func (ahs *allHealState) updateHealStatus(tracker *healingTracker) {",
          "134:  ahs.Lock()",
          "135:  defer ahs.Unlock()",
          "137: }",
          "",
          "[Removed Lines]",
          "136:  ahs.healStatus[tracker.ID] = *tracker",
          "",
          "[Added Lines]",
          "137:  tracker.mu.RLock()",
          "138:  t := *tracker",
          "139:  t.QueuedBuckets = append(make([]string, 0, len(tracker.QueuedBuckets)), tracker.QueuedBuckets...)",
          "140:  t.HealedBuckets = append(make([]string, 0, len(tracker.HealedBuckets)), tracker.HealedBuckets...)",
          "141:  ahs.healStatus[tracker.ID] = t",
          "142:  tracker.mu.RUnlock()",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "9a3c992d7a2729e865940e7031f158fcf831144a",
      "candidate_info": {
        "commit_hash": "9a3c992d7a2729e865940e7031f158fcf831144a",
        "repo": "minio/minio",
        "commit_url": "https://github.com/minio/minio/commit/9a3c992d7a2729e865940e7031f158fcf831144a",
        "files": [
          "Makefile",
          "buildscripts/verify-healing-empty-erasure-set.sh",
          "buildscripts/verify-healing.sh",
          "cmd/global-heal.go"
        ],
        "message": "heal: Fix regression in healing a new fresh drive (#19615)",
        "before_after_code_files": [
          "buildscripts/verify-healing-empty-erasure-set.sh||buildscripts/verify-healing-empty-erasure-set.sh",
          "buildscripts/verify-healing.sh||buildscripts/verify-healing.sh",
          "cmd/global-heal.go||cmd/global-heal.go"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "buildscripts/verify-healing-empty-erasure-set.sh||buildscripts/verify-healing-empty-erasure-set.sh",
            "buildscripts/verify-healing.sh||buildscripts/verify-healing.sh"
          ],
          "candidate": [
            "buildscripts/verify-healing-empty-erasure-set.sh||buildscripts/verify-healing-empty-erasure-set.sh",
            "buildscripts/verify-healing.sh||buildscripts/verify-healing.sh"
          ]
        }
      },
      "candidate_diff": {
        "buildscripts/verify-healing-empty-erasure-set.sh||buildscripts/verify-healing-empty-erasure-set.sh": [
          "File: buildscripts/verify-healing-empty-erasure-set.sh -> buildscripts/verify-healing-empty-erasure-set.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: #!/bin/bash -e",
          "2: #",
          "4: set -E",
          "5: set -o pipefail",
          "7: if [ ! -x \"$PWD/minio\" ]; then",
          "8:  echo \"minio executable binary not found in current directory\"",
          "9:  exit 1",
          "10: fi",
          "12: WORK_DIR=\"$PWD/.verify-$RANDOM\"",
          "13: MINIO_CONFIG_DIR=\"$WORK_DIR/.minio\"",
          "14: MINIO=(\"$PWD/minio\" --config-dir \"$MINIO_CONFIG_DIR\" server)",
          "16: function start_minio_3_node() {",
          "17:  export MINIO_ROOT_USER=minio",
          "18:  export MINIO_ROOT_PASSWORD=minio123",
          "19:  export MINIO_ERASURE_SET_DRIVE_COUNT=6",
          "20:  export MINIO_CI_CD=1",
          "22:  start_port=$2",
          "23:  args=\"\"",
          "24:  for i in $(seq 1 3); do",
          "25:   args=\"$args http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/1/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/2/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/3/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/4/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/5/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/6/\"",
          "26:  done",
          "28:  \"${MINIO[@]}\" --address \":$((start_port + 1))\" $args >\"${WORK_DIR}/dist-minio-server1.log\" 2>&1 &",
          "29:  pid1=$!",
          "30:  disown ${pid1}",
          "32:  \"${MINIO[@]}\" --address \":$((start_port + 2))\" $args >\"${WORK_DIR}/dist-minio-server2.log\" 2>&1 &",
          "33:  pid2=$!",
          "34:  disown $pid2",
          "36:  \"${MINIO[@]}\" --address \":$((start_port + 3))\" $args >\"${WORK_DIR}/dist-minio-server3.log\" 2>&1 &",
          "37:  pid3=$!",
          "38:  disown $pid3",
          "40:  sleep \"$1\"",
          "42:  if ! ps -p $pid1 1>&2 >/dev/null; then",
          "43:   echo \"server1 log:\"",
          "44:   cat \"${WORK_DIR}/dist-minio-server1.log\"",
          "45:   echo \"FAILED\"",
          "46:   purge \"$WORK_DIR\"",
          "47:   exit 1",
          "48:  fi",
          "50:  if ! ps -p $pid2 1>&2 >/dev/null; then",
          "51:   echo \"server2 log:\"",
          "52:   cat \"${WORK_DIR}/dist-minio-server2.log\"",
          "53:   echo \"FAILED\"",
          "54:   purge \"$WORK_DIR\"",
          "55:   exit 1",
          "56:  fi",
          "58:  if ! ps -p $pid3 1>&2 >/dev/null; then",
          "59:   echo \"server3 log:\"",
          "60:   cat \"${WORK_DIR}/dist-minio-server3.log\"",
          "61:   echo \"FAILED\"",
          "62:   purge \"$WORK_DIR\"",
          "63:   exit 1",
          "64:  fi",
          "66:  if ! pkill minio; then",
          "67:   for i in $(seq 1 3); do",
          "68:    echo \"server$i log:\"",
          "69:    cat \"${WORK_DIR}/dist-minio-server$i.log\"",
          "70:   done",
          "71:   echo \"FAILED\"",
          "72:   purge \"$WORK_DIR\"",
          "73:   exit 1",
          "74:  fi",
          "76:  sleep 1",
          "77:  if pgrep minio; then",
          "78:   # forcibly killing, to proceed further properly.",
          "79:   if ! pkill -9 minio; then",
          "80:    echo \"no minio process running anymore, proceed.\"",
          "81:   fi",
          "82:  fi",
          "83: }",
          "85: function check_online() {",
          "86:  if ! grep -q 'Status:' ${WORK_DIR}/dist-minio-*.log; then",
          "87:   echo \"1\"",
          "88:  fi",
          "89: }",
          "91: function purge() {",
          "92:  rm -rf \"$1\"",
          "93: }",
          "95: function __init__() {",
          "96:  echo \"Initializing environment\"",
          "97:  mkdir -p \"$WORK_DIR\"",
          "98:  mkdir -p \"$MINIO_CONFIG_DIR\"",
          "100:  ## version is purposefully set to '3' for minio to migrate configuration file",
          "101:  echo '{\"version\": \"3\", \"credential\": {\"accessKey\": \"minio\", \"secretKey\": \"minio123\"}, \"region\": \"us-east-1\"}' >\"$MINIO_CONFIG_DIR/config.json\"",
          "102: }",
          "104: function perform_test() {",
          "105:  start_minio_3_node 120 $2",
          "107:  echo \"Testing Distributed Erasure setup healing of drives\"",
          "108:  echo \"Remove the contents of the disks belonging to '${1}' erasure set\"",
          "112:  set -x",
          "113:  start_minio_3_node 120 $2",
          "115:  rv=$(check_online)",
          "116:  if [ \"$rv\" == \"1\" ]; then",
          "117:   for i in $(seq 1 3); do",
          "118:    echo \"server$i log:\"",
          "119:    cat \"${WORK_DIR}/dist-minio-server$i.log\"",
          "120:   done",
          "121:   pkill -9 minio",
          "122:   echo \"FAILED\"",
          "123:   purge \"$WORK_DIR\"",
          "124:   exit 1",
          "125:  fi",
          "126: }",
          "128: function main() {",
          "129:  # use same ports for all tests",
          "130:  start_port=$(shuf -i 10000-65000 -n 1)",
          "132:  perform_test \"2\" ${start_port}",
          "133:  perform_test \"1\" ${start_port}",
          "134:  perform_test \"3\" ${start_port}",
          "135: }",
          "137: (__init__ \"$@\" && main \"$@\")",
          "138: rv=$?",
          "139: purge \"$WORK_DIR\"",
          "140: exit \"$rv\"",
          "",
          "---------------"
        ],
        "buildscripts/verify-healing.sh||buildscripts/verify-healing.sh": [
          "File: buildscripts/verify-healing.sh -> buildscripts/verify-healing.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "12: WORK_DIR=\"$PWD/.verify-$RANDOM\"",
          "13: MINIO_CONFIG_DIR=\"$WORK_DIR/.minio\"",
          "14: MINIO=(\"$PWD/minio\" --config-dir \"$MINIO_CONFIG_DIR\" server)",
          "16: function start_minio_3_node() {",
          "17:  export MINIO_ROOT_USER=minio",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "15: GOPATH=/tmp/gopath",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "19:  export MINIO_ERASURE_SET_DRIVE_COUNT=6",
          "20:  export MINIO_CI_CD=1",
          "22:  start_port=$2",
          "23:  args=\"\"",
          "26:  done",
          "28:  \"${MINIO[@]}\" --address \":$((start_port + 1))\" $args >\"${WORK_DIR}/dist-minio-server1.log\" 2>&1 &",
          "",
          "[Removed Lines]",
          "24:  for i in $(seq 1 3); do",
          "25:   args=\"$args http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/1/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/2/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/3/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/4/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/5/ http://127.0.0.1:$((start_port + i))${WORK_DIR}/$i/6/\"",
          "",
          "[Added Lines]",
          "23:  first_time=$(find ${WORK_DIR}/ | grep format.json | wc -l)",
          "27:  for d in $(seq 1 3 5); do",
          "28:   args=\"$args http://127.0.0.1:$((start_port + 1))${WORK_DIR}/1/${d}/ http://127.0.0.1:$((start_port + 2))${WORK_DIR}/2/${d}/ http://127.0.0.1:$((start_port + 3))${WORK_DIR}/3/${d}/ \"",
          "29:   d=$((d + 1))",
          "30:   args=\"$args http://127.0.0.1:$((start_port + 1))${WORK_DIR}/1/${d}/ http://127.0.0.1:$((start_port + 2))${WORK_DIR}/2/${d}/ http://127.0.0.1:$((start_port + 3))${WORK_DIR}/3/${d}/ \"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "40:  sleep \"$1\"",
          "42:  if ! ps -p $pid1 1>&2 >/dev/null; then",
          "43:   echo \"server1 log:\"",
          "44:   cat \"${WORK_DIR}/dist-minio-server1.log\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "47:  [ ${first_time} -eq 0 ] && upload_objects $start_port",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "82:  fi",
          "83: }",
          "86:  if ! grep -q 'Status:' ${WORK_DIR}/dist-minio-*.log; then",
          "88:  fi",
          "89: }",
          "91: function purge() {",
          "",
          "[Removed Lines]",
          "85: function check_online() {",
          "87:   echo \"1\"",
          "",
          "[Added Lines]",
          "92: function check_heal() {",
          "94:   return 1",
          "97:  for ((i = 0; i < 20; i++)); do",
          "98:   test -f ${WORK_DIR}/$1/1/.minio.sys/format.json",
          "99:   v1=$?",
          "100:   nextInES=$(($1 + 1)) && [ $nextInES -gt 3 ] && nextInES=1",
          "101:   foundFiles1=$(find ${WORK_DIR}/$1/1/ | grep -v .minio.sys | grep xl.meta | wc -l)",
          "102:   foundFiles2=$(find ${WORK_DIR}/$nextInES/1/ | grep -v .minio.sys | grep xl.meta | wc -l)",
          "103:   test $foundFiles1 -eq $foundFiles2",
          "104:   v2=$?",
          "105:   [ $v1 == 0 -a $v2 == 0 ] && return 0",
          "106:   sleep 10",
          "107:  done",
          "108:  return 1",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "100:  ## version is purposefully set to '3' for minio to migrate configuration file",
          "101:  echo '{\"version\": \"3\", \"credential\": {\"accessKey\": \"minio\", \"secretKey\": \"minio123\"}, \"region\": \"us-east-1\"}' >\"$MINIO_CONFIG_DIR/config.json\"",
          "102: }",
          "104: function perform_test() {",
          "107:  echo \"Testing Distributed Erasure setup healing of drives\"",
          "112:  set -x",
          "116:  if [ \"$rv\" == \"1\" ]; then",
          "117:   for i in $(seq 1 3); do",
          "118:    echo \"server$i log:\"",
          "",
          "[Removed Lines]",
          "105:  start_minio_3_node 120 $2",
          "108:  echo \"Remove the contents of the disks belonging to '${1}' erasure set\"",
          "113:  start_minio_3_node 120 $2",
          "115:  rv=$(check_online)",
          "",
          "[Added Lines]",
          "123:  if [ ! -f /tmp/mc ]; then",
          "124:   wget --quiet -O /tmp/mc https://dl.minio.io/client/mc/release/linux-amd64/mc &&",
          "125:    chmod +x /tmp/mc",
          "126:  fi",
          "127: }",
          "129: function upload_objects() {",
          "130:  start_port=$1",
          "132:  /tmp/mc alias set myminio http://127.0.0.1:$((start_port + 1)) minio minio123 --api=s3v4",
          "133:  /tmp/mc ready myminio",
          "134:  /tmp/mc mb myminio/testbucket/",
          "135:  for ((i = 0; i < 20; i++)); do",
          "136:   echo \"my content\" | /tmp/mc pipe myminio/testbucket/file-$i",
          "137:  done",
          "141:  start_port=$2",
          "143:  start_minio_3_node 120 $start_port",
          "146:  echo \"Remove the contents of the disks belonging to '${1}' node\"",
          "151:  start_minio_3_node 120 $start_port",
          "153:  check_heal ${1}",
          "154:  rv=$?",
          "",
          "---------------"
        ],
        "cmd/global-heal.go||cmd/global-heal.go": [
          "File: cmd/global-heal.go -> cmd/global-heal.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "29:  \"github.com/dustin/go-humanize\"",
          "30:  \"github.com/minio/madmin-go/v3\"",
          "31:  \"github.com/minio/minio/internal/color\"",
          "32:  \"github.com/minio/minio/internal/config/storageclass\"",
          "33:  xioutil \"github.com/minio/minio/internal/ioutil\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "31:  \"github.com/minio/minio/internal/bucket/lifecycle\"",
          "32:  objectlock \"github.com/minio/minio/internal/bucket/object/lock\"",
          "33:  \"github.com/minio/minio/internal/bucket/replication\"",
          "34:  \"github.com/minio/minio/internal/bucket/versioning\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "214:    continue",
          "215:   }",
          "245:   }",
          "247:   if serverDebugLog {",
          "",
          "[Removed Lines]",
          "217:   vc, err := globalBucketVersioningSys.Get(bucket)",
          "218:   if err != nil {",
          "219:    retErr = err",
          "220:    healingLogIf(ctx, err)",
          "221:    continue",
          "222:   }",
          "225:   lc, err := globalLifecycleSys.Get(bucket)",
          "226:   if err != nil && !errors.Is(err, BucketLifecycleNotFound{Bucket: bucket}) {",
          "227:    retErr = err",
          "228:    healingLogIf(ctx, err)",
          "229:    continue",
          "230:   }",
          "233:   lr, err := globalBucketObjectLockSys.Get(bucket)",
          "234:   if err != nil {",
          "235:    retErr = err",
          "236:    healingLogIf(ctx, err)",
          "237:    continue",
          "238:   }",
          "240:   rcfg, err := getReplicationConfig(ctx, bucket)",
          "241:   if err != nil {",
          "242:    retErr = err",
          "243:    healingLogIf(ctx, err)",
          "244:    continue",
          "",
          "[Added Lines]",
          "221:   var (",
          "222:    vc   *versioning.Versioning",
          "223:    lc   *lifecycle.Lifecycle",
          "224:    lr   objectlock.Retention",
          "225:    rcfg *replication.Config",
          "226:   )",
          "228:   if !isMinioMetaBucketName(bucket) {",
          "229:    vc, err = globalBucketVersioningSys.Get(bucket)",
          "230:    if err != nil {",
          "231:     retErr = err",
          "232:     healingLogIf(ctx, err)",
          "233:     continue",
          "234:    }",
          "236:    lc, err = globalLifecycleSys.Get(bucket)",
          "237:    if err != nil && !errors.Is(err, BucketLifecycleNotFound{Bucket: bucket}) {",
          "238:     retErr = err",
          "239:     healingLogIf(ctx, err)",
          "240:     continue",
          "241:    }",
          "243:    lr, err = globalBucketObjectLockSys.Get(bucket)",
          "244:    if err != nil {",
          "245:     retErr = err",
          "246:     healingLogIf(ctx, err)",
          "247:     continue",
          "248:    }",
          "249:    rcfg, err = getReplicationConfig(ctx, bucket)",
          "250:    if err != nil {",
          "251:     retErr = err",
          "252:     healingLogIf(ctx, err)",
          "253:     continue",
          "254:    }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "9693c382a8b5320252076c95269ebdaf75814c59",
      "candidate_info": {
        "commit_hash": "9693c382a8b5320252076c95269ebdaf75814c59",
        "repo": "minio/minio",
        "commit_url": "https://github.com/minio/minio/commit/9693c382a8b5320252076c95269ebdaf75814c59",
        "files": [
          ".github/workflows/multipart/migrate.sh",
          "buildscripts/rewrite-old-new.sh",
          "cmd/erasure-metadata-utils.go",
          "cmd/erasure-multipart.go",
          "cmd/erasure-object.go",
          "cmd/global-heal.go",
          "cmd/mrf.go",
          "cmd/naughty-disk_test.go",
          "cmd/storage-datatypes.go",
          "cmd/storage-datatypes_gen.go",
          "cmd/storage-interface.go",
          "cmd/storage-rest-client.go",
          "cmd/storage-rest-server.go",
          "cmd/xl-storage-disk-id-check.go",
          "cmd/xl-storage.go",
          "docs/bucket/replication/setup_3site_replication.sh",
          "docs/distributed/decom-compressed-sse-s3.sh",
          "docs/distributed/decom-encrypted-sse-s3.sh",
          "docs/distributed/decom-encrypted.sh",
          "docs/distributed/decom.sh",
          "internal/grid/handlers.go",
          "internal/grid/handlers_string.go"
        ],
        "message": "make renameData() more defensive during overwrites (#19548)\n\ninstead upon any error in renameData(), we still\npreserve the existing dataDir in some form for\nrecoverability in strange situations such as out\nof disk space type errors.\n\nBonus: avoid running list and heal() instead allow\nversions disparity to return the actual versions,\nuuid to heal. Currently limit this to 100 versions\nand lesser disparate objects.\n\nan undo now reverts back the xl.meta from xl.meta.bkp\nduring overwrites on such flaky setups.\n\nBonus: Save N depth syscalls via skipping the parents\nupon overwrites and versioned updates.\n\nFlaky setup examples are stretch clusters with regular\npacket drops etc, we need to add some defensive code\naround to avoid dangling objects.",
        "before_after_code_files": [
          ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh",
          "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh",
          "cmd/erasure-metadata-utils.go||cmd/erasure-metadata-utils.go",
          "cmd/erasure-multipart.go||cmd/erasure-multipart.go",
          "cmd/erasure-object.go||cmd/erasure-object.go",
          "cmd/global-heal.go||cmd/global-heal.go",
          "cmd/mrf.go||cmd/mrf.go",
          "cmd/naughty-disk_test.go||cmd/naughty-disk_test.go",
          "cmd/storage-datatypes.go||cmd/storage-datatypes.go",
          "cmd/storage-datatypes_gen.go||cmd/storage-datatypes_gen.go",
          "cmd/storage-interface.go||cmd/storage-interface.go",
          "cmd/storage-rest-client.go||cmd/storage-rest-client.go",
          "cmd/storage-rest-server.go||cmd/storage-rest-server.go",
          "cmd/xl-storage-disk-id-check.go||cmd/xl-storage-disk-id-check.go",
          "cmd/xl-storage.go||cmd/xl-storage.go",
          "internal/grid/handlers.go||internal/grid/handlers.go",
          "internal/grid/handlers_string.go||internal/grid/handlers_string.go"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh",
            "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh"
          ],
          "candidate": [
            ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh",
            "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh"
          ]
        }
      },
      "candidate_diff": {
        ".github/workflows/multipart/migrate.sh||.github/workflows/multipart/migrate.sh": [
          "File: .github/workflows/multipart/migrate.sh -> .github/workflows/multipart/migrate.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "24:   chmod +x mc",
          "25: fi",
          "32: export RELEASE=RELEASE.2023-08-29T23-07-35Z",
          "",
          "[Removed Lines]",
          "27: (",
          "28:  cd ./docs/debugging/s3-check-md5",
          "29:  go install -v",
          "30: )",
          "",
          "[Added Lines]",
          "27: go install -v github.com/minio/minio/docs/debugging/s3-check-md5@latest",
          "",
          "---------------"
        ],
        "buildscripts/rewrite-old-new.sh||buildscripts/rewrite-old-new.sh": [
          "File: buildscripts/rewrite-old-new.sh -> buildscripts/rewrite-old-new.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "87:   exit 1",
          "88:  fi",
          "95:  if ! s3-check-md5 \\",
          "96:   -debug \\",
          "",
          "[Removed Lines]",
          "90:  (",
          "91:   cd ./docs/debugging/s3-check-md5",
          "92:   go install -v",
          "93:  )",
          "",
          "[Added Lines]",
          "90:  go install -v github.com/minio/minio/docs/debugging/s3-check-md5@latest",
          "",
          "---------------"
        ],
        "cmd/erasure-metadata-utils.go||cmd/erasure-metadata-utils.go": [
          "File: cmd/erasure-metadata-utils.go -> cmd/erasure-metadata-utils.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: import (",
          "21:  \"context\"",
          "22:  \"errors\"",
          "23:  \"hash/crc32\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "22:  \"encoding/binary\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "26: )",
          "32:  diskVersionsCount := make(map[uint64]int)",
          "33:  for _, versions := range diskVersions {",
          "35:  }",
          "37:  max := 0",
          "38:  for versions, count := range diskVersionsCount {",
          "39:   if max < count {",
          "",
          "[Removed Lines]",
          "31: func reduceCommonVersions(diskVersions []uint64, writeQuorum int) (commonVersions uint64) {",
          "34:   diskVersionsCount[versions]++",
          "",
          "[Added Lines]",
          "32: func reduceCommonVersions(diskVersions [][]byte, writeQuorum int) (versions []byte) {",
          "35:   if len(versions) > 0 {",
          "36:    diskVersionsCount[binary.BigEndian.Uint64(versions)]++",
          "37:   }",
          "40:  var commonVersions uint64",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "43:  }",
          "45:  if max >= writeQuorum {",
          "47:  }",
          "50: }",
          "",
          "[Removed Lines]",
          "46:   return commonVersions",
          "49:  return 0",
          "",
          "[Added Lines]",
          "50:   for _, versions := range diskVersions {",
          "51:    if binary.BigEndian.Uint64(versions) == commonVersions {",
          "52:     return versions",
          "53:    }",
          "54:   }",
          "55:  }",
          "57:  return []byte{}",
          "58: }",
          "63: func reduceCommonDataDir(dataDirs []string, writeQuorum int) (dataDir string) {",
          "64:  dataDirsCount := make(map[string]int)",
          "65:  for _, ddir := range dataDirs {",
          "66:   dataDirsCount[ddir]++",
          "67:  }",
          "69:  max := 0",
          "70:  for ddir, count := range dataDirsCount {",
          "71:   if max < count {",
          "72:    max = count",
          "73:    dataDir = ddir",
          "74:   }",
          "75:  }",
          "77:  if max >= writeQuorum {",
          "78:   return dataDir",
          "81:  return \"\"",
          "",
          "---------------"
        ],
        "cmd/erasure-multipart.go||cmd/erasure-multipart.go": [
          "File: cmd/erasure-multipart.go -> cmd/erasure-multipart.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "1311:  }()",
          "1315:   partsMetadata, bucket, object, writeQuorum)",
          "1316:  if err != nil {",
          "1317:   return oi, toObjectErr(err, bucket, object)",
          "1318:  }",
          "1321:   globalMRFState.addPartialOp(partialOperation{",
          "1328:   })",
          "1329:  }",
          "1333:   for _, disk := range onlineDisks {",
          "1334:    if disk != nil && disk.IsOnline() {",
          "",
          "[Removed Lines]",
          "1314:  onlineDisks, versionsDisparity, err := renameData(ctx, onlineDisks, minioMetaMultipartBucket, uploadIDPath,",
          "1320:  if !opts.Speedtest && versionsDisparity {",
          "1322:    bucket:      bucket,",
          "1323:    object:      object,",
          "1324:    queued:      time.Now(),",
          "1325:    allVersions: true,",
          "1326:    setIndex:    er.setIndex,",
          "1327:    poolIndex:   er.poolIndex,",
          "1331:  if !opts.Speedtest && !versionsDisparity {",
          "",
          "[Added Lines]",
          "1314:  onlineDisks, versions, oldDataDir, err := renameData(ctx, onlineDisks, minioMetaMultipartBucket, uploadIDPath,",
          "1320:  if err = er.commitRenameDataDir(ctx, bucket, object, oldDataDir, onlineDisks); err != nil {",
          "1321:   return ObjectInfo{}, toObjectErr(err, bucket, object)",
          "1322:  }",
          "1324:  if !opts.Speedtest && len(versions) > 0 {",
          "1326:    bucket:    bucket,",
          "1327:    object:    object,",
          "1328:    queued:    time.Now(),",
          "1329:    versions:  versions,",
          "1330:    setIndex:  er.setIndex,",
          "1331:    poolIndex: er.poolIndex,",
          "1335:  if !opts.Speedtest && len(versions) == 0 {",
          "",
          "---------------"
        ],
        "cmd/erasure-object.go||cmd/erasure-object.go": [
          "File: cmd/erasure-object.go -> cmd/erasure-object.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "48:  \"github.com/minio/minio/internal/logger\"",
          "49:  \"github.com/minio/pkg/v2/mimedb\"",
          "50:  \"github.com/minio/pkg/v2/sync/errgroup\"",
          "52: )",
          "",
          "[Removed Lines]",
          "51:  \"github.com/minio/pkg/v2/wildcard\"",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1006: }",
          "1010:  g := errgroup.WithNErrs(len(disks))",
          "1012:  fvID := mustGetUUID()",
          "",
          "[Removed Lines]",
          "1009: func renameData(ctx context.Context, disks []StorageAPI, srcBucket, srcEntry string, metadata []FileInfo, dstBucket, dstEntry string, writeQuorum int) ([]StorageAPI, bool, error) {",
          "",
          "[Added Lines]",
          "1008: func renameData(ctx context.Context, disks []StorageAPI, srcBucket, srcEntry string, metadata []FileInfo, dstBucket, dstEntry string, writeQuorum int) ([]StorageAPI, []byte, string, error) {",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "1014:   metadata[index].SetTierFreeVersionID(fvID)",
          "1015:  }",
          "1019:  for index := range disks {",
          "1020:   index := index",
          "",
          "[Removed Lines]",
          "1017:  diskVersions := make([]uint64, len(disks))",
          "",
          "[Added Lines]",
          "1016:  diskVersions := make([][]byte, len(disks))",
          "1017:  dataDirs := make([]string, len(disks))",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "1033:    if !fi.IsValid() {",
          "1034:     return errFileCorrupt",
          "1035:    }",
          "1037:    if err != nil {",
          "1038:     return err",
          "1039:    }",
          "1041:    return nil",
          "1042:   }, index)",
          "1043:  }",
          "",
          "[Removed Lines]",
          "1036:    sign, err := disks[index].RenameData(ctx, srcBucket, srcEntry, fi, dstBucket, dstEntry, RenameOptions{})",
          "1040:    diskVersions[index] = sign",
          "",
          "[Added Lines]",
          "1036:    resp, err := disks[index].RenameData(ctx, srcBucket, srcEntry, fi, dstBucket, dstEntry, RenameOptions{})",
          "1040:    diskVersions[index] = resp.Sign",
          "1041:    dataDirs[index] = resp.OldDataDir",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "1046:  errs := g.Wait()",
          "1050:  err := reduceWriteQuorumErrs(ctx, errs, objectOpIgnoredErrs, writeQuorum)",
          "1051:  if err != nil {",
          "1052:   dg := errgroup.WithNErrs(len(disks))",
          "",
          "[Removed Lines]",
          "1048:  var versionsDisparity bool",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "1062:    dg.Go(func() error {",
          "1064:    }, index)",
          "1065:   }",
          "1066:   dg.Wait()",
          "1067:  }",
          "1068:  if err == nil {",
          "1070:   for index, dversions := range diskVersions {",
          "1071:    if errs[index] != nil {",
          "1072:     continue",
          "1073:    }",
          "1076:     break",
          "1077:    }",
          "1078:   }",
          "1079:  }",
          "1084: }",
          "1086: func (er erasureObjects) putMetacacheObject(ctx context.Context, key string, r *PutObjReader, opts ObjectOptions) (objInfo ObjectInfo, err error) {",
          "",
          "[Removed Lines]",
          "1063:     return disks[index].DeleteVersion(context.Background(), dstBucket, dstEntry, metadata[index], false, DeleteOptions{UndoWrite: true})",
          "1069:   versions := reduceCommonVersions(diskVersions, writeQuorum)",
          "1074:    if versions != dversions {",
          "1075:     versionsDisparity = true",
          "1083:  return evalDisks(disks, errs), versionsDisparity, err",
          "",
          "[Added Lines]",
          "1062:     return disks[index].DeleteVersion(context.Background(), dstBucket, dstEntry, metadata[index], false, DeleteOptions{",
          "1063:      UndoWrite:  true,",
          "1064:      OldDataDir: dataDirs[index],",
          "1065:     })",
          "1070:  var dataDir string",
          "1071:  var versions []byte",
          "1073:   versions = reduceCommonVersions(diskVersions, writeQuorum)",
          "1078:    if !bytes.Equal(dversions, versions) {",
          "1079:     if len(dversions) > len(versions) {",
          "1080:      versions = dversions",
          "1081:     }",
          "1085:   dataDir = reduceCommonDataDir(dataDirs, writeQuorum)",
          "1090:  return evalDisks(disks, errs), versions, dataDir, err",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "1229:  return er.putObject(ctx, bucket, object, data, opts)",
          "1230: }",
          "1271: func (er erasureObjects) putObject(ctx context.Context, bucket string, object string, r *PutObjReader, opts ObjectOptions) (objInfo ObjectInfo, err error) {",
          "1272:  if !opts.NoAuditLog {",
          "",
          "[Removed Lines]",
          "1233: func healObjectVersionsDisparity(bucket string, entry metaCacheEntry, scanMode madmin.HealScanMode) error {",
          "1234:  if entry.isDir() {",
          "1235:   return nil",
          "1236:  }",
          "1240:  if bucket == minioMetaBucket {",
          "1241:   if wildcard.Match(\"buckets/*/.metacache/*\", entry.name) {",
          "1242:    return nil",
          "1243:   }",
          "1244:   if wildcard.Match(\"tmp/*\", entry.name) {",
          "1245:    return nil",
          "1246:   }",
          "1247:   if wildcard.Match(\"multipart/*\", entry.name) {",
          "1248:    return nil",
          "1249:   }",
          "1250:   if wildcard.Match(\"tmp-old/*\", entry.name) {",
          "1251:    return nil",
          "1252:   }",
          "1253:  }",
          "1255:  fivs, err := entry.fileInfoVersions(bucket)",
          "1256:  if err != nil {",
          "1257:   healObject(bucket, entry.name, \"\", madmin.HealDeepScan)",
          "1258:   return err",
          "1259:  }",
          "1261:  if len(fivs.Versions) <= 2 {",
          "1262:   for _, version := range fivs.Versions {",
          "1263:    healObject(bucket, entry.name, version.VersionID, scanMode)",
          "1264:   }",
          "1265:  }",
          "1267:  return nil",
          "1268: }",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "1547:  }",
          "1551:  if err != nil {",
          "1552:   if errors.Is(err, errFileNotFound) {",
          "1553:    return ObjectInfo{}, toObjectErr(errErasureWriteQuorum, bucket, object)",
          "",
          "[Removed Lines]",
          "1550:  onlineDisks, versionsDisparity, err := renameData(ctx, onlineDisks, minioMetaTmpBucket, tempObj, partsMetadata, bucket, object, writeQuorum)",
          "",
          "[Added Lines]",
          "1519:  onlineDisks, versions, oldDataDir, err := renameData(ctx, onlineDisks, minioMetaTmpBucket, tempObj, partsMetadata, bucket, object, writeQuorum)",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "1555:   return ObjectInfo{}, toObjectErr(err, bucket, object)",
          "1556:  }",
          "1558:  for i := 0; i < len(onlineDisks); i++ {",
          "1559:   if onlineDisks[i] != nil && onlineDisks[i].IsOnline() {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1527:  if err = er.commitRenameDataDir(ctx, bucket, object, oldDataDir, onlineDisks); err != nil {",
          "1528:   return ObjectInfo{}, toObjectErr(err, bucket, object)",
          "1529:  }",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "1575:    for i := 0; i < len(onlineDisks); i++ {",
          "",
          "[Removed Lines]",
          "1572:   if !versionsDisparity {",
          "",
          "[Added Lines]",
          "1545:   if len(versions) == 0 {",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "1582:    }",
          "1583:   } else {",
          "1584:    globalMRFState.addPartialOp(partialOperation{",
          "1591:    })",
          "1592:   }",
          "1593:  }",
          "",
          "[Removed Lines]",
          "1585:     bucket:      bucket,",
          "1586:     object:      object,",
          "1587:     queued:      time.Now(),",
          "1588:     allVersions: true,",
          "1589:     setIndex:    er.setIndex,",
          "1590:     poolIndex:   er.poolIndex,",
          "",
          "[Added Lines]",
          "1558:     bucket:    bucket,",
          "1559:     object:    object,",
          "1560:     queued:    time.Now(),",
          "1561:     versions:  versions,",
          "1562:     setIndex:  er.setIndex,",
          "1563:     poolIndex: er.poolIndex,",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "1797:  return dobjects, errs",
          "1798: }",
          "1800: func (er erasureObjects) deletePrefix(ctx context.Context, bucket, prefix string) error {",
          "1801:  disks := er.getDisks()",
          "1802:  g := errgroup.WithNErrs(len(disks))",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1773: func (er erasureObjects) commitRenameDataDir(ctx context.Context, bucket, object, dataDir string, onlineDisks []StorageAPI) error {",
          "1774:  if dataDir == \"\" {",
          "1775:   return nil",
          "1776:  }",
          "1777:  g := errgroup.WithNErrs(len(onlineDisks))",
          "1778:  for index := range onlineDisks {",
          "1779:   index := index",
          "1780:   g.Go(func() error {",
          "1781:    if onlineDisks[index] == nil {",
          "1782:     return nil",
          "1783:    }",
          "1784:    return onlineDisks[index].Delete(ctx, bucket, pathJoin(object, dataDir), DeleteOptions{",
          "1785:     Recursive: true,",
          "1786:    })",
          "1787:   }, index)",
          "1788:  }",
          "1789:  for _, err := range g.Wait() {",
          "1790:   if err != nil {",
          "1791:    return err",
          "1792:   }",
          "1793:  }",
          "1794:  return nil",
          "1795: }",
          "",
          "---------------"
        ],
        "cmd/global-heal.go||cmd/global-heal.go": [
          "File: cmd/global-heal.go -> cmd/global-heal.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "531:  bgSeq, ok := globalBackgroundHealState.getHealSequenceByToken(bgHealingUUID)",
          "532:  if ok {",
          "543:  }",
          "544:  return nil",
          "545: }",
          "",
          "[Removed Lines]",
          "533:   return bgSeq.queueHealTask(healSource{",
          "534:    bucket:    bucket,",
          "535:    object:    object,",
          "536:    versionID: versionID,",
          "537:    noWait:    true, // do not block callers.",
          "538:    opts: &madmin.HealOpts{",
          "539:     Remove:   healDeleteDangling, // if found dangling purge it.",
          "540:     ScanMode: scan,",
          "541:    },",
          "542:   }, madmin.HealItemObject)",
          "",
          "[Added Lines]",
          "533:   return bgSeq.healObject(bucket, object, versionID, scan)",
          "",
          "---------------"
        ],
        "cmd/mrf.go||cmd/mrf.go": [
          "File: cmd/mrf.go -> cmd/mrf.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "21:  \"context\"",
          "22:  \"time\"",
          "24:  \"github.com/minio/madmin-go/v3\"",
          "25:  \"github.com/minio/pkg/v2/wildcard\"",
          "26: )",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "24:  \"github.com/google/uuid\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "35:  bucket              string",
          "36:  object              string",
          "37:  versionID           string",
          "39:  setIndex, poolIndex int",
          "40:  queued              time.Time",
          "41:  scanMode            madmin.HealScanMode",
          "",
          "[Removed Lines]",
          "38:  allVersions         bool",
          "",
          "[Added Lines]",
          "39:  versions            []byte",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "111:    if u.object == \"\" {",
          "112:     healBucket(u.bucket, scan)",
          "113:    } else {",
          "116:     } else {",
          "117:      healObject(u.bucket, u.object, u.versionID, scan)",
          "118:     }",
          "",
          "[Removed Lines]",
          "114:     if u.allVersions {",
          "115:      z.serverPools[u.poolIndex].sets[u.setIndex].listAndHeal(u.bucket, u.object, u.scanMode, healObjectVersionsDisparity)",
          "",
          "[Added Lines]",
          "115:     if len(u.versions) > 0 {",
          "116:      vers := len(u.versions) / 16",
          "117:      if vers > 0 {",
          "118:       for i := 0; i < vers; i++ {",
          "119:        healObject(u.bucket, u.object, uuid.UUID(u.versions[16*i:]).String(), scan)",
          "120:       }",
          "121:      }",
          "",
          "---------------"
        ],
        "cmd/naughty-disk_test.go||cmd/naughty-disk_test.go": [
          "File: cmd/naughty-disk_test.go -> cmd/naughty-disk_test.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "201:  return d.disk.AppendFile(ctx, volume, path, buf)",
          "202: }",
          "205:  if err := d.calcError(); err != nil {",
          "207:  }",
          "208:  return d.disk.RenameData(ctx, srcVolume, srcPath, fi, dstVolume, dstPath, opts)",
          "209: }",
          "",
          "[Removed Lines]",
          "204: func (d *naughtyDisk) RenameData(ctx context.Context, srcVolume, srcPath string, fi FileInfo, dstVolume, dstPath string, opts RenameOptions) (uint64, error) {",
          "206:   return 0, err",
          "",
          "[Added Lines]",
          "204: func (d *naughtyDisk) RenameData(ctx context.Context, srcVolume, srcPath string, fi FileInfo, dstVolume, dstPath string, opts RenameOptions) (RenameDataResp, error) {",
          "206:   return RenameDataResp{}, err",
          "",
          "---------------"
        ],
        "cmd/storage-datatypes.go||cmd/storage-datatypes.go": [
          "File: cmd/storage-datatypes.go -> cmd/storage-datatypes.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "33:  Recursive bool `msg:\"r\"`",
          "34:  Immediate bool `msg:\"i\"`",
          "35:  UndoWrite bool `msg:\"u\"`",
          "36: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "37:  OldDataDir string `msg:\"o,omitempty\"` // old data dir used only when to revert a rename()",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "490: }",
          "493: type RenameDataResp struct {",
          "495: }",
          "",
          "[Removed Lines]",
          "494:  Signature uint64 `msg:\"sig\"`",
          "",
          "[Added Lines]",
          "501:  Sign       []byte",
          "502:  OldDataDir string // contains '<uuid>', it is designed to be passed as value to Delete(bucket, pathJoin(object, dataDir))",
          "",
          "---------------"
        ],
        "cmd/storage-datatypes_gen.go||cmd/storage-datatypes_gen.go": [
          "File: cmd/storage-datatypes_gen.go -> cmd/storage-datatypes_gen.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "514:     err = msgp.WrapError(err, \"UndoWrite\")",
          "515:     return",
          "516:    }",
          "517:   default:",
          "518:    err = dc.Skip()",
          "519:    if err != nil {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "517:   case \"o\":",
          "518:    z.OldDataDir, err = dc.ReadString()",
          "519:    if err != nil {",
          "520:     err = msgp.WrapError(err, \"OldDataDir\")",
          "521:     return",
          "522:    }",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "529: func (z *DeleteOptions) EncodeMsg(en *msgp.Writer) (err error) {",
          "533:  if err != nil {",
          "534:   return",
          "535:  }",
          "",
          "[Removed Lines]",
          "532:  err = en.Append(0x84, 0xab, 0x42, 0x61, 0x73, 0x65, 0x4f, 0x70, 0x74, 0x69, 0x6f, 0x6e, 0x73)",
          "",
          "[Added Lines]",
          "537:  zb0001Len := uint32(5)",
          "539:  _ = zb0001Mask",
          "540:  if z.OldDataDir == \"\" {",
          "541:   zb0001Len--",
          "542:   zb0001Mask |= 0x10",
          "543:  }",
          "545:  err = en.Append(0x80 | uint8(zb0001Len))",
          "546:  if err != nil {",
          "547:   return",
          "548:  }",
          "549:  if zb0001Len == 0 {",
          "550:   return",
          "551:  }",
          "553:  err = en.Append(0xab, 0x42, 0x61, 0x73, 0x65, 0x4f, 0x70, 0x74, 0x69, 0x6f, 0x6e, 0x73)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "569:   err = msgp.WrapError(err, \"UndoWrite\")",
          "570:   return",
          "571:  }",
          "572:  return",
          "573: }",
          "576: func (z *DeleteOptions) MarshalMsg(b []byte) (o []byte, err error) {",
          "577:  o = msgp.Require(b, z.Msgsize())",
          "582:  _ = z.BaseOptions",
          "583:  o = append(o, 0x80)",
          "",
          "[Removed Lines]",
          "580:  o = append(o, 0x84, 0xab, 0x42, 0x61, 0x73, 0x65, 0x4f, 0x70, 0x74, 0x69, 0x6f, 0x6e, 0x73)",
          "",
          "[Added Lines]",
          "593:  if (zb0001Mask & 0x10) == 0 { // if not omitted",
          "595:   err = en.Append(0xa1, 0x6f)",
          "596:   if err != nil {",
          "597:    return",
          "598:   }",
          "599:   err = en.WriteString(z.OldDataDir)",
          "600:   if err != nil {",
          "601:    err = msgp.WrapError(err, \"OldDataDir\")",
          "602:    return",
          "603:   }",
          "604:  }",
          "612:  zb0001Len := uint32(5)",
          "614:  _ = zb0001Mask",
          "615:  if z.OldDataDir == \"\" {",
          "616:   zb0001Len--",
          "617:   zb0001Mask |= 0x10",
          "618:  }",
          "620:  o = append(o, 0x80|uint8(zb0001Len))",
          "621:  if zb0001Len == 0 {",
          "622:   return",
          "623:  }",
          "625:  o = append(o, 0xab, 0x42, 0x61, 0x73, 0x65, 0x4f, 0x70, 0x74, 0x69, 0x6f, 0x6e, 0x73)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "591:  o = append(o, 0xa1, 0x75)",
          "592:  o = msgp.AppendBool(o, z.UndoWrite)",
          "593:  return",
          "594: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "638:  if (zb0001Mask & 0x10) == 0 { // if not omitted",
          "640:   o = append(o, 0xa1, 0x6f)",
          "641:   o = msgp.AppendString(o, z.OldDataDir)",
          "642:  }",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "652:     err = msgp.WrapError(err, \"UndoWrite\")",
          "653:     return",
          "654:    }",
          "655:   default:",
          "656:    bts, err = msgp.Skip(bts)",
          "657:    if err != nil {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "705:   case \"o\":",
          "706:    z.OldDataDir, bts, err = msgp.ReadStringBytes(bts)",
          "707:    if err != nil {",
          "708:     err = msgp.WrapError(err, \"OldDataDir\")",
          "709:     return",
          "710:    }",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "668: func (z *DeleteOptions) Msgsize() (s int) {",
          "670:  return",
          "671: }",
          "",
          "[Removed Lines]",
          "669:  s = 1 + 12 + 1 + 2 + msgp.BoolSize + 2 + msgp.BoolSize + 2 + msgp.BoolSize",
          "",
          "[Added Lines]",
          "725:  s = 1 + 12 + 1 + 2 + msgp.BoolSize + 2 + msgp.BoolSize + 2 + msgp.BoolSize + 2 + msgp.StringPrefixSize + len(z.OldDataDir)",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "4751:    return",
          "4752:   }",
          "4753:   switch msgp.UnsafeString(field) {",
          "4756:    if err != nil {",
          "4758:     return",
          "4759:    }",
          "4760:   default:",
          "",
          "[Removed Lines]",
          "4754:   case \"sig\":",
          "4755:    z.Signature, err = dc.ReadUint64()",
          "4757:     err = msgp.WrapError(err, \"Signature\")",
          "",
          "[Added Lines]",
          "4810:   case \"Sign\":",
          "4811:    z.Sign, err = dc.ReadBytes(z.Sign)",
          "4812:    if err != nil {",
          "4813:     err = msgp.WrapError(err, \"Sign\")",
          "4814:     return",
          "4815:    }",
          "4816:   case \"OldDataDir\":",
          "4817:    z.OldDataDir, err = dc.ReadString()",
          "4819:     err = msgp.WrapError(err, \"OldDataDir\")",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "4769: }",
          "4776:  if err != nil {",
          "4777:   return",
          "4778:  }",
          "4780:  if err != nil {",
          "4782:   return",
          "4783:  }",
          "4784:  return",
          "4785: }",
          "4789:  o = msgp.Require(b, z.Msgsize())",
          "4794:  return",
          "4795: }",
          "",
          "[Removed Lines]",
          "4772: func (z RenameDataResp) EncodeMsg(en *msgp.Writer) (err error) {",
          "4775:  err = en.Append(0x81, 0xa3, 0x73, 0x69, 0x67)",
          "4779:  err = en.WriteUint64(z.Signature)",
          "4781:   err = msgp.WrapError(err, \"Signature\")",
          "4788: func (z RenameDataResp) MarshalMsg(b []byte) (o []byte, err error) {",
          "4792:  o = append(o, 0x81, 0xa3, 0x73, 0x69, 0x67)",
          "4793:  o = msgp.AppendUint64(o, z.Signature)",
          "",
          "[Added Lines]",
          "4834: func (z *RenameDataResp) EncodeMsg(en *msgp.Writer) (err error) {",
          "4837:  err = en.Append(0x82, 0xa4, 0x53, 0x69, 0x67, 0x6e)",
          "4838:  if err != nil {",
          "4839:   return",
          "4840:  }",
          "4841:  err = en.WriteBytes(z.Sign)",
          "4842:  if err != nil {",
          "4843:   err = msgp.WrapError(err, \"Sign\")",
          "4844:   return",
          "4845:  }",
          "4847:  err = en.Append(0xaa, 0x4f, 0x6c, 0x64, 0x44, 0x61, 0x74, 0x61, 0x44, 0x69, 0x72)",
          "4851:  err = en.WriteString(z.OldDataDir)",
          "4853:   err = msgp.WrapError(err, \"OldDataDir\")",
          "4860: func (z *RenameDataResp) MarshalMsg(b []byte) (o []byte, err error) {",
          "4864:  o = append(o, 0x82, 0xa4, 0x53, 0x69, 0x67, 0x6e)",
          "4865:  o = msgp.AppendBytes(o, z.Sign)",
          "4867:  o = append(o, 0xaa, 0x4f, 0x6c, 0x64, 0x44, 0x61, 0x74, 0x61, 0x44, 0x69, 0x72)",
          "4868:  o = msgp.AppendString(o, z.OldDataDir)",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "4812:    return",
          "4813:   }",
          "4814:   switch msgp.UnsafeString(field) {",
          "4817:    if err != nil {",
          "4819:     return",
          "4820:    }",
          "4821:   default:",
          "",
          "[Removed Lines]",
          "4815:   case \"sig\":",
          "4816:    z.Signature, bts, err = msgp.ReadUint64Bytes(bts)",
          "4818:     err = msgp.WrapError(err, \"Signature\")",
          "",
          "[Added Lines]",
          "4890:   case \"Sign\":",
          "4891:    z.Sign, bts, err = msgp.ReadBytesBytes(bts, z.Sign)",
          "4892:    if err != nil {",
          "4893:     err = msgp.WrapError(err, \"Sign\")",
          "4894:     return",
          "4895:    }",
          "4896:   case \"OldDataDir\":",
          "4897:    z.OldDataDir, bts, err = msgp.ReadStringBytes(bts)",
          "4899:     err = msgp.WrapError(err, \"OldDataDir\")",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "4831: }",
          "4836:  return",
          "4837: }",
          "",
          "[Removed Lines]",
          "4834: func (z RenameDataResp) Msgsize() (s int) {",
          "4835:  s = 1 + 4 + msgp.Uint64Size",
          "",
          "[Added Lines]",
          "4915: func (z *RenameDataResp) Msgsize() (s int) {",
          "4916:  s = 1 + 5 + msgp.BytesPrefixSize + len(z.Sign) + 11 + msgp.StringPrefixSize + len(z.OldDataDir)",
          "",
          "---------------"
        ],
        "cmd/storage-interface.go||cmd/storage-interface.go": [
          "File: cmd/storage-interface.go -> cmd/storage-interface.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "85:  UpdateMetadata(ctx context.Context, volume, path string, fi FileInfo, opts UpdateMetadataOpts) error",
          "86:  ReadVersion(ctx context.Context, origvolume, volume, path, versionID string, opts ReadOptions) (FileInfo, error)",
          "87:  ReadXL(ctx context.Context, volume, path string, readData bool) (RawFileInfo, error)",
          "91:  ListDir(ctx context.Context, origvolume, volume, dirPath string, count int) ([]string, error)",
          "",
          "[Removed Lines]",
          "88:  RenameData(ctx context.Context, srcVolume, srcPath string, fi FileInfo, dstVolume, dstPath string, opts RenameOptions) (uint64, error)",
          "",
          "[Added Lines]",
          "88:  RenameData(ctx context.Context, srcVolume, srcPath string, fi FileInfo, dstVolume, dstPath string, opts RenameOptions) (RenameDataResp, error)",
          "",
          "---------------"
        ],
        "cmd/storage-rest-client.go||cmd/storage-rest-client.go": [
          "File: cmd/storage-rest-client.go -> cmd/storage-rest-client.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "440: }",
          "444:  params := RenameDataHandlerParams{",
          "445:   DiskID:    *client.diskID.Load(),",
          "446:   SrcVolume: srcVolume,",
          "",
          "[Removed Lines]",
          "443: func (client *storageRESTClient) RenameData(ctx context.Context, srcVolume, srcPath string, fi FileInfo, dstVolume, dstPath string, opts RenameOptions) (sign uint64, err error) {",
          "",
          "[Added Lines]",
          "443: func (client *storageRESTClient) RenameData(ctx context.Context, srcVolume, srcPath string, fi FileInfo,",
          "444:  dstVolume, dstPath string, opts RenameOptions,",
          "445: ) (res RenameDataResp, err error) {",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "457:   resp, err = storageRenameDataInlineRPC.Call(ctx, client.gridConn, &RenameDataInlineHandlerParams{params})",
          "458:  }",
          "459:  if err != nil {",
          "461:  }",
          "463:  defer storageRenameDataRPC.PutResponse(resp)",
          "465: }",
          "",
          "[Removed Lines]",
          "460:   return 0, toStorageErr(err)",
          "464:  return resp.Signature, nil",
          "",
          "[Added Lines]",
          "462:   return res, toStorageErr(err)",
          "466:  return *resp, nil",
          "",
          "---------------"
        ],
        "cmd/storage-rest-server.go||cmd/storage-rest-server.go": [
          "File: cmd/storage-rest-server.go -> cmd/storage-rest-server.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "67:  storageWriteAllRPC         = grid.NewSingleHandler[*WriteAllHandlerParams, grid.NoPayload](grid.HandlerWriteAll, func() *WriteAllHandlerParams { return &WriteAllHandlerParams{} }, grid.NewNoPayload)",
          "68:  storageReadVersionRPC      = grid.NewSingleHandler[*grid.MSS, *FileInfo](grid.HandlerReadVersion, grid.NewMSS, func() *FileInfo { return &FileInfo{} })",
          "69:  storageReadXLRPC           = grid.NewSingleHandler[*grid.MSS, *RawFileInfo](grid.HandlerReadXL, grid.NewMSS, func() *RawFileInfo { return &RawFileInfo{} })",
          "71:  storageRenameDataInlineRPC = grid.NewSingleHandler[*RenameDataInlineHandlerParams, *RenameDataResp](grid.HandlerRenameDataInline, newRenameDataInlineHandlerParams, func() *RenameDataResp { return &RenameDataResp{} }).AllowCallRequestPool(false)",
          "72:  storageRenameFileRPC       = grid.NewSingleHandler[*RenameFileHandlerParams, grid.NoPayload](grid.HandlerRenameFile, func() *RenameFileHandlerParams { return &RenameFileHandlerParams{} }, grid.NewNoPayload).AllowCallRequestPool(true)",
          "73:  storageStatVolRPC          = grid.NewSingleHandler[*grid.MSS, *VolInfo](grid.HandlerStatVol, grid.NewMSS, func() *VolInfo { return &VolInfo{} })",
          "",
          "[Removed Lines]",
          "70:  storageRenameDataRPC       = grid.NewSingleHandler[*RenameDataHandlerParams, *RenameDataResp](grid.HandlerRenameData, func() *RenameDataHandlerParams { return &RenameDataHandlerParams{} }, func() *RenameDataResp { return &RenameDataResp{} })",
          "",
          "[Added Lines]",
          "70:  storageRenameDataRPC       = grid.NewSingleHandler[*RenameDataHandlerParams, *RenameDataResp](grid.HandlerRenameData2, func() *RenameDataHandlerParams { return &RenameDataHandlerParams{} }, func() *RenameDataResp { return &RenameDataResp{} })",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "695:   return nil, grid.NewRemoteErr(errDiskNotFound)",
          "696:  }",
          "702: }",
          "",
          "[Removed Lines]",
          "698:  sign, err := s.getStorage().RenameData(context.Background(), p.SrcVolume, p.SrcPath, p.FI, p.DstVolume, p.DstPath, p.Opts)",
          "699:  return &RenameDataResp{",
          "700:   Signature: sign,",
          "701:  }, grid.NewRemoteErr(err)",
          "",
          "[Added Lines]",
          "698:  resp, err := s.getStorage().RenameData(context.Background(), p.SrcVolume, p.SrcPath, p.FI, p.DstVolume, p.DstPath, p.Opts)",
          "699:  return &resp, grid.NewRemoteErr(err)",
          "",
          "---------------"
        ],
        "cmd/xl-storage-disk-id-check.go||cmd/xl-storage-disk-id-check.go": [
          "File: cmd/xl-storage-disk-id-check.go -> cmd/xl-storage-disk-id-check.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "461:  return w.Run(func() error { return p.storage.RenameFile(ctx, srcVolume, srcPath, dstVolume, dstPath) })",
          "462: }",
          "465:  ctx, done, err := p.TrackDiskHealth(ctx, storageMetricRenameData, srcPath, fi.DataDir, dstVolume, dstPath)",
          "466:  if err != nil {",
          "468:  }",
          "469:  defer func() {",
          "470:   if err == nil && !skipAccessChecks(dstVolume) {",
          "",
          "[Removed Lines]",
          "464: func (p *xlStorageDiskIDCheck) RenameData(ctx context.Context, srcVolume, srcPath string, fi FileInfo, dstVolume, dstPath string, opts RenameOptions) (sign uint64, err error) {",
          "467:   return 0, err",
          "",
          "[Added Lines]",
          "464: func (p *xlStorageDiskIDCheck) RenameData(ctx context.Context, srcVolume, srcPath string, fi FileInfo, dstVolume, dstPath string, opts RenameOptions) (res RenameDataResp, err error) {",
          "467:   return res, err",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "472:   }",
          "473:   done(&err)",
          "474:  }()",
          "476:  if len(fi.Data) > 0 {",
          "477:   fi.Data = append(grid.GetByteBufferCap(len(fi.Data))[:0], fi.Data...)",
          "478:  }",
          "480:   if len(fi.Data) > 0 {",
          "481:    defer grid.PutByteBuffer(fi.Data)",
          "482:   }",
          "",
          "[Removed Lines]",
          "479:  return xioutil.WithDeadline[uint64](ctx, globalDriveConfig.GetMaxTimeout(), func(ctx context.Context) (result uint64, err error) {",
          "",
          "[Added Lines]",
          "480:  return xioutil.WithDeadline[RenameDataResp](ctx, globalDriveConfig.GetMaxTimeout(), func(ctx context.Context) (res RenameDataResp, err error) {",
          "",
          "---------------"
        ],
        "cmd/xl-storage.go||cmd/xl-storage.go": [
          "File: cmd/xl-storage.go -> cmd/xl-storage.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "29:  pathutil \"path\"",
          "30:  \"path/filepath\"",
          "31:  \"runtime\"",
          "32:  \"strconv\"",
          "33:  \"strings\"",
          "34:  \"sync\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "32:  \"slices\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "48:  xioutil \"github.com/minio/minio/internal/ioutil\"",
          "49:  \"github.com/minio/minio/internal/logger\"",
          "50:  \"github.com/pkg/xattr\"",
          "52: )",
          "54: const (",
          "",
          "[Removed Lines]",
          "51:  \"github.com/zeebo/xxh3\"",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "67:  xlStorageFormatFile = \"xl.meta\"",
          "68: )",
          "70: var alignedBuf []byte",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "70:  xlStorageFormatFileBackup = \"xl.meta.bkp\"",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "1366:   return s.WriteAll(ctx, volume, pathJoin(path, xlStorageFormatFile), buf)",
          "1367:  }",
          "1369:  return s.deleteFile(volumeDir, pathJoin(volumeDir, path, xlStorageFormatFile), true, false)",
          "1370: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1372:  if opts.UndoWrite && opts.OldDataDir != \"\" {",
          "1373:   return renameAll(pathJoin(filePath, opts.OldDataDir, xlStorageFormatFileBackup), pathJoin(filePath, xlStorageFormatFile), filePath)",
          "1374:  }",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "1375:   return errInvalidArgument",
          "1376:  }",
          "1378:  buf, err := s.ReadAll(ctx, volume, pathJoin(path, xlStorageFormatFile))",
          "1379:  if err != nil {",
          "1384:   }",
          "1385:   return err",
          "1386:  }",
          "",
          "[Removed Lines]",
          "1380:   if err == errFileNotFound {",
          "1381:    if fi.VersionID != \"\" {",
          "1382:     return errFileVersionNotFound",
          "1383:    }",
          "",
          "[Added Lines]",
          "1385:  volumeDir, err := s.getVolDir(volume)",
          "1386:  if err != nil {",
          "1387:   return err",
          "1388:  }",
          "1391:  filePath := pathJoin(volumeDir, path)",
          "1392:  if err = checkPathLength(filePath); err != nil {",
          "1393:   return err",
          "1394:  }",
          "1398:   if err == errFileNotFound && fi.VersionID != \"\" {",
          "1399:    return errFileVersionNotFound",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "1405:  }",
          "1406:  defer metaDataPoolPut(wbuf)",
          "1409: }",
          "",
          "[Removed Lines]",
          "1408:  return s.writeAll(ctx, volume, pathJoin(path, xlStorageFormatFile), wbuf, !opts.NoPersistence)",
          "",
          "[Added Lines]",
          "1424:  return s.writeAll(ctx, volume, pathJoin(path, xlStorageFormatFile), wbuf, !opts.NoPersistence, volumeDir)",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "1442:  }",
          "1444:  buf, err := s.ReadAll(ctx, volume, pathJoin(path, xlStorageFormatFile))",
          "",
          "[Removed Lines]",
          "1441:   return s.writeAll(ctx, volume, pathJoin(path, xlStorageFormatFile), buf, false)",
          "",
          "[Added Lines]",
          "1457:   return s.writeAll(ctx, volume, pathJoin(path, xlStorageFormatFile), buf, false, \"\")",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "1936:  return w, nil",
          "1937: }",
          "1941: }",
          "1947:   return nil, osErrToFileErr(err)",
          "1948:  }",
          "",
          "[Removed Lines]",
          "1939: func (s *xlStorage) openFileSync(filePath string, mode int) (f *os.File, err error) {",
          "1940:  return s.openFile(filePath, mode|writeMode)",
          "1943: func (s *xlStorage) openFile(filePath string, mode int) (f *os.File, err error) {",
          "1946:  if err = mkdirAll(pathutil.Dir(filePath), 0o777, s.drivePath); err != nil {",
          "",
          "[Added Lines]",
          "1955: func (s *xlStorage) openFileSync(filePath string, mode int, skipParent string) (f *os.File, err error) {",
          "1956:  return s.openFile(filePath, mode|writeMode, skipParent)",
          "1959: func (s *xlStorage) openFile(filePath string, mode int, skipParent string) (f *os.File, err error) {",
          "1960:  if skipParent == \"\" {",
          "1961:   skipParent = s.drivePath",
          "1962:  }",
          "1965:  if err = mkdirAll(pathutil.Dir(filePath), 0o777, skipParent); err != nil {",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "2095:   }",
          "2096:  }()",
          "2099: }",
          "2102:  if contextCanceled(ctx) {",
          "2103:   return ctx.Err()",
          "2104:  }",
          "2108:  parentFilePath := pathutil.Dir(filePath)",
          "2110:   return osErrToFileErr(err)",
          "2111:  }",
          "",
          "[Removed Lines]",
          "2098:  return s.writeAllDirect(ctx, filePath, fileSize, r, os.O_CREATE|os.O_WRONLY|os.O_EXCL)",
          "2101: func (s *xlStorage) writeAllDirect(ctx context.Context, filePath string, fileSize int64, r io.Reader, flags int) (err error) {",
          "2109:  if err = mkdirAll(parentFilePath, 0o777, s.drivePath); err != nil {",
          "",
          "[Added Lines]",
          "2117:  return s.writeAllDirect(ctx, filePath, fileSize, r, os.O_CREATE|os.O_WRONLY|os.O_EXCL, volumeDir)",
          "2120: func (s *xlStorage) writeAllDirect(ctx context.Context, filePath string, fileSize int64, r io.Reader, flags int, skipParent string) (err error) {",
          "2125:  if skipParent == \"\" {",
          "2126:   skipParent = s.drivePath",
          "2127:  }",
          "2132:  if err = mkdirAll(parentFilePath, 0o777, skipParent); err != nil {",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "2168:  return w.Close()",
          "2169: }",
          "2172:  if contextCanceled(ctx) {",
          "2173:   return ctx.Err()",
          "2174:  }",
          "",
          "[Removed Lines]",
          "2171: func (s *xlStorage) writeAll(ctx context.Context, volume string, path string, b []byte, sync bool) (err error) {",
          "",
          "[Added Lines]",
          "2194: func (s *xlStorage) writeAll(ctx context.Context, volume string, path string, b []byte, sync bool, skipParent string) (err error) {",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "2195:   if len(b) > xioutil.DirectioAlignSize {",
          "2196:    r := bytes.NewReader(b)",
          "2198:   }",
          "2200:  } else {",
          "2202:  }",
          "2203:  if err != nil {",
          "2204:   return err",
          "",
          "[Removed Lines]",
          "2197:    return s.writeAllDirect(ctx, filePath, r.Size(), r, flags)",
          "2199:   w, err = s.openFileSync(filePath, flags)",
          "2201:   w, err = s.openFile(filePath, flags)",
          "",
          "[Added Lines]",
          "2220:    return s.writeAllDirect(ctx, filePath, r.Size(), r, flags, skipParent)",
          "2222:   w, err = s.openFileSync(filePath, flags, skipParent)",
          "2224:   w, err = s.openFile(filePath, flags, skipParent)",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "2235:   s.Unlock()",
          "2236:  }",
          "2239: }",
          "",
          "[Removed Lines]",
          "2238:  return s.writeAll(ctx, volume, path, b, true)",
          "",
          "[Added Lines]",
          "2261:  volumeDir, err := s.getVolDir(volume)",
          "2262:  if err != nil {",
          "2263:   return err",
          "2264:  }",
          "2266:  return s.writeAll(ctx, volume, path, b, true, volumeDir)",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "2261:  var w *os.File",
          "2265:  if err != nil {",
          "2266:   return err",
          "2267:  }",
          "",
          "[Removed Lines]",
          "2264:  w, err = s.openFileSync(filePath, os.O_CREATE|os.O_APPEND|os.O_WRONLY)",
          "",
          "[Added Lines]",
          "2292:  w, err = s.openFileSync(filePath, os.O_CREATE|os.O_APPEND|os.O_WRONLY, volumeDir)",
          "",
          "---------------",
          "--- Hunk 14 ---",
          "[Context before]",
          "2425: }",
          "2429:  defer func() {",
          "2430:   ignoredErrs := []error{",
          "2431:    errFileNotFound,",
          "",
          "[Removed Lines]",
          "2428: func (s *xlStorage) RenameData(ctx context.Context, srcVolume, srcPath string, fi FileInfo, dstVolume, dstPath string, opts RenameOptions) (sign uint64, err error) {",
          "",
          "[Added Lines]",
          "2456: func (s *xlStorage) RenameData(ctx context.Context, srcVolume, srcPath string, fi FileInfo, dstVolume, dstPath string, opts RenameOptions) (res RenameDataResp, err error) {",
          "",
          "---------------",
          "--- Hunk 15 ---",
          "[Context before]",
          "2452:  srcVolumeDir, err := s.getVolDir(srcVolume)",
          "2453:  if err != nil {",
          "2455:  }",
          "2457:  dstVolumeDir, err := s.getVolDir(dstVolume)",
          "2458:  if err != nil {",
          "2460:  }",
          "2462:  if !skipAccessChecks(srcVolume) {",
          "2464:   if err = Access(srcVolumeDir); err != nil {",
          "2466:   }",
          "2467:  }",
          "2469:  if !skipAccessChecks(dstVolume) {",
          "2470:   if err = Access(dstVolumeDir); err != nil {",
          "2472:   }",
          "2473:  }",
          "",
          "[Removed Lines]",
          "2454:   return 0, err",
          "2459:   return 0, err",
          "2465:    return 0, convertAccessError(err, errVolumeAccessDenied)",
          "2471:    return 0, convertAccessError(err, errVolumeAccessDenied)",
          "",
          "[Added Lines]",
          "2482:   return res, err",
          "2487:   return res, err",
          "2493:    return res, convertAccessError(err, errVolumeAccessDenied)",
          "2499:    return res, convertAccessError(err, errVolumeAccessDenied)",
          "",
          "---------------",
          "--- Hunk 16 ---",
          "[Context before]",
          "2490:  }",
          "2492:  if err = checkPathLength(srcFilePath); err != nil {",
          "2494:  }",
          "2496:  if err = checkPathLength(dstFilePath); err != nil {",
          "2498:  }",
          "2500:  dstBuf, err := xioutil.ReadFile(dstFilePath)",
          "2501:  if err != nil {",
          "",
          "[Removed Lines]",
          "2493:   return 0, err",
          "2497:   return 0, err",
          "",
          "[Added Lines]",
          "2521:   return res, err",
          "2525:   return res, err",
          "2528:  s.RLock()",
          "2529:  formatLegacy := s.formatLegacy",
          "2530:  s.RUnlock()",
          "",
          "---------------",
          "--- Hunk 17 ---",
          "[Context before]",
          "2506:   if isSysErrNotDir(err) && runtime.GOOS != globalWindowsOSName {",
          "2510:   }",
          "2511:   if !osIsNotExist(err) {",
          "2518:   }",
          "2523:    }",
          "2524:   }",
          "2525:  }",
          "",
          "[Removed Lines]",
          "2509:    return 0, errFileAccessDenied",
          "2512:    return 0, osErrToFileErr(err)",
          "2513:   }",
          "2515:   err = s.renameLegacyMetadata(dstVolumeDir, dstPath)",
          "2516:   if err != nil && err != errFileNotFound {",
          "2517:    return 0, err",
          "2519:   if err == nil {",
          "2520:    dstBuf, err = xioutil.ReadFile(dstFilePath)",
          "2521:    if err != nil && !osIsNotExist(err) {",
          "2522:     return 0, osErrToFileErr(err)",
          "",
          "[Added Lines]",
          "2541:    return res, errFileAccessDenied",
          "2544:    return res, osErrToFileErr(err)",
          "2546:   if formatLegacy {",
          "2548:    err = s.renameLegacyMetadata(dstVolumeDir, dstPath)",
          "2549:    if err != nil && err != errFileNotFound {",
          "2550:     return res, err",
          "2551:    }",
          "2552:    if err == nil {",
          "2553:     dstBuf, err = xioutil.ReadFile(dstFilePath)",
          "2554:     if err != nil && !osIsNotExist(err) {",
          "2555:      return res, osErrToFileErr(err)",
          "2556:     }",
          "",
          "---------------",
          "--- Hunk 18 ---",
          "[Context before]",
          "2548:    }",
          "2549:   }",
          "2550:  } else {",
          "",
          "[Removed Lines]",
          "2551:   s.RLock()",
          "2552:   formatLegacy := s.formatLegacy",
          "2553:   s.RUnlock()",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 19 ---",
          "[Context before]",
          "2562:    currentDataPath := pathJoin(dstVolumeDir, dstPath)",
          "2563:    entries, err := readDirN(currentDataPath, 1)",
          "2564:    if err != nil && err != errFileNotFound {",
          "2566:    }",
          "2567:    for _, entry := range entries {",
          "2568:     if entry == xlStorageFormatFile || strings.HasSuffix(entry, slashSeparator) {",
          "",
          "[Removed Lines]",
          "2565:     return 0, osErrToFileErr(err)",
          "",
          "[Added Lines]",
          "2596:     return res, osErrToFileErr(err)",
          "",
          "---------------",
          "--- Hunk 20 ---",
          "[Context before]",
          "2576:   }",
          "2577:  }",
          "2599:    }",
          "2603:     s.deleteFile(dstVolumeDir, legacyDataPath, true, false)",
          "2606:    }",
          "2607:   }",
          "2608:  }",
          "2612:  if fi.VersionID == \"\" {",
          "2613:   reqVID = nullVersionID",
          "2614:  } else {",
          "2615:   reqVID = fi.VersionID",
          "2616:  }",
          "",
          "[Removed Lines]",
          "2579:  legacyDataPath := pathJoin(dstVolumeDir, dstPath, legacyDataDir)",
          "2580:  if legacyPreserved {",
          "2582:   currentDataPath := pathJoin(dstVolumeDir, dstPath)",
          "2583:   entries, err := readDir(currentDataPath)",
          "2584:   if err != nil {",
          "2585:    return 0, osErrToFileErr(err)",
          "2586:   }",
          "2589:   if err = mkdirAll(legacyDataPath, 0o777, dstVolumeDir); err != nil {",
          "2591:    s.deleteFile(dstVolumeDir, legacyDataPath, true, false)",
          "2592:    return 0, osErrToFileErr(err)",
          "2593:   }",
          "2595:   for _, entry := range entries {",
          "2597:    if entry == xlStorageFormatFile || strings.HasSuffix(entry, slashSeparator) {",
          "2598:     continue",
          "2601:    if err = Rename(pathJoin(currentDataPath, entry), pathJoin(legacyDataPath, entry)); err != nil {",
          "2605:     return 0, osErrToFileErr(err)",
          "2610:  var oldDstDataPath, reqVID string",
          "2619:  _, ver, err := xlMeta.findVersionStr(reqVID)",
          "2620:  if err == nil {",
          "2621:   dataDir := ver.getDataDir()",
          "2622:   if dataDir != \"\" && (xlMeta.SharedDataDirCountStr(reqVID, dataDir) == 0) {",
          "2625:    oldDstDataPath = pathJoin(dstVolumeDir, dstPath, dataDir)",
          "2629:    if oldDstDataPath == dstDataPath {",
          "2630:     oldDstDataPath = \"\"",
          "2631:    } else {",
          "2632:     xlMeta.data.remove(reqVID, dataDir)",
          "2633:    }",
          "2634:   }",
          "2635:  }",
          "",
          "[Added Lines]",
          "2610:  var legacyDataPath string",
          "2611:  if formatLegacy {",
          "2612:   legacyDataPath = pathJoin(dstVolumeDir, dstPath, legacyDataDir)",
          "2613:   if legacyPreserved {",
          "2615:    currentDataPath := pathJoin(dstVolumeDir, dstPath)",
          "2616:    entries, err := readDir(currentDataPath)",
          "2617:    if err != nil {",
          "2618:     return res, osErrToFileErr(err)",
          "2622:    if err = mkdirAll(legacyDataPath, 0o777, dstVolumeDir); err != nil {",
          "2625:     return res, osErrToFileErr(err)",
          "2626:    }",
          "2628:    for _, entry := range entries {",
          "2630:     if entry == xlStorageFormatFile || strings.HasSuffix(entry, slashSeparator) {",
          "2631:      continue",
          "2632:     }",
          "2634:     if err = Rename(pathJoin(currentDataPath, entry), pathJoin(legacyDataPath, entry)); err != nil {",
          "2636:      s.deleteFile(dstVolumeDir, legacyDataPath, true, false)",
          "2638:      return res, osErrToFileErr(err)",
          "2639:     }",
          "2650:  skipParent := dstVolumeDir",
          "2651:  if len(dstBuf) > 0 {",
          "2652:   skipParent = pathutil.Dir(dstFilePath)",
          "2653:  }",
          "2655:  var reqVID string",
          "",
          "---------------",
          "--- Hunk 21 ---",
          "[Context before]",
          "2651:  }",
          "2657:  if err = xlMeta.AddVersion(fi); err != nil {",
          "2658:   if legacyPreserved {",
          "2660:    s.deleteFile(dstVolumeDir, legacyDataPath, true, false)",
          "2661:   }",
          "2663:  }",
          "2668:  }",
          "2673:  if err != nil {",
          "2674:   if legacyPreserved {",
          "2675:    s.deleteFile(dstVolumeDir, legacyDataPath, true, false)",
          "2676:   }",
          "2678:  }",
          "2681:   if legacyPreserved {",
          "2682:    s.deleteFile(dstVolumeDir, legacyDataPath, true, false)",
          "2683:   }",
          "2685:  }",
          "2686:  diskHealthCheckOK(ctx, err)",
          "2691:   if healing {",
          "2695:    s.moveToTrash(legacyDataPath, true, false)",
          "2696:   }",
          "2698:    if legacyPreserved {",
          "2700:     s.deleteFile(dstVolumeDir, legacyDataPath, true, false)",
          "2701:    }",
          "2702:    s.deleteFile(dstVolumeDir, dstDataPath, false, false)",
          "2704:   }",
          "2705:  }",
          "2709:   if legacyPreserved {",
          "2711:    s.deleteFile(dstVolumeDir, legacyDataPath, true, false)",
          "2712:   }",
          "2713:   s.deleteFile(dstVolumeDir, dstDataPath, false, false)",
          "2722:  }",
          "2724:  if srcVolume != minioMetaMultipartBucket {",
          "",
          "[Removed Lines]",
          "2655:  healing := fi.XLV1 && fi.DataDir != legacyDataDir",
          "2662:   return 0, err",
          "2665:  var sbuf bytes.Buffer",
          "2666:  for _, ver := range xlMeta.versions {",
          "2667:   sbuf.Write(ver.header.Signature[:])",
          "2669:  sign = xxh3.Hash(sbuf.Bytes())",
          "2671:  dstBuf, err = xlMeta.AppendTo(metaDataPoolGet())",
          "2672:  defer metaDataPoolPut(dstBuf)",
          "2677:   return 0, errFileCorrupt",
          "2680:  if err = s.WriteAll(ctx, srcVolume, pathJoin(srcPath, xlStorageFormatFile), dstBuf); err != nil {",
          "2684:   return 0, osErrToFileErr(err)",
          "2688:  if srcDataPath != \"\" && len(fi.Data) == 0 && fi.Size > 0 {",
          "2690:   s.moveToTrash(dstDataPath, true, false)",
          "2697:   if err = renameAll(srcDataPath, dstDataPath, dstVolumeDir); err != nil {",
          "2703:    return 0, osErrToFileErr(err)",
          "2708:  if err = renameAll(srcFilePath, dstFilePath, dstVolumeDir); err != nil {",
          "2714:   return 0, osErrToFileErr(err)",
          "2715:  }",
          "2720:  if oldDstDataPath != \"\" {",
          "2721:   s.moveToTrash(oldDstDataPath, true, false)",
          "",
          "[Added Lines]",
          "2679:  healing := fi.Healing()",
          "2682:  _, ver, err := xlMeta.findVersionStr(reqVID)",
          "2683:  if err == nil {",
          "2684:   dataDir := ver.getDataDir()",
          "2685:   if dataDir != \"\" && (xlMeta.SharedDataDirCountStr(reqVID, dataDir) == 0) {",
          "2688:    res.OldDataDir = dataDir",
          "2689:    if healing {",
          "2693:     res.OldDataDir = \"\"",
          "2694:    } else {",
          "2695:     xlMeta.data.remove(reqVID, dataDir)",
          "2696:    }",
          "2697:   }",
          "2698:  }",
          "2705:   return res, err",
          "2708:  if len(xlMeta.versions) <= 10 {",
          "2712:   dst := []byte{}",
          "2713:   for _, ver := range xlMeta.versions {",
          "2714:    dst = slices.Grow(dst, 16)",
          "2715:    copy(dst[len(dst):], ver.header.VersionID[:])",
          "2716:   }",
          "2717:   res.Sign = dst",
          "2720:  newDstBuf, err := xlMeta.AppendTo(metaDataPoolGet())",
          "2721:  defer metaDataPoolPut(newDstBuf)",
          "2726:   return res, errFileCorrupt",
          "2729:  if err = s.WriteAll(ctx, srcVolume, pathJoin(srcPath, xlStorageFormatFile), newDstBuf); err != nil {",
          "2733:   return res, osErrToFileErr(err)",
          "2737:  notInline := srcDataPath != \"\" && len(fi.Data) == 0 && fi.Size > 0",
          "2738:  if notInline {",
          "2745:    s.moveToTrash(dstDataPath, true, false)",
          "2752:   if err = renameAll(srcDataPath, dstDataPath, skipParent); err != nil {",
          "2759:    return res, osErrToFileErr(err)",
          "2767:  if notInline && res.OldDataDir != \"\" {",
          "2769:   if err = s.writeAll(ctx, dstVolume, pathJoin(dstPath, res.OldDataDir, xlStorageFormatFileBackup), dstBuf, true, skipParent); err != nil {",
          "2770:    if legacyPreserved {",
          "2771:     s.deleteFile(dstVolumeDir, legacyDataPath, true, false)",
          "2772:    }",
          "2773:    return res, osErrToFileErr(err)",
          "2774:   }",
          "2775:   diskHealthCheckOK(ctx, err)",
          "2776:  }",
          "2779:  if err = renameAll(srcFilePath, dstFilePath, skipParent); err != nil {",
          "2787:   return res, osErrToFileErr(err)",
          "",
          "---------------",
          "--- Hunk 22 ---",
          "[Context before]",
          "2729:  } else {",
          "2730:   s.deleteFile(srcVolumeDir, pathutil.Dir(srcFilePath), true, false)",
          "2731:  }",
          "2733: }",
          "",
          "[Removed Lines]",
          "2732:  return sign, nil",
          "",
          "[Added Lines]",
          "2798:  return res, nil",
          "",
          "---------------",
          "--- Hunk 23 ---",
          "[Context before]",
          "3048:  for dir := range foundDirs {",
          "3049:   toRemove := pathJoin(volumeDir, path, dir+SlashSeparator)",
          "3051:   diskHealthCheckOK(ctx, err)",
          "3052:  }",
          "",
          "[Removed Lines]",
          "3050:   err := s.deleteFile(volumeDir, toRemove, true, true)",
          "",
          "[Added Lines]",
          "3116:   err = s.deleteFile(volumeDir, toRemove, true, true)",
          "3118:   if err != nil {",
          "3119:    return err",
          "3120:   }",
          "",
          "---------------",
          "--- Hunk 24 ---",
          "[Context before]",
          "3056:  if err != nil {",
          "3057:   return err",
          "3058:  }",
          "3060:  for k := range foundDirs {",
          "3061:   delete(foundDirs, k)",
          "3062:  }",
          "3064:  for _, k := range dirs {",
          "3065:   foundDirs[k] = struct{}{}",
          "3066:  }",
          "3068:  for _, dir := range wantDirs {",
          "3069:   delete(foundDirs, dir)",
          "3070:  }",
          "3085:   }",
          "3086:  }",
          "3087:  return nil",
          "",
          "[Removed Lines]",
          "3073:  if len(foundDirs) > 0 {",
          "3075:   dirs = dirs[:0]",
          "3076:   for dir := range foundDirs {",
          "3077:    dirs = append(dirs, dir)",
          "3078:   }",
          "3079:   if xl.data.remove(dirs...) {",
          "3080:    newBuf, err := xl.AppendTo(metaDataPoolGet())",
          "3081:    if err == nil {",
          "3082:     defer metaDataPoolPut(newBuf)",
          "3083:     return s.WriteAll(ctx, volume, pathJoin(path, xlStorageFormatFile), buf)",
          "3084:    }",
          "",
          "[Added Lines]",
          "3145:  if len(foundDirs) == 0 {",
          "3146:   return nil",
          "3147:  }",
          "3151:  dirs = dirs[:0]",
          "3152:  for dir := range foundDirs {",
          "3153:   dirs = append(dirs, dir)",
          "3154:  }",
          "3155:  if xl.data.remove(dirs...) {",
          "3156:   newBuf, err := xl.AppendTo(metaDataPoolGet())",
          "3157:   if err == nil {",
          "3158:    defer metaDataPoolPut(newBuf)",
          "3159:    return s.WriteAll(ctx, volume, pathJoin(path, xlStorageFormatFile), buf)",
          "",
          "---------------"
        ],
        "internal/grid/handlers.go||internal/grid/handlers.go": [
          "File: internal/grid/handlers.go -> internal/grid/handlers.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "111:  HandlerWriteAll",
          "112:  HandlerListBuckets",
          "113:  HandlerRenameDataInline",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "114:  HandlerRenameData2",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "189:  HandlerConsoleLog:                  peerPrefix,",
          "190:  HandlerListDir:                     storagePrefix,",
          "191:  HandlerListBuckets:                 peerPrefixS3,",
          "192: }",
          "194: const (",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "193:  HandlerRenameDataInline:            storagePrefix,",
          "194:  HandlerRenameData2:                 storagePrefix,",
          "",
          "---------------"
        ],
        "internal/grid/handlers_string.go||internal/grid/handlers_string.go": [
          "File: internal/grid/handlers_string.go -> internal/grid/handlers_string.go",
          "--- Hunk 1 ---",
          "[Context before]",
          "81:  _ = x[HandlerWriteAll-70]",
          "82:  _ = x[HandlerListBuckets-71]",
          "83:  _ = x[HandlerRenameDataInline-72]",
          "87: }",
          "93: func (i HandlerID) String() string {",
          "94:  if i >= HandlerID(len(_HandlerID_index)-1) {",
          "",
          "[Removed Lines]",
          "84:  _ = x[handlerTest-73]",
          "85:  _ = x[handlerTest2-74]",
          "86:  _ = x[handlerLast-75]",
          "89: const _HandlerID_name = \"handlerInvalidLockLockLockRLockLockUnlockLockRUnlockLockRefreshLockForceUnlockWalkDirStatVolDiskInfoNSScannerReadXLReadVersionDeleteFileDeleteVersionUpdateMetadataWriteMetadataCheckPartsRenameDataRenameFileReadAllServerVerifyTraceListenDeleteBucketMetadataLoadBucketMetadataReloadSiteReplicationConfigReloadPoolMetaStopRebalanceLoadRebalanceMetaLoadTransitionTierConfigDeletePolicyLoadPolicyLoadPolicyMappingDeleteServiceAccountLoadServiceAccountDeleteUserLoadUserLoadGroupHealBucketMakeBucketHeadBucketDeleteBucketGetMetricsGetResourceMetricsGetMemInfoGetProcInfoGetOSInfoGetPartitionsGetNetInfoGetCPUsServerInfoGetSysConfigGetSysServicesGetSysErrorsGetAllBucketStatsGetBucketStatsGetSRMetricsGetPeerMetricsGetMetacacheListingUpdateMetacacheListingGetPeerBucketMetricsStorageInfoConsoleLogListDirGetLocksBackgroundHealStatusGetLastDayTierStatsSignalServiceGetBandwidthWriteAllListBucketsRenameDataInlinehandlerTesthandlerTest2handlerLast\"",
          "91: var _HandlerID_index = [...]uint16{0, 14, 22, 31, 41, 52, 63, 78, 85, 92, 100, 109, 115, 126, 136, 149, 163, 176, 186, 196, 206, 213, 225, 230, 236, 256, 274, 301, 315, 328, 345, 369, 381, 391, 408, 428, 446, 456, 464, 473, 483, 493, 503, 515, 525, 543, 553, 564, 573, 586, 596, 603, 613, 625, 639, 651, 668, 682, 694, 708, 727, 749, 769, 780, 790, 797, 805, 825, 844, 857, 869, 877, 888, 904, 915, 927, 938}",
          "",
          "[Added Lines]",
          "84:  _ = x[HandlerRenameData2-73]",
          "85:  _ = x[handlerTest-74]",
          "86:  _ = x[handlerTest2-75]",
          "87:  _ = x[handlerLast-76]",
          "90: const _HandlerID_name = \"handlerInvalidLockLockLockRLockLockUnlockLockRUnlockLockRefreshLockForceUnlockWalkDirStatVolDiskInfoNSScannerReadXLReadVersionDeleteFileDeleteVersionUpdateMetadataWriteMetadataCheckPartsRenameDataRenameFileReadAllServerVerifyTraceListenDeleteBucketMetadataLoadBucketMetadataReloadSiteReplicationConfigReloadPoolMetaStopRebalanceLoadRebalanceMetaLoadTransitionTierConfigDeletePolicyLoadPolicyLoadPolicyMappingDeleteServiceAccountLoadServiceAccountDeleteUserLoadUserLoadGroupHealBucketMakeBucketHeadBucketDeleteBucketGetMetricsGetResourceMetricsGetMemInfoGetProcInfoGetOSInfoGetPartitionsGetNetInfoGetCPUsServerInfoGetSysConfigGetSysServicesGetSysErrorsGetAllBucketStatsGetBucketStatsGetSRMetricsGetPeerMetricsGetMetacacheListingUpdateMetacacheListingGetPeerBucketMetricsStorageInfoConsoleLogListDirGetLocksBackgroundHealStatusGetLastDayTierStatsSignalServiceGetBandwidthWriteAllListBucketsRenameDataInlineRenameData2handlerTesthandlerTest2handlerLast\"",
          "92: var _HandlerID_index = [...]uint16{0, 14, 22, 31, 41, 52, 63, 78, 85, 92, 100, 109, 115, 126, 136, 149, 163, 176, 186, 196, 206, 213, 225, 230, 236, 256, 274, 301, 315, 328, 345, 369, 381, 391, 408, 428, 446, 456, 464, 473, 483, 493, 503, 515, 525, 543, 553, 564, 573, 586, 596, 603, 613, 625, 639, 651, 668, 682, 694, 708, 727, 749, 769, 780, 790, 797, 805, 825, 844, 857, 869, 877, 888, 904, 915, 926, 938, 949}",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "e5335450a4a9333215bae8ed03442d1ac258ec63",
      "candidate_info": {
        "commit_hash": "e5335450a4a9333215bae8ed03442d1ac258ec63",
        "repo": "minio/minio",
        "commit_url": "https://github.com/minio/minio/commit/e5335450a4a9333215bae8ed03442d1ac258ec63",
        "files": [
          "buildscripts/verify-healing-empty-erasure-set.sh",
          "buildscripts/verify-healing.sh"
        ],
        "message": "test: Healing test to avoid infinite waiting for servers to be up (#19954)\n\ntests: Healing test to avoid infinite waiting for servers to be up\n\nQuit after 15 minutes and print server logs instead",
        "before_after_code_files": [
          "buildscripts/verify-healing-empty-erasure-set.sh||buildscripts/verify-healing-empty-erasure-set.sh",
          "buildscripts/verify-healing.sh||buildscripts/verify-healing.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "buildscripts/verify-healing-empty-erasure-set.sh||buildscripts/verify-healing-empty-erasure-set.sh",
            "buildscripts/verify-healing.sh||buildscripts/verify-healing.sh"
          ],
          "candidate": [
            "buildscripts/verify-healing-empty-erasure-set.sh||buildscripts/verify-healing-empty-erasure-set.sh",
            "buildscripts/verify-healing.sh||buildscripts/verify-healing.sh"
          ]
        }
      },
      "candidate_diff": {
        "buildscripts/verify-healing-empty-erasure-set.sh||buildscripts/verify-healing-empty-erasure-set.sh": [
          "File: buildscripts/verify-healing-empty-erasure-set.sh -> buildscripts/verify-healing-empty-erasure-set.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "40:  export MC_HOST_myminio=\"http://minio:minio123@127.0.0.1:$((start_port + 1))\"",
          "44:  # Wait for all drives to be online and formatted",
          "45:  while [ $(/tmp/mc admin info --json myminio | jq '.info.servers[].drives[].state | select(. != \"ok\")' | wc -l) -gt 0 ]; do sleep 1; done",
          "",
          "[Removed Lines]",
          "42:  /tmp/mc ready myminio",
          "",
          "[Added Lines]",
          "42:  timeout 15m /tmp/mc ready myminio || fail",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "62:   fi",
          "64:   # Failure",
          "73:  done",
          "75:  if ! ps -p $pid1 1>&2 >/dev/null; then",
          "81:  fi",
          "83:  if ! ps -p $pid2 1>&2 >/dev/null; then",
          "89:  fi",
          "91:  if ! ps -p $pid3 1>&2 >/dev/null; then",
          "97:  fi",
          "99:  if ! pkill minio; then",
          "107:  fi",
          "109:  sleep 1",
          "",
          "[Removed Lines]",
          "65:   for i in $(seq 1 3); do",
          "66:    echo \"server$i log:\"",
          "67:    cat \"${WORK_DIR}/dist-minio-server$i.log\"",
          "68:   done",
          "69:   pkill -9 minio",
          "70:   echo \"FAILED\"",
          "71:   purge \"$WORK_DIR\"",
          "72:   exit 1",
          "76:   echo \"server1 log:\"",
          "77:   cat \"${WORK_DIR}/dist-minio-server1.log\"",
          "78:   echo \"FAILED\"",
          "79:   purge \"$WORK_DIR\"",
          "80:   exit 1",
          "84:   echo \"server2 log:\"",
          "85:   cat \"${WORK_DIR}/dist-minio-server2.log\"",
          "86:   echo \"FAILED\"",
          "87:   purge \"$WORK_DIR\"",
          "88:   exit 1",
          "92:   echo \"server3 log:\"",
          "93:   cat \"${WORK_DIR}/dist-minio-server3.log\"",
          "94:   echo \"FAILED\"",
          "95:   purge \"$WORK_DIR\"",
          "96:   exit 1",
          "100:   for i in $(seq 1 3); do",
          "101:    echo \"server$i log:\"",
          "102:    cat \"${WORK_DIR}/dist-minio-server$i.log\"",
          "103:   done",
          "104:   echo \"FAILED\"",
          "105:   purge \"$WORK_DIR\"",
          "106:   exit 1",
          "",
          "[Added Lines]",
          "65:   fail",
          "69:   echo \"minio-server-1 is not running.\" && fail",
          "73:   echo \"minio-server-2 is not running.\" && fail",
          "77:   echo \"minio-server-3 is not running.\" && fail",
          "81:   fail",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "115:  fi",
          "116: }",
          "118: function check_online() {",
          "119:  if ! grep -q 'Status:' ${WORK_DIR}/dist-minio-*.log; then",
          "120:   echo \"1\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "93: function fail() {",
          "94:  for i in $(seq 1 3); do",
          "95:   echo \"server$i log:\"",
          "96:   cat \"${WORK_DIR}/dist-minio-server$i.log\"",
          "97:  done",
          "98:  echo \"FAILED\"",
          "99:  purge \"$WORK_DIR\"",
          "100:  exit 1",
          "101: }",
          "",
          "---------------"
        ],
        "buildscripts/verify-healing.sh||buildscripts/verify-healing.sh": [
          "File: buildscripts/verify-healing.sh -> buildscripts/verify-healing.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "47:  disown $pid3",
          "49:  export MC_HOST_myminio=\"http://minio:minio123@127.0.0.1:$((start_port + 1))\"",
          "52:  [ ${first_time} -eq 0 ] && upload_objects",
          "53:  [ ${first_time} -ne 0 ] && sleep 120",
          "55:  if ! ps -p $pid1 1>&2 >/dev/null; then",
          "61:  fi",
          "63:  if ! ps -p $pid2 1>&2 >/dev/null; then",
          "69:  fi",
          "71:  if ! ps -p $pid3 1>&2 >/dev/null; then",
          "77:  fi",
          "79:  if ! pkill minio; then",
          "87:  fi",
          "89:  sleep 1",
          "",
          "[Removed Lines]",
          "50:  /tmp/mc ready myminio",
          "56:   echo \"server1 log:\"",
          "57:   cat \"${WORK_DIR}/dist-minio-server1.log\"",
          "58:   echo \"FAILED\"",
          "59:   purge \"$WORK_DIR\"",
          "60:   exit 1",
          "64:   echo \"server2 log:\"",
          "65:   cat \"${WORK_DIR}/dist-minio-server2.log\"",
          "66:   echo \"FAILED\"",
          "67:   purge \"$WORK_DIR\"",
          "68:   exit 1",
          "72:   echo \"server3 log:\"",
          "73:   cat \"${WORK_DIR}/dist-minio-server3.log\"",
          "74:   echo \"FAILED\"",
          "75:   purge \"$WORK_DIR\"",
          "76:   exit 1",
          "80:   for i in $(seq 1 3); do",
          "81:    echo \"server$i log:\"",
          "82:    cat \"${WORK_DIR}/dist-minio-server$i.log\"",
          "83:   done",
          "84:   echo \"FAILED\"",
          "85:   purge \"$WORK_DIR\"",
          "86:   exit 1",
          "",
          "[Added Lines]",
          "50:  timeout 15m /tmp/mc ready myminio || fail",
          "56:   echo \"minio server 1 is not running\" && fail",
          "60:   echo \"minio server 2 is not running\" && fail",
          "64:   echo \"minio server 3 is not running\" && fail",
          "68:   fail",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "118:  rm -rf \"$1\"",
          "119: }",
          "121: function __init__() {",
          "122:  echo \"Initializing environment\"",
          "123:  mkdir -p \"$WORK_DIR\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "103: function fail() {",
          "104:  for i in $(seq 1 3); do",
          "105:   echo \"server$i log:\"",
          "106:   cat \"${WORK_DIR}/dist-minio-server$i.log\"",
          "107:  done",
          "108:  pkill -9 minio",
          "109:  echo \"FAILED\"",
          "110:  purge \"$WORK_DIR\"",
          "111:  exit 1",
          "112: }",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "155:  check_heal ${1}",
          "156:  rv=$?",
          "157:  if [ \"$rv\" == \"1\" ]; then",
          "166:  fi",
          "167: }",
          "",
          "[Removed Lines]",
          "158:   for i in $(seq 1 3); do",
          "159:    echo \"server$i log:\"",
          "160:    cat \"${WORK_DIR}/dist-minio-server$i.log\"",
          "161:   done",
          "162:   pkill -9 minio",
          "163:   echo \"FAILED\"",
          "164:   purge \"$WORK_DIR\"",
          "165:   exit 1",
          "",
          "[Added Lines]",
          "151:   fail",
          "",
          "---------------"
        ]
      }
    }
  ]
}