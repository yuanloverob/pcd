{
  "cve_id": "CVE-2024-7042",
  "cve_desc": "A vulnerability in the GraphCypherQAChain class of langchain-ai/langchainjs versions 0.2.5 and all versions with this class allows for prompt injection, leading to SQL injection. This vulnerability permits unauthorized data manipulation, data exfiltration, denial of service (DoS) by deleting all data, breaches in multi-tenant security environments, and data integrity issues. Attackers can create, update, or delete nodes and relationships without proper authorization, extract sensitive data, disrupt services, access data across different tenants, and compromise the integrity of the database.",
  "repo": "langchain-ai/langchainjs",
  "patch_hash": "615b9d9ab30a2d23a2f95fb8d7acfdf4b41ad7a6",
  "patch_info": {
    "commit_hash": "615b9d9ab30a2d23a2f95fb8d7acfdf4b41ad7a6",
    "repo": "langchain-ai/langchainjs",
    "commit_url": "https://github.com/langchain-ai/langchainjs/commit/615b9d9ab30a2d23a2f95fb8d7acfdf4b41ad7a6",
    "files": [
      "examples/package.json",
      "examples/src/indexes/vector_stores/lancedb/fromDocs.ts",
      "examples/src/indexes/vector_stores/lancedb/fromTexts.ts",
      "libs/langchain-community/package.json",
      "libs/langchain-community/src/vectorstores/lancedb.ts",
      "libs/langchain-community/src/vectorstores/tests/lancedb.int.test.ts",
      "yarn.lock"
    ],
    "message": "feat(community): Remove required param from LanceDB integration (#6706)\n\nCo-authored-by: jacoblee93 <jacoblee93@gmail.com>",
    "before_after_code_files": [
      "examples/src/indexes/vector_stores/lancedb/fromDocs.ts||examples/src/indexes/vector_stores/lancedb/fromDocs.ts",
      "examples/src/indexes/vector_stores/lancedb/fromTexts.ts||examples/src/indexes/vector_stores/lancedb/fromTexts.ts",
      "libs/langchain-community/src/vectorstores/lancedb.ts||libs/langchain-community/src/vectorstores/lancedb.ts",
      "libs/langchain-community/src/vectorstores/tests/lancedb.int.test.ts||libs/langchain-community/src/vectorstores/tests/lancedb.int.test.ts",
      "yarn.lock||yarn.lock"
    ]
  },
  "patch_diff": {
    "examples/src/indexes/vector_stores/lancedb/fromDocs.ts||examples/src/indexes/vector_stores/lancedb/fromDocs.ts": [
      "File: examples/src/indexes/vector_stores/lancedb/fromDocs.ts -> examples/src/indexes/vector_stores/lancedb/fromDocs.ts",
      "--- Hunk 1 ---",
      "[Context before]",
      "4: import fs from \"node:fs/promises\";",
      "5: import path from \"node:path\";",
      "6: import os from \"node:os\";",
      "10: const loader = new TextLoader(\"src/document_loaders/example_data/example.txt\");",
      "11: const docs = await loader.load();",
      "13: export const run = async () => {",
      "14:   const dir = await fs.mkdtemp(path.join(os.tmpdir(), \"lancedb-\"));",
      "26:   const resultOne = await vectorStore.similaritySearch(\"hello world\", 1);",
      "27:   console.log(resultOne);",
      "",
      "[Removed Lines]",
      "7: import { connect } from \"vectordb\";",
      "15:   const db = await connect(dir);",
      "16:   const table = await db.createTable(\"vectors\", [",
      "17:     { vector: Array(1536), text: \"sample\", source: \"a\" },",
      "18:   ]);",
      "20:   const vectorStore = await LanceDB.fromDocuments(",
      "21:     docs,",
      "22:     new OpenAIEmbeddings(),",
      "23:     { table }",
      "24:   );",
      "",
      "[Added Lines]",
      "13:   const vectorStore = await LanceDB.fromDocuments(docs, new OpenAIEmbeddings());",
      "15:   const resultOne = await vectorStore.similaritySearch(\"hello world\", 1);",
      "16:   console.log(resultOne);",
      "24: };",
      "26: export const run_with_existing_table = async () => {",
      "29:   const vectorStore = await LanceDB.fromDocuments(docs, new OpenAIEmbeddings());",
      "",
      "---------------"
    ],
    "examples/src/indexes/vector_stores/lancedb/fromTexts.ts||examples/src/indexes/vector_stores/lancedb/fromTexts.ts": [
      "File: examples/src/indexes/vector_stores/lancedb/fromTexts.ts -> examples/src/indexes/vector_stores/lancedb/fromTexts.ts",
      "--- Hunk 1 ---",
      "[Context before]",
      "1: import { LanceDB } from \"@langchain/community/vectorstores/lancedb\";",
      "2: import { OpenAIEmbeddings } from \"@langchain/openai\";",
      "4: import * as fs from \"node:fs/promises\";",
      "5: import * as path from \"node:path\";",
      "6: import os from \"node:os\";",
      "8: export const run = async () => {",
      "15:   const vectorStore = await LanceDB.fromTexts(",
      "16:     [\"Hello world\", \"Bye bye\", \"hello nice world\"],",
      "17:     [{ id: 2 }, { id: 1 }, { id: 3 }],",
      "20:   );",
      "22:   const resultOne = await vectorStore.similaritySearch(\"hello world\", 1);",
      "",
      "[Removed Lines]",
      "3: import { connect } from \"vectordb\";",
      "9:   const dir = await fs.mkdtemp(path.join(os.tmpdir(), \"lancedb-\"));",
      "10:   const db = await connect(dir);",
      "11:   const table = await db.createTable(\"vectors\", [",
      "12:     { vector: Array(1536), text: \"sample\", id: 1 },",
      "13:   ]);",
      "18:     new OpenAIEmbeddings(),",
      "19:     { table }",
      "",
      "[Added Lines]",
      "8:   const vectorStore = await LanceDB.fromTexts(",
      "9:     [\"Hello world\", \"Bye bye\", \"hello nice world\"],",
      "10:     [{ id: 2 }, { id: 1 }, { id: 3 }],",
      "11:     new OpenAIEmbeddings()",
      "12:   );",
      "14:   const resultOne = await vectorStore.similaritySearch(\"hello world\", 1);",
      "15:   console.log(resultOne);",
      "17: };",
      "19: export const run_with_existing_table = async () => {",
      "20:   const dir = await fs.mkdtemp(path.join(os.tmpdir(), \"lancedb-\"));",
      "24:     new OpenAIEmbeddings()",
      "",
      "---------------"
    ],
    "libs/langchain-community/src/vectorstores/lancedb.ts||libs/langchain-community/src/vectorstores/lancedb.ts": [
      "File: libs/langchain-community/src/vectorstores/lancedb.ts -> libs/langchain-community/src/vectorstores/lancedb.ts",
      "--- Hunk 1 ---",
      "[Context before]",
      "2: import type { EmbeddingsInterface } from \"@langchain/core/embeddings\";",
      "3: import { VectorStore } from \"@langchain/core/vectorstores\";",
      "4: import { Document } from \"@langchain/core/documents\";",
      "",
      "[Removed Lines]",
      "1: import { Table } from \"vectordb\";",
      "",
      "[Added Lines]",
      "1: import { connect, Table, Connection, WriteMode } from \"vectordb\";",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "10: export type LanceDBArgs = {",
      "12:   textKey?: string;",
      "13: };",
      "",
      "[Removed Lines]",
      "11:   table: Table;",
      "",
      "[Added Lines]",
      "11:   table?: Table;",
      "13:   uri?: string;",
      "14:   tableName?: string;",
      "15:   mode?: WriteMode;",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "20: export class LanceDB extends VectorStore {",
      "23:   private textKey: string;",
      "28:     this.embeddings = embeddings;",
      "30:   }",
      "",
      "[Removed Lines]",
      "21:   private table: Table;",
      "25:   constructor(embeddings: EmbeddingsInterface, args: LanceDBArgs) {",
      "26:     super(embeddings, args);",
      "27:     this.table = args.table;",
      "29:     this.textKey = args.textKey || \"text\";",
      "",
      "[Added Lines]",
      "24:   private table?: Table;",
      "28:   private uri: string;",
      "30:   private tableName: string;",
      "32:   private mode?: WriteMode;",
      "34:   constructor(embeddings: EmbeddingsInterface, args?: LanceDBArgs) {",
      "35:     super(embeddings, args || {});",
      "36:     this.table = args?.table;",
      "38:     this.textKey = args?.textKey || \"text\";",
      "39:     this.uri = args?.uri || \"~/lancedb\";",
      "40:     this.tableName = args?.tableName || \"langchain\";",
      "41:     this.mode = args?.mode || WriteMode.Overwrite;",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "71:       });",
      "72:       data.push(record);",
      "73:     }",
      "74:     await this.table.add(data);",
      "75:   }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "86:     if (!this.table) {",
      "87:       const db: Connection = await connect(this.uri);",
      "88:       this.table = await db.createTable(this.tableName, data, {",
      "89:         writeMode: this.mode,",
      "90:       });",
      "92:       return;",
      "93:     }",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "85:     query: number[],",
      "86:     k: number",
      "87:   ): Promise<[Document, number][]> {",
      "88:     const results = await this.table.search(query).limit(k).execute();",
      "90:     const docsAndScore: [Document, number][] = [];",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "108:     if (!this.table) {",
      "109:       throw new Error(",
      "110:         \"Table not found. Please add vectors to the table first.\"",
      "111:       );",
      "112:     }",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "119:     texts: string[],",
      "120:     metadatas: object[] | object,",
      "121:     embeddings: EmbeddingsInterface,",
      "123:   ): Promise<LanceDB> {",
      "124:     const docs: Document[] = [];",
      "125:     for (let i = 0; i < texts.length; i += 1) {",
      "",
      "[Removed Lines]",
      "122:     dbConfig: LanceDBArgs",
      "",
      "[Added Lines]",
      "147:     dbConfig?: LanceDBArgs",
      "",
      "---------------",
      "--- Hunk 7 ---",
      "[Context before]",
      "143:   static async fromDocuments(",
      "144:     docs: Document[],",
      "145:     embeddings: EmbeddingsInterface,",
      "147:   ): Promise<LanceDB> {",
      "148:     const instance = new this(embeddings, dbConfig);",
      "149:     await instance.addDocuments(docs);",
      "",
      "[Removed Lines]",
      "146:     dbConfig: LanceDBArgs",
      "",
      "[Added Lines]",
      "171:     dbConfig?: LanceDBArgs",
      "",
      "---------------"
    ],
    "libs/langchain-community/src/vectorstores/tests/lancedb.int.test.ts||libs/langchain-community/src/vectorstores/tests/lancedb.int.test.ts": [
      "File: libs/langchain-community/src/vectorstores/tests/lancedb.int.test.ts -> libs/langchain-community/src/vectorstores/tests/lancedb.int.test.ts",
      "--- Hunk 1 ---",
      "[Context before]",
      "45:     expect(resultsTwo.length).toBe(5);",
      "46:   });",
      "47: });",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "49: describe(\"LanceDB empty schema\", () => {",
      "50:   test(\"Test fromTexts + addDocuments\", async () => {",
      "51:     const embeddings = new OpenAIEmbeddings();",
      "52:     const vectorStore = await LanceDB.fromTexts(",
      "53:       [\"hello bye\", \"hello world\", \"bye bye\"],",
      "54:       [{ id: 1 }, { id: 2 }, { id: 3 }],",
      "55:       embeddings",
      "56:     );",
      "58:     const results = await vectorStore.similaritySearch(\"hello bye\", 10);",
      "59:     expect(results.length).toBe(3);",
      "61:     await vectorStore.addDocuments([",
      "62:       new Document({",
      "63:         pageContent: \"a new world\",",
      "64:         metadata: { id: 4 },",
      "65:       }),",
      "66:     ]);",
      "68:     const resultsTwo = await vectorStore.similaritySearch(\"hello bye\", 10);",
      "69:     expect(resultsTwo.length).toBe(4);",
      "70:   });",
      "71: });",
      "",
      "---------------"
    ],
    "yarn.lock||yarn.lock": [
      "File: yarn.lock -> yarn.lock",
      "--- Hunk 1 ---",
      "[Context before]",
      "251:   languageName: node",
      "252:   linkType: hard",
      "272: \"@apify/consts@npm:^2.13.0, @apify/consts@npm:^2.9.0\":",
      "273:   version: 2.13.0",
      "274:   resolution: \"@apify/consts@npm:2.13.0\"",
      "",
      "[Removed Lines]",
      "254: \"@apache-arrow/ts@npm:^12.0.0\":",
      "255:   version: 12.0.0",
      "256:   resolution: \"@apache-arrow/ts@npm:12.0.0\"",
      "257:   dependencies:",
      "258:     \"@types/command-line-args\": 5.2.0",
      "259:     \"@types/command-line-usage\": 5.0.2",
      "260:     \"@types/node\": 18.14.5",
      "261:     \"@types/pad-left\": 2.1.1",
      "262:     command-line-args: 5.2.1",
      "263:     command-line-usage: 6.1.3",
      "264:     flatbuffers: 23.3.3",
      "265:     json-bignum: ^0.0.3",
      "266:     pad-left: ^2.1.0",
      "267:     tslib: ^2.5.0",
      "268:   checksum: 67b2791e14d5377b1d160a0d8390decc386e013c517713f8b9c100737a0e478a394086d91a8c846848d4e30289070a119d8e65191998f4c2555b18a29564df50",
      "269:   languageName: node",
      "270:   linkType: hard",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "11112:   languageName: node",
      "11113:   linkType: hard",
      "11115: \"@langchain/anthropic@*, @langchain/anthropic@workspace:*, @langchain/anthropic@workspace:libs/langchain-anthropic\":",
      "11116:   version: 0.0.0-use.local",
      "11117:   resolution: \"@langchain/anthropic@workspace:libs/langchain-anthropic\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "11097: \"@lancedb/vectordb-darwin-arm64@npm:0.4.20\":",
      "11098:   version: 0.4.20",
      "11099:   resolution: \"@lancedb/vectordb-darwin-arm64@npm:0.4.20\"",
      "11100:   conditions: os=darwin & cpu=arm64",
      "11101:   languageName: node",
      "11102:   linkType: hard",
      "11104: \"@lancedb/vectordb-darwin-x64@npm:0.4.20\":",
      "11105:   version: 0.4.20",
      "11106:   resolution: \"@lancedb/vectordb-darwin-x64@npm:0.4.20\"",
      "11107:   conditions: os=darwin & cpu=x64",
      "11108:   languageName: node",
      "11109:   linkType: hard",
      "11111: \"@lancedb/vectordb-linux-arm64-gnu@npm:0.4.20\":",
      "11112:   version: 0.4.20",
      "11113:   resolution: \"@lancedb/vectordb-linux-arm64-gnu@npm:0.4.20\"",
      "11114:   conditions: os=linux & cpu=arm64",
      "11115:   languageName: node",
      "11116:   linkType: hard",
      "11118: \"@lancedb/vectordb-linux-x64-gnu@npm:0.4.20\":",
      "11119:   version: 0.4.20",
      "11120:   resolution: \"@lancedb/vectordb-linux-x64-gnu@npm:0.4.20\"",
      "11121:   conditions: os=linux & cpu=x64",
      "11122:   languageName: node",
      "11123:   linkType: hard",
      "11125: \"@lancedb/vectordb-win32-x64-msvc@npm:0.4.20\":",
      "11126:   version: 0.4.20",
      "11127:   resolution: \"@lancedb/vectordb-win32-x64-msvc@npm:0.4.20\"",
      "11128:   conditions: os=win32 & cpu=x64",
      "11129:   languageName: node",
      "11130:   linkType: hard",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "11577:     typesense: ^1.5.3",
      "11578:     usearch: ^1.1.1",
      "11579:     uuid: ^10.0.0",
      "11581:     voy-search: 0.6.2",
      "11582:     weaviate-ts-client: ^1.4.0",
      "11583:     web-auth-library: ^1.0.3",
      "",
      "[Removed Lines]",
      "11580:     vectordb: ^0.1.4",
      "",
      "[Added Lines]",
      "11597:     vectordb: ^0.9.0",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "13039:   languageName: node",
      "13040:   linkType: hard",
      "13042: \"@neondatabase/serverless@npm:0.6.0\":",
      "13043:   version: 0.6.0",
      "13044:   resolution: \"@neondatabase/serverless@npm:0.6.0\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "13059: \"@neon-rs/load@npm:^0.0.74\":",
      "13060:   version: 0.0.74",
      "13061:   resolution: \"@neon-rs/load@npm:0.0.74\"",
      "13062:   checksum: d26ec9b08cdf1a7c5aeefe98f77112d205d11b4005a7934b21fe8fd27528847e08e4749e7e6c3fc05ae9f701175a58c11a095ae6af449634df3991a2c82e1dfa",
      "13063:   languageName: node",
      "13064:   linkType: hard",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "20774:   languageName: node",
      "20775:   linkType: hard",
      "20797: \"apache-arrow@npm:^12.0.1\":",
      "20798:   version: 12.0.1",
      "20799:   resolution: \"apache-arrow@npm:12.0.1\"",
      "",
      "[Removed Lines]",
      "20777: \"apache-arrow@npm:^12.0.0\":",
      "20778:   version: 12.0.0",
      "20779:   resolution: \"apache-arrow@npm:12.0.0\"",
      "20780:   dependencies:",
      "20781:     \"@types/command-line-args\": 5.2.0",
      "20782:     \"@types/command-line-usage\": 5.0.2",
      "20783:     \"@types/node\": 18.14.5",
      "20784:     \"@types/pad-left\": 2.1.1",
      "20785:     command-line-args: 5.2.1",
      "20786:     command-line-usage: 6.1.3",
      "20787:     flatbuffers: 23.3.3",
      "20788:     json-bignum: ^0.0.3",
      "20789:     pad-left: ^2.1.0",
      "20790:     tslib: ^2.5.0",
      "20791:   bin:",
      "20792:     arrow2csv: bin/arrow2csv.js",
      "20793:   checksum: 3285189517c2b298cda42852321ce127754918513116eade6e4914c57983f68b6ba96605cfaa2202796d3d6e14755d3b3758f76c1374492affa3d95714eaca40",
      "20794:   languageName: node",
      "20795:   linkType: hard",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "27133:     typescript: ~5.1.6",
      "27134:     typesense: ^1.5.3",
      "27135:     uuid: ^10.0.0",
      "27137:     voy-search: 0.6.2",
      "27138:     weaviate-ts-client: ^2.0.0",
      "27139:     zod: ^3.22.4",
      "",
      "[Removed Lines]",
      "27136:     vectordb: ^0.1.4",
      "",
      "[Added Lines]",
      "27140:     vectordb: ^0.9.0",
      "",
      "---------------",
      "--- Hunk 7 ---",
      "[Context before]",
      "42444:   languageName: node",
      "42445:   linkType: hard",
      "42454:   languageName: node",
      "42455:   linkType: hard",
      "",
      "[Removed Lines]",
      "42447: \"vectordb@npm:^0.1.4\":",
      "42448:   version: 0.1.4",
      "42449:   resolution: \"vectordb@npm:0.1.4\"",
      "42450:   dependencies:",
      "42451:     \"@apache-arrow/ts\": ^12.0.0",
      "42452:     apache-arrow: ^12.0.0",
      "42453:   checksum: 8a40abf4466479b0b9e61687416b5ab232458401917bf9a1d5f3d8ea8c8320ecc5691174f4d4c0cfef0bb6c16328a9088419fd90ac85fd7267dbccdd1f9e55d7",
      "",
      "[Added Lines]",
      "42451: \"vectordb@npm:^0.9.0\":",
      "42452:   version: 0.9.0",
      "42453:   resolution: \"vectordb@npm:0.9.0\"",
      "42454:   dependencies:",
      "42455:     \"@lancedb/vectordb-darwin-arm64\": 0.4.20",
      "42456:     \"@lancedb/vectordb-darwin-x64\": 0.4.20",
      "42457:     \"@lancedb/vectordb-linux-arm64-gnu\": 0.4.20",
      "42458:     \"@lancedb/vectordb-linux-x64-gnu\": 0.4.20",
      "42459:     \"@lancedb/vectordb-win32-x64-msvc\": 0.4.20",
      "42460:     \"@neon-rs/load\": ^0.0.74",
      "42461:     axios: ^1.4.0",
      "42462:   peerDependencies:",
      "42463:     \"@apache-arrow/ts\": ^14.0.2",
      "42464:     apache-arrow: ^14.0.2",
      "42465:   dependenciesMeta:",
      "42466:     \"@lancedb/vectordb-darwin-arm64\":",
      "42467:       optional: true",
      "42468:     \"@lancedb/vectordb-darwin-x64\":",
      "42469:       optional: true",
      "42470:     \"@lancedb/vectordb-linux-arm64-gnu\":",
      "42471:       optional: true",
      "42472:     \"@lancedb/vectordb-linux-x64-gnu\":",
      "42473:       optional: true",
      "42474:     \"@lancedb/vectordb-win32-x64-msvc\":",
      "42475:       optional: true",
      "42476:   conditions: (os=darwin | os=linux | os=win32) & (cpu=x64 | cpu=arm64)",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "49acaec559a0d1095b55bcf0f354d740ee1d3e8e",
      "candidate_info": {
        "commit_hash": "49acaec559a0d1095b55bcf0f354d740ee1d3e8e",
        "repo": "langchain-ai/langchainjs",
        "commit_url": "https://github.com/langchain-ai/langchainjs/commit/49acaec559a0d1095b55bcf0f354d740ee1d3e8e",
        "files": [
          "yarn.lock"
        ],
        "message": "fix: Commit yarn.lock (#7083)",
        "before_after_code_files": [
          "yarn.lock||yarn.lock"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "yarn.lock||yarn.lock"
          ],
          "candidate": [
            "yarn.lock||yarn.lock"
          ]
        }
      },
      "candidate_diff": {
        "yarn.lock||yarn.lock": [
          "File: yarn.lock -> yarn.lock",
          "--- Hunk 1 ---",
          "[Context before]",
          "11147:   languageName: node",
          "11148:   linkType: hard",
          "11151:   version: 0.0.0-use.local",
          "11152:   resolution: \"@langchain/anthropic@workspace:libs/langchain-anthropic\"",
          "11153:   dependencies:",
          "",
          "[Removed Lines]",
          "11150: \"@langchain/anthropic@*, @langchain/anthropic@workspace:*, @langchain/anthropic@workspace:libs/langchain-anthropic\":",
          "",
          "[Added Lines]",
          "11150: \"@langchain/anthropic@npm:*\":",
          "11151:   version: 0.3.5",
          "11152:   resolution: \"@langchain/anthropic@npm:0.3.5\"",
          "11153:   dependencies:",
          "11154:     \"@anthropic-ai/sdk\": ^0.27.3",
          "11155:     fast-xml-parser: ^4.4.1",
          "11156:     zod: ^3.22.4",
          "11157:     zod-to-json-schema: ^3.22.4",
          "11158:   peerDependencies:",
          "11159:     \"@langchain/core\": \">=0.2.21 <0.4.0\"",
          "11160:   checksum: a241f3f863dbf1c233802553f3b955e4d71c114e5736eb344ba85aaece8d6d3596a0b4bd9ebabaf5bca180f913da242b0f72bebaba8d7600a88f489e44ced9be",
          "11161:   languageName: node",
          "11162:   linkType: hard",
          "11164: \"@langchain/anthropic@workspace:*, @langchain/anthropic@workspace:libs/langchain-anthropic\":",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "7da6e8f30625e51374774ccca0ee7117f019f0a0",
      "candidate_info": {
        "commit_hash": "7da6e8f30625e51374774ccca0ee7117f019f0a0",
        "repo": "langchain-ai/langchainjs",
        "commit_url": "https://github.com/langchain-ai/langchainjs/commit/7da6e8f30625e51374774ccca0ee7117f019f0a0",
        "files": [
          "libs/langchain-google-gauth/package.json",
          "yarn.lock"
        ],
        "message": "release(google-gauth): 0.1.3 (#7271)",
        "before_after_code_files": [
          "yarn.lock||yarn.lock"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "yarn.lock||yarn.lock"
          ],
          "candidate": [
            "yarn.lock||yarn.lock"
          ]
        }
      },
      "candidate_diff": {
        "yarn.lock||yarn.lock": [
          "File: yarn.lock -> yarn.lock",
          "--- Hunk 1 ---",
          "[Context before]",
          "12349:   languageName: unknown",
          "12350:   linkType: soft",
          "12365:   version: 0.0.0-use.local",
          "12366:   resolution: \"@langchain/google-gauth@workspace:libs/langchain-google-gauth\"",
          "12367:   dependencies:",
          "",
          "[Removed Lines]",
          "12352: \"@langchain/google-gauth@npm:~0.1.3\":",
          "12353:   version: 0.1.3",
          "12354:   resolution: \"@langchain/google-gauth@npm:0.1.3\"",
          "12355:   dependencies:",
          "12356:     \"@langchain/google-common\": ~0.1.3",
          "12357:     google-auth-library: ^8.9.0",
          "12358:   peerDependencies:",
          "12359:     \"@langchain/core\": \">=0.2.21 <0.4.0\"",
          "12360:   checksum: ac83e180af492068de82284a396842eb9bb1e5eaa428b5270a192499da737bf192ad48a1c90eeca462e31238e37bd5698c8d071eb1d780a4f4c759270f8ab706",
          "12361:   languageName: node",
          "12362:   linkType: hard",
          "12364: \"@langchain/google-gauth@workspace:libs/langchain-google-gauth\":",
          "",
          "[Added Lines]",
          "12352: \"@langchain/google-gauth@workspace:libs/langchain-google-gauth, @langchain/google-gauth@~0.1.3\":",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "c21474026212c628ce49356701767068ea04b669",
      "candidate_info": {
        "commit_hash": "c21474026212c628ce49356701767068ea04b669",
        "repo": "langchain-ai/langchainjs",
        "commit_url": "https://github.com/langchain-ai/langchainjs/commit/c21474026212c628ce49356701767068ea04b669",
        "files": [
          "libs/langchain-community/package.json",
          "yarn.lock"
        ],
        "message": "chore(community): Bump langchain dep within community (#7071)",
        "before_after_code_files": [
          "yarn.lock||yarn.lock"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "yarn.lock||yarn.lock"
          ],
          "candidate": [
            "yarn.lock||yarn.lock"
          ]
        }
      },
      "candidate_diff": {
        "yarn.lock||yarn.lock": [
          "File: yarn.lock -> yarn.lock",
          "--- Hunk 1 ---",
          "[Context before]",
          "11582:     js-yaml: ^4.1.0",
          "11583:     jsdom: ^22.1.0",
          "11584:     jsonwebtoken: ^9.0.2",
          "11586:     langsmith: ^0.2.0",
          "11587:     llmonitor: ^0.5.9",
          "11588:     lodash: ^4.17.21",
          "",
          "[Removed Lines]",
          "11585:     langchain: \">=0.2.3 <0.4.0\"",
          "",
          "[Added Lines]",
          "11585:     langchain: \">=0.2.3 <0.3.0 || >=0.3.4 <0.4.0\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "32875:   languageName: node",
          "32876:   linkType: hard",
          "32879:   version: 0.0.0-use.local",
          "32880:   resolution: \"langchain@workspace:langchain\"",
          "32881:   dependencies:",
          "",
          "[Removed Lines]",
          "32878: \"langchain@>=0.2.3 <0.4.0, langchain@workspace:*, langchain@workspace:langchain\":",
          "",
          "[Added Lines]",
          "32878: \"langchain@>=0.2.3 <0.3.0 || >=0.3.4 <0.4.0, langchain@workspace:*, langchain@workspace:langchain\":",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "7ccc8d5fe8db9b2d294c8ecafcf3293d03d47630",
      "candidate_info": {
        "commit_hash": "7ccc8d5fe8db9b2d294c8ecafcf3293d03d47630",
        "repo": "langchain-ai/langchainjs",
        "commit_url": "https://github.com/langchain-ai/langchainjs/commit/7ccc8d5fe8db9b2d294c8ecafcf3293d03d47630",
        "files": [
          "docs/core_docs/docs/integrations/chat/index.mdx",
          "docs/core_docs/docs/integrations/chat/xai.ipynb",
          "examples/package.json",
          "libs/langchain-xai/.eslintrc.cjs",
          "libs/langchain-xai/.gitignore",
          "libs/langchain-xai/.prettierrc",
          "libs/langchain-xai/.release-it.json",
          "libs/langchain-xai/LICENSE",
          "libs/langchain-xai/README.md",
          "libs/langchain-xai/jest.config.cjs",
          "libs/langchain-xai/jest.env.cjs",
          "libs/langchain-xai/langchain.config.js",
          "libs/langchain-xai/package.json",
          "libs/langchain-xai/scripts/jest-setup-after-env.js",
          "libs/langchain-xai/src/chat_models.ts",
          "libs/langchain-xai/src/index.ts",
          "libs/langchain-xai/src/tests/chat_models.int.test.ts",
          "libs/langchain-xai/src/tests/chat_models.standard.int.test.ts",
          "libs/langchain-xai/src/tests/chat_models.standard.test.ts",
          "libs/langchain-xai/src/tests/chat_models.test.ts",
          "libs/langchain-xai/src/tests/chat_models_structured_output.int.test.ts",
          "libs/langchain-xai/tsconfig.cjs.json",
          "libs/langchain-xai/tsconfig.json",
          "libs/langchain-xai/turbo.json",
          "yarn.lock"
        ],
        "message": "feat(xai): Add xAI integration package (#7156)",
        "before_after_code_files": [
          "libs/langchain-xai/.eslintrc.cjs||libs/langchain-xai/.eslintrc.cjs",
          "libs/langchain-xai/jest.config.cjs||libs/langchain-xai/jest.config.cjs",
          "libs/langchain-xai/jest.env.cjs||libs/langchain-xai/jest.env.cjs",
          "libs/langchain-xai/langchain.config.js||libs/langchain-xai/langchain.config.js",
          "libs/langchain-xai/scripts/jest-setup-after-env.js||libs/langchain-xai/scripts/jest-setup-after-env.js",
          "libs/langchain-xai/src/chat_models.ts||libs/langchain-xai/src/chat_models.ts",
          "libs/langchain-xai/src/index.ts||libs/langchain-xai/src/index.ts",
          "libs/langchain-xai/src/tests/chat_models.int.test.ts||libs/langchain-xai/src/tests/chat_models.int.test.ts",
          "libs/langchain-xai/src/tests/chat_models.standard.int.test.ts||libs/langchain-xai/src/tests/chat_models.standard.int.test.ts",
          "libs/langchain-xai/src/tests/chat_models.standard.test.ts||libs/langchain-xai/src/tests/chat_models.standard.test.ts",
          "libs/langchain-xai/src/tests/chat_models.test.ts||libs/langchain-xai/src/tests/chat_models.test.ts",
          "libs/langchain-xai/src/tests/chat_models_structured_output.int.test.ts||libs/langchain-xai/src/tests/chat_models_structured_output.int.test.ts",
          "yarn.lock||yarn.lock"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "yarn.lock||yarn.lock"
          ],
          "candidate": [
            "yarn.lock||yarn.lock"
          ]
        }
      },
      "candidate_diff": {
        "libs/langchain-xai/.eslintrc.cjs||libs/langchain-xai/.eslintrc.cjs": [
          "File: libs/langchain-xai/.eslintrc.cjs -> libs/langchain-xai/.eslintrc.cjs",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: module.exports = {",
          "2:   extends: [",
          "3:     \"airbnb-base\",",
          "4:     \"eslint:recommended\",",
          "5:     \"prettier\",",
          "6:     \"plugin:@typescript-eslint/recommended\",",
          "7:   ],",
          "8:   parserOptions: {",
          "9:     ecmaVersion: 12,",
          "10:     parser: \"@typescript-eslint/parser\",",
          "11:     project: \"./tsconfig.json\",",
          "12:     sourceType: \"module\",",
          "13:   },",
          "14:   plugins: [\"@typescript-eslint\", \"no-instanceof\"],",
          "15:   ignorePatterns: [",
          "16:     \".eslintrc.cjs\",",
          "17:     \"scripts\",",
          "18:     \"node_modules\",",
          "19:     \"dist\",",
          "20:     \"dist-cjs\",",
          "21:     \"*.js\",",
          "22:     \"*.cjs\",",
          "23:     \"*.d.ts\",",
          "24:   ],",
          "25:   rules: {",
          "26:     \"no-process-env\": 2,",
          "27:     \"no-instanceof/no-instanceof\": 2,",
          "28:     \"@typescript-eslint/explicit-module-boundary-types\": 0,",
          "29:     \"@typescript-eslint/no-empty-function\": 0,",
          "30:     \"@typescript-eslint/no-shadow\": 0,",
          "31:     \"@typescript-eslint/no-empty-interface\": 0,",
          "32:     \"@typescript-eslint/no-use-before-define\": [\"error\", \"nofunc\"],",
          "33:     \"@typescript-eslint/no-unused-vars\": [\"warn\", { args: \"none\" }],",
          "34:     \"@typescript-eslint/no-floating-promises\": \"error\",",
          "35:     \"@typescript-eslint/no-misused-promises\": \"error\",",
          "36:     camelcase: 0,",
          "37:     \"class-methods-use-this\": 0,",
          "38:     \"import/extensions\": [2, \"ignorePackages\"],",
          "39:     \"import/no-extraneous-dependencies\": [",
          "40:       \"error\",",
          "41:       { devDependencies: [\"**/*.test.ts\"] },",
          "42:     ],",
          "43:     \"import/no-unresolved\": 0,",
          "44:     \"import/prefer-default-export\": 0,",
          "45:     \"keyword-spacing\": \"error\",",
          "46:     \"max-classes-per-file\": 0,",
          "47:     \"max-len\": 0,",
          "48:     \"no-await-in-loop\": 0,",
          "49:     \"no-bitwise\": 0,",
          "50:     \"no-console\": 0,",
          "51:     \"no-restricted-syntax\": 0,",
          "52:     \"no-shadow\": 0,",
          "53:     \"no-continue\": 0,",
          "54:     \"no-void\": 0,",
          "55:     \"no-underscore-dangle\": 0,",
          "56:     \"no-use-before-define\": 0,",
          "57:     \"no-useless-constructor\": 0,",
          "58:     \"no-return-await\": 0,",
          "59:     \"consistent-return\": 0,",
          "60:     \"no-else-return\": 0,",
          "61:     \"func-names\": 0,",
          "62:     \"no-lonely-if\": 0,",
          "63:     \"prefer-rest-params\": 0,",
          "64:     \"new-cap\": [\"error\", { properties: false, capIsNew: false }],",
          "65:   },",
          "66:   overrides: [",
          "67:     {",
          "68:       files: ['**/*.test.ts'],",
          "69:       rules: {",
          "70:         '@typescript-eslint/no-unused-vars': 'off'",
          "71:       }",
          "72:     }",
          "73:   ]",
          "74: };",
          "",
          "---------------"
        ],
        "libs/langchain-xai/jest.config.cjs||libs/langchain-xai/jest.config.cjs": [
          "File: libs/langchain-xai/jest.config.cjs -> libs/langchain-xai/jest.config.cjs",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "2: module.exports = {",
          "3:   preset: \"ts-jest/presets/default-esm\",",
          "4:   testEnvironment: \"./jest.env.cjs\",",
          "5:   modulePathIgnorePatterns: [\"dist/\", \"docs/\"],",
          "6:   moduleNameMapper: {",
          "7:     \"^(\\\\.{1,2}/.*)\\\\.js$\": \"$1\",",
          "8:   },",
          "9:   transform: {",
          "10:     \"^.+\\\\.tsx?$\": [\"@swc/jest\"],",
          "11:   },",
          "12:   transformIgnorePatterns: [",
          "13:     \"/node_modules/\",",
          "14:     \"\\\\.pnp\\\\.[^\\\\/]+$\",",
          "15:     \"./scripts/jest-setup-after-env.js\",",
          "16:   ],",
          "17:   setupFiles: [\"dotenv/config\"],",
          "18:   testTimeout: 20_000,",
          "19:   passWithNoTests: true,",
          "20: };",
          "",
          "---------------"
        ],
        "libs/langchain-xai/jest.env.cjs||libs/langchain-xai/jest.env.cjs": [
          "File: libs/langchain-xai/jest.env.cjs -> libs/langchain-xai/jest.env.cjs",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: const { TestEnvironment } = require(\"jest-environment-node\");",
          "3: class AdjustedTestEnvironmentToSupportFloat32Array extends TestEnvironment {",
          "4:   constructor(config, context) {",
          "7:     super(config, context);",
          "8:     this.global.Float32Array = Float32Array;",
          "9:   }",
          "10: }",
          "12: module.exports = AdjustedTestEnvironmentToSupportFloat32Array;",
          "",
          "---------------"
        ],
        "libs/langchain-xai/langchain.config.js||libs/langchain-xai/langchain.config.js": [
          "File: libs/langchain-xai/langchain.config.js -> libs/langchain-xai/langchain.config.js",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: import { resolve, dirname } from \"node:path\";",
          "2: import { fileURLToPath } from \"node:url\";",
          "8: function abs(relativePath) {",
          "9:   return resolve(dirname(fileURLToPath(import.meta.url)), relativePath);",
          "10: }",
          "12: export const config = {",
          "13:   internals: [/node\\:/, /@langchain\\/core\\//],",
          "14:   entrypoints: {",
          "15:     index: \"index\",",
          "16:   },",
          "17:   tsConfigPath: resolve(\"./tsconfig.json\"),",
          "18:   cjsSource: \"./dist-cjs\",",
          "19:   cjsDestination: \"./dist\",",
          "20:   abs,",
          "21: }",
          "",
          "---------------"
        ],
        "libs/langchain-xai/scripts/jest-setup-after-env.js||libs/langchain-xai/scripts/jest-setup-after-env.js": [
          "File: libs/langchain-xai/scripts/jest-setup-after-env.js -> libs/langchain-xai/scripts/jest-setup-after-env.js",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: import { awaitAllCallbacks } from \"@langchain/core/callbacks/promises\";",
          "2: import { afterAll, jest } from \"@jest/globals\";",
          "4: afterAll(awaitAllCallbacks);",
          "7: if (process.env.DISABLE_CONSOLE_LOGS === \"true\") {",
          "8:   console.log = jest.fn();",
          "9: }",
          "",
          "---------------"
        ],
        "libs/langchain-xai/src/chat_models.ts||libs/langchain-xai/src/chat_models.ts": [
          "File: libs/langchain-xai/src/chat_models.ts -> libs/langchain-xai/src/chat_models.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: import {",
          "2:   BaseChatModelCallOptions,",
          "3:   BindToolsInput,",
          "4:   LangSmithParams,",
          "5:   type BaseChatModelParams,",
          "6: } from \"@langchain/core/language_models/chat_models\";",
          "7: import { Serialized } from \"@langchain/core/load/serializable\";",
          "8: import { getEnvironmentVariable } from \"@langchain/core/utils/env\";",
          "9: import {",
          "10:   type OpenAICoreRequestOptions,",
          "11:   type OpenAIClient,",
          "12:   ChatOpenAI,",
          "13:   OpenAIToolChoice,",
          "14: } from \"@langchain/openai\";",
          "16: type ChatXAIToolType = BindToolsInput | OpenAIClient.ChatCompletionTool;",
          "18: export interface ChatXAICallOptions extends BaseChatModelCallOptions {",
          "19:   headers?: Record<string, string>;",
          "20:   tools?: ChatXAIToolType[];",
          "21:   tool_choice?: OpenAIToolChoice | string | \"auto\" | \"any\";",
          "22: }",
          "24: export interface ChatXAIInput extends BaseChatModelParams {",
          "29:   apiKey?: string;",
          "34:   model?: string;",
          "40:   stop?: Array<string>;",
          "45:   stopSequences?: Array<string>;",
          "49:   streaming?: boolean;",
          "54:   temperature?: number;",
          "59:   maxTokens?: number;",
          "60: }",
          "388: export class ChatXAI extends ChatOpenAI<ChatXAICallOptions> {",
          "389:   static lc_name() {",
          "390:     return \"ChatXAI\";",
          "391:   }",
          "393:   _llmType() {",
          "394:     return \"xAI\";",
          "395:   }",
          "397:   get lc_secrets(): { [key: string]: string } | undefined {",
          "398:     return {",
          "399:       apiKey: \"XAI_API_KEY\",",
          "400:     };",
          "401:   }",
          "403:   lc_serializable = true;",
          "405:   lc_namespace = [\"langchain\", \"chat_models\", \"xai\"];",
          "407:   constructor(fields?: Partial<ChatXAIInput>) {",
          "408:     const apiKey = fields?.apiKey || getEnvironmentVariable(\"XAI_API_KEY\");",
          "409:     if (!apiKey) {",
          "410:       throw new Error(",
          "411:         `xAI API key not found. Please set the XAI_API_KEY environment variable or provide the key into \"apiKey\" field.`",
          "412:       );",
          "413:     }",
          "415:     super({",
          "416:       ...fields,",
          "417:       model: fields?.model || \"grok-beta\",",
          "418:       apiKey,",
          "419:       configuration: {",
          "420:         baseURL: \"https://api.x.ai/v1\",",
          "421:       },",
          "422:     });",
          "423:   }",
          "425:   toJSON(): Serialized {",
          "426:     const result = super.toJSON();",
          "428:     if (",
          "429:       \"kwargs\" in result &&",
          "430:       typeof result.kwargs === \"object\" &&",
          "431:       result.kwargs != null",
          "432:     ) {",
          "433:       delete result.kwargs.openai_api_key;",
          "434:       delete result.kwargs.configuration;",
          "435:     }",
          "437:     return result;",
          "438:   }",
          "440:   getLsParams(options: this[\"ParsedCallOptions\"]): LangSmithParams {",
          "441:     const params = super.getLsParams(options);",
          "442:     params.ls_provider = \"xai\";",
          "443:     return params;",
          "444:   }",
          "446:   async completionWithRetry(",
          "447:     request: OpenAIClient.Chat.ChatCompletionCreateParamsStreaming,",
          "448:     options?: OpenAICoreRequestOptions",
          "449:   ): Promise<AsyncIterable<OpenAIClient.Chat.Completions.ChatCompletionChunk>>;",
          "451:   async completionWithRetry(",
          "452:     request: OpenAIClient.Chat.ChatCompletionCreateParamsNonStreaming,",
          "453:     options?: OpenAICoreRequestOptions",
          "454:   ): Promise<OpenAIClient.Chat.Completions.ChatCompletion>;",
          "462:   async completionWithRetry(",
          "463:     request:",
          "464:       | OpenAIClient.Chat.ChatCompletionCreateParamsStreaming",
          "465:       | OpenAIClient.Chat.ChatCompletionCreateParamsNonStreaming,",
          "466:     options?: OpenAICoreRequestOptions",
          "467:   ): Promise<",
          "468:     | AsyncIterable<OpenAIClient.Chat.Completions.ChatCompletionChunk>",
          "469:     | OpenAIClient.Chat.Completions.ChatCompletion",
          "470:   > {",
          "471:     delete request.frequency_penalty;",
          "472:     delete request.presence_penalty;",
          "473:     delete request.logit_bias;",
          "474:     delete request.functions;",
          "476:     const newRequestMessages = request.messages.map((msg) => {",
          "477:       if (!msg.content) {",
          "478:         return {",
          "479:           ...msg,",
          "480:           content: \"\",",
          "481:         };",
          "482:       }",
          "483:       return msg;",
          "484:     });",
          "486:     const newRequest = {",
          "487:       ...request,",
          "488:       messages: newRequestMessages,",
          "489:     };",
          "491:     if (newRequest.stream === true) {",
          "492:       return super.completionWithRetry(newRequest, options);",
          "493:     }",
          "495:     return super.completionWithRetry(newRequest, options);",
          "496:   }",
          "497: }",
          "",
          "---------------"
        ],
        "libs/langchain-xai/src/index.ts||libs/langchain-xai/src/index.ts": [
          "File: libs/langchain-xai/src/index.ts -> libs/langchain-xai/src/index.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: export * from \"./chat_models.js\";",
          "",
          "---------------"
        ],
        "libs/langchain-xai/src/tests/chat_models.int.test.ts||libs/langchain-xai/src/tests/chat_models.int.test.ts": [
          "File: libs/langchain-xai/src/tests/chat_models.int.test.ts -> libs/langchain-xai/src/tests/chat_models.int.test.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: import { test } from \"@jest/globals\";",
          "2: import {",
          "3:   AIMessage,",
          "4:   AIMessageChunk,",
          "5:   HumanMessage,",
          "6:   ToolMessage,",
          "7: } from \"@langchain/core/messages\";",
          "8: import { tool } from \"@langchain/core/tools\";",
          "9: import { z } from \"zod\";",
          "10: import { concat } from \"@langchain/core/utils/stream\";",
          "11: import { ChatXAI } from \"../chat_models.js\";",
          "13: test(\"invoke\", async () => {",
          "14:   const chat = new ChatXAI({",
          "15:     maxRetries: 0,",
          "16:   });",
          "17:   const message = new HumanMessage(\"What color is the sky?\");",
          "18:   const res = await chat.invoke([message]);",
          "20:   expect(res.content.length).toBeGreaterThan(10);",
          "21: });",
          "23: test(\"invoke with stop sequence\", async () => {",
          "24:   const chat = new ChatXAI({",
          "25:     maxRetries: 0,",
          "26:   });",
          "27:   const message = new HumanMessage(\"Count to ten.\");",
          "28:   const res = await chat.bind({ stop: [\"5\", \"five\"] }).invoke([message]);",
          "30:   expect((res.content as string).toLowerCase()).not.toContain(\"6\");",
          "31:   expect((res.content as string).toLowerCase()).not.toContain(\"six\");",
          "32: });",
          "34: test(\"stream should respect passed headers\", async () => {",
          "35:   const chat = new ChatXAI({",
          "36:     maxRetries: 0,",
          "37:   });",
          "38:   const message = new HumanMessage(\"Count to ten.\");",
          "39:   await expect(async () => {",
          "40:     await chat.stream([message], {",
          "41:       headers: { Authorization: \"badbadbad\" },",
          "42:     });",
          "43:   }).rejects.toThrowError();",
          "44: });",
          "46: test(\"generate\", async () => {",
          "47:   const chat = new ChatXAI();",
          "48:   const message = new HumanMessage(\"Hello!\");",
          "49:   const res = await chat.generate([[message]]);",
          "51:   expect(res.generations[0][0].text.length).toBeGreaterThan(10);",
          "52: });",
          "54: test(\"streaming\", async () => {",
          "55:   const chat = new ChatXAI();",
          "56:   const message = new HumanMessage(\"What color is the sky?\");",
          "57:   const stream = await chat.stream([message]);",
          "58:   let iters = 0;",
          "59:   let finalRes = \"\";",
          "60:   for await (const chunk of stream) {",
          "61:     iters += 1;",
          "62:     finalRes += chunk.content;",
          "63:   }",
          "65:   expect(iters).toBeGreaterThan(1);",
          "66: });",
          "68: test(\"invoke with bound tools\", async () => {",
          "69:   const chat = new ChatXAI({",
          "70:     maxRetries: 0,",
          "71:     model: \"grok-beta\",",
          "72:   });",
          "73:   const message = new HumanMessage(\"What is the current weather in Hawaii?\");",
          "74:   const res = await chat",
          "75:     .bind({",
          "76:       tools: [",
          "77:         {",
          "78:           type: \"function\",",
          "79:           function: {",
          "80:             name: \"get_current_weather\",",
          "81:             description: \"Get the current weather in a given location\",",
          "82:             parameters: {",
          "83:               type: \"object\",",
          "84:               properties: {",
          "85:                 location: {",
          "86:                   type: \"string\",",
          "87:                   description: \"The city and state, e.g. San Francisco, CA\",",
          "88:                 },",
          "89:                 unit: { type: \"string\", enum: [\"celsius\", \"fahrenheit\"] },",
          "90:               },",
          "91:               required: [\"location\"],",
          "92:             },",
          "93:           },",
          "94:         },",
          "95:       ],",
          "96:       tool_choice: \"auto\",",
          "97:     })",
          "98:     .invoke([message]);",
          "100:   expect(res.additional_kwargs.tool_calls?.length).toEqual(1);",
          "101:   expect(",
          "102:     JSON.parse(",
          "103:       res.additional_kwargs?.tool_calls?.[0].function.arguments ?? \"{}\"",
          "104:     )",
          "105:   ).toEqual(res.tool_calls?.[0].args);",
          "106: });",
          "108: test(\"stream with bound tools, yielding a single chunk\", async () => {",
          "109:   const chat = new ChatXAI({",
          "110:     maxRetries: 0,",
          "111:   });",
          "112:   const message = new HumanMessage(\"What is the current weather in Hawaii?\");",
          "113:   const stream = await chat",
          "114:     .bind({",
          "115:       tools: [",
          "116:         {",
          "117:           type: \"function\",",
          "118:           function: {",
          "119:             name: \"get_current_weather\",",
          "120:             description: \"Get the current weather in a given location\",",
          "121:             parameters: {",
          "122:               type: \"object\",",
          "123:               properties: {",
          "124:                 location: {",
          "125:                   type: \"string\",",
          "126:                   description: \"The city and state, e.g. San Francisco, CA\",",
          "127:                 },",
          "128:                 unit: { type: \"string\", enum: [\"celsius\", \"fahrenheit\"] },",
          "129:               },",
          "130:               required: [\"location\"],",
          "131:             },",
          "132:           },",
          "133:         },",
          "134:       ],",
          "135:       tool_choice: \"auto\",",
          "136:     })",
          "137:     .stream([message]);",
          "140:   for await (const chunk of stream) {",
          "142:   }",
          "143: });",
          "145: test(\"Few shotting with tool calls\", async () => {",
          "146:   const chat = new ChatXAI({",
          "147:     model: \"grok-beta\",",
          "148:     temperature: 0,",
          "149:   }).bind({",
          "150:     tools: [",
          "151:       {",
          "152:         type: \"function\",",
          "153:         function: {",
          "154:           name: \"get_current_weather\",",
          "155:           description: \"Get the current weather in a given location\",",
          "156:           parameters: {",
          "157:             type: \"object\",",
          "158:             properties: {",
          "159:               location: {",
          "160:                 type: \"string\",",
          "161:                 description: \"The city and state, e.g. San Francisco, CA\",",
          "162:               },",
          "163:               unit: { type: \"string\", enum: [\"celsius\", \"fahrenheit\"] },",
          "164:             },",
          "165:             required: [\"location\"],",
          "166:           },",
          "167:         },",
          "168:       },",
          "169:     ],",
          "170:     tool_choice: \"auto\",",
          "171:   });",
          "172:   const res = await chat.invoke([",
          "173:     new HumanMessage(\"What is the weather in SF?\"),",
          "174:     new AIMessage({",
          "175:       content: \"\",",
          "176:       tool_calls: [",
          "177:         {",
          "178:           id: \"12345\",",
          "179:           name: \"get_current_weather\",",
          "180:           args: {",
          "181:             location: \"SF\",",
          "182:           },",
          "183:         },",
          "184:       ],",
          "185:     }),",
          "186:     new ToolMessage({",
          "187:       tool_call_id: \"12345\",",
          "188:       content: \"It is currently 24 degrees with hail in SF.\",",
          "189:     }),",
          "190:     new AIMessage(\"It is currently 24 degrees in SF with hail in SF.\"),",
          "191:     new HumanMessage(\"What did you say the weather was?\"),",
          "192:   ]);",
          "194:   expect(res.content).toContain(\"24\");",
          "195: });",
          "197: test(\"Groq can stream tool calls\", async () => {",
          "198:   const model = new ChatXAI({",
          "199:     model: \"grok-beta\",",
          "200:     temperature: 0,",
          "201:   });",
          "203:   const weatherTool = tool((_) => \"The temperature is 24 degrees with hail.\", {",
          "204:     name: \"get_current_weather\",",
          "205:     schema: z.object({",
          "206:       location: z",
          "207:         .string()",
          "208:         .describe(\"The location to get the current weather for.\"),",
          "209:     }),",
          "210:     description: \"Get the current weather in a given location.\",",
          "211:   });",
          "213:   const modelWithTools = model.bindTools([weatherTool]);",
          "215:   const stream = await modelWithTools.stream(",
          "216:     \"What is the weather in San Francisco?\"",
          "217:   );",
          "219:   let finalMessage: AIMessageChunk | undefined;",
          "220:   for await (const chunk of stream) {",
          "221:     finalMessage = !finalMessage ? chunk : concat(finalMessage, chunk);",
          "222:   }",
          "224:   expect(finalMessage).toBeDefined();",
          "225:   if (!finalMessage) return;",
          "227:   expect(finalMessage.tool_calls?.[0]).toBeDefined();",
          "228:   if (!finalMessage.tool_calls?.[0]) return;",
          "230:   expect(finalMessage.tool_calls?.[0].name).toBe(\"get_current_weather\");",
          "231:   expect(finalMessage.tool_calls?.[0].args).toHaveProperty(\"location\");",
          "232:   expect(finalMessage.tool_calls?.[0].id).toBeDefined();",
          "233: });",
          "",
          "---------------"
        ],
        "libs/langchain-xai/src/tests/chat_models.standard.int.test.ts||libs/langchain-xai/src/tests/chat_models.standard.int.test.ts": [
          "File: libs/langchain-xai/src/tests/chat_models.standard.int.test.ts -> libs/langchain-xai/src/tests/chat_models.standard.int.test.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "2: import { test, expect } from \"@jest/globals\";",
          "3: import { ChatModelIntegrationTests } from \"@langchain/standard-tests\";",
          "4: import { AIMessageChunk } from \"@langchain/core/messages\";",
          "5: import { ChatXAI, ChatXAICallOptions } from \"../chat_models.js\";",
          "7: class ChatXAIStandardIntegrationTests extends ChatModelIntegrationTests<",
          "8:   ChatXAICallOptions,",
          "9:   AIMessageChunk",
          "10: > {",
          "11:   constructor() {",
          "12:     if (!process.env.XAI_API_KEY) {",
          "13:       throw new Error(",
          "14:         \"Can not run xAI integration tests because XAI_API_KEY is not set\"",
          "15:       );",
          "16:     }",
          "17:     super({",
          "18:       Cls: ChatXAI,",
          "19:       chatModelHasToolCalling: true,",
          "20:       chatModelHasStructuredOutput: true,",
          "21:       constructorArgs: {",
          "22:         maxRetries: 1,",
          "23:         temperature: 0,",
          "24:       },",
          "25:     });",
          "26:   }",
          "27: }",
          "29: const testClass = new ChatXAIStandardIntegrationTests();",
          "31: test(\"ChatXAIStandardIntegrationTests\", async () => {",
          "32:   console.warn = (..._args: unknown[]) => {",
          "34:   };",
          "35:   const testResults = await testClass.runTests();",
          "36:   expect(testResults).toBe(true);",
          "37: });",
          "",
          "---------------"
        ],
        "libs/langchain-xai/src/tests/chat_models.standard.test.ts||libs/langchain-xai/src/tests/chat_models.standard.test.ts": [
          "File: libs/langchain-xai/src/tests/chat_models.standard.test.ts -> libs/langchain-xai/src/tests/chat_models.standard.test.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "2: import { test, expect } from \"@jest/globals\";",
          "3: import { ChatModelUnitTests } from \"@langchain/standard-tests\";",
          "4: import { AIMessageChunk } from \"@langchain/core/messages\";",
          "5: import { ChatXAI, ChatXAICallOptions } from \"../chat_models.js\";",
          "7: class ChatXAIStandardUnitTests extends ChatModelUnitTests<",
          "8:   ChatXAICallOptions,",
          "9:   AIMessageChunk",
          "10: > {",
          "11:   constructor() {",
          "12:     super({",
          "13:       Cls: ChatXAI,",
          "14:       chatModelHasToolCalling: true,",
          "15:       chatModelHasStructuredOutput: true,",
          "16:       constructorArgs: {},",
          "17:     });",
          "21:     process.env.XAI_API_KEY = \"test\";",
          "22:   }",
          "24:   testChatModelInitApiKey() {",
          "27:     process.env.XAI_API_KEY = \"\";",
          "28:     super.testChatModelInitApiKey();",
          "30:     process.env.XAI_API_KEY = \"test\";",
          "31:   }",
          "32: }",
          "34: const testClass = new ChatXAIStandardUnitTests();",
          "36: test(\"ChatXAIStandardUnitTests\", () => {",
          "37:   const testResults = testClass.runTests();",
          "38:   expect(testResults).toBe(true);",
          "39: });",
          "",
          "---------------"
        ],
        "libs/langchain-xai/src/tests/chat_models.test.ts||libs/langchain-xai/src/tests/chat_models.test.ts": [
          "File: libs/langchain-xai/src/tests/chat_models.test.ts -> libs/langchain-xai/src/tests/chat_models.test.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "2: import { test, expect } from \"@jest/globals\";",
          "3: import { ChatXAI } from \"../chat_models.js\";",
          "5: test(\"Serialization\", () => {",
          "6:   const model = new ChatXAI({",
          "7:     apiKey: \"foo\",",
          "8:   });",
          "9:   expect(JSON.stringify(model)).toEqual(",
          "10:     `{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"chat_models\",\"xai\",\"ChatXAI\"],\"kwargs\":{\"api_key\":{\"lc\":1,\"type\":\"secret\",\"id\":[\"XAI_API_KEY\"]}}}`",
          "11:   );",
          "12: });",
          "14: test(\"Serialization with no params\", () => {",
          "15:   process.env.GROQ_API_KEY = \"foo\";",
          "16:   const model = new ChatXAI();",
          "17:   expect(JSON.stringify(model)).toEqual(",
          "18:     `{\"lc\":1,\"type\":\"constructor\",\"id\":[\"langchain\",\"chat_models\",\"xai\",\"ChatXAI\"],\"kwargs\":{\"api_key\":{\"lc\":1,\"type\":\"secret\",\"id\":[\"XAI_API_KEY\"]}}}`",
          "19:   );",
          "20: });",
          "",
          "---------------"
        ],
        "libs/langchain-xai/src/tests/chat_models_structured_output.int.test.ts||libs/langchain-xai/src/tests/chat_models_structured_output.int.test.ts": [
          "File: libs/langchain-xai/src/tests/chat_models_structured_output.int.test.ts -> libs/langchain-xai/src/tests/chat_models_structured_output.int.test.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: import { z } from \"zod\";",
          "2: import { zodToJsonSchema } from \"zod-to-json-schema\";",
          "3: import { ChatPromptTemplate } from \"@langchain/core/prompts\";",
          "4: import { AIMessage } from \"@langchain/core/messages\";",
          "5: import { ChatXAI } from \"../chat_models.js\";",
          "7: test(\"withStructuredOutput zod schema function calling\", async () => {",
          "8:   const model = new ChatXAI({",
          "9:     temperature: 0,",
          "10:     model: \"grok-beta\",",
          "11:   });",
          "13:   const calculatorSchema = z.object({",
          "14:     operation: z.enum([\"add\", \"subtract\", \"multiply\", \"divide\"]),",
          "15:     number1: z.number(),",
          "16:     number2: z.number(),",
          "17:   });",
          "18:   const modelWithStructuredOutput = model.withStructuredOutput(",
          "19:     calculatorSchema,",
          "20:     {",
          "21:       name: \"calculator\",",
          "22:     }",
          "23:   );",
          "25:   const prompt = ChatPromptTemplate.fromMessages([",
          "26:     [\"system\", \"You are VERY bad at math and must always use a calculator.\"],",
          "27:     [\"human\", \"Please help me!! What is 2 + 2?\"],",
          "28:   ]);",
          "29:   const chain = prompt.pipe(modelWithStructuredOutput);",
          "30:   const result = await chain.invoke({});",
          "32:   expect(\"operation\" in result).toBe(true);",
          "33:   expect(\"number1\" in result).toBe(true);",
          "34:   expect(\"number2\" in result).toBe(true);",
          "35: });",
          "37: test(\"withStructuredOutput zod schema JSON mode\", async () => {",
          "38:   const model = new ChatXAI({",
          "39:     temperature: 0,",
          "40:     model: \"grok-beta\",",
          "41:   });",
          "43:   const calculatorSchema = z.object({",
          "44:     operation: z.enum([\"add\", \"subtract\", \"multiply\", \"divide\"]),",
          "45:     number1: z.number(),",
          "46:     number2: z.number(),",
          "47:   });",
          "48:   const modelWithStructuredOutput = model.withStructuredOutput(",
          "49:     calculatorSchema,",
          "50:     {",
          "51:       name: \"calculator\",",
          "52:       method: \"jsonMode\",",
          "53:     }",
          "54:   );",
          "56:   const prompt = ChatPromptTemplate.fromMessages([",
          "57:     [",
          "58:       \"system\",",
          "59:       `You are VERY bad at math and must always use a calculator.",
          "60: Respond with a JSON object containing three keys:",
          "61: 'operation': the type of operation to execute, either 'add', 'subtract', 'multiply' or 'divide',",
          "62: 'number1': the first number to operate on,",
          "63: 'number2': the second number to operate on.",
          "64: `,",
          "65:     ],",
          "66:     [\"human\", \"Please help me!! What is 2 + 2?\"],",
          "67:   ]);",
          "68:   const chain = prompt.pipe(modelWithStructuredOutput);",
          "69:   const result = await chain.invoke({});",
          "71:   expect(\"operation\" in result).toBe(true);",
          "72:   expect(\"number1\" in result).toBe(true);",
          "73:   expect(\"number2\" in result).toBe(true);",
          "74: });",
          "76: test(\"withStructuredOutput JSON schema function calling\", async () => {",
          "77:   const model = new ChatXAI({",
          "78:     temperature: 0,",
          "79:     model: \"grok-beta\",",
          "80:   });",
          "82:   const calculatorSchema = z.object({",
          "83:     operation: z.enum([\"add\", \"subtract\", \"multiply\", \"divide\"]),",
          "84:     number1: z.number(),",
          "85:     number2: z.number(),",
          "86:   });",
          "87:   const modelWithStructuredOutput = model.withStructuredOutput(",
          "88:     zodToJsonSchema(calculatorSchema),",
          "89:     {",
          "90:       name: \"calculator\",",
          "91:     }",
          "92:   );",
          "94:   const prompt = ChatPromptTemplate.fromMessages([",
          "95:     [\"system\", `You are VERY bad at math and must always use a calculator.`],",
          "96:     [\"human\", \"Please help me!! What is 2 + 2?\"],",
          "97:   ]);",
          "98:   const chain = prompt.pipe(modelWithStructuredOutput);",
          "99:   const result = await chain.invoke({});",
          "101:   expect(\"operation\" in result).toBe(true);",
          "102:   expect(\"number1\" in result).toBe(true);",
          "103:   expect(\"number2\" in result).toBe(true);",
          "104: });",
          "106: test(\"withStructuredOutput OpenAI function definition function calling\", async () => {",
          "107:   const model = new ChatXAI({",
          "108:     temperature: 0,",
          "109:     model: \"grok-beta\",",
          "110:   });",
          "112:   const calculatorSchema = z.object({",
          "113:     operation: z.enum([\"add\", \"subtract\", \"multiply\", \"divide\"]),",
          "114:     number1: z.number(),",
          "115:     number2: z.number(),",
          "116:   });",
          "117:   const modelWithStructuredOutput = model.withStructuredOutput({",
          "118:     name: \"calculator\",",
          "119:     parameters: zodToJsonSchema(calculatorSchema),",
          "120:   });",
          "122:   const prompt = ChatPromptTemplate.fromMessages([",
          "123:     \"system\",",
          "124:     `You are VERY bad at math and must always use a calculator.`,",
          "125:     \"human\",",
          "126:     \"Please help me!! What is 2 + 2?\",",
          "127:   ]);",
          "128:   const chain = prompt.pipe(modelWithStructuredOutput);",
          "129:   const result = await chain.invoke({});",
          "131:   expect(\"operation\" in result).toBe(true);",
          "132:   expect(\"number1\" in result).toBe(true);",
          "133:   expect(\"number2\" in result).toBe(true);",
          "134: });",
          "136: test(\"withStructuredOutput JSON schema JSON mode\", async () => {",
          "137:   const model = new ChatXAI({",
          "138:     temperature: 0,",
          "139:     model: \"grok-beta\",",
          "140:   });",
          "142:   const calculatorSchema = z.object({",
          "143:     operation: z.enum([\"add\", \"subtract\", \"multiply\", \"divide\"]),",
          "144:     number1: z.number(),",
          "145:     number2: z.number(),",
          "146:   });",
          "147:   const modelWithStructuredOutput = model.withStructuredOutput(",
          "148:     zodToJsonSchema(calculatorSchema),",
          "149:     {",
          "150:       name: \"calculator\",",
          "151:       method: \"jsonMode\",",
          "152:     }",
          "153:   );",
          "155:   const prompt = ChatPromptTemplate.fromMessages([",
          "156:     [",
          "157:       \"system\",",
          "158:       `You are VERY bad at math and must always use a calculator.",
          "159: Respond with a JSON object containing three keys:",
          "160: 'operation': the type of operation to execute, either 'add', 'subtract', 'multiply' or 'divide',",
          "161: 'number1': the first number to operate on,",
          "162: 'number2': the second number to operate on.",
          "163: `,",
          "164:     ],",
          "165:     [\"human\", \"Please help me!! What is 2 + 2?\"],",
          "166:   ]);",
          "167:   const chain = prompt.pipe(modelWithStructuredOutput);",
          "168:   const result = await chain.invoke({});",
          "170:   expect(\"operation\" in result).toBe(true);",
          "171:   expect(\"number1\" in result).toBe(true);",
          "172:   expect(\"number2\" in result).toBe(true);",
          "173: });",
          "175: test(\"withStructuredOutput JSON schema\", async () => {",
          "176:   const model = new ChatXAI({",
          "177:     temperature: 0,",
          "178:     model: \"grok-beta\",",
          "179:   });",
          "181:   const jsonSchema = {",
          "182:     title: \"calculator\",",
          "183:     description: \"A simple calculator\",",
          "184:     type: \"object\",",
          "185:     properties: {",
          "186:       operation: {",
          "187:         type: \"string\",",
          "188:         enum: [\"add\", \"subtract\", \"multiply\", \"divide\"],",
          "189:       },",
          "190:       number1: { type: \"number\" },",
          "191:       number2: { type: \"number\" },",
          "192:     },",
          "193:   };",
          "194:   const modelWithStructuredOutput = model.withStructuredOutput(jsonSchema);",
          "196:   const prompt = ChatPromptTemplate.fromMessages([",
          "197:     [",
          "198:       \"system\",",
          "199:       `You are VERY bad at math and must always use a calculator.",
          "200: Respond with a JSON object containing three keys:",
          "201: 'operation': the type of operation to execute, either 'add', 'subtract', 'multiply' or 'divide',",
          "202: 'number1': the first number to operate on,",
          "203: 'number2': the second number to operate on.",
          "204: `,",
          "205:     ],",
          "206:     [\"human\", \"Please help me!! What is 2 + 2?\"],",
          "207:   ]);",
          "208:   const chain = prompt.pipe(modelWithStructuredOutput);",
          "209:   const result = await chain.invoke({});",
          "211:   expect(\"operation\" in result).toBe(true);",
          "212:   expect(\"number1\" in result).toBe(true);",
          "213:   expect(\"number2\" in result).toBe(true);",
          "214: });",
          "216: test(\"withStructuredOutput includeRaw true\", async () => {",
          "217:   const model = new ChatXAI({",
          "218:     temperature: 0,",
          "219:     model: \"grok-beta\",",
          "220:   });",
          "222:   const calculatorSchema = z.object({",
          "223:     operation: z.enum([\"add\", \"subtract\", \"multiply\", \"divide\"]),",
          "224:     number1: z.number(),",
          "225:     number2: z.number(),",
          "226:   });",
          "227:   const modelWithStructuredOutput = model.withStructuredOutput(",
          "228:     calculatorSchema,",
          "229:     {",
          "230:       name: \"calculator\",",
          "231:       includeRaw: true,",
          "232:     }",
          "233:   );",
          "235:   const prompt = ChatPromptTemplate.fromMessages([",
          "236:     [\"system\", \"You are VERY bad at math and must always use a calculator.\"],",
          "237:     [\"human\", \"Please help me!! What is 2 + 2?\"],",
          "238:   ]);",
          "239:   const chain = prompt.pipe(modelWithStructuredOutput);",
          "240:   const result = await chain.invoke({});",
          "243:   expect(\"parsed\" in result).toBe(true);",
          "245:   if (!(\"parsed\" in result)) {",
          "246:     throw new Error(\"parsed not in result\");",
          "247:   }",
          "248:   const { parsed } = result;",
          "249:   expect(\"operation\" in parsed).toBe(true);",
          "250:   expect(\"number1\" in parsed).toBe(true);",
          "251:   expect(\"number2\" in parsed).toBe(true);",
          "253:   expect(\"raw\" in result).toBe(true);",
          "255:   if (!(\"raw\" in result)) {",
          "256:     throw new Error(\"raw not in result\");",
          "257:   }",
          "258:   const { raw } = result as { raw: AIMessage };",
          "260:   expect(raw.tool_calls?.[0].args).toBeDefined();",
          "261:   if (!raw.tool_calls?.[0].args) {",
          "262:     throw new Error(\"args not in tool call\");",
          "263:   }",
          "264:   expect(raw.tool_calls?.length).toBeGreaterThan(0);",
          "265:   expect(raw.tool_calls?.[0].name).toBe(\"calculator\");",
          "266:   expect(\"operation\" in raw.tool_calls[0].args).toBe(true);",
          "267:   expect(\"number1\" in raw.tool_calls[0].args).toBe(true);",
          "268:   expect(\"number2\" in raw.tool_calls[0].args).toBe(true);",
          "269: });",
          "",
          "---------------"
        ],
        "yarn.lock||yarn.lock": [
          "File: yarn.lock -> yarn.lock",
          "--- Hunk 1 ---",
          "[Context before]",
          "12820:   languageName: unknown",
          "12821:   linkType: soft",
          "12823: \"@langchain/yandex@workspace:*, @langchain/yandex@workspace:libs/langchain-yandex\":",
          "12824:   version: 0.0.0-use.local",
          "12825:   resolution: \"@langchain/yandex@workspace:libs/langchain-yandex\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "12823: \"@langchain/xai@workspace:*, @langchain/xai@workspace:libs/langchain-xai\":",
          "12824:   version: 0.0.0-use.local",
          "12825:   resolution: \"@langchain/xai@workspace:libs/langchain-xai\"",
          "12826:   dependencies:",
          "12827:     \"@jest/globals\": ^29.5.0",
          "12828:     \"@langchain/core\": \"workspace:*\"",
          "12829:     \"@langchain/openai\": \"workspace:^\"",
          "12830:     \"@langchain/scripts\": \">=0.1.0 <0.2.0\"",
          "12831:     \"@langchain/standard-tests\": 0.0.0",
          "12832:     \"@swc/core\": ^1.3.90",
          "12833:     \"@swc/jest\": ^0.2.29",
          "12834:     \"@tsconfig/recommended\": ^1.0.3",
          "12835:     \"@types/uuid\": ^9",
          "12836:     \"@typescript-eslint/eslint-plugin\": ^6.12.0",
          "12837:     \"@typescript-eslint/parser\": ^6.12.0",
          "12838:     dotenv: ^16.3.1",
          "12839:     dpdm: ^3.12.0",
          "12840:     eslint: ^8.33.0",
          "12841:     eslint-config-airbnb-base: ^15.0.0",
          "12842:     eslint-config-prettier: ^8.6.0",
          "12843:     eslint-plugin-import: ^2.27.5",
          "12844:     eslint-plugin-no-instanceof: ^1.0.1",
          "12845:     eslint-plugin-prettier: ^4.2.1",
          "12846:     jest: ^29.5.0",
          "12847:     jest-environment-node: ^29.6.4",
          "12848:     prettier: ^2.8.3",
          "12849:     release-it: ^17.6.0",
          "12850:     rollup: ^4.5.2",
          "12851:     ts-jest: ^29.1.0",
          "12852:     typescript: <5.2.0",
          "12853:     zod: ^3.22.4",
          "12854:   peerDependencies:",
          "12855:     \"@langchain/core\": \">=0.2.21 <0.4.0\"",
          "12856:   languageName: unknown",
          "12857:   linkType: soft",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "27304:     \"@langchain/scripts\": \">=0.1.0 <0.2.0\"",
          "27305:     \"@langchain/textsplitters\": \"workspace:*\"",
          "27306:     \"@langchain/weaviate\": \"workspace:*\"",
          "27307:     \"@langchain/yandex\": \"workspace:*\"",
          "27308:     \"@layerup/layerup-security\": ^1.5.12",
          "27309:     \"@opensearch-project/opensearch\": ^2.2.0",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "27343:     \"@langchain/xai\": \"workspace:*\"",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "ac05b302246c554acb1bd1afea26ab6ff9b09d63",
      "candidate_info": {
        "commit_hash": "ac05b302246c554acb1bd1afea26ab6ff9b09d63",
        "repo": "langchain-ai/langchainjs",
        "commit_url": "https://github.com/langchain-ai/langchainjs/commit/ac05b302246c554acb1bd1afea26ab6ff9b09d63",
        "files": [
          "docs/core_docs/docs/integrations/chat/openai.ipynb",
          "libs/langchain-openai/package.json",
          "libs/langchain-openai/src/chat_models.ts",
          "libs/langchain-openai/src/tests/chat_models.int.test.ts",
          "libs/langchain-openai/src/types.ts",
          "yarn.lock"
        ],
        "message": "Revert \"feat(openai): Support audio output\" (#7016)",
        "before_after_code_files": [
          "libs/langchain-openai/src/chat_models.ts||libs/langchain-openai/src/chat_models.ts",
          "libs/langchain-openai/src/tests/chat_models.int.test.ts||libs/langchain-openai/src/tests/chat_models.int.test.ts",
          "libs/langchain-openai/src/types.ts||libs/langchain-openai/src/types.ts",
          "yarn.lock||yarn.lock"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "yarn.lock||yarn.lock"
          ],
          "candidate": [
            "yarn.lock||yarn.lock"
          ]
        }
      },
      "candidate_diff": {
        "libs/langchain-openai/src/chat_models.ts||libs/langchain-openai/src/chat_models.ts": [
          "File: libs/langchain-openai/src/chat_models.ts -> libs/langchain-openai/src/chat_models.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "16:   isAIMessage,",
          "17:   convertToChunk,",
          "18:   UsageMetadata,",
          "20: } from \"@langchain/core/messages\";",
          "21: import {",
          "22:   type ChatGeneration,",
          "",
          "[Removed Lines]",
          "19:   MessageContent,",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "175:           system_fingerprint: rawResponse.system_fingerprint,",
          "176:         };",
          "177:       }",
          "180:       return new AIMessage({",
          "182:         tool_calls: toolCalls,",
          "183:         invalid_tool_calls: invalidToolCalls,",
          "184:         additional_kwargs,",
          "",
          "[Removed Lines]",
          "178:       const content = message.audio ? [message.audio] : message.content;",
          "181:         content: content || \"\",",
          "",
          "[Added Lines]",
          "178:         content: message.content || \"\",",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "199:   includeRawResponse?: boolean",
          "200: ) {",
          "201:   const role = delta.role ?? defaultRole;",
          "213:   let additional_kwargs: Record<string, unknown>;",
          "214:   if (delta.function_call) {",
          "215:     additional_kwargs = {",
          "",
          "[Removed Lines]",
          "202:   let content: MessageContent;",
          "203:   if (delta.audio) {",
          "204:     content = [",
          "205:       {",
          "206:         ...delta.audio,",
          "207:         index: rawResponse.choices[0].index,",
          "208:       },",
          "209:     ];",
          "210:   } else {",
          "211:     content = delta.content ?? \"\";",
          "212:   }",
          "",
          "[Added Lines]",
          "199:   const content = delta.content ?? \"\";",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "387:   strict?: boolean;",
          "408: }",
          "410: export interface ChatOpenAIFields",
          "",
          "[Removed Lines]",
          "400:   modalities?: Array<OpenAIClient.Chat.ChatCompletionModality>;",
          "407:   audio?: OpenAIClient.Chat.ChatCompletionAudioParam;",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "1029:   supportsStrictToolCalling?: boolean;",
          "1035:   constructor(",
          "1036:     fields?: ChatOpenAIFields,",
          "",
          "[Removed Lines]",
          "1031:   audio?: OpenAIClient.Chat.ChatCompletionAudioParam;",
          "1033:   modalities?: Array<OpenAIClient.Chat.ChatCompletionModality>;",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "1100:     this.stopSequences = this?.stop;",
          "1101:     this.user = fields?.user;",
          "1102:     this.__includeRawResponse = fields?.__includeRawResponse;",
          "1106:     if (this.azureOpenAIApiKey || this.azureADTokenProvider) {",
          "1107:       if (",
          "",
          "[Removed Lines]",
          "1103:     this.audio = fields?.audio;",
          "1104:     this.modalities = fields?.modalities;",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "1266:       seed: options?.seed,",
          "1267:       ...streamOptionsConfig,",
          "1268:       parallel_tool_calls: options?.parallel_tool_calls,",
          "1275:       ...this.modelKwargs,",
          "1276:     };",
          "1277:     return params;",
          "",
          "[Removed Lines]",
          "1269:       ...(this.audio || options?.audio",
          "1270:         ? { audio: this.audio || options?.audio }",
          "1271:         : {}),",
          "1272:       ...(this.modalities || options?.modalities",
          "1273:         ? { modalities: this.modalities || options?.modalities }",
          "1274:         : {}),",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "1323:     const streamIterable = await this.completionWithRetry(params, options);",
          "1324:     let usage: OpenAIClient.Completions.CompletionUsage | undefined;",
          "1325:     for await (const data of streamIterable) {",
          "1327:       if (data.usage) {",
          "1328:         usage = data.usage;",
          "1329:       }",
          "",
          "[Removed Lines]",
          "1326:       const choice = data?.choices?.[0];",
          "",
          "[Added Lines]",
          "1244:       const choice = data?.choices[0];",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "1346:         prompt: options.promptIndex ?? 0,",
          "1347:         completion: choice.index ?? 0,",
          "1348:       };",
          "1350:       const generationInfo: Record<string, any> = { ...newTokenIndices };",
          "1351:       if (choice.finish_reason != null) {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1267:       if (typeof chunk.content !== \"string\") {",
          "1268:         console.log(",
          "1269:           \"[WARNING]: Received non-string content from OpenAI. This is currently not supported.\"",
          "1270:         );",
          "1271:         continue;",
          "1272:       }",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "1359:       }",
          "1360:       const generationChunk = new ChatGenerationChunk({",
          "1361:         message: chunk,",
          "1363:         generationInfo,",
          "1364:       });",
          "1365:       yield generationChunk;",
          "",
          "[Removed Lines]",
          "1362:         text: typeof chunk.content === \"string\" ? chunk.content : \"\",",
          "",
          "[Added Lines]",
          "1286:         text: chunk.content,",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "1567:       const generations: ChatGeneration[] = [];",
          "1568:       for (const part of data?.choices ?? []) {",
          "1569:         const generation: ChatGeneration = {",
          "1571:           message: openAIResponseToChatMessage(",
          "1572:             part.message ?? { role: \"assistant\" },",
          "1573:             data,",
          "",
          "[Removed Lines]",
          "1570:           text: part.message?.content ?? \"\",",
          "",
          "[Added Lines]",
          "1493:         const text = part.message?.content ?? \"\";",
          "1495:           text,",
          "",
          "---------------"
        ],
        "libs/langchain-openai/src/tests/chat_models.int.test.ts||libs/langchain-openai/src/tests/chat_models.int.test.ts": [
          "File: libs/langchain-openai/src/tests/chat_models.int.test.ts -> libs/langchain-openai/src/tests/chat_models.int.test.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: import { CallbackManager } from \"@langchain/core/callbacks/manager\";",
          "20: import { NewTokenIndices } from \"@langchain/core/callbacks/base\";",
          "21: import { InMemoryCache } from \"@langchain/core/caches\";",
          "23: import { ChatOpenAI } from \"../chat_models.js\";",
          "",
          "[Removed Lines]",
          "22: import { concat } from \"@langchain/core/utils/stream\";",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "987:   }",
          "988:   expect(chunks.length).toEqual(1);",
          "989: });",
          "",
          "[Removed Lines]",
          "991: describe(\"Audio output\", () => {",
          "992:   test(\"Audio output\", async () => {",
          "993:     const model = new ChatOpenAI({",
          "994:       model: \"gpt-4o-audio-preview\",",
          "995:       temperature: 0,",
          "996:       modalities: [\"text\", \"audio\"],",
          "997:       audio: {",
          "998:         voice: \"alloy\",",
          "999:         format: \"wav\",",
          "1000:       },",
          "1001:     });",
          "1003:     const response = await model.invoke(\"Make me an audio clip of you yelling\");",
          "1004:     expect(Array.isArray(response.content)).toBeTruthy();",
          "1005:     expect(Object.keys(response.content[0]).sort()).toEqual([",
          "1006:       \"data\",",
          "1007:       \"expires_at\",",
          "1008:       \"id\",",
          "1009:       \"transcript\",",
          "1010:     ]);",
          "1011:   });",
          "1013:   test(\"Audio output can stream\", async () => {",
          "1014:     const model = new ChatOpenAI({",
          "1015:       model: \"gpt-4o-audio-preview\",",
          "1016:       temperature: 0,",
          "1017:       modalities: [\"text\", \"audio\"],",
          "1018:       audio: {",
          "1019:         voice: \"alloy\",",
          "1020:         format: \"pcm16\",",
          "1021:       },",
          "1022:     });",
          "1024:     const stream = await model.stream(\"Make me an audio clip of you yelling\");",
          "1025:     let finalMsg: AIMessageChunk | undefined;",
          "1026:     for await (const chunk of stream) {",
          "1027:       finalMsg = finalMsg ? concat(finalMsg, chunk) : chunk;",
          "1028:     }",
          "1029:     if (!finalMsg) {",
          "1030:       throw new Error(\"No final message found\");",
          "1031:     }",
          "1032:     console.dir(finalMsg, { depth: null });",
          "1033:     expect(Array.isArray(finalMsg.content)).toBeTruthy();",
          "1034:     expect(Object.keys(finalMsg.content[1]).sort()).toEqual([",
          "1035:       \"data\",",
          "1036:       \"expires_at\",",
          "1037:       \"id\",",
          "1038:       \"index\",",
          "1039:       \"transcript\",",
          "1040:     ]);",
          "1041:   });",
          "1043:   test(\"Can bind audio output args\", async () => {",
          "1044:     const model = new ChatOpenAI({",
          "1045:       model: \"gpt-4o-audio-preview\",",
          "1046:       temperature: 0,",
          "1047:     }).bind({",
          "1048:       modalities: [\"text\", \"audio\"],",
          "1049:       audio: {",
          "1050:         voice: \"alloy\",",
          "1051:         format: \"wav\",",
          "1052:       },",
          "1053:     });",
          "1055:     const response = await model.invoke(\"Make me an audio clip of you yelling\");",
          "1056:     expect(Array.isArray(response.content)).toBeTruthy();",
          "1057:     expect(Object.keys(response.content[0]).sort()).toEqual([",
          "1058:       \"data\",",
          "1059:       \"expires_at\",",
          "1060:       \"id\",",
          "1061:       \"transcript\",",
          "1062:     ]);",
          "1063:   });",
          "1064: });",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "libs/langchain-openai/src/types.ts||libs/langchain-openai/src/types.ts": [
          "File: libs/langchain-openai/src/types.ts -> libs/langchain-openai/src/types.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "169:   supportsStrictToolCalling?: boolean;",
          "191: }",
          "193: export declare interface AzureOpenAIInput {",
          "",
          "[Removed Lines]",
          "183:   modalities?: Array<OpenAIClient.Chat.ChatCompletionModality>;",
          "190:   audio?: OpenAIClient.Chat.ChatCompletionAudioParam;",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "yarn.lock||yarn.lock": [
          "File: yarn.lock -> yarn.lock",
          "--- Hunk 1 ---",
          "[Context before]",
          "12530:     jest: ^29.5.0",
          "12531:     jest-environment-node: ^29.6.4",
          "12532:     js-tiktoken: ^1.0.12",
          "12534:     prettier: ^2.8.3",
          "12535:     release-it: ^17.6.0",
          "12536:     rimraf: ^5.0.1",
          "",
          "[Removed Lines]",
          "12533:     openai: ^4.68.0",
          "",
          "[Added Lines]",
          "12533:     openai: ^4.67.2",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "35510:   languageName: node",
          "35511:   linkType: hard",
          "35516:   dependencies:",
          "35517:     \"@types/node\": ^18.11.18",
          "35518:     \"@types/node-fetch\": ^2.6.4",
          "",
          "[Removed Lines]",
          "35513: \"openai@npm:^4.68.0\":",
          "35514:   version: 4.68.0",
          "35515:   resolution: \"openai@npm:4.68.0\"",
          "",
          "[Added Lines]",
          "35513: \"openai@npm:^4.67.2\":",
          "35514:   version: 4.67.2",
          "35515:   resolution: \"openai@npm:4.67.2\"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "35528:       optional: true",
          "35529:   bin:",
          "35530:     openai: bin/cli",
          "35532:   languageName: node",
          "35533:   linkType: hard",
          "",
          "[Removed Lines]",
          "35531:   checksum: 2866e54ac1b34e074055dde7cc809bcc33d1172f0ab289dacd54ced04a62ab3c2b9f584fdb84ece981edc5c30939497af4e91fe33646f71d5c6ced5d7106a797",
          "",
          "[Added Lines]",
          "35531:   checksum: 8c83e2632f2c51fea0f9b059026239a46ad171feaedd1456019481136defd468e828b0b091c53da3ebb65da37c4bb76455142c64ea9bc664124c1a341f7f2b78",
          "",
          "---------------"
        ]
      }
    }
  ]
}