{
  "cve_id": "CVE-2021-45229",
  "cve_desc": "It was discovered that the \"Trigger DAG with config\" screen was susceptible to XSS attacks via the `origin` query argument. This issue affects Apache Airflow versions 2.2.3 and below.",
  "repo": "apache/airflow",
  "patch_hash": "628aa1f99c865d97d0b1c7c76e630e43a7b8d319",
  "patch_info": {
    "commit_hash": "628aa1f99c865d97d0b1c7c76e630e43a7b8d319",
    "repo": "apache/airflow",
    "commit_url": "https://github.com/apache/airflow/commit/628aa1f99c865d97d0b1c7c76e630e43a7b8d319",
    "files": [
      "airflow/www/templates/airflow/trigger.html",
      "tests/www/views/test_views_trigger_dag.py"
    ],
    "message": "Simplify trigger cancel button (#21591)\n\nCo-authored-by: Jed Cunningham <jedcunningham@apache.org>\n(cherry picked from commit 65297673a318660fba76797e50d0c06804dfcafc)",
    "before_after_code_files": [
      "airflow/www/templates/airflow/trigger.html||airflow/www/templates/airflow/trigger.html",
      "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py"
    ]
  },
  "patch_diff": {
    "airflow/www/templates/airflow/trigger.html||airflow/www/templates/airflow/trigger.html": [
      "File: airflow/www/templates/airflow/trigger.html -> airflow/www/templates/airflow/trigger.html",
      "--- Hunk 1 ---",
      "[Context before]",
      "63:       </label>",
      "64:     </div>",
      "65:     <button type=\"submit\" class=\"btn btn-primary\">Trigger</button>",
      "67:   </form>",
      "68: {% endblock %}",
      "",
      "[Removed Lines]",
      "66:     <button type=\"button\" class=\"btn\" onclick=\"location.href = '{{ origin }}'; return false\">Cancel</button>",
      "",
      "[Added Lines]",
      "66:     <a class=\"btn\" href=\"{{ origin }}\">Cancel</a>",
      "",
      "---------------"
    ],
    "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py": [
      "File: tests/www/views/test_views_trigger_dag.py -> tests/www/views/test_views_trigger_dag.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "133:         (\"javascript:alert(1)\", \"/home\"),",
      "134:         (\"http://google.com\", \"/home\"),",
      "135:         (\"36539'%3balert(1)%2f%2f166\", \"/home\"),",
      "136:         (",
      "137:             \"%2Ftree%3Fdag_id%3Dexample_bash_operator';alert(33)//\",",
      "138:             \"/home\",",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "136:         (",
      "137:             '\"><script>alert(99)</script><a href=\"',",
      "138:             \"&#34;&gt;&lt;script&gt;alert(99)&lt;/script&gt;&lt;a href=&#34;\",",
      "139:         ),",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "145:     test_dag_id = \"example_bash_operator\"",
      "147:     resp = admin_client.get(f'trigger?dag_id={test_dag_id}&origin={test_origin}')",
      "156: @pytest.mark.parametrize(",
      "",
      "[Removed Lines]",
      "148:     check_content_in_response(",
      "149:         '<button type=\"button\" class=\"btn\" onclick=\"location.href = \\'{}\\'; return false\">'.format(",
      "150:             expected_origin",
      "151:         ),",
      "152:         resp,",
      "153:     )",
      "",
      "[Added Lines]",
      "152:     check_content_in_response(f'<a class=\"btn\" href=\"{expected_origin}\">Cancel</a>', resp)",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "4b09facbf9186ca6b60abf58b57e95468c7c6de9",
      "candidate_info": {
        "commit_hash": "4b09facbf9186ca6b60abf58b57e95468c7c6de9",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/4b09facbf9186ca6b60abf58b57e95468c7c6de9",
        "files": [
          "scripts/ci/docker-compose/integration-pinot.yml",
          "scripts/ci/docker-compose/integration-statsd.yml",
          "scripts/ci/testing/ci_run_single_airflow_test_in_docker.sh"
        ],
        "message": "Fix failing CI phase with unhealthy container issue (#19633)\n\nFix failing CI phase with unhealthy container issue\n\n* Add post cleanup\n* Pin pinot to stable version\n* Pin grafana to stable version\n\nCo-authored-by: Jarek Potiuk <jarek@potiuk.com>\n(cherry picked from commit fcf90c5970aaf7043b1a57d58296d7fd80d6ebf9)",
        "before_after_code_files": [
          "scripts/ci/testing/ci_run_single_airflow_test_in_docker.sh||scripts/ci/testing/ci_run_single_airflow_test_in_docker.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "scripts/ci/testing/ci_run_single_airflow_test_in_docker.sh||scripts/ci/testing/ci_run_single_airflow_test_in_docker.sh": [
          "File: scripts/ci/testing/ci_run_single_airflow_test_in_docker.sh -> scripts/ci/testing/ci_run_single_airflow_test_in_docker.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "113:     echo \"Making sure docker-compose is down and remnants removed\"",
          "114:     echo",
          "115:     docker-compose -f \"${SCRIPTS_CI_DIR}/docker-compose/base.yml\" \\",
          "116:         --project-name \"airflow-${TEST_TYPE}-${BACKEND}\" \\",
          "117:         down --remove-orphans \\",
          "118:         --volumes --timeout 10",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "116:         \"${INTEGRATIONS[@]}\" \\",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "123:       \"${DOCKER_COMPOSE_LOCAL[@]}\" \\",
          "124:       --project-name \"airflow-${TEST_TYPE}-${BACKEND}\" \\",
          "125:          run airflow \"${@}\"",
          "126:     exit_code=$?",
          "127:     docker-compose --log-level INFO -f \"${SCRIPTS_CI_DIR}/docker-compose/base.yml\" \\",
          "128:         --project-name \"airflow-${TEST_TYPE}-${BACKEND}\" \\",
          "129:         down --remove-orphans \\",
          "130:         --volumes --timeout 10",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "127:     docker ps",
          "130:         \"${INTEGRATIONS[@]}\" \\",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "b43882ca1a8f26a582f13a5e4443e9d95c8842f5",
      "candidate_info": {
        "commit_hash": "b43882ca1a8f26a582f13a5e4443e9d95c8842f5",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/b43882ca1a8f26a582f13a5e4443e9d95c8842f5",
        "files": [
          "airflow/models/taskinstance.py",
          "tests/conftest.py",
          "tests/models/test_taskinstance.py"
        ],
        "message": "Avoid calling DAG.following_schedule() for TaskInstance.get_template_context() (#20486)\n\nThis can use a more modern mechanism since get_template_context() has\nenough context (namely, the current data interval).\n\n(cherry picked from commit 9e315ff7caec7fd3d4c0dfe8b89ee2a1c7b5fe3a)",
        "before_after_code_files": [
          "airflow/models/taskinstance.py||airflow/models/taskinstance.py",
          "tests/conftest.py||tests/conftest.py",
          "tests/models/test_taskinstance.py||tests/models/test_taskinstance.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/models/taskinstance.py||airflow/models/taskinstance.py": [
          "File: airflow/models/taskinstance.py -> airflow/models/taskinstance.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1840:         @cache",
          "1841:         def get_yesterday_ds() -> str:",
          "1844:         def get_yesterday_ds_nodash() -> str:",
          "1845:             return get_yesterday_ds().replace('-', '')",
          "1847:         @cache",
          "1848:         def get_tomorrow_ds() -> str:",
          "1851:         def get_tomorrow_ds_nodash() -> str:",
          "1852:             return get_tomorrow_ds().replace('-', '')",
          "",
          "[Removed Lines]",
          "1842:             return (self.execution_date - timedelta(1)).strftime('%Y-%m-%d')",
          "1849:             return (self.execution_date + timedelta(1)).strftime('%Y-%m-%d')",
          "",
          "[Added Lines]",
          "1842:             return (logical_date - timedelta(1)).strftime('%Y-%m-%d')",
          "1849:             return (logical_date + timedelta(1)).strftime('%Y-%m-%d')",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1854:         @cache",
          "1855:         def get_next_execution_date() -> Optional[pendulum.DateTime]:",
          "1856:             # For manually triggered dagruns that aren't run on a schedule,",
          "1858:             # to execution date for consistency with how execution_date is set",
          "1859:             # for manually triggered tasks, i.e. triggered_date == execution_date.",
          "1860:             if dag_run.external_trigger:",
          "1867:                 return None",
          "1870:         def get_next_ds() -> Optional[str]:",
          "1871:             execution_date = get_next_execution_date()",
          "",
          "[Removed Lines]",
          "1857:             # next/previous execution dates don't make sense, and should be set",
          "1861:                 next_execution_date = dag_run.execution_date",
          "1862:             else:",
          "1863:                 with warnings.catch_warnings():",
          "1864:                     warnings.simplefilter(\"ignore\", DeprecationWarning)",
          "1865:                     next_execution_date = dag.following_schedule(self.execution_date)",
          "1866:             if next_execution_date is None:",
          "1868:             return timezone.coerce_datetime(next_execution_date)",
          "",
          "[Added Lines]",
          "1857:             # the \"next\" execution date doesn't make sense, and should be set",
          "1861:                 return logical_date",
          "1862:             next_info = dag.next_dagrun_info(data_interval, restricted=False)",
          "1863:             if next_info is None:",
          "1865:             return timezone.coerce_datetime(next_info.logical_date)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "1882:         @cache",
          "1883:         def get_prev_execution_date():",
          "1884:             if dag_run.external_trigger:",
          "1886:             with warnings.catch_warnings():",
          "1887:                 warnings.simplefilter(\"ignore\", DeprecationWarning)",
          "1890:         @cache",
          "1891:         def get_prev_ds() -> Optional[str]:",
          "",
          "[Removed Lines]",
          "1885:                 return timezone.coerce_datetime(self.execution_date)",
          "1888:                 return dag.previous_schedule(self.execution_date)",
          "",
          "[Added Lines]",
          "1881:             # For manually triggered dagruns that aren't run on a schedule,",
          "1882:             # the \"previous\" execution date doesn't make sense, and should be set",
          "1883:             # to execution date for consistency with how execution_date is set",
          "1884:             # for manually triggered tasks, i.e. triggered_date == execution_date.",
          "1886:                 return logical_date",
          "1889:                 return dag.previous_schedule(logical_date)",
          "",
          "---------------"
        ],
        "tests/conftest.py||tests/conftest.py": [
          "File: tests/conftest.py -> tests/conftest.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "709:     Uses ``create_dummy_dag`` to create the dag structure.",
          "710:     \"\"\"",
          "713:         if execution_date is None:",
          "714:             from airflow.utils import timezone",
          "",
          "[Removed Lines]",
          "712:     def maker(execution_date=None, dagrun_state=None, state=None, run_id=None, run_type=None, **kwargs):",
          "",
          "[Added Lines]",
          "712:     def maker(",
          "713:         execution_date=None,",
          "714:         dagrun_state=None,",
          "715:         state=None,",
          "716:         run_id=None,",
          "717:         run_type=None,",
          "718:         data_interval=None,",
          "720:     ):",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "721:             dagrun_kwargs[\"run_id\"] = run_id",
          "722:         if run_type is not None:",
          "723:             dagrun_kwargs[\"run_type\"] = run_type",
          "724:         dagrun = dag_maker.create_dagrun(**dagrun_kwargs)",
          "725:         (ti,) = dagrun.task_instances",
          "726:         ti.state = state",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "732:         if data_interval is not None:",
          "733:             dagrun_kwargs[\"data_interval\"] = data_interval",
          "",
          "---------------"
        ],
        "tests/models/test_taskinstance.py||tests/models/test_taskinstance.py": [
          "File: tests/models/test_taskinstance.py -> tests/models/test_taskinstance.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "30: from freezegun import freeze_time",
          "32: from airflow import models, settings",
          "33: from airflow.exceptions import (",
          "34:     AirflowException,",
          "35:     AirflowFailException,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "33: from airflow.example_dags.plugins.workday import AfterWorkdayTimetable",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1630:         with pytest.raises(KeyError):",
          "1631:             ti.task.render_template('{{ var.json.get(\"missing_variable\") }}', context)",
          "1633:     def test_execute_callback(self, create_task_instance):",
          "1634:         called = False",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1634:     def test_tempalte_with_custom_timetable_deprecated_context(self, create_task_instance):",
          "1635:         ti = create_task_instance(",
          "1636:             start_date=DEFAULT_DATE,",
          "1637:             timetable=AfterWorkdayTimetable(),",
          "1638:             run_type=DagRunType.SCHEDULED,",
          "1639:             execution_date=timezone.datetime(2021, 9, 6),",
          "1640:             data_interval=(timezone.datetime(2021, 9, 6), timezone.datetime(2021, 9, 7)),",
          "1641:         )",
          "1642:         context = ti.get_template_context()",
          "1643:         with pytest.deprecated_call():",
          "1644:             assert context[\"execution_date\"] == pendulum.DateTime(2021, 9, 6, tzinfo=timezone.TIMEZONE)",
          "1645:         with pytest.deprecated_call():",
          "1646:             assert context[\"next_ds\"] == \"2021-09-07\"",
          "1647:         with pytest.deprecated_call():",
          "1648:             assert context[\"next_ds_nodash\"] == \"20210907\"",
          "1649:         with pytest.deprecated_call():",
          "1650:             assert context[\"next_execution_date\"] == pendulum.DateTime(2021, 9, 7, tzinfo=timezone.TIMEZONE)",
          "1651:         with pytest.deprecated_call():",
          "1652:             assert context[\"prev_ds\"] is None, \"Does not make sense for custom timetable\"",
          "1653:         with pytest.deprecated_call():",
          "1654:             assert context[\"prev_ds_nodash\"] is None, \"Does not make sense for custom timetable\"",
          "1655:         with pytest.deprecated_call():",
          "1656:             assert context[\"prev_execution_date\"] is None, \"Does not make sense for custom timetable\"",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "f19a89ce204bd96dd9576f8f499162b9a90f9e16",
      "candidate_info": {
        "commit_hash": "f19a89ce204bd96dd9576f8f499162b9a90f9e16",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/f19a89ce204bd96dd9576f8f499162b9a90f9e16",
        "files": [
          "scripts/ci/constraints/ci_branch_constraints.sh"
        ],
        "message": "Fix Constraints failure in PRs (#20631)\n\nThe #20624 broke PRs that are changing setup.py.\n\nThis PR fixes it.\n\n(cherry picked from commit fd2d7d3fd817c9405feb4ff8cf696ef510b56f43)",
        "before_after_code_files": [
          "scripts/ci/constraints/ci_branch_constraints.sh||scripts/ci/constraints/ci_branch_constraints.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "scripts/ci/constraints/ci_branch_constraints.sh||scripts/ci/constraints/ci_branch_constraints.sh": [
          "File: scripts/ci/constraints/ci_branch_constraints.sh -> scripts/ci/constraints/ci_branch_constraints.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: if [[ ${GITHUB_REF} == 'refs/heads/main' ]]; then",
          "22:   echo \"::set-output name=branch::constraints-main\"",
          "25: elif [[ ${GITHUB_REF} =~ refs/heads/v([0-9\\-]*)\\-(test|stable) ]]; then",
          "26:   echo \"::set-output name=branch::constraints-${BASH_REMATCH[1]}\"",
          "27: else",
          "28:   echo",
          "30:   echo",
          "32: fi",
          "",
          "[Removed Lines]",
          "23: elif [[ ${GITHUB_REF} == 'refs/heads/main' ]]; then",
          "24:   echo \"::set-output name=branch::constraints-main\"",
          "29:   echo \"Unexpected ref ${GITHUB_REF}. Exiting!\"",
          "31:   exit 1",
          "",
          "[Added Lines]",
          "26:   # Assume PR to constraints-main here",
          "28:   echo \"[${COLOR_YELLOW}Assuming that the PR is to 'main' branch!${COLOR_RESET}\"",
          "30:   echo \"::set-output name=branch::constraints-main\"",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "eeeacc4d7e8dca4af971d1873404f8ba788b8e73",
      "candidate_info": {
        "commit_hash": "eeeacc4d7e8dca4af971d1873404f8ba788b8e73",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/eeeacc4d7e8dca4af971d1873404f8ba788b8e73",
        "files": [
          "setup.cfg"
        ],
        "message": "Unpin ``argcomplete`` and ``colorlog`` (#20878)\n\nFor Both of these libraries, the only breaking changes are dropping support for old Python version.\n\n- https://github.com/kislyuk/argcomplete/blob/develop/Changes.rst\n- https://github.com/borntyping/python-colorlog/releases\n\n(cherry picked from commit 915773430427e219c1404270d828e709234ed294)",
        "before_after_code_files": [
          "setup.cfg||setup.cfg"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "setup.cfg||setup.cfg": [
          "File: setup.cfg -> setup.cfg",
          "--- Hunk 1 ---",
          "[Context before]",
          "82: #####################################################################################################",
          "83: install_requires =",
          "84:     alembic>=1.5.1, <2.0",
          "86:     attrs>=20.0, <21.0",
          "87:     blinker",
          "88:     cached_property~=1.5;python_version<=\"3.7\"",
          "",
          "[Removed Lines]",
          "85:     argcomplete~=1.10",
          "",
          "[Added Lines]",
          "85:     argcomplete>=1.10, <3.0",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "91:     cattrs~=1.1, !=1.7.*;python_version>\"3.6\"",
          "92:     # Required by vendored-in connexion",
          "93:     clickclick>=1.2",
          "95:     croniter>=0.3.17",
          "96:     cryptography>=0.9.3",
          "97:     dataclasses;python_version<\"3.7\"",
          "",
          "[Removed Lines]",
          "94:     colorlog>=4.0.2, <6.0",
          "",
          "[Added Lines]",
          "94:     colorlog>=4.0.2, <7.0",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "56aa22e685b34c2121cc7bebb130c524374bcdd6",
      "candidate_info": {
        "commit_hash": "56aa22e685b34c2121cc7bebb130c524374bcdd6",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/56aa22e685b34c2121cc7bebb130c524374bcdd6",
        "files": [
          "breeze",
          "scripts/ci/docker-compose/base.yml",
          "scripts/ci/libraries/_build_images.sh",
          "scripts/ci/libraries/_docker_engine_resources.sh",
          "scripts/ci/libraries/_push_pull_remove_images.sh",
          "scripts/ci/libraries/_runs.sh",
          "scripts/ci/provider_packages/ci_install_and_test_provider_packages.sh",
          "scripts/ci/static_checks/in_container_bats_tests.sh",
          "scripts/ci/static_checks/mypy.sh",
          "scripts/ci/static_checks/ui_lint.sh",
          "scripts/ci/static_checks/www_lint.sh",
          "scripts/ci/testing/ci_run_single_airflow_test_in_docker.sh",
          "scripts/ci/tools/fix_ownership.sh"
        ],
        "message": "Fix --github-image-id flag for Breeze (#18882) (#18946)\n\nWhen we moved to github registry, the --github-image-id flag was\nbroken as it had pulled the \"latest\" image when run right after\npulling the tagged image (and it run that image instead).\n\nThis change fixes it and uses GITHUB_PULL_IMAGE_TAG (latest if not\nspecified) everywhere where the image is used for running.\nThis flag is not persistent so it is not persistent.\n\n(cherry picked from commit 0a82a422e42072db459f527db976e0621ccab9fb)",
        "before_after_code_files": [
          "scripts/ci/libraries/_build_images.sh||scripts/ci/libraries/_build_images.sh",
          "scripts/ci/libraries/_docker_engine_resources.sh||scripts/ci/libraries/_docker_engine_resources.sh",
          "scripts/ci/libraries/_push_pull_remove_images.sh||scripts/ci/libraries/_push_pull_remove_images.sh",
          "scripts/ci/libraries/_runs.sh||scripts/ci/libraries/_runs.sh",
          "scripts/ci/provider_packages/ci_install_and_test_provider_packages.sh||scripts/ci/provider_packages/ci_install_and_test_provider_packages.sh",
          "scripts/ci/static_checks/in_container_bats_tests.sh||scripts/ci/static_checks/in_container_bats_tests.sh",
          "scripts/ci/static_checks/mypy.sh||scripts/ci/static_checks/mypy.sh",
          "scripts/ci/static_checks/ui_lint.sh||scripts/ci/static_checks/ui_lint.sh",
          "scripts/ci/static_checks/www_lint.sh||scripts/ci/static_checks/www_lint.sh",
          "scripts/ci/testing/ci_run_single_airflow_test_in_docker.sh||scripts/ci/testing/ci_run_single_airflow_test_in_docker.sh",
          "scripts/ci/tools/fix_ownership.sh||scripts/ci/tools/fix_ownership.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "scripts/ci/libraries/_build_images.sh||scripts/ci/libraries/_build_images.sh": [
          "File: scripts/ci/libraries/_build_images.sh -> scripts/ci/libraries/_build_images.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "271:     local_image_build_cache_file=\"${AIRFLOW_SOURCES}/manifests/local-build-cache-hash-${PYTHON_MAJOR_MINOR_VERSION}\"",
          "272:     # Remove the container just in case",
          "273:     docker_v rm --force \"local-airflow-ci-container\" 2>/dev/null >/dev/null",
          "275:         verbosity::print_info",
          "276:         verbosity::print_info \"Local airflow CI image not available\"",
          "277:         verbosity::print_info",
          "",
          "[Removed Lines]",
          "274:     if ! docker_v inspect \"${AIRFLOW_CI_IMAGE}\" 2>/dev/null >/dev/null; then",
          "",
          "[Added Lines]",
          "274:     if ! docker_v inspect \"${AIRFLOW_CI_IMAGE_WITH_TAG}\" 2>/dev/null >/dev/null; then",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "282:         return",
          "284:     fi",
          "286:     docker_v cp \"local-airflow-ci-container:/build-cache-hash\" \\",
          "287:         \"${local_image_build_cache_file}\" 2>/dev/null ||",
          "288:         touch \"${local_image_build_cache_file}\"",
          "",
          "[Removed Lines]",
          "285:     docker_v create --name \"local-airflow-ci-container\" \"${AIRFLOW_CI_IMAGE}\" 2>/dev/null >/dev/null",
          "",
          "[Added Lines]",
          "285:     docker_v create --name \"local-airflow-ci-container\" \"${AIRFLOW_CI_IMAGE_WITH_TAG}\" 2>/dev/null >/dev/null",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "399:     #  ghcr.io/apache/airflow/main/ci/python3.8",
          "400:     export AIRFLOW_CI_IMAGE=\"${image_name}/${BRANCH_NAME}/ci/python${PYTHON_MAJOR_MINOR_VERSION}\"",
          "402:     # Example:",
          "403:     #  local-airflow-ci-manifest/main/python3.8",
          "404:     export AIRFLOW_CI_LOCAL_MANIFEST_IMAGE=\"local-airflow-ci-manifest/${BRANCH_NAME}/python${PYTHON_MAJOR_MINOR_VERSION}\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "402:     # Example:",
          "403:     #  ghcr.io/apache/airflow/main/ci/python3.8:latest",
          "404:     #  ghcr.io/apache/airflow/main/ci/python3.8:<COMMIT_SHA>",
          "405:     export AIRFLOW_CI_IMAGE_WITH_TAG=\"${image_name}/${BRANCH_NAME}/ci/python${PYTHON_MAJOR_MINOR_VERSION}:${GITHUB_REGISTRY_PULL_IMAGE_TAG}\"",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "455:         else",
          "456:             verbosity::print_info \"Skip Login to GitHub Container Registry as token is missing\"",
          "457:         fi",
          "458:     fi",
          "459: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "463:         start_end::group_end",
          "",
          "---------------"
        ],
        "scripts/ci/libraries/_docker_engine_resources.sh||scripts/ci/libraries/_docker_engine_resources.sh": [
          "File: scripts/ci/libraries/_docker_engine_resources.sh -> scripts/ci/libraries/_docker_engine_resources.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "45: function docker_engine_resources::check_all_resources() {",
          "46:     docker_v run -t \"${EXTRA_DOCKER_FLAGS[@]}\" \\",
          "47:         --entrypoint \"/bin/bash\"  \\",
          "49:         -c \"/opt/airflow/scripts/in_container/run_resource_check.sh\"",
          "50: }",
          "",
          "[Removed Lines]",
          "48:         \"${AIRFLOW_CI_IMAGE}\" \\",
          "",
          "[Added Lines]",
          "48:         \"${AIRFLOW_CI_IMAGE_WITH_TAG}\" \\",
          "",
          "---------------"
        ],
        "scripts/ci/libraries/_push_pull_remove_images.sh||scripts/ci/libraries/_push_pull_remove_images.sh": [
          "File: scripts/ci/libraries/_push_pull_remove_images.sh -> scripts/ci/libraries/_push_pull_remove_images.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "108:         echo -n \"Docker pull base python image. Upgrade to newer deps: ${UPGRADE_TO_NEWER_DEPENDENCIES}",
          "109: \" > \"${DETECTED_TERMINAL}\"",
          "110:     fi",
          "131:     fi",
          "132: }",
          "",
          "[Removed Lines]",
          "111:     if [[ ${GITHUB_REGISTRY_PULL_IMAGE_TAG} != \"latest\" ]]; then",
          "112:         push_pull_remove_images::pull_image_if_not_present_or_forced \\",
          "113:             \"${AIRFLOW_PYTHON_BASE_IMAGE}${GITHUB_REGISTRY_PULL_IMAGE_TAG}\"",
          "114:         if [[ ${CHECK_IF_BASE_PYTHON_IMAGE_UPDATED} == \"true\" ]] ; then",
          "115:             echo",
          "116:             echo  \"${COLOR_RED}ERROR: You cannot check for base python image if you pull specific tag: ${GITHUB_REGISTRY_PULL_IMAGE_TAG}.${COLOR_RESET}\"",
          "117:             echo",
          "118:             return 1",
          "119:         fi",
          "120:     else",
          "121:         set +e",
          "122:         push_pull_remove_images::pull_image_if_not_present_or_forced \"${AIRFLOW_PYTHON_BASE_IMAGE}\"",
          "123:         local res=\"$?\"",
          "124:         set -e",
          "125:         if [[ ${CHECK_IF_BASE_PYTHON_IMAGE_UPDATED} == \"true\" || ${res} != \"0\" ]] ; then",
          "126:             # Rebuild the base python image using DockerHub - either when we explicitly want it",
          "127:             # or when there is no image available yet in ghcr.io (usually when you build it for the",
          "128:             # first time in your repository",
          "129:             push_pull_remove_images::check_and_rebuild_python_base_image_if_needed",
          "130:         fi",
          "",
          "[Added Lines]",
          "111:     set +e",
          "112:     push_pull_remove_images::pull_image_if_not_present_or_forced \"${AIRFLOW_PYTHON_BASE_IMAGE}\"",
          "113:     local res=\"$?\"",
          "114:     set -e",
          "115:     if [[ ${CHECK_IF_BASE_PYTHON_IMAGE_UPDATED} == \"true\" || ${res} != \"0\" ]] ; then",
          "116:         # Rebuild the base python image using DockerHub - either when we explicitly want it",
          "117:         # or when there is no image available yet in ghcr.io (usually when you build it for the",
          "118:         # first time in your repository",
          "119:         push_pull_remove_images::check_and_rebuild_python_base_image_if_needed",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "144:     fi",
          "145:     if [[ \"${DOCKER_CACHE}\" == \"pulled\" ]]; then",
          "146:         set +e",
          "149:         local res=\"$?\"",
          "150:         set -e",
          "151:         if [[ ${res} != \"0\" ]]; then",
          "",
          "[Removed Lines]",
          "147:         push_pull_remove_images::pull_image_if_not_present_or_forced \\",
          "148:             \"${AIRFLOW_CI_IMAGE}:${GITHUB_REGISTRY_PULL_IMAGE_TAG}\"",
          "",
          "[Added Lines]",
          "136:         push_pull_remove_images::pull_image_if_not_present_or_forced \"${AIRFLOW_CI_IMAGE_WITH_TAG}\"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "229: # Pushes Ci images and their tags to registry in GitHub",
          "230: function push_pull_remove_images::push_ci_images_to_github() {",
          "231:     if [[ \"${PUSH_PYTHON_BASE_IMAGE=}\" != \"false\" ]]; then",
          "232:         push_pull_remove_images::push_python_image_to_github",
          "233:     fi",
          "237:     # Also push ci manifest image if GITHUB_REGISTRY_PUSH_IMAGE_TAG is \"latest\"",
          "238:     if [[ ${GITHUB_REGISTRY_PUSH_IMAGE_TAG} == \"latest\" ]]; then",
          "239:         local airflow_ci_manifest_tagged_image=\"${AIRFLOW_CI_REMOTE_MANIFEST_IMAGE}:latest\"",
          "240:         docker_v tag \"${AIRFLOW_CI_LOCAL_MANIFEST_IMAGE}\" \"${airflow_ci_manifest_tagged_image}\"",
          "241:         push_pull_remove_images::push_image_with_retries \"${airflow_ci_manifest_tagged_image}\"",
          "242:     fi",
          "243: }",
          "245: # Pushes PROD image to registry in GitHub",
          "",
          "[Removed Lines]",
          "234:     local airflow_ci_tagged_image=\"${AIRFLOW_CI_IMAGE}:${GITHUB_REGISTRY_PUSH_IMAGE_TAG}\"",
          "235:     docker_v tag \"${AIRFLOW_CI_IMAGE}\" \"${airflow_ci_tagged_image}\"",
          "236:     push_pull_remove_images::push_image_with_retries \"${airflow_ci_tagged_image}\"",
          "",
          "[Added Lines]",
          "219:     start_end::group_start \"Push image\"",
          "223:     docker_v tag \"${AIRFLOW_CI_IMAGE}\" \"${AIRFLOW_CI_IMAGE}:${GITHUB_REGISTRY_PUSH_IMAGE_TAG}\"",
          "224:     push_pull_remove_images::push_image_with_retries \"${AIRFLOW_CI_IMAGE}:${GITHUB_REGISTRY_PUSH_IMAGE_TAG}\"",
          "231:     start_end::group_end",
          "",
          "---------------"
        ],
        "scripts/ci/libraries/_runs.sh||scripts/ci/libraries/_runs.sh": [
          "File: scripts/ci/libraries/_runs.sh -> scripts/ci/libraries/_runs.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "23:         -e \"GITHUB_ACTIONS=${GITHUB_ACTIONS=\"false\"}\" \\",
          "24:         --entrypoint \"/usr/local/bin/dumb-init\"  \\",
          "25:         --pull never \\",
          "27:         \"--\" \"/opt/airflow/scripts/in_container/run_docs_build.sh\" \"${@}\"",
          "28:     start_end::group_end",
          "29: }",
          "",
          "[Removed Lines]",
          "26:         \"${AIRFLOW_CI_IMAGE}\" \\",
          "",
          "[Added Lines]",
          "26:         \"${AIRFLOW_CI_IMAGE_WITH_TAG}\" \\",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "34:     docker_v run \"${EXTRA_DOCKER_FLAGS[@]}\" \\",
          "35:         --entrypoint \"/usr/local/bin/dumb-init\"  \\",
          "36:         --pull never \\",
          "38:         \"--\" \"/opt/airflow/scripts/in_container/run_generate_constraints.sh\"",
          "39:     start_end::group_end",
          "40: }",
          "",
          "[Removed Lines]",
          "37:         \"${AIRFLOW_CI_IMAGE}\" \\",
          "",
          "[Added Lines]",
          "37:         \"${AIRFLOW_CI_IMAGE_WITH_TAG}\" \\",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "47:         -t \\",
          "48:         -v \"${AIRFLOW_SOURCES}:/opt/airflow\" \\",
          "49:         --pull never \\",
          "51:         \"--\" \"/opt/airflow/scripts/in_container/run_prepare_airflow_packages.sh\"",
          "52:     start_end::group_end",
          "53: }",
          "",
          "[Removed Lines]",
          "50:         \"${AIRFLOW_CI_IMAGE}\" \\",
          "",
          "[Added Lines]",
          "50:         \"${AIRFLOW_CI_IMAGE_WITH_TAG}\" \\",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "61:         -t \\",
          "62:         -v \"${AIRFLOW_SOURCES}:/opt/airflow\" \\",
          "63:         --pull never \\",
          "65:         \"--\" \"/opt/airflow/scripts/in_container/run_prepare_provider_packages.sh\" \"${@}\"",
          "66: }",
          "",
          "[Removed Lines]",
          "64:         \"${AIRFLOW_CI_IMAGE}\" \\",
          "",
          "[Added Lines]",
          "64:         \"${AIRFLOW_CI_IMAGE_WITH_TAG}\" \\",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "80:         -e \"GENERATE_PROVIDERS_ISSUE\" \\",
          "81:         -e \"GITHUB_TOKEN\" \\",
          "82:         --pull never \\",
          "84:         \"--\" \"/opt/airflow/scripts/in_container/run_prepare_provider_documentation.sh\" \"${@}\"",
          "85: }",
          "",
          "[Removed Lines]",
          "83:         \"${AIRFLOW_CI_IMAGE}\" \\",
          "",
          "[Added Lines]",
          "83:         \"${AIRFLOW_CI_IMAGE_WITH_TAG}\" \\",
          "",
          "---------------"
        ],
        "scripts/ci/provider_packages/ci_install_and_test_provider_packages.sh||scripts/ci/provider_packages/ci_install_and_test_provider_packages.sh": [
          "File: scripts/ci/provider_packages/ci_install_and_test_provider_packages.sh -> scripts/ci/provider_packages/ci_install_and_test_provider_packages.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "38:         -v \"${AIRFLOW_SOURCES}/empty:/opt/airflow/airflow:cached\" \\",
          "39:         -v \"${AIRFLOW_SOURCES}/scripts/in_container:/opt/airflow/scripts/in_container:cached\" \\",
          "40:         -v \"${AIRFLOW_SOURCES}/dev/import_all_classes.py:/opt/airflow/dev/import_all_classes.py:cached\" \\",
          "42:         \"--\" \"/opt/airflow/scripts/in_container/run_install_and_test_provider_packages.sh\"",
          "43: }",
          "",
          "[Removed Lines]",
          "41:         \"${AIRFLOW_CI_IMAGE}\" \\",
          "",
          "[Added Lines]",
          "41:         \"${AIRFLOW_CI_IMAGE_WITH_TAG}\" \\",
          "",
          "---------------"
        ],
        "scripts/ci/static_checks/in_container_bats_tests.sh||scripts/ci/static_checks/in_container_bats_tests.sh": [
          "File: scripts/ci/static_checks/in_container_bats_tests.sh -> scripts/ci/static_checks/in_container_bats_tests.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "23:         docker_v run \"${EXTRA_DOCKER_FLAGS[@]}\" \\",
          "24:         --entrypoint \"/opt/bats/bin/bats\"  \\",
          "25:         \"-v\" \"$(pwd):/airflow\" \\",
          "27:         --tap  \"tests/bats/in_container/\"",
          "28:     else",
          "29:         docker_v run \"${EXTRA_DOCKER_FLAGS[@]}\" \\",
          "30:         --entrypoint \"/opt/bats/bin/bats\"  \\",
          "31:         \"-v\" \"$(pwd):/airflow\" \\",
          "33:         --tap \"${@}\"",
          "34:     fi",
          "35: }",
          "",
          "[Removed Lines]",
          "26:         \"${AIRFLOW_CI_IMAGE}\" \\",
          "32:         \"${AIRFLOW_CI_IMAGE}\" \\",
          "",
          "[Added Lines]",
          "26:         \"${AIRFLOW_CI_IMAGE_WITH_TAG}\" \\",
          "32:         \"${AIRFLOW_CI_IMAGE_WITH_TAG}\" \\",
          "",
          "---------------"
        ],
        "scripts/ci/static_checks/mypy.sh||scripts/ci/static_checks/mypy.sh": [
          "File: scripts/ci/static_checks/mypy.sh -> scripts/ci/static_checks/mypy.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "29:     docker_v run \"${EXTRA_DOCKER_FLAGS[@]}\" \\",
          "30:         --entrypoint \"/usr/local/bin/dumb-init\"  \\",
          "31:         \"-v\" \"${AIRFLOW_SOURCES}/.mypy_cache:/opt/airflow/.mypy_cache\" \\",
          "33:         \"--\" \"/opt/airflow/scripts/in_container/run_mypy.sh\" \"${files[@]}\"",
          "34: }",
          "",
          "[Removed Lines]",
          "32:         \"${AIRFLOW_CI_IMAGE}\" \\",
          "",
          "[Added Lines]",
          "32:         \"${AIRFLOW_CI_IMAGE_WITH_TAG}\" \\",
          "",
          "---------------"
        ],
        "scripts/ci/static_checks/ui_lint.sh||scripts/ci/static_checks/ui_lint.sh": [
          "File: scripts/ci/static_checks/ui_lint.sh -> scripts/ci/static_checks/ui_lint.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "28: docker run \"${EXTRA_DOCKER_FLAGS[@]}\" \\",
          "29:     --entrypoint \"/bin/bash\"  \\",
          "31:     -c 'cd airflow/ui && yarn --frozen-lockfile --non-interactive && yarn run lint \"${@}\"' \"${@#airflow/ui/}\"",
          "",
          "[Removed Lines]",
          "30:     \"${AIRFLOW_CI_IMAGE}\" \\",
          "",
          "[Added Lines]",
          "30:     \"${AIRFLOW_CI_IMAGE_WITH_TAG}\" \\",
          "",
          "---------------"
        ],
        "scripts/ci/static_checks/www_lint.sh||scripts/ci/static_checks/www_lint.sh": [
          "File: scripts/ci/static_checks/www_lint.sh -> scripts/ci/static_checks/www_lint.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "28: docker run \"${EXTRA_DOCKER_FLAGS[@]}\" \\",
          "29:     --entrypoint \"/bin/bash\"  \\",
          "31:     -c 'cd airflow/www && yarn --frozen-lockfile --non-interactive && yarn run lint \"${@}\"' \"${@#airflow/www/static/js/}\"",
          "",
          "[Removed Lines]",
          "30:     \"${AIRFLOW_CI_IMAGE}\" \\",
          "",
          "[Added Lines]",
          "30:     \"${AIRFLOW_CI_IMAGE_WITH_TAG}\" \\",
          "",
          "---------------"
        ],
        "scripts/ci/testing/ci_run_single_airflow_test_in_docker.sh||scripts/ci/testing/ci_run_single_airflow_test_in_docker.sh": [
          "File: scripts/ci/testing/ci_run_single_airflow_test_in_docker.sh -> scripts/ci/testing/ci_run_single_airflow_test_in_docker.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "170:             echo \"${COLOR_BLUE}*${COLOR_RESET}\"",
          "171:             echo \"${COLOR_BLUE}***********************************************************************************************${COLOR_RESET}\"",
          "172:             echo",
          "174:                 | sort | grep -v \"apache_airflow\" | grep -v \"@\" | grep -v \"/opt/airflow\" | grep -ve \"^#\")",
          "175:             echo",
          "176:         fi",
          "",
          "[Removed Lines]",
          "173:             curl \"${constraints_url}\" | grep -ve \"^#\" | diff --color=always - <( docker run --entrypoint /bin/bash \"${AIRFLOW_CI_IMAGE}\"  -c 'pip freeze' \\",
          "",
          "[Added Lines]",
          "173:             curl \"${constraints_url}\" | grep -ve \"^#\" | diff --color=always - <( docker run --entrypoint /bin/bash \"${AIRFLOW_CI_IMAGE_WITH_TAG}\"  -c 'pip freeze' \\",
          "",
          "---------------"
        ],
        "scripts/ci/tools/fix_ownership.sh||scripts/ci/tools/fix_ownership.sh": [
          "File: scripts/ci/tools/fix_ownership.sh -> scripts/ci/tools/fix_ownership.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "34: read -r -a EXTRA_DOCKER_FLAGS <<<\"$(local_mounts::convert_local_mounts_to_docker_params)\"",
          "37:     docker_v run --entrypoint /bin/bash \"${EXTRA_DOCKER_FLAGS[@]}\" \\",
          "38:         --rm \\",
          "39:         --env-file \"${AIRFLOW_SOURCES}/scripts/ci/docker-compose/_docker.env\" \\",
          "41:         -c /opt/airflow/scripts/in_container/run_fix_ownership.sh || true",
          "42: else",
          "44: fi",
          "",
          "[Removed Lines]",
          "36: if docker image inspect \"${AIRFLOW_CI_IMAGE}\" >/dev/null 2>&1; then",
          "40:         \"${AIRFLOW_CI_IMAGE}\" \\",
          "43:     echo \"Skip fixing ownership as seems that you do not have the ${AIRFLOW_CI_IMAGE} image yet\"",
          "",
          "[Added Lines]",
          "36: if docker image inspect \"${AIRFLOW_CI_IMAGE_WITH_TAG}\" >/dev/null 2>&1; then",
          "40:         \"${AIRFLOW_CI_IMAGE_WITH_TAG}\" \\",
          "43:     echo \"Skip fixing ownership as seems that you do not have the ${AIRFLOW_CI_IMAGE_WITH_TAG} image yet\"",
          "",
          "---------------"
        ]
      }
    }
  ]
}