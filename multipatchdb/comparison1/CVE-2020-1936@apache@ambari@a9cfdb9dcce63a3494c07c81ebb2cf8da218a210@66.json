{
  "cve_id": "CVE-2020-1936",
  "cve_desc": "A cross-site scripting issue was found in Apache Ambari Views. This was addressed in Apache Ambari 2.7.4.",
  "repo": "apache/ambari",
  "patch_hash": "a9cfdb9dcce63a3494c07c81ebb2cf8da218a210",
  "patch_info": {
    "commit_hash": "a9cfdb9dcce63a3494c07c81ebb2cf8da218a210",
    "repo": "apache/ambari",
    "commit_url": "https://github.com/apache/ambari/pull/3040/commits/a9cfdb9dcce63a3494c07c81ebb2cf8da218a210",
    "files": [
      "ambari-web/app/views/common/breadcrumbs_view.js"
    ],
    "message": "AMBARI-25329. Ambari breadcrumbs xss vulnerability",
    "before_after_code_files": [
      "ambari-web/app/views/common/breadcrumbs_view.js||ambari-web/app/views/common/breadcrumbs_view.js"
    ]
  },
  "patch_diff": {
    "ambari-web/app/views/common/breadcrumbs_view.js||ambari-web/app/views/common/breadcrumbs_view.js": [
      "File: ambari-web/app/views/common/breadcrumbs_view.js -> ambari-web/app/views/common/breadcrumbs_view.js",
      "--- Hunk 1 ---",
      "[Context before]",
      "149:   createLabel() {",
      "150:     let label = this.get('label');",
      "151:     let labelBindingPath = this.get('labelBindingPath');",
      "154:     this.set('formattedLabel', this.labelPostFormat(formattedLabel));",
      "155:   },",
      "",
      "[Removed Lines]",
      "153:     let formattedLabel = labelBindingPath ? App.get(_getLabelPathWithoutApp(labelBindingPath)) : label;",
      "",
      "[Added Lines]",
      "152:     let formattedLabel;",
      "154:     if (labelBindingPath) {",
      "155:       formattedLabel = Ember.Handlebars.Utils.escapeExpression(App.get(_getLabelPathWithoutApp(labelBindingPath)));",
      "156:     } else{",
      "157:       formattedLabel = label;",
      "158:     }",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "216:       }",
      "217:       currentState = currentState.get('parentState');",
      "218:     }",
      "220:     if (items.length) {",
      "221:       items.get('lastObject').setProperties({",
      "222:         disabled: true,",
      "",
      "[Removed Lines]",
      "219:     items = items.reverse().map(item => App.BreadcrumbItem.extend(item).create());",
      "",
      "[Added Lines]",
      "227:     items.reverse();",
      "228:     items.slice(1).forEach(item => item.label = Ember.Handlebars.Utils.escapeExpression(item.label));",
      "229:     items = items.map(item => App.BreadcrumbItem.extend(item).create());",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "79414c352647b03bffddfce8e3b64a5c97204aa5",
      "candidate_info": {
        "commit_hash": "79414c352647b03bffddfce8e3b64a5c97204aa5",
        "repo": "apache/ambari",
        "commit_url": "https://github.com/apache/ambari/commit/79414c352647b03bffddfce8e3b64a5c97204aa5",
        "files": [
          "ambari-metrics/ambari-metrics-timelineservice/src/test/java/org/apache/ambari/metrics/core/timeline/TimelineMetricsFilterTest.java"
        ],
        "message": "AMBARI-23811. TimelineMetricsFilterTest fails if dir name contains @ due to AMBARI-24066 (#2032)",
        "before_after_code_files": [
          "ambari-metrics/ambari-metrics-timelineservice/src/test/java/org/apache/ambari/metrics/core/timeline/TimelineMetricsFilterTest.java||ambari-metrics/ambari-metrics-timelineservice/src/test/java/org/apache/ambari/metrics/core/timeline/TimelineMetricsFilterTest.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/ambari/pull/3633",
          "https://github.com/apache/ambari/pull/3631",
          "https://github.com/apache/ambari/pull/3637",
          "https://github.com/apache/ambari/pull/3632",
          "https://github.com/apache/ambari/pull/3634",
          "https://github.com/apache/ambari/pull/3635"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "ambari-metrics/ambari-metrics-timelineservice/src/test/java/org/apache/ambari/metrics/core/timeline/TimelineMetricsFilterTest.java||ambari-metrics/ambari-metrics-timelineservice/src/test/java/org/apache/ambari/metrics/core/timeline/TimelineMetricsFilterTest.java": [
          "File: ambari-metrics/ambari-metrics-timelineservice/src/test/java/org/apache/ambari/metrics/core/timeline/TimelineMetricsFilterTest.java -> ambari-metrics/ambari-metrics-timelineservice/src/test/java/org/apache/ambari/metrics/core/timeline/TimelineMetricsFilterTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "27: import org.junit.Test;",
          "29: import java.net.URISyntaxException;",
          "31: import java.util.HashSet;",
          "32: import java.util.Set;",
          "",
          "[Removed Lines]",
          "30: import java.net.URL;",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "91:     expect(configuration.getMetricsConf()).andReturn(metricsConf).once();",
          "92:     replay(configuration);",
          "97:     TimelineMetricsFilter.initializeMetricFilter(configuration);",
          "99:     TimelineMetric timelineMetric = new TimelineMetric();",
          "",
          "[Removed Lines]",
          "94:     URL fileUrl = ClassLoader.getSystemResource(\"test_data/metric_blacklist.dat\");",
          "96:     metricsConf.set(\"timeline.metrics.blacklist.file\", fileUrl.getPath());",
          "",
          "[Added Lines]",
          "93:     metricsConf.set(\"timeline.metrics.blacklist.file\", getTestBlacklistFilePath());",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "183:     metricsConf.set(\"timeline.metrics.apps.whitelist\", \"namenode,nimbus\");",
          "184:     metricsConf.set(\"timeline.metrics.apps.blacklist\", \"datanode,kafka_broker\");",
          "185:     metricsConf.set(\"timeline.metrics.whitelist.file\", getTestWhitelistFilePath());",
          "188:     expect(configuration.getMetricsConf()).andReturn(metricsConf).once();",
          "190:     Set<String> whitelist = new HashSet<>();",
          "",
          "[Removed Lines]",
          "186:     URL fileUrl2 = ClassLoader.getSystemResource(\"test_data/metric_blacklist.dat\");",
          "187:     metricsConf.set(\"timeline.metrics.blacklist.file\", fileUrl2.getPath());",
          "",
          "[Added Lines]",
          "183:     metricsConf.set(\"timeline.metrics.blacklist.file\", getTestBlacklistFilePath());",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "256:   private static String getTestWhitelistFilePath() throws URISyntaxException {",
          "257:     return ClassLoader.getSystemResource(\"test_data/metric_whitelist.dat\").toURI().getPath();",
          "258:   }",
          "259: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "256:   private static String getTestBlacklistFilePath() throws URISyntaxException {",
          "257:     return ClassLoader.getSystemResource(\"test_data/metric_blacklist.dat\").toURI().getPath();",
          "258:   }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "df55794d96ff830cbfe06602a50e6796d454d798",
      "candidate_info": {
        "commit_hash": "df55794d96ff830cbfe06602a50e6796d454d798",
        "repo": "apache/ambari",
        "commit_url": "https://github.com/apache/ambari/commit/df55794d96ff830cbfe06602a50e6796d454d798",
        "files": [
          "ambari-server/src/main/java/org/apache/ambari/server/configuration/AmbariServerConfigurationKey.java",
          "ambari-server/src/main/java/org/apache/ambari/server/upgrade/SchemaUpgradeHelper.java",
          "ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog272.java",
          "ambari-server/src/main/python/ambari_server/setupSecurity.py",
          "ambari-server/src/test/java/org/apache/ambari/server/upgrade/UpgradeCatalog272Test.java",
          "ambari-server/src/test/python/TestAmbariServer.py"
        ],
        "message": "AMBARI-24542. Fixing typo in LDAP configuration property name (#2178)",
        "before_after_code_files": [
          "ambari-server/src/main/java/org/apache/ambari/server/configuration/AmbariServerConfigurationKey.java||ambari-server/src/main/java/org/apache/ambari/server/configuration/AmbariServerConfigurationKey.java",
          "ambari-server/src/main/java/org/apache/ambari/server/upgrade/SchemaUpgradeHelper.java||ambari-server/src/main/java/org/apache/ambari/server/upgrade/SchemaUpgradeHelper.java",
          "ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog272.java||ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog272.java",
          "ambari-server/src/main/python/ambari_server/setupSecurity.py||ambari-server/src/main/python/ambari_server/setupSecurity.py",
          "ambari-server/src/test/java/org/apache/ambari/server/upgrade/UpgradeCatalog272Test.java||ambari-server/src/test/java/org/apache/ambari/server/upgrade/UpgradeCatalog272Test.java",
          "ambari-server/src/test/python/TestAmbariServer.py||ambari-server/src/test/python/TestAmbariServer.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/ambari/pull/3633",
          "https://github.com/apache/ambari/pull/3631",
          "https://github.com/apache/ambari/pull/3637",
          "https://github.com/apache/ambari/pull/3632",
          "https://github.com/apache/ambari/pull/3634",
          "https://github.com/apache/ambari/pull/3635"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "ambari-server/src/main/java/org/apache/ambari/server/configuration/AmbariServerConfigurationKey.java||ambari-server/src/main/java/org/apache/ambari/server/configuration/AmbariServerConfigurationKey.java": [
          "File: ambari-server/src/main/java/org/apache/ambari/server/configuration/AmbariServerConfigurationKey.java -> ambari-server/src/main/java/org/apache/ambari/server/configuration/AmbariServerConfigurationKey.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "72:   FORCE_LOWERCASE_USERNAMES(AmbariServerConfigurationCategory.LDAP_CONFIGURATION, \"ambari.ldap.advanced.force_lowercase_usernames\", PLAINTEXT, \"\", \"Declares whether to force the ldap user name to be lowercase or leave as-is.\\nThis is useful when local user names are expected to be lowercase but the LDAP user names are not.\"),",
          "73:   REFERRAL_HANDLING(AmbariServerConfigurationCategory.LDAP_CONFIGURATION, \"ambari.ldap.advanced.referrals\", PLAINTEXT, \"follow\", \"Determines whether to follow LDAP referrals to other URLs when the LDAP controller doesn't have the requested object.\"),",
          "74:   PAGINATION_ENABLED(AmbariServerConfigurationCategory.LDAP_CONFIGURATION, \"ambari.ldap.advanced.pagination_enabled\", PLAINTEXT, \"true\", \"Determines whether results from LDAP are paginated when requested.\"),",
          "76:   DISABLE_ENDPOINT_IDENTIFICATION(AmbariServerConfigurationCategory.LDAP_CONFIGURATION, \"ambari.ldap.advanced.disable_endpoint_identification\", PLAINTEXT, \"false\", \"Determines whether to disable endpoint identification (hostname verification) during SSL handshake while updating from LDAP.\"),",
          "",
          "[Removed Lines]",
          "75:   COLLISION_BEHAVIOR(AmbariServerConfigurationCategory.LDAP_CONFIGURATION, \"ambari.ldap.advance.collision_behavior\", PLAINTEXT, \"convert\", \"Determines how to handle username collision while updating from LDAP.\"),",
          "",
          "[Added Lines]",
          "75:   COLLISION_BEHAVIOR(AmbariServerConfigurationCategory.LDAP_CONFIGURATION, \"ambari.ldap.advanced.collision_behavior\", PLAINTEXT, \"convert\", \"Determines how to handle username collision while updating from LDAP.\"),",
          "",
          "---------------"
        ],
        "ambari-server/src/main/java/org/apache/ambari/server/upgrade/SchemaUpgradeHelper.java||ambari-server/src/main/java/org/apache/ambari/server/upgrade/SchemaUpgradeHelper.java": [
          "File: ambari-server/src/main/java/org/apache/ambari/server/upgrade/SchemaUpgradeHelper.java -> ambari-server/src/main/java/org/apache/ambari/server/upgrade/SchemaUpgradeHelper.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "190:       catalogBinder.addBinding().to(UpgradeCatalog262.class);",
          "191:       catalogBinder.addBinding().to(UpgradeCatalog270.class);",
          "192:       catalogBinder.addBinding().to(UpgradeCatalog271.class);",
          "193:       catalogBinder.addBinding().to(UpdateAlertScriptPaths.class);",
          "194:       catalogBinder.addBinding().to(FinalUpgradeCatalog.class);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "193:       catalogBinder.addBinding().to(UpgradeCatalog272.class);",
          "",
          "---------------"
        ],
        "ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog272.java||ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog272.java": [
          "File: ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog272.java -> ambari-server/src/main/java/org/apache/ambari/server/upgrade/UpgradeCatalog272.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.ambari.server.upgrade;",
          "20: import static org.apache.ambari.server.configuration.AmbariServerConfigurationCategory.LDAP_CONFIGURATION;",
          "21: import static org.apache.ambari.server.upgrade.UpgradeCatalog270.AMBARI_CONFIGURATION_CATEGORY_NAME_COLUMN;",
          "22: import static org.apache.ambari.server.upgrade.UpgradeCatalog270.AMBARI_CONFIGURATION_PROPERTY_NAME_COLUMN;",
          "23: import static org.apache.ambari.server.upgrade.UpgradeCatalog270.AMBARI_CONFIGURATION_TABLE;",
          "25: import java.sql.SQLException;",
          "27: import org.apache.ambari.server.AmbariException;",
          "28: import org.slf4j.Logger;",
          "29: import org.slf4j.LoggerFactory;",
          "31: import com.google.inject.Inject;",
          "32: import com.google.inject.Injector;",
          "37: public class UpgradeCatalog272 extends AbstractUpgradeCatalog {",
          "39:   private static final Logger LOG = LoggerFactory.getLogger(UpgradeCatalog272.class);",
          "41:   private static final String LDAP_CONFIGURATION_WRONG_COLLISION_BEHAVIOR_PROPERTY_NAME = \"ambari.ldap.advance.collision_behavior\";",
          "42:   private static final String LDAP_CONFIGURATION_CORRECT_COLLISION_BEHAVIOR_PROPERTY_NAME = \"ambari.ldap.advanced.collision_behavior\";",
          "43:   static final String RENAME_COLLISION_BEHAVIOR_PROPERTY_SQL = String.format(\"UPDATE %s SET %s = '%s' WHERE %s = '%s' AND %s = '%s'\", AMBARI_CONFIGURATION_TABLE,",
          "44:       AMBARI_CONFIGURATION_PROPERTY_NAME_COLUMN, LDAP_CONFIGURATION_CORRECT_COLLISION_BEHAVIOR_PROPERTY_NAME, AMBARI_CONFIGURATION_CATEGORY_NAME_COLUMN,",
          "45:       LDAP_CONFIGURATION.getCategoryName(), AMBARI_CONFIGURATION_PROPERTY_NAME_COLUMN, LDAP_CONFIGURATION_WRONG_COLLISION_BEHAVIOR_PROPERTY_NAME);",
          "47:   @Inject",
          "48:   public UpgradeCatalog272(Injector injector) {",
          "49:     super(injector);",
          "50:   }",
          "52:   @Override",
          "53:   public String getSourceVersion() {",
          "54:     return \"2.7.1\";",
          "55:   }",
          "57:   @Override",
          "58:   public String getTargetVersion() {",
          "59:     return \"2.7.2\";",
          "60:   }",
          "62:   @Override",
          "63:   protected void executeDDLUpdates() throws AmbariException, SQLException {",
          "65:   }",
          "67:   @Override",
          "68:   protected void executePreDMLUpdates() throws AmbariException, SQLException {",
          "70:   }",
          "72:   @Override",
          "73:   protected void executeDMLUpdates() throws AmbariException, SQLException {",
          "74:     renameLdapSynchCollisionBehaviorValue();",
          "75:   }",
          "77:   protected int renameLdapSynchCollisionBehaviorValue() throws SQLException {",
          "78:     int numberOfRecordsRenamed = 0;",
          "79:     if (dbAccessor.tableExists(AMBARI_CONFIGURATION_TABLE)) {",
          "80:       LOG.debug(\"Executing: {}\", RENAME_COLLISION_BEHAVIOR_PROPERTY_SQL);",
          "81:       numberOfRecordsRenamed = dbAccessor.executeUpdate(RENAME_COLLISION_BEHAVIOR_PROPERTY_SQL);",
          "82:       LOG.info(\"Renamed {} {} with incorrect LDAP configuration property name\", numberOfRecordsRenamed, 1 >= numberOfRecordsRenamed ? \"record\" : \"records\");",
          "83:     } else {",
          "84:       LOG.info(\"{} table does not exists; nothing to update\", AMBARI_CONFIGURATION_TABLE);",
          "85:     }",
          "86:     return numberOfRecordsRenamed;",
          "87:   }",
          "89: }",
          "",
          "---------------"
        ],
        "ambari-server/src/main/python/ambari_server/setupSecurity.py||ambari-server/src/main/python/ambari_server/setupSecurity.py": [
          "File: ambari-server/src/main/python/ambari_server/setupSecurity.py -> ambari-server/src/main/python/ambari_server/setupSecurity.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "683:     LdapPropTemplate(properties, options.ldap_base_dn, \"ambari.ldap.attributes.user.search_base\", \"Search Base{0}: \", REGEX_ANYTHING, False, \"dc=ambari,dc=apache,dc=org\"),",
          "684:     LdapPropTemplate(properties, options.ldap_referral, \"ambari.ldap.advanced.referrals\", \"Referral method [follow/ignore]{0}: \", REGEX_REFERRAL, True, \"follow\"),",
          "685:     LdapPropTemplate(properties, options.ldap_bind_anonym, \"ambari.ldap.connectivity.anonymous_bind\", \"Bind anonymously [true/false]{0}: \", REGEX_TRUE_FALSE, False, \"false\"),",
          "687:     LdapPropTemplate(properties, options.ldap_force_lowercase_usernames, \"ambari.ldap.advanced.force_lowercase_usernames\", \"Force lower-case user names [true/false]{0}:\", REGEX_TRUE_FALSE, True),",
          "688:     LdapPropTemplate(properties, options.ldap_pagination_enabled, \"ambari.ldap.advanced.pagination_enabled\", \"Results from LDAP are paginated when requested [true/false]{0}:\", REGEX_TRUE_FALSE, True)",
          "689:   ]",
          "",
          "[Removed Lines]",
          "686:     LdapPropTemplate(properties, options.ldap_sync_username_collisions_behavior, \"ambari.ldap.advance.collision_behavior\", \"Handling behavior for username collisions [convert/skip] for LDAP sync{0}: \", REGEX_SKIP_CONVERT, False, \"skip\"),",
          "",
          "[Added Lines]",
          "686:     LdapPropTemplate(properties, options.ldap_sync_username_collisions_behavior, \"ambari.ldap.advanced.collision_behavior\", \"Handling behavior for username collisions [convert/skip] for LDAP sync{0}: \", REGEX_SKIP_CONVERT, False, \"skip\"),",
          "",
          "---------------"
        ],
        "ambari-server/src/test/java/org/apache/ambari/server/upgrade/UpgradeCatalog272Test.java||ambari-server/src/test/java/org/apache/ambari/server/upgrade/UpgradeCatalog272Test.java": [
          "File: ambari-server/src/test/java/org/apache/ambari/server/upgrade/UpgradeCatalog272Test.java -> ambari-server/src/test/java/org/apache/ambari/server/upgrade/UpgradeCatalog272Test.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.ambari.server.upgrade;",
          "20: import static org.apache.ambari.server.upgrade.UpgradeCatalog270.AMBARI_CONFIGURATION_TABLE;",
          "21: import static org.apache.ambari.server.upgrade.UpgradeCatalog272.RENAME_COLLISION_BEHAVIOR_PROPERTY_SQL;",
          "22: import static org.easymock.EasyMock.createMockBuilder;",
          "23: import static org.easymock.EasyMock.expect;",
          "24: import static org.easymock.EasyMock.replay;",
          "25: import static org.easymock.EasyMock.verify;",
          "26: import static org.junit.Assert.assertEquals;",
          "28: import java.lang.reflect.Method;",
          "30: import org.apache.ambari.server.orm.DBAccessor;",
          "31: import org.easymock.EasyMockSupport;",
          "32: import org.junit.Before;",
          "33: import org.junit.Test;",
          "35: import com.google.inject.Injector;",
          "37: public class UpgradeCatalog272Test {",
          "39:   private Injector injector;",
          "40:   private DBAccessor dbAccessor;",
          "42:   @Before",
          "43:   public void init() {",
          "44:     final EasyMockSupport easyMockSupport = new EasyMockSupport();",
          "45:     injector = easyMockSupport.createNiceMock(Injector.class);",
          "46:     dbAccessor = easyMockSupport.createNiceMock(DBAccessor.class);",
          "47:   }",
          "49:   @Test",
          "50:   public void testExecuteDMLUpdates() throws Exception {",
          "51:     final Method renameLdapSynchCollisionBehaviorValue = UpgradeCatalog272.class.getDeclaredMethod(\"renameLdapSynchCollisionBehaviorValue\");",
          "53:     final UpgradeCatalog272 upgradeCatalog272 = createMockBuilder(UpgradeCatalog272.class).addMockedMethod(renameLdapSynchCollisionBehaviorValue).createMock();",
          "55:     expect(upgradeCatalog272.renameLdapSynchCollisionBehaviorValue()).andReturn(0).once();",
          "57:     replay(upgradeCatalog272);",
          "59:     upgradeCatalog272.executeDMLUpdates();",
          "61:     verify(upgradeCatalog272);",
          "62:   }",
          "64:   @Test",
          "65:   public void shouldRenameCollisionBehaviorLdapCategoryPropertyNameIfTableWithDataExists() throws Exception {",
          "66:     final int expectedResult = 3;",
          "67:     expect(dbAccessor.tableExists(AMBARI_CONFIGURATION_TABLE)).andReturn(true).once();",
          "68:     expect(dbAccessor.executeUpdate(RENAME_COLLISION_BEHAVIOR_PROPERTY_SQL)).andReturn(expectedResult).once();",
          "69:     replay(dbAccessor);",
          "70:     final UpgradeCatalog272 upgradeCatalog272 = new UpgradeCatalog272(injector);",
          "71:     upgradeCatalog272.dbAccessor = dbAccessor;",
          "72:     assertEquals(expectedResult, upgradeCatalog272.renameLdapSynchCollisionBehaviorValue());",
          "73:     verify(dbAccessor);",
          "74:   }",
          "76:   @Test",
          "77:   public void shouldNotRenameCollisionBehaviorLdapCategoryPropertyNameIfTableDoesNotExist() throws Exception {",
          "78:     final int expectedResult = 0;",
          "79:     expect(dbAccessor.tableExists(AMBARI_CONFIGURATION_TABLE)).andReturn(false).once();",
          "80:     replay(dbAccessor);",
          "81:     final UpgradeCatalog272 upgradeCatalog272 = new UpgradeCatalog272(injector);",
          "82:     upgradeCatalog272.dbAccessor = dbAccessor;",
          "83:     assertEquals(expectedResult, upgradeCatalog272.renameLdapSynchCollisionBehaviorValue());",
          "84:     verify(dbAccessor);",
          "85:   }",
          "87: }",
          "",
          "---------------"
        ],
        "ambari-server/src/test/python/TestAmbariServer.py||ambari-server/src/test/python/TestAmbariServer.py": [
          "File: ambari-server/src/test/python/TestAmbariServer.py -> ambari-server/src/test/python/TestAmbariServer.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "7070:         \"ambari.ldap.attributes.user.search_base\": \"base\",",
          "7071:         \"ambari.ldap.advanced.referrals\": \"follow\",",
          "7072:         \"ambari.ldap.connectivity.anonymous_bind\": \"true\",",
          "7074:         \"ambari.ldap.advanced.force_lowercase_usernames\": \"false\",",
          "7075:         \"ambari.ldap.advanced.pagination_enabled\": \"false\",",
          "7076:         \"ambari.ldap.authentication.enabled\": \"true\"",
          "",
          "[Removed Lines]",
          "7073:         \"ambari.ldap.advance.collision_behavior\": \"skip\",",
          "",
          "[Added Lines]",
          "7073:         \"ambari.ldap.advanced.collision_behavior\": \"skip\",",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "7088:         \"ambari.ldap.attributes.user.name_attr\": \"user\",",
          "7089:         \"ambari.ldap.attributes.user.search_base\": \"uid\",",
          "7090:         \"ambari.ldap.connectivity.anonymous_bind\": \"true\",",
          "7092:         \"ambari.ldap.advanced.force_lowercase_usernames\": \"false\",",
          "7093:         \"ambari.ldap.advanced.pagination_enabled\": \"false\",",
          "7094:         \"ambari.ldap.advanced.referrals\": \"follow\",",
          "",
          "[Removed Lines]",
          "7091:         \"ambari.ldap.advance.collision_behavior\": \"skip\",",
          "",
          "[Added Lines]",
          "7091:         \"ambari.ldap.advanced.collision_behavior\": \"skip\",",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "7113:         \"ambari.ldap.attributes.user.search_base\": \"base\",",
          "7114:         \"ambari.ldap.advanced.referrals\": \"follow\",",
          "7115:         \"ambari.ldap.connectivity.anonymous_bind\": \"true\",",
          "7117:         \"ambari.ldap.advanced.force_lowercase_usernames\": \"false\",",
          "7118:         \"ambari.ldap.advanced.pagination_enabled\": \"false\",",
          "7119:         \"ambari.ldap.authentication.enabled\": \"true\"",
          "",
          "[Removed Lines]",
          "7116:         \"ambari.ldap.advance.collision_behavior\": \"skip\",",
          "",
          "[Added Lines]",
          "7116:         \"ambari.ldap.advanced.collision_behavior\": \"skip\",",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "7244:         \"ambari.ldap.attributes.user.name_attr\": \"test\",",
          "7245:         \"ambari.ldap.attributes.user.search_base\": \"test\",",
          "7246:         \"ambari.ldap.connectivity.anonymous_bind\": \"false\",",
          "7248:         \"ambari.ldap.advanced.force_lowercase_usernames\": \"false\",",
          "7249:         \"ambari.ldap.advanced.pagination_enabled\": \"false\",",
          "7250:         \"ambari.ldap.connectivity.bind_dn\": \"test\",",
          "",
          "[Removed Lines]",
          "7247:         \"ambari.ldap.advance.collision_behavior\": \"skip\",",
          "",
          "[Added Lines]",
          "7247:         \"ambari.ldap.advanced.collision_behavior\": \"skip\",",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "7269:         \"ambari.ldap.attributes.user.name_attr\": \"test\",",
          "7270:         \"ambari.ldap.attributes.user.search_base\": \"test\",",
          "7271:         \"ambari.ldap.connectivity.anonymous_bind\": \"false\",",
          "7273:         \"ambari.ldap.advanced.force_lowercase_usernames\": \"false\",",
          "7274:         \"ambari.ldap.advanced.pagination_enabled\": \"false\",",
          "7275:         \"ambari.ldap.connectivity.bind_dn\": \"test\",",
          "",
          "[Removed Lines]",
          "7272:         \"ambari.ldap.advance.collision_behavior\": \"skip\",",
          "",
          "[Added Lines]",
          "7272:         \"ambari.ldap.advanced.collision_behavior\": \"skip\",",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "7430:         \"ambari.ldap.attributes.user.search_base\": \"test\",",
          "7431:         \"ambari.ldap.attributes.dn_attr\": \"test\",",
          "7432:         \"ambari.ldap.connectivity.anonymous_bind\": \"false\",",
          "7434:         \"ambari.ldap.connectivity.bind_dn\": \"test\",",
          "7435:         \"client.security\": \"ldap\",",
          "7436:         \"ssl.trustStore.type\": \"test\",",
          "",
          "[Removed Lines]",
          "7433:         \"ambari.ldap.advance.collision_behavior\": \"skip\",",
          "",
          "[Added Lines]",
          "7433:         \"ambari.ldap.advanced.collision_behavior\": \"skip\",",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "9c5e9e26a62a67c3fe5bc311e88c6d4f2242c3d7",
      "candidate_info": {
        "commit_hash": "9c5e9e26a62a67c3fe5bc311e88c6d4f2242c3d7",
        "repo": "apache/ambari",
        "commit_url": "https://github.com/apache/ambari/commit/9c5e9e26a62a67c3fe5bc311e88c6d4f2242c3d7",
        "files": [
          "ambari-common/src/main/python/resource_management/core/sudo.py"
        ],
        "message": "AMBARI-24247. Kafka failed to stop (aonishuk)",
        "before_after_code_files": [
          "ambari-common/src/main/python/resource_management/core/sudo.py||ambari-common/src/main/python/resource_management/core/sudo.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/ambari/pull/3633",
          "https://github.com/apache/ambari/pull/3631",
          "https://github.com/apache/ambari/pull/3637",
          "https://github.com/apache/ambari/pull/3632",
          "https://github.com/apache/ambari/pull/3634",
          "https://github.com/apache/ambari/pull/3635"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "ambari-common/src/main/python/resource_management/core/sudo.py||ambari-common/src/main/python/resource_management/core/sudo.py": [
          "File: ambari-common/src/main/python/resource_management/core/sudo.py -> ambari-common/src/main/python/resource_management/core/sudo.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "50:     for root, dirs, files in unicode_walk(path, followlinks=True):",
          "51:       for name in files + dirs:",
          "58:   def chmod(path, mode):",
          "",
          "[Removed Lines]",
          "52:         if follow_links:",
          "53:           os.chown(os.path.join(root, name), uid, gid)",
          "54:         else:",
          "55:           os.lchown(os.path.join(root, name), uid, gid)",
          "",
          "[Added Lines]",
          "52:         try:",
          "53:           if follow_links:",
          "54:             os.chown(os.path.join(root, name), uid, gid)",
          "55:           else:",
          "56:             os.lchown(os.path.join(root, name), uid, gid)",
          "57:         except OSError as ex:",
          "58:           # Handle race condition: file was deleted/moved while iterating by",
          "59:           # ignoring OSError: [Errno 2] No such file or directory",
          "60:           if ex.errno != errno.ENOENT:",
          "61:             raise",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "5cadc1d2ce6bc11e07f106c03466342a345919e4",
      "candidate_info": {
        "commit_hash": "5cadc1d2ce6bc11e07f106c03466342a345919e4",
        "repo": "apache/ambari",
        "commit_url": "https://github.com/apache/ambari/commit/5cadc1d2ce6bc11e07f106c03466342a345919e4",
        "files": [
          "ambari-common/src/main/python/resource_management/libraries/functions/hive_check.py",
          "ambari-server/src/main/resources/common-services/HIVE/0.12.0.2.0/package/alerts/alert_hive_interactive_thrift_port.py",
          "ambari-server/src/main/resources/common-services/HIVE/0.12.0.2.0/package/alerts/alert_hive_thrift_port.py",
          "ambari-server/src/test/python/stacks/2.0.6/HIVE/test_hive_service_check.py"
        ],
        "message": "[AMBARI-24582] - Ambari Alert - HiveServer2 Process - False negative in Certain Scenarios",
        "before_after_code_files": [
          "ambari-common/src/main/python/resource_management/libraries/functions/hive_check.py||ambari-common/src/main/python/resource_management/libraries/functions/hive_check.py",
          "ambari-server/src/main/resources/common-services/HIVE/0.12.0.2.0/package/alerts/alert_hive_interactive_thrift_port.py||ambari-server/src/main/resources/common-services/HIVE/0.12.0.2.0/package/alerts/alert_hive_interactive_thrift_port.py",
          "ambari-server/src/main/resources/common-services/HIVE/0.12.0.2.0/package/alerts/alert_hive_thrift_port.py||ambari-server/src/main/resources/common-services/HIVE/0.12.0.2.0/package/alerts/alert_hive_thrift_port.py",
          "ambari-server/src/test/python/stacks/2.0.6/HIVE/test_hive_service_check.py||ambari-server/src/test/python/stacks/2.0.6/HIVE/test_hive_service_check.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/ambari/pull/3633",
          "https://github.com/apache/ambari/pull/3631",
          "https://github.com/apache/ambari/pull/3637",
          "https://github.com/apache/ambari/pull/3632",
          "https://github.com/apache/ambari/pull/3634",
          "https://github.com/apache/ambari/pull/3635"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "ambari-common/src/main/python/resource_management/libraries/functions/hive_check.py||ambari-common/src/main/python/resource_management/libraries/functions/hive_check.py": [
          "File: ambari-common/src/main/python/resource_management/libraries/functions/hive_check.py -> ambari-common/src/main/python/resource_management/libraries/functions/hive_check.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "27: def check_thrift_port_sasl(address, port, hive_auth=\"NOSASL\", key=None, kinitcmd=None, smokeuser='ambari-qa',",
          "30:   \"\"\"",
          "31:   Hive thrift SASL port check",
          "32:   \"\"\"",
          "",
          "[Removed Lines]",
          "28:                            transport_mode=\"binary\", http_endpoint=\"cliservice\", ssl=False, ssl_keystore=None,",
          "29:                            ssl_password=None, check_command_timeout=30, ldap_username=\"\", ldap_password=\"\"):",
          "",
          "[Added Lines]",
          "28:                            hive_user='hive', transport_mode=\"binary\", http_endpoint=\"cliservice\",",
          "29:                            ssl=False, ssl_keystore=None, ssl_password=None, check_command_timeout=30,",
          "30:                            ldap_username=\"\", ldap_password=\"\"):",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "71:     finally:",
          "72:       kinit_lock.release()",
          "77:   Execute(cmd,",
          "78:     user=smokeuser,",
          "",
          "[Removed Lines]",
          "74:   cmd = \"! beeline -u '%s' %s -e '' 2>&1| awk '{print}'|grep -i -e 'Connection refused' -e 'Invalid URL'\" % \\",
          "75:         (format(\";\".join(beeline_url)), format(credential_str))",
          "",
          "[Added Lines]",
          "75:   # -n the user to connect as (ignored when using the hive principal in the URL, can be different from the user running the beeline command)",
          "76:   # -e ';' executes a SQL commmand of NOOP",
          "77:   cmd = \"beeline -n %s -u '%s' %s -e ';' 2>&1 | awk '{print}' | grep -i -e 'Connected to:' -e 'Transaction isolation:'\" % \\",
          "78:         (format(hive_user), format(\";\".join(beeline_url)), format(credential_str))",
          "",
          "---------------"
        ],
        "ambari-server/src/main/resources/common-services/HIVE/0.12.0.2.0/package/alerts/alert_hive_interactive_thrift_port.py||ambari-server/src/main/resources/common-services/HIVE/0.12.0.2.0/package/alerts/alert_hive_interactive_thrift_port.py": [
          "File: ambari-server/src/main/resources/common-services/HIVE/0.12.0.2.0/package/alerts/alert_hive_interactive_thrift_port.py -> ambari-server/src/main/resources/common-services/HIVE/0.12.0.2.0/package/alerts/alert_hive_interactive_thrift_port.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "69: SMOKEUSER_SCRIPT_PARAM_KEY = 'default.smoke.user'",
          "70: SMOKEUSER_DEFAULT = 'ambari-qa'",
          "75: CHECK_COMMAND_TIMEOUT_KEY = 'check.command.timeout'",
          "76: CHECK_COMMAND_TIMEOUT_DEFAULT = 60.0",
          "",
          "[Removed Lines]",
          "72: HADOOPUSER_KEY = '{{cluster-env/hadoop.user.name}}'",
          "73: HADOOPUSER_DEFAULT = 'hadoop'",
          "",
          "[Added Lines]",
          "72: HIVE_USER_KEY = '{{hive-env/hive_user}}'",
          "73: HIVE_USER_DEFAULT = 'hive'",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "88:           HIVE_SERVER_INTERACTIVE_PRINCIPAL_KEY, SMOKEUSER_KEYTAB_KEY, SMOKEUSER_PRINCIPAL_KEY,",
          "89:           HIVE_SERVER_INTERACTIVE_THRIFT_HTTP_PORT_KEY, HIVE_SERVER_INTERACTIVE_TRANSPORT_MODE_KEY,",
          "90:           HIVE_SERVER_TRANSPORT_MODE_KEY, KERBEROS_EXECUTABLE_SEARCH_PATHS_KEY, HIVE_SSL,",
          "98: @OsFamilyFuncImpl(os_family=OsFamilyImpl.DEFAULT)",
          "99: def execute(configurations={}, parameters={}, host_name=None):",
          "100:   \"\"\"",
          "",
          "[Removed Lines]",
          "91:           HIVE_SSL_KEYSTORE_PATH, HIVE_SSL_KEYSTORE_PASSWORD, HIVE_LDAP_USERNAME, HIVE_LDAP_PASSWORD)",
          "94: @OsFamilyFuncImpl(os_family=OSConst.WINSRV_FAMILY)",
          "95: def get_tokens():",
          "96:   pass",
          "",
          "[Added Lines]",
          "91:           HIVE_SSL_KEYSTORE_PATH, HIVE_SSL_KEYSTORE_PASSWORD, HIVE_LDAP_USERNAME, HIVE_LDAP_PASSWORD,",
          "92:           HIVE_USER_KEY)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "170:   if SMOKEUSER_KEY in configurations:",
          "171:     smokeuser = configurations[SMOKEUSER_KEY]",
          "173:   ldap_username = \"\"",
          "174:   ldap_password = \"\"",
          "175:   if HIVE_LDAP_USERNAME in configurations:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "170:   hive_user = HIVE_USER_DEFAULT",
          "171:   if HIVE_USER_KEY in configurations:",
          "172:     hive_user = configurations[HIVE_USER_KEY]",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "208:     try:",
          "209:       hive_check.check_thrift_port_sasl(host_name, port, hive_server2_authentication, hive_server_principal,",
          "211:                                         ssl_keystore=hive_ssl_keystore_path, ssl_password=hive_ssl_keystore_password,",
          "212:                                         check_command_timeout=int(check_command_timeout), ldap_username=ldap_username,",
          "213:                                         ldap_password=ldap_password)",
          "",
          "[Removed Lines]",
          "210:                                         kinitcmd, smokeuser, transport_mode=transport_mode, ssl=hive_ssl,",
          "",
          "[Added Lines]",
          "211:                                         kinitcmd, smokeuser, hive_user = hive_user, transport_mode=transport_mode, ssl=hive_ssl,",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "223:     result_code = 'UNKNOWN'",
          "225:   return (result_code, [label])",
          "",
          "[Removed Lines]",
          "228: @OsFamilyFuncImpl(os_family=OSConst.WINSRV_FAMILY)",
          "229: def execute(configurations={}, parameters={}, host_name=None):",
          "230:   pass",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "ambari-server/src/main/resources/common-services/HIVE/0.12.0.2.0/package/alerts/alert_hive_thrift_port.py||ambari-server/src/main/resources/common-services/HIVE/0.12.0.2.0/package/alerts/alert_hive_thrift_port.py": [
          "File: ambari-server/src/main/resources/common-services/HIVE/0.12.0.2.0/package/alerts/alert_hive_thrift_port.py -> ambari-server/src/main/resources/common-services/HIVE/0.12.0.2.0/package/alerts/alert_hive_thrift_port.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "69: SMOKEUSER_SCRIPT_PARAM_KEY = 'default.smoke.user'",
          "70: SMOKEUSER_DEFAULT = 'ambari-qa'",
          "75: CHECK_COMMAND_TIMEOUT_KEY = 'check.command.timeout'",
          "76: CHECK_COMMAND_TIMEOUT_DEFAULT = 60.0",
          "",
          "[Removed Lines]",
          "72: HADOOPUSER_KEY = '{{cluster-env/hadoop.user.name}}'",
          "73: HADOOPUSER_DEFAULT = 'hadoop'",
          "",
          "[Added Lines]",
          "72: HIVE_USER_KEY = '{{hive-env/hive_user}}'",
          "73: HIVE_USER_DEFAULT = 'hive'",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "87:           HIVE_SERVER2_AUTHENTICATION_KEY, HIVE_SERVER_PRINCIPAL_KEY,",
          "88:           SMOKEUSER_KEYTAB_KEY, SMOKEUSER_PRINCIPAL_KEY, HIVE_SERVER_THRIFT_HTTP_PORT_KEY,",
          "89:           HIVE_SERVER_TRANSPORT_MODE_KEY, KERBEROS_EXECUTABLE_SEARCH_PATHS_KEY, HIVE_SSL,",
          "101: @OsFamilyFuncImpl(os_family=OsFamilyImpl.DEFAULT)",
          "102: def execute(configurations={}, parameters={}, host_name=None):",
          "",
          "[Removed Lines]",
          "90:           HIVE_SSL_KEYSTORE_PATH, HIVE_SSL_KEYSTORE_PASSWORD, HIVE_LDAP_USERNAME, HIVE_LDAP_PASSWORD)",
          "92: @OsFamilyFuncImpl(os_family=OSConst.WINSRV_FAMILY)",
          "93: def get_tokens():",
          "94:   \"\"\"",
          "95:   Returns a tuple of tokens in the format {{site/property}} that will be used",
          "96:   to build the dictionary passed into execute",
          "97:   \"\"\"",
          "98:   return (HIVE_SERVER_THRIFT_PORT_KEY, HIVE_SERVER_THRIFT_HTTP_PORT_KEY,",
          "99:           HIVE_SERVER_TRANSPORT_MODE_KEY, HADOOPUSER_KEY)",
          "",
          "[Added Lines]",
          "90:           HIVE_SSL_KEYSTORE_PATH, HIVE_SSL_KEYSTORE_PASSWORD, HIVE_LDAP_USERNAME, HIVE_LDAP_PASSWORD,",
          "91:           HIVE_USER_KEY)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "169:   if SMOKEUSER_KEY in configurations:",
          "170:     smokeuser = configurations[SMOKEUSER_KEY]",
          "172:   ldap_username = \"\"",
          "173:   ldap_password = \"\"",
          "174:   if HIVE_LDAP_USERNAME in configurations:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "164:   hive_user = HIVE_USER_DEFAULT",
          "165:   if HIVE_USER_KEY in configurations:",
          "166:     hive_user = configurations[HIVE_USER_KEY]",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "207:     try:",
          "208:       hive_check.check_thrift_port_sasl(host_name, port, hive_server2_authentication, hive_server_principal,",
          "210:                                         ssl_keystore=hive_ssl_keystore_path, ssl_password=hive_ssl_keystore_password,",
          "211:                                         check_command_timeout=int(check_command_timeout),ldap_username=ldap_username,",
          "212:                                         ldap_password=ldap_password)",
          "",
          "[Removed Lines]",
          "209:                                         kinitcmd, smokeuser, transport_mode=transport_mode, ssl=hive_ssl,",
          "",
          "[Added Lines]",
          "205:                                         kinitcmd, smokeuser, hive_user = hive_user, transport_mode=transport_mode, ssl=hive_ssl,",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "222:     result_code = 'UNKNOWN'",
          "224:   return (result_code, [label])",
          "",
          "[Removed Lines]",
          "227: @OsFamilyFuncImpl(os_family=OSConst.WINSRV_FAMILY)",
          "228: def execute(configurations={}, parameters={}, host_name=None):",
          "229:   \"\"\"",
          "230:   Returns a tuple containing the result code and a pre-formatted result label",
          "232:   Keyword arguments:",
          "233:   configurations (dictionary): a mapping of configuration key to value",
          "234:   parameters (dictionary): a mapping of script parameter key to value",
          "235:   host_name (string): the name of this host where the alert is running",
          "236:   \"\"\"",
          "238:   from resource_management.libraries.functions import reload_windows_env",
          "239:   from resource_management.core.resources import Execute",
          "240:   reload_windows_env()",
          "241:   hive_home = os.environ['HIVE_HOME']",
          "243:   if configurations is None:",
          "244:     return ('UNKNOWN', ['There were no configurations supplied to the script.'])",
          "246:   transport_mode = HIVE_SERVER_TRANSPORT_MODE_DEFAULT",
          "247:   if HIVE_SERVER_TRANSPORT_MODE_KEY in configurations:",
          "248:     transport_mode = configurations[HIVE_SERVER_TRANSPORT_MODE_KEY]",
          "250:   port = THRIFT_PORT_DEFAULT",
          "251:   if transport_mode.lower() == 'binary' and HIVE_SERVER_THRIFT_PORT_KEY in configurations:",
          "252:     port = int(configurations[HIVE_SERVER_THRIFT_PORT_KEY])",
          "253:   elif transport_mode.lower() == 'http' and HIVE_SERVER_THRIFT_HTTP_PORT_KEY in configurations:",
          "254:     port = int(configurations[HIVE_SERVER_THRIFT_HTTP_PORT_KEY])",
          "256:   hiveuser = HADOOPUSER_DEFAULT",
          "257:   if HADOOPUSER_KEY in configurations:",
          "258:     hiveuser = configurations[HADOOPUSER_KEY]",
          "260:   result_code = None",
          "261:   try:",
          "262:     if host_name is None:",
          "263:       host_name = socket.getfqdn()",
          "265:     beeline_url = ['jdbc:hive2://{host_name}:{port}/', \"transportMode={transport_mode}\"]",
          "266:     # append url according to used transport",
          "267:     if transport_mode == \"http\":",
          "268:       beeline_url.append('httpPath=cliservice')",
          "269:     beeline_url_string = format(\";\".join(beeline_url))",
          "270:     beeline_cmd = os.path.join(hive_home, \"bin\", \"beeline.cmd\")",
          "271:     cmd = format(\"cmd /c {beeline_cmd} -u {beeline_url_string} -e '' 2>&1 | findstr Connected\")",
          "273:     start_time = time.time()",
          "274:     try:",
          "275:       Execute(cmd, user=hiveuser, timeout=30, timeout_kill_strategy=TerminateStrategy.KILL_PROCESS_TREE)",
          "276:       total_time = time.time() - start_time",
          "277:       result_code = 'OK'",
          "278:       label = OK_MESSAGE.format(total_time, port)",
          "279:     except:",
          "280:       result_code = 'CRITICAL'",
          "281:       label = CRITICAL_MESSAGE.format(host_name, port, traceback.format_exc())",
          "282:   except:",
          "283:     label = traceback.format_exc()",
          "284:     result_code = 'UNKNOWN'",
          "286:   return (result_code, [label])",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "ambari-server/src/test/python/stacks/2.0.6/HIVE/test_hive_service_check.py||ambari-server/src/test/python/stacks/2.0.6/HIVE/test_hive_service_check.py": [
          "File: ambari-server/src/test/python/stacks/2.0.6/HIVE/test_hive_service_check.py -> ambari-server/src/test/python/stacks/2.0.6/HIVE/test_hive_service_check.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "46:                         stack_version = self.STACK_VERSION,",
          "47:                         target = RMFTestCase.TARGET_COMMON_SERVICES",
          "48:     )",
          "50:                               path = ['/bin/', '/usr/bin/', '/usr/lib/hive/bin/', '/usr/sbin/'],",
          "51:                               user = 'ambari-qa',",
          "52:                               timeout = 30,",
          "",
          "[Removed Lines]",
          "49:     self.assertResourceCalled('Execute', \"! beeline -u 'jdbc:hive2://c6402.ambari.apache.org:10000/;transportMode=binary;auth=noSasl'  -e '' 2>&1| awk '{print}'|grep -i -e 'Connection refused' -e 'Invalid URL'\",",
          "",
          "[Added Lines]",
          "49:     self.assertResourceCalled('Execute', \"beeline -n hive -u 'jdbc:hive2://c6402.ambari.apache.org:10000/;transportMode=binary;auth=noSasl'  -e ';' 2>&1 | awk '{print}' | grep -i -e 'Connected to:' -e 'Transaction isolation:'\",",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "165:     self.assertResourceCalled('Execute', '/usr/bin/kinit -kt /etc/security/keytabs/smokeuser.headless.keytab ambari-qa@EXAMPLE.COM; ',",
          "166:                               user = 'ambari-qa',",
          "167:                               )",
          "169:                               path = ['/bin/', '/usr/bin/', '/usr/lib/hive/bin/', '/usr/sbin/'],",
          "170:                               user = 'ambari-qa',",
          "171:                               timeout = 30,",
          "",
          "[Removed Lines]",
          "168:     self.assertResourceCalled('Execute', \"! beeline -u 'jdbc:hive2://c6402.ambari.apache.org:10000/;transportMode=binary;principal=hive/_HOST@EXAMPLE.COM'  -e '' 2>&1| awk '{print}'|grep -i -e 'Connection refused' -e 'Invalid URL'\",",
          "",
          "[Added Lines]",
          "168:     self.assertResourceCalled('Execute', \"beeline -n hive -u 'jdbc:hive2://c6402.ambari.apache.org:10000/;transportMode=binary;principal=hive/_HOST@EXAMPLE.COM'  -e ';' 2>&1 | awk '{print}' | grep -i -e 'Connected to:' -e 'Transaction isolation:'\",",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "283:       stack_version = self.STACK_VERSION,",
          "284:       target = RMFTestCase.TARGET_COMMON_SERVICES)",
          "287:       path = ['/bin/', '/usr/bin/', '/usr/lib/hive/bin/', '/usr/sbin/'],",
          "288:       timeout = 30,",
          "289:       user = 'ambari-qa',",
          "",
          "[Removed Lines]",
          "286:     self.assertResourceCalled('Execute', \"! beeline -u 'jdbc:hive2://c6402.ambari.apache.org:10010/;transportMode=binary'  -e '' 2>&1| awk '{print}'|grep -i -e 'Connection refused' -e 'Invalid URL'\",",
          "",
          "[Added Lines]",
          "286:     self.assertResourceCalled('Execute', \"beeline -n hive -u 'jdbc:hive2://c6402.ambari.apache.org:10010/;transportMode=binary'  -e ';' 2>&1 | awk '{print}' | grep -i -e 'Connected to:' -e 'Transaction isolation:'\",",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "322:       target = RMFTestCase.TARGET_COMMON_SERVICES)",
          "324:     self.assertResourceCalled('Execute',",
          "326:       path = ['/bin/', '/usr/bin/', '/usr/lib/hive/bin/', '/usr/sbin/'],",
          "327:       timeout = 30,",
          "328:       user = 'ambari-qa',",
          "",
          "[Removed Lines]",
          "325:       \"! beeline -u 'jdbc:hive2://c6402.ambari.apache.org:10010/;transportMode=binary'  -e '' 2>&1| awk '{print}'|grep -i -e 'Connection refused' -e 'Invalid URL'\",",
          "",
          "[Added Lines]",
          "325:       \"beeline -n hive -u 'jdbc:hive2://c6402.ambari.apache.org:10010/;transportMode=binary'  -e ';' 2>&1 | awk '{print}' | grep -i -e 'Connected to:' -e 'Transaction isolation:'\",",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "330:     )",
          "332:     self.assertResourceCalled('Execute',",
          "334:       path = ['/bin/', '/usr/bin/', '/usr/lib/hive/bin/', '/usr/sbin/'],",
          "335:       timeout = 30,",
          "336:       user = 'ambari-qa',",
          "",
          "[Removed Lines]",
          "333:       \"! beeline -u 'jdbc:hive2://c6402.ambari.apache.org:10500/;transportMode=binary'  -e '' 2>&1| awk '{print}'|grep -i -e 'Connection refused' -e 'Invalid URL'\",",
          "",
          "[Added Lines]",
          "333:       \"beeline -n hive -u 'jdbc:hive2://c6402.ambari.apache.org:10500/;transportMode=binary'  -e ';' 2>&1 | awk '{print}' | grep -i -e 'Connected to:' -e 'Transaction isolation:'\",",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "340:     # LLAP call",
          "341:     self.assertResourceCalled('Execute',",
          "343:       path = ['/usr/sbin', '/usr/local/bin', '/bin', '/usr/bin', '/bin:/usr/hdp/2.3.0.0-1234/hadoop/bin:/usr/hdp/current/hive-server2-hive2/bin'],",
          "344:       tries = 1,",
          "345:       stderr = -1,",
          "",
          "[Removed Lines]",
          "342:       \"! beeline -u 'jdbc:hive2://c6402.ambari.apache.org:10500/;transportMode=binary' --hiveconf \\\"hiveLlapServiceCheck=\\\" -f /usr/hdp/current/hive-server2-hive2/scripts/llap/sql/serviceCheckScript.sql -e '' 2>&1| awk '{print}'|grep -i -e 'Invalid status\\|Invalid URL\\|command not found\\|Connection refused'\",",
          "",
          "[Added Lines]",
          "342:       '! beeline -u \\'jdbc:hive2://c6402.ambari.apache.org:10500/;transportMode=binary\\' --hiveconf \"hiveLlapServiceCheck=\" -f /usr/hdp/current/hive-server2-hive2/scripts/llap/sql/serviceCheckScript.sql -e \\'\\' 2>&1| awk \\'{print}\\'|grep -i -e \\'Invalid status\\\\|Invalid URL\\\\|command not found\\\\|Connection refused\\'',",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "3c69f2d14b259fccb17eca889a2f7762ec98b7c7",
      "candidate_info": {
        "commit_hash": "3c69f2d14b259fccb17eca889a2f7762ec98b7c7",
        "repo": "apache/ambari",
        "commit_url": "https://github.com/apache/ambari/commit/3c69f2d14b259fccb17eca889a2f7762ec98b7c7",
        "files": [
          "contrib/management-packs/isilon-onefs-mpack/src/main/resources/addon-services/ONEFS/1.0.0/service_advisor.py"
        ],
        "message": "AMBARI-24596. Stack Advisor reported an error. Exit Code: 2. Error: KeyError: 'onefs' (amagyar) (#2258) (#2263)",
        "before_after_code_files": [
          "contrib/management-packs/isilon-onefs-mpack/src/main/resources/addon-services/ONEFS/1.0.0/service_advisor.py||contrib/management-packs/isilon-onefs-mpack/src/main/resources/addon-services/ONEFS/1.0.0/service_advisor.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/ambari/pull/3633",
          "https://github.com/apache/ambari/pull/3631",
          "https://github.com/apache/ambari/pull/3637",
          "https://github.com/apache/ambari/pull/3632",
          "https://github.com/apache/ambari/pull/3634",
          "https://github.com/apache/ambari/pull/3635"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "contrib/management-packs/isilon-onefs-mpack/src/main/resources/addon-services/ONEFS/1.0.0/service_advisor.py||contrib/management-packs/isilon-onefs-mpack/src/main/resources/addon-services/ONEFS/1.0.0/service_advisor.py": [
          "File: contrib/management-packs/isilon-onefs-mpack/src/main/resources/addon-services/ONEFS/1.0.0/service_advisor.py -> contrib/management-packs/isilon-onefs-mpack/src/main/resources/addon-services/ONEFS/1.0.0/service_advisor.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "139:     def getServiceConfigurationsValidationItems(self, configs, recommendedDefaults, services, hosts):",
          "140:       validation_errors = []",
          "143:       return validation_errors",
          "",
          "[Removed Lines]",
          "141:       validation_errors.extend(self.toConfigurationValidationProblems(CoreSite(services).validate(), 'core-site'))",
          "142:       validation_errors.extend(self.toConfigurationValidationProblems(HdfsSite(services).validate(), 'hdfs-site'))",
          "",
          "[Added Lines]",
          "141:       try:",
          "142:         validation_errors.extend(self.toConfigurationValidationProblems(CoreSite(services).validate(), 'core-site'))",
          "143:         validation_errors.extend(self.toConfigurationValidationProblems(HdfsSite(services).validate(), 'hdfs-site'))",
          "144:       except KeyError as e:",
          "145:         self.logger.info('Cannot get OneFS properties from config. KeyError: %s' % e)",
          "",
          "---------------"
        ]
      }
    }
  ]
}