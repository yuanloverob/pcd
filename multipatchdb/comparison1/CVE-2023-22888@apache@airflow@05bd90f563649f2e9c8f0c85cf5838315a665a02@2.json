{
  "cve_id": "CVE-2023-22888",
  "cve_desc": "Apache Airflow, versions before 2.6.3, is affected by a vulnerability that allows an attacker to cause a service disruption by manipulating the run_id parameter. This vulnerability is considered low since it requires an authenticated user to exploit it. It is recommended to upgrade to a version that is not affected",
  "repo": "apache/airflow",
  "patch_hash": "05bd90f563649f2e9c8f0c85cf5838315a665a02",
  "patch_info": {
    "commit_hash": "05bd90f563649f2e9c8f0c85cf5838315a665a02",
    "repo": "apache/airflow",
    "commit_url": "https://github.com/apache/airflow/commit/05bd90f563649f2e9c8f0c85cf5838315a665a02",
    "files": [
      "airflow/config_templates/config.yml",
      "airflow/config_templates/default_airflow.cfg",
      "airflow/models/dag.py",
      "airflow/models/dagrun.py",
      "airflow/www/views.py",
      "tests/models/test_dagrun.py",
      "tests/www/views/test_views_trigger_dag.py"
    ],
    "message": "Sanitize `DagRun.run_id` and allow flexibility (#32293)\n\nThis commit sanitizes the DagRun.run_id parameter by introducing a configurable option.\nUsers now have the ability to select a specific run_id pattern for their runs,\nensuring stricter control over the values used. This update does not impact the default run_id\ngeneration performed by the scheduler for scheduled DAG runs or for Dag runs triggered without\nmodifying the run_id parameter in the run configuration page.\nThe configuration flexibility empowers users to align the run_id pattern with their specific requirements.",
    "before_after_code_files": [
      "airflow/config_templates/default_airflow.cfg||airflow/config_templates/default_airflow.cfg",
      "airflow/models/dag.py||airflow/models/dag.py",
      "airflow/models/dagrun.py||airflow/models/dagrun.py",
      "airflow/www/views.py||airflow/www/views.py",
      "tests/models/test_dagrun.py||tests/models/test_dagrun.py",
      "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py"
    ]
  },
  "patch_diff": {
    "airflow/config_templates/default_airflow.cfg||airflow/config_templates/default_airflow.cfg": [
      "File: airflow/config_templates/default_airflow.cfg -> airflow/config_templates/default_airflow.cfg",
      "--- Hunk 1 ---",
      "[Context before]",
      "1325: # longer than `[scheduler] task_queued_timeout`.",
      "1326: task_queued_timeout_check_interval = 120.0",
      "1328: [triggerer]",
      "1329: # How many triggers a single Triggerer will run at once, by default.",
      "1330: default_capacity = 1000",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "1328: # The run_id pattern used to verify the validity of user input to the run_id parameter when",
      "1329: # triggering a DAG. This pattern cannot change the pattern used by scheduler to generate run_id",
      "1330: # for scheduled DAG runs or DAG runs triggered without changing the run_id parameter.",
      "1331: allowed_run_id_pattern = ^[A-Za-z0-9_.~:+-]+$",
      "",
      "---------------"
    ],
    "airflow/models/dag.py||airflow/models/dag.py": [
      "File: airflow/models/dag.py -> airflow/models/dag.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "80: import airflow.templates",
      "81: from airflow import settings, utils",
      "82: from airflow.api_internal.internal_api_call import internal_api_call",
      "84: from airflow.exceptions import (",
      "85:     AirflowDagInconsistent,",
      "86:     AirflowException,",
      "",
      "[Removed Lines]",
      "83: from airflow.configuration import conf, secrets_backend_list",
      "",
      "[Added Lines]",
      "83: from airflow.configuration import conf as airflow_conf, secrets_backend_list",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "96: from airflow.models.baseoperator import BaseOperator",
      "97: from airflow.models.dagcode import DagCode",
      "98: from airflow.models.dagpickle import DagPickle",
      "100: from airflow.models.operator import Operator",
      "101: from airflow.models.param import DagParam, ParamsDict",
      "102: from airflow.models.taskinstance import Context, TaskInstance, TaskInstanceKey, clear_task_instances",
      "",
      "[Removed Lines]",
      "99: from airflow.models.dagrun import DagRun",
      "",
      "[Added Lines]",
      "99: from airflow.models.dagrun import RUN_ID_REGEX, DagRun",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "422:         user_defined_filters: dict | None = None,",
      "423:         default_args: dict | None = None,",
      "424:         concurrency: int | None = None,",
      "427:         dagrun_timeout: timedelta | None = None,",
      "428:         sla_miss_callback: None | SLAMissCallback | list[SLAMissCallback] = None,",
      "432:         on_success_callback: None | DagStateChangeCallback | list[DagStateChangeCallback] = None,",
      "433:         on_failure_callback: None | DagStateChangeCallback | list[DagStateChangeCallback] = None,",
      "434:         doc_md: str | None = None,",
      "",
      "[Removed Lines]",
      "425:         max_active_tasks: int = conf.getint(\"core\", \"max_active_tasks_per_dag\"),",
      "426:         max_active_runs: int = conf.getint(\"core\", \"max_active_runs_per_dag\"),",
      "429:         default_view: str = conf.get_mandatory_value(\"webserver\", \"dag_default_view\").lower(),",
      "430:         orientation: str = conf.get_mandatory_value(\"webserver\", \"dag_orientation\"),",
      "431:         catchup: bool = conf.getboolean(\"scheduler\", \"catchup_by_default\"),",
      "",
      "[Added Lines]",
      "425:         max_active_tasks: int = airflow_conf.getint(\"core\", \"max_active_tasks_per_dag\"),",
      "426:         max_active_runs: int = airflow_conf.getint(\"core\", \"max_active_runs_per_dag\"),",
      "429:         default_view: str = airflow_conf.get_mandatory_value(\"webserver\", \"dag_default_view\").lower(),",
      "430:         orientation: str = airflow_conf.get_mandatory_value(\"webserver\", \"dag_orientation\"),",
      "431:         catchup: bool = airflow_conf.getboolean(\"scheduler\", \"catchup_by_default\"),",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "2588:         mark_success=False,",
      "2589:         local=False,",
      "2590:         executor=None,",
      "2592:         ignore_task_deps=False,",
      "2593:         ignore_first_depends_on_past=True,",
      "2594:         pool=None,",
      "",
      "[Removed Lines]",
      "2591:         donot_pickle=conf.getboolean(\"core\", \"donot_pickle\"),",
      "",
      "[Added Lines]",
      "2591:         donot_pickle=airflow_conf.getboolean(\"core\", \"donot_pickle\"),",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "2826:                 \"Creating DagRun needs either `run_id` or both `run_type` and `execution_date`\"",
      "2827:             )",
      "2837:         # create a copy of params before validating",
      "2838:         copied_params = copy.deepcopy(self.params)",
      "",
      "[Removed Lines]",
      "2829:         if run_id and \"/\" in run_id:",
      "2830:             warnings.warn(",
      "2831:                 \"Using forward slash ('/') in a DAG run ID is deprecated. Note that this character \"",
      "2832:                 \"also makes the run impossible to retrieve via Airflow's REST API.\",",
      "2833:                 RemovedInAirflow3Warning,",
      "2834:                 stacklevel=3,",
      "2835:             )",
      "",
      "[Added Lines]",
      "2829:         regex = airflow_conf.get(\"scheduler\", \"allowed_run_id_pattern\")",
      "2831:         if run_id and not re.match(RUN_ID_REGEX, run_id):",
      "2832:             if not regex.strip() or not re.match(regex.strip(), run_id):",
      "2833:                 raise AirflowException(",
      "2834:                     f\"The provided run ID '{run_id}' is invalid. It does not match either \"",
      "2835:                     f\"the configured pattern: '{regex}' or the built-in pattern: '{RUN_ID_REGEX}'\"",
      "2836:                 )",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "3125:     def get_default_view(self):",
      "3126:         \"\"\"This is only there for backward compatible jinja2 templates.\"\"\"",
      "3127:         if self.default_view is None:",
      "3129:         else:",
      "3130:             return self.default_view",
      "",
      "[Removed Lines]",
      "3128:             return conf.get(\"webserver\", \"dag_default_view\").lower()",
      "",
      "[Added Lines]",
      "3129:             return airflow_conf.get(\"webserver\", \"dag_default_view\").lower()",
      "",
      "---------------",
      "--- Hunk 7 ---",
      "[Context before]",
      "3342:     root_dag_id = Column(StringID())",
      "3343:     # A DAG can be paused from the UI / DB",
      "3344:     # Set this default value of is_paused based on a configuration value!",
      "3346:     is_paused = Column(Boolean, default=is_paused_at_creation)",
      "3347:     # Whether the DAG is a subdag",
      "3348:     is_subdag = Column(Boolean, default=False)",
      "",
      "[Removed Lines]",
      "3345:     is_paused_at_creation = conf.getboolean(\"core\", \"dags_are_paused_at_creation\")",
      "",
      "[Added Lines]",
      "3346:     is_paused_at_creation = airflow_conf.getboolean(\"core\", \"dags_are_paused_at_creation\")",
      "",
      "---------------",
      "--- Hunk 8 ---",
      "[Context before]",
      "3416:         \"TaskOutletDatasetReference\",",
      "3417:         cascade=\"all, delete, delete-orphan\",",
      "3418:     )",
      "3421:     def __init__(self, concurrency=None, **kwargs):",
      "3422:         super().__init__(**kwargs)",
      "",
      "[Removed Lines]",
      "3419:     NUM_DAGS_PER_DAGRUN_QUERY = conf.getint(\"scheduler\", \"max_dagruns_to_create_per_loop\", fallback=10)",
      "",
      "[Added Lines]",
      "3420:     NUM_DAGS_PER_DAGRUN_QUERY = airflow_conf.getint(",
      "3421:         \"scheduler\", \"max_dagruns_to_create_per_loop\", fallback=10",
      "3422:     )",
      "",
      "---------------",
      "--- Hunk 9 ---",
      "[Context before]",
      "3429:                 )",
      "3430:                 self.max_active_tasks = concurrency",
      "3431:             else:",
      "3434:         if self.max_active_runs is None:",
      "3437:         if self.has_task_concurrency_limits is None:",
      "3438:             # Be safe -- this will be updated later once the DAG is parsed",
      "",
      "[Removed Lines]",
      "3432:                 self.max_active_tasks = conf.getint(\"core\", \"max_active_tasks_per_dag\")",
      "3435:             self.max_active_runs = conf.getint(\"core\", \"max_active_runs_per_dag\")",
      "",
      "[Added Lines]",
      "3435:                 self.max_active_tasks = airflow_conf.getint(\"core\", \"max_active_tasks_per_dag\")",
      "3438:             self.max_active_runs = airflow_conf.getint(\"core\", \"max_active_runs_per_dag\")",
      "",
      "---------------",
      "--- Hunk 10 ---",
      "[Context before]",
      "3510:         have a value.",
      "3511:         \"\"\"",
      "3512:         # This is for backwards-compatibility with old dags that don't have None as default_view",
      "3515:     @property",
      "3516:     def safe_dag_id(self):",
      "",
      "[Removed Lines]",
      "3513:         return self.default_view or conf.get_mandatory_value(\"webserver\", \"dag_default_view\").lower()",
      "",
      "[Added Lines]",
      "3516:         return self.default_view or airflow_conf.get_mandatory_value(\"webserver\", \"dag_default_view\").lower()",
      "",
      "---------------",
      "--- Hunk 11 ---",
      "[Context before]",
      "3699:     user_defined_filters: dict | None = None,",
      "3700:     default_args: dict | None = None,",
      "3701:     concurrency: int | None = None,",
      "3704:     dagrun_timeout: timedelta | None = None,",
      "3705:     sla_miss_callback: None | SLAMissCallback | list[SLAMissCallback] = None,",
      "3709:     on_success_callback: None | DagStateChangeCallback | list[DagStateChangeCallback] = None,",
      "3710:     on_failure_callback: None | DagStateChangeCallback | list[DagStateChangeCallback] = None,",
      "3711:     doc_md: str | None = None,",
      "",
      "[Removed Lines]",
      "3702:     max_active_tasks: int = conf.getint(\"core\", \"max_active_tasks_per_dag\"),",
      "3703:     max_active_runs: int = conf.getint(\"core\", \"max_active_runs_per_dag\"),",
      "3706:     default_view: str = conf.get_mandatory_value(\"webserver\", \"dag_default_view\").lower(),",
      "3707:     orientation: str = conf.get_mandatory_value(\"webserver\", \"dag_orientation\"),",
      "3708:     catchup: bool = conf.getboolean(\"scheduler\", \"catchup_by_default\"),",
      "",
      "[Added Lines]",
      "3705:     max_active_tasks: int = airflow_conf.getint(\"core\", \"max_active_tasks_per_dag\"),",
      "3706:     max_active_runs: int = airflow_conf.getint(\"core\", \"max_active_runs_per_dag\"),",
      "3709:     default_view: str = airflow_conf.get_mandatory_value(\"webserver\", \"dag_default_view\").lower(),",
      "3710:     orientation: str = airflow_conf.get_mandatory_value(\"webserver\", \"dag_orientation\"),",
      "3711:     catchup: bool = airflow_conf.getboolean(\"scheduler\", \"catchup_by_default\"),",
      "",
      "---------------"
    ],
    "airflow/models/dagrun.py||airflow/models/dagrun.py": [
      "File: airflow/models/dagrun.py -> airflow/models/dagrun.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "24: from datetime import datetime",
      "25: from typing import TYPE_CHECKING, Any, Callable, Iterable, Iterator, NamedTuple, Sequence, TypeVar, overload",
      "27: from sqlalchemy import (",
      "28:     Boolean,",
      "29:     Column,",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "27: import re2 as re",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "44: )",
      "45: from sqlalchemy.exc import IntegrityError",
      "46: from sqlalchemy.ext.associationproxy import association_proxy",
      "48: from sqlalchemy.sql.expression import false, select, true",
      "50: from airflow import settings",
      "",
      "[Removed Lines]",
      "47: from sqlalchemy.orm import Query, Session, declared_attr, joinedload, relationship, synonym",
      "",
      "[Added Lines]",
      "48: from sqlalchemy.orm import Query, Session, declared_attr, joinedload, relationship, synonym, validates",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "76:     CreatedTasks = TypeVar(\"CreatedTasks\", Iterator[\"dict[str, Any]\"], Iterator[TI])",
      "77:     TaskCreator = Callable[[Operator, Iterable[int]], CreatedTasks]",
      "80: class TISchedulingDecision(NamedTuple):",
      "81:     \"\"\"Type of return for DagRun.task_instance_scheduling_decisions.\"\"\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "80: RUN_ID_REGEX = r\"^(?:manual|scheduled|dataset_triggered)__(?:\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\+00:00)$\"",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "240:             external_trigger=self.external_trigger,",
      "241:         )",
      "243:     @property",
      "244:     def stats_tags(self) -> dict[str, str]:",
      "245:         return prune_dict({\"dag_id\": self.dag_id, \"run_type\": self.run_type})",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "246:     @validates(\"run_id\")",
      "247:     def validate_run_id(self, key: str, run_id: str) -> str | None:",
      "248:         if not run_id:",
      "249:             return None",
      "250:         regex = airflow_conf.get(\"scheduler\", \"allowed_run_id_pattern\")",
      "251:         if not re.match(regex, run_id) and not re.match(RUN_ID_REGEX, run_id):",
      "252:             raise ValueError(",
      "253:                 f\"The run_id provided '{run_id}' does not match the pattern '{regex}' or '{RUN_ID_REGEX}'\"",
      "254:             )",
      "255:         return run_id",
      "",
      "---------------"
    ],
    "airflow/www/views.py||airflow/www/views.py": [
      "File: airflow/www/views.py -> airflow/www/views.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "99: from airflow.models.abstractoperator import AbstractOperator",
      "100: from airflow.models.dag import DAG, get_dataset_triggered_next_run_info",
      "101: from airflow.models.dagcode import DagCode",
      "103: from airflow.models.dataset import DagScheduleDatasetReference, DatasetDagRunQueue, DatasetEvent, DatasetModel",
      "104: from airflow.models.mappedoperator import MappedOperator",
      "105: from airflow.models.operator import Operator",
      "",
      "[Removed Lines]",
      "102: from airflow.models.dagrun import DagRun, DagRunType",
      "",
      "[Added Lines]",
      "102: from airflow.models.dagrun import RUN_ID_REGEX, DagRun, DagRunType",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "1975:     @provide_session",
      "1976:     def trigger(self, dag_id: str, session: Session = NEW_SESSION):",
      "1977:         \"\"\"Triggers DAG Run.\"\"\"",
      "1979:         origin = get_safe_url(request.values.get(\"origin\"))",
      "1980:         unpause = request.values.get(\"unpause\")",
      "1981:         request_conf = request.values.get(\"conf\")",
      "",
      "[Removed Lines]",
      "1978:         run_id = request.values.get(\"run_id\", \"\")",
      "",
      "[Added Lines]",
      "1978:         run_id = request.values.get(\"run_id\", \"\").replace(\" \", \"+\")",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "2096:             flash(message, \"error\")",
      "2097:             return redirect(origin)",
      "2107:         run_conf = {}",
      "2108:         if request_conf:",
      "",
      "[Removed Lines]",
      "2099:         # Flash a warning when slash is used, but still allow it to continue on.",
      "2100:         if run_id and \"/\" in run_id:",
      "2101:             flash(",
      "2102:                 \"Using forward slash ('/') in a DAG run ID is deprecated. Note that this character \"",
      "2103:                 \"also makes the run impossible to retrieve via Airflow's REST API.\",",
      "2104:                 \"warning\",",
      "2105:             )",
      "",
      "[Added Lines]",
      "2099:         regex = conf.get(\"scheduler\", \"allowed_run_id_pattern\")",
      "2100:         if run_id and not re.match(RUN_ID_REGEX, run_id):",
      "2101:             if not regex.strip() or not re.match(regex.strip(), run_id):",
      "2102:                 flash(",
      "2103:                     f\"The provided run ID '{run_id}' is invalid. It does not match either \"",
      "2104:                     f\"the configured pattern: '{regex}' or the built-in pattern: '{RUN_ID_REGEX}'\",",
      "2105:                     \"error\",",
      "2106:                 )",
      "2108:                 form = DateTimeForm(data={\"execution_date\": execution_date})",
      "2109:                 return self.render_template(",
      "2110:                     \"airflow/trigger.html\",",
      "2111:                     form_fields=form_fields,",
      "2112:                     dag=dag,",
      "2113:                     dag_id=dag_id,",
      "2114:                     origin=origin,",
      "2115:                     conf=request_conf,",
      "2116:                     form=form,",
      "2117:                     is_dag_run_conf_overrides_params=is_dag_run_conf_overrides_params,",
      "2118:                     recent_confs=recent_confs,",
      "2119:                 )",
      "",
      "---------------"
    ],
    "tests/models/test_dagrun.py||tests/models/test_dagrun.py": [
      "File: tests/models/test_dagrun.py -> tests/models/test_dagrun.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "30: from airflow import settings",
      "31: from airflow.callbacks.callback_requests import DagCallbackRequest",
      "32: from airflow.decorators import setup, task, task_group, teardown",
      "33: from airflow.models import (",
      "34:     DAG,",
      "35:     DagBag,",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "33: from airflow.exceptions import AirflowException",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "54: from airflow.utils.types import DagRunType",
      "55: from tests.models import DEFAULT_DATE as _DEFAULT_DATE",
      "56: from tests.test_utils import db",
      "57: from tests.test_utils.mock_operators import MockOperator",
      "59: DEFAULT_DATE = pendulum.instance(_DEFAULT_DATE)",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "58: from tests.test_utils.config import conf_vars",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "2541:     tis = dr.task_instance_scheduling_decisions(session).tis",
      "2542:     tis_for_state = {x.task_id for x in dr._tis_for_dagrun_state(dag=dag, tis=tis)}",
      "2543:     assert tis_for_state == expected",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "2548: @pytest.mark.parametrize(",
      "2549:     \"pattern, run_id, result\",",
      "2550:     [",
      "2551:         [\"^[A-Z]\", \"ABC\", True],",
      "2552:         [\"^[A-Z]\", \"abc\", False],",
      "2553:         [\"^[0-9]\", \"123\", True],",
      "2554:         # The below params tests that user configuration does not affect internally generated",
      "2555:         # run_ids",
      "2556:         [\"\", \"scheduled__2023-01-01T00:00:00+00:00\", True],",
      "2557:         [\"\", \"manual__2023-01-01T00:00:00+00:00\", True],",
      "2558:         [\"\", \"dataset_triggered__2023-01-01T00:00:00+00:00\", True],",
      "2559:         [\"\", \"scheduled_2023-01-01T00\", False],",
      "2560:         [\"\", \"manual_2023-01-01T00\", False],",
      "2561:         [\"\", \"dataset_triggered_2023-01-01T00\", False],",
      "2562:         [\"^[0-9]\", \"scheduled__2023-01-01T00:00:00+00:00\", True],",
      "2563:         [\"^[0-9]\", \"manual__2023-01-01T00:00:00+00:00\", True],",
      "2564:         [\"^[a-z]\", \"dataset_triggered__2023-01-01T00:00:00+00:00\", True],",
      "2565:     ],",
      "2566: )",
      "2567: def test_dag_run_id_config(session, dag_maker, pattern, run_id, result):",
      "2568:     with conf_vars({(\"scheduler\", \"allowed_run_id_pattern\"): pattern}):",
      "2569:         with dag_maker():",
      "2570:             ...",
      "2571:         if result:",
      "2572:             dag_maker.create_dagrun(run_id=run_id)",
      "2573:         else:",
      "2574:             with pytest.raises(AirflowException):",
      "2575:                 dag_maker.create_dagrun(run_id=run_id)",
      "",
      "---------------"
    ],
    "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py": [
      "File: tests/www/views/test_views_trigger_dag.py -> tests/www/views/test_views_trigger_dag.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "30: from airflow.utils.session import create_session",
      "31: from airflow.utils.types import DagRunType",
      "32: from tests.test_utils.api_connexion_utils import create_test_client",
      "33: from tests.test_utils.www import check_content_in_response",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "33: from tests.test_utils.config import conf_vars",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "287:         f'<textarea style=\"display: none;\" id=\"json_start\" name=\"json_start\">{expected_dag_conf}</textarea>',",
      "288:         resp,",
      "289:     )",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "293: @pytest.mark.parametrize(",
      "294:     \"pattern, run_id, result\",",
      "295:     [",
      "296:         [\"^[A-Z]\", \"ABC\", True],",
      "297:         [\"^[A-Z]\", \"abc\", False],",
      "298:         [\"^[0-9]\", \"123\", True],",
      "299:         # The below params tests that user configuration does not affect internally generated",
      "300:         # run_ids. We use manual__ as a prefix for manually triggered DAGs due to a restriction",
      "301:         # in manually triggered DAGs that the run_id must not start with scheduled__.",
      "302:         [\"\", \"manual__2023-01-01T00:00:00+00:00\", True],",
      "303:         [\"\", \"scheduled_2023-01-01T00\", False],",
      "304:         [\"\", \"manual_2023-01-01T00\", False],",
      "305:         [\"\", \"dataset_triggered_2023-01-01T00\", False],",
      "306:         [\"^[0-9]\", \"manual__2023-01-01T00:00:00+00:00\", True],",
      "307:         [\"^[a-z]\", \"manual__2023-01-01T00:00:00+00:00\", True],",
      "308:     ],",
      "309: )",
      "310: def test_dag_run_id_pattern(session, admin_client, pattern, run_id, result):",
      "311:     with conf_vars({(\"scheduler\", \"allowed_run_id_pattern\"): pattern}):",
      "312:         test_dag_id = \"example_bash_operator\"",
      "313:         admin_client.post(f\"dags/{test_dag_id}/trigger?&run_id={run_id}\")",
      "314:         run = session.query(DagRun).filter(DagRun.dag_id == test_dag_id).first()",
      "315:         if result:",
      "316:             assert run is not None",
      "317:             assert run.run_type == DagRunType.MANUAL",
      "318:         else:",
      "319:             assert run is None",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "a2d6e6e2dabe382945f37cf197138e9cfc9393d8",
      "candidate_info": {
        "commit_hash": "a2d6e6e2dabe382945f37cf197138e9cfc9393d8",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/a2d6e6e2dabe382945f37cf197138e9cfc9393d8",
        "files": [
          "airflow/www/views.py",
          "tests/www/views/test_views_trigger_dag.py"
        ],
        "message": "Fix bug introduced by replacing spaces by + in run_id (#36877)\n\nWhile working on sanitizing the run_id(#32293), I replaced spaces with +\nwhich is not an ideal way to quote a URL. This led to issues when users\nuse spaces in their DAG run_id.\nThis commit fixes the issue by using urllib.parse.quote to properly quote\nthe URL.\n\n(cherry picked from commit ec8fab5d2a0c1c30aa4f45f6d1a54d2610a6594e)",
        "before_after_code_files": [
          "airflow/www/views.py||airflow/www/views.py",
          "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "airflow/www/views.py||airflow/www/views.py",
            "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py"
          ],
          "candidate": [
            "airflow/www/views.py||airflow/www/views.py",
            "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py"
          ]
        }
      },
      "candidate_diff": {
        "airflow/www/views.py||airflow/www/views.py": [
          "File: airflow/www/views.py -> airflow/www/views.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1944:     @provide_session",
          "1945:     def trigger(self, dag_id: str, session: Session = NEW_SESSION):",
          "1946:         \"\"\"Triggers DAG Run.\"\"\"",
          "1948:         origin = get_safe_url(request.values.get(\"origin\"))",
          "1949:         unpause = request.values.get(\"unpause\")",
          "1950:         request_conf = request.values.get(\"conf\")",
          "",
          "[Removed Lines]",
          "1947:         run_id = request.values.get(\"run_id\", \"\").replace(\" \", \"+\")",
          "",
          "[Added Lines]",
          "1947:         run_id = request.values.get(\"run_id\", \"\")",
          "",
          "---------------"
        ],
        "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py": [
          "File: tests/www/views/test_views_trigger_dag.py -> tests/www/views/test_views_trigger_dag.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: import datetime",
          "21: import json",
          "23: import pytest",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "22: from urllib.parse import quote",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "369: def test_dag_run_id_pattern(session, admin_client, pattern, run_id, result):",
          "370:     with conf_vars({(\"scheduler\", \"allowed_run_id_pattern\"): pattern}):",
          "371:         test_dag_id = \"example_bash_operator\"",
          "372:         admin_client.post(f\"dags/{test_dag_id}/trigger?run_id={run_id}\", data={\"conf\": \"{}\"})",
          "373:         run = session.query(DagRun).filter(DagRun.dag_id == test_dag_id).first()",
          "374:         if result:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "373:         run_id = quote(run_id)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "ec8fab5d2a0c1c30aa4f45f6d1a54d2610a6594e",
      "candidate_info": {
        "commit_hash": "ec8fab5d2a0c1c30aa4f45f6d1a54d2610a6594e",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/ec8fab5d2a0c1c30aa4f45f6d1a54d2610a6594e",
        "files": [
          "airflow/www/views.py",
          "tests/www/views/test_views_trigger_dag.py"
        ],
        "message": "Fix bug introduced by replacing spaces by + in run_id (#36877)\n\nWhile working on sanitizing the run_id(#32293), I replaced spaces with +\nwhich is not an ideal way to quote a URL. This led to issues when users\nuse spaces in their DAG run_id.\nThis commit fixes the issue by using urllib.parse.quote to properly quote\nthe URL.",
        "before_after_code_files": [
          "airflow/www/views.py||airflow/www/views.py",
          "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "airflow/www/views.py||airflow/www/views.py",
            "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py"
          ],
          "candidate": [
            "airflow/www/views.py||airflow/www/views.py",
            "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py"
          ]
        }
      },
      "candidate_diff": {
        "airflow/www/views.py||airflow/www/views.py": [
          "File: airflow/www/views.py -> airflow/www/views.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1944:     @provide_session",
          "1945:     def trigger(self, dag_id: str, session: Session = NEW_SESSION):",
          "1946:         \"\"\"Triggers DAG Run.\"\"\"",
          "1948:         origin = get_safe_url(request.values.get(\"origin\"))",
          "1949:         unpause = request.values.get(\"unpause\")",
          "1950:         request_conf = request.values.get(\"conf\")",
          "",
          "[Removed Lines]",
          "1947:         run_id = request.values.get(\"run_id\", \"\").replace(\" \", \"+\")",
          "",
          "[Added Lines]",
          "1947:         run_id = request.values.get(\"run_id\", \"\")",
          "",
          "---------------"
        ],
        "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py": [
          "File: tests/www/views/test_views_trigger_dag.py -> tests/www/views/test_views_trigger_dag.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: import datetime",
          "21: import json",
          "23: import pytest",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "22: from urllib.parse import quote",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "369: def test_dag_run_id_pattern(session, admin_client, pattern, run_id, result):",
          "370:     with conf_vars({(\"scheduler\", \"allowed_run_id_pattern\"): pattern}):",
          "371:         test_dag_id = \"example_bash_operator\"",
          "372:         admin_client.post(f\"dags/{test_dag_id}/trigger?run_id={run_id}\", data={\"conf\": \"{}\"})",
          "373:         run = session.query(DagRun).filter(DagRun.dag_id == test_dag_id).first()",
          "374:         if result:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "373:         run_id = quote(run_id)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "be63c36bf1667c8a420d34e70e5a5efd7ca42815",
      "candidate_info": {
        "commit_hash": "be63c36bf1667c8a420d34e70e5a5efd7ca42815",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/be63c36bf1667c8a420d34e70e5a5efd7ca42815",
        "files": [
          "airflow/example_dags/example_dag_decorator.py",
          "airflow/example_dags/example_sla_dag.py",
          "airflow/models/dag.py",
          "docs/spelling_wordlist.txt"
        ],
        "message": "Explicitly list @dag arguments (#25044)",
        "before_after_code_files": [
          "airflow/example_dags/example_dag_decorator.py||airflow/example_dags/example_dag_decorator.py",
          "airflow/example_dags/example_sla_dag.py||airflow/example_dags/example_sla_dag.py",
          "airflow/models/dag.py||airflow/models/dag.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "airflow/models/dag.py||airflow/models/dag.py"
          ],
          "candidate": [
            "airflow/models/dag.py||airflow/models/dag.py"
          ]
        }
      },
      "candidate_diff": {
        "airflow/example_dags/example_dag_decorator.py||airflow/example_dags/example_dag_decorator.py": [
          "File: airflow/example_dags/example_dag_decorator.py -> airflow/example_dags/example_dag_decorator.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "67:     )",
          "71: # [END dag_decorator_usage]",
          "",
          "[Removed Lines]",
          "70: dag = example_dag_decorator()",
          "",
          "[Added Lines]",
          "70: example_dag = example_dag_decorator()",
          "",
          "---------------"
        ],
        "airflow/example_dags/example_sla_dag.py||airflow/example_dags/example_sla_dag.py": [
          "File: airflow/example_dags/example_sla_dag.py -> airflow/example_dags/example_sla_dag.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "60:     sleep_20() >> sleep_30()",
          "65: # [END howto_task_sla]",
          "",
          "[Removed Lines]",
          "63: dag = example_sla_dag()",
          "",
          "[Added Lines]",
          "63: example_dag = example_sla_dag()",
          "",
          "---------------"
        ],
        "airflow/models/dag.py||airflow/models/dag.py": [
          "File: airflow/models/dag.py -> airflow/models/dag.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "112: # See also: https://discuss.python.org/t/9126/7",
          "113: ScheduleIntervalArg = Union[ArgNotSet, ScheduleInterval]",
          "116: # Backward compatibility: If neither schedule_interval nor timetable is",
          "117: # *provided by the user*, default to a one-day interval.",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "115: SLAMissCallback = Callable[[\"DAG\", str, str, List[\"SlaMiss\"], List[TaskInstance]], None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "309:     parent_dag: Optional[\"DAG\"] = None  # Gets set when DAGs are loaded",
          "311:     def __init__(",
          "312:         self,",
          "313:         dag_id: str,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "313:     # NOTE: When updating arguments here, please also keep arguments in @dag()",
          "314:     # below in sync. (Search for 'def dag(' in this file.)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "326:         max_active_tasks: int = conf.getint('core', 'max_active_tasks_per_dag'),",
          "327:         max_active_runs: int = conf.getint('core', 'max_active_runs_per_dag'),",
          "328:         dagrun_timeout: Optional[timedelta] = None,",
          "332:         default_view: str = conf.get_mandatory_value('webserver', 'dag_default_view').lower(),",
          "333:         orientation: str = conf.get_mandatory_value('webserver', 'dag_orientation'),",
          "334:         catchup: bool = conf.getboolean('scheduler', 'catchup_by_default'),",
          "",
          "[Removed Lines]",
          "329:         sla_miss_callback: Optional[",
          "330:             Callable[[\"DAG\", str, str, List[\"SlaMiss\"], List[TaskInstance]], None]",
          "331:         ] = None,",
          "",
          "[Added Lines]",
          "333:         sla_miss_callback: Optional[SLAMissCallback] = None,",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "3060:         )",
          "3064:     \"\"\"",
          "3065:     Python dag decorator. Wraps a function into an Airflow DAG.",
          "3066:     Accepts kwargs for operator kwarg. Can be used to parameterize DAGs.",
          "",
          "[Removed Lines]",
          "3063: def dag(*dag_args, **dag_kwargs):",
          "",
          "[Added Lines]",
          "3065: # NOTE: Please keep the list of arguments in sync with DAG.__init__.",
          "3066: # Only exception: dag_id here should have a default value, but not in DAG.",
          "3067: def dag(",
          "3068:     dag_id: str = \"\",",
          "3069:     description: Optional[str] = None,",
          "3070:     schedule_interval: ScheduleIntervalArg = NOTSET,",
          "3071:     timetable: Optional[Timetable] = None,",
          "3072:     start_date: Optional[datetime] = None,",
          "3073:     end_date: Optional[datetime] = None,",
          "3074:     full_filepath: Optional[str] = None,",
          "3075:     template_searchpath: Optional[Union[str, Iterable[str]]] = None,",
          "3076:     template_undefined: Type[jinja2.StrictUndefined] = jinja2.StrictUndefined,",
          "3077:     user_defined_macros: Optional[Dict] = None,",
          "3078:     user_defined_filters: Optional[Dict] = None,",
          "3079:     default_args: Optional[Dict] = None,",
          "3080:     concurrency: Optional[int] = None,",
          "3081:     max_active_tasks: int = conf.getint('core', 'max_active_tasks_per_dag'),",
          "3082:     max_active_runs: int = conf.getint('core', 'max_active_runs_per_dag'),",
          "3083:     dagrun_timeout: Optional[timedelta] = None,",
          "3084:     sla_miss_callback: Optional[SLAMissCallback] = None,",
          "3085:     default_view: str = conf.get_mandatory_value('webserver', 'dag_default_view').lower(),",
          "3086:     orientation: str = conf.get_mandatory_value('webserver', 'dag_orientation'),",
          "3087:     catchup: bool = conf.getboolean('scheduler', 'catchup_by_default'),",
          "3088:     on_success_callback: Optional[DagStateChangeCallback] = None,",
          "3089:     on_failure_callback: Optional[DagStateChangeCallback] = None,",
          "3090:     doc_md: Optional[str] = None,",
          "3091:     params: Optional[Dict] = None,",
          "3092:     access_control: Optional[Dict] = None,",
          "3093:     is_paused_upon_creation: Optional[bool] = None,",
          "3094:     jinja_environment_kwargs: Optional[Dict] = None,",
          "3095:     render_template_as_native_obj: bool = False,",
          "3096:     tags: Optional[List[str]] = None,",
          "3097:     schedule_on: Optional[Sequence[\"Dataset\"]] = None,",
          "3098: ) -> Callable[[Callable], Callable[..., DAG]]:",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "3069:     :param dag_kwargs: Kwargs for DAG object.",
          "3070:     \"\"\"",
          "3077:         @functools.wraps(f)",
          "3078:         def factory(*args, **kwargs):",
          "3079:             # Generate signature for decorated function and bind the arguments when called",
          "",
          "[Removed Lines]",
          "3072:     def wrapper(f: Callable):",
          "3073:         # Get dag initializer signature and bind it to validate that dag_args, and dag_kwargs are correct",
          "3074:         dag_sig = signature(DAG.__init__)",
          "3075:         dag_bound_args = dag_sig.bind_partial(*dag_args, **dag_kwargs)",
          "",
          "[Added Lines]",
          "3107:     def wrapper(f: Callable) -> Callable[..., DAG]:",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "3083:             # Apply defaults to capture default values if set.",
          "3084:             f_sig.apply_defaults()",
          "3090:             # Initialize DAG with bound arguments",
          "3092:                 # Set DAG documentation from function documentation.",
          "3093:                 if f.__doc__:",
          "3094:                     dag_obj.doc_md = f.__doc__",
          "",
          "[Removed Lines]",
          "3086:             # Set function name as dag_id if not set",
          "3087:             dag_id = dag_bound_args.arguments.get('dag_id', f.__name__)",
          "3088:             dag_bound_args.arguments['dag_id'] = dag_id",
          "3091:             with DAG(*dag_bound_args.args, **dag_bound_args.kwargs) as dag_obj:",
          "",
          "[Added Lines]",
          "3118:             with DAG(",
          "3119:                 dag_id or f.__name__,",
          "3120:                 description=description,",
          "3121:                 schedule_interval=schedule_interval,",
          "3122:                 timetable=timetable,",
          "3123:                 start_date=start_date,",
          "3124:                 end_date=end_date,",
          "3125:                 full_filepath=full_filepath,",
          "3126:                 template_searchpath=template_searchpath,",
          "3127:                 template_undefined=template_undefined,",
          "3128:                 user_defined_macros=user_defined_macros,",
          "3129:                 user_defined_filters=user_defined_filters,",
          "3130:                 default_args=default_args,",
          "3131:                 concurrency=concurrency,",
          "3132:                 max_active_tasks=max_active_tasks,",
          "3133:                 max_active_runs=max_active_runs,",
          "3134:                 dagrun_timeout=dagrun_timeout,",
          "3135:                 sla_miss_callback=sla_miss_callback,",
          "3136:                 default_view=default_view,",
          "3137:                 orientation=orientation,",
          "3138:                 catchup=catchup,",
          "3139:                 on_success_callback=on_success_callback,",
          "3140:                 on_failure_callback=on_failure_callback,",
          "3141:                 doc_md=doc_md,",
          "3142:                 params=params,",
          "3143:                 access_control=access_control,",
          "3144:                 is_paused_upon_creation=is_paused_upon_creation,",
          "3145:                 jinja_environment_kwargs=jinja_environment_kwargs,",
          "3146:                 render_template_as_native_obj=render_template_as_native_obj,",
          "3147:                 tags=tags,",
          "3148:                 schedule_on=schedule_on,",
          "3149:             ) as dag_obj:",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "f5d802791fa5f6b13b635f06a1ea2eccc22a9ba7",
      "candidate_info": {
        "commit_hash": "f5d802791fa5f6b13b635f06a1ea2eccc22a9ba7",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/f5d802791fa5f6b13b635f06a1ea2eccc22a9ba7",
        "files": [
          "airflow/www/templates/airflow/dag.html",
          "airflow/www/templates/airflow/dags.html",
          "airflow/www/views.py",
          "tests/www/views/test_views_trigger_dag.py"
        ],
        "message": "Change Trigger UI to use HTTP POST in web ui (#36026)\n\n* Change Trigger UI to use HTTP POST in web ui, GET always shows trigger form\n* Adjust tests to changed behavior of trigger handling, expects data submitted in POST",
        "before_after_code_files": [
          "airflow/www/templates/airflow/dag.html||airflow/www/templates/airflow/dag.html",
          "airflow/www/templates/airflow/dags.html||airflow/www/templates/airflow/dags.html",
          "airflow/www/views.py||airflow/www/views.py",
          "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "airflow/www/views.py||airflow/www/views.py",
            "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py"
          ],
          "candidate": [
            "airflow/www/views.py||airflow/www/views.py",
            "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py"
          ]
        }
      },
      "candidate_diff": {
        "airflow/www/templates/airflow/dag.html||airflow/www/templates/airflow/dag.html": [
          "File: airflow/www/templates/airflow/dag.html -> airflow/www/templates/airflow/dag.html",
          "--- Hunk 1 ---",
          "[Context before]",
          "254:           {% else %}",
          "255:             <a href=\"{{ url_for('Airflow.trigger', dag_id=dag.dag_id, origin=url_for(request.endpoint, dag_id=dag.dag_id, **request.args)) }}\"",
          "256:           {% endif %}",
          "258:               aria-label=\"Trigger DAG\"",
          "259:               class=\"btn btn-default btn-icon-only{{ ' disabled' if not dag.can_trigger }} trigger-dropdown-btn\">",
          "260:               <span class=\"material-icons\" aria-hidden=\"true\">play_arrow</span>",
          "",
          "[Removed Lines]",
          "257:               title=\"Trigger&nbsp;DAG\"",
          "",
          "[Added Lines]",
          "257:               onclick=\"return triggerDag(this, '{{ dag.dag_id }}')\" title=\"Trigger&nbsp;DAG\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "289:       }",
          "290:       return false;",
          "291:     }",
          "292:   </script>",
          "293: {% endblock %}",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "293:     function triggerDag(link, dagId) {",
          "294:       postAsForm(link.href, {});",
          "295:       return false;",
          "296:     }",
          "",
          "---------------"
        ],
        "airflow/www/templates/airflow/dags.html||airflow/www/templates/airflow/dags.html": [
          "File: airflow/www/templates/airflow/dags.html -> airflow/www/templates/airflow/dags.html",
          "--- Hunk 1 ---",
          "[Context before]",
          "385:                   </div>",
          "386:                 {% else %}",
          "387:                   <a href=\"{{ url_for('Airflow.trigger', dag_id=dag.dag_id, redirect_url=url_for(request.endpoint)) }}\"",
          "389:                     aria-label=\"Trigger DAG\"",
          "390:                     class=\"btn btn-sm btn-default btn-icon-only{{ ' disabled' if not dag.can_trigger }} trigger-dropdown-btn\">",
          "391:                     <span class=\"material-icons\" aria-hidden=\"true\">play_arrow</span>",
          "",
          "[Removed Lines]",
          "388:                     title=\"Trigger&nbsp;DAG\"",
          "",
          "[Added Lines]",
          "388:                   onclick=\"return triggerDag(this, '{{ dag.dag_id }}')\" title=\"Trigger&nbsp;DAG\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "483:       }",
          "484:       return false;",
          "485:     }",
          "486:   </script>",
          "487: {% endblock %}",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "487:     function triggerDag(link, dagId) {",
          "488:       postAsForm(link.href, {});",
          "489:       return false;",
          "490:     }",
          "",
          "---------------"
        ],
        "airflow/www/views.py||airflow/www/views.py": [
          "File: airflow/www/views.py -> airflow/www/views.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "2047:             if isinstance(run_conf, dict) and any(run_conf)",
          "2048:         }",
          "2051:             # Populate conf textarea with conf requests parameter, or dag.params",
          "2052:             default_conf = \"\"",
          "",
          "[Removed Lines]",
          "2050:         if request.method == \"GET\" and (ui_fields_defined or show_trigger_form_if_no_params):",
          "",
          "[Added Lines]",
          "2050:         if request.method == \"GET\" or (",
          "2051:             not request_conf and (ui_fields_defined or show_trigger_form_if_no_params)",
          "2052:         ):",
          "",
          "---------------"
        ],
        "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py": [
          "File: tests/www/views/test_views_trigger_dag.py -> tests/www/views/test_views_trigger_dag.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "57: )",
          "58: def test_trigger_dag_button(admin_client, req, expected_run_id):",
          "59:     test_dag_id = \"example_bash_operator\"",
          "61:     with create_session() as session:",
          "62:         run = session.query(DagRun).filter(DagRun.dag_id == test_dag_id).first()",
          "63:     assert run is not None",
          "",
          "[Removed Lines]",
          "60:     admin_client.post(f\"dags/{test_dag_id}/trigger?{req}\")",
          "",
          "[Added Lines]",
          "60:     admin_client.post(f\"dags/{test_dag_id}/trigger?{req}\", data={\"conf\": \"{}\"})",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "68: def test_duplicate_run_id(admin_client):",
          "69:     test_dag_id = \"example_bash_operator\"",
          "70:     run_id = \"test_run\"",
          "73:     check_content_in_response(f\"The run ID {run_id} already exists\", response)",
          "",
          "[Removed Lines]",
          "71:     admin_client.post(f\"dags/{test_dag_id}/trigger?run_id={run_id}\", follow_redirects=True)",
          "72:     response = admin_client.post(f\"dags/{test_dag_id}/trigger?run_id={run_id}\", follow_redirects=True)",
          "",
          "[Added Lines]",
          "71:     admin_client.post(",
          "72:         f\"dags/{test_dag_id}/trigger?run_id={run_id}\", data={\"conf\": \"{}\"}, follow_redirects=True",
          "73:     )",
          "74:     response = admin_client.post(",
          "75:         f\"dags/{test_dag_id}/trigger?run_id={run_id}\", data={\"conf\": \"{}\"}, follow_redirects=True",
          "76:     )",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "112: def test_trigger_dag_wrong_execution_date(admin_client):",
          "113:     test_dag_id = \"example_bash_operator\"",
          "116:     check_content_in_response(\"Invalid execution date\", response)",
          "118:     with create_session() as session:",
          "",
          "[Removed Lines]",
          "115:     response = admin_client.post(f\"dags/{test_dag_id}/trigger\", data={\"execution_date\": \"not_a_date\"})",
          "",
          "[Added Lines]",
          "119:     response = admin_client.post(",
          "120:         f\"dags/{test_dag_id}/trigger\", data={\"conf\": \"{}\", \"execution_date\": \"not_a_date\"}",
          "121:     )",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "124:     test_dag_id = \"example_bash_operator\"",
          "125:     exec_date = timezone.utcnow()",
          "129:     with create_session() as session:",
          "130:         run = session.query(DagRun).filter(DagRun.dag_id == test_dag_id).first()",
          "",
          "[Removed Lines]",
          "127:     admin_client.post(f\"dags/{test_dag_id}/trigger\", data={\"execution_date\": exec_date.isoformat()})",
          "",
          "[Added Lines]",
          "133:     admin_client.post(",
          "134:         f\"dags/{test_dag_id}/trigger\", data={\"conf\": \"{}\", \"execution_date\": exec_date.isoformat()}",
          "135:     )",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "361: def test_dag_run_id_pattern(session, admin_client, pattern, run_id, result):",
          "362:     with conf_vars({(\"scheduler\", \"allowed_run_id_pattern\"): pattern}):",
          "363:         test_dag_id = \"example_bash_operator\"",
          "365:         run = session.query(DagRun).filter(DagRun.dag_id == test_dag_id).first()",
          "366:         if result:",
          "367:             assert run is not None",
          "",
          "[Removed Lines]",
          "364:         admin_client.post(f\"dags/{test_dag_id}/trigger?&run_id={run_id}\")",
          "",
          "[Added Lines]",
          "372:         admin_client.post(f\"dags/{test_dag_id}/trigger?run_id={run_id}\", data={\"conf\": \"{}\"})",
          "",
          "---------------"
        ]
      }
    }
  ]
}