{
  "cve_id": "CVE-2023-25392",
  "cve_desc": "Allegro Tech BigFlow <1.6 is vulnerable to Missing SSL Certificate Validation.",
  "repo": "allegro/bigflow",
  "patch_hash": "7e956661f76907594e8c82e8fb0af76dbea2a0fc",
  "patch_info": {
    "commit_hash": "7e956661f76907594e8c82e8fb0af76dbea2a0fc",
    "repo": "allegro/bigflow",
    "commit_url": "https://github.com/allegro/bigflow/commit/7e956661f76907594e8c82e8fb0af76dbea2a0fc",
    "files": [
      "CHANGELOG.md",
      "bigflow/_version.py",
      "bigflow/build/operate.py",
      "bigflow/cli.py",
      "bigflow/deploy.py"
    ],
    "message": "Enabled TLS certificate verification in get_vault_token()",
    "before_after_code_files": [
      "bigflow/_version.py||bigflow/_version.py",
      "bigflow/build/operate.py||bigflow/build/operate.py",
      "bigflow/cli.py||bigflow/cli.py",
      "bigflow/deploy.py||bigflow/deploy.py"
    ]
  },
  "patch_diff": {
    "bigflow/_version.py||bigflow/_version.py": [
      "File: bigflow/_version.py -> bigflow/_version.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "[No context available]",
      "",
      "[Removed Lines]",
      "1: __version__ = '1.5.4'",
      "",
      "[Added Lines]",
      "1: __version__ = '1.6.0.dev1'",
      "",
      "---------------"
    ],
    "bigflow/build/operate.py||bigflow/build/operate.py": [
      "File: bigflow/build/operate.py -> bigflow/build/operate.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "95:             auth_method=cache_params.auth_method or bigflow.deploy.AuthorizationType.LOCAL_ACCOUNT,",
      "96:             vault_endpoint=cache_params.vault_endpoint,",
      "97:             vault_secret=cache_params.vault_secret,",
      "98:         )",
      "100:         for image in (cache_params.cache_from_image or []):",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "98:             vault_endpoint_verify=cache_params.vault_endpoint_verify",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "120:     vault_secret: str | None = None",
      "121:     cache_from_version: list[str] | None = None",
      "122:     cache_from_image: list[str] | None = None",
      "125: def build_image(",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "124:     vault_endpoint_verify: str | bool | None = None",
      "",
      "---------------"
    ],
    "bigflow/cli.py||bigflow/cli.py": [
      "File: bigflow/cli.py -> bigflow/cli.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "13: from importlib import import_module",
      "14: from pathlib import Path",
      "15: from types import ModuleType",
      "18: import fnmatch",
      "20: import bigflow as bf",
      "",
      "[Removed Lines]",
      "16: from typing import Tuple, Iterator",
      "17: from typing import Optional",
      "",
      "[Added Lines]",
      "16: from typing import Tuple, Iterator, Optional",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "386: def _add_auth_parsers_arguments(parser):",
      "387:     parser.add_argument('-a', '--auth-method',",
      "388:                         type=bigflow.deploy.AuthorizationType,",
      "389:                         default='local_account',",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "386:     class VaultEndpointVerifyAction(argparse.Action):",
      "387:         def __call__(self, parser, args, values, option_string=None):",
      "388:             if values in ['true', 'false']:",
      "389:                 setattr(args, self.dest, values == 'true')",
      "390:             else:",
      "391:                 setattr(args, self.dest, str(values))",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "399:                              'Required if auth-method is vault. '",
      "400:                              'If not set, will be read from deployment_config.py.'",
      "401:                         )",
      "402:     parser.add_argument('-vs', '--vault-secret',",
      "403:                         type=str,",
      "404:                         help='Vault secret token. '",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "408:     parser.add_argument('-vev', '--vault-endpoint-verify',",
      "409:                         type=str,",
      "410:                         action=VaultEndpointVerifyAction,",
      "411:                         help='Can be \"true\", \"false\", a path to certificate PEM file or a path to directory with PEM files. '",
      "412:                              'Enables/disables vault endpoint TLS certificate verification. Enabled by default. '",
      "413:                              'Disabling makes execution vulnerable for MITM attacks - do it only when justified and in trusted environments. '",
      "414:                              'For details see: https://requests.readthedocs.io/en/latest/user/advanced/#ssl-cert-verification',",
      "415:                         dest='vault_endpoint_verify',",
      "416:                         default=True",
      "417:                         )",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "514: def _resolve_property(args, property_name, ignore_value_error=False):",
      "515:     try:",
      "516:         cli_atr = getattr(args, property_name)",
      "518:             return cli_atr",
      "519:         else:",
      "520:             config = import_deployment_config(_resolve_deployment_config_path(args), property_name)",
      "",
      "[Removed Lines]",
      "517:         if cli_atr:",
      "",
      "[Added Lines]",
      "533:         if cli_atr or cli_atr is False:",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "533:                        clear_dags_folder=args.clear_dags_folder,",
      "534:                        auth_method=args.auth_method,",
      "535:                        vault_endpoint=_resolve_vault_endpoint(args),",
      "536:                        vault_secret=vault_secret,",
      "537:                        project_id=_resolve_property(args, 'gcp_project_id')",
      "538:                        )",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "552:                        vault_endpoint_verify=_resolve_property(args, 'vault_endpoint_verify', ignore_value_error=True),",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "543:     docker_repository = _resolve_property(args, 'docker_repository')",
      "544:     vault_secret = _resolve_property(args, 'vault_secret', ignore_value_error=True)",
      "545:     vault_endpoint = _resolve_vault_endpoint(args)",
      "546:     image_tar_path = args.image_tar_path if args.image_tar_path else find_image_file()",
      "548:     bigflow.deploy.deploy_docker_image(",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "563:     vault_endpoint_verify = _resolve_property(args, 'vault_endpoint_verify', ignore_value_error=True)",
      "",
      "---------------",
      "--- Hunk 7 ---",
      "[Context before]",
      "550:         auth_method=args.auth_method,",
      "551:         docker_repository=docker_repository,",
      "552:         vault_endpoint=vault_endpoint,",
      "553:         vault_secret=vault_secret,",
      "554:     )",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "571:         vault_endpoint_verify=vault_endpoint_verify,",
      "",
      "---------------",
      "--- Hunk 8 ---",
      "[Context before]",
      "579:         logger.debug(\"Image caching is requested - create build image cache params obj\")",
      "580:         vault_secret = _resolve_property(args, 'vault_secret', ignore_value_error=True)",
      "581:         vault_endpoint = _resolve_vault_endpoint(args)",
      "582:         return bigflow.build.operate.BuildImageCacheParams(",
      "583:             auth_method=args.auth_method,",
      "584:             vault_endpoint=vault_endpoint,",
      "585:             vault_secret=vault_secret,",
      "586:             cache_from_version=args.cache_from_version,",
      "587:             cache_from_image=args.cache_from_image,",
      "588:         )",
      "589:     else:",
      "590:         logger.debug(\"No caching is requested - so just disable it completly\")",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "601:         vault_endpoint_verify = _resolve_property(args, 'vault_endpoint_verify', ignore_value_error=True)",
      "608:             vault_endpoint_verify=vault_endpoint_verify",
      "",
      "---------------"
    ],
    "bigflow/deploy.py||bigflow/deploy.py": [
      "File: bigflow/deploy.py -> bigflow/deploy.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "42:     docker_repository: str,",
      "43:     auth_method: AuthorizationType = AuthorizationType.LOCAL_ACCOUNT,",
      "44:     vault_endpoint: T.Optional[str] = None,",
      "45:     vault_secret: T.Optional[str] = None,",
      "46: ) -> str:",
      "47:     if image_tar_path.endswith(\".toml\"):",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "45:     vault_endpoint_verify: str | bool | None = None,",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "53:         docker_repository,",
      "54:         auth_method,",
      "55:         vault_endpoint,",
      "56:         vault_secret,",
      "57:     )",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "57:         vault_endpoint_verify,",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "62:     docker_repository: str,",
      "63:     auth_method: AuthorizationType = AuthorizationType.LOCAL_ACCOUNT,",
      "64:     vault_endpoint: str | None = None,",
      "65:     vault_secret: str | None = None,",
      "66: ) -> str:",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "67:     vault_endpoint_verify: str | bool | None = None,",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "81:         docker_repository=docker_repository,",
      "82:         auth_method=auth_method,",
      "83:         vault_endpoint=vault_endpoint,",
      "84:         vault_secret=vault_secret,",
      "85:         image_id=image_id,",
      "86:         build_ver=build_ver,",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "87:         vault_endpoint_verify=vault_endpoint_verify,",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "92:     docker_repository: str,",
      "93:     auth_method: AuthorizationType = AuthorizationType.LOCAL_ACCOUNT,",
      "94:     vault_endpoint: str | None = None,",
      "95:     vault_secret: str | None = None,",
      "96: ) -> str:",
      "97:     build_ver = bf_commons.decode_version_number_from_file_name(Path(image_tar_path))",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "99:     vault_endpoint_verify: str | bool | None = None,",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "105:             image_id=image_id,",
      "106:             auth_method=auth_method,",
      "107:             vault_endpoint=vault_endpoint,",
      "108:             vault_secret=vault_secret,",
      "109:         )",
      "110:     finally:",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "113:             vault_endpoint_verify=vault_endpoint_verify,",
      "",
      "---------------",
      "--- Hunk 7 ---",
      "[Context before]",
      "118:     image_id: str,",
      "119:     auth_method: AuthorizationType,",
      "120:     vault_endpoint: str | None = None,",
      "121:     vault_secret: str | None = None,",
      "122: ) -> str:",
      "123:     docker_image = docker_repository + \":\" + build_ver",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "127:     vault_endpoint_verify: str | bool | None = None,",
      "",
      "---------------",
      "--- Hunk 8 ---",
      "[Context before]",
      "125:     tag_image(image_id, docker_repository, \"latest\")",
      "127:     logger.info(\"Deploying docker image tag=%s auth_method=%s\", docker_image, auth_method)",
      "129:     bf_commons.run_process(['docker', 'push', docker_image])",
      "130:     bf_commons.run_process(['docker', 'push', docker_image_latest])",
      "",
      "[Removed Lines]",
      "128:     authenticate_to_registry(auth_method, vault_endpoint, vault_secret)",
      "",
      "[Added Lines]",
      "135:     authenticate_to_registry(auth_method, vault_endpoint, vault_secret, vault_endpoint_verify)",
      "",
      "---------------",
      "--- Hunk 9 ---",
      "[Context before]",
      "136:         auth_method: AuthorizationType,",
      "137:         vault_endpoint: T.Optional[str] = None,",
      "138:         vault_secret: T.Optional[str] = None,",
      "139: ):",
      "140:     logger.info(\"Authenticating to registry with auth_method=%s\", auth_method)",
      "142:     if auth_method == AuthorizationType.LOCAL_ACCOUNT:",
      "143:         bf_commons.run_process(['gcloud', 'auth', 'configure-docker'])",
      "144:     elif auth_method == AuthorizationType.VAULT:",
      "146:         bf_commons.run_process(",
      "147:             ['docker', 'login', '-u', 'oauth2accesstoken', '--password-stdin', 'https://eu.gcr.io'],",
      "148:             input=oauthtoken,",
      "",
      "[Removed Lines]",
      "145:         oauthtoken = get_vault_token(vault_endpoint, vault_secret)",
      "",
      "[Added Lines]",
      "146:         vault_endpoint_verify: str | bool | None = None,",
      "153:         oauthtoken = get_vault_token(vault_endpoint, vault_secret, vault_endpoint_verify)",
      "",
      "---------------",
      "--- Hunk 10 ---",
      "[Context before]",
      "156:         auth_method: AuthorizationType,",
      "157:         vault_endpoint: T.Optional[str] = None,",
      "158:         vault_secret: T.Optional[str] = None,",
      "159: ):",
      "160:     logger.info(\"Checking if images used in DAGs exist in the registry\")",
      "162:     missing_images = set()",
      "163:     for image in images:",
      "164:         found_images = bf_commons.run_process(['docker', 'manifest', 'inspect', image], check=False, verbose=False)",
      "",
      "[Removed Lines]",
      "161:     authenticate_to_registry(auth_method, vault_endpoint, vault_secret)",
      "",
      "[Added Lines]",
      "167:         vault_endpoint_verify: str | bool | None = None",
      "170:     authenticate_to_registry(auth_method, vault_endpoint, vault_secret, vault_endpoint_verify)",
      "",
      "---------------",
      "--- Hunk 11 ---",
      "[Context before]",
      "189:         clear_dags_folder: bool = False,",
      "190:         auth_method: AuthorizationType = AuthorizationType.LOCAL_ACCOUNT,",
      "191:         vault_endpoint: T.Optional[str] = None,",
      "192:         vault_secret: T.Optional[str] = None,",
      "193:         gs_client: T.Optional[storage.Client] = None,",
      "194: ) -> str:",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "201:         vault_endpoint_verify: str | bool | None = None,",
      "",
      "---------------",
      "--- Hunk 12 ---",
      "[Context before]",
      "196:     if images:",
      "197:         check_images_exist(auth_method=auth_method,",
      "198:                            vault_endpoint=vault_endpoint,",
      "199:                            vault_secret=vault_secret,",
      "200:                            images=images)",
      "202:     logger.info(\"Deploying DAGs folder, auth_method=%s, clear_dags_folder=%s, dags_dir=%s\", auth_method, clear_dags_folder, dags_dir)",
      "205:     bucket = client.bucket(dags_bucket)",
      "207:     if clear_dags_folder:",
      "",
      "[Removed Lines]",
      "204:     client = gs_client or create_storage_client(auth_method, project_id, vault_endpoint, vault_secret)",
      "",
      "[Added Lines]",
      "209:                            vault_endpoint_verify=vault_endpoint_verify,",
      "215:     client = gs_client or create_storage_client(auth_method, project_id, vault_endpoint, vault_secret, vault_endpoint_verify)",
      "",
      "---------------",
      "--- Hunk 13 ---",
      "[Context before]",
      "246:         project_id: str,",
      "247:         vault_endpoint: str,",
      "248:         vault_secret: str,",
      "249: ) -> storage.Client:",
      "250:     if auth_method == AuthorizationType.LOCAL_ACCOUNT:",
      "251:         return storage.Client(project=project_id)",
      "252:     elif auth_method == AuthorizationType.VAULT:",
      "254:         return storage.Client(project=project_id, credentials=credentials.Credentials(oauthtoken))",
      "255:     else:",
      "256:         raise ValueError(f\"unsupported auth_method: {auth_method!r}\")",
      "260:     if not vault_endpoint:",
      "261:         raise ValueError('vault_endpoint is required')",
      "262:     if not vault_secret:",
      "263:         raise ValueError('vault_secret is required')",
      "265:     headers = {'X-Vault-Token': vault_secret}",
      "268:     if response.status_code != 200:",
      "269:         logger.info(response.text)",
      "",
      "[Removed Lines]",
      "253:         oauthtoken = get_vault_token(vault_endpoint, vault_secret)",
      "259: def get_vault_token(vault_endpoint: str, vault_secret: str) -> str:",
      "266:     response = requests.get(vault_endpoint, headers=headers, verify=False)",
      "",
      "[Added Lines]",
      "260:         vault_endpoint_verify: str | bool | None = None",
      "265:         oauthtoken = get_vault_token(vault_endpoint, vault_secret, vault_endpoint_verify)",
      "271: def get_vault_token(vault_endpoint: str, vault_secret: str, vault_endpoint_verify: str | bool | None = True) -> str:",
      "278:     response = requests.get(vault_endpoint, headers=headers, verify=vault_endpoint_verify)",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "ad9795fa4d9a805d933db1dbe360a9da337ec867",
      "candidate_info": {
        "commit_hash": "ad9795fa4d9a805d933db1dbe360a9da337ec867",
        "repo": "allegro/bigflow",
        "commit_url": "https://github.com/allegro/bigflow/commit/ad9795fa4d9a805d933db1dbe360a9da337ec867",
        "files": [
          "bigflow/_version.py"
        ],
        "message": "bumping to 1.5.0, tested on 2 production projects (#330)",
        "before_after_code_files": [
          "bigflow/_version.py||bigflow/_version.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "bigflow/_version.py||bigflow/_version.py"
          ],
          "candidate": [
            "bigflow/_version.py||bigflow/_version.py"
          ]
        }
      },
      "candidate_diff": {
        "bigflow/_version.py||bigflow/_version.py": [
          "File: bigflow/_version.py -> bigflow/_version.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "1: __version__ = '1.5.0dev2'",
          "",
          "[Added Lines]",
          "1: __version__ = '1.5.0'",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "2c8460a5c6c57e95ac681a76c7c67416a0280ced",
      "candidate_info": {
        "commit_hash": "2c8460a5c6c57e95ac681a76c7c67416a0280ced",
        "repo": "allegro/bigflow",
        "commit_url": "https://github.com/allegro/bigflow/commit/2c8460a5c6c57e95ac681a76c7c67416a0280ced",
        "files": [
          "bigflow/_version.py",
          "bigflow/build/dev.py",
          "bigflow/build/operate.py",
          "bigflow/build/spec.py",
          "bigflow/cli.py",
          "bigflow/commons.py",
          "bigflow/deploy.py",
          "bigflow/version.py",
          "test/buildd/test_dist.py",
          "test/buildd/test_operate.py",
          "test/buildd/test_spec.py",
          "test/cli/test_cli.py",
          "test/mixins.py",
          "test/test_deploy.py",
          "test/test_version.py"
        ],
        "message": "Add caching/exporting flags to 'bf build' and 'bf build-image' (#308)\n\n* Add flag to not export docker image into tar file\n\n* Add option 'export_image_tar' to project spec\n\n* Add '--cache-from-{version,image}' to 'build-image' command\n\n* Fix tests after adding new flags to 'build-image'\n\n* Fixup comments for #308\n\n* Add e2e test for building image as tag\n\n* Add unit tests for #308\n\n* Bump version to 1.4.2.dev2\n\n* Fixup tests - add mock\n\n* Remove from-imports from cli.py\n\n* Add option '--git-commit' to 'bf pv' command\n\n* Allow multipe --cache-from-{image,version}\n\n* Bump version to 1.4.2.dev3",
        "before_after_code_files": [
          "bigflow/_version.py||bigflow/_version.py",
          "bigflow/build/dev.py||bigflow/build/dev.py",
          "bigflow/build/operate.py||bigflow/build/operate.py",
          "bigflow/build/spec.py||bigflow/build/spec.py",
          "bigflow/cli.py||bigflow/cli.py",
          "bigflow/commons.py||bigflow/commons.py",
          "bigflow/deploy.py||bigflow/deploy.py",
          "bigflow/version.py||bigflow/version.py",
          "test/buildd/test_dist.py||test/buildd/test_dist.py",
          "test/buildd/test_operate.py||test/buildd/test_operate.py",
          "test/buildd/test_spec.py||test/buildd/test_spec.py",
          "test/cli/test_cli.py||test/cli/test_cli.py",
          "test/mixins.py||test/mixins.py",
          "test/test_deploy.py||test/test_deploy.py",
          "test/test_version.py||test/test_version.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "bigflow/_version.py||bigflow/_version.py",
            "bigflow/build/operate.py||bigflow/build/operate.py",
            "bigflow/cli.py||bigflow/cli.py",
            "bigflow/deploy.py||bigflow/deploy.py"
          ],
          "candidate": [
            "bigflow/_version.py||bigflow/_version.py",
            "bigflow/build/operate.py||bigflow/build/operate.py",
            "bigflow/cli.py||bigflow/cli.py",
            "bigflow/deploy.py||bigflow/deploy.py"
          ]
        }
      },
      "candidate_diff": {
        "bigflow/_version.py||bigflow/_version.py": [
          "File: bigflow/_version.py -> bigflow/_version.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "1: __version__ = '1.4.2.dev1'",
          "",
          "[Added Lines]",
          "1: __version__ = '1.4.2.dev3'",
          "",
          "---------------"
        ],
        "bigflow/build/dev.py||bigflow/build/dev.py": [
          "File: bigflow/build/dev.py -> bigflow/build/dev.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "46: def _read_setuppy_args(path_to_setup: Path) -> dict:",
          "47:     logger.info(\"Read project options from %s\", path_to_setup)",
          "48:     with tempfile.NamedTemporaryFile(\"r+b\") as f:",
          "50:         return pickle.load(f)",
          "",
          "[Removed Lines]",
          "49:         bf_commons.run_process([\"python\", path_to_setup, DUMP_PARAMS_SETUPPY_CMDARG, f.name], cwd=str(path_to_setup.parent))",
          "",
          "[Added Lines]",
          "49:         bf_commons.run_process(",
          "50:             [\"python\", path_to_setup, DUMP_PARAMS_SETUPPY_CMDARG, f.name],",
          "51:             cwd=str(path_to_setup.parent),",
          "52:             verbose=False,",
          "53:         )",
          "",
          "---------------"
        ],
        "bigflow/build/operate.py||bigflow/build/operate.py": [
          "File: bigflow/build/operate.py -> bigflow/build/operate.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1: \"\"\"Actual implementaion of buid/distribution operations\"\"\"",
          "3: import os",
          "4: import subprocess",
          "5: import shutil",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "3: from __future__ import annotations",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "8: import textwrap",
          "9: import sys",
          "11: from pathlib import Path",
          "13: import bigflow.resources",
          "14: import bigflow.dagbuilder",
          "15: import bigflow.version",
          "16: import bigflow.build.pip",
          "17: import bigflow.build.dev",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "13: from datetime import datetime",
          "15: from dataclasses import dataclass",
          "17: import toml",
          "21: import bigflow.deploy",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "72:     bf_commons.run_process([\"docker\", \"image\", \"save\", \"-o\", image_target_path, bf_commons.get_docker_image_id(tag)])",
          "76:     logger.debug(\"Run docker build...\")",
          "80: def build_image(",
          "81:     project_spec: BigflowProjectSpec,",
          "82: ):",
          "83:     logger.info(\"Building docker image...\")",
          "84:     clear_image_leftovers(project_spec)",
          "86:     image_dir = project_spec.project_dir / \".image\"",
          "87:     os.mkdir(image_dir)",
          "89:     tag = bf_commons.build_docker_image_tag(project_spec.docker_repository, project_spec.version)",
          "90:     logger.info(\"Generated image tag: %s\", tag)",
          "93:     try:",
          "94:         _export_docker_image_to_file(tag, image_dir, project_spec.version)",
          "97:     finally:",
          "99:         try:",
          "100:             bf_commons.remove_docker_image_from_local_registry(tag)",
          "101:         except Exception:",
          "102:             logger.exception(\"Couldn't remove the docker image. Tag: %s, image ID: %s\", tag, bf_commons.get_docker_image_id(tag))",
          "107: def create_image_version_file(dags_dir: str, image_version: str):",
          "108:     dags_path = bigflow.dagbuilder.get_dags_output_dir(dags_dir) / \"image_version.txt\"",
          "",
          "[Removed Lines]",
          "75: def _build_docker_image(project_dir: Path, tag: str):",
          "77:     bf_commons.run_process(f'docker build {project_dir} --tag {tag}')",
          "91:     _build_docker_image(project_spec.project_dir, tag)",
          "95:         dconf_file = Path(project_spec.deployment_config_file)",
          "96:         shutil.copyfile(dconf_file, image_dir / dconf_file.name)",
          "98:         logger.info(\"Trying to remove the docker image. Tag: %s, image ID: %s\", tag, bf_commons.get_docker_image_id(tag))",
          "104:     logger.info(\"Docker image was built\")",
          "",
          "[Added Lines]",
          "82: def _build_docker_image(",
          "83:     project_spec: BigflowProjectSpec,",
          "84:     tag: str,",
          "85:     cache_params: BuildImageCacheParams | None,",
          "86: ):",
          "89:     cmd = [\"docker\", \"build\", project_spec.project_dir, \"--tag\", tag]",
          "91:     if cache_params:",
          "93:         logger.debug(\"Authenticate to docker registry\")",
          "94:         bigflow.deploy.authenticate_to_registry(",
          "95:             auth_method=cache_params.auth_method or bigflow.deploy.AuthorizationType.LOCAL_ACCOUNT,",
          "96:             vault_endpoint=cache_params.vault_endpoint,",
          "97:             vault_secret=cache_params.vault_secret,",
          "98:         )",
          "100:         for image in (cache_params.cache_from_image or []):",
          "101:             logger.debug(\"Add --cache-from=%s to `docker build`\", image)",
          "102:             cmd.extend([\"--cache-from\", image])",
          "104:         for version in (cache_params.cache_from_version or []):",
          "105:             image = f\"{project_spec.docker_repository}:{version}\"",
          "106:             logger.debug(\"Add --cache-from=%s to `docker build`\", image)",
          "107:             cmd.extend([\"--cache-from\", image])",
          "109:     # noop when building backend is not a buildkit",
          "110:     logger.debug(\"Enable buildkit inline cache\")",
          "111:     cmd.extend([\"--build-arg\", \"BUILDKIT_INLINE_CACHE=1\"])",
          "113:     return bf_commons.run_process(cmd)",
          "116: @dataclass()",
          "117: class BuildImageCacheParams:",
          "118:     auth_method: bigflow.deploy.AuthorizationType",
          "119:     vault_endpoint: str | None = None",
          "120:     vault_secret: str | None = None",
          "121:     cache_from_version: list[str] | None = None",
          "122:     cache_from_image: list[str] | None = None",
          "127:     export_image_tar: bool | None = None,",
          "128:     cache_params: BuildImageCacheParams | None = None,",
          "130:     if export_image_tar is None:",
          "131:         export_image_tar = project_spec.export_image_tar",
          "139:     dconf_file = Path(project_spec.deployment_config_file)",
          "140:     shutil.copyfile(dconf_file, image_dir / dconf_file.name)",
          "144:     _build_docker_image(project_spec, tag, cache_params)",
          "146:     if export_image_tar:",
          "147:         _export_image_as_tar(project_spec, image_dir, tag)",
          "148:     else:",
          "149:         _export_image_as_tag(project_spec, image_dir, tag)",
          "150:     logger.info(\"Docker image was built\")",
          "153: def _export_image_as_tag(project_spec, image_dir, tag):",
          "154:     infofile = Path(image_dir) / f\"imageinfo-{project_spec.version}.toml\"",
          "155:     image_id = bf_commons.get_docker_image_id(tag)",
          "156:     info = toml.dumps({",
          "157:             'created': datetime.now(),",
          "158:             'project_version': project_spec.version,",
          "159:             'project_name': project_spec.name,",
          "160:             'docker_image_id': image_id,",
          "161:             'docker_image_tag': tag,",
          "162:         })",
          "163:     logger.debug(\"Create 'image-info' marker %s\", infofile)",
          "164:     infofile.write_text(",
          "165:         textwrap.dedent(f\"\"\"",
          "166:             # This file is a marker indicating that docker image",
          "167:             # was built by bigflow but wasn't exported to a tar.",
          "168:             # Instead it kept inside local docker repo",
          "169:             # and tagged with `{tag}`.",
          "170:         \"\"\") + info",
          "171:     )",
          "174: def _export_image_as_tar(project_spec, image_dir, tag):",
          "178:         logger.info(",
          "179:                 \"Trying to remove the docker image. Tag: %s, image ID: %s\",",
          "180:                 tag,",
          "181:                 bf_commons.get_docker_image_id(tag),",
          "182:             )",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "199: def build_project(",
          "200:     project_spec: BigflowProjectSpec,",
          "201:     start_time: str,",
          "203: ):",
          "204:     logger.info(\"Build the project\")",
          "205:     build_dags(project_spec, start_time, workflow_id=workflow_id)",
          "206:     build_package(project_spec)",
          "208:     logger.info(\"Project was built\")",
          "",
          "[Removed Lines]",
          "202:     workflow_id: typing.Optional[str] = None,",
          "207:     build_image(project_spec)",
          "",
          "[Added Lines]",
          "284:     workflow_id: str | None = None,",
          "285:     export_image_tar: bool | None = None,",
          "286:     cache_params: BuildImageCacheParams | None = None,",
          "291:     build_image(",
          "292:         project_spec,",
          "293:         export_image_tar=export_image_tar,",
          "294:         cache_params=cache_params,",
          "295:     )",
          "",
          "---------------"
        ],
        "bigflow/build/spec.py||bigflow/build/spec.py": [
          "File: bigflow/build/spec.py -> bigflow/build/spec.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "69:     setuptools: typing.Dict[str, typing.Any]",
          "71:     test_framework: Literal['pytest', 'unittest']",
          "74: def parse_project_spec(",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "72:     export_image_tar: bool",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "84:     project_requirements_file=\"resources/requirements.txt\",",
          "85:     resources_dir=\"resources\",",
          "86:     test_framework='unittest',",
          "89: ) -> BigflowProjectSpec:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "88:     export_image_tar=True,",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "128:         metainfo=metainfo,",
          "129:         setuptools=kwargs,",
          "130:         test_framework=test_framework,",
          "131:     )",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "133:         export_image_tar=export_image_tar,",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "144:         # 'data_files': prj.data_files,  # https://github.com/uiri/toml/issues/270",
          "145:         'resources_dir': prj.resources_dir,",
          "146:         'test_framework': prj.test_framework,",
          "149:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "150:         'export_image_tar': prj.export_image_tar,",
          "",
          "---------------"
        ],
        "bigflow/cli.py||bigflow/cli.py": [
          "File: bigflow/cli.py -> bigflow/cli.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "15: from types import ModuleType",
          "16: from typing import Tuple, Iterator",
          "17: from typing import Optional",
          "20: import bigflow as bf",
          "21: import bigflow.build.pip",
          "",
          "[Removed Lines]",
          "18: from glob import glob1",
          "",
          "[Added Lines]",
          "18: import fnmatch",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "26: import bigflow.build.operate",
          "27: import bigflow.build.spec",
          "28: import bigflow.migrate",
          "30: from bigflow import Config",
          "36: logger = logging.getLogger(__name__)",
          "",
          "[Removed Lines]",
          "31: from bigflow.deploy import deploy_dags_folder, deploy_docker_image, AuthorizationType",
          "32: from bigflow.scaffold import start_project",
          "33: from bigflow.version import get_version, release",
          "",
          "[Added Lines]",
          "29: import bigflow.deploy",
          "30: import bigflow.scaffold",
          "31: import bigflow.version",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "297: def _create_build_parser(subparsers):",
          "298:     parser = subparsers.add_parser('build', description='Builds a Docker image, DAG files and .whl package from local sources.')",
          "299:     _add_build_dags_parser_arguments(parser)",
          "302: def _create_build_package_parser(subparsers):",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "300:     _add_build_image_parser_arguments(parser)",
          "301:     _add_parsers_common_arguments(parser)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "318:                         type=bf_commons.valid_datetime)",
          "321: def _create_build_dags_parser(subparsers):",
          "322:     parser = subparsers.add_parser('build-dags',",
          "323:                                    description='Builds DAG files from local sources to {current_dir}/.dags')",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "323: def _add_build_image_parser_arguments(parser: argparse.ArgumentParser):",
          "324:     parser.add_argument(",
          "325:         '--export-image-tar', dest='export_image_tar', action='store_true',",
          "326:         help=\"Export built docker image into .tar file\",",
          "327:     )",
          "328:     parser.add_argument(",
          "329:         '--no-export-image-tar', dest='export_image_tar', action='store_false',",
          "330:         help=\"Don't export built docker image into .tar file (keep image in local docker registry)\",",
          "331:     )",
          "332:     parser.set_defaults(export_image_tar=None)",
          "334:     parser.add_argument(",
          "335:         '--cache-from-image',",
          "336:         dest='cache_from_image',",
          "337:         action='append',",
          "338:         help=\"Docker images to consider as cache sources\",",
          "339:     )",
          "340:     parser.add_argument(",
          "341:         '--cache-from-version',",
          "342:         dest='cache_from_version',",
          "343:         action='append',",
          "344:         help=\"Use previous version of the project as cache source\",",
          "345:     )",
          "346:     _add_auth_parsers_arguments(parser)",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "327: def _create_build_image_parser(subparsers):",
          "332: def _create_run_parser(subparsers, project_name):",
          "",
          "[Removed Lines]",
          "328:     subparsers.add_parser('build-image',",
          "329:                           description='Builds a docker image from local files.')",
          "",
          "[Added Lines]",
          "356:     parser = subparsers.add_parser(",
          "357:         'build-image',",
          "358:         description='Builds a docker image from local files.',",
          "359:     )",
          "360:     _add_build_image_parser_arguments(parser)",
          "361:     _add_parsers_common_arguments(parser)",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "365:                              ' individual workflows as well as to deployment_config.py.')",
          "369:     parser.add_argument('-a', '--auth-method',",
          "371:                         default='local_account',",
          "372:                         help='One of two authentication method: '",
          "373:                              'local_account -- you are using credentials of your local user authenticated in gcloud; '",
          "374:                              'vault -- credentials for service account are obtained from Vault. '",
          "375:                              'Default: local_account',",
          "377:     )",
          "378:     parser.add_argument('-ve', '--vault-endpoint',",
          "379:                         type=str,",
          "",
          "[Removed Lines]",
          "368: def _add_deploy_parsers_common_arguments(parser):",
          "370:                         type=AuthorizationType,",
          "376:                         choices=list(AuthorizationType),",
          "",
          "[Added Lines]",
          "400: def _add_auth_parsers_arguments(parser):",
          "402:                         type=bigflow.deploy.AuthorizationType,",
          "408:                         choices=list(bigflow.deploy.AuthorizationType),",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "391:                         help='Path to the deployment_config.py file. '",
          "392:                              'If not set, {current_dir}/deployment_config.py will be used.')",
          "394:     _add_parsers_common_arguments(parser)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "427: def _add_deploy_parsers_common_arguments(parser):",
          "428:     _add_auth_parsers_arguments(parser)",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "424: def _create_project_version_parser(subparsers):",
          "428: def _create_release_parser(subparsers):",
          "",
          "[Removed Lines]",
          "425:     subparsers.add_parser('project-version', aliases=['pv'], description='Prints project version')",
          "",
          "[Added Lines]",
          "460:     parser = subparsers.add_parser('project-version', aliases=['pv'], description='Prints project version')",
          "461:     parser.add_argument(",
          "462:         '--git-commit',",
          "463:         type=str,",
          "464:         help=\"Return project version of specifid git commit\",",
          "465:     )",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "481: def _resolve_vault_endpoint(args):",
          "483:         return _resolve_property(args, 'vault_endpoint')",
          "484:     else:",
          "485:         return None",
          "497: def _cli_deploy_dags(args):",
          "503:                        dags_bucket=_resolve_property(args, 'dags_bucket'),",
          "504:                        clear_dags_folder=args.clear_dags_folder,",
          "505:                        auth_method=args.auth_method,",
          "",
          "[Removed Lines]",
          "482:     if args.auth_method == AuthorizationType.VAULT:",
          "488: def _resolve_property(args, property_name):",
          "489:     cli_atr = getattr(args, property_name)",
          "490:     if cli_atr:",
          "491:         return cli_atr",
          "492:     else:",
          "493:         config = import_deployment_config(_resolve_deployment_config_path(args), property_name)",
          "494:         return config.resolve_property(property_name, args.config)",
          "498:     try:",
          "499:         vault_secret = _resolve_property(args, 'vault_secret')",
          "500:     except ValueError:",
          "501:         vault_secret = None",
          "502:     deploy_dags_folder(dags_dir=_resolve_dags_dir(args),",
          "",
          "[Added Lines]",
          "522:     if args.auth_method == bigflow.deploy.AuthorizationType.VAULT:",
          "528: def _resolve_property(args, property_name, ignore_value_error=False):",
          "529:     try:",
          "530:         cli_atr = getattr(args, property_name)",
          "531:         if cli_atr:",
          "532:             return cli_atr",
          "533:         else:",
          "534:             config = import_deployment_config(_resolve_deployment_config_path(args), property_name)",
          "535:             return config.resolve_property(property_name, args.config)",
          "536:     except ValueError:",
          "537:         if ignore_value_error:",
          "538:             return None",
          "539:         else:",
          "540:             raise",
          "544:     vault_secret = _resolve_property(args, 'vault_secret', ignore_value_error=True)",
          "545:     bigflow.deploy.deploy_dags_folder(dags_dir=_resolve_dags_dir(args),",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "509:                        )",
          "516: def _cli_deploy_image(args):",
          "531: def find_image_file():",
          "536:     else:",
          "540: def _cli_build_image(args):",
          "541:     prj = bigflow.build.spec.get_project_spec()",
          "545: def _cli_build_package():",
          "",
          "[Removed Lines]",
          "512: def _load_image_from_tar(image_tar_path: str):",
          "513:     print(f'Loading Docker image from {image_tar_path} ...', )",
          "517:     docker_repository = _resolve_property(args, 'docker_repository')",
          "518:     try:",
          "519:         vault_secret = _resolve_property(args, 'vault_secret')",
          "520:     except ValueError:",
          "521:         vault_secret = None",
          "522:     image_tar_path = args.image_tar_path if args.image_tar_path  else find_image_file()",
          "524:     deploy_docker_image(image_tar_path=image_tar_path,",
          "525:                         auth_method=args.auth_method,",
          "526:                         docker_repository=docker_repository,",
          "527:                         vault_endpoint=_resolve_vault_endpoint(args),",
          "528:                         vault_secret=vault_secret)",
          "532:     # TODO parametrize \".image\" using settings from build.py",
          "533:     files = glob1(\".image\", \"*-*.tar\")",
          "534:     if files:",
          "535:         return os.path.join(\".image\", files[0])",
          "537:         raise ValueError('File containing image to deploy not found')",
          "542:     bigflow.build.operate.build_image(prj)",
          "",
          "[Added Lines]",
          "557:     docker_repository = _resolve_property(args, 'docker_repository')",
          "558:     vault_secret = _resolve_property(args, 'vault_secret', ignore_value_error=True)",
          "559:     vault_endpoint = _resolve_vault_endpoint(args)",
          "560:     image_tar_path = args.image_tar_path if args.image_tar_path else find_image_file()",
          "562:     bigflow.deploy.deploy_docker_image(",
          "563:         image_tar_path=image_tar_path,",
          "564:         auth_method=args.auth_method,",
          "565:         docker_repository=docker_repository,",
          "566:         vault_endpoint=vault_endpoint,",
          "567:         vault_secret=vault_secret,",
          "568:     )",
          "573:     logger.debug(\"Scan folder .image\")",
          "574:     if not os.path.isdir(\".image\"):",
          "575:         raise ValueError(\"Directory .image does not exist\")",
          "577:     for f in os.listdir(\".image\"):",
          "578:         logger.debug(\"Found file %s\", f)",
          "580:         if fnmatch.fnmatch(f, \"*-*.tar\"):",
          "581:             logger.info(\"Found image located at .image/%s\", f)",
          "582:             return f\".image/{f}\"",
          "584:         if fnmatch.fnmatch(f, \"imageinfo-*.toml\"):",
          "585:             logger.info(\"Found image info file located at .image/%s\", f)",
          "586:             return f\".image/{f}\"",
          "588:     raise ValueError('File containing image to deploy not found')",
          "591: def _grab_image_cache_params(args):",
          "592:     if args.cache_from_image or args.cache_from_version:",
          "593:         logger.debug(\"Image caching is requested - create build image cache params obj\")",
          "594:         vault_secret = _resolve_property(args, 'vault_secret', ignore_value_error=True)",
          "595:         vault_endpoint = _resolve_vault_endpoint(args)",
          "596:         return bigflow.build.operate.BuildImageCacheParams(",
          "597:             auth_method=args.auth_method,",
          "598:             vault_endpoint=vault_endpoint,",
          "599:             vault_secret=vault_secret,",
          "600:             cache_from_version=args.cache_from_version,",
          "601:             cache_from_image=args.cache_from_image,",
          "602:         )",
          "604:         logger.debug(\"No caching is requested - so just disable it completly\")",
          "605:         return None",
          "610:     bigflow.build.operate.build_image(",
          "611:         prj,",
          "612:         export_image_tar=args.export_image_tar,",
          "613:         cache_params=_grab_image_cache_params(args),",
          "614:     )",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "562:         prj,",
          "563:         start_time=args.start_time if _is_starttime_selected(args) else datetime.now().strftime(\"%Y-%m-%d %H:00:00\"),",
          "564:         workflow_id=args.workflow if _is_workflow_selected(args) else None,",
          "565:     )",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "637:         export_image_tar=args.export_image_tar,",
          "638:         cache_params=_grab_image_cache_params(args),",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "687:         config['pyspark_job'] = True",
          "690:     print('Bigflow project created successfully.')",
          "693: def _cli_project_version(args):",
          "697: def _cli_release(args):",
          "701: class _ConsoleStreamLogHandler(logging.Handler):",
          "",
          "[Removed Lines]",
          "689:     start_project(**config)",
          "694:     print(get_version())",
          "698:     release(args.ssh_identity_file)",
          "",
          "[Added Lines]",
          "763:     bigflow.scaffold.start_project(**config)",
          "768:     commit_ish = args.git_commit or \"HEAD\"",
          "769:     print(bigflow.version.get_version(commit_ish))",
          "773:     bigflow.version.release(args.ssh_identity_file)",
          "",
          "---------------"
        ],
        "bigflow/commons.py||bigflow/commons.py": [
          "File: bigflow/commons.py -> bigflow/commons.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "293: def get_docker_image_id(tag):",
          "294:     logger.info(\"Getting docker image ID.\")",
          "296:     logger.info(images[:1000] + '...')",
          "300: def build_docker_image_tag(docker_repository: str, package_version: str):",
          "",
          "[Removed Lines]",
          "295:     images = run_process(f\"docker images -q {tag}\")",
          "297:     return images.split('\\n')[0]",
          "",
          "[Added Lines]",
          "295:     images = run_process([\"docker\", \"images\", \"-q\", \"--no-trunc\", tag])",
          "297:     return images.split(\"\\n\")[0]",
          "",
          "---------------"
        ],
        "bigflow/deploy.py||bigflow/deploy.py": [
          "File: bigflow/deploy.py -> bigflow/deploy.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "7: from pathlib import Path",
          "9: import requests",
          "10: from google.cloud.storage import Bucket",
          "11: from google.oauth2 import credentials",
          "12: from google.cloud import storage",
          "14: import bigflow.commons as bf_commons",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "10: import toml",
          "15: from bigflow.build.spec import get_project_spec",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "37: def deploy_docker_image(",
          "43: ) -> str:",
          "44:     build_ver = bf_commons.decode_version_number_from_file_name(Path(image_tar_path))",
          "45:     build_ver = build_ver.replace(\"+\", \"-\")  # fix local version separator",
          "46:     image_id = load_image_from_tar(image_tar_path)",
          "47:     try:",
          "50:     finally:",
          "51:         image_tag = bf_commons.build_docker_image_tag(docker_repository, build_ver)",
          "52:         bf_commons.remove_docker_image_from_local_registry(image_tag)",
          "",
          "[Removed Lines]",
          "38:         image_tar_path: str,",
          "39:         docker_repository: str,",
          "40:         auth_method: AuthorizationType = AuthorizationType.LOCAL_ACCOUNT,",
          "41:         vault_endpoint: T.Optional[str] = None,",
          "42:         vault_secret: T.Optional[str] = None,",
          "48:         return _deploy_image_loaded_to_local_registry(build_ver, docker_repository, image_id, auth_method,",
          "49:                                                       vault_endpoint, vault_secret)",
          "",
          "[Added Lines]",
          "41:     image_tar_path: str,",
          "42:     docker_repository: str,",
          "43:     auth_method: AuthorizationType = AuthorizationType.LOCAL_ACCOUNT,",
          "44:     vault_endpoint: T.Optional[str] = None,",
          "45:     vault_secret: T.Optional[str] = None,",
          "46: ) -> str:",
          "47:     if image_tar_path.endswith(\".toml\"):",
          "48:         deploy_fn = _deploy_docker_image_from_local_repo",
          "49:     else:",
          "50:         deploy_fn = _deploy_docker_image_from_fs",
          "51:     return deploy_fn(",
          "52:         image_tar_path,",
          "53:         docker_repository,",
          "54:         auth_method,",
          "55:         vault_endpoint,",
          "56:         vault_secret,",
          "57:     )",
          "60: def _deploy_docker_image_from_local_repo(",
          "61:     image_info_path: str,",
          "62:     docker_repository: str,",
          "63:     auth_method: AuthorizationType = AuthorizationType.LOCAL_ACCOUNT,",
          "64:     vault_endpoint: str | None = None,",
          "65:     vault_secret: str | None = None,",
          "66: ) -> str:",
          "68:     spec = get_project_spec()",
          "69:     info = toml.load(image_info_path)",
          "70:     image_project_version = info['project_version']",
          "71:     image_id = info['docker_image_id']",
          "72:     build_ver = image_project_version.replace(\"+\", \"-\")",
          "74:     if spec.version != image_project_version:",
          "75:         logger.warning(",
          "76:             \"Project version is %r, but image was built for %r\",",
          "77:             spec.version, image_project_version,",
          "78:         )",
          "80:     return _deploy_image_loaded_to_local_registry(",
          "81:         docker_repository=docker_repository,",
          "82:         auth_method=auth_method,",
          "83:         vault_endpoint=vault_endpoint,",
          "84:         vault_secret=vault_secret,",
          "85:         image_id=image_id,",
          "86:         build_ver=build_ver,",
          "87:     )",
          "90: def _deploy_docker_image_from_fs(",
          "91:     image_tar_path: str,",
          "92:     docker_repository: str,",
          "93:     auth_method: AuthorizationType = AuthorizationType.LOCAL_ACCOUNT,",
          "94:     vault_endpoint: str | None = None,",
          "95:     vault_secret: str | None = None,",
          "101:         tag_image(image_id, docker_repository, build_ver)",
          "102:         return _deploy_image_loaded_to_local_registry(",
          "103:             build_ver=build_ver,",
          "104:             docker_repository=docker_repository,",
          "105:             image_id=image_id,",
          "106:             auth_method=auth_method,",
          "107:             vault_endpoint=vault_endpoint,",
          "108:             vault_secret=vault_secret,",
          "109:         )",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "60:     vault_endpoint: str | None = None,",
          "61:     vault_secret: str | None = None,",
          "62: ) -> str:",
          "66:     docker_image = docker_repository + \":\" + build_ver",
          "67:     docker_image_latest = docker_repository + \":latest\"",
          "69:     logger.info(\"Deploying docker image tag=%s auth_method=%s\", docker_image, auth_method)",
          "72:     bf_commons.run_process(['docker', 'push', docker_image])",
          "73:     bf_commons.run_process(['docker', 'push', docker_image_latest])",
          "75:     return docker_image",
          "79:         auth_method: AuthorizationType,",
          "80:         vault_endpoint: T.Optional[str] = None,",
          "81:         vault_secret: T.Optional[str] = None,",
          "",
          "[Removed Lines]",
          "63:     tag_image(image_id, docker_repository, build_ver)",
          "64:     tag_image(image_id, docker_repository, \"latest\")",
          "71:     _authenticate_to_registry(auth_method, vault_endpoint, vault_secret)",
          "78: def _authenticate_to_registry(",
          "",
          "[Added Lines]",
          "125:     tag_image(image_id, docker_repository, \"latest\")",
          "128:     authenticate_to_registry(auth_method, vault_endpoint, vault_secret)",
          "135: def authenticate_to_registry(",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "101:         vault_secret: T.Optional[str] = None,",
          "102: ):",
          "103:     logger.info(\"Checking if images used in DAGs exist in the registry\")",
          "105:     missing_images = set()",
          "106:     for image in images:",
          "107:         found_images = bf_commons.run_process(['docker', 'manifest', 'inspect', image], check=False, verbose=False)",
          "",
          "[Removed Lines]",
          "104:     _authenticate_to_registry(auth_method, vault_endpoint, vault_secret)",
          "",
          "[Added Lines]",
          "161:     authenticate_to_registry(auth_method, vault_endpoint, vault_secret)",
          "",
          "---------------"
        ],
        "bigflow/version.py||bigflow/version.py": [
          "File: bigflow/version.py -> bigflow/version.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "18:     return bigflow.commons.run_process(*args, verbose=verbose, **kwargs)",
          "22:     if not _is_git_available():",
          "23:         logger.warning(\"No git repo is available\")",
          "24:         return f\"0+BROKEN\"",
          "28:     if not dirty:",
          "29:         # try direct tag match",
          "30:         try:",
          "32:         except subprocess.SubprocessError as e:",
          "33:             logger.debug(\"No direct git tag match: %s\", e)",
          "34:         else:",
          "",
          "[Removed Lines]",
          "21: def get_version() -> str:",
          "26:     dirty = _generate_dirty_suffix()",
          "31:             tag = run_process([\"git\", \"describe\", \"--exact-match\", \"--dirty=+dirty\", \"--tags\"])",
          "",
          "[Added Lines]",
          "21: def get_version(commit_ish: str = \"HEAD\") -> str:",
          "27:     dirty = _generate_dirty_suffix() if commit_ish == \"HEAD\" else \"\"",
          "32:             tag = run_process([\"git\", \"describe\", \"--exact-match\", \"--tags\", commit_ish])",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "44:     # try generic 'git describe' (fail when there are no tags)",
          "45:     try:",
          "47:     except subprocess.SubprocessError as e:",
          "48:         logger.debug(\"No long git describtion: %s\", e)",
          "49:     else:",
          "",
          "[Removed Lines]",
          "46:         version = run_process([\"git\", \"describe\", \"--abbrev=8\", \"--long\", \"--tags\"])",
          "",
          "[Added Lines]",
          "47:         version = run_process([\"git\", \"describe\", \"--abbrev=8\", \"--long\", \"--tags\", commit_ish])",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "63:     # no tags? mayb just githash will work",
          "64:     try:",
          "66:     except subprocess.SubprocessError as e:",
          "67:         logger.debug(\"No githash available: %s\", e)",
          "68:     else:",
          "",
          "[Removed Lines]",
          "65:         ghash = run_process([\"git\", \"rev-parse\", \"HEAD\"])[:12]",
          "",
          "[Added Lines]",
          "66:         ghash = run_process([\"git\", \"rev-parse\", commit_ish])[:12]",
          "",
          "---------------"
        ],
        "test/buildd/test_dist.py||test/buildd/test_dist.py": [
          "File: test/buildd/test_dist.py -> test/buildd/test_dist.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "6: from datetime import timedelta",
          "7: from pathlib import Path",
          "8: from unittest import TestCase, mock",
          "10: from test import mixins",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "8: import time",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "46:     mkdir(test_project_dir_path / '.image')",
          "47:     (test_project_dir_path / '.image' / 'leftover').touch()",
          "50: def create_package_leftovers(",
          "51:         test_project_dir_path=None,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "49:     (test_project_dir_path / '.image' / 'imageinfo-1.2.3.toml').touch()",
          "50:     (test_project_dir_path / '.image' / 'image-1.2.3.tar').touch()",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "140: class SetupTestCase(",
          "141:     mixins.PrototypedDirMixin,",
          "142:     mixins.SubprocessMixin,",
          "143:     mixins.BigflowInPythonPathMixin,",
          "144:     TestCase,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "144:     mixins.BfCliInteractionMixin,",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "256:         clear_dags_leftovers(self.prj)",
          "257:         clear_package_leftovers(self.prj)",
          "261:         # when",
          "264:         # then",
          "265:         self.assertFalse(image_leftovers_exist())",
          "",
          "[Removed Lines]",
          "259:         self.run_build('python setup.py build_project --build-package')",
          "262:         self.run_build('python setup.py build_project --build-image')",
          "",
          "[Added Lines]",
          "263:         self.bigflow_run([\"build-package\"])",
          "264:         self.bigflow_run([\"build-image\"])",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "267:         self.assertTrue(docker_image_as_file_built())",
          "268:         self.assertTrue(deployment_config_copied())",
          "271: class BuildImageTest(SetupTestCase):",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "272:     def test_build_image_without_tar(self):",
          "274:         self.addCleanup(self.subprocess_run, [\"docker\", \"rmi\", f\"{DOCKER_REPOSITORY}:0.1.0\"], check=False)",
          "276:         # given",
          "277:         create_image_leftovers(self.prj.project_dir)",
          "278:         clear_dags_leftovers(self.prj)",
          "279:         clear_package_leftovers(self.prj)",
          "281:         # when",
          "282:         self.bigflow_run([\"build-package\"])",
          "283:         self.bigflow_run([\"build-image\", \"--no-export-image-tar\"])",
          "285:         # then",
          "286:         self.assertFalse(image_leftovers_exist())",
          "287:         self.assertTrue(docker_image_built_in_registry(DOCKER_REPOSITORY, '0.1.0'))",
          "288:         self.assertTrue(deployment_config_copied())",
          "290:         imginfo = self.assertFileExists(\".image/imageinfo-0.1.0.toml\")",
          "291:         self.assertFileContentRegex(imginfo, r\"created = .*\")",
          "292:         self.assertFileContentRegex(imginfo, r'project_version = \"0.1.0\"')",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "290:             build_image(self.prj)",
          "292:         # then",
          "294:         remove_docker_image_from_local_registry.assert_called_with('tag_value')",
          "",
          "[Removed Lines]",
          "293:         build_docker_image.assert_called_with(self.prj.project_dir, 'tag_value')",
          "",
          "[Added Lines]",
          "317:         build_docker_image.assert_called_once_with(self.prj, 'tag_value', None)",
          "",
          "---------------"
        ],
        "test/buildd/test_operate.py||test/buildd/test_operate.py": [
          "File: test/buildd/test_operate.py -> test/buildd/test_operate.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: from pathlib import PurePath, PurePosixPath",
          "2: from test import mixins",
          "4: from unittest.mock import patch, call",
          "6: import bigflow.build.operate",
          "7: import bigflow.build.spec",
          "8: import bigflow.deploy",
          "11: class BuildDockerImageTestCase(",
          "12:     mixins.BaseTestCase,",
          "13:     mixins.TempCwdMixin,",
          "14: ):",
          "16:     def setUp(self):",
          "17:         super().setUp()",
          "19:         self.project_spec = bigflow.build.spec.parse_project_spec(",
          "20:             name=\"test_project\",",
          "21:             project_dir=PurePath(\".\"),",
          "22:             docker_repository=\"docker-repo\",",
          "23:             version=\"1.2\",",
          "24:             requries=[],",
          "25:         )",
          "27:         self.auth_registry_mock = self.addMock(patch('bigflow.deploy.authenticate_to_registry'))",
          "28:         self.run_process_mock = self.addMock(patch('bigflow.commons.run_process'))",
          "29:         self.remove_docker_image_mock = self.addMock(patch('bigflow.commons.remove_docker_image_from_local_registry'))",
          "30:         self.clear_image_leftovers_mock = self.addMock(patch('bigflow.build.operate.clear_image_leftovers'))",
          "31:         self.get_docker_image_mock = self.addMock(patch('bigflow.commons.get_docker_image_id', return_value=\"12345\"))",
          "33:         (self.cwd / \"deployment_config.py\").touch()",
          "35:     def test_build_image_nocache(self):",
          "37:         # when",
          "38:         bigflow.build.operate.build_image(self.project_spec, True, None)",
          "40:         # then",
          "41:         self.auth_registry_mock.assert_not_called()",
          "42:         self.clear_image_leftovers_mock.assert_called()",
          "43:         self.remove_docker_image_mock.assert_called_once_with(\"docker-repo:1.2\")",
          "45:         self.run_process_mock.assert_has_calls([",
          "46:             call(['docker', 'build', PurePosixPath('.'), '--tag', 'docker-repo:1.2', '--build-arg', 'BUILDKIT_INLINE_CACHE=1']),",
          "47:             call(['docker', 'image', 'save', '-o', PurePosixPath('.image/image-1.2.tar'), '12345']),",
          "48:         ])",
          "50:     def test_build_image_notar_respect_project_defaults(self):",
          "52:         for project_global_setting, cli_arg_setting, should_export_tar in [",
          "53:             (True, None, True),",
          "54:             (True, False, False),",
          "55:             (True, True, True),",
          "56:             (False, None, False),",
          "57:             (False, True, True),",
          "58:             (False, False, False),",
          "59:         ]:",
          "60:             # given",
          "61:             self.chdir_new_temp()",
          "62:             (self.cwd / \"deployment_config.py\").touch()",
          "64:             self.remove_docker_image_mock.reset_mock()",
          "65:             self.run_process_mock.reset_mock()",
          "67:             # when",
          "68:             self.project_spec.export_image_tar = project_global_setting",
          "69:             bigflow.build.operate.build_image(self.project_spec, cli_arg_setting, None)",
          "71:             # then",
          "72:             if should_export_tar:",
          "73:                 self.remove_docker_image_mock.assert_called_once_with(\"docker-repo:1.2\")",
          "74:                 self.run_process_mock.assert_has_calls([",
          "75:                     call(['docker', 'image', 'save', '-o', PurePosixPath('.image/image-1.2.tar'), '12345']),",
          "76:                 ])",
          "77:             else:",
          "78:                 self.remove_docker_image_mock.assert_not_called()",
          "80:     def test_build_image_notar(self):",
          "82:         # when",
          "83:         bigflow.build.operate.build_image(self.project_spec, False, None)",
          "85:         # then",
          "86:         self.auth_registry_mock.assert_not_called()",
          "87:         self.clear_image_leftovers_mock.assert_called()",
          "88:         self.remove_docker_image_mock.assert_not_called()",
          "90:         self.run_process_mock.assert_has_calls([",
          "91:             call(['docker', 'build', PurePosixPath('.'), '--tag', 'docker-repo:1.2', '--build-arg', 'BUILDKIT_INLINE_CACHE=1']),",
          "92:         ])",
          "94:     def test_build_image_cache_image(self):",
          "96:         # when",
          "97:         bigflow.build.operate.build_image(",
          "98:             self.project_spec, True,",
          "99:             bigflow.build.operate.BuildImageCacheParams(",
          "100:                 auth_method=bigflow.deploy.AuthorizationType.LOCAL_ACCOUNT,",
          "101:                 cache_from_image=[\"xyz.org/foo:bar\"],",
          "102:             ),",
          "103:         )",
          "105:         # then",
          "106:         self.auth_registry_mock.assert_called()",
          "107:         self.clear_image_leftovers_mock.assert_called_once()",
          "108:         self.remove_docker_image_mock.assert_called_once_with(\"docker-repo:1.2\")",
          "110:         self.run_process_mock.assert_has_calls([",
          "111:             call(['docker', 'build', PurePosixPath('.'), '--tag', 'docker-repo:1.2', '--cache-from', 'xyz.org/foo:bar', '--build-arg', 'BUILDKIT_INLINE_CACHE=1']),",
          "112:             call(['docker', 'image', 'save', '-o', PurePosixPath('.image/image-1.2.tar'), '12345']),",
          "113:         ])",
          "115:     def test_build_image_cache_version(self):",
          "117:         # when",
          "118:         bigflow.build.operate.build_image(",
          "119:             self.project_spec, \"1.2\",",
          "120:             bigflow.build.operate.BuildImageCacheParams(",
          "121:                 auth_method=bigflow.deploy.AuthorizationType.LOCAL_ACCOUNT,",
          "122:                 cache_from_version=[\"1.1\"],",
          "123:             ),",
          "124:         )",
          "126:         # then",
          "127:         self.auth_registry_mock.assert_called()",
          "128:         self.clear_image_leftovers_mock.assert_called_once()",
          "129:         self.remove_docker_image_mock.assert_called_once_with(\"docker-repo:1.2\")",
          "131:         self.run_process_mock.assert_has_calls([",
          "132:             call(['docker', 'build', PurePosixPath('.'), '--tag', 'docker-repo:1.2', '--cache-from', 'docker-repo:1.1', '--build-arg', 'BUILDKIT_INLINE_CACHE=1']),",
          "133:             call(['docker', 'image', 'save', '-o', PurePosixPath('.image/image-1.2.tar'), '12345']),",
          "134:         ])",
          "",
          "---------------"
        ],
        "test/buildd/test_spec.py||test/buildd/test_spec.py": [
          "File: test/buildd/test_spec.py -> test/buildd/test_spec.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "105:             'url': \"http://example.org/myproject\",",
          "106:         }",
          "107:         s.test_framework = 'pytest'",
          "109:         # when",
          "110:         spec.add_spec_to_pyproject_toml(self.cwd / \"pyproject.toml\", s)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "108:         s.export_image_tar = False",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "122:             'metainfo',",
          "123:             'data_files',",
          "124:             'test_framework',",
          "125:         ]:",
          "126:             self.assertEqual(getattr(s, f), getattr(ss, f), f\"field {f} should be same\")",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "126:             'export_image_tar',",
          "",
          "---------------"
        ],
        "test/cli/test_cli.py||test/cli/test_cli.py": [
          "File: test/cli/test_cli.py -> test/cli/test_cli.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "3: import shutil",
          "4: import freezegun",
          "6: from bigflow.testing.isolate import ForkIsolateMixin",
          "7: from bigflow.cli import *",
          "8: from bigflow.cli import _ConsoleStreamLogHandler",
          "",
          "[Removed Lines]",
          "1: from unittest import TestCase, mock",
          "2: import itertools",
          "",
          "[Added Lines]",
          "1: from unittest import mock",
          "5: from bigflow.build.operate import BuildImageCacheParams",
          "6: from bigflow.deploy import AuthorizationType",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "15: class CliTestCase(",
          "16:     mixins.PrototypedDirMixin,",
          "17:     ForkIsolateMixin,",
          "19: ):",
          "20:     proto_dir = \"bf-projects/example_project\"",
          "",
          "[Removed Lines]",
          "18:     TestCase,",
          "",
          "[Added Lines]",
          "20:     mixins.BaseTestCase,",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "269:             # when",
          "270:             cli(['deploy-dags'])",
          "273:     def test_should_call_cli_deploy_dags_command__with_defaults_and_with_implicit_deployment_config_file(self,",
          "274:                                                                                                          deploy_dags_folder_mock):",
          "275:         # given",
          "",
          "[Removed Lines]",
          "272:     @mock.patch('bigflow.cli.deploy_dags_folder')",
          "",
          "[Added Lines]",
          "274:     @mock.patch('bigflow.deploy.deploy_dags_folder')",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "297:                                                    vault_endpoint=None,",
          "298:                                                    vault_secret='secret')",
          "301:     def test_should_call_cli_deploy_dags_command_for_different_environments(self, deploy_dags_folder_mock):",
          "302:         # given",
          "303:         self._touch_file('deployment_config.py',",
          "",
          "[Removed Lines]",
          "300:     @mock.patch('bigflow.cli.deploy_dags_folder')",
          "",
          "[Added Lines]",
          "302:     @mock.patch('bigflow.deploy.deploy_dags_folder')",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "355:                                                    vault_endpoint=None,",
          "356:                                                    vault_secret='secret-prod')",
          "359:     def test_should_call_cli_deploy_dags_command__when_parameters_are_given_by_explicit_deployment_config_file(self,",
          "360:                                                                                                                deploy_dags_folder_mock):",
          "361:         # given",
          "",
          "[Removed Lines]",
          "358:     @mock.patch('bigflow.cli.deploy_dags_folder')",
          "",
          "[Added Lines]",
          "360:     @mock.patch('bigflow.deploy.deploy_dags_folder')",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "388:                                                    vault_endpoint='my-another-vault-endpoint',",
          "389:                                                    vault_secret='secrett')",
          "392:     def test_should_call_cli_deploy_dags_command__when_all_parameters_are_given_by_cli_arguments(self,",
          "393:                                                                                                  deploy_dags_folder_mock):",
          "394:         # when",
          "",
          "[Removed Lines]",
          "391:     @mock.patch('bigflow.cli.deploy_dags_folder')",
          "",
          "[Added Lines]",
          "393:     @mock.patch('bigflow.deploy.deploy_dags_folder')",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "411:                                                    vault_endpoint='my-vault-endpoint',",
          "412:                                                    vault_secret='secrett')",
          "415:     def test_should_call_cli_deploy_image_command__with_defaults_and_with_implicit_deployment_config_file(self,",
          "416:                                                                                                           deploy_docker_image_mock):",
          "417:         # given",
          "",
          "[Removed Lines]",
          "414:     @mock.patch('bigflow.cli.deploy_docker_image')",
          "",
          "[Added Lines]",
          "416:     @mock.patch('bigflow.deploy.deploy_docker_image')",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "435:                                                     vault_endpoint=None,",
          "436:                                                     vault_secret=None)",
          "439:     def test_should_call_cli_deploy_image_command__with_explicit_deployment_config_file(self, deploy_docker_image_mock):",
          "440:         # given",
          "441:         dc_file = self._touch_file('my_deployment_config.py',",
          "",
          "[Removed Lines]",
          "438:     @mock.patch('bigflow.cli.deploy_docker_image')",
          "",
          "[Added Lines]",
          "440:     @mock.patch('bigflow.deploy.deploy_docker_image')",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "464:                                                     vault_endpoint='my-another-vault-endpoint',",
          "465:                                                     vault_secret='secrett')",
          "468:     def test_should_call_cli_deploy_image_command__when_all_parameters_are_given_by_cli_arguments_and_image_is_loaded_from_tar(",
          "469:             self, deploy_docker_image_mock):",
          "470:         # when",
          "",
          "[Removed Lines]",
          "467:     @mock.patch('bigflow.cli.deploy_docker_image')",
          "",
          "[Added Lines]",
          "469:     @mock.patch('bigflow.deploy.deploy_docker_image')",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "483:                                                     vault_endpoint='my-vault-endpoint',",
          "484:                                                     vault_secret='secrett')",
          "487:     def test_should_find_tar_in_image_directory(self, deploy_docker_image_mock):",
          "488:         # given",
          "",
          "[Removed Lines]",
          "486:     @mock.patch('bigflow.cli.deploy_docker_image')",
          "",
          "[Added Lines]",
          "488:     @mock.patch('bigflow.deploy.deploy_docker_image')",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "505:                                                     vault_endpoint='my-vault-endpoint',",
          "506:                                                     vault_secret='secrett')",
          "510:     def test_should_call_both_deploy_methods_with_deploy_command(self, deploy_docker_image_mock,",
          "511:                                                                  deploy_dags_folder_mock):",
          "512:         # given",
          "",
          "[Removed Lines]",
          "508:     @mock.patch('bigflow.cli.deploy_dags_folder')",
          "509:     @mock.patch('bigflow.cli.deploy_docker_image')",
          "",
          "[Added Lines]",
          "510:     @mock.patch('bigflow.deploy.deploy_docker_image')",
          "511:     def test_should_find_toml_ref_in_image_directory(self, deploy_docker_image_mock):",
          "513:         # given",
          "514:         shutil.rmtree(Path.cwd() / \".image\", ignore_errors=True)",
          "515:         self._touch_file('imageinfo-123.toml', '', '.image')",
          "517:         # when",
          "518:         cli(['deploy-image',",
          "519:              '--docker-repository', 'my-docker-repository',",
          "520:              '--vault-endpoint', 'my-vault-endpoint',",
          "521:              '--auth-method', 'vault',",
          "522:              '--vault-secret', 'secrett',",
          "523:              ])",
          "525:         # then",
          "526:         deploy_docker_image_mock.assert_called_with(",
          "527:             auth_method=AuthorizationType.VAULT,",
          "528:             docker_repository='my-docker-repository',",
          "529:             image_tar_path='.image/imageinfo-123.toml',",
          "530:             vault_endpoint='my-vault-endpoint',",
          "531:             vault_secret='secrett',",
          "532:         )",
          "534:     @mock.patch('bigflow.deploy.deploy_dags_folder')",
          "535:     @mock.patch('bigflow.deploy.deploy_docker_image')",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "612:             read_project_spec.return_value,",
          "613:             start_time=\"2001-02-03 15:00:00\",",
          "614:             workflow_id=None,",
          "615:         )",
          "619:         # when",
          "622:         # then",
          "625:     @mock.patch('bigflow.build.operate.build_project')",
          "626:     @mock.patch('bigflow.build.spec.read_project_spec')",
          "",
          "[Removed Lines]",
          "617:     @mock.patch('bigflow.cli._cli_build_image')",
          "618:     def test_should_call_cli_build_image_command(self, _cli_build_image_mock):",
          "620:         cli(['build-image'])",
          "623:         _cli_build_image_mock.assert_called_with(Namespace(operation='build-image', verbose=False))",
          "",
          "[Added Lines]",
          "641:             cache_params=None,",
          "642:             export_image_tar=None,",
          "645:     def test_should_call_cli_build_image_command_without_tar(self):",
          "646:         # given",
          "647:         cli_build_mock = self.addMock(mock.patch('bigflow.cli._cli_build_image'))",
          "650:         cli(['build-image', '--no-export-image-tar'])",
          "653:         cli_build_mock.assert_called_once()",
          "654:         self.assertEqual(cli_build_mock.call_args[0][0].export_image_tar, False)",
          "656:     def test_should_call_cli_build_image_command_with_tar(self):",
          "657:         # given",
          "658:         cli_build_mock = self.addMock(mock.patch('bigflow.cli._cli_build_image'))",
          "660:         # when",
          "661:         cli(['build-image', '--export-image-tar'])",
          "663:         # then",
          "664:         cli_build_mock.assert_called_once()",
          "665:         self.assertEqual(cli_build_mock.call_args[0][0].export_image_tar, True)",
          "667:     @mock.patch('bigflow.cli._cli_build_image')",
          "668:     def test_should_call_cli_build_image_command_without_tar(self, _cli_build_image_mock):",
          "669:         # when",
          "670:         cli(['build-image', '--no-export-image-tar'])",
          "672:         # then",
          "673:         _cli_build_image_mock.assert_called_with(",
          "674:             Namespace(",
          "675:                 auth_method=AuthorizationType.LOCAL_ACCOUNT,",
          "676:                 cache_from_image=None,",
          "677:                 cache_from_version=None,",
          "678:                 config=None,",
          "679:                 deployment_config_path=None,",
          "680:                 export_image_tar=False,",
          "681:                 operation='build-image',",
          "682:                 vault_endpoint=None,",
          "683:                 vault_secret=None,",
          "684:                 verbose=False,",
          "685:             )",
          "686:         )",
          "688:     def test_should_call_cli_build_image_with_cached_from_image(self):",
          "690:         # given",
          "691:         self.addMock(mock.patch('bigflow.build.spec.read_project_spec'))",
          "692:         build_image_mock = self.addMock(mock.patch('bigflow.build.operate.build_image'))",
          "694:         # when",
          "695:         cli([",
          "696:             'build-image',",
          "697:             '--no-export-image-tar',",
          "698:             '--vault-endpoint', 'my-vault-endpoint',",
          "699:             '--auth-method', 'vault',",
          "700:             '--vault-secret', 'secrett',",
          "701:             '--cache-from-image', 'xyz.org/foo:bar',",
          "702:             '--cache-from-image', 'xyz.org/foo:baz',",
          "703:         ])",
          "705:         # then",
          "706:         build_image_mock.assert_called_once()",
          "707:         _, kwrgs = build_image_mock.call_args",
          "708:         self.assertEqual(kwrgs['export_image_tar'], False)",
          "709:         self.assertEqual(kwrgs['cache_params'], BuildImageCacheParams(",
          "710:             auth_method=AuthorizationType.VAULT,",
          "711:             vault_endpoint='my-vault-endpoint',",
          "712:             vault_secret='secrett',",
          "713:             cache_from_image=['xyz.org/foo:bar', 'xyz.org/foo:baz'],",
          "714:             cache_from_version=None,",
          "715:         ))",
          "717:     def test_should_call_cli_build_image_with_cached_from_version(self):",
          "719:         # given",
          "720:         self.addMock(mock.patch('bigflow.build.spec.read_project_spec'))",
          "721:         build_image_mock = self.addMock(mock.patch('bigflow.build.operate.build_image'))",
          "723:         # when",
          "724:         cli([",
          "725:             'build-image',",
          "726:             '--no-export-image-tar',",
          "727:             '--vault-endpoint', 'my-vault-endpoint',",
          "728:             '--auth-method', 'vault',",
          "729:             '--vault-secret', 'secrett',",
          "730:             '--cache-from-version', 'bar',",
          "731:             '--cache-from-version', 'baz',",
          "732:         ])",
          "734:         # then",
          "735:         build_image_mock.assert_called_once()",
          "736:         _, kwrgs = build_image_mock.call_args",
          "737:         self.assertEqual(kwrgs['export_image_tar'], False)",
          "738:         self.assertEqual(kwrgs['cache_params'], BuildImageCacheParams(",
          "739:             auth_method=AuthorizationType.VAULT,",
          "740:             vault_endpoint='my-vault-endpoint',",
          "741:             vault_secret='secrett',",
          "742:             cache_from_image=None,",
          "743:             cache_from_version=['bar', 'baz'],",
          "744:         ))",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "639:             read_project_spec.return_value,",
          "640:             start_time=\"2001-02-03 15:00:00\",",
          "641:             workflow_id=None,",
          "642:         )",
          "644:     @mock.patch('bigflow.cli._cli_build_package')",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "763:             cache_params=None,",
          "764:             export_image_tar=None,",
          "",
          "---------------",
          "--- Hunk 14 ---",
          "[Context before]",
          "653:     def test_should_call_cli_build_command(self, _cli_build_mock):",
          "654:         # when",
          "655:         cli(['build'])",
          "657:         # then",
          "660:         # when",
          "661:         cli(['build', '--start-time', '2020-01-01 00:00:00'])",
          "663:         # then",
          "667:         # when",
          "668:         cli(['build', '--start-time', '2020-01-01 00:00:00', '--workflow', 'some_workflow'])",
          "670:         # then",
          "673:     @mock.patch('bigflow.build.operate.build_package')",
          "674:     @mock.patch('bigflow.build.spec.read_project_spec')",
          "",
          "[Removed Lines]",
          "658:         _cli_build_mock.assert_called_with(Namespace(operation='build', start_time=None, workflow=None, verbose=False))",
          "665:         _cli_build_mock.assert_called_with(Namespace(operation='build', start_time='2020-01-01 00:00:00', workflow=None, verbose=False))",
          "671:         _cli_build_mock.assert_called_with(Namespace(operation='build', start_time='2020-01-01 00:00:00', workflow='some_workflow', verbose=False))",
          "",
          "[Added Lines]",
          "779:         args = Namespace(",
          "780:             auth_method=AuthorizationType.LOCAL_ACCOUNT,",
          "781:             cache_from_image=None,",
          "782:             cache_from_version=None,",
          "783:             deployment_config_path=None,",
          "784:             export_image_tar=None,",
          "785:             operation='build',",
          "786:             start_time=None,",
          "787:             vault_endpoint=None,",
          "788:             vault_secret=None,",
          "789:             verbose=False,",
          "790:             workflow=None,",
          "791:             config=None,",
          "792:         )",
          "795:         _cli_build_mock.assert_called_with(args)",
          "801:         args.start_time = '2020-01-01 00:00:00'",
          "802:         _cli_build_mock.assert_called_with(args)",
          "808:         args.start_time = '2020-01-01 00:00:00'",
          "809:         args.workflow = 'some_workflow'",
          "810:         _cli_build_mock.assert_called_with(args)",
          "",
          "---------------",
          "--- Hunk 15 ---",
          "[Context before]",
          "698:         # then",
          "699:         read_project_mock.assert_called_once()",
          "702:     @mock.patch('bigflow.build.operate.build_dags')",
          "703:     @mock.patch('bigflow.build.spec.read_project_spec')",
          "",
          "[Removed Lines]",
          "700:         build_image_mock.assert_any_call(read_project_mock.return_value)",
          "",
          "[Added Lines]",
          "839:         build_image_mock.assert_called_once()",
          "",
          "---------------",
          "--- Hunk 16 ---",
          "[Context before]",
          "718:             workflow_id=None,",
          "719:         )",
          "722:     def test_should_call_cli_project_version_command(self, get_version):",
          "723:         # when",
          "724:         cli(['project-version'])",
          "",
          "[Removed Lines]",
          "721:     @mock.patch('bigflow.cli.get_version')",
          "",
          "[Added Lines]",
          "860:     @mock.patch('bigflow.version.get_version')",
          "",
          "---------------",
          "--- Hunk 17 ---",
          "[Context before]",
          "726:         # then",
          "727:         get_version.assert_called_once()",
          "730:     def test_should_call_cli_project_version_command_by_alias(self, get_version):",
          "731:         # when",
          "732:         cli(['pv'])",
          "",
          "[Removed Lines]",
          "729:     @mock.patch('bigflow.cli.get_version')",
          "",
          "[Added Lines]",
          "868:     @mock.patch('bigflow.version.get_version')",
          "",
          "---------------",
          "--- Hunk 18 ---",
          "[Context before]",
          "734:         # then",
          "735:         get_version.assert_called_once()",
          "738:     def test_should_call_cli_release_command_with_no_args(self, release):",
          "739:         # when",
          "740:         cli(['release'])",
          "",
          "[Removed Lines]",
          "737:     @mock.patch('bigflow.cli.release')",
          "",
          "[Added Lines]",
          "876:     @mock.patch('bigflow.version.release')",
          "",
          "---------------",
          "--- Hunk 19 ---",
          "[Context before]",
          "742:         # then",
          "743:         release.assert_called_once_with(None)",
          "746:     def test_should_call_cli_release_command_with_identity_file(self, release):",
          "747:         # when",
          "748:         cli(['release', '--ssh-identity-file', 'path/to/identity_file'])",
          "",
          "[Removed Lines]",
          "745:     @mock.patch('bigflow.cli.release')",
          "",
          "[Added Lines]",
          "884:     @mock.patch('bigflow.version.release')",
          "",
          "---------------",
          "--- Hunk 20 ---",
          "[Context before]",
          "750:         # then",
          "751:         release.assert_called_once_with('path/to/identity_file')",
          "754:     def test_should_call_cli_release_command_with_identity_file_parameter_shortcut(self, release):",
          "755:         # when",
          "756:         cli(['release', '-i', 'path/to/identity_file'])",
          "",
          "[Removed Lines]",
          "753:     @mock.patch('bigflow.cli.release')",
          "",
          "[Added Lines]",
          "892:     @mock.patch('bigflow.version.release')",
          "",
          "---------------"
        ],
        "test/mixins.py||test/mixins.py": [
          "File: test/mixins.py -> test/mixins.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "34: class FileUtilsMixin(Mixin):",
          "36:     def assertFileExists(self, pattern):",
          "37:         if os.path.isabs(pattern):",
          "38:             # TODO: Add absolute globs?",
          "39:             p = Path(pattern)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "37:         if isinstance(pattern, Path):",
          "38:             pattern = str(pattern)",
          "",
          "---------------"
        ],
        "test/test_deploy.py||test/test_deploy.py": [
          "File: test/test_deploy.py -> test/test_deploy.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "132:         # given",
          "133:         decode_version_number_from_file_name.return_value = 'version123'",
          "134:         load_image_from_tar.return_value = 'image_id'",
          "136:         # when",
          "137:         deploy_docker_image('image-version123.tar', 'docker_repository')",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "135:         self.addMock(mock.patch('bigflow.deploy.tag_image'))",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "139:         # then",
          "140:         decode_version_number_from_file_name.assert_called_with(Path('image-version123.tar'))",
          "141:         load_image_from_tar.assert_called_with('image-version123.tar')",
          "144:         remove_docker_image_from_local_registry.assert_called_with('docker_repository:version123')",
          "146:     @mock.patch('bigflow.commons.decode_version_number_from_file_name')",
          "",
          "[Removed Lines]",
          "142:         _deploy_image_loaded_to_local_registry.assert_called_with('version123', 'docker_repository', 'image_id',",
          "143:                                                                   AuthorizationType.LOCAL_ACCOUNT, None, None)",
          "",
          "[Added Lines]",
          "143:         _deploy_image_loaded_to_local_registry.assert_called_with(",
          "144:             auth_method=AuthorizationType.LOCAL_ACCOUNT,",
          "145:             build_ver='version123',",
          "146:             docker_repository='docker_repository',",
          "147:             image_id='image_id',",
          "148:             vault_endpoint=None,",
          "149:             vault_secret=None,",
          "150:         )",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "180:         # then",
          "181:         self.assertEqual(tags, {f'{docker_repository}:{version1}', f'{docker_repository}:{version2}'})",
          "184:     @mock.patch('bigflow.deploy.bf_commons.run_process', return_value='')",
          "186:         with self.assertRaises(ValueError):",
          "187:             check_images_exist(auth_method=AuthorizationType.LOCAL_ACCOUNT,",
          "188:                                images={f'eu.gcr.io/non-existing-project/name:some-version'})",
          "191:     @mock.patch('bigflow.commons.run_process', return_value='[{\"name\": \"some_image\"}]')",
          "193:         check_images_exist(auth_method=AuthorizationType.LOCAL_ACCOUNT,",
          "194:                            images={f'eu.gcr.io/non-existing-project/name:some-version'})",
          "197:     @mock.patch('bigflow.deploy.upload_dags_folder')",
          "198:     @mock.patch('bigflow.commons.run_process', return_value=None)",
          "200:                                                         upload_dags_folder, run_process):",
          "201:         # given",
          "202:         gs_client = mock.Mock()",
          "",
          "[Removed Lines]",
          "183:     @mock.patch('bigflow.deploy._authenticate_to_registry')",
          "185:     def test_should_raise_error_when_image_doesnt_exist(self, _authenticate_to_registry, run_process):",
          "190:     @mock.patch('bigflow.deploy._authenticate_to_registry')",
          "192:     def test_should_not_raise_error_if_the_image_exists(self, _authenticate_to_registry, run_process):",
          "196:     @mock.patch('bigflow.deploy._authenticate_to_registry')",
          "199:     def test_should_not_upload_dags_if_image_is_missing(self, _authenticate_to_registry,",
          "",
          "[Added Lines]",
          "190:     @mock.patch('bigflow.deploy.authenticate_to_registry')",
          "192:     def test_should_raise_error_when_image_doesnt_exist(self, authenticate_to_registry, run_process):",
          "197:     @mock.patch('bigflow.deploy.authenticate_to_registry')",
          "199:     def test_should_not_raise_error_if_the_image_exists(self, authenticate_to_registry, run_process):",
          "203:     @mock.patch('bigflow.deploy.authenticate_to_registry')",
          "206:     def test_should_not_upload_dags_if_image_is_missing(self, authenticate_to_registry,",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "209:             deploy_dags_folder(dags_dir=os.path.join(self.cwd, '.dags'), dags_bucket='europe-west1-1-bucket', project_id='',",
          "210:                                clear_dags_folder=False, auth_method=AuthorizationType.LOCAL_ACCOUNT, gs_client=gs_client)",
          "213:         gs_client.bucket.assert_not_called()",
          "214:         upload_dags_folder.assert_not_called()",
          "217:     def test_deploy_image_pushes_tags(self):",
          "218:         # given",
          "220:         run_process_mock = self.addMock(mock.patch('bigflow.commons.run_process'))",
          "222:         # when",
          "",
          "[Removed Lines]",
          "212:         _authenticate_to_registry.assert_called_once()",
          "219:         authenticate_to_registry_mock = self.addMock(mock.patch('bigflow.deploy._authenticate_to_registry'))",
          "",
          "[Added Lines]",
          "219:         authenticate_to_registry.assert_called_once()",
          "226:         authenticate_to_registry_mock = self.addMock(mock.patch('bigflow.deploy.authenticate_to_registry'))",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "234:             AuthorizationType.VAULT, \"vault_endpoint\", \"vault_secret\")",
          "236:         run_process_mock.assert_has_calls([",
          "238:             mock.call([\"docker\", \"tag\", \"image123\", \"docker_repository:latest\"]),",
          "239:             mock.call([\"docker\", \"push\", \"docker_repository:1.2\"]),",
          "240:             mock.call([\"docker\", \"push\", \"docker_repository:latest\"]),",
          "",
          "[Removed Lines]",
          "237:             mock.call([\"docker\", \"tag\", \"image123\", \"docker_repository:1.2\"]),",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "test/test_version.py||test/test_version.py": [
          "File: test/test_version.py -> test/test_version.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "10: class GetVersionE2E(",
          "11:     mixins.TempCwdMixin,",
          "12:     mixins.SubprocessMixin,",
          "13:     mixins.BigflowInPythonPathMixin,",
          "14:     unittest.TestCase,",
          "15: ):",
          "17:     def get_version(self):",
          "27:     def test_should_version_based_on_git_tags(self):",
          "28:         # then",
          "",
          "[Removed Lines]",
          "18:         return self.subprocess_run([",
          "19:             \"python\", \"-c\", textwrap.dedent(\"\"\"",
          "20:                 import bigflow.version",
          "21:                 print(bigflow.version.get_version())",
          "22:             \"\"\")",
          "23:             ],",
          "24:             text=True,",
          "25:         ).stdout.strip()",
          "",
          "[Added Lines]",
          "12:     mixins.BfCliInteractionMixin,",
          "19:         return self.bigflow_run([\"project-version\"]).stdout.decode()",
          "21:     def get_version_of_commit(self, commit_ish):",
          "22:         return self.bigflow_run([\"project-version\", \"--git-commit\", commit_ish]).stdout.decode()",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "67:         (self.cwd / \"file1\").write_text(\"change4\")",
          "68:         # then",
          "69:         self.assertRegex(self.get_version(), r\"^0.2.0.dev1\\+g.{8,}\\.t.+$\", \"No exact tag matched, dirty\")",
          "72: class ReleaseTestCase(unittest.TestCase):",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "67:         self.assertRegex(self.get_version_of_commit(\"HEAD~1\"), r\"^0.2.0$\", \"Explicit commit passed\")",
          "69:         # when",
          "70:         (self.cwd / \"file1\").write_text(\"change5\")",
          "71:         self.subprocess_run(\"git add file1\")",
          "72:         self.subprocess_run(\"git commit -m message\")",
          "74:         # then",
          "75:         self.assertRegex(self.get_version(), r\"^0.2.0.dev2\\+g.{8,}$\", \"No exact tag matched, clean\")",
          "76:         self.assertRegex(self.get_version_of_commit(\"HEAD~1\"), r\"^0.2.0.dev1\\+g.{8,}$\", \"Previous dev version\")",
          "77:         self.assertRegex(self.get_version_of_commit(\"HEAD~2\"), r\"^0.2.0$\", \"Previous tag version\")",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "c85dbb4201e5e2e441d0a9dda2db6b8eba26a762",
      "candidate_info": {
        "commit_hash": "c85dbb4201e5e2e441d0a9dda2db6b8eba26a762",
        "repo": "allegro/bigflow",
        "commit_url": "https://github.com/allegro/bigflow/commit/c85dbb4201e5e2e441d0a9dda2db6b8eba26a762",
        "files": [
          "CHANGELOG.md",
          "bigflow/_version.py"
        ],
        "message": "updating the changelog and bumping to 1.5.3 (#340)",
        "before_after_code_files": [
          "bigflow/_version.py||bigflow/_version.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "bigflow/_version.py||bigflow/_version.py"
          ],
          "candidate": [
            "bigflow/_version.py||bigflow/_version.py"
          ]
        }
      },
      "candidate_diff": {
        "bigflow/_version.py||bigflow/_version.py": [
          "File: bigflow/_version.py -> bigflow/_version.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "1: __version__ = '1.5.3.dev1'",
          "",
          "[Added Lines]",
          "1: __version__ = '1.5.3'",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "62eb4b9399945110e53f42d47f76dbfce673bd21",
      "candidate_info": {
        "commit_hash": "62eb4b9399945110e53f42d47f76dbfce673bd21",
        "repo": "allegro/bigflow",
        "commit_url": "https://github.com/allegro/bigflow/commit/62eb4b9399945110e53f42d47f76dbfce673bd21",
        "files": [
          "bigflow/_version.py",
          "requirements.txt",
          "requirements/base.txt",
          "requirements/base_frozen.in",
          "requirements/base_frozen.txt"
        ],
        "message": "1.5.2.dev2 bumping jinja (#335)",
        "before_after_code_files": [
          "bigflow/_version.py||bigflow/_version.py",
          "requirements/base_frozen.in||requirements/base_frozen.in"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "bigflow/_version.py||bigflow/_version.py"
          ],
          "candidate": [
            "bigflow/_version.py||bigflow/_version.py"
          ]
        }
      },
      "candidate_diff": {
        "bigflow/_version.py||bigflow/_version.py": [
          "File: bigflow/_version.py -> bigflow/_version.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "1: __version__ = '1.5.1'",
          "",
          "[Added Lines]",
          "1: __version__ = '1.5.2.dev1'",
          "",
          "---------------"
        ],
        "requirements/base_frozen.in||requirements/base_frozen.in": [
          "File: requirements/base_frozen.in -> requirements/base_frozen.in",
          "--- Hunk 1 ---",
          "[Context before]",
          "6: MarkupSafe<2.1.0 # version 2.1.0 is broken",
          "7: google-auth>=1.20,<3",
          "8: unittest-xml-reporting>=3.0.2,<4",
          "10: pip-tools>=5.3,<7",
          "11: deprecated>=1.2.10,<2",
          "12: toml>=0.10",
          "",
          "[Removed Lines]",
          "9: jinja2>=2.10,<3",
          "",
          "[Added Lines]",
          "9: jinja2>=3,<4",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "cb61b758e0b6e1b01abd8e778c39f7e24a9fda33",
      "candidate_info": {
        "commit_hash": "cb61b758e0b6e1b01abd8e778c39f7e24a9fda33",
        "repo": "allegro/bigflow",
        "commit_url": "https://github.com/allegro/bigflow/commit/cb61b758e0b6e1b01abd8e778c39f7e24a9fda33",
        "files": [
          "bigflow/_version.py"
        ],
        "message": "1.5.1 release (#334)",
        "before_after_code_files": [
          "bigflow/_version.py||bigflow/_version.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "bigflow/_version.py||bigflow/_version.py"
          ],
          "candidate": [
            "bigflow/_version.py||bigflow/_version.py"
          ]
        }
      },
      "candidate_diff": {
        "bigflow/_version.py||bigflow/_version.py": [
          "File: bigflow/_version.py -> bigflow/_version.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "1: __version__ = '1.5.1.dev1'",
          "",
          "[Added Lines]",
          "1: __version__ = '1.5.1'",
          "",
          "---------------"
        ]
      }
    }
  ]
}