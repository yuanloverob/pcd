{
  "cve_id": "CVE-2023-35005",
  "cve_desc": "In Apache Airflow, some potentially sensitive values were being shown to the user in certain situations.\n\nThis vulnerability is mitigated by the fact configuration is not shown in the UI by default (only if `[webserver] expose_config` is set to `non-sensitive-only`), and not all uncensored values are actually sentitive.\n\n\nThis issue affects Apache Airflow: from 2.5.0 before 2.6.2. Users are recommended to update to version 2.6.2 or later.\n\n\n",
  "repo": "apache/airflow",
  "patch_hash": "5679a01919ac9d5153e858f8b1390cbc7915f148",
  "patch_info": {
    "commit_hash": "5679a01919ac9d5153e858f8b1390cbc7915f148",
    "repo": "apache/airflow",
    "commit_url": "https://github.com/apache/airflow/commit/5679a01919ac9d5153e858f8b1390cbc7915f148",
    "files": [
      "airflow/config_templates/config.yml",
      "airflow/config_templates/default_airflow.cfg",
      "airflow/configuration.py",
      "airflow/www/views.py",
      "tests/core/test_configuration.py",
      "tests/www/views/test_views_configuration.py"
    ],
    "message": "Use single source of truth for sensitive config items (#31820)\n\nPreviously we had them defined both in constant and in config.yml.\n\nNow just config.yml\n\n(cherry picked from commit cab342ee010bfd048006ca458c760b37470b6ea5)",
    "before_after_code_files": [
      "airflow/config_templates/default_airflow.cfg||airflow/config_templates/default_airflow.cfg",
      "airflow/configuration.py||airflow/configuration.py",
      "airflow/www/views.py||airflow/www/views.py",
      "tests/core/test_configuration.py||tests/core/test_configuration.py",
      "tests/www/views/test_views_configuration.py||tests/www/views/test_views_configuration.py"
    ]
  },
  "patch_diff": {
    "airflow/config_templates/default_airflow.cfg||airflow/config_templates/default_airflow.cfg": [
      "File: airflow/config_templates/default_airflow.cfg -> airflow/config_templates/default_airflow.cfg",
      "--- Hunk 1 ---",
      "[Context before]",
      "995: # Example: result_backend = db+postgresql://postgres:airflow@postgres/airflow",
      "996: # result_backend =",
      "998: # Celery Flower is a sweet UI for Celery. Airflow has a shortcut to start",
      "999: # it ``airflow celery flower``. This defines the IP that Celery Flower runs on",
      "1000: flower_host = 0.0.0.0",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "998: # Optional configuration dictionary to pass to the Celery result backend SQLAlchemy engine.",
      "999: # Example: result_backend_sqlalchemy_engine_options = {{\"pool_recycle\": 1800}}",
      "1000: result_backend_sqlalchemy_engine_options =",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "1018: # Import path for celery configuration options",
      "1019: celery_config_options = airflow.config_templates.default_celery.DEFAULT_CELERY_CONFIG",
      "1020: ssl_active = False",
      "1021: ssl_key =",
      "1022: ssl_cert =",
      "1023: ssl_cacert =",
      "1025: # Celery Pool implementation.",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "1026: # Path to the client key.",
      "1029: # Path to the client certificate.",
      "1032: # Path to the CA certificate.",
      "",
      "---------------"
    ],
    "airflow/configuration.py||airflow/configuration.py": [
      "File: airflow/configuration.py -> airflow/configuration.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "37: from contextlib import contextmanager, suppress",
      "38: from json.decoder import JSONDecodeError",
      "39: from re import Pattern",
      "41: from urllib.parse import urlsplit",
      "43: from typing_extensions import overload",
      "",
      "[Removed Lines]",
      "40: from typing import IO, Any, Dict, Iterable, Tuple, Union",
      "",
      "[Added Lines]",
      "40: from typing import IO, Any, Dict, Iterable, Set, Tuple, Union",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "147:         return yaml.safe_load(config_file)",
      "165: class AirflowConfigParser(ConfigParser):",
      "166:     \"\"\"Custom Airflow Configparser supporting defaults and deprecated options.\"\"\"",
      "",
      "[Removed Lines]",
      "150: SENSITIVE_CONFIG_VALUES = {",
      "151:     (\"database\", \"sql_alchemy_conn\"),",
      "152:     (\"core\", \"fernet_key\"),",
      "153:     (\"celery\", \"broker_url\"),",
      "154:     (\"celery\", \"flower_basic_auth\"),",
      "155:     (\"celery\", \"result_backend\"),",
      "156:     (\"atlas\", \"password\"),",
      "157:     (\"smtp\", \"smtp_password\"),",
      "158:     (\"webserver\", \"secret_key\"),",
      "159:     (\"secrets\", \"backend_kwargs\"),",
      "160:     # The following options are deprecated",
      "161:     (\"core\", \"sql_alchemy_conn\"),",
      "162: }",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "171:     # These configs can also be fetched from Secrets backend",
      "172:     # following the \"{section}__{name}__secret\" pattern",
      "176:     # A mapping of (new section, new option) -> (old section, old option, since_version).",
      "177:     # When reading new option, the old option will be checked to see if it exists. If it does a",
      "",
      "[Removed Lines]",
      "174:     sensitive_config_values: set[tuple[str, str]] = SENSITIVE_CONFIG_VALUES",
      "",
      "[Added Lines]",
      "159:     @cached_property",
      "160:     def sensitive_config_values(self) -> Set[tuple[str, str]]:  # noqa: UP006",
      "161:         default_config = default_config_yaml()",
      "162:         flattened = {",
      "163:             (s, k): item for s, s_c in default_config.items() for k, item in s_c.get(\"options\").items()",
      "164:         }",
      "165:         sensitive = {(section, key) for (section, key), v in flattened.items() if v.get(\"sensitive\") is True}",
      "166:         depr_option = {self.deprecated_options[x][:-1] for x in sensitive if x in self.deprecated_options}",
      "167:         depr_section = {",
      "168:             (self.deprecated_sections[s][0], k) for s, k in sensitive if s in self.deprecated_sections",
      "169:         }",
      "170:         sensitive.update(depr_section, depr_option)",
      "171:         return sensitive",
      "",
      "---------------"
    ],
    "airflow/www/views.py||airflow/www/views.py": [
      "File: airflow/www/views.py -> airflow/www/views.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "3951:         # TODO remove \"if raw\" usage in Airflow 3.0. Configuration can be fetched via the REST API.",
      "3952:         if raw:",
      "3953:             if expose_config == \"non-sensitive-only\":",
      "3956:                 updater = configupdater.ConfigUpdater()",
      "3957:                 updater.read(AIRFLOW_CONFIG)",
      "3959:                     if updater.has_option(sect, key):",
      "3960:                         updater[sect][key].value = \"< hidden >\"",
      "3961:                 config = str(updater)",
      "",
      "[Removed Lines]",
      "3954:                 from airflow.configuration import SENSITIVE_CONFIG_VALUES",
      "3958:                 for sect, key in SENSITIVE_CONFIG_VALUES:",
      "",
      "[Added Lines]",
      "3956:                 for sect, key in conf.sensitive_config_values:",
      "",
      "---------------"
    ],
    "tests/core/test_configuration.py||tests/core/test_configuration.py": [
      "File: tests/core/test_configuration.py -> tests/core/test_configuration.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "36:     AirflowConfigException,",
      "37:     AirflowConfigParser,",
      "38:     conf,",
      "39:     expand_env_var,",
      "40:     get_airflow_config,",
      "41:     get_airflow_home,",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "39:     default_config_yaml,",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "1447:             w = captured.pop()",
      "1448:             assert \"your `conf.get*` call to use the new name\" in str(w.message)",
      "1449:             assert w.category == FutureWarning",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "1453: def test_sensitive_values():",
      "1454:     from airflow.settings import conf",
      "1456:     # this list was hardcoded prior to 2.6.2",
      "1457:     # included here to avoid regression in refactor",
      "1458:     # inclusion of keys ending in \"password\" or \"kwargs\" is automated from 2.6.2",
      "1459:     # items not matching this pattern must be added here manually",
      "1460:     sensitive_values = {",
      "1461:         (\"database\", \"sql_alchemy_conn\"),",
      "1462:         (\"core\", \"fernet_key\"),",
      "1463:         (\"celery\", \"broker_url\"),",
      "1464:         (\"celery\", \"flower_basic_auth\"),",
      "1465:         (\"celery\", \"result_backend\"),",
      "1466:         (\"atlas\", \"password\"),",
      "1467:         (\"smtp\", \"smtp_password\"),",
      "1468:         (\"webserver\", \"secret_key\"),",
      "1469:         (\"secrets\", \"backend_kwargs\"),",
      "1470:         (\"sentry\", \"sentry_dsn\"),",
      "1471:         (\"database\", \"sql_alchemy_engine_args\"),",
      "1472:         (\"core\", \"sql_alchemy_conn\"),",
      "1473:     }",
      "1474:     default_config = default_config_yaml()",
      "1475:     all_keys = {(s, k) for s, v in default_config.items() for k in v.get(\"options\")}",
      "1476:     suspected_sensitive = {(s, k) for (s, k) in all_keys if k.endswith((\"password\", \"kwargs\"))}",
      "1477:     exclude_list = {",
      "1478:         (\"kubernetes_executor\", \"delete_option_kwargs\"),",
      "1479:     }",
      "1480:     suspected_sensitive -= exclude_list",
      "1481:     sensitive_values.update(suspected_sensitive)",
      "1482:     assert sensitive_values == conf.sensitive_config_values",
      "",
      "---------------"
    ],
    "tests/www/views/test_views_configuration.py||tests/www/views/test_views_configuration.py": [
      "File: tests/www/views/test_views_configuration.py -> tests/www/views/test_views_configuration.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "19: import html",
      "22: from tests.test_utils.config import conf_vars",
      "23: from tests.test_utils.www import check_content_in_response, check_content_not_in_response",
      "",
      "[Removed Lines]",
      "21: from airflow.configuration import SENSITIVE_CONFIG_VALUES, conf",
      "",
      "[Added Lines]",
      "21: from airflow.configuration import conf",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "36: @conf_vars({(\"webserver\", \"expose_config\"): \"True\"})",
      "37: def test_user_can_view_configuration(admin_client):",
      "38:     resp = admin_client.get(\"configuration\", follow_redirects=True)",
      "40:         value = conf.get(section, key, fallback=\"\")",
      "41:         if not value:",
      "42:             continue",
      "",
      "[Removed Lines]",
      "39:     for section, key in SENSITIVE_CONFIG_VALUES:",
      "",
      "[Added Lines]",
      "39:     for section, key in conf.sensitive_config_values:",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "46: @conf_vars({(\"webserver\", \"expose_config\"): \"non-sensitive-only\"})",
      "47: def test_configuration_redacted(admin_client):",
      "48:     resp = admin_client.get(\"configuration\", follow_redirects=True)",
      "50:         value = conf.get(section, key, fallback=\"\")",
      "51:         if not value or value == \"airflow\":",
      "52:             continue",
      "",
      "[Removed Lines]",
      "49:     for section, key in SENSITIVE_CONFIG_VALUES:",
      "",
      "[Added Lines]",
      "49:     for section, key in conf.sensitive_config_values:",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "58: @conf_vars({(\"webserver\", \"expose_config\"): \"non-sensitive-only\"})",
      "59: def test_configuration_redacted_in_running_configuration(admin_client):",
      "60:     resp = admin_client.get(\"configuration\", follow_redirects=True)",
      "62:         value = conf.get(section, key, fallback=\"\")",
      "63:         if not value or value == \"airflow\":",
      "64:             continue",
      "",
      "[Removed Lines]",
      "61:     for section, key in SENSITIVE_CONFIG_VALUES:",
      "",
      "[Added Lines]",
      "61:     for section, key in conf.sensitive_config_values:",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "283b3d21bc8af5a9721737fa8892cd98396bbc4a",
      "candidate_info": {
        "commit_hash": "283b3d21bc8af5a9721737fa8892cd98396bbc4a",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/283b3d21bc8af5a9721737fa8892cd98396bbc4a",
        "files": [
          "airflow/configuration.py",
          "airflow/www/views.py",
          "setup.cfg",
          "tests/core/test_configuration.py",
          "tests/www/views/test_views_configuration.py"
        ],
        "message": "Add option to mask sensitive data in UI configuration page (#25346)\n\n* Add option to mask sensitive data in UI configuration page\n\nThis PR adds an option to mask sensitive data in the UI configuration page, making it possible to view the page with redated data",
        "before_after_code_files": [
          "airflow/configuration.py||airflow/configuration.py",
          "airflow/www/views.py||airflow/www/views.py",
          "setup.cfg||setup.cfg",
          "tests/core/test_configuration.py||tests/core/test_configuration.py",
          "tests/www/views/test_views_configuration.py||tests/www/views/test_views_configuration.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "airflow/configuration.py||airflow/configuration.py",
            "airflow/www/views.py||airflow/www/views.py",
            "tests/core/test_configuration.py||tests/core/test_configuration.py",
            "tests/www/views/test_views_configuration.py||tests/www/views/test_views_configuration.py"
          ],
          "candidate": [
            "airflow/configuration.py||airflow/configuration.py",
            "airflow/www/views.py||airflow/www/views.py",
            "tests/core/test_configuration.py||tests/core/test_configuration.py",
            "tests/www/views/test_views_configuration.py||tests/www/views/test_views_configuration.py"
          ]
        }
      },
      "candidate_diff": {
        "airflow/configuration.py||airflow/configuration.py": [
          "File: airflow/configuration.py -> airflow/configuration.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "142:         return yaml.safe_load(config_file)",
          "145: class AirflowConfigParser(ConfigParser):",
          "146:     \"\"\"Custom Airflow Configparser supporting defaults and deprecated options\"\"\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "145: SENSITIVE_CONFIG_VALUES = {",
          "146:     ('database', 'sql_alchemy_conn'),",
          "147:     ('core', 'fernet_key'),",
          "148:     ('celery', 'broker_url'),",
          "149:     ('celery', 'flower_basic_auth'),",
          "150:     ('celery', 'result_backend'),",
          "151:     ('atlas', 'password'),",
          "152:     ('smtp', 'smtp_password'),",
          "153:     ('webserver', 'secret_key'),",
          "154:     # The following options are deprecated",
          "155:     ('core', 'sql_alchemy_conn'),",
          "156: }",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "150:     # is to not store password on boxes in text files.",
          "151:     # These configs can also be fetched from Secrets backend",
          "152:     # following the \"{section}__{name}__secret\" pattern",
          "166:     # A mapping of (new section, new option) -> (old section, old option, since_version).",
          "167:     # When reading new option, the old option will be checked to see if it exists. If it does a",
          "",
          "[Removed Lines]",
          "153:     sensitive_config_values: Set[Tuple[str, str]] = {",
          "154:         ('database', 'sql_alchemy_conn'),",
          "155:         ('core', 'fernet_key'),",
          "156:         ('celery', 'broker_url'),",
          "157:         ('celery', 'flower_basic_auth'),",
          "158:         ('celery', 'result_backend'),",
          "159:         ('atlas', 'password'),",
          "160:         ('smtp', 'smtp_password'),",
          "161:         ('webserver', 'secret_key'),",
          "162:         # The following options are deprecated",
          "163:         ('core', 'sql_alchemy_conn'),",
          "164:     }",
          "",
          "[Added Lines]",
          "168:     sensitive_config_values: Set[Tuple[str, str]] = SENSITIVE_CONFIG_VALUES",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "887:         :return: Dictionary, where the key is the name of the section and the content is",
          "888:             the dictionary with the name of the parameter and its value.",
          "889:         \"\"\"",
          "890:         config_sources: ConfigSourcesType = {}",
          "891:         configs = [",
          "892:             ('default', self.airflow_defaults),",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "894:         if not display_sensitive:",
          "895:             # We want to hide the sensitive values at the appropriate methods",
          "896:             # since envs from cmds, secrets can be read at _include_envs method",
          "897:             if not all([include_env, include_cmds, include_secret]):",
          "898:                 raise ValueError(",
          "899:                     \"If display_sensitive is false, then include_env, \"",
          "900:                     \"include_cmds, include_secret must all be set as True\"",
          "901:                 )",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "922:         else:",
          "923:             self._filter_by_source(config_sources, display_source, self._get_secret_option)",
          "925:         return config_sources",
          "927:     def _include_secrets(",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "938:         if not display_sensitive:",
          "939:             # This ensures the ones from config file is hidden too",
          "940:             # if they are not provided through env, cmd and secret",
          "941:             hidden = '< hidden >'",
          "942:             for (section, key) in self.sensitive_config_values:",
          "943:                 if not config_sources.get(section):",
          "944:                     continue",
          "945:                 if config_sources[section].get(key, None):",
          "946:                     if display_source:",
          "947:                         source = config_sources[section][key][1]",
          "948:                         config_sources[section][key] = (hidden, source)",
          "949:                     else:",
          "950:                         config_sources[section][key] = hidden",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "987:                 log.warning(\"Ignoring unknown env var '%s'\", env_var)",
          "988:                 continue",
          "989:             if not display_sensitive and env_var != self._env_var_name('core', 'unit_test_mode'):",
          "991:             elif raw:",
          "992:                 opt = opt.replace('%', '%%')",
          "993:             if display_source:",
          "",
          "[Removed Lines]",
          "990:                 opt = '< hidden >'",
          "",
          "[Added Lines]",
          "1017:                 # Don't hide cmd/secret values here",
          "1018:                 if not env_var.lower().endswith('cmd') and not env_var.lower().endswith(\"secret\"):",
          "1019:                     opt = '< hidden >'",
          "",
          "---------------"
        ],
        "airflow/www/views.py||airflow/www/views.py": [
          "File: airflow/www/views.py -> airflow/www/views.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "35: from typing import Any, Callable, Dict, List, Optional, Set, Tuple, Union",
          "36: from urllib.parse import parse_qsl, unquote, urlencode, urlparse",
          "38: import lazy_object_proxy",
          "39: import markupsafe",
          "40: import nvd3",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "38: import configupdater",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "3752:         raw = request.args.get('raw') == \"true\"",
          "3753:         title = \"Airflow Configuration\"",
          "3754:         subtitle = AIRFLOW_CONFIG",
          "3755:         # Don't show config when expose_config variable is False in airflow config",
          "3757:             with open(AIRFLOW_CONFIG) as file:",
          "3758:                 config = file.read()",
          "3759:             table = [",
          "3761:                 for section, parameters in conf.as_dict(True, True).items()",
          "3762:                 for key, (value, source) in parameters.items()",
          "3763:             ]",
          "",
          "[Removed Lines]",
          "3756:         if conf.getboolean(\"webserver\", \"expose_config\"):",
          "3760:                 (section, key, value, source)",
          "",
          "[Added Lines]",
          "3757:         expose_config = conf.get('webserver', 'expose_config')",
          "3760:         # Don't show sensitive config values if expose_config variable is 'non-sensitive-only'",
          "3761:         # in airflow config",
          "3762:         if expose_config.lower() == 'non-sensitive-only':",
          "3763:             from airflow.configuration import SENSITIVE_CONFIG_VALUES",
          "3765:             updater = configupdater.ConfigUpdater()",
          "3766:             updater.read(AIRFLOW_CONFIG)",
          "3767:             for sect, key in SENSITIVE_CONFIG_VALUES:",
          "3768:                 if updater.has_option(sect, key):",
          "3769:                     updater[sect][key].value = '< hidden >'",
          "3770:             config = str(updater)",
          "3772:             table = [",
          "3773:                 (section, key, str(value), source)",
          "3774:                 for section, parameters in conf.as_dict(True, False).items()",
          "3775:                 for key, (value, source) in parameters.items()",
          "3776:             ]",
          "3777:         elif expose_config.lower() in ['true', 't', '1']:",
          "3782:                 (section, key, str(value), source)",
          "",
          "---------------"
        ],
        "setup.cfg||setup.cfg": [
          "File: setup.cfg -> setup.cfg",
          "--- Hunk 1 ---",
          "[Context before]",
          "95:     # Colorlog 6.x merges TTYColoredFormatter into ColoredFormatter, breaking backwards compatibility with 4.x",
          "96:     # Update CustomTTYColoredFormatter to remove",
          "97:     colorlog>=4.0.2, <5.0",
          "98:     connexion[swagger-ui,flask]>=2.10.0",
          "99:     cron-descriptor>=1.2.24",
          "100:     croniter>=0.3.17",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "98:     configupdater>=3.1.1",
          "",
          "---------------"
        ],
        "tests/core/test_configuration.py||tests/core/test_configuration.py": [
          "File: tests/core/test_configuration.py -> tests/core/test_configuration.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "262:         assert 'sqlite:////Users/airflow/airflow/airflow.db' == test_conf.get('test', 'sql_alchemy_conn')",
          "264:     @mock.patch(\"airflow.providers.hashicorp._internal_client.vault_client.hvac\")",
          "265:     @conf_vars(",
          "266:         {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "264:     def test_hidding_of_sensitive_config_values(self):",
          "265:         test_config = '''[test]",
          "266:                          sql_alchemy_conn_secret = sql_alchemy_conn",
          "267:                       '''",
          "268:         test_config_default = '''[test]",
          "269:                                  sql_alchemy_conn = airflow",
          "270:                               '''",
          "271:         test_conf = AirflowConfigParser(default_config=parameterized_config(test_config_default))",
          "272:         test_conf.read_string(test_config)",
          "273:         test_conf.sensitive_config_values = test_conf.sensitive_config_values | {",
          "274:             ('test', 'sql_alchemy_conn'),",
          "275:         }",
          "277:         assert 'airflow' == test_conf.get('test', 'sql_alchemy_conn')",
          "278:         # Hide sensitive fields",
          "279:         asdict = test_conf.as_dict(display_sensitive=False)",
          "280:         assert '< hidden >' == asdict['test']['sql_alchemy_conn']",
          "281:         # If display_sensitive is false, then include_cmd, include_env,include_secrets must all be True",
          "282:         # This ensures that cmd and secrets env are hidden at the appropriate method and no surprises",
          "283:         with pytest.raises(ValueError):",
          "284:             test_conf.as_dict(display_sensitive=False, include_cmds=False)",
          "285:         # Test that one of include_cmds, include_env, include_secret can be false when display_sensitive",
          "286:         # is True",
          "287:         assert test_conf.as_dict(display_sensitive=True, include_cmds=False)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "559:             # the environment variable's echo command",
          "560:             assert test_cmdenv_conf.get('testcmdenv', 'notacommand') == 'OK'",
          "562:     def test_parameterized_config_gen(self):",
          "563:         config = textwrap.dedent(",
          "564:             \"\"\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "587:     @pytest.mark.parametrize('display_sensitive, result', [(True, 'OK'), (False, '< hidden >')])",
          "588:     def test_as_dict_display_sensitivewith_command_from_env(self, display_sensitive, result):",
          "590:         test_cmdenv_conf = AirflowConfigParser()",
          "591:         test_cmdenv_conf.sensitive_config_values.add(('testcmdenv', 'itsacommand'))",
          "592:         with unittest.mock.patch.dict('os.environ'):",
          "593:             asdict = test_cmdenv_conf.as_dict(True, display_sensitive)",
          "594:             assert asdict['testcmdenv']['itsacommand'] == (result, 'cmd')",
          "",
          "---------------"
        ],
        "tests/www/views/test_views_configuration.py||tests/www/views/test_views_configuration.py": [
          "File: tests/www/views/test_views_configuration.py -> tests/www/views/test_views_configuration.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: # Licensed to the Apache Software Foundation (ASF) under one",
          "2: # or more contributor license agreements.  See the NOTICE file",
          "3: # distributed with this work for additional information",
          "4: # regarding copyright ownership.  The ASF licenses this file",
          "5: # to you under the Apache License, Version 2.0 (the",
          "6: # \"License\"); you may not use this file except in compliance",
          "7: # with the License.  You may obtain a copy of the License at",
          "8: #",
          "9: #   http://www.apache.org/licenses/LICENSE-2.0",
          "10: #",
          "11: # Unless required by applicable law or agreed to in writing,",
          "12: # software distributed under the License is distributed on an",
          "13: # \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY",
          "14: # KIND, either express or implied.  See the License for the",
          "15: # specific language governing permissions and limitations",
          "16: # under the License.",
          "18: import html",
          "20: from airflow.configuration import SENSITIVE_CONFIG_VALUES, conf",
          "21: from tests.test_utils.config import conf_vars",
          "22: from tests.test_utils.www import check_content_in_response, check_content_not_in_response",
          "25: @conf_vars({(\"webserver\", \"expose_config\"): 'False'})",
          "26: def test_user_cant_view_configuration(admin_client):",
          "27:     resp = admin_client.get('configuration', follow_redirects=True)",
          "28:     check_content_in_response(",
          "29:         \"Your Airflow administrator chose not to expose the configuration, \"",
          "30:         \"most likely for security reasons.\",",
          "31:         resp,",
          "32:     )",
          "35: @conf_vars({(\"webserver\", \"expose_config\"): 'True'})",
          "36: def test_user_can_view_configuration(admin_client):",
          "37:     resp = admin_client.get('configuration', follow_redirects=True)",
          "38:     for section, key in SENSITIVE_CONFIG_VALUES:",
          "39:         value = conf.get(section, key, fallback='')",
          "40:         if not value:",
          "41:             continue",
          "42:         check_content_in_response(html.escape(value), resp)",
          "45: @conf_vars({(\"webserver\", \"expose_config\"): 'non-sensitive-only'})",
          "46: def test_configuration_redacted(admin_client):",
          "47:     resp = admin_client.get('configuration', follow_redirects=True)",
          "48:     for section, key in SENSITIVE_CONFIG_VALUES:",
          "49:         value = conf.get(section, key, fallback='')",
          "50:         if not value or value == 'airflow':",
          "51:             continue",
          "52:         if value.startswith('db+postgresql'):  # this is in configuration comment",
          "53:             continue",
          "54:         check_content_not_in_response(value, resp)",
          "57: @conf_vars({(\"webserver\", \"expose_config\"): 'non-sensitive-only'})",
          "58: def test_configuration_redacted_in_running_configuration(admin_client):",
          "59:     resp = admin_client.get('configuration', follow_redirects=True)",
          "60:     for section, key in SENSITIVE_CONFIG_VALUES:",
          "61:         value = conf.get(section, key, fallback='')",
          "62:         if not value or value == 'airflow':",
          "63:             continue",
          "64:         check_content_not_in_response(\"<td class='code'>\" + html.escape(value) + '</td', resp)",
          "67: @conf_vars({(\"webserver\", \"expose_config\"): 'non-sensitive-only'})",
          "68: @conf_vars({(\"database\", \"# sql_alchemy_conn\"): 'testconn'})",
          "69: @conf_vars({(\"core\", \"  # secret_key\"): 'core_secret'})",
          "70: @conf_vars({(\"core\", \"fernet_key\"): 'secret_fernet_key'})",
          "71: def test_commented_out_config(admin_client):",
          "72:     resp = admin_client.get('configuration', follow_redirects=True)",
          "73:     check_content_in_response(\"testconn\", resp)",
          "74:     check_content_in_response(\"core_secret\", resp)",
          "75:     check_content_not_in_response(\"secret_fernet_key\", resp)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "b3295879888f28c807941484c99d8eabbbcb950f",
      "candidate_info": {
        "commit_hash": "b3295879888f28c807941484c99d8eabbbcb950f",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/b3295879888f28c807941484c99d8eabbbcb950f",
        "files": [
          ".pre-commit-config.yaml",
          "STATIC_CODE_CHECKS.rst",
          "airflow/api_connexion/endpoints/provider_endpoint.py",
          "airflow/cli/commands/provider_command.py",
          "airflow/cli/commands/user_command.py",
          "airflow/config_templates/default_celery.py",
          "airflow/configuration.py",
          "airflow/decorators/base.py",
          "airflow/kubernetes/pod_generator.py",
          "airflow/kubernetes/pod_generator_deprecated.py",
          "airflow/models/dag.py",
          "airflow/models/dagrun.py",
          "airflow/security/utils.py",
          "airflow/serialization/serde.py",
          "airflow/utils/cli.py",
          "airflow/utils/db_cleanup.py",
          "airflow/utils/email.py",
          "airflow/utils/file.py",
          "airflow/utils/log/colored_log.py",
          "airflow/utils/log/logging_mixin.py",
          "airflow/utils/log/secrets_masker.py",
          "airflow/utils/task_group.py",
          "airflow/www/fab_security/manager.py",
          "airflow/www/views.py",
          "dev/breeze/src/airflow_breeze/pre_commit_ids.py",
          "images/breeze/output-commands-hash.txt",
          "images/breeze/output-commands.svg",
          "images/breeze/output_setup.svg",
          "images/breeze/output_shell.svg",
          "images/breeze/output_start-airflow.svg",
          "images/breeze/output_static-checks.svg",
          "images/breeze/output_testing_docker-compose-tests.svg",
          "kubernetes_tests/test_base.py",
          "tests/utils/log/test_secrets_masker.py"
        ],
        "message": "Use linear time regular expressions (#32303)\n\nThe standard regexp library can consume > O(n) in certain circumstances.\nThe re2 library does not have this issue.\n\n(cherry picked from commit ee38382efa54565c4b389eaeb536f0d45e12d498)",
        "before_after_code_files": [
          "airflow/api_connexion/endpoints/provider_endpoint.py||airflow/api_connexion/endpoints/provider_endpoint.py",
          "airflow/cli/commands/provider_command.py||airflow/cli/commands/provider_command.py",
          "airflow/cli/commands/user_command.py||airflow/cli/commands/user_command.py",
          "airflow/config_templates/default_celery.py||airflow/config_templates/default_celery.py",
          "airflow/configuration.py||airflow/configuration.py",
          "airflow/decorators/base.py||airflow/decorators/base.py",
          "airflow/kubernetes/pod_generator.py||airflow/kubernetes/pod_generator.py",
          "airflow/kubernetes/pod_generator_deprecated.py||airflow/kubernetes/pod_generator_deprecated.py",
          "airflow/models/dag.py||airflow/models/dag.py",
          "airflow/models/dagrun.py||airflow/models/dagrun.py",
          "airflow/security/utils.py||airflow/security/utils.py",
          "airflow/serialization/serde.py||airflow/serialization/serde.py",
          "airflow/utils/cli.py||airflow/utils/cli.py",
          "airflow/utils/db_cleanup.py||airflow/utils/db_cleanup.py",
          "airflow/utils/email.py||airflow/utils/email.py",
          "airflow/utils/file.py||airflow/utils/file.py",
          "airflow/utils/log/colored_log.py||airflow/utils/log/colored_log.py",
          "airflow/utils/log/logging_mixin.py||airflow/utils/log/logging_mixin.py",
          "airflow/utils/log/secrets_masker.py||airflow/utils/log/secrets_masker.py",
          "airflow/utils/task_group.py||airflow/utils/task_group.py",
          "airflow/www/fab_security/manager.py||airflow/www/fab_security/manager.py",
          "airflow/www/views.py||airflow/www/views.py",
          "dev/breeze/src/airflow_breeze/pre_commit_ids.py||dev/breeze/src/airflow_breeze/pre_commit_ids.py",
          "kubernetes_tests/test_base.py||kubernetes_tests/test_base.py",
          "tests/utils/log/test_secrets_masker.py||tests/utils/log/test_secrets_masker.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "airflow/configuration.py||airflow/configuration.py",
            "airflow/www/views.py||airflow/www/views.py"
          ],
          "candidate": [
            "airflow/configuration.py||airflow/configuration.py",
            "airflow/www/views.py||airflow/www/views.py"
          ]
        }
      },
      "candidate_diff": {
        "airflow/api_connexion/endpoints/provider_endpoint.py||airflow/api_connexion/endpoints/provider_endpoint.py": [
          "File: airflow/api_connexion/endpoints/provider_endpoint.py -> airflow/api_connexion/endpoints/provider_endpoint.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "16: # under the License.",
          "17: from __future__ import annotations",
          "21: from airflow.api_connexion import security",
          "22: from airflow.api_connexion.schemas.provider_schema import (",
          "",
          "[Removed Lines]",
          "19: import re",
          "",
          "[Added Lines]",
          "19: import re2",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "32: def _remove_rst_syntax(value: str) -> str:",
          "36: def _provider_mapper(provider: ProviderInfo) -> Provider:",
          "",
          "[Removed Lines]",
          "33:     return re.sub(\"[`_<>]\", \"\", value.strip(\" \\n.\"))",
          "",
          "[Added Lines]",
          "33:     return re2.sub(\"[`_<>]\", \"\", value.strip(\" \\n.\"))",
          "",
          "---------------"
        ],
        "airflow/cli/commands/provider_command.py||airflow/cli/commands/provider_command.py": [
          "File: airflow/cli/commands/provider_command.py -> airflow/cli/commands/provider_command.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: \"\"\"Providers sub-commands.\"\"\"",
          "18: from __future__ import annotations",
          "22: from airflow.cli.simple_table import AirflowConsole",
          "23: from airflow.providers_manager import ProvidersManager",
          "",
          "[Removed Lines]",
          "20: import re",
          "",
          "[Added Lines]",
          "20: import re2",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "29: def _remove_rst_syntax(value: str) -> str:",
          "33: @suppress_logs_and_warning",
          "",
          "[Removed Lines]",
          "30:     return re.sub(\"[`_<>]\", \"\", value.strip(\" \\n.\"))",
          "",
          "[Added Lines]",
          "30:     return re2.sub(\"[`_<>]\", \"\", value.strip(\" \\n.\"))",
          "",
          "---------------"
        ],
        "airflow/cli/commands/user_command.py||airflow/cli/commands/user_command.py": [
          "File: airflow/cli/commands/user_command.py -> airflow/cli/commands/user_command.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: import json",
          "23: import os",
          "24: import random",
          "26: import string",
          "27: from typing import Any",
          "29: from marshmallow import Schema, fields, validate",
          "30: from marshmallow.exceptions import ValidationError",
          "",
          "[Removed Lines]",
          "25: import re",
          "",
          "[Added Lines]",
          "28: import re2",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "164:         # In the User model the first and last name fields have underscores,",
          "165:         # but the corresponding parameters in the CLI don't",
          "166:         def remove_underscores(s):",
          "169:         users = [",
          "170:             {",
          "",
          "[Removed Lines]",
          "167:             return re.sub(\"_\", \"\", s)",
          "",
          "[Added Lines]",
          "167:             return re2.sub(\"_\", \"\", s)",
          "",
          "---------------"
        ],
        "airflow/config_templates/default_celery.py||airflow/config_templates/default_celery.py": [
          "File: airflow/config_templates/default_celery.py -> airflow/config_templates/default_celery.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: from __future__ import annotations",
          "21: import logging",
          "23: import ssl",
          "25: from airflow.configuration import conf",
          "26: from airflow.exceptions import AirflowConfigException, AirflowException",
          "",
          "[Removed Lines]",
          "22: import re",
          "",
          "[Added Lines]",
          "24: import re2",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "85:                 \"ca_certs\": conf.get(\"celery\", \"SSL_CACERT\"),",
          "86:                 \"cert_reqs\": ssl.CERT_REQUIRED,",
          "87:             }",
          "89:             broker_use_ssl = {",
          "90:                 \"ssl_keyfile\": conf.get(\"celery\", \"SSL_KEY\"),",
          "91:                 \"ssl_certfile\": conf.get(\"celery\", \"SSL_CERT\"),",
          "",
          "[Removed Lines]",
          "88:         elif broker_url and re.search(\"rediss?://|sentinel://\", broker_url):",
          "",
          "[Added Lines]",
          "89:         elif broker_url and re2.search(\"rediss?://|sentinel://\", broker_url):",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "111:         f\"all necessary certs and key ({e}).\"",
          "112:     )",
          "115:     log.warning(",
          "116:         \"You have configured a result_backend of %s, it is highly recommended \"",
          "117:         \"to use an alternative result_backend (i.e. a database).\",",
          "",
          "[Removed Lines]",
          "114: if re.search(\"rediss?://|amqp://|rpc://\", result_backend):",
          "",
          "[Added Lines]",
          "115: if re2.search(\"rediss?://|amqp://|rpc://\", result_backend):",
          "",
          "---------------"
        ],
        "airflow/configuration.py||airflow/configuration.py": [
          "File: airflow/configuration.py -> airflow/configuration.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "23: import multiprocessing",
          "24: import os",
          "25: import pathlib",
          "27: import shlex",
          "28: import stat",
          "29: import subprocess",
          "",
          "[Removed Lines]",
          "26: import re",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "36: from configparser import _UNSET, ConfigParser, NoOptionError, NoSectionError  # type: ignore",
          "37: from contextlib import contextmanager, suppress",
          "38: from json.decoder import JSONDecodeError",
          "41: from urllib.parse import urlsplit",
          "43: from typing_extensions import overload",
          "45: from airflow.compat.functools import cached_property",
          "",
          "[Removed Lines]",
          "39: from re import Pattern",
          "40: from typing import IO, Any, Dict, Iterable, Set, Tuple, Union",
          "",
          "[Added Lines]",
          "38: from typing import IO, Any, Dict, Iterable, Pattern, Set, Tuple, Union",
          "41: import re2",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "56:     warnings.filterwarnings(action=\"default\", category=DeprecationWarning, module=\"airflow\")",
          "57:     warnings.filterwarnings(action=\"default\", category=PendingDeprecationWarning, module=\"airflow\")",
          "61: ConfigType = Union[str, int, float, bool]",
          "62: ConfigOptionsDictType = Dict[str, ConfigType]",
          "",
          "[Removed Lines]",
          "59: _SQLITE3_VERSION_PATTERN = re.compile(r\"(?P<version>^\\d+(?:\\.\\d+)*)\\D?.*$\")",
          "",
          "[Added Lines]",
          "58: _SQLITE3_VERSION_PATTERN = re2.compile(r\"(?P<version>^\\d+(?:\\.\\d+)*)\\D?.*$\")",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "270:     # about. Mapping of section -> setting -> { old, replace, by_version }",
          "271:     deprecated_values: dict[str, dict[str, tuple[Pattern, str, str]]] = {",
          "272:         \"core\": {",
          "274:         },",
          "275:         \"webserver\": {",
          "278:         },",
          "279:         \"email\": {",
          "280:             \"email_backend\": (",
          "282:                 r\"airflow.providers.sendgrid.utils.emailer.send_email\",",
          "283:                 \"2.1\",",
          "284:             ),",
          "285:         },",
          "286:         \"logging\": {",
          "287:             \"log_filename_template\": (",
          "289:                 \"XX-set-after-default-config-loaded-XX\",",
          "290:                 \"3.0\",",
          "291:             ),",
          "292:         },",
          "293:         \"api\": {",
          "294:             \"auth_backends\": (",
          "296:                 \"airflow.api.auth.backend.session\",",
          "297:                 \"3.0\",",
          "298:             ),",
          "299:         },",
          "300:         \"elasticsearch\": {",
          "301:             \"log_id_template\": (",
          "303:                 \"{dag_id}-{task_id}-{run_id}-{map_index}-{try_number}\",",
          "304:                 \"3.0\",",
          "305:             )",
          "",
          "[Removed Lines]",
          "273:             \"hostname_callable\": (re.compile(r\":\"), r\".\", \"2.1\"),",
          "276:             \"navbar_color\": (re.compile(r\"\\A#007A87\\Z\", re.IGNORECASE), \"#fff\", \"2.1\"),",
          "277:             \"dag_default_view\": (re.compile(r\"^tree$\"), \"grid\", \"3.0\"),",
          "281:                 re.compile(r\"^airflow\\.contrib\\.utils\\.sendgrid\\.send_email$\"),",
          "288:                 re.compile(re.escape(\"{{ ti.dag_id }}/{{ ti.task_id }}/{{ ts }}/{{ try_number }}.log\")),",
          "295:                 re.compile(r\"^airflow\\.api\\.auth\\.backend\\.deny_all$|^$\"),",
          "302:                 re.compile(\"^\" + re.escape(\"{dag_id}-{task_id}-{execution_date}-{try_number}\") + \"$\"),",
          "",
          "[Added Lines]",
          "272:             \"hostname_callable\": (re2.compile(r\":\"), r\".\", \"2.1\"),",
          "275:             \"navbar_color\": (re2.compile(r\"(?i)\\A#007A87\\z\"), \"#fff\", \"2.1\"),",
          "276:             \"dag_default_view\": (re2.compile(r\"^tree$\"), \"grid\", \"3.0\"),",
          "280:                 re2.compile(r\"^airflow\\.contrib\\.utils\\.sendgrid\\.send_email$\"),",
          "287:                 re2.compile(re2.escape(\"{{ ti.dag_id }}/{{ ti.task_id }}/{{ ts }}/{{ try_number }}.log\")),",
          "294:                 re2.compile(r\"^airflow\\.api\\.auth\\.backend\\.deny_all$|^$\"),",
          "301:                 re2.compile(\"^\" + re2.escape(\"{dag_id}-{task_id}-{execution_date}-{try_number}\") + \"$\"),",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "426:                 FutureWarning,",
          "427:             )",
          "428:             self.upgraded_values[(section, key)] = old_value",
          "430:             self._update_env_var(section=section, name=key, new_value=new_value)",
          "432:             # if the old value is set via env var, we need to wipe it",
          "",
          "[Removed Lines]",
          "429:             new_value = re.sub(\"^\" + re.escape(f\"{parsed.scheme}://\"), f\"{good_scheme}://\", old_value)",
          "",
          "[Added Lines]",
          "428:             new_value = re2.sub(\"^\" + re2.escape(f\"{parsed.scheme}://\"), f\"{good_scheme}://\", old_value)",
          "",
          "---------------"
        ],
        "airflow/decorators/base.py||airflow/decorators/base.py": [
          "File: airflow/decorators/base.py -> airflow/decorators/base.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: from __future__ import annotations",
          "19: import inspect",
          "21: import warnings",
          "22: from itertools import chain",
          "23: from textwrap import dedent",
          "",
          "[Removed Lines]",
          "20: import re",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "37: )",
          "39: import attr",
          "40: import typing_extensions",
          "41: from sqlalchemy.orm import Session",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "39: import re2",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "143:         return task_id",
          "145:     def _find_id_suffixes(dag: DAG) -> Iterator[int]:",
          "147:         for task_id in dag.task_ids:",
          "149:             if match is None:",
          "150:                 continue",
          "151:             yield int(match.group(1))",
          "152:         yield 0  # Default if there's no matching task ID.",
          "155:     return f\"{core}__{max(_find_id_suffixes(dag)) + 1}\"",
          "",
          "[Removed Lines]",
          "146:         prefix = re.split(r\"__\\d+$\", tg_task_id)[0]",
          "148:             match = re.match(rf\"^{prefix}__(\\d+)$\", task_id)",
          "154:     core = re.split(r\"__\\d+$\", task_id)[0]",
          "",
          "[Added Lines]",
          "146:         prefix = re2.split(r\"__\\d+$\", tg_task_id)[0]",
          "148:             match = re2.match(rf\"^{prefix}__(\\d+)$\", task_id)",
          "154:     core = re2.split(r\"__\\d+$\", task_id)[0]",
          "",
          "---------------"
        ],
        "airflow/kubernetes/pod_generator.py||airflow/kubernetes/pod_generator.py": [
          "File: airflow/kubernetes/pod_generator.py -> airflow/kubernetes/pod_generator.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "29: import hashlib",
          "30: import logging",
          "31: import os",
          "33: import warnings",
          "34: from functools import reduce",
          "36: from dateutil import parser",
          "37: from kubernetes.client import models as k8s",
          "38: from kubernetes.client.api_client import ApiClient",
          "",
          "[Removed Lines]",
          "32: import re",
          "",
          "[Added Lines]",
          "35: import re2",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "65:     way from the original value sent to this function, then we need to truncate to",
          "66:     53 chars, and append it with a unique hash.",
          "67:     \"\"\"",
          "70:     if len(safe_label) > MAX_LABEL_LEN or string != safe_label:",
          "71:         safe_hash = hashlib.md5(string.encode()).hexdigest()[:9]",
          "",
          "[Removed Lines]",
          "68:     safe_label = re.sub(r\"^[^a-z0-9A-Z]*|[^a-zA-Z0-9_\\-\\.]|[^a-z0-9A-Z]*$\", \"\", string)",
          "",
          "[Added Lines]",
          "68:     safe_label = re2.sub(r\"^[^a-z0-9A-Z]*|[^a-zA-Z0-9_\\-\\.]|[^a-z0-9A-Z]*$\", \"\", string)",
          "",
          "---------------"
        ],
        "airflow/kubernetes/pod_generator_deprecated.py||airflow/kubernetes/pod_generator_deprecated.py": [
          "File: airflow/kubernetes/pod_generator_deprecated.py -> airflow/kubernetes/pod_generator_deprecated.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "27: import copy",
          "28: import hashlib",
          "30: import uuid",
          "32: from kubernetes.client import models as k8s",
          "34: MAX_POD_ID_LEN = 253",
          "",
          "[Removed Lines]",
          "29: import re",
          "",
          "[Added Lines]",
          "31: import re2",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "69:     way from the original value sent to this function, then we need to truncate to",
          "70:     53 chars, and append it with a unique hash.",
          "71:     \"\"\"",
          "74:     if len(safe_label) > MAX_LABEL_LEN or string != safe_label:",
          "75:         safe_hash = hashlib.md5(string.encode()).hexdigest()[:9]",
          "",
          "[Removed Lines]",
          "72:     safe_label = re.sub(r\"^[^a-z0-9A-Z]*|[^a-zA-Z0-9_\\-\\.]|[^a-z0-9A-Z]*$\", \"\", string)",
          "",
          "[Added Lines]",
          "72:     safe_label = re2.sub(r\"^[^a-z0-9A-Z]*|[^a-zA-Z0-9_\\-\\.]|[^a-z0-9A-Z]*$\", \"\", string)",
          "",
          "---------------"
        ],
        "airflow/models/dag.py||airflow/models/dag.py": [
          "File: airflow/models/dag.py -> airflow/models/dag.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "53: import jinja2",
          "54: import pendulum",
          "56: from dateutil.relativedelta import relativedelta",
          "57: from pendulum.tz.timezone import Timezone",
          "58: from sqlalchemy import Boolean, Column, ForeignKey, Index, Integer, String, Text, and_, case, func, not_, or_",
          "",
          "[Removed Lines]",
          "55: import re2 as re",
          "",
          "[Added Lines]",
          "55: import re2",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "2206:         dag = copy.deepcopy(self, memo)  # type: ignore",
          "2208:         if isinstance(task_ids_or_regex, (str, Pattern)):",
          "2210:         else:",
          "2211:             matched_tasks = [t for t in self.tasks if t.task_id in task_ids_or_regex]",
          "",
          "[Removed Lines]",
          "2209:             matched_tasks = [t for t in self.tasks if re.findall(task_ids_or_regex, t.task_id)]",
          "",
          "[Added Lines]",
          "2209:             matched_tasks = [t for t in self.tasks if re2.findall(task_ids_or_regex, t.task_id)]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "2669:         regex = airflow_conf.get(\"scheduler\", \"allowed_run_id_pattern\")",
          "2673:                 raise AirflowException(",
          "2674:                     f\"The provided run ID '{run_id}' is invalid. It does not match either \"",
          "2675:                     f\"the configured pattern: '{regex}' or the built-in pattern: '{RUN_ID_REGEX}'\"",
          "",
          "[Removed Lines]",
          "2671:         if run_id and not re.match(RUN_ID_REGEX, run_id):",
          "2672:             if not regex.strip() or not re.match(regex.strip(), run_id):",
          "",
          "[Added Lines]",
          "2671:         if run_id and not re2.match(RUN_ID_REGEX, run_id):",
          "2672:             if not regex.strip() or not re2.match(regex.strip(), run_id):",
          "",
          "---------------"
        ],
        "airflow/models/dagrun.py||airflow/models/dagrun.py": [
          "File: airflow/models/dagrun.py -> airflow/models/dagrun.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "24: from datetime import datetime",
          "25: from typing import TYPE_CHECKING, Any, Callable, Iterable, Iterator, NamedTuple, Sequence, TypeVar, overload",
          "28: from sqlalchemy import (",
          "29:     Boolean,",
          "30:     Column,",
          "",
          "[Removed Lines]",
          "27: import re2 as re",
          "",
          "[Added Lines]",
          "27: import re2",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "246:         if not run_id:",
          "247:             return None",
          "248:         regex = airflow_conf.get(\"scheduler\", \"allowed_run_id_pattern\")",
          "250:             raise ValueError(",
          "251:                 f\"The run_id provided '{run_id}' does not match the pattern '{regex}' or '{RUN_ID_REGEX}'\"",
          "252:             )",
          "",
          "[Removed Lines]",
          "249:         if not re.match(regex, run_id) and not re.match(RUN_ID_REGEX, run_id):",
          "",
          "[Added Lines]",
          "249:         if not re2.match(regex, run_id) and not re2.match(RUN_ID_REGEX, run_id):",
          "",
          "---------------"
        ],
        "airflow/security/utils.py||airflow/security/utils.py": [
          "File: airflow/security/utils.py -> airflow/security/utils.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "34: # limitations under the License.",
          "35: #",
          "36: \"\"\"Various security-related utils.\"\"\"",
          "38: import socket",
          "40: from airflow.utils.net import get_hostname",
          "",
          "[Removed Lines]",
          "37: import re",
          "",
          "[Added Lines]",
          "39: import re2",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "49:     \"\"\"",
          "50:     if not principal:",
          "51:         return None",
          "55: def replace_hostname_pattern(components, host=None):",
          "",
          "[Removed Lines]",
          "52:     return re.split(r\"[/@]\", str(principal))",
          "",
          "[Added Lines]",
          "53:     return re2.split(r\"[/@]\", str(principal))",
          "",
          "---------------"
        ],
        "airflow/serialization/serde.py||airflow/serialization/serde.py": [
          "File: airflow/serialization/serde.py -> airflow/serialization/serde.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: import enum",
          "22: import functools",
          "23: import logging",
          "25: import sys",
          "26: from importlib import import_module",
          "27: from types import ModuleType",
          "30: import attr",
          "32: import airflow.serialization.serializers",
          "33: from airflow.configuration import conf",
          "",
          "[Removed Lines]",
          "24: import re",
          "28: from typing import Any, TypeVar, Union, cast",
          "",
          "[Added Lines]",
          "27: from typing import Any, Pattern, TypeVar, Union, cast",
          "30: import re2",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "345: @functools.lru_cache(maxsize=None)",
          "347:     patterns = conf.get(\"core\", \"allowed_deserialization_classes\").split()",
          "351: _register()",
          "",
          "[Removed Lines]",
          "346: def _get_patterns() -> list[re.Pattern]:",
          "348:     return [re.compile(re.sub(r\"(\\w)\\.\", r\"\\1\\..\", p)) for p in patterns]",
          "",
          "[Added Lines]",
          "346: def _get_patterns() -> list[Pattern]:",
          "348:     return [re2.compile(re2.sub(r\"(\\w)\\.\", r\"\\1\\..\", p)) for p in patterns]",
          "",
          "---------------"
        ],
        "airflow/utils/cli.py||airflow/utils/cli.py": [
          "File: airflow/utils/cli.py -> airflow/utils/cli.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: import functools",
          "22: import logging",
          "23: import os",
          "25: import socket",
          "26: import sys",
          "27: import threading",
          "",
          "[Removed Lines]",
          "24: import re",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "32: from pathlib import Path",
          "33: from typing import TYPE_CHECKING, Callable, TypeVar, cast",
          "35: from sqlalchemy.orm import Session",
          "37: from airflow import settings",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "34: import re2",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "245:     if not use_regex:",
          "246:         return [get_dag(subdir, dag_id)]",
          "247:     dagbag = DagBag(process_subdir(subdir))",
          "249:     if not matched_dags:",
          "250:         raise AirflowException(",
          "251:             f\"dag_id could not be found with regex: {dag_id}. Either the dag did not exist or \"",
          "",
          "[Removed Lines]",
          "248:     matched_dags = [dag for dag in dagbag.dags.values() if re.search(dag_id, dag.dag_id)]",
          "",
          "[Added Lines]",
          "248:     matched_dags = [dag for dag in dagbag.dags.values() if re2.search(dag_id, dag.dag_id)]",
          "",
          "---------------"
        ],
        "airflow/utils/db_cleanup.py||airflow/utils/db_cleanup.py": [
          "File: airflow/utils/db_cleanup.py -> airflow/utils/db_cleanup.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "143: def _do_delete(*, query, orm_model, skip_archive, session):",
          "145:     from datetime import datetime",
          "147:     print(\"Performing Delete...\")",
          "148:     # using bulk delete",
          "149:     # create a new table and copy the rows there",
          "151:     target_table_name = f\"{ARCHIVE_TABLE_PREFIX}{orm_model.name}__{timestamp_str}\"",
          "152:     print(f\"Moving data to table {target_table_name}\")",
          "153:     bind = session.get_bind()",
          "",
          "[Removed Lines]",
          "144:     import re",
          "150:     timestamp_str = re.sub(r\"[^\\d]\", \"\", datetime.utcnow().isoformat())[:14]",
          "",
          "[Added Lines]",
          "146:     import re2",
          "151:     timestamp_str = re2.sub(r\"[^\\d]\", \"\", datetime.utcnow().isoformat())[:14]",
          "",
          "---------------"
        ],
        "airflow/utils/email.py||airflow/utils/email.py": [
          "File: airflow/utils/email.py -> airflow/utils/email.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: import collections.abc",
          "21: import logging",
          "22: import os",
          "24: import smtplib",
          "25: import warnings",
          "26: from email.mime.application import MIMEApplication",
          "",
          "[Removed Lines]",
          "23: import re",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "29: from email.utils import formatdate",
          "30: from typing import Any, Iterable",
          "32: from airflow.configuration import conf",
          "33: from airflow.exceptions import AirflowConfigException, AirflowException, RemovedInAirflow3Warning",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "31: import re2",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "328:     :return: A list of email addresses.",
          "329:     \"\"\"",
          "330:     pattern = r\"\\s*[,;]\\s*\"",
          "",
          "[Removed Lines]",
          "331:     return [address for address in re.split(pattern, addresses)]",
          "",
          "[Added Lines]",
          "332:     return [address for address in re2.split(pattern, addresses)]",
          "",
          "---------------"
        ],
        "airflow/utils/file.py||airflow/utils/file.py": [
          "File: airflow/utils/file.py -> airflow/utils/file.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: import io",
          "22: import logging",
          "23: import os",
          "25: import zipfile",
          "26: from collections import OrderedDict",
          "27: from pathlib import Path",
          "28: from typing import TYPE_CHECKING, Generator, NamedTuple, Pattern, overload",
          "30: from pathspec.patterns import GitWildMatchPattern",
          "31: from typing_extensions import Protocol",
          "",
          "[Removed Lines]",
          "24: import re",
          "",
          "[Added Lines]",
          "29: import re2",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "64:     def compile(pattern: str, base_dir: Path, definition_file: Path) -> _IgnoreRule | None:",
          "65:         \"\"\"Build an ignore rule from the supplied regexp pattern and log a useful warning if it is invalid\"\"\"",
          "66:         try:",
          "69:             log.warning(\"Ignoring invalid regex '%s' from %s: %s\", pattern, definition_file, e)",
          "70:             return None",
          "",
          "[Removed Lines]",
          "67:             return _RegexpIgnoreRule(re.compile(pattern), base_dir)",
          "68:         except re.error as e:",
          "",
          "[Added Lines]",
          "67:             return _RegexpIgnoreRule(re2.compile(pattern), base_dir)",
          "68:         except re2.error as e:",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "154:     Path(path).mkdir(mode=mode, parents=True, exist_ok=True)",
          "160: @overload",
          "",
          "[Removed Lines]",
          "157: ZIP_REGEX = re.compile(rf\"((.*\\.zip){re.escape(os.sep)})?(.*)\")",
          "",
          "[Added Lines]",
          "157: ZIP_REGEX = re2.compile(rf\"((.*\\.zip){re2.escape(os.sep)})?(.*)\")",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "222:         ignore_file_path = Path(root) / ignore_file_name",
          "223:         if ignore_file_path.is_file():",
          "224:             with open(ignore_file_path) as ifile:",
          "226:                 # append new patterns and filter out \"None\" objects, which are invalid patterns",
          "227:                 patterns += [",
          "228:                     p",
          "",
          "[Removed Lines]",
          "225:                 lines_no_comments = [re.sub(r\"\\s*#.*\", \"\", line) for line in ifile.read().split(\"\\n\")]",
          "",
          "[Added Lines]",
          "224:                 lines_no_comments = [re2.sub(r\"\\s*#.*\", \"\", line) for line in ifile.read().split(\"\\n\")]",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "333:     return file_paths",
          "339: def might_contain_dag(file_path: str, safe_mode: bool, zip_file: zipfile.ZipFile | None = None) -> bool:",
          "",
          "[Removed Lines]",
          "336: COMMENT_PATTERN = re.compile(r\"\\s*#.*\")",
          "",
          "[Added Lines]",
          "335: COMMENT_PATTERN = re2.compile(r\"\\s*#.*\")",
          "",
          "---------------"
        ],
        "airflow/utils/log/colored_log.py||airflow/utils/log/colored_log.py": [
          "File: airflow/utils/log/colored_log.py -> airflow/utils/log/colored_log.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: \"\"\"Class responsible for colouring logs based on log level.\"\"\"",
          "19: from __future__ import annotations",
          "22: import sys",
          "23: from logging import LogRecord",
          "24: from typing import Any",
          "26: from colorlog import TTYColoredFormatter",
          "27: from colorlog.escape_codes import esc, escape_codes",
          "",
          "[Removed Lines]",
          "21: import re",
          "",
          "[Added Lines]",
          "25: import re2",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "62:     @staticmethod",
          "63:     def _count_number_of_arguments_in_message(record: LogRecord) -> int:",
          "65:         return len(matches) if matches else 0",
          "67:     def _color_record_args(self, record: LogRecord) -> LogRecord:",
          "",
          "[Removed Lines]",
          "64:         matches = re.findall(r\"%.\", record.msg)",
          "",
          "[Added Lines]",
          "64:         matches = re2.findall(r\"%.\", record.msg)",
          "",
          "---------------"
        ],
        "airflow/utils/log/logging_mixin.py||airflow/utils/log/logging_mixin.py": [
          "File: airflow/utils/log/logging_mixin.py -> airflow/utils/log/logging_mixin.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: import abc",
          "21: import enum",
          "22: import logging",
          "24: import sys",
          "25: from io import IOBase",
          "26: from logging import Handler, Logger, StreamHandler",
          "27: from typing import IO, Any, TypeVar, cast",
          "29: # 7-bit C1 ANSI escape sequences",
          "33: # Private: A sentinel objects",
          "",
          "[Removed Lines]",
          "23: import re",
          "30: ANSI_ESCAPE = re.compile(r\"\\x1B[@-_][0-?]*[ -/]*[@-~]\")",
          "",
          "[Added Lines]",
          "28: import re2",
          "31: ANSI_ESCAPE = re2.compile(r\"\\x1B[@-_][0-?]*[ -/]*[@-~]\")",
          "",
          "---------------"
        ],
        "airflow/utils/log/secrets_masker.py||airflow/utils/log/secrets_masker.py": [
          "File: airflow/utils/log/secrets_masker.py -> airflow/utils/log/secrets_masker.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: import collections.abc",
          "21: import logging",
          "23: import sys",
          "24: from typing import (",
          "25:     TYPE_CHECKING,",
          "",
          "[Removed Lines]",
          "22: import re",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "30:     Iterable,",
          "31:     Iterator,",
          "32:     List,",
          "33:     TextIO,",
          "34:     Tuple,",
          "35:     TypeVar,",
          "36:     Union,",
          "37: )",
          "39: from airflow import settings",
          "40: from airflow.compat.functools import cache, cached_property",
          "41: from airflow.typing_compat import TypeGuard",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "32:     Pattern,",
          "39: import re2",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "143: class SecretsMasker(logging.Filter):",
          "144:     \"\"\"Redact secrets from logs\"\"\"",
          "147:     patterns: set[str]",
          "149:     ALREADY_FILTERED_FLAG = \"__SecretsMasker_filtered\"",
          "",
          "[Removed Lines]",
          "146:     replacer: re.Pattern | None = None",
          "",
          "[Added Lines]",
          "148:     replacer: Pattern | None = None",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "331:             new_mask = False",
          "332:             for s in self._adaptations(secret):",
          "333:                 if s:",
          "335:                     if pattern not in self.patterns and (not name or should_hide_value_for_key(name)):",
          "336:                         self.patterns.add(pattern)",
          "337:                         new_mask = True",
          "339:             if new_mask:",
          "342:         elif isinstance(secret, collections.abc.Iterable):",
          "343:             for v in secret:",
          "",
          "[Removed Lines]",
          "334:                     pattern = re.escape(s)",
          "340:                 self.replacer = re.compile(\"|\".join(self.patterns))",
          "",
          "[Added Lines]",
          "336:                     pattern = re2.escape(s)",
          "342:                 self.replacer = re2.compile(\"|\".join(self.patterns))",
          "",
          "---------------"
        ],
        "airflow/utils/task_group.py||airflow/utils/task_group.py": [
          "File: airflow/utils/task_group.py -> airflow/utils/task_group.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "24: import copy",
          "25: import functools",
          "26: import operator",
          "28: import weakref",
          "29: from typing import TYPE_CHECKING, Any, Generator, Iterator, Sequence",
          "31: from airflow.compat.functools import cache",
          "32: from airflow.exceptions import (",
          "33:     AirflowDagCycleException,",
          "",
          "[Removed Lines]",
          "27: import re",
          "",
          "[Added Lines]",
          "30: import re2",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "166:         if self._group_id in self.used_group_ids:",
          "167:             if not add_suffix_on_collision:",
          "168:                 raise DuplicateTaskIdFound(f\"group_id '{self._group_id}' has already been added to the DAG\")",
          "170:             suffixes = sorted(",
          "172:                 for used_group_id in self.used_group_ids",
          "174:             )",
          "175:             if not suffixes:",
          "176:                 self._group_id += \"__1\"",
          "",
          "[Removed Lines]",
          "169:             base = re.split(r\"__\\d+$\", self._group_id)[0]",
          "171:                 int(re.split(r\"^.+__\", used_group_id)[1])",
          "173:                 if used_group_id is not None and re.match(rf\"^{base}__\\d+$\", used_group_id)",
          "",
          "[Added Lines]",
          "170:             base = re2.split(r\"__\\d+$\", self._group_id)[0]",
          "172:                 int(re2.split(r\"^.+__\", used_group_id)[1])",
          "174:                 if used_group_id is not None and re2.match(rf\"^{base}__\\d+$\", used_group_id)",
          "",
          "---------------"
        ],
        "airflow/www/fab_security/manager.py||airflow/www/fab_security/manager.py": [
          "File: airflow/www/fab_security/manager.py -> airflow/www/fab_security/manager.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: import datetime",
          "23: import json",
          "24: import logging",
          "26: from typing import Any",
          "27: from uuid import uuid4",
          "29: from flask import Flask, current_app, g, session, url_for",
          "30: from flask_appbuilder import AppBuilder",
          "31: from flask_appbuilder.const import (",
          "",
          "[Removed Lines]",
          "25: import re",
          "",
          "[Added Lines]",
          "28: import re2",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "703:     def _azure_parse_jwt(self, id_token):",
          "704:         jwt_token_parts = r\"^([^\\.\\s]*)\\.([^\\.\\s]+)\\.([^\\.\\s]*)$\"",
          "706:         if not matches or len(matches.groups()) < 3:",
          "707:             log.error(\"Unable to parse token.\")",
          "708:             return {}",
          "",
          "[Removed Lines]",
          "705:         matches = re.search(jwt_token_parts, id_token)",
          "",
          "[Added Lines]",
          "705:         matches = re2.search(jwt_token_parts, id_token)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "1372:     def _has_access_builtin_roles(self, role, action_name: str, resource_name: str) -> bool:",
          "1373:         \"\"\"Checks permission on builtin role\"\"\"",
          "1374:         perms = self.builtin_roles.get(role.name, [])",
          "1377:                 return True",
          "1378:         return False",
          "",
          "[Removed Lines]",
          "1375:         for (_resource_name, _action_name) in perms:",
          "1376:             if re.match(_resource_name, resource_name) and re.match(_action_name, action_name):",
          "",
          "[Added Lines]",
          "1375:         for _resource_name, _action_name in perms:",
          "1376:             if re2.match(_resource_name, resource_name) and re2.match(_action_name, action_name):",
          "",
          "---------------"
        ],
        "airflow/www/views.py||airflow/www/views.py": [
          "File: airflow/www/views.py -> airflow/www/views.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "24: import json",
          "25: import logging",
          "26: import math",
          "28: import sys",
          "29: import traceback",
          "30: import warnings",
          "",
          "[Removed Lines]",
          "27: import re",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "40: import lazy_object_proxy",
          "41: import markupsafe",
          "42: import nvd3",
          "43: import sqlalchemy as sqla",
          "44: from croniter import croniter",
          "45: from flask import (",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "42: import re2",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "2025:             return redirect(origin)",
          "2027:         regex = conf.get(\"scheduler\", \"allowed_run_id_pattern\")",
          "2030:                 flash(",
          "2031:                     f\"The provided run ID '{run_id}' is invalid. It does not match either \"",
          "2032:                     f\"the configured pattern: '{regex}' or the built-in pattern: '{RUN_ID_REGEX}'\",",
          "",
          "[Removed Lines]",
          "2028:         if run_id and not re.match(RUN_ID_REGEX, run_id):",
          "2029:             if not regex.strip() or not re.match(regex.strip(), run_id):",
          "",
          "[Added Lines]",
          "2028:         if run_id and not re2.match(RUN_ID_REGEX, run_id):",
          "2029:             if not regex.strip() or not re2.match(regex.strip(), run_id):",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "4508:         \"\"\"Duplicate Multiple connections\"\"\"",
          "4509:         for selected_conn in connections:",
          "4510:             new_conn_id = selected_conn.conn_id",
          "4513:             base_conn_id = selected_conn.conn_id",
          "4514:             if match:",
          "",
          "[Removed Lines]",
          "4511:             match = re.search(r\"_copy(\\d+)$\", selected_conn.conn_id)",
          "",
          "[Added Lines]",
          "4511:             match = re2.search(r\"_copy(\\d+)$\", selected_conn.conn_id)",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "4765:             return markupsafe.Markup(f'<a href=\"{url}\">{text}</a>')",
          "4767:         cd = markupsafe.escape(description)",
          "4770:         return markupsafe.Markup(cd)",
          "",
          "[Removed Lines]",
          "4768:         cd = re.sub(r\"`(.*)[\\s+]+&lt;(.*)&gt;`__\", _build_link, cd)",
          "4769:         cd = re.sub(r\"\\n\", r\"<br>\", cd)",
          "",
          "[Added Lines]",
          "4768:         cd = re2.sub(r\"`(.*)[\\s+]+&lt;(.*)&gt;`__\", _build_link, cd)",
          "4769:         cd = re2.sub(r\"\\n\", r\"<br>\", cd)",
          "",
          "---------------"
        ],
        "dev/breeze/src/airflow_breeze/pre_commit_ids.py||dev/breeze/src/airflow_breeze/pre_commit_ids.py": [
          "File: dev/breeze/src/airflow_breeze/pre_commit_ids.py -> dev/breeze/src/airflow_breeze/pre_commit_ids.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "68:     \"check-system-tests-present\",",
          "69:     \"check-system-tests-tocs\",",
          "70:     \"check-urlparse-usage-in-code\",",
          "71:     \"check-xml\",",
          "72:     \"codespell\",",
          "73:     \"compile-www-assets\",",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "71:     \"check-usage-of-re2-over-re\",",
          "",
          "---------------"
        ],
        "kubernetes_tests/test_base.py||kubernetes_tests/test_base.py": [
          "File: kubernetes_tests/test_base.py -> kubernetes_tests/test_base.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: from __future__ import annotations",
          "19: import os",
          "21: import subprocess",
          "22: import tempfile",
          "23: import time",
          "",
          "[Removed Lines]",
          "20: import re",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "26: from subprocess import check_call, check_output",
          "28: import pytest",
          "29: import requests",
          "30: import requests.exceptions",
          "31: from requests.adapters import HTTPAdapter",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "28: import re2",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "103:     def _num_pods_in_namespace(namespace):",
          "104:         air_pod = check_output([\"kubectl\", \"get\", \"pods\", \"-n\", namespace]).decode()",
          "105:         air_pod = air_pod.split(\"\\n\")",
          "107:         return len(names)",
          "109:     @staticmethod",
          "",
          "[Removed Lines]",
          "106:         names = [re.compile(r\"\\s+\").split(x)[0] for x in air_pod if \"airflow\" in x]",
          "",
          "[Added Lines]",
          "106:         names = [re2.compile(r\"\\s+\").split(x)[0] for x in air_pod if \"airflow\" in x]",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "111:         suffix = \"-\" + name if name else \"\"",
          "112:         air_pod = check_output([\"kubectl\", \"get\", \"pods\"]).decode()",
          "113:         air_pod = air_pod.split(\"\\n\")",
          "115:         if names:",
          "116:             check_call([\"kubectl\", \"delete\", \"pod\", names[0]])",
          "",
          "[Removed Lines]",
          "114:         names = [re.compile(r\"\\s+\").split(x)[0] for x in air_pod if \"airflow\" + suffix in x]",
          "",
          "[Added Lines]",
          "114:         names = [re2.compile(r\"\\s+\").split(x)[0] for x in air_pod if \"airflow\" + suffix in x]",
          "",
          "---------------"
        ],
        "tests/utils/log/test_secrets_masker.py||tests/utils/log/test_secrets_masker.py": [
          "File: tests/utils/log/test_secrets_masker.py -> tests/utils/log/test_secrets_masker.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "393:     def reset_secrets_masker_and_skip_escape(self):",
          "394:         self.secrets_masker = SecretsMasker()",
          "395:         with patch(\"airflow.utils.log.secrets_masker._secrets_masker\", return_value=self.secrets_masker):",
          "397:                 yield",
          "399:     def test_calling_mask_secret_adds_adaptations_for_returned_str(self):",
          "",
          "[Removed Lines]",
          "396:             with patch(\"airflow.utils.log.secrets_masker.re.escape\", lambda x: x):",
          "",
          "[Added Lines]",
          "396:             with patch(\"airflow.utils.log.secrets_masker.re2.escape\", lambda x: x):",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "185faab2112c4d3f736f8d40350401d8c1cac35b",
      "candidate_info": {
        "commit_hash": "185faab2112c4d3f736f8d40350401d8c1cac35b",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/185faab2112c4d3f736f8d40350401d8c1cac35b",
        "files": [
          "airflow/www/templates/airflow/config.html",
          "airflow/www/views.py",
          "newsfragments/28892.improvement.rst",
          "tests/www/views/test_views.py"
        ],
        "message": "Display only the running configuration in configurations view (#28892)\n\n* Display only the rendered configuration in the configurations view\n\n* Add back raw endpoint with deprecation warning\n\n* Show title\n\n* Add newsfragment\n\n* Fix tests",
        "before_after_code_files": [
          "airflow/www/templates/airflow/config.html||airflow/www/templates/airflow/config.html",
          "airflow/www/views.py||airflow/www/views.py",
          "tests/www/views/test_views.py||tests/www/views/test_views.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "airflow/www/views.py||airflow/www/views.py"
          ],
          "candidate": [
            "airflow/www/views.py||airflow/www/views.py"
          ]
        }
      },
      "candidate_diff": {
        "airflow/www/templates/airflow/config.html||airflow/www/templates/airflow/config.html": [
          "File: airflow/www/templates/airflow/config.html -> airflow/www/templates/airflow/config.html",
          "--- Hunk 1 ---",
          "[Context before]",
          "27:     {{ super() }}",
          "28:     <h2>{{ title }}</h2>",
          "48:         <div>",
          "49:             <table class=\"table table-striped table-bordered\">",
          "50:                 <tr>",
          "",
          "[Removed Lines]",
          "30:     {% if pre_subtitle %}",
          "31:         <pre>{{ pre_subtitle }}</pre>",
          "32:     {% endif %}",
          "34:     {% if subtitle %}",
          "35:         <h5>{{ subtitle }}</h5>",
          "36:     {% endif %}",
          "38:     {% if code_html %}",
          "39:         {{ code_html }}",
          "40:     {% endif %}",
          "42:     <hr>",
          "44:     {% if table %}",
          "45:         <br>",
          "46:         <h3>Running Configuration</h3>",
          "47:         <br>",
          "",
          "[Added Lines]",
          "30:     {% if hide_config_msg is defined %}",
          "31:         <div class=\"alert alert-info\">",
          "32:             <p>{{ hide_config_msg }}</p>",
          "33:         </div>",
          "34:     {% elif table %}",
          "",
          "---------------"
        ],
        "airflow/www/views.py||airflow/www/views.py": [
          "File: airflow/www/views.py -> airflow/www/views.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "3920:         \"\"\"Shows configuration.\"\"\"",
          "3921:         raw = request.args.get(\"raw\") == \"true\"",
          "3922:         title = \"Airflow Configuration\"",
          "3940:             table = [",
          "3941:                 (section, key, str(value), source)",
          "3943:                 for key, (value, source) in parameters.items()",
          "3944:             ]",
          "3958:             )",
          "3963:         else:",
          "3971:             return self.render_template(",
          "3972:                 \"airflow/config.html\",",
          "3975:                 title=title,",
          "3978:             )",
          "",
          "[Removed Lines]",
          "3923:         subtitle = AIRFLOW_CONFIG",
          "3925:         expose_config = conf.get(\"webserver\", \"expose_config\")",
          "3927:         # Don't show config when expose_config variable is False in airflow config",
          "3928:         # Don't show sensitive config values if expose_config variable is 'non-sensitive-only'",
          "3929:         # in airflow config",
          "3930:         if expose_config.lower() == \"non-sensitive-only\":",
          "3931:             from airflow.configuration import SENSITIVE_CONFIG_VALUES",
          "3933:             updater = configupdater.ConfigUpdater()",
          "3934:             updater.read(AIRFLOW_CONFIG)",
          "3935:             for sect, key in SENSITIVE_CONFIG_VALUES:",
          "3936:                 if updater.has_option(sect, key):",
          "3937:                     updater[sect][key].value = \"< hidden >\"",
          "3938:             config = str(updater)",
          "3942:                 for section, parameters in conf.as_dict(True, False).items()",
          "3945:         elif expose_config.lower() in [\"true\", \"t\", \"1\"]:",
          "3947:             with open(AIRFLOW_CONFIG) as file:",
          "3948:                 config = file.read()",
          "3949:             table = [",
          "3950:                 (section, key, str(value), source)",
          "3951:                 for section, parameters in conf.as_dict(True, True).items()",
          "3952:                 for key, (value, source) in parameters.items()",
          "3953:             ]",
          "3954:         else:",
          "3955:             config = (",
          "3956:                 \"# Your Airflow administrator chose not to expose the \"",
          "3957:                 \"configuration, most likely for security reasons.\"",
          "3959:             table = None",
          "3961:         if raw:",
          "3962:             return Response(response=config, status=200, mimetype=\"application/text\")",
          "3964:             code_html = Markup(",
          "3965:                 highlight(",
          "3966:                     config,",
          "3967:                     lexers.IniLexer(),  # Lexer call",
          "3968:                     HtmlFormatter(noclasses=True),",
          "3969:                 )",
          "3970:             )",
          "3973:                 pre_subtitle=settings.HEADER + \"  v\" + airflow.__version__,",
          "3974:                 code_html=code_html,",
          "3976:                 subtitle=subtitle,",
          "3977:                 table=table,",
          "",
          "[Added Lines]",
          "3923:         expose_config = conf.get(\"webserver\", \"expose_config\").lower()",
          "3925:         # TODO remove \"if raw\" usage in Airflow 3.0. Configuration can be fetched via the REST API.",
          "3926:         if raw:",
          "3927:             if expose_config == \"non-sensitive-only\":",
          "3928:                 from airflow.configuration import SENSITIVE_CONFIG_VALUES",
          "3930:                 updater = configupdater.ConfigUpdater()",
          "3931:                 updater.read(AIRFLOW_CONFIG)",
          "3932:                 for sect, key in SENSITIVE_CONFIG_VALUES:",
          "3933:                     if updater.has_option(sect, key):",
          "3934:                         updater[sect][key].value = \"< hidden >\"",
          "3935:                 config = str(updater)",
          "3936:             elif expose_config in {\"true\", \"t\", \"1\"}:",
          "3937:                 with open(AIRFLOW_CONFIG) as file:",
          "3938:                     config = file.read()",
          "3939:             else:",
          "3940:                 config = (",
          "3941:                     \"# Your Airflow administrator chose not to expose the configuration, \"",
          "3942:                     \"most likely for security reasons.\"",
          "3943:                 )",
          "3945:             return Response(",
          "3946:                 response=config,",
          "3947:                 status=200,",
          "3948:                 mimetype=\"application/text\",",
          "3949:                 headers={\"Deprecation\": \"Endpoint will be removed in Airflow 3.0, use the REST API instead.\"},",
          "3950:             )",
          "3952:         if expose_config in {\"non-sensitive-only\", \"true\", \"t\", \"1\"}:",
          "3953:             display_sensitive = expose_config != \"non-sensitive-only\"",
          "3957:                 for section, parameters in conf.as_dict(True, display_sensitive).items()",
          "3961:             return self.render_template(",
          "3962:                 template=\"airflow/config.html\",",
          "3963:                 title=title,",
          "3964:                 table=table,",
          "3971:                 hide_config_msg=(",
          "3972:                     \"Your Airflow administrator chose not to expose the configuration, \"",
          "3973:                     \"most likely for security reasons.\"",
          "3974:                 ),",
          "",
          "---------------"
        ],
        "tests/www/views/test_views.py||tests/www/views/test_views.py": [
          "File: tests/www/views/test_views.py -> tests/www/views/test_views.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "45:     check_content_in_response(",
          "46:         [",
          "47:             \"Airflow Configuration\",",
          "49:             \"most likely for security reasons.\",",
          "50:         ],",
          "51:         resp,",
          "",
          "[Removed Lines]",
          "48:             \"# Your Airflow administrator chose not to expose the configuration, \"",
          "",
          "[Added Lines]",
          "48:             \"Your Airflow administrator chose not to expose the configuration, \"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "59:     conf.validate()",
          "60:     with conf_vars({(\"webserver\", \"expose_config\"): \"True\"}):",
          "61:         resp = admin_client.get(\"configuration\", follow_redirects=True)",
          "65: def test_redoc_should_render_template(capture_templates, admin_client):",
          "",
          "[Removed Lines]",
          "62:     check_content_in_response([\"Airflow Configuration\", \"Running Configuration\"], resp)",
          "",
          "[Added Lines]",
          "62:     check_content_in_response([\"Airflow Configuration\"], resp)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "f5132681dcf6bdb03f1edd86bea293a1c262cdad",
      "candidate_info": {
        "commit_hash": "f5132681dcf6bdb03f1edd86bea293a1c262cdad",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/f5132681dcf6bdb03f1edd86bea293a1c262cdad",
        "files": [
          "airflow/config_templates/airflow_local_settings.py",
          "airflow/config_templates/default_webserver_config.py",
          "airflow/configuration.py",
          "airflow/listeners/events.py",
          "airflow/listeners/listener.py",
          "airflow/sensors/base.py",
          "airflow/sensors/bash.py",
          "airflow/sensors/date_time.py",
          "airflow/sensors/external_task.py",
          "airflow/sensors/time_delta.py",
          "airflow/sensors/time_sensor.py",
          "airflow/sensors/weekday.py",
          "airflow/task/task_runner/base_task_runner.py",
          "airflow/task/task_runner/cgroup_task_runner.py",
          "airflow/task/task_runner/standard_task_runner.py"
        ],
        "message": "Completed D400 for multiple folders (#27748)",
        "before_after_code_files": [
          "airflow/config_templates/airflow_local_settings.py||airflow/config_templates/airflow_local_settings.py",
          "airflow/config_templates/default_webserver_config.py||airflow/config_templates/default_webserver_config.py",
          "airflow/configuration.py||airflow/configuration.py",
          "airflow/listeners/events.py||airflow/listeners/events.py",
          "airflow/listeners/listener.py||airflow/listeners/listener.py",
          "airflow/sensors/base.py||airflow/sensors/base.py",
          "airflow/sensors/bash.py||airflow/sensors/bash.py",
          "airflow/sensors/date_time.py||airflow/sensors/date_time.py",
          "airflow/sensors/external_task.py||airflow/sensors/external_task.py",
          "airflow/sensors/time_delta.py||airflow/sensors/time_delta.py",
          "airflow/sensors/time_sensor.py||airflow/sensors/time_sensor.py",
          "airflow/sensors/weekday.py||airflow/sensors/weekday.py",
          "airflow/task/task_runner/base_task_runner.py||airflow/task/task_runner/base_task_runner.py",
          "airflow/task/task_runner/cgroup_task_runner.py||airflow/task/task_runner/cgroup_task_runner.py",
          "airflow/task/task_runner/standard_task_runner.py||airflow/task/task_runner/standard_task_runner.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "airflow/configuration.py||airflow/configuration.py"
          ],
          "candidate": [
            "airflow/configuration.py||airflow/configuration.py"
          ]
        }
      },
      "candidate_diff": {
        "airflow/config_templates/airflow_local_settings.py||airflow/config_templates/airflow_local_settings.py": [
          "File: airflow/config_templates/airflow_local_settings.py -> airflow/config_templates/airflow_local_settings.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "15: # KIND, either express or implied.  See the License for the",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "19: from __future__ import annotations",
          "21: import os",
          "",
          "[Removed Lines]",
          "18: \"\"\"Airflow logging settings\"\"\"",
          "",
          "[Added Lines]",
          "18: \"\"\"Airflow logging settings.\"\"\"",
          "",
          "---------------"
        ],
        "airflow/config_templates/default_webserver_config.py||airflow/config_templates/default_webserver_config.py": [
          "File: airflow/config_templates/default_webserver_config.py -> airflow/config_templates/default_webserver_config.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "15: # KIND, either express or implied.  See the License for the",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "19: from __future__ import annotations",
          "21: import os",
          "",
          "[Removed Lines]",
          "18: \"\"\"Default configuration for the Airflow webserver\"\"\"",
          "",
          "[Added Lines]",
          "18: \"\"\"Default configuration for the Airflow webserver.\"\"\"",
          "",
          "---------------"
        ],
        "airflow/configuration.py||airflow/configuration.py": [
          "File: airflow/configuration.py -> airflow/configuration.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "84: def expand_env_var(env_var: str | None) -> str | None:",
          "85:     \"\"\"",
          "89:     \"\"\"",
          "90:     if not env_var:",
          "91:         return env_var",
          "",
          "[Removed Lines]",
          "86:     Expands (potentially nested) env vars by repeatedly applying",
          "87:     `expandvars` and `expanduser` until interpolation stops having",
          "88:     any effect.",
          "",
          "[Added Lines]",
          "86:     Expands (potentially nested) env vars.",
          "88:     Repeat and apply `expandvars` and `expanduser` until",
          "89:     interpolation stops having any effect.",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "100: def run_command(command: str) -> str:",
          "102:     process = subprocess.Popen(",
          "103:         shlex.split(command), stdout=subprocess.PIPE, stderr=subprocess.PIPE, close_fds=True",
          "104:     )",
          "",
          "[Removed Lines]",
          "101:     \"\"\"Runs command and returns stdout\"\"\"",
          "",
          "[Added Lines]",
          "102:     \"\"\"Runs command and returns stdout.\"\"\"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "116: def _get_config_value_from_secret_backend(config_key: str) -> str | None:",
          "118:     try:",
          "119:         secrets_client = get_custom_secret_backend()",
          "120:         if not secrets_client:",
          "",
          "[Removed Lines]",
          "117:     \"\"\"Get Config option values from Secret Backend\"\"\"",
          "",
          "[Added Lines]",
          "118:     \"\"\"Get Config option values from Secret Backend.\"\"\"",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "137: def default_config_yaml() -> list[dict[str, Any]]:",
          "138:     \"\"\"",
          "141:     :return: Python dictionary containing configs & their info",
          "142:     \"\"\"",
          "",
          "[Removed Lines]",
          "139:     Read Airflow configs from YAML file",
          "",
          "[Added Lines]",
          "140:     Read Airflow configs from YAML file.",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "161: class AirflowConfigParser(ConfigParser):",
          "164:     # These configuration elements can be fetched as the stdout of commands",
          "165:     # following the \"{section}__{name}_cmd\" pattern, the idea behind this",
          "",
          "[Removed Lines]",
          "162:     \"\"\"Custom Airflow Configparser supporting defaults and deprecated options\"\"\"",
          "",
          "[Added Lines]",
          "163:     \"\"\"Custom Airflow Configparser supporting defaults and deprecated options.\"\"\"",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "371:     def _upgrade_auth_backends(self):",
          "372:         \"\"\"",
          "375:         \"\"\"",
          "376:         old_value = self.get(\"api\", \"auth_backends\", fallback=\"\")",
          "377:         if old_value in (\"airflow.api.auth.backend.default\", \"\"):",
          "",
          "[Removed Lines]",
          "373:         Ensure a custom auth_backends setting contains session,",
          "374:         which is needed by the UI for ajax queries.",
          "",
          "[Added Lines]",
          "374:         Ensure a custom auth_backends setting contains session.",
          "376:         This is required by the UI for ajax queries.",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "397:     def _upgrade_postgres_metastore_conn(self):",
          "398:         \"\"\"",
          "399:         As of SQLAlchemy 1.4, schemes `postgres+psycopg2` and `postgres`",
          "400:         must be replaced with `postgresql`.",
          "401:         \"\"\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "401:         Upgrade SQL schemas.",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "421:             os.environ.pop(old_env_var, None)",
          "423:     def _validate_enums(self):",
          "425:         for (section_key, option_key), enum_options in self.enums_options.items():",
          "426:             if self.has_option(section_key, option_key):",
          "427:                 value = self.get(section_key, option_key)",
          "",
          "[Removed Lines]",
          "424:         \"\"\"Validate that enum type config has an accepted value\"\"\"",
          "",
          "[Added Lines]",
          "428:         \"\"\"Validate that enum type config has an accepted value.\"\"\"",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "434:     def _validate_config_dependencies(self):",
          "435:         \"\"\"",
          "437:         or system-level limitations and requirements.",
          "438:         \"\"\"",
          "439:         is_executor_without_sqlite_support = self.get(\"core\", \"executor\") not in (",
          "",
          "[Removed Lines]",
          "436:         Validate that config values aren't invalid given other config values",
          "",
          "[Added Lines]",
          "440:         Validate that config based on condition.",
          "442:         Values are considered invalid when they conflict with other config values",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "521:         return None",
          "523:     def _get_secret_option(self, section: str, key: str) -> str | None:",
          "525:         fallback_key = key + \"_secret\"",
          "526:         if (section, key) in self.sensitive_config_values:",
          "527:             if super().has_option(section, fallback_key):",
          "",
          "[Removed Lines]",
          "524:         \"\"\"Get Config option values from Secret Backend\"\"\"",
          "",
          "[Added Lines]",
          "530:         \"\"\"Get Config option values from Secret Backend.\"\"\"",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "814:     def remove_option(self, section: str, option: str, remove_default: bool = True):",
          "815:         \"\"\"",
          "819:         \"\"\"",
          "820:         if super().has_option(section, option):",
          "821:             super().remove_option(section, option)",
          "",
          "[Removed Lines]",
          "816:         Remove an option if it exists in config from a file or",
          "817:         default config. If both of config have the same option, this removes",
          "818:         the option in both configs unless remove_default=False.",
          "",
          "[Added Lines]",
          "823:         Remove an option if it exists in config from a file or default config.",
          "825:         If both of config have the same option, this removes the option",
          "826:         in both configs unless remove_default=False.",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "826:     def getsection(self, section: str) -> ConfigOptionsDictType | None:",
          "827:         \"\"\"",
          "831:         :param section: section from the config",
          "832:         \"\"\"",
          "",
          "[Removed Lines]",
          "828:         Returns the section as a dict. Values are converted to int, float, bool",
          "829:         as required.",
          "",
          "[Added Lines]",
          "836:         Returns the section as a dict.",
          "838:         Values are converted to int, float, bool as required.",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "1071:         getter_func,",
          "1072:     ):",
          "1073:         \"\"\"",
          "1077:         This is necessary because bare configs take precedence over the command",
          "1078:         or secret key equivalents so if the current running config is",
          "",
          "[Removed Lines]",
          "1074:         Deletes default configs from current configuration (an OrderedDict of",
          "1075:         OrderedDicts) if it would conflict with special sensitive_config_values.",
          "",
          "[Added Lines]",
          "1083:         Deletes default configs from current configuration.",
          "1085:         An OrderedDict of OrderedDicts, if it would conflict with special sensitive_config_values.",
          "",
          "---------------",
          "--- Hunk 14 ---",
          "[Context before]",
          "1302: def get_airflow_home() -> str:",
          "1304:     return expand_env_var(os.environ.get(\"AIRFLOW_HOME\", \"~/airflow\"))",
          "1307: def get_airflow_config(airflow_home) -> str:",
          "1309:     airflow_config_var = os.environ.get(\"AIRFLOW_CONFIG\")",
          "1310:     if airflow_config_var is None:",
          "1311:         return os.path.join(airflow_home, \"airflow.cfg\")",
          "",
          "[Removed Lines]",
          "1303:     \"\"\"Get path to Airflow Home\"\"\"",
          "1308:     \"\"\"Get Path to airflow.cfg path\"\"\"",
          "",
          "[Added Lines]",
          "1313:     \"\"\"Get path to Airflow Home.\"\"\"",
          "1318:     \"\"\"Get Path to airflow.cfg path.\"\"\"",
          "",
          "---------------",
          "--- Hunk 15 ---",
          "[Context before]",
          "1327: def parameterized_config(template) -> str:",
          "1328:     \"\"\"",
          "1332:     :param template: a config content templated with {{variables}}",
          "1333:     \"\"\"",
          "",
          "[Removed Lines]",
          "1329:     Generates a configuration from the provided template + variables defined in",
          "1330:     current scope",
          "",
          "[Added Lines]",
          "1339:     Generates configuration from provided template & variables defined in current scope.",
          "",
          "---------------",
          "--- Hunk 16 ---",
          "[Context before]",
          "1338: def get_airflow_test_config(airflow_home) -> str:",
          "1340:     if \"AIRFLOW_TEST_CONFIG\" not in os.environ:",
          "1341:         return os.path.join(airflow_home, \"unittests.cfg\")",
          "1342:     # It will never return None",
          "",
          "[Removed Lines]",
          "1339:     \"\"\"Get path to unittests.cfg\"\"\"",
          "",
          "[Added Lines]",
          "1348:     \"\"\"Get path to unittests.cfg.\"\"\"",
          "",
          "---------------",
          "--- Hunk 17 ---",
          "[Context before]",
          "1433: # Historical convenience functions to access config entries",
          "1434: def load_test_config():",
          "1436:     warnings.warn(",
          "1437:         \"Accessing configuration method 'load_test_config' directly from the configuration module is \"",
          "1438:         \"deprecated. Please access the configuration from the 'configuration.conf' object via \"",
          "",
          "[Removed Lines]",
          "1435:     \"\"\"Historical load_test_config\"\"\"",
          "",
          "[Added Lines]",
          "1444:     \"\"\"Historical load_test_config.\"\"\"",
          "",
          "---------------",
          "--- Hunk 18 ---",
          "[Context before]",
          "1446: def get(*args, **kwargs) -> ConfigType | None:",
          "1448:     warnings.warn(",
          "1449:         \"Accessing configuration method 'get' directly from the configuration module is \"",
          "1450:         \"deprecated. Please access the configuration from the 'configuration.conf' object via \"",
          "",
          "[Removed Lines]",
          "1447:     \"\"\"Historical get\"\"\"",
          "",
          "[Added Lines]",
          "1456:     \"\"\"Historical get.\"\"\"",
          "",
          "---------------",
          "--- Hunk 19 ---",
          "[Context before]",
          "1458: def getboolean(*args, **kwargs) -> bool:",
          "1460:     warnings.warn(",
          "1461:         \"Accessing configuration method 'getboolean' directly from the configuration module is \"",
          "1462:         \"deprecated. Please access the configuration from the 'configuration.conf' object via \"",
          "",
          "[Removed Lines]",
          "1459:     \"\"\"Historical getboolean\"\"\"",
          "",
          "[Added Lines]",
          "1468:     \"\"\"Historical getboolean.\"\"\"",
          "",
          "---------------",
          "--- Hunk 20 ---",
          "[Context before]",
          "1470: def getfloat(*args, **kwargs) -> float:",
          "1472:     warnings.warn(",
          "1473:         \"Accessing configuration method 'getfloat' directly from the configuration module is \"",
          "1474:         \"deprecated. Please access the configuration from the 'configuration.conf' object via \"",
          "",
          "[Removed Lines]",
          "1471:     \"\"\"Historical getfloat\"\"\"",
          "",
          "[Added Lines]",
          "1480:     \"\"\"Historical getfloat.\"\"\"",
          "",
          "---------------",
          "--- Hunk 21 ---",
          "[Context before]",
          "1482: def getint(*args, **kwargs) -> int:",
          "1484:     warnings.warn(",
          "1485:         \"Accessing configuration method 'getint' directly from the configuration module is \"",
          "1486:         \"deprecated. Please access the configuration from the 'configuration.conf' object via \"",
          "",
          "[Removed Lines]",
          "1483:     \"\"\"Historical getint\"\"\"",
          "",
          "[Added Lines]",
          "1492:     \"\"\"Historical getint.\"\"\"",
          "",
          "---------------",
          "--- Hunk 22 ---",
          "[Context before]",
          "1494: def getsection(*args, **kwargs) -> ConfigOptionsDictType | None:",
          "1496:     warnings.warn(",
          "1497:         \"Accessing configuration method 'getsection' directly from the configuration module is \"",
          "1498:         \"deprecated. Please access the configuration from the 'configuration.conf' object via \"",
          "",
          "[Removed Lines]",
          "1495:     \"\"\"Historical getsection\"\"\"",
          "",
          "[Added Lines]",
          "1504:     \"\"\"Historical getsection.\"\"\"",
          "",
          "---------------",
          "--- Hunk 23 ---",
          "[Context before]",
          "1506: def has_option(*args, **kwargs) -> bool:",
          "1508:     warnings.warn(",
          "1509:         \"Accessing configuration method 'has_option' directly from the configuration module is \"",
          "1510:         \"deprecated. Please access the configuration from the 'configuration.conf' object via \"",
          "",
          "[Removed Lines]",
          "1507:     \"\"\"Historical has_option\"\"\"",
          "",
          "[Added Lines]",
          "1516:     \"\"\"Historical has_option.\"\"\"",
          "",
          "---------------",
          "--- Hunk 24 ---",
          "[Context before]",
          "1518: def remove_option(*args, **kwargs) -> bool:",
          "1520:     warnings.warn(",
          "1521:         \"Accessing configuration method 'remove_option' directly from the configuration module is \"",
          "1522:         \"deprecated. Please access the configuration from the 'configuration.conf' object via \"",
          "",
          "[Removed Lines]",
          "1519:     \"\"\"Historical remove_option\"\"\"",
          "",
          "[Added Lines]",
          "1528:     \"\"\"Historical remove_option.\"\"\"",
          "",
          "---------------",
          "--- Hunk 25 ---",
          "[Context before]",
          "1530: def as_dict(*args, **kwargs) -> ConfigSourcesType:",
          "1532:     warnings.warn(",
          "1533:         \"Accessing configuration method 'as_dict' directly from the configuration module is \"",
          "1534:         \"deprecated. Please access the configuration from the 'configuration.conf' object via \"",
          "",
          "[Removed Lines]",
          "1531:     \"\"\"Historical as_dict\"\"\"",
          "",
          "[Added Lines]",
          "1540:     \"\"\"Historical as_dict.\"\"\"",
          "",
          "---------------",
          "--- Hunk 26 ---",
          "[Context before]",
          "1542: def set(*args, **kwargs) -> None:",
          "1544:     warnings.warn(",
          "1545:         \"Accessing configuration method 'set' directly from the configuration module is \"",
          "1546:         \"deprecated. Please access the configuration from the 'configuration.conf' object via \"",
          "",
          "[Removed Lines]",
          "1543:     \"\"\"Historical set\"\"\"",
          "",
          "[Added Lines]",
          "1552:     \"\"\"Historical set.\"\"\"",
          "",
          "---------------",
          "--- Hunk 27 ---",
          "[Context before]",
          "1565: def get_custom_secret_backend() -> BaseSecretsBackend | None:",
          "1567:     secrets_backend_cls = conf.getimport(section=\"secrets\", key=\"backend\")",
          "1569:     if not secrets_backend_cls:",
          "",
          "[Removed Lines]",
          "1566:     \"\"\"Get Secret Backend if defined in airflow.cfg\"\"\"",
          "",
          "[Added Lines]",
          "1575:     \"\"\"Get Secret Backend if defined in airflow.cfg.\"\"\"",
          "",
          "---------------",
          "--- Hunk 28 ---",
          "[Context before]",
          "1588: def initialize_secrets_backends() -> list[BaseSecretsBackend]:",
          "1589:     \"\"\"",
          "1592:     \"\"\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1599:     Initialize secrets backend.",
          "",
          "---------------"
        ],
        "airflow/listeners/events.py||airflow/listeners/events.py": [
          "File: airflow/listeners/events.py -> airflow/listeners/events.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "73: def register_task_instance_state_events():",
          "75:     global _is_listening",
          "76:     if not _is_listening:",
          "77:         event.listen(Session, \"after_flush\", on_task_instance_state_session_flush)",
          "",
          "[Removed Lines]",
          "74:     \"\"\"Register a task instance state event\"\"\"",
          "",
          "[Added Lines]",
          "74:     \"\"\"Register a task instance state event.\"\"\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "81: def unregister_task_instance_state_events():",
          "83:     global _is_listening",
          "84:     event.remove(Session, \"after_flush\", on_task_instance_state_session_flush)",
          "85:     _is_listening = False",
          "",
          "[Removed Lines]",
          "82:     \"\"\"Unregister a task instance state event\"\"\"",
          "",
          "[Added Lines]",
          "82:     \"\"\"Unregister a task instance state event.\"\"\"",
          "",
          "---------------"
        ],
        "airflow/listeners/listener.py||airflow/listeners/listener.py": [
          "File: airflow/listeners/listener.py -> airflow/listeners/listener.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "68: def get_listener_manager() -> ListenerManager:",
          "70:     global _listener_manager",
          "71:     if not _listener_manager:",
          "72:         _listener_manager = ListenerManager()",
          "",
          "[Removed Lines]",
          "69:     \"\"\"Get singleton listener manager\"\"\"",
          "",
          "[Added Lines]",
          "69:     \"\"\"Get singleton listener manager.\"\"\"",
          "",
          "---------------"
        ],
        "airflow/sensors/base.py||airflow/sensors/base.py": [
          "File: airflow/sensors/base.py -> airflow/sensors/base.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "58: class PokeReturnValue:",
          "59:     \"\"\"",
          "60:     Sensors can optionally return an instance of the PokeReturnValue class in the poke method.",
          "61:     If an XCom value is supplied when the sensor is done, then the XCom value will be",
          "62:     pushed through the operator return value.",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "60:     Optional return value for poke methods.",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "158:                 )",
          "160:     def poke(self, context: Context) -> bool | PokeReturnValue:",
          "165:         raise AirflowException(\"Override me.\")",
          "167:     def execute(self, context: Context) -> Any:",
          "",
          "[Removed Lines]",
          "161:         \"\"\"",
          "162:         Function that the sensors defined while deriving this class should",
          "163:         override.",
          "164:         \"\"\"",
          "",
          "[Added Lines]",
          "163:         \"\"\"Function defined by the sensors while deriving this class should override.\"\"\"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "279: def poke_mode_only(cls):",
          "280:     \"\"\"",
          "284:     Will decorate all methods in the class to assert they did not change",
          "285:     the mode from 'poke'.",
          "",
          "[Removed Lines]",
          "281:     Class Decorator for child classes of BaseSensorOperator to indicate",
          "282:     that instances of this class are only safe to use poke mode.",
          "",
          "[Added Lines]",
          "280:     Decorate a subclass of BaseSensorOperator with poke.",
          "282:     Indicate that instances of this class are only safe to use poke mode.",
          "",
          "---------------"
        ],
        "airflow/sensors/bash.py||airflow/sensors/bash.py": [
          "File: airflow/sensors/bash.py -> airflow/sensors/bash.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "29: class BashSensor(BaseSensorOperator):",
          "30:     \"\"\"",
          "34:     :param bash_command: The command, set of commands or reference to a",
          "35:         bash script (must be '.sh') to be executed.",
          "",
          "[Removed Lines]",
          "31:     Executes a bash command/script and returns True if and only if the",
          "32:     return code is 0.",
          "",
          "[Added Lines]",
          "31:     Executes a bash command/script.",
          "33:     Return True if and only if the return code is 0.",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "55:         self.output_encoding = output_encoding",
          "57:     def poke(self, context: Context):",
          "62:         bash_command = self.bash_command",
          "63:         self.log.info(\"Tmp dir root location: \\n %s\", gettempdir())",
          "64:         with TemporaryDirectory(prefix=\"airflowtmp\") as tmp_dir:",
          "",
          "[Removed Lines]",
          "58:         \"\"\"",
          "59:         Execute the bash command in a temporary directory",
          "60:         which will be cleaned afterwards",
          "61:         \"\"\"",
          "",
          "[Added Lines]",
          "58:         \"\"\"Execute the bash command in a temporary directory.\"\"\"",
          "",
          "---------------"
        ],
        "airflow/sensors/date_time.py||airflow/sensors/date_time.py": [
          "File: airflow/sensors/date_time.py -> airflow/sensors/date_time.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "78: class DateTimeSensorAsync(DateTimeSensor):",
          "79:     \"\"\"",
          "83:     It is a drop-in replacement for DateTimeSensor.",
          "85:     :param target_time: datetime after which the job succeeds. (templated)",
          "",
          "[Removed Lines]",
          "80:     Waits until the specified datetime, deferring itself to avoid taking up",
          "81:     a worker slot while it is waiting.",
          "",
          "[Added Lines]",
          "80:     Waits until the specified datetime occurs.",
          "82:     Deferring itself to avoid taking up a worker slot while it is waiting.",
          "",
          "---------------"
        ],
        "airflow/sensors/external_task.py||airflow/sensors/external_task.py": [
          "File: airflow/sensors/external_task.py -> airflow/sensors/external_task.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "60: class ExternalTaskSensor(BaseSensorOperator):",
          "61:     \"\"\"",
          "65:     If both `external_task_group_id` and `external_task_id` are ``None`` (default), the sensor",
          "66:     waits for the DAG.",
          "67:     Values for `external_task_group_id` and `external_task_id` can't be set at the same time.",
          "70:     succeed, at which point it will also succeed. However, by default it will",
          "72:     until the sensor times out (thus giving you time to retry the external task",
          "",
          "[Removed Lines]",
          "62:     Waits for a different DAG, a task group, or a task in a different DAG to complete for a",
          "63:     specific logical date.",
          "69:     By default the ExternalTaskSensor will wait for the external task to",
          "",
          "[Added Lines]",
          "63:     Waits for a different DAG, task group, or task to complete for a specific logical date.",
          "69:     By default, the ExternalTaskSensor will wait for the external task to",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "288:     def get_count(self, dttm_filter, session, states) -> int:",
          "289:         \"\"\"",
          "292:         :param dttm_filter: date time filter for execution date",
          "293:         :param session: airflow session object",
          "",
          "[Removed Lines]",
          "290:         Get the count of records against dttm filter and states",
          "",
          "[Added Lines]",
          "290:         Get the count of records against dttm filter and states.",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "338:     def _handle_execution_date_fn(self, context) -> Any:",
          "339:         \"\"\"",
          "340:         This function is to handle backwards compatibility with how this operator was",
          "341:         previously where it only passes the execution date, but also allow for the newer",
          "342:         implementation to pass all context variables as keyword arguments, to allow",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "340:         Handle backward compatibility.",
          "",
          "---------------"
        ],
        "airflow/sensors/time_delta.py||airflow/sensors/time_delta.py": [
          "File: airflow/sensors/time_delta.py -> airflow/sensors/time_delta.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "50: class TimeDeltaSensorAsync(TimeDeltaSensor):",
          "51:     \"\"\"",
          "55:     :param delta: time length to wait after the data interval before succeeding.",
          "",
          "[Removed Lines]",
          "52:     A drop-in replacement for TimeDeltaSensor that defers itself to avoid",
          "53:     taking up a worker slot while it is waiting.",
          "",
          "[Added Lines]",
          "52:     A deferrable drop-in replacement for TimeDeltaSensor.",
          "54:     Will defers itself to avoid taking up a worker slot while it is waiting.",
          "",
          "---------------"
        ],
        "airflow/sensors/time_sensor.py||airflow/sensors/time_sensor.py": [
          "File: airflow/sensors/time_sensor.py -> airflow/sensors/time_sensor.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "49: class TimeSensorAsync(BaseSensorOperator):",
          "50:     \"\"\"",
          "54:     :param target_time: time after which the job succeeds",
          "",
          "[Removed Lines]",
          "51:     Waits until the specified time of the day, freeing up a worker slot while",
          "52:     it is waiting.",
          "",
          "[Added Lines]",
          "51:     Waits until the specified time of the day.",
          "53:     This frees up a worker slot while it is waiting.",
          "",
          "---------------"
        ],
        "airflow/sensors/weekday.py||airflow/sensors/weekday.py": [
          "File: airflow/sensors/weekday.py -> airflow/sensors/weekday.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "30: class DayOfWeekSensor(BaseSensorOperator):",
          "31:     \"\"\"",
          "",
          "[Removed Lines]",
          "32:     Waits until the first specified day of the week. For example, if the execution",
          "33:     day of the task is '2018-12-22' (Saturday) and you pass 'FRIDAY', the task will wait",
          "34:     until next Friday.",
          "",
          "[Added Lines]",
          "32:     Waits until the first specified day of the week.",
          "34:     For example, if the execution day of the task is '2018-12-22' (Saturday)",
          "35:     and you pass 'FRIDAY', the task will wait until next Friday.",
          "",
          "---------------"
        ],
        "airflow/task/task_runner/base_task_runner.py||airflow/task/task_runner/base_task_runner.py": [
          "File: airflow/task/task_runner/base_task_runner.py -> airflow/task/task_runner/base_task_runner.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "15: # KIND, either express or implied.  See the License for the",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "19: from __future__ import annotations",
          "21: import os",
          "",
          "[Removed Lines]",
          "18: \"\"\"Base task runner\"\"\"",
          "",
          "[Added Lines]",
          "18: \"\"\"Base task runner.\"\"\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "43: class BaseTaskRunner(LoggingMixin):",
          "44:     \"\"\"",
          "48:     :param local_task_job: The local task job associated with running the",
          "49:         associated task instance.",
          "",
          "[Removed Lines]",
          "45:     Runs Airflow task instances by invoking the `airflow tasks run` command with raw",
          "46:     mode enabled in a subprocess.",
          "",
          "[Added Lines]",
          "45:     Runs Airflow task instances via CLI.",
          "47:     Invoke the `airflow tasks run` command with raw mode enabled in a subprocess.",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "167:     def return_code(self, timeout: int = 0) -> int | None:",
          "168:         \"\"\"",
          "169:         :return: The return code associated with running the task instance or",
          "170:             None if the task is not yet done.",
          "171:         \"\"\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "170:         Extract the return code.",
          "",
          "---------------"
        ],
        "airflow/task/task_runner/cgroup_task_runner.py||airflow/task/task_runner/cgroup_task_runner.py": [
          "File: airflow/task/task_runner/cgroup_task_runner.py -> airflow/task/task_runner/cgroup_task_runner.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "15: # KIND, either express or implied.  See the License for the",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "19: from __future__ import annotations",
          "21: import datetime",
          "",
          "[Removed Lines]",
          "18: \"\"\"Task runner for cgroup to run Airflow task\"\"\"",
          "",
          "[Added Lines]",
          "18: \"\"\"Task runner for cgroup to run Airflow task.\"\"\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "34: class CgroupTaskRunner(BaseTaskRunner):",
          "35:     \"\"\"",
          "40:     Cgroup must be mounted first otherwise CgroupTaskRunner",
          "41:     will not be able to work.",
          "",
          "[Removed Lines]",
          "36:     Runs the raw Airflow task in a cgroup that has containment for memory and",
          "37:     cpu. It uses the resource requirements defined in the task to construct",
          "38:     the settings for the cgroup.",
          "",
          "[Added Lines]",
          "36:     Runs the raw Airflow task in a cgroup container.",
          "38:     With containment for memory and cpu. It uses the resource requirements",
          "39:      defined in the task to construct the settings for the cgroup.",
          "",
          "---------------"
        ],
        "airflow/task/task_runner/standard_task_runner.py||airflow/task/task_runner/standard_task_runner.py": [
          "File: airflow/task/task_runner/standard_task_runner.py -> airflow/task/task_runner/standard_task_runner.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "15: # KIND, either express or implied.  See the License for the",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "19: from __future__ import annotations",
          "21: import logging",
          "",
          "[Removed Lines]",
          "18: \"\"\"Standard task runner\"\"\"",
          "",
          "[Added Lines]",
          "18: \"\"\"Standard task runner.\"\"\"",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "090b5cf3efc42e5a2b773aae3126cfb55bb6054b",
      "candidate_info": {
        "commit_hash": "090b5cf3efc42e5a2b773aae3126cfb55bb6054b",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/090b5cf3efc42e5a2b773aae3126cfb55bb6054b",
        "files": [
          "airflow/config_templates/config.yml",
          "airflow/config_templates/default_airflow.cfg"
        ],
        "message": "Add descriptions for celery and dask cert configs (#31822)",
        "before_after_code_files": [
          "airflow/config_templates/default_airflow.cfg||airflow/config_templates/default_airflow.cfg"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "diff_branch_olp_changes": 1,
        "olp_code_files": {
          "patch": [
            "airflow/config_templates/default_airflow.cfg||airflow/config_templates/default_airflow.cfg"
          ],
          "candidate": [
            "airflow/config_templates/default_airflow.cfg||airflow/config_templates/default_airflow.cfg"
          ]
        }
      },
      "candidate_diff": {
        "airflow/config_templates/default_airflow.cfg||airflow/config_templates/default_airflow.cfg": [
          "File: airflow/config_templates/default_airflow.cfg -> airflow/config_templates/default_airflow.cfg",
          "--- Hunk 1 ---",
          "[Context before]",
          "1086: # Import path for celery configuration options",
          "1087: celery_config_options = airflow.config_templates.default_celery.DEFAULT_CELERY_CONFIG",
          "1088: ssl_active = False",
          "1089: ssl_key =",
          "1090: ssl_cert =",
          "1091: ssl_cacert =",
          "1093: # Celery Pool implementation.",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1090: # Path to the client key.",
          "1093: # Path to the client certificate.",
          "1096: # Path to the CA certificate.",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1144: # The IP address and port of the Dask cluster's scheduler.",
          "1145: cluster_address = 127.0.0.1:8786",
          "1148: tls_ca =",
          "1149: tls_cert =",
          "1150: tls_key =",
          "1152: [scheduler]",
          "",
          "[Removed Lines]",
          "1147: # TLS/ SSL settings to access a secured Dask scheduler.",
          "",
          "[Added Lines]",
          "1153: # Path to a CA certificate file encoded in PEM format to access a secured Dask scheduler.",
          "1156: # Path to a certificate file for the client, encoded in PEM format.",
          "1159: # Path to a key file for the client, encoded in PEM format.",
          "",
          "---------------"
        ]
      }
    }
  ]
}