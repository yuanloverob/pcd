{
  "cve_id": "CVE-2023-45348",
  "cve_desc": "Apache Airflow, versions 2.7.0 and 2.7.1, is affected by a vulnerability that allows an authenticated user to retrieve sensitive configuration information when the \"expose_config\" option is set to \"non-sensitive-only\". The `expose_config` option is False by default.\nIt is recommended to upgrade to a version that is not affected.",
  "repo": "apache/airflow",
  "patch_hash": "a4a0b5dd3d0ce05311c70bb9a32b66a650dbc0b4",
  "patch_info": {
    "commit_hash": "a4a0b5dd3d0ce05311c70bb9a32b66a650dbc0b4",
    "repo": "apache/airflow",
    "commit_url": "https://github.com/apache/airflow/commit/a4a0b5dd3d0ce05311c70bb9a32b66a650dbc0b4",
    "files": [
      "airflow/api_connexion/endpoints/config_endpoint.py",
      "airflow/configuration.py",
      "tests/api_connexion/endpoints/test_config_endpoint.py"
    ],
    "message": "Check if the lower of provided values are sensitives in config endpoint (#34712)\n\n* Check if the lower of provided values are sensitives in config endpoint\n\n* update unit test\n\n* ensure that all values in sensitive dict are in lower characters\n\n(cherry picked from commit f044589b685855a8fce8f5376bea2564c5a001f7)",
    "before_after_code_files": [
      "airflow/api_connexion/endpoints/config_endpoint.py||airflow/api_connexion/endpoints/config_endpoint.py",
      "airflow/configuration.py||airflow/configuration.py",
      "tests/api_connexion/endpoints/test_config_endpoint.py||tests/api_connexion/endpoints/test_config_endpoint.py"
    ]
  },
  "patch_diff": {
    "airflow/api_connexion/endpoints/config_endpoint.py||airflow/api_connexion/endpoints/config_endpoint.py": [
      "File: airflow/api_connexion/endpoints/config_endpoint.py -> airflow/api_connexion/endpoints/config_endpoint.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "123:                 \"Config not found.\", detail=f\"The option [{section}/{option}] is not found in config.\"",
      "124:             )",
      "127:             value = \"< hidden >\"",
      "128:         else:",
      "129:             value = conf.get(section, option)",
      "",
      "[Removed Lines]",
      "126:         if (section, option) in conf.sensitive_config_values:",
      "",
      "[Added Lines]",
      "126:         if (section.lower(), option.lower()) in conf.sensitive_config_values:",
      "",
      "---------------"
    ],
    "airflow/configuration.py||airflow/configuration.py": [
      "File: airflow/configuration.py -> airflow/configuration.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "311:             for s, s_c in self.configuration_description.items()",
      "312:             for k, item in s_c.get(\"options\").items()  # type: ignore[union-attr]",
      "313:         }",
      "315:         depr_option = {self.deprecated_options[x][:-1] for x in sensitive if x in self.deprecated_options}",
      "316:         depr_section = {",
      "317:             (self.deprecated_sections[s][0], k) for s, k in sensitive if s in self.deprecated_sections",
      "",
      "[Removed Lines]",
      "314:         sensitive = {(section, key) for (section, key), v in flattened.items() if v.get(\"sensitive\") is True}",
      "",
      "[Added Lines]",
      "314:         sensitive = {",
      "315:             (section.lower(), key.lower())",
      "316:             for (section, key), v in flattened.items()",
      "317:             if v.get(\"sensitive\") is True",
      "318:         }",
      "",
      "---------------"
    ],
    "tests/api_connexion/endpoints/test_config_endpoint.py||tests/api_connexion/endpoints/test_config_endpoint.py": [
      "File: tests/api_connexion/endpoints/test_config_endpoint.py -> tests/api_connexion/endpoints/test_config_endpoint.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "247:         return_value=MOCK_CONF_WITH_SENSITIVE_VALUE,",
      "248:     )",
      "249:     @conf_vars({(\"webserver\", \"expose_config\"): \"non-sensitive-only\"})",
      "251:         response = self.client.get(",
      "253:             headers={\"Accept\": \"text/plain\"},",
      "254:             environ_overrides={\"REMOTE_USER\": \"test\"},",
      "255:         )",
      "256:         assert response.status_code == 200",
      "257:         expected = textwrap.dedent(",
      "261:         \"\"\"",
      "262:         )",
      "263:         assert expected == response.data.decode()",
      "",
      "[Removed Lines]",
      "250:     def test_should_respond_200_text_plain_with_non_sensitive_only(self, mock_as_dict):",
      "252:             \"/api/v1/config/section/core/option/sql_alchemy_conn\",",
      "258:             \"\"\"\\",
      "259:         [core]",
      "260:         sql_alchemy_conn = < hidden >",
      "",
      "[Added Lines]",
      "250:     @pytest.mark.parametrize(",
      "251:         \"section, option\",",
      "252:         [",
      "253:             (\"core\", \"sql_alchemy_conn\"),",
      "254:             (\"core\", \"SQL_ALCHEMY_CONN\"),",
      "255:             (\"corE\", \"sql_alchemy_conn\"),",
      "256:             (\"CORE\", \"sql_alchemy_conn\"),",
      "257:         ],",
      "258:     )",
      "259:     def test_should_respond_200_text_plain_with_non_sensitive_only(self, mock_as_dict, section, option):",
      "261:             f\"/api/v1/config/section/{section}/option/{option}\",",
      "267:             f\"\"\"\\",
      "268:         [{section}]",
      "269:         {option} = < hidden >",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "739bfb44bf20281fac8e34b506f6e4a258f3d0bb",
      "candidate_info": {
        "commit_hash": "739bfb44bf20281fac8e34b506f6e4a258f3d0bb",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/739bfb44bf20281fac8e34b506f6e4a258f3d0bb",
        "files": [
          "dev/breeze/src/airflow_breeze/commands/release_management_commands.py",
          "dev/breeze/src/airflow_breeze/commands/setup_commands.py",
          "dev/breeze/src/airflow_breeze/commands/testing_commands.py",
          "dev/breeze/src/airflow_breeze/utils/run_utils.py",
          "dev/breeze/src/airflow_breeze/utils/selective_checks.py"
        ],
        "message": "Refactor: Simplify code in breeze (#33273)\n\n* Refactor: Simplify code in breeze\n\n---------\n\nCo-authored-by: Tzu-ping Chung <uranusjr@gmail.com>\n(cherry picked from commit 7c950a85b769e2c136c968bdbe103f87a2c45d3c)",
        "before_after_code_files": [
          "dev/breeze/src/airflow_breeze/commands/release_management_commands.py||dev/breeze/src/airflow_breeze/commands/release_management_commands.py",
          "dev/breeze/src/airflow_breeze/commands/setup_commands.py||dev/breeze/src/airflow_breeze/commands/setup_commands.py",
          "dev/breeze/src/airflow_breeze/commands/testing_commands.py||dev/breeze/src/airflow_breeze/commands/testing_commands.py",
          "dev/breeze/src/airflow_breeze/utils/run_utils.py||dev/breeze/src/airflow_breeze/utils/run_utils.py",
          "dev/breeze/src/airflow_breeze/utils/selective_checks.py||dev/breeze/src/airflow_breeze/utils/selective_checks.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/34775"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "dev/breeze/src/airflow_breeze/commands/release_management_commands.py||dev/breeze/src/airflow_breeze/commands/release_management_commands.py": [
          "File: dev/breeze/src/airflow_breeze/commands/release_management_commands.py -> dev/breeze/src/airflow_breeze/commands/release_management_commands.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1033: def is_package_in_dist(dist_files: list[str], package: str) -> bool:",
          "1034:     \"\"\"Check if package has been prepared in dist folder.\"\"\"",
          "1043: def get_prs_for_package(package_id: str) -> list[int]:",
          "",
          "[Removed Lines]",
          "1035:     for file in dist_files:",
          "1036:         if file.startswith(f'apache_airflow_providers_{package.replace(\".\", \"_\")}') or file.startswith(",
          "1037:             f'apache-airflow-providers-{package.replace(\".\", \"-\")}'",
          "1038:         ):",
          "1039:             return True",
          "1040:     return False",
          "",
          "[Added Lines]",
          "1035:     return any(",
          "1036:         file.startswith(",
          "1037:             (",
          "1038:                 f'apache_airflow_providers_{package.replace(\".\", \"_\")}',",
          "1039:                 f'apache-airflow-providers-{package.replace(\".\", \"-\")}',",
          "1040:             )",
          "1041:         )",
          "1042:         for file in dist_files",
          "1043:     )",
          "",
          "---------------"
        ],
        "dev/breeze/src/airflow_breeze/commands/setup_commands.py||dev/breeze/src/airflow_breeze/commands/setup_commands.py": [
          "File: dev/breeze/src/airflow_breeze/commands/setup_commands.py -> dev/breeze/src/airflow_breeze/commands/setup_commands.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "410:     results = {}",
          "411:     for line in hash_file_content.splitlines():",
          "412:         strip_line = line.strip()",
          "414:             continue",
          "415:         command = \":\".join(strip_line.split(\":\")[:-1])",
          "416:         the_hash = strip_line.split(\":\")[-1]",
          "",
          "[Removed Lines]",
          "413:         if strip_line.strip() == \"\" or strip_line.startswith(\"#\"):",
          "",
          "[Added Lines]",
          "413:         if not strip_line or strip_line.startswith(\"#\"):",
          "",
          "---------------"
        ],
        "dev/breeze/src/airflow_breeze/commands/testing_commands.py||dev/breeze/src/airflow_breeze/commands/testing_commands.py": [
          "File: dev/breeze/src/airflow_breeze/commands/testing_commands.py -> dev/breeze/src/airflow_breeze/commands/testing_commands.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "587:         env_variables[\"HELM_TEST_PACKAGE\"] = helm_test_package",
          "588:     perform_environment_checks()",
          "589:     cleanup_python_generated_files()",
          "592:     result = run_command(cmd, env=env_variables, check=False, output_outside_the_group=True)",
          "593:     sys.exit(result.returncode)",
          "",
          "[Removed Lines]",
          "590:     cmd = [*DOCKER_COMPOSE_COMMAND, \"run\", \"--service-ports\", \"--rm\", \"airflow\"]",
          "591:     cmd.extend(list(extra_pytest_args))",
          "",
          "[Added Lines]",
          "590:     cmd = [*DOCKER_COMPOSE_COMMAND, \"run\", \"--service-ports\", \"--rm\", \"airflow\", *extra_pytest_args]",
          "",
          "---------------"
        ],
        "dev/breeze/src/airflow_breeze/utils/run_utils.py||dev/breeze/src/airflow_breeze/utils/run_utils.py": [
          "File: dev/breeze/src/airflow_breeze/utils/run_utils.py -> dev/breeze/src/airflow_breeze/utils/run_utils.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "362: def filter_out_none(**kwargs) -> dict:",
          "363:     \"\"\"Filters out all None values from parameters passed.\"\"\"",
          "370: def check_if_image_exists(image: str) -> bool:",
          "",
          "[Removed Lines]",
          "364:     for key in list(kwargs):",
          "365:         if kwargs[key] is None:",
          "366:             kwargs.pop(key)",
          "367:     return kwargs",
          "",
          "[Added Lines]",
          "364:     return {key: val for key, val in kwargs.items() if val is not None}",
          "",
          "---------------"
        ],
        "dev/breeze/src/airflow_breeze/utils/selective_checks.py||dev/breeze/src/airflow_breeze/utils/selective_checks.py": [
          "File: dev/breeze/src/airflow_breeze/utils/selective_checks.py -> dev/breeze/src/airflow_breeze/utils/selective_checks.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "621:             get_console().print(",
          "622:                 \"[warning]There are no core/other files. Only tests relevant to the changed files are run.[/]\"",
          "623:             )",
          "625:         get_console().print(\"[warning]Selected test type candidates to run:[/]\")",
          "626:         get_console().print(sorted_candidate_test_types)",
          "627:         return sorted_candidate_test_types",
          "",
          "[Removed Lines]",
          "624:         sorted_candidate_test_types = list(sorted(candidate_test_types))",
          "",
          "[Added Lines]",
          "624:         sorted_candidate_test_types = sorted(candidate_test_types)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "714:         ):",
          "715:             return _ALL_DOCS_LIST",
          "716:         packages = []",
          "720:             packages.append(\"apache-airflow\")",
          "722:             packages.append(\"apache-airflow-providers\")",
          "724:             packages.append(\"helm-chart\")",
          "726:             packages.append(\"docker-stack\")",
          "727:         if providers_affected:",
          "728:             for provider in providers_affected:",
          "",
          "[Removed Lines]",
          "717:         if any(",
          "718:             [file.startswith(\"airflow/\") or file.startswith(\"docs/apache-airflow/\") for file in self._files]",
          "719:         ):",
          "721:         if any([file.startswith(\"docs/apache-airflow-providers/\") for file in self._files]):",
          "723:         if any([file.startswith(\"chart/\") or file.startswith(\"docs/helm-chart\") for file in self._files]):",
          "725:         if any([file.startswith(\"docs/docker-stack/\") for file in self._files]):",
          "",
          "[Added Lines]",
          "717:         if any(file.startswith((\"airflow/\", \"docs/apache-airflow/\")) for file in self._files):",
          "719:         if any(file.startswith(\"docs/apache-airflow-providers/\") for file in self._files):",
          "721:         if any(file.startswith((\"chart/\", \"docs/helm-chart\")) for file in self._files):",
          "723:         if any(file.startswith(\"docs/docker-stack/\") for file in self._files):",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "05e5ffd351c4928b87241f14750a0763d28352aa",
      "candidate_info": {
        "commit_hash": "05e5ffd351c4928b87241f14750a0763d28352aa",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/05e5ffd351c4928b87241f14750a0763d28352aa",
        "files": [
          ".github/workflows/ci.yml",
          "Dockerfile.ci",
          "dev/breeze/src/airflow_breeze/commands/developer_commands.py",
          "dev/breeze/src/airflow_breeze/commands/developer_commands_config.py",
          "dev/breeze/src/airflow_breeze/commands/testing_commands.py",
          "dev/breeze/src/airflow_breeze/commands/testing_commands_config.py",
          "dev/breeze/src/airflow_breeze/params/shell_params.py",
          "dev/breeze/src/airflow_breeze/utils/common_options.py",
          "dev/breeze/src/airflow_breeze/utils/docker_command_utils.py",
          "images/breeze/output-commands-hash.txt",
          "images/breeze/output_shell.svg",
          "images/breeze/output_testing_tests.svg",
          "scripts/ci/docker-compose/_docker.env",
          "scripts/ci/docker-compose/base.yml",
          "scripts/ci/docker-compose/devcontainer.env",
          "scripts/docker/entrypoint_ci.sh",
          "setup.cfg"
        ],
        "message": "Update min-sqlalchemy version to account for latest features used (#34293)\n\nSome of the recent sqlalchemy changes are not working with minimum\nversion of sqlalchemy of ours - for example `where` syntax does\nnot allow moe than one clause and we are already passing more\nin _do_delete_old_records (added in #33527). This syntax however\nwas added in SQL Alchemy 1.4.28 and our minimum version was\n1.4.27.\n\nThis change bumps the minimum SQLAlchemy version to 1.4.28 but it also\nadds a special test job that only runs on Postgres that downgrades\nthe SQLAlchemy to the minimum supported version (retrieved from\nsetup.cfg). This way, we will be able to detect such incompatible\nchanges at the PR time. This is a new flag `--downgrade-sqlalchemy`\non test command that works similar to earlier `--upgrade-boto`.\n\nWe also enable the `--upgrade-boto` and `--downgrade-sqlalchemy` flags\nto be used for `breeze shell` command - thanks to that we can\neasily test both flags with `breeze shell` command.\n\n(cherry picked from commit efbead9fe7462b3634b6d9c842bd9a7ac78a0207)",
        "before_after_code_files": [
          "Dockerfile.ci||Dockerfile.ci",
          "dev/breeze/src/airflow_breeze/commands/developer_commands.py||dev/breeze/src/airflow_breeze/commands/developer_commands.py",
          "dev/breeze/src/airflow_breeze/commands/developer_commands_config.py||dev/breeze/src/airflow_breeze/commands/developer_commands_config.py",
          "dev/breeze/src/airflow_breeze/commands/testing_commands.py||dev/breeze/src/airflow_breeze/commands/testing_commands.py",
          "dev/breeze/src/airflow_breeze/commands/testing_commands_config.py||dev/breeze/src/airflow_breeze/commands/testing_commands_config.py",
          "dev/breeze/src/airflow_breeze/params/shell_params.py||dev/breeze/src/airflow_breeze/params/shell_params.py",
          "dev/breeze/src/airflow_breeze/utils/common_options.py||dev/breeze/src/airflow_breeze/utils/common_options.py",
          "dev/breeze/src/airflow_breeze/utils/docker_command_utils.py||dev/breeze/src/airflow_breeze/utils/docker_command_utils.py",
          "scripts/ci/docker-compose/_docker.env||scripts/ci/docker-compose/_docker.env",
          "scripts/ci/docker-compose/devcontainer.env||scripts/ci/docker-compose/devcontainer.env",
          "scripts/docker/entrypoint_ci.sh||scripts/docker/entrypoint_ci.sh",
          "setup.cfg||setup.cfg"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/34775"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "Dockerfile.ci||Dockerfile.ci": [
          "File: Dockerfile.ci -> Dockerfile.ci",
          "--- Hunk 1 ---",
          "[Context before]",
          "937: fi",
          "939: rm -f \"${AIRFLOW_SOURCES}/pytest.ini\"",
          "941: set +u",
          "942: if [[ \"${RUN_TESTS}\" != \"true\" ]]; then",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "940: if [[ ${UPGRADE_BOTO=} == \"true\" ]]; then",
          "941:     echo",
          "942:     echo \"${COLOR_BLUE}Upgrading boto3, botocore to latest version to run Amazon tests with them${COLOR_RESET}\"",
          "943:     echo",
          "944:     pip uninstall --root-user-action ignore aiobotocore -y || true",
          "945:     pip install --root-user-action ignore --upgrade boto3 botocore",
          "946:     pip check",
          "947: fi",
          "948: if [[ ${DOWNGRADE_SQLALCHEMY=} == \"true\" ]]; then",
          "949:     min_sqlalchemy_version=$(grep \"sqlalchemy>=\" setup.cfg | sed \"s/.*>=\\([0-9\\.]*\\).*/\\1/\")",
          "950:     echo",
          "951:     echo \"${COLOR_BLUE}Downgrading sqlalchemy to minimum supported version: ${min_sqlalchemy_version}${COLOR_RESET}\"",
          "952:     echo",
          "953:     pip install --root-user-action ignore \"sqlalchemy==${min_sqlalchemy_version}\"",
          "954:     pip check",
          "955: fi",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1166:         exit 1",
          "1167:     fi",
          "1168: fi",
          "1176: readonly SELECTED_TESTS CLI_TESTS API_TESTS PROVIDERS_TESTS CORE_TESTS WWW_TESTS \\",
          "1177:     ALL_TESTS ALL_PRESELECTED_TESTS",
          "",
          "[Removed Lines]",
          "1169: if [[ ${UPGRADE_BOTO=} == \"true\" ]]; then",
          "1170:     echo",
          "1171:     echo \"${COLOR_BLUE}Upgrading boto3, botocore to latest version to run Amazon tests with them${COLOR_RESET}\"",
          "1172:     echo",
          "1173:     pip uninstall aiobotocore -y || true",
          "1174:     pip install --upgrade boto3 botocore",
          "1175: fi",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "dev/breeze/src/airflow_breeze/commands/developer_commands.py||dev/breeze/src/airflow_breeze/commands/developer_commands.py": [
          "File: dev/breeze/src/airflow_breeze/commands/developer_commands.py -> dev/breeze/src/airflow_breeze/commands/developer_commands.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "51:     option_celery_broker,",
          "52:     option_celery_flower,",
          "53:     option_db_reset,",
          "54:     option_dry_run,",
          "55:     option_executor,",
          "56:     option_force_build,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "54:     option_downgrade_sqlalchemy,",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "70:     option_platform_single,",
          "71:     option_postgres_version,",
          "72:     option_python,",
          "73:     option_use_airflow_version,",
          "74:     option_use_packages_from_dist,",
          "75:     option_verbose,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "74:     option_upgrade_boto,",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "162: @option_image_tag_for_running",
          "163: @option_max_time",
          "164: @option_include_mypy_volume",
          "165: @option_verbose",
          "166: @option_dry_run",
          "167: @option_github_repository",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "167: @option_upgrade_boto",
          "168: @option_downgrade_sqlalchemy",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "197:     celery_broker: str,",
          "198:     celery_flower: bool,",
          "199:     extra_args: tuple,",
          "200: ):",
          "201:     \"\"\"Enter breeze environment. this is the default command use when no other is selected.\"\"\"",
          "202:     if get_verbose() or get_dry_run():",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "204:     upgrade_boto: bool,",
          "205:     downgrade_sqlalchemy: bool,",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "234:         executor=executor,",
          "235:         celery_broker=celery_broker,",
          "236:         celery_flower=celery_flower,",
          "237:     )",
          "238:     sys.exit(result.returncode)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "243:         upgrade_boto=upgrade_boto,",
          "244:         downgrade_sqlalchemy=downgrade_sqlalchemy,",
          "",
          "---------------"
        ],
        "dev/breeze/src/airflow_breeze/commands/developer_commands_config.py||dev/breeze/src/airflow_breeze/commands/developer_commands_config.py": [
          "File: dev/breeze/src/airflow_breeze/commands/developer_commands_config.py -> dev/breeze/src/airflow_breeze/commands/developer_commands_config.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "99:                 \"--package-format\",",
          "100:             ],",
          "101:         },",
          "102:     ],",
          "103:     \"breeze compile-www-assets\": [",
          "104:         {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "102:         {",
          "103:             \"name\": \"Upgrading/downgrading selected packages\",",
          "104:             \"options\": [",
          "105:                 \"--upgrade-boto\",",
          "106:                 \"--downgrade-sqlalchemy\",",
          "107:             ],",
          "108:         },",
          "",
          "---------------"
        ],
        "dev/breeze/src/airflow_breeze/commands/testing_commands.py||dev/breeze/src/airflow_breeze/commands/testing_commands.py": [
          "File: dev/breeze/src/airflow_breeze/commands/testing_commands.py -> dev/breeze/src/airflow_breeze/commands/testing_commands.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "38:     option_backend,",
          "39:     option_db_reset,",
          "40:     option_debug_resources,",
          "41:     option_dry_run,",
          "42:     option_github_repository,",
          "43:     option_image_name,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "41:     option_downgrade_sqlalchemy,",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "52:     option_python,",
          "53:     option_run_in_parallel,",
          "54:     option_skip_cleanup,",
          "55:     option_use_airflow_version,",
          "56:     option_verbose,",
          "57: )",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "56:     option_upgrade_boto,",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "367:     show_default=True,",
          "368:     envvar=\"PARALLEL_TEST_TYPES\",",
          "369: )",
          "376: @click.option(",
          "377:     \"--collect-only\",",
          "378:     help=\"Collect tests only, do not run them.\",",
          "",
          "[Removed Lines]",
          "370: @click.option(",
          "371:     \"--upgrade-boto\",",
          "372:     help=\"Remove aiobotocore and upgrade botocore and boto to the latest version.\",",
          "373:     is_flag=True,",
          "374:     envvar=\"UPGRADE_BOTO\",",
          "375: )",
          "",
          "[Added Lines]",
          "372: @option_upgrade_boto",
          "373: @option_downgrade_sqlalchemy",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "416:     mount_sources: str,",
          "417:     extra_pytest_args: tuple,",
          "418:     upgrade_boto: bool,",
          "419:     collect_only: bool,",
          "420:     remove_arm_packages: bool,",
          "421:     github_repository: str,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "417:     downgrade_sqlalchemy: bool,",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "436:         forward_ports=False,",
          "437:         test_type=test_type,",
          "438:         upgrade_boto=upgrade_boto,",
          "439:         collect_only=collect_only,",
          "440:         remove_arm_packages=remove_arm_packages,",
          "441:         github_repository=github_repository,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "438:         downgrade_sqlalchemy=downgrade_sqlalchemy,",
          "",
          "---------------"
        ],
        "dev/breeze/src/airflow_breeze/commands/testing_commands_config.py||dev/breeze/src/airflow_breeze/commands/testing_commands_config.py": [
          "File: dev/breeze/src/airflow_breeze/commands/testing_commands_config.py -> dev/breeze/src/airflow_breeze/commands/testing_commands_config.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "56:                 \"--use-airflow-version\",",
          "57:                 \"--mount-sources\",",
          "58:                 \"--upgrade-boto\",",
          "59:                 \"--remove-arm-packages\",",
          "60:                 \"--skip-docker-compose-down\",",
          "61:             ],",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "59:                 \"--downgrade-sqlalchemy\",",
          "",
          "---------------"
        ],
        "dev/breeze/src/airflow_breeze/params/shell_params.py||dev/breeze/src/airflow_breeze/params/shell_params.py": [
          "File: dev/breeze/src/airflow_breeze/params/shell_params.py -> dev/breeze/src/airflow_breeze/params/shell_params.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "120:     dry_run: bool = False",
          "121:     verbose: bool = False",
          "122:     upgrade_boto: bool = False",
          "123:     executor: str = START_AIRFLOW_DEFAULT_ALLOWED_EXECUTORS",
          "124:     celery_broker: str = DEFAULT_CELERY_BROKER",
          "125:     celery_flower: bool = False",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "123:     downgrade_sqlalchemy: bool = False",
          "",
          "---------------"
        ],
        "dev/breeze/src/airflow_breeze/utils/common_options.py||dev/breeze/src/airflow_breeze/utils/common_options.py": [
          "File: dev/breeze/src/airflow_breeze/utils/common_options.py -> dev/breeze/src/airflow_breeze/utils/common_options.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "601:     help=\"Optional additional requirements to upgrade eagerly to avoid backtracking \"",
          "602:     \"(see `breeze ci find-backtracking-candidates`).\",",
          "603: )",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "604: option_upgrade_boto = click.option(",
          "605:     \"--upgrade-boto\",",
          "606:     help=\"Remove aiobotocore and upgrade botocore and boto to the latest version.\",",
          "607:     is_flag=True,",
          "608:     envvar=\"UPGRADE_BOTO\",",
          "609: )",
          "610: option_downgrade_sqlalchemy = click.option(",
          "611:     \"--downgrade-sqlalchemy\",",
          "612:     help=\"Downgrade SQLAlchemy to minimum supported version.\",",
          "613:     is_flag=True,",
          "614:     envvar=\"DOWNGRADE_SQLALCHEMY\",",
          "615: )",
          "",
          "---------------"
        ],
        "dev/breeze/src/airflow_breeze/utils/docker_command_utils.py||dev/breeze/src/airflow_breeze/utils/docker_command_utils.py": [
          "File: dev/breeze/src/airflow_breeze/utils/docker_command_utils.py -> dev/breeze/src/airflow_breeze/utils/docker_command_utils.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "597:     set_value_to_default_if_not_set(env, \"TEST_TYPE\", \"\")",
          "598:     set_value_to_default_if_not_set(env, \"TEST_TIMEOUT\", \"60\")",
          "599:     set_value_to_default_if_not_set(env, \"UPGRADE_BOTO\", \"false\")",
          "600:     set_value_to_default_if_not_set(env, \"UPGRADE_TO_NEWER_DEPENDENCIES\", \"false\")",
          "601:     set_value_to_default_if_not_set(env, \"USE_PACKAGES_FROM_DIST\", \"false\")",
          "602:     set_value_to_default_if_not_set(env, \"VERBOSE\", \"false\")",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "600:     set_value_to_default_if_not_set(env, \"DOWNGRADE_SQLALCHEMY\", \"false\")",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "644:     \"SQLITE_URL\": \"sqlite_url\",",
          "645:     \"START_AIRFLOW\": \"start_airflow\",",
          "646:     \"UPGRADE_BOTO\": \"upgrade_boto\",",
          "647:     \"USE_AIRFLOW_VERSION\": \"use_airflow_version\",",
          "648:     \"USE_PACKAGES_FROM_DIST\": \"use_packages_from_dist\",",
          "649:     \"VERSION_SUFFIX_FOR_PYPI\": \"version_suffix_for_pypi\",",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "648:     \"DOWNGRADE_SQLALCHEMY\": \"downgrade_sqlalchemy\",",
          "",
          "---------------"
        ],
        "scripts/ci/docker-compose/_docker.env||scripts/ci/docker-compose/_docker.env": [
          "File: scripts/ci/docker-compose/_docker.env -> scripts/ci/docker-compose/_docker.env",
          "--- Hunk 1 ---",
          "[Context before]",
          "75: TEST_TYPE",
          "76: UPGRADE_BOTO",
          "77: UPGRADE_TO_NEWER_DEPENDENCIES",
          "78: VERBOSE",
          "79: VERBOSE_COMMANDS",
          "80: VERSION_SUFFIX_FOR_PYPI",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "78: DOWNGRADE_SQLALCHEMY",
          "",
          "---------------"
        ],
        "scripts/ci/docker-compose/devcontainer.env||scripts/ci/docker-compose/devcontainer.env": [
          "File: scripts/ci/docker-compose/devcontainer.env -> scripts/ci/docker-compose/devcontainer.env",
          "--- Hunk 1 ---",
          "[Context before]",
          "69: SUSPENDED_PROVIDERS_FOLDERS=\"\"",
          "70: TEST_TYPE=",
          "71: UPGRADE_BOTO=\"false\"",
          "72: UPGRADE_TO_NEWER_DEPENDENCIES=\"false\"",
          "73: VERBOSE=\"false\"",
          "74: VERBOSE_COMMANDS=\"false\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "72: DOWNGRADE_SQLALCHEMY=\"false\"",
          "",
          "---------------"
        ],
        "scripts/docker/entrypoint_ci.sh||scripts/docker/entrypoint_ci.sh": [
          "File: scripts/docker/entrypoint_ci.sh -> scripts/docker/entrypoint_ci.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "326: # Remove pytest.ini from the current directory if it exists. It has been removed from the source tree",
          "327: # but may still be present in the local directory if the user has old breeze image",
          "328: rm -f \"${AIRFLOW_SOURCES}/pytest.ini\"",
          "330: set +u",
          "331: # If we do not want to run tests, we simply drop into bash",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "329: if [[ ${UPGRADE_BOTO=} == \"true\" ]]; then",
          "330:     echo",
          "331:     echo \"${COLOR_BLUE}Upgrading boto3, botocore to latest version to run Amazon tests with them${COLOR_RESET}\"",
          "332:     echo",
          "333:     pip uninstall --root-user-action ignore aiobotocore -y || true",
          "334:     pip install --root-user-action ignore --upgrade boto3 botocore",
          "335:     pip check",
          "336: fi",
          "337: if [[ ${DOWNGRADE_SQLALCHEMY=} == \"true\" ]]; then",
          "338:     min_sqlalchemy_version=$(grep \"sqlalchemy>=\" setup.cfg | sed \"s/.*>=\\([0-9\\.]*\\).*/\\1/\")",
          "339:     echo",
          "340:     echo \"${COLOR_BLUE}Downgrading sqlalchemy to minimum supported version: ${min_sqlalchemy_version}${COLOR_RESET}\"",
          "341:     echo",
          "342:     pip install --root-user-action ignore \"sqlalchemy==${min_sqlalchemy_version}\"",
          "343:     pip check",
          "344: fi",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "558:         exit 1",
          "559:     fi",
          "560: fi",
          "568: readonly SELECTED_TESTS CLI_TESTS API_TESTS PROVIDERS_TESTS CORE_TESTS WWW_TESTS \\",
          "569:     ALL_TESTS ALL_PRESELECTED_TESTS",
          "",
          "[Removed Lines]",
          "561: if [[ ${UPGRADE_BOTO=} == \"true\" ]]; then",
          "562:     echo",
          "563:     echo \"${COLOR_BLUE}Upgrading boto3, botocore to latest version to run Amazon tests with them${COLOR_RESET}\"",
          "564:     echo",
          "565:     pip uninstall aiobotocore -y || true",
          "566:     pip install --upgrade boto3 botocore",
          "567: fi",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "setup.cfg||setup.cfg": [
          "File: setup.cfg -> setup.cfg",
          "--- Hunk 1 ---",
          "[Context before]",
          "142:     # See https://sqlalche.me/e/b8d9 for details of deprecated features",
          "143:     # you can set environment variable SQLALCHEMY_WARN_20=1 to show all deprecation warnings.",
          "144:     # The issue tracking it is https://github.com/apache/airflow/issues/28723",
          "146:     sqlalchemy_jsonfield>=1.0",
          "147:     tabulate>=0.7.5",
          "148:     tenacity>=6.2.0,!=8.2.0",
          "",
          "[Removed Lines]",
          "145:     sqlalchemy>=1.4.24,<2.0",
          "",
          "[Added Lines]",
          "145:     sqlalchemy>=1.4.28,<2.0",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "b9b7a40168413cd3f4b5c09e2006ad9eab0d8282",
      "candidate_info": {
        "commit_hash": "b9b7a40168413cd3f4b5c09e2006ad9eab0d8282",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/b9b7a40168413cd3f4b5c09e2006ad9eab0d8282",
        "files": [
          "airflow/api_connexion/endpoints/dag_source_endpoint.py",
          "airflow/api_connexion/schemas/dag_schema.py",
          "airflow/cli/cli_config.py",
          "airflow/cli/commands/connection_command.py",
          "airflow/dag_processing/processor.py",
          "airflow/operators/python.py",
          "airflow/serialization/serialized_objects.py",
          "airflow/utils/db_cleanup.py",
          "airflow/utils/log/secrets_masker.py",
          "airflow/www/extensions/init_manifest_files.py"
        ],
        "message": "Use literal dict instead of calling dict() in Airflow core (#33762)\n\n(cherry picked from commit 1e81ed19997114cc7dc136e9fd64676a7710715a)",
        "before_after_code_files": [
          "airflow/api_connexion/endpoints/dag_source_endpoint.py||airflow/api_connexion/endpoints/dag_source_endpoint.py",
          "airflow/api_connexion/schemas/dag_schema.py||airflow/api_connexion/schemas/dag_schema.py",
          "airflow/cli/cli_config.py||airflow/cli/cli_config.py",
          "airflow/cli/commands/connection_command.py||airflow/cli/commands/connection_command.py",
          "airflow/dag_processing/processor.py||airflow/dag_processing/processor.py",
          "airflow/operators/python.py||airflow/operators/python.py",
          "airflow/serialization/serialized_objects.py||airflow/serialization/serialized_objects.py",
          "airflow/utils/db_cleanup.py||airflow/utils/db_cleanup.py",
          "airflow/utils/log/secrets_masker.py||airflow/utils/log/secrets_masker.py",
          "airflow/www/extensions/init_manifest_files.py||airflow/www/extensions/init_manifest_files.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/34775"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/api_connexion/endpoints/dag_source_endpoint.py||airflow/api_connexion/endpoints/dag_source_endpoint.py": [
          "File: airflow/api_connexion/endpoints/dag_source_endpoint.py -> airflow/api_connexion/endpoints/dag_source_endpoint.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "43:     if return_type == \"text/plain\":",
          "44:         return Response(dag_source, headers={\"Content-Type\": return_type})",
          "45:     if return_type == \"application/json\":",
          "47:         return Response(content, headers={\"Content-Type\": return_type})",
          "48:     return Response(\"Not Allowed Accept Header\", status=HTTPStatus.NOT_ACCEPTABLE)",
          "",
          "[Removed Lines]",
          "46:         content = dag_source_schema.dumps(dict(content=dag_source))",
          "",
          "[Added Lines]",
          "46:         content = dag_source_schema.dumps({\"content\": dag_source})",
          "",
          "---------------"
        ],
        "airflow/api_connexion/schemas/dag_schema.py||airflow/api_connexion/schemas/dag_schema.py": [
          "File: airflow/api_connexion/schemas/dag_schema.py -> airflow/api_connexion/schemas/dag_schema.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "120:         \"\"\"Dump tags as objects.\"\"\"",
          "121:         tags = obj.tags",
          "122:         if tags:",
          "124:         return []",
          "126:     @staticmethod",
          "",
          "[Removed Lines]",
          "123:             return [DagTagSchema().dump(dict(name=tag)) for tag in tags]",
          "",
          "[Added Lines]",
          "123:             return [DagTagSchema().dump({\"name\": tag}) for tag in tags]",
          "",
          "---------------"
        ],
        "airflow/cli/cli_config.py||airflow/cli/cli_config.py": [
          "File: airflow/cli/cli_config.py -> airflow/cli/cli_config.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "2209:         name=\"standalone\",",
          "2210:         help=\"Run an all-in-one copy of Airflow\",",
          "2211:         func=lazy_load_command(\"airflow.cli.commands.standalone_command.standalone\"),",
          "2213:     ),",
          "2214: ]",
          "",
          "[Removed Lines]",
          "2212:         args=tuple(),",
          "",
          "[Added Lines]",
          "2212:         args=(),",
          "",
          "---------------"
        ],
        "airflow/cli/commands/connection_command.py||airflow/cli/commands/connection_command.py": [
          "File: airflow/cli/commands/connection_command.py -> airflow/cli/commands/connection_command.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "98: def _connection_to_dict(conn: Connection) -> dict:",
          "111: def create_default_connections(args):",
          "",
          "[Removed Lines]",
          "99:     return dict(",
          "100:         conn_type=conn.conn_type,",
          "101:         description=conn.description,",
          "102:         login=conn.login,",
          "103:         password=conn.password,",
          "104:         host=conn.host,",
          "105:         port=conn.port,",
          "106:         schema=conn.schema,",
          "107:         extra=conn.extra,",
          "108:     )",
          "",
          "[Added Lines]",
          "99:     return {",
          "100:         \"conn_type\": conn.conn_type,",
          "101:         \"description\": conn.description,",
          "102:         \"login\": conn.login,",
          "103:         \"password\": conn.password,",
          "104:         \"host\": conn.host,",
          "105:         \"port\": conn.port,",
          "106:         \"schema\": conn.schema,",
          "107:         \"extra\": conn.extra,",
          "108:     }",
          "",
          "---------------"
        ],
        "airflow/dag_processing/processor.py||airflow/dag_processing/processor.py": [
          "File: airflow/dag_processing/processor.py -> airflow/dag_processing/processor.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "628:         for filename, stacktrace in import_errors.items():",
          "629:             if filename in existing_import_error_files:",
          "630:                 session.query(errors.ImportError).filter(errors.ImportError.filename == filename).update(",
          "632:                     synchronize_session=\"fetch\",",
          "633:                 )",
          "634:             else:",
          "",
          "[Removed Lines]",
          "631:                     dict(filename=filename, timestamp=timezone.utcnow(), stacktrace=stacktrace),",
          "",
          "[Added Lines]",
          "631:                     {\"filename\": filename, \"timestamp\": timezone.utcnow(), \"stacktrace\": stacktrace},",
          "",
          "---------------"
        ],
        "airflow/operators/python.py||airflow/operators/python.py": [
          "File: airflow/operators/python.py -> airflow/operators/python.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "430:         self._write_args(input_path)",
          "431:         self._write_string_args(string_args_path)",
          "432:         write_python_script(",
          "441:             filename=os.fspath(script_path),",
          "442:             render_template_as_native_obj=self.dag.render_template_as_native_obj,",
          "443:         )",
          "",
          "[Removed Lines]",
          "433:             jinja_context=dict(",
          "434:                 op_args=self.op_args,",
          "435:                 op_kwargs=op_kwargs,",
          "436:                 expect_airflow=self.expect_airflow,",
          "437:                 pickling_library=self.pickling_library.__name__,",
          "438:                 python_callable=self.python_callable.__name__,",
          "439:                 python_callable_source=self.get_python_source(),",
          "440:             ),",
          "",
          "[Added Lines]",
          "433:             jinja_context={",
          "434:                 \"op_args\": self.op_args,",
          "435:                 \"op_kwargs\": op_kwargs,",
          "436:                 \"expect_airflow\": self.expect_airflow,",
          "437:                 \"pickling_library\": self.pickling_library.__name__,",
          "438:                 \"python_callable\": self.python_callable.__name__,",
          "439:                 \"python_callable_source\": self.get_python_source(),",
          "440:             },",
          "",
          "---------------"
        ],
        "airflow/serialization/serialized_objects.py||airflow/serialization/serialized_objects.py": [
          "File: airflow/serialization/serialized_objects.py -> airflow/serialization/serialized_objects.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "476:         elif isinstance(var, XComArg):",
          "477:             return cls._encode(serialize_xcom_arg(var), type_=DAT.XCOM_REF)",
          "478:         elif isinstance(var, Dataset):",
          "480:         elif isinstance(var, SimpleTaskInstance):",
          "481:             return cls._encode(",
          "482:                 cls.serialize(var.__dict__, strict=strict, use_pydantic_models=use_pydantic_models),",
          "",
          "[Removed Lines]",
          "479:             return cls._encode(dict(uri=var.uri, extra=var.extra), type_=DAT.DATASET)",
          "",
          "[Added Lines]",
          "479:             return cls._encode({\"uri\": var.uri, \"extra\": var.extra}, type_=DAT.DATASET)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "617:     @classmethod",
          "618:     def _serialize_param(cls, param: Param):",
          "626:     @classmethod",
          "627:     def _deserialize_param(cls, param_dict: dict):",
          "",
          "[Removed Lines]",
          "619:         return dict(",
          "620:             __class=f\"{param.__module__}.{param.__class__.__name__}\",",
          "621:             default=cls.serialize(param.value),",
          "622:             description=cls.serialize(param.description),",
          "623:             schema=cls.serialize(param.schema),",
          "624:         )",
          "",
          "[Added Lines]",
          "619:         return {",
          "620:             \"__class\": f\"{param.__module__}.{param.__class__.__name__}\",",
          "621:             \"default\": cls.serialize(param.value),",
          "622:             \"description\": cls.serialize(param.description),",
          "623:             \"schema\": cls.serialize(param.schema),",
          "624:         }",
          "",
          "---------------"
        ],
        "airflow/utils/db_cleanup.py||airflow/utils/db_cleanup.py": [
          "File: airflow/utils/db_cleanup.py -> airflow/utils/db_cleanup.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "84:     @property",
          "85:     def readable_config(self):",
          "95: config_list: list[_TableConfig] = [",
          "",
          "[Removed Lines]",
          "86:         return dict(",
          "87:             table=self.orm_model.name,",
          "88:             recency_column=str(self.recency_column),",
          "89:             keep_last=self.keep_last,",
          "90:             keep_last_filters=[str(x) for x in self.keep_last_filters] if self.keep_last_filters else None,",
          "91:             keep_last_group_by=str(self.keep_last_group_by),",
          "92:         )",
          "",
          "[Added Lines]",
          "86:         return {",
          "87:             \"table\": self.orm_model.name,",
          "88:             \"recency_column\": str(self.recency_column),",
          "89:             \"keep_last\": self.keep_last,",
          "90:             \"keep_last_filters\": [str(x) for x in self.keep_last_filters] if self.keep_last_filters else None,",
          "91:             \"keep_last_group_by\": str(self.keep_last_group_by),",
          "92:         }",
          "",
          "---------------"
        ],
        "airflow/utils/log/secrets_masker.py||airflow/utils/log/secrets_masker.py": [
          "File: airflow/utils/log/secrets_masker.py -> airflow/utils/log/secrets_masker.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "176:             __file__,",
          "177:             1,",
          "178:             \"\",",
          "180:             exc_info=None,",
          "181:             func=\"funcname\",",
          "182:         )",
          "",
          "[Removed Lines]",
          "179:             tuple(),",
          "",
          "[Added Lines]",
          "179:             (),",
          "",
          "---------------"
        ],
        "airflow/www/extensions/init_manifest_files.py||airflow/www/extensions/init_manifest_files.py": [
          "File: airflow/www/extensions/init_manifest_files.py -> airflow/www/extensions/init_manifest_files.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "56:         static/dist folder. This template tag reads the asset name in",
          "57:         ``manifest.json`` and returns the appropriate file.",
          "58:         \"\"\"",
          "",
          "[Removed Lines]",
          "59:         return dict(url_for_asset=get_asset_url)",
          "",
          "[Added Lines]",
          "59:         return {\"url_for_asset\": get_asset_url}",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "de5ec9b58bee9b7c9478ecce3153935815c43563",
      "candidate_info": {
        "commit_hash": "de5ec9b58bee9b7c9478ecce3153935815c43563",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/de5ec9b58bee9b7c9478ecce3153935815c43563",
        "files": [
          "airflow/www/api/experimental/endpoints.py",
          "airflow/www/extensions/init_appbuilder.py",
          "airflow/www/extensions/init_views.py",
          "airflow/www/extensions/init_wsgi_middlewares.py",
          "airflow/www/fab_security/manager.py",
          "airflow/www/security.py",
          "airflow/www/utils.py",
          "airflow/www/views.py"
        ],
        "message": "Improve importing the modules in Airflow www package (#33810)\n\n(cherry picked from commit b470c6bdcc801bcd57c4008a823bd768405d1736)",
        "before_after_code_files": [
          "airflow/www/api/experimental/endpoints.py||airflow/www/api/experimental/endpoints.py",
          "airflow/www/extensions/init_appbuilder.py||airflow/www/extensions/init_appbuilder.py",
          "airflow/www/extensions/init_views.py||airflow/www/extensions/init_views.py",
          "airflow/www/extensions/init_wsgi_middlewares.py||airflow/www/extensions/init_wsgi_middlewares.py",
          "airflow/www/fab_security/manager.py||airflow/www/fab_security/manager.py",
          "airflow/www/security.py||airflow/www/security.py",
          "airflow/www/utils.py||airflow/www/utils.py",
          "airflow/www/views.py||airflow/www/views.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/34775"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/www/api/experimental/endpoints.py||airflow/www/api/experimental/endpoints.py": [
          "File: airflow/www/api/experimental/endpoints.py -> airflow/www/api/experimental/endpoints.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: import logging",
          "21: from functools import wraps",
          "26: from airflow import models",
          "27: from airflow.api.common.experimental import delete_dag as delete, pool as pool_api, trigger_dag as trigger",
          "",
          "[Removed Lines]",
          "22: from typing import Callable, TypeVar, cast",
          "24: from flask import Blueprint, Response, current_app, g, jsonify, request, url_for",
          "",
          "[Added Lines]",
          "22: from typing import TYPE_CHECKING, Callable, TypeVar, cast",
          "24: from flask import Blueprint, current_app, g, jsonify, request, url_for",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "37: from airflow.utils.strings import to_boolean",
          "38: from airflow.version import version",
          "40: log = logging.getLogger(__name__)",
          "42: T = TypeVar(\"T\", bound=Callable)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "40: if TYPE_CHECKING:",
          "41:     from flask import Response",
          "",
          "---------------"
        ],
        "airflow/www/extensions/init_appbuilder.py||airflow/www/extensions/init_appbuilder.py": [
          "File: airflow/www/extensions/init_appbuilder.py -> airflow/www/extensions/init_appbuilder.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: import logging",
          "22: from functools import reduce",
          "24: from flask import Blueprint, current_app, url_for",
          "26: from flask_appbuilder.babel.manager import BabelManager",
          "27: from flask_appbuilder.const import (",
          "28:     LOGMSG_ERR_FAB_ADD_PERMISSION_MENU,",
          "",
          "[Removed Lines]",
          "25: from flask_appbuilder import BaseView, __version__",
          "",
          "[Added Lines]",
          "23: from typing import TYPE_CHECKING",
          "26: from flask_appbuilder import __version__",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "35: )",
          "36: from flask_appbuilder.filters import TemplateFilters",
          "37: from flask_appbuilder.menu import Menu",
          "39: from flask_appbuilder.views import IndexView, UtilView",
          "42: from airflow import settings",
          "43: from airflow.configuration import conf",
          "44: from airflow.www.extensions.init_auth_manager import get_auth_manager",
          "46: # This product contains a modified portion of 'Flask App Builder' developed by Daniel Vaz Gaspar.",
          "47: # (https://github.com/dpgaspar/Flask-AppBuilder).",
          "48: # Copyright 2013, Daniel Vaz Gaspar",
          "",
          "[Removed Lines]",
          "38: from flask_appbuilder.security.manager import BaseSecurityManager",
          "40: from sqlalchemy.orm import Session",
          "",
          "[Added Lines]",
          "45: if TYPE_CHECKING:",
          "46:     from flask_appbuilder import BaseView",
          "47:     from flask_appbuilder.security.manager import BaseSecurityManager",
          "48:     from sqlalchemy.orm import Session",
          "",
          "---------------"
        ],
        "airflow/www/extensions/init_views.py||airflow/www/extensions/init_views.py": [
          "File: airflow/www/extensions/init_views.py -> airflow/www/extensions/init_views.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: import warnings",
          "21: from functools import cached_property",
          "22: from os import path",
          "24: from connexion import FlaskApi, ProblemException, Resolver",
          "25: from connexion.decorators.validation import RequestBodyValidator",
          "26: from connexion.exceptions import BadRequestProblem",
          "29: from airflow.api_connexion.exceptions import common_error_handler",
          "30: from airflow.configuration import conf",
          "",
          "[Removed Lines]",
          "27: from flask import Flask, request",
          "",
          "[Added Lines]",
          "23: from typing import TYPE_CHECKING",
          "28: from flask import request",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "32: from airflow.security import permissions",
          "33: from airflow.utils.yaml import safe_load",
          "35: log = logging.getLogger(__name__)",
          "37: # airflow/www/extensions/init_views.py => airflow/",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "36: if TYPE_CHECKING:",
          "37:     from flask import Flask",
          "",
          "---------------"
        ],
        "airflow/www/extensions/init_wsgi_middlewares.py||airflow/www/extensions/init_wsgi_middlewares.py": [
          "File: airflow/www/extensions/init_wsgi_middlewares.py -> airflow/www/extensions/init_wsgi_middlewares.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: from typing import TYPE_CHECKING, Iterable",
          "21: from urllib.parse import urlsplit",
          "24: from werkzeug.middleware.dispatcher import DispatcherMiddleware",
          "25: from werkzeug.middleware.proxy_fix import ProxyFix",
          "",
          "[Removed Lines]",
          "23: from flask import Flask",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "30: if TYPE_CHECKING:",
          "31:     from _typeshed.wsgi import StartResponse, WSGIEnvironment",
          "34: def _root_app(env: WSGIEnvironment, resp: StartResponse) -> Iterable[bytes]:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "31:     from flask import Flask",
          "",
          "---------------"
        ],
        "airflow/www/fab_security/manager.py||airflow/www/fab_security/manager.py": [
          "File: airflow/www/fab_security/manager.py -> airflow/www/fab_security/manager.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: import datetime",
          "23: import json",
          "24: import logging",
          "26: from uuid import uuid4",
          "28: import re2",
          "31: from flask_appbuilder.const import (",
          "32:     AUTH_DB,",
          "33:     AUTH_LDAP,",
          "",
          "[Removed Lines]",
          "25: from typing import Any",
          "29: from flask import Flask, g, session, url_for",
          "30: from flask_appbuilder import AppBuilder",
          "",
          "[Added Lines]",
          "25: from typing import TYPE_CHECKING, Any",
          "29: from flask import g, session, url_for",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "69: from flask_limiter.util import get_remote_address",
          "70: from werkzeug.security import check_password_hash",
          "73: from airflow.configuration import conf",
          "74: from airflow.www.extensions.init_auth_manager import get_auth_manager",
          "76: # This product contains a modified portion of 'Flask App Builder' developed by Daniel Vaz Gaspar.",
          "77: # (https://github.com/dpgaspar/Flask-AppBuilder).",
          "78: # Copyright 2013, Daniel Vaz Gaspar",
          "",
          "[Removed Lines]",
          "72: from airflow.auth.managers.fab.models import Action, Permission, RegisterUser, Resource, Role, User",
          "",
          "[Added Lines]",
          "74: if TYPE_CHECKING:",
          "75:     from flask import Flask",
          "76:     from flask_appbuilder import AppBuilder",
          "78:     from airflow.auth.managers.fab.models import Action, Permission, RegisterUser, Resource, Role, User",
          "",
          "---------------"
        ],
        "airflow/www/security.py||airflow/www/security.py": [
          "File: airflow/www/security.py -> airflow/www/security.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: from flask import g",
          "23: from sqlalchemy import or_",
          "26: from airflow.auth.managers.fab.models import Permission, Resource, Role, User",
          "27: from airflow.auth.managers.fab.views.user_details import CustomUserDBModelView",
          "",
          "[Removed Lines]",
          "24: from sqlalchemy.orm import Session, joinedload",
          "",
          "[Added Lines]",
          "24: from sqlalchemy.orm import joinedload",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "57: }",
          "59: if TYPE_CHECKING:",
          "60:     SecurityManagerOverride: type = object",
          "61: else:",
          "62:     # Fetch the security manager override from the auth manager",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "60:     from sqlalchemy.orm import Session",
          "",
          "---------------"
        ],
        "airflow/www/utils.py||airflow/www/utils.py": [
          "File: airflow/www/utils.py -> airflow/www/utils.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "27: from flask.helpers import flash",
          "28: from flask_appbuilder.forms import FieldConverter",
          "29: from flask_appbuilder.models.filters import BaseFilter",
          "31: from flask_appbuilder.models.sqla.filters import get_field_setup_query, set_value_to_type",
          "32: from flask_appbuilder.models.sqla.interface import SQLAInterface",
          "33: from flask_babel import lazy_gettext",
          "34: from markdown_it import MarkdownIt",
          "35: from markupsafe import Markup",
          "37: from pygments import highlight, lexers",
          "38: from pygments.formatters import HtmlFormatter",
          "40: from sqlalchemy import delete, func, select, types",
          "41: from sqlalchemy.ext.associationproxy import AssociationProxy",
          "44: from airflow.exceptions import RemovedInAirflow3Warning",
          "45: from airflow.models import errors",
          "",
          "[Removed Lines]",
          "30: from flask_appbuilder.models.sqla import Model, filters as fab_sqlafilters",
          "36: from pendulum.datetime import DateTime",
          "39: from pygments.lexer import Lexer",
          "42: from sqlalchemy.sql import Select",
          "",
          "[Added Lines]",
          "30: from flask_appbuilder.models.sqla import filters as fab_sqlafilters",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "56: from airflow.www.widgets import AirflowDateTimePickerWidget",
          "58: if TYPE_CHECKING:",
          "59:     from sqlalchemy.orm.session import Session",
          "60:     from sqlalchemy.sql.operators import ColumnOperators",
          "62:     from airflow.www.fab_security.sqla.manager import SecurityManager",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "56:     from flask_appbuilder.models.sqla import Model",
          "57:     from pendulum.datetime import DateTime",
          "58:     from pygments.lexer import Lexer",
          "60:     from sqlalchemy.sql import Select",
          "",
          "---------------"
        ],
        "airflow/www/views.py||airflow/www/views.py": [
          "File: airflow/www/views.py -> airflow/www/views.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "31: from collections import defaultdict",
          "32: from functools import cached_property, wraps",
          "33: from json import JSONDecodeError",
          "35: from urllib.parse import unquote, urljoin, urlsplit",
          "37: import configupdater",
          "",
          "[Removed Lines]",
          "34: from typing import Any, Callable, Collection, Iterator, Mapping, MutableMapping, Sequence",
          "",
          "[Added Lines]",
          "34: from typing import TYPE_CHECKING, Any, Callable, Collection, Iterator, Mapping, MutableMapping, Sequence",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "69: from pendulum.parsing.exceptions import ParserError",
          "70: from sqlalchemy import Date, and_, case, desc, func, inspect, select, union_all",
          "71: from sqlalchemy.exc import IntegrityError",
          "73: from wtforms import BooleanField, validators",
          "75: import airflow",
          "",
          "[Removed Lines]",
          "72: from sqlalchemy.orm import Session, joinedload",
          "",
          "[Added Lines]",
          "72: from sqlalchemy.orm import joinedload",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "96: from airflow.jobs.scheduler_job_runner import SchedulerJobRunner",
          "97: from airflow.jobs.triggerer_job_runner import TriggererJobRunner",
          "98: from airflow.models import Connection, DagModel, DagTag, Log, SlaMiss, TaskFail, Trigger, XCom, errors",
          "101: from airflow.models.dagrun import RUN_ID_REGEX, DagRun, DagRunType",
          "102: from airflow.models.dataset import DagScheduleDatasetReference, DatasetDagRunQueue, DatasetEvent, DatasetModel",
          "103: from airflow.models.mappedoperator import MappedOperator",
          "105: from airflow.models.serialized_dag import SerializedDagModel",
          "106: from airflow.models.taskinstance import TaskInstance, TaskInstanceNote",
          "107: from airflow.providers_manager import ProvidersManager",
          "",
          "[Removed Lines]",
          "99: from airflow.models.abstractoperator import AbstractOperator",
          "100: from airflow.models.dag import DAG, get_dataset_triggered_next_run_info",
          "104: from airflow.models.operator import Operator",
          "",
          "[Added Lines]",
          "99: from airflow.models.dag import get_dataset_triggered_next_run_info",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "138: )",
          "139: from airflow.www.widgets import AirflowModelListWidget, AirflowVariableShowWidget",
          "141: PAGE_SIZE = conf.getint(\"webserver\", \"page_size\")",
          "142: FILTER_TAGS_COOKIE = \"tags_filter\"",
          "143: FILTER_STATUS_COOKIE = \"dag_status_filter\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "139: if TYPE_CHECKING:",
          "140:     from sqlalchemy.orm import Session",
          "142:     from airflow.models.abstractoperator import AbstractOperator",
          "143:     from airflow.models.dag import DAG",
          "144:     from airflow.models.operator import Operator",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "836:             is_paused_count = dict(",
          "837:                 session.execute(",
          "841:                 ).all()",
          "842:             )",
          "",
          "[Removed Lines]",
          "838:                     all_dags.with_only_columns([DagModel.is_paused, func.count()]).group_by(",
          "839:                         DagModel.is_paused",
          "840:                     )",
          "",
          "[Added Lines]",
          "843:                     select(DagModel.is_paused, func.count(DagModel.dag_id)).group_by(DagModel.is_paused)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "3188f511bd92a530435ad05b8d3d0346a96a1dc3",
      "candidate_info": {
        "commit_hash": "3188f511bd92a530435ad05b8d3d0346a96a1dc3",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/3188f511bd92a530435ad05b8d3d0346a96a1dc3",
        "files": [
          "airflow/kubernetes/pre_7_4_0_compatibility/pod_generator.py",
          "scripts/ci/testing/summarize_junit_failures.py",
          "scripts/in_container/run_migration_reference.py",
          "scripts/in_container/verify_providers.py",
          "tests/providers/cncf/kubernetes/test_pod_generator.py"
        ],
        "message": "Refactor: Simplify string generation (#34118)\n\n(cherry picked from commit a1fe77bc820a0dccf170fc123ec7e7280747e145)",
        "before_after_code_files": [
          "airflow/kubernetes/pre_7_4_0_compatibility/pod_generator.py||airflow/kubernetes/pre_7_4_0_compatibility/pod_generator.py",
          "scripts/ci/testing/summarize_junit_failures.py||scripts/ci/testing/summarize_junit_failures.py",
          "scripts/in_container/run_migration_reference.py||scripts/in_container/run_migration_reference.py",
          "scripts/in_container/verify_providers.py||scripts/in_container/verify_providers.py",
          "tests/providers/cncf/kubernetes/test_pod_generator.py||tests/providers/cncf/kubernetes/test_pod_generator.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/34775"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/kubernetes/pre_7_4_0_compatibility/pod_generator.py||airflow/kubernetes/pre_7_4_0_compatibility/pod_generator.py": [
          "File: airflow/kubernetes/pre_7_4_0_compatibility/pod_generator.py -> airflow/kubernetes/pre_7_4_0_compatibility/pod_generator.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "492:             airflow_worker=airflow_worker,",
          "493:         )",
          "494:         label_strings = [f\"{label_id}={label}\" for label_id, label in sorted(labels.items())]",
          "496:         if not airflow_worker:  # this filters out KPO pods even when we don't know the scheduler job id",
          "498:         return selector",
          "500:     @classmethod",
          "",
          "[Removed Lines]",
          "495:         selector = \",\".join(label_strings)",
          "497:             selector += \",airflow-worker\"",
          "",
          "[Added Lines]",
          "496:             label_strings.append(\"airflow-worker\")",
          "497:         selector = \",\".join(label_strings)",
          "",
          "---------------"
        ],
        "scripts/ci/testing/summarize_junit_failures.py||scripts/ci/testing/summarize_junit_failures.py": [
          "File: scripts/ci/testing/summarize_junit_failures.py -> scripts/ci/testing/summarize_junit_failures.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "84:     testsuite = root.find(\".//testsuite\")",
          "103:         return",
          "106:     for testcase in testsuite.findall(\".//testcase[error]\"):",
          "107:         case_name = translate_name(testcase)",
          "",
          "[Removed Lines]",
          "86:     fail_message = \"\"",
          "88:     num = int(testsuite.get(\"failures\"))",
          "89:     if num:",
          "90:         fail_message = f\"{num} failure\"",
          "91:         if num != 1:",
          "92:             fail_message += \"s\"",
          "94:     num = int(testsuite.get(\"errors\"))",
          "95:     if num:",
          "96:         if fail_message:",
          "97:             fail_message += \", \"",
          "98:         fail_message += f\"{num} error\"",
          "99:         if num != 1:",
          "100:             fail_message += \"s\"",
          "102:     if not fail_message:",
          "104:     print(f\"\\n{TEXT_RED}==== {test_type} {backend}: {fail_message} ===={TEXT_RESET}\\n\")",
          "",
          "[Added Lines]",
          "86:     fail_message_parts = []",
          "88:     num_failures = int(testsuite.get(\"failures\"))",
          "89:     if num_failures:",
          "90:         fail_message_parts.append(f\"{num_failures} failure{'' if num_failures == 1 else 's'}\")",
          "92:     num_errors = int(testsuite.get(\"errors\"))",
          "93:     if num_errors:",
          "94:         fail_message_parts.append(f\"{num_errors} error{'' if num_errors == 1 else 's'}\")",
          "96:     if not fail_message_parts:",
          "98:     print(f\"\\n{TEXT_RED}==== {test_type} {backend}: {', '.join(fail_message_parts)} ===={TEXT_RESET}\\n\")",
          "",
          "---------------"
        ],
        "scripts/in_container/run_migration_reference.py||scripts/in_container/run_migration_reference.py": [
          "File: scripts/in_container/run_migration_reference.py -> scripts/in_container/run_migration_reference.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "135:     )",
          "142: def ensure_mod_prefix(mod_name, idx, version):",
          "144:     match = re.match(r\"([0-9]+)_([0-9]+)_([0-9]+)_([0-9]+)_(.+)\", mod_name)",
          "145:     if match:",
          "146:         # previously standardized file, rebuild the name",
          "148:     else:",
          "149:         # new migration file, standard format",
          "150:         match = re.match(r\"([a-z0-9]+)_(.+)\", mod_name)",
          "151:         if match:",
          "156: def ensure_filenames_are_sorted(revisions):",
          "",
          "[Removed Lines]",
          "138: def num_to_prefix(idx: int) -> str:",
          "139:     return f\"000{idx+1}\"[-4:] + \"_\"",
          "143:     prefix = num_to_prefix(idx) + \"_\".join(version) + \"_\"",
          "147:         mod_name = match.group(5)",
          "152:             mod_name = match.group(2)",
          "153:     return prefix + mod_name",
          "",
          "[Added Lines]",
          "139:     parts = [f\"{idx + 1:04}\", *version]",
          "143:         parts.append(match.group(5))",
          "148:             parts.append(match.group(2))",
          "149:     return \"_\".join(parts)",
          "",
          "---------------"
        ],
        "scripts/in_container/verify_providers.py||scripts/in_container/verify_providers.py": [
          "File: scripts/in_container/verify_providers.py -> scripts/in_container/verify_providers.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "548:         s = s[1:]",
          "549:     if not s:",
          "550:         return True",
          "554: def check_if_classes_are_properly_named(",
          "",
          "[Removed Lines]",
          "551:     return s != s.lower() and s != s.upper() and \"_\" not in s and s[0].upper() == s[0]",
          "",
          "[Added Lines]",
          "551:     return s[0].isupper() and not (s.islower() or s.isupper() or \"_\" in s)",
          "",
          "---------------"
        ],
        "tests/providers/cncf/kubernetes/test_pod_generator.py||tests/providers/cncf/kubernetes/test_pod_generator.py": [
          "File: tests/providers/cncf/kubernetes/test_pod_generator.py -> tests/providers/cncf/kubernetes/test_pod_generator.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "818:         )",
          "819:         labels = PodGenerator.build_labels_for_k8s_executor_pod(**kwargs, **extra)",
          "820:         assert labels == {**expected, **extra_expected}",
          "822:         if \"airflow_worker\" not in extra:",
          "824:         assert PodGenerator.build_selector_for_k8s_executor_pod(**kwargs, **extra) == exp_selector",
          "",
          "[Removed Lines]",
          "821:         exp_selector = \",\".join([f\"{k}={v}\" for k, v in sorted(labels.items())])",
          "823:             exp_selector += \",airflow-worker\"",
          "",
          "[Added Lines]",
          "821:         items = [f\"{k}={v}\" for k, v in sorted(labels.items())]",
          "823:             items.append(\"airflow-worker\")",
          "824:         exp_selector = \",\".join(items)",
          "",
          "---------------"
        ]
      }
    }
  ]
}