{
  "cve_id": "CVE-2024-56128",
  "cve_desc": "Incorrect Implementation of Authentication Algorithm in Apache Kafka's SCRAM implementation.\n\nIssue Summary:\nApache Kafka's implementation of the Salted Challenge Response Authentication Mechanism (SCRAM) did not fully adhere to the requirements of RFC 5802 [1].\nSpecifically, as per RFC 5802, the server must verify that the nonce sent by the client in the second message matches the nonce sent by the server in its first message.\nHowever, Kafka's SCRAM implementation did not perform this validation.\n\nImpact:\nThis vulnerability is exploitable only when an attacker has plaintext access to the SCRAM authentication exchange. However, the usage of SCRAM over plaintext is strongly\ndiscouraged as it is considered an insecure practice [2]. Apache Kafka recommends deploying SCRAM exclusively with TLS encryption to protect SCRAM exchanges from interception [3].\nDeployments using SCRAM with TLS are not affected by this issue.\n\nHow to Detect If You Are Impacted:\nIf your deployment uses SCRAM authentication over plaintext communication channels (without TLS encryption), you are likely impacted.\nTo check if TLS is enabled, review your server.properties configuration file for listeners property. If you have SASL_PLAINTEXT in the listeners, then you are likely impacted.\n\nFix Details:\nThe issue has been addressed by introducing nonce verification in the final message of the SCRAM authentication exchange to ensure compliance with RFC 5802.\n\nAffected Versions:\nApache Kafka versions 0.10.2.0 through 3.9.0, excluding the fixed versions below.\n\nFixed Versions:\n3.9.0\n3.8.1\n3.7.2\n\nUsers are advised to upgrade to 3.7.2 or later to mitigate this issue.\n\nRecommendations for Mitigation:\nUsers unable to upgrade to the fixed versions can mitigate the issue by:\n- Using TLS with SCRAM Authentication:\nAlways deploy SCRAM over TLS to encrypt authentication exchanges and protect against interception.\n- Considering Alternative Authentication Mechanisms:\nEvaluate alternative authentication mechanisms, such as PLAIN, Kerberos or OAuth with TLS, which provide additional layers of security.",
  "repo": "apache/kafka",
  "patch_hash": "2cbc5bd3ca22185d9cd357c9db23a2cfb43a0fff",
  "patch_info": {
    "commit_hash": "2cbc5bd3ca22185d9cd357c9db23a2cfb43a0fff",
    "repo": "apache/kafka",
    "commit_url": "https://github.com/apache/kafka/commit/2cbc5bd3ca22185d9cd357c9db23a2cfb43a0fff",
    "files": [
      "core/src/main/scala/kafka/tools/StorageTool.scala",
      "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
    ],
    "message": "KAFKA-17636 Fix missing SCRAM bootstrap records (#17305)\n\nFixes a regression introduced by #16669 which inadvertently stopped processing SCRAM arguments from kafka-storage.sh\n\nReviewers: Colin P. McCabe <cmccabe@apache.org>, Federico Valeri <fedevaleri@gmail.com>",
    "before_after_code_files": [
      "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
      "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
    ]
  },
  "patch_diff": {
    "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala": [
      "File: core/src/main/scala/kafka/tools/StorageTool.scala -> core/src/main/scala/kafka/tools/StorageTool.scala",
      "--- Hunk 1 ---",
      "[Context before]",
      "130:     if (namespace.getBoolean(\"standalone\")) {",
      "131:       formatter.setInitialVoters(createStandaloneDynamicVoters(config))",
      "132:     }",
      "133:     configToLogDirectories(config).foreach(formatter.addDirectory(_))",
      "134:     formatter.run()",
      "135:   }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "133:     Option(namespace.getList(\"add_scram\")).",
      "134:       foreach(scramArgs => formatter.setScramArguments(scramArgs.asInstanceOf[util.List[String]]))",
      "",
      "---------------"
    ],
    "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala": [
      "File: core/src/test/scala/unit/kafka/tools/StorageToolTest.scala -> core/src/test/scala/unit/kafka/tools/StorageToolTest.scala",
      "--- Hunk 1 ---",
      "[Context before]",
      "21: import java.nio.charset.StandardCharsets",
      "22: import java.nio.file.Files",
      "23: import java.util",
      "25: import kafka.server.KafkaConfig",
      "26: import kafka.utils.TestUtils",
      "27: import net.sourceforge.argparse4j.inf.ArgumentParserException",
      "28: import org.apache.kafka.common.utils.Utils",
      "29: import org.apache.kafka.server.common.Features",
      "30: import org.apache.kafka.metadata.properties.{MetaPropertiesEnsemble, PropertiesUtils}",
      "31: import org.apache.kafka.metadata.storage.FormatterException",
      "32: import org.apache.kafka.raft.QuorumConfig",
      "",
      "[Removed Lines]",
      "24: import java.util.Properties",
      "",
      "[Added Lines]",
      "24: import java.util.{Optional, Properties}",
      "28: import org.apache.kafka.common.metadata.UserScramCredentialRecord",
      "31: import org.apache.kafka.metadata.bootstrap.BootstrapDirectory",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "37: import org.junit.jupiter.params.provider.ValueSource",
      "39: import scala.collection.mutable.ListBuffer",
      "41: @Timeout(value = 40)",
      "42: class StorageToolTest {",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "42: import scala.jdk.CollectionConverters.IterableHasAsScala",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "433:       contains(\"Formatting dynamic metadata voter directory %s\".format(availableDirs.head)),",
      "434:       \"Failed to find content in output: \" + stream.toString())",
      "435:   }",
      "",
      "[Removed Lines]",
      "436: }",
      "",
      "[Added Lines]",
      "440:   @Test",
      "441:   def testBootstrapScramRecords(): Unit = {",
      "442:     val availableDirs = Seq(TestUtils.tempDir())",
      "443:     val properties = new Properties()",
      "444:     properties.putAll(defaultDynamicQuorumProperties)",
      "445:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
      "446:     val stream = new ByteArrayOutputStream()",
      "447:     val arguments = ListBuffer[String](",
      "448:       \"--release-version\", \"3.9-IV0\",",
      "449:       \"--add-scram\", \"SCRAM-SHA-512=[name=alice,password=changeit]\",",
      "450:       \"--add-scram\", \"SCRAM-SHA-512=[name=bob,password=changeit]\"",
      "451:     )",
      "453:     assertEquals(0, runFormatCommand(stream, properties, arguments.toSeq))",
      "457:     val bootstrapMetadata = new BootstrapDirectory(availableDirs.head.toString, Optional.empty).read",
      "458:     val scramRecords = bootstrapMetadata.records().asScala",
      "459:       .filter(apiMessageAndVersion => apiMessageAndVersion.message().isInstanceOf[UserScramCredentialRecord])",
      "460:       .map(apiMessageAndVersion => apiMessageAndVersion.message().asInstanceOf[UserScramCredentialRecord])",
      "461:       .toList",
      "462:     assertEquals(2, scramRecords.size)",
      "463:     assertEquals(\"alice\", scramRecords.head.name())",
      "464:     assertEquals(\"bob\", scramRecords.last.name())",
      "465:   }",
      "467:   @Test",
      "468:   def testScramRecordsOldReleaseVersion(): Unit = {",
      "469:     val availableDirs = Seq(TestUtils.tempDir())",
      "470:     val properties = new Properties()",
      "471:     properties.putAll(defaultDynamicQuorumProperties)",
      "472:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
      "473:     val stream = new ByteArrayOutputStream()",
      "474:     val arguments = ListBuffer[String](",
      "475:       \"--release-version\", \"3.4\",",
      "476:       \"--add-scram\", \"SCRAM-SHA-512=[name=alice,password=changeit]\",",
      "477:       \"--add-scram\", \"SCRAM-SHA-512=[name=bob,password=changeit]\"",
      "478:     )",
      "480:     assertEquals(",
      "481:       \"SCRAM is only supported in metadata.version 3.5-IV2 or later.\",",
      "482:       assertThrows(classOf[FormatterException], () => runFormatCommand(stream, properties, arguments.toSeq)).getMessage)",
      "483:   }",
      "484: }",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "7e1c453af9533aba8c19da2d08ce6595c1441fc0",
      "candidate_info": {
        "commit_hash": "7e1c453af9533aba8c19da2d08ce6595c1441fc0",
        "repo": "apache/kafka",
        "commit_url": "https://github.com/apache/kafka/commit/7e1c453af9533aba8c19da2d08ce6595c1441fc0",
        "files": [
          "clients/src/main/java/org/apache/kafka/common/Uuid.java",
          "core/src/main/scala/kafka/log/LogManager.scala",
          "core/src/main/scala/kafka/server/BrokerMetadataCheckpoint.scala",
          "core/src/main/scala/kafka/server/KafkaServer.scala",
          "core/src/main/scala/kafka/tools/StorageTool.scala",
          "core/src/test/scala/kafka/server/BrokerMetadataCheckpointTest.scala",
          "core/src/test/scala/unit/kafka/log/LogManagerTest.scala",
          "core/src/test/scala/unit/kafka/server/KafkaRaftServerTest.scala",
          "core/src/test/scala/unit/kafka/server/ServerGenerateBrokerIdTest.scala",
          "core/src/test/scala/unit/kafka/server/ServerGenerateClusterIdTest.scala",
          "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
        ],
        "message": "KAFKA-15356: Generate and persist directory IDs (#14291)\n\nReviewers: Proven Provenzano <pprovenzano@confluent.io>, Ron Dagostino <rdagostino@confluent.io>",
        "before_after_code_files": [
          "clients/src/main/java/org/apache/kafka/common/Uuid.java||clients/src/main/java/org/apache/kafka/common/Uuid.java",
          "core/src/main/scala/kafka/log/LogManager.scala||core/src/main/scala/kafka/log/LogManager.scala",
          "core/src/main/scala/kafka/server/BrokerMetadataCheckpoint.scala||core/src/main/scala/kafka/server/BrokerMetadataCheckpoint.scala",
          "core/src/main/scala/kafka/server/KafkaServer.scala||core/src/main/scala/kafka/server/KafkaServer.scala",
          "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
          "core/src/test/scala/kafka/server/BrokerMetadataCheckpointTest.scala||core/src/test/scala/kafka/server/BrokerMetadataCheckpointTest.scala",
          "core/src/test/scala/unit/kafka/log/LogManagerTest.scala||core/src/test/scala/unit/kafka/log/LogManagerTest.scala",
          "core/src/test/scala/unit/kafka/server/KafkaRaftServerTest.scala||core/src/test/scala/unit/kafka/server/KafkaRaftServerTest.scala",
          "core/src/test/scala/unit/kafka/server/ServerGenerateBrokerIdTest.scala||core/src/test/scala/unit/kafka/server/ServerGenerateBrokerIdTest.scala",
          "core/src/test/scala/unit/kafka/server/ServerGenerateClusterIdTest.scala||core/src/test/scala/unit/kafka/server/ServerGenerateClusterIdTest.scala",
          "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
            "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
          ],
          "candidate": [
            "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
            "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
          ]
        }
      },
      "candidate_diff": {
        "clients/src/main/java/org/apache/kafka/common/Uuid.java||clients/src/main/java/org/apache/kafka/common/Uuid.java": [
          "File: clients/src/main/java/org/apache/kafka/common/Uuid.java -> clients/src/main/java/org/apache/kafka/common/Uuid.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: package org.apache.kafka.common;",
          "19: import java.nio.ByteBuffer;",
          "20: import java.util.Base64;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "20: import java.util.Arrays;",
          "22: import java.util.Collections;",
          "23: import java.util.HashSet;",
          "24: import java.util.Set;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "28: public class Uuid implements Comparable<Uuid> {",
          "38:     public static final Uuid ZERO_UUID = new Uuid(0L, 0L);",
          "40:     private final long mostSignificantBits;",
          "41:     private final long leastSignificantBits;",
          "",
          "[Removed Lines]",
          "33:     public static final Uuid METADATA_TOPIC_ID = new Uuid(0L, 1L);",
          "",
          "[Added Lines]",
          "37:     public static final Uuid ONE_UUID = new Uuid(0L, 1L);",
          "42:     public static final Uuid METADATA_TOPIC_ID = ONE_UUID;",
          "52:     public static final Uuid UNKNOWN_DIR = ZERO_UUID;",
          "57:     public static final Uuid OFFLINE_DIR = ONE_UUID;",
          "66:     public static final Uuid SELECTED_DIR = new Uuid(0L, 2L);",
          "71:     public static final Set<Uuid> RESERVED;",
          "73:     static {",
          "74:         HashSet<Uuid> reserved = new HashSet<>(Arrays.asList(",
          "75:                 METADATA_TOPIC_ID,",
          "76:                 ZERO_UUID,",
          "77:                 ONE_UUID,",
          "78:                 UNKNOWN_DIR,",
          "79:                 OFFLINE_DIR,",
          "80:                 SELECTED_DIR",
          "81:         ));",
          "83:         for (long i = 0L; i < 100L; i++) {",
          "84:             reserved.add(new Uuid(0L, i));",
          "85:         }",
          "86:         RESERVED = Collections.unmodifiableSet(reserved);",
          "87:     }",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "62:     public static Uuid randomUuid() {",
          "63:         Uuid uuid = unsafeRandomUuid();",
          "65:             uuid = unsafeRandomUuid();",
          "66:         }",
          "67:         return uuid;",
          "",
          "[Removed Lines]",
          "64:         while (uuid.equals(METADATA_TOPIC_ID) || uuid.equals(ZERO_UUID) || uuid.toString().startsWith(\"-\")) {",
          "",
          "[Added Lines]",
          "113:         while (RESERVED.contains(uuid) || uuid.toString().startsWith(\"-\")) {",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/log/LogManager.scala||core/src/main/scala/kafka/log/LogManager.scala": [
          "File: core/src/main/scala/kafka/log/LogManager.scala -> core/src/main/scala/kafka/log/LogManager.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "117:   }",
          "119:   private val dirLocks = lockLogDirs(liveLogDirs)",
          "120:   @volatile private var recoveryPointCheckpoints = liveLogDirs.map(dir =>",
          "121:     (dir, new OffsetCheckpointFile(new File(dir, RecoveryPointCheckpointFile), logDirFailureChannel))).toMap",
          "122:   @volatile private var logStartOffsetCheckpoints = liveLogDirs.map(dir =>",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "120:   private val dirIds = directoryIds(liveLogDirs)",
          "122:   private[log] val directoryIds: Set[Uuid] = dirIds.values.toSet",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "261:     }",
          "262:   }",
          "264:   private def addLogToBeDeleted(log: UnifiedLog): Unit = {",
          "265:     this.logsToBeDeleted.add((log, time.milliseconds()))",
          "266:   }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "270:   def directoryId(dir: String): Option[Uuid] = dirIds.get(dir)",
          "277:   private def directoryIds(dirs: Seq[File]): Map[String, Uuid] = {",
          "278:     dirs.flatMap { dir =>",
          "279:       try {",
          "280:         val metadataCheckpoint = new BrokerMetadataCheckpoint(new File(dir, KafkaServer.brokerMetaPropsFile))",
          "281:         metadataCheckpoint.read().map { props =>",
          "282:           val rawMetaProperties = new RawMetaProperties(props)",
          "283:           val uuid = rawMetaProperties.directoryId match {",
          "284:             case Some(uuidStr) => Uuid.fromString(uuidStr)",
          "285:             case None =>",
          "286:               val uuid = Uuid.randomUuid()",
          "287:               rawMetaProperties.directoryId = uuid.toString",
          "288:               metadataCheckpoint.write(rawMetaProperties.props)",
          "289:               uuid",
          "290:           }",
          "291:           dir.getAbsolutePath -> uuid",
          "292:         }.toMap",
          "293:       } catch {",
          "294:         case e: IOException =>",
          "295:           logDirFailureChannel.maybeAddOfflineLogDir(dir.getAbsolutePath, s\"Disk error while loading ID $dir\", e)",
          "296:           None",
          "297:       }",
          "298:     }.toMap",
          "299:   }",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/server/BrokerMetadataCheckpoint.scala||core/src/main/scala/kafka/server/BrokerMetadataCheckpoint.scala": [
          "File: core/src/main/scala/kafka/server/BrokerMetadataCheckpoint.scala -> core/src/main/scala/kafka/server/BrokerMetadataCheckpoint.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "34:   val ClusterIdKey = \"cluster.id\"",
          "35:   val BrokerIdKey = \"broker.id\"",
          "36:   val NodeIdKey = \"node.id\"",
          "37:   val VersionKey = \"version\"",
          "38: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "37:   val DirectoryIdKey = \"directory.id\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "63:     props.setProperty(NodeIdKey, id.toString)",
          "64:   }",
          "66:   def version: Int = {",
          "67:     intValue(VersionKey).getOrElse(0)",
          "68:   }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "67:   def directoryId: Option[String] = {",
          "68:     Option(props.getProperty(DirectoryIdKey))",
          "69:   }",
          "71:   def directoryId_=(id: String): Unit = {",
          "72:     props.setProperty(DirectoryIdKey, id)",
          "73:   }",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "71:     props.setProperty(VersionKey, ver.toString)",
          "72:   }",
          "81:   private def intValue(key: String): Option[Int] = {",
          "82:     try {",
          "83:       Option(props.getProperty(key)).map(Integer.parseInt)",
          "",
          "[Removed Lines]",
          "74:   def requireVersion(expectedVersion: Int): Unit = {",
          "75:     if (version != expectedVersion) {",
          "76:       throw new RuntimeException(s\"Expected version $expectedVersion, but got \"+",
          "77:         s\"version $version\")",
          "78:     }",
          "79:   }",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "141:   clusterId: String,",
          "142:   nodeId: Int,",
          "143: ) {",
          "145:     val properties = new RawMetaProperties()",
          "146:     properties.version = 1",
          "147:     properties.clusterId = clusterId",
          "148:     properties.nodeId = nodeId",
          "149:     properties.props",
          "150:   }",
          "",
          "[Removed Lines]",
          "144:   def toProperties: Properties = {",
          "",
          "[Added Lines]",
          "146:   private def toRawMetaProperties: RawMetaProperties = {",
          "151:     properties",
          "152:   }",
          "154:   def toProperties: Properties = {",
          "155:     toRawMetaProperties.props",
          "156:   }",
          "158:   def toPropertiesWithDirectoryId(directoryId: String): Properties = {",
          "159:     val properties = toRawMetaProperties",
          "160:     properties.directoryId = directoryId",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "166:     val offlineDirs = mutable.ArrayBuffer.empty[String]",
          "168:     for (logDir <- logDirs) {",
          "170:       val brokerCheckpoint = new BrokerMetadataCheckpoint(brokerCheckpointFile)",
          "172:       try {",
          "",
          "[Removed Lines]",
          "169:       val brokerCheckpointFile = new File(logDir, \"meta.properties\")",
          "",
          "[Added Lines]",
          "181:       val brokerCheckpointFile = new File(logDir, KafkaServer.brokerMetaPropsFile)",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/server/KafkaServer.scala||core/src/main/scala/kafka/server/KafkaServer.scala": [
          "File: core/src/main/scala/kafka/server/KafkaServer.scala -> core/src/main/scala/kafka/server/KafkaServer.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "70: object KafkaServer {",
          "72:   def zkClientConfigFromKafkaConfig(config: KafkaConfig, forceZkSslClientEnable: Boolean = false): ZKClientConfig = {",
          "73:     val clientConfig = new ZKClientConfig",
          "74:     if (config.zkSslClientEnable || forceZkSslClientEnable) {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "72:   val brokerMetaPropsFile = \"meta.properties\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "165:   private var configRepository: ZkConfigRepository = _",
          "167:   val correlationId: AtomicInteger = new AtomicInteger(0)",
          "169:   val brokerMetadataCheckpoints = config.logDirs.map { logDir =>",
          "171:   }.toMap",
          "173:   private var _clusterId: String = _",
          "",
          "[Removed Lines]",
          "168:   val brokerMetaPropsFile = \"meta.properties\"",
          "170:     (logDir, new BrokerMetadataCheckpoint(new File(logDir + File.separator + brokerMetaPropsFile)))",
          "",
          "[Added Lines]",
          "171:     (logDir, new BrokerMetadataCheckpoint(new File(logDir + File.separator + KafkaServer.brokerMetaPropsFile)))",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala": [
          "File: core/src/main/scala/kafka/tools/StorageTool.scala -> core/src/main/scala/kafka/tools/StorageTool.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: import java.io.PrintStream",
          "21: import java.nio.file.{Files, Paths}",
          "23: import kafka.utils.{Exit, Logging}",
          "24: import net.sourceforge.argparse4j.ArgumentParsers",
          "26: import net.sourceforge.argparse4j.inf.Namespace",
          "27: import org.apache.kafka.common.Uuid",
          "28: import org.apache.kafka.common.utils.Utils",
          "",
          "[Removed Lines]",
          "22: import kafka.server.{BrokerMetadataCheckpoint, KafkaConfig, MetaProperties, RawMetaProperties}",
          "25: import net.sourceforge.argparse4j.impl.Arguments.{store, storeTrue, append}",
          "",
          "[Added Lines]",
          "22: import kafka.server.{BrokerMetadataCheckpoint, KafkaConfig, KafkaServer, MetaProperties, RawMetaProperties}",
          "25: import net.sourceforge.argparse4j.impl.Arguments.{append, store, storeTrue}",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "281:         }",
          "282:       } else {",
          "283:         foundDirectories += directoryPath.toString",
          "285:         if (!Files.exists(metaPath)) {",
          "286:           problems += s\"$directoryPath is not formatted.\"",
          "287:         } else {",
          "",
          "[Removed Lines]",
          "284:         val metaPath = directoryPath.resolve(\"meta.properties\")",
          "",
          "[Added Lines]",
          "283:         val metaPath = directoryPath.resolve(KafkaServer.brokerMetaPropsFile)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "410:     }",
          "412:     val unformattedDirectories = directories.filter(directory => {",
          "414:           true",
          "415:       } else if (!ignoreFormatted) {",
          "416:         throw new TerseFailure(s\"Log directory $directory is already formatted. \" +",
          "",
          "[Removed Lines]",
          "413:       if (!Files.isDirectory(Paths.get(directory)) || !Files.exists(Paths.get(directory, \"meta.properties\"))) {",
          "",
          "[Added Lines]",
          "412:       if (!Files.isDirectory(Paths.get(directory)) || !Files.exists(Paths.get(directory, KafkaServer.brokerMetaPropsFile))) {",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "429:         case e: Throwable => throw new TerseFailure(s\"Unable to create storage \" +",
          "430:           s\"directory $directory: ${e.getMessage}\")",
          "431:       }",
          "433:       val checkpoint = new BrokerMetadataCheckpoint(metaPropertiesPath.toFile)",
          "436:       val bootstrapDirectory = new BootstrapDirectory(directory, Optional.empty())",
          "437:       bootstrapDirectory.writeBinaryFile(bootstrapMetadata)",
          "",
          "[Removed Lines]",
          "432:       val metaPropertiesPath = Paths.get(directory, \"meta.properties\")",
          "434:       checkpoint.write(metaProperties.toProperties)",
          "",
          "[Added Lines]",
          "431:       val metaPropertiesPath = Paths.get(directory, KafkaServer.brokerMetaPropsFile)",
          "433:       checkpoint.write(metaProperties.toPropertiesWithDirectoryId(Uuid.randomUuid().toString))",
          "",
          "---------------"
        ],
        "core/src/test/scala/kafka/server/BrokerMetadataCheckpointTest.scala||core/src/test/scala/kafka/server/BrokerMetadataCheckpointTest.scala": [
          "File: core/src/test/scala/kafka/server/BrokerMetadataCheckpointTest.scala -> core/src/test/scala/kafka/server/BrokerMetadataCheckpointTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "168:       for (mp <- metaProperties) {",
          "169:         val logDir = TestUtils.tempDirectory()",
          "170:         logDirs += logDir",
          "172:         val fs = new FileOutputStream(propFile)",
          "173:         try {",
          "174:           mp.props.store(fs, \"\")",
          "",
          "[Removed Lines]",
          "171:         val propFile = new File(logDir.getAbsolutePath, \"meta.properties\")",
          "",
          "[Added Lines]",
          "171:         val propFile = new File(logDir.getAbsolutePath, KafkaServer.brokerMetaPropsFile)",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/log/LogManagerTest.scala||core/src/test/scala/unit/kafka/log/LogManagerTest.scala": [
          "File: core/src/test/scala/unit/kafka/log/LogManagerTest.scala -> core/src/test/scala/unit/kafka/log/LogManagerTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: import com.yammer.metrics.core.{Gauge, MetricName}",
          "21: import kafka.server.checkpoints.OffsetCheckpointFile",
          "22: import kafka.server.metadata.{ConfigRepository, MockConfigRepository}",
          "24: import kafka.utils._",
          "25: import org.apache.directory.api.util.FileUtils",
          "26: import org.apache.kafka.common.config.TopicConfig",
          "27: import org.apache.kafka.common.errors.OffsetOutOfRangeException",
          "28: import org.apache.kafka.common.utils.Utils",
          "30: import org.junit.jupiter.api.Assertions._",
          "31: import org.junit.jupiter.api.{AfterEach, BeforeEach, Test}",
          "32: import org.mockito.ArgumentMatchers.any",
          "",
          "[Removed Lines]",
          "23: import kafka.server.BrokerTopicStats",
          "29: import org.apache.kafka.common.{KafkaException, TopicPartition}",
          "",
          "[Added Lines]",
          "23: import kafka.server.{BrokerMetadataCheckpoint, BrokerTopicStats, KafkaServer, RawMetaProperties}",
          "29: import org.apache.kafka.common.{KafkaException, TopicPartition, Uuid}",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1010:     assertEquals(8, invokedCount)",
          "1011:     assertEquals(4, failureCount)",
          "1012:   }",
          "1013: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1014:   @Test",
          "1015:   def testLoadDirectoryIds(): Unit = {",
          "1016:     def writeMetaProperties(dir: File, id: Option[String] = None): Unit = {",
          "1017:       val rawProps = new RawMetaProperties()",
          "1018:       rawProps.nodeId = 1",
          "1019:       rawProps.clusterId = \"IVT1Seu3QjacxS7oBTKhDQ\"",
          "1020:       id.foreach(v => rawProps.directoryId = v)",
          "1021:       new BrokerMetadataCheckpoint(new File(dir, KafkaServer.brokerMetaPropsFile)).write(rawProps.props)",
          "1022:     }",
          "1023:     val dirs: Seq[File] = Seq.fill(5)(TestUtils.tempDir())",
          "1024:     writeMetaProperties(dirs(0))",
          "1025:     writeMetaProperties(dirs(1), Some(\"ZwkGXjB0TvSF6mjVh6gO7Q\"))",
          "1027:     writeMetaProperties(dirs(3), Some(\"kQfNPJ2FTHq_6Qlyyv6Jqg\"))",
          "1028:     writeMetaProperties(dirs(4))",
          "1030:     logManager = createLogManager(dirs)",
          "1032:     assertTrue(logManager.directoryId(dirs(0).getAbsolutePath).isDefined)",
          "1033:     assertEquals(Some(Uuid.fromString(\"ZwkGXjB0TvSF6mjVh6gO7Q\")), logManager.directoryId(dirs(1).getAbsolutePath))",
          "1034:     assertEquals(None, logManager.directoryId(dirs(2).getAbsolutePath))",
          "1035:     assertEquals(Some(Uuid.fromString(\"kQfNPJ2FTHq_6Qlyyv6Jqg\")), logManager.directoryId(dirs(3).getAbsolutePath))",
          "1036:     assertTrue(logManager.directoryId(dirs(4).getAbsolutePath).isDefined)",
          "1037:     assertEquals(4, logManager.directoryIds.size)",
          "1038:   }",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/server/KafkaRaftServerTest.scala||core/src/test/scala/unit/kafka/server/KafkaRaftServerTest.scala": [
          "File: core/src/test/scala/unit/kafka/server/KafkaRaftServerTest.scala -> core/src/test/scala/unit/kafka/server/KafkaRaftServerTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "91:     logDir: File,",
          "92:     metaProperties: MetaProperties",
          "93:   ): Unit = {",
          "95:     val checkpoint = new BrokerMetadataCheckpoint(metaPropertiesFile)",
          "96:     checkpoint.write(metaProperties.toProperties)",
          "97:   }",
          "",
          "[Removed Lines]",
          "94:     val metaPropertiesFile = new File(logDir.getAbsolutePath, \"meta.properties\")",
          "",
          "[Added Lines]",
          "94:     val metaPropertiesFile = new File(logDir.getAbsolutePath, KafkaServer.brokerMetaPropsFile)",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/server/ServerGenerateBrokerIdTest.scala||core/src/test/scala/unit/kafka/server/ServerGenerateBrokerIdTest.scala": [
          "File: core/src/test/scala/unit/kafka/server/ServerGenerateBrokerIdTest.scala -> core/src/test/scala/unit/kafka/server/ServerGenerateBrokerIdTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "33:   var config1: KafkaConfig = _",
          "34:   var props2: Properties = _",
          "35:   var config2: KafkaConfig = _",
          "37:   var servers: Seq[KafkaServer] = Seq()",
          "39:   @BeforeEach",
          "",
          "[Removed Lines]",
          "36:   val brokerMetaPropsFile = \"meta.properties\"",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "160:     serverB.config.logDirs.foreach { logDir =>",
          "162:       assertFalse(brokerMetaFile.exists())",
          "163:     }",
          "",
          "[Removed Lines]",
          "161:       val brokerMetaFile = new File(logDir + File.separator + brokerMetaPropsFile)",
          "",
          "[Added Lines]",
          "160:       val brokerMetaFile = new File(logDir + File.separator + KafkaServer.brokerMetaPropsFile)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "180:   def verifyBrokerMetadata(logDirs: Seq[String], brokerId: Int): Boolean = {",
          "181:     for (logDir <- logDirs) {",
          "182:       val brokerMetadataOpt = new BrokerMetadataCheckpoint(",
          "184:       brokerMetadataOpt match {",
          "185:         case Some(properties) =>",
          "186:           val brokerMetadata = new RawMetaProperties(properties)",
          "",
          "[Removed Lines]",
          "183:         new File(logDir + File.separator + brokerMetaPropsFile)).read()",
          "",
          "[Added Lines]",
          "182:         new File(logDir + File.separator + KafkaServer.brokerMetaPropsFile)).read()",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/server/ServerGenerateClusterIdTest.scala||core/src/test/scala/unit/kafka/server/ServerGenerateClusterIdTest.scala": [
          "File: core/src/test/scala/unit/kafka/server/ServerGenerateClusterIdTest.scala -> core/src/test/scala/unit/kafka/server/ServerGenerateClusterIdTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "38:   var config2: KafkaConfig = _",
          "39:   var config3: KafkaConfig = _",
          "40:   var servers: Seq[KafkaServer] = Seq()",
          "43:   @BeforeEach",
          "44:   override def setUp(testInfo: TestInfo): Unit = {",
          "",
          "[Removed Lines]",
          "41:   val brokerMetaPropsFile = \"meta.properties\"",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "214:   def forgeBrokerMetadata(logDir: String, brokerId: Int, clusterId: String): Unit = {",
          "215:     val checkpoint = new BrokerMetadataCheckpoint(",
          "217:     checkpoint.write(ZkMetaProperties(clusterId, brokerId).toProperties)",
          "218:   }",
          "220:   def verifyBrokerMetadata(logDirs: Seq[String], clusterId: String): Boolean = {",
          "221:     for (logDir <- logDirs) {",
          "222:       val brokerMetadataOpt = new BrokerMetadataCheckpoint(",
          "224:       brokerMetadataOpt match {",
          "225:         case Some(properties) =>",
          "226:           val brokerMetadata = new RawMetaProperties(properties)",
          "",
          "[Removed Lines]",
          "216:       new File(logDir + File.separator + brokerMetaPropsFile))",
          "223:         new File(logDir + File.separator + brokerMetaPropsFile)).read()",
          "",
          "[Added Lines]",
          "215:       new File(logDir + File.separator + KafkaServer.brokerMetaPropsFile))",
          "222:         new File(logDir + File.separator + KafkaServer.brokerMetaPropsFile)).read()",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala": [
          "File: core/src/test/scala/unit/kafka/tools/StorageToolTest.scala -> core/src/test/scala/unit/kafka/tools/StorageToolTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: import java.io.{ByteArrayOutputStream, PrintStream}",
          "21: import java.nio.charset.StandardCharsets",
          "23: import java.util",
          "24: import java.util.Properties",
          "27: import kafka.utils.Exit",
          "28: import kafka.utils.TestUtils",
          "29: import org.apache.kafka.common.utils.Utils",
          "30: import org.apache.kafka.server.common.MetadataVersion",
          "31: import org.apache.kafka.common.metadata.UserScramCredentialRecord",
          "33: import org.junit.jupiter.api.{Test, Timeout}",
          "35: import scala.collection.mutable",
          "",
          "[Removed Lines]",
          "22: import java.nio.file.Files",
          "25: import org.apache.kafka.common.KafkaException",
          "26: import kafka.server.{KafkaConfig, MetaProperties}",
          "32: import org.junit.jupiter.api.Assertions.{assertEquals, assertThrows, assertTrue}",
          "",
          "[Added Lines]",
          "22: import java.nio.file.{Files, Paths}",
          "25: import org.apache.kafka.common.{KafkaException, Uuid}",
          "26: import kafka.server.{BrokerMetadataCheckpoint, KafkaConfig, KafkaServer, MetaProperties}",
          "29: import org.apache.commons.io.output.NullOutputStream",
          "33: import org.junit.jupiter.api.Assertions.{assertEquals, assertFalse, assertThrows, assertTrue}",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "114:     val stream = new ByteArrayOutputStream()",
          "115:     val tempDir = TestUtils.tempDir()",
          "116:     try {",
          "118:         String.join(\"\\n\", util.Arrays.asList(",
          "119:           \"version=1\",",
          "120:           \"cluster.id=XcZZOzUqS4yHOjhMQB6JLQ\")).",
          "",
          "[Removed Lines]",
          "117:       Files.write(tempDir.toPath.resolve(\"meta.properties\"),",
          "",
          "[Added Lines]",
          "118:       Files.write(tempDir.toPath.resolve(KafkaServer.brokerMetaPropsFile),",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "138:     val stream = new ByteArrayOutputStream()",
          "139:     val tempDir = TestUtils.tempDir()",
          "140:     try {",
          "142:         String.join(\"\\n\", util.Arrays.asList(",
          "143:           \"version=0\",",
          "144:           \"broker.id=1\",",
          "",
          "[Removed Lines]",
          "141:       Files.write(tempDir.toPath.resolve(\"meta.properties\"),",
          "",
          "[Added Lines]",
          "142:       Files.write(tempDir.toPath.resolve(KafkaServer.brokerMetaPropsFile),",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "361:       Exit.resetExitProcedure()",
          "362:     }",
          "363:   }",
          "364: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "366:   @Test",
          "367:   def testDirUuidGeneration(): Unit = {",
          "368:     val tempDir = TestUtils.tempDir()",
          "369:     try {",
          "370:       val metaProperties = MetaProperties(",
          "371:         clusterId = \"XcZZOzUqS4yHOjhMQB6JLQ\", nodeId = 2)",
          "372:       val bootstrapMetadata = StorageTool.buildBootstrapMetadata(MetadataVersion.latest(), None, \"test format command\")",
          "373:       assertEquals(0, StorageTool.",
          "374:         formatCommand(new PrintStream(NullOutputStream.NULL_OUTPUT_STREAM), Seq(tempDir.toString), metaProperties, bootstrapMetadata, MetadataVersion.latest(), ignoreFormatted = false))",
          "376:       val metaPropertiesFile = Paths.get(tempDir.toURI).resolve(KafkaServer.brokerMetaPropsFile).toFile",
          "377:       assertTrue(metaPropertiesFile.exists())",
          "378:       val properties = new BrokerMetadataCheckpoint(metaPropertiesFile).read().get",
          "379:       assertTrue(properties.containsKey(\"directory.id\"))",
          "380:       val directoryId = Uuid.fromString(properties.getProperty(\"directory.id\"))",
          "381:       assertFalse(Uuid.RESERVED.contains(directoryId))",
          "382:     } finally Utils.delete(tempDir)",
          "383:   }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "7060c08d6f9b0408e7f40a90499caf2e636fac61",
      "candidate_info": {
        "commit_hash": "7060c08d6f9b0408e7f40a90499caf2e636fac61",
        "repo": "apache/kafka",
        "commit_url": "https://github.com/apache/kafka/commit/7060c08d6f9b0408e7f40a90499caf2e636fac61",
        "files": [
          "checkstyle/suppressions.xml",
          "core/src/main/scala/kafka/log/LogManager.scala",
          "core/src/main/scala/kafka/server/BrokerMetadataCheckpoint.scala",
          "core/src/main/scala/kafka/server/BrokerServer.scala",
          "core/src/main/scala/kafka/server/ControllerServer.scala",
          "core/src/main/scala/kafka/server/KafkaRaftServer.scala",
          "core/src/main/scala/kafka/server/KafkaServer.scala",
          "core/src/main/scala/kafka/server/SharedServer.scala",
          "core/src/main/scala/kafka/tools/StorageTool.scala",
          "core/src/test/java/kafka/testkit/BrokerNode.java",
          "core/src/test/java/kafka/testkit/ControllerNode.java",
          "core/src/test/java/kafka/testkit/KafkaClusterTestKit.java",
          "core/src/test/java/kafka/testkit/TestKitNode.java",
          "core/src/test/java/kafka/testkit/TestKitNodes.java",
          "core/src/test/scala/integration/kafka/server/QuorumTestHarness.scala",
          "core/src/test/scala/kafka/server/BrokerMetadataCheckpointTest.scala",
          "core/src/test/scala/unit/kafka/log/LogManagerTest.scala",
          "core/src/test/scala/unit/kafka/server/KafkaRaftServerTest.scala",
          "core/src/test/scala/unit/kafka/server/ServerGenerateBrokerIdTest.scala",
          "core/src/test/scala/unit/kafka/server/ServerGenerateClusterIdTest.scala",
          "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala",
          "metadata/src/main/java/org/apache/kafka/metadata/bootstrap/BootstrapDirectory.java",
          "metadata/src/main/java/org/apache/kafka/metadata/properties/MetaProperties.java",
          "metadata/src/main/java/org/apache/kafka/metadata/properties/MetaPropertiesEnsemble.java",
          "metadata/src/main/java/org/apache/kafka/metadata/properties/MetaPropertiesVersion.java",
          "metadata/src/main/java/org/apache/kafka/metadata/properties/PropertiesUtils.java",
          "metadata/src/test/java/org/apache/kafka/metadata/properties/MetaPropertiesEnsembleTest.java",
          "metadata/src/test/java/org/apache/kafka/metadata/properties/MetaPropertiesTest.java",
          "metadata/src/test/java/org/apache/kafka/metadata/properties/MetaPropertiesVersionTest.java",
          "metadata/src/test/java/org/apache/kafka/metadata/properties/PropertiesUtilsTest.java"
        ],
        "message": "MINOR: Rewrite the meta.properties handling code in Java and fix some issues #14628 (#14628)\n\nmeta.properties files are used by Kafka to identify log directories within the filesystem.\nPreviously, the code for handling them was in BrokerMetadataCheckpoint.scala. This PR rewrites the\ncode for handling them as Java and moves it to the apache.kafka.metadata.properties namespace. It\nalso gets rid of the separate types for v0 and v1 meta.properties objects. Having separate types\nwasn't so bad back when we had a strict rule that zk clusters used v0 and kraft clusters used v1.\nBut ZK migration has blurred the lines. Now, a zk cluster may have either v0 or v1, if it is\nmigrating, and a kraft cluster may have either v0 or v1, at any time.\n\nThe new code distinguishes between an individual meta.properties file, which is represented by\nMetaProperties, and a collection of meta.properties files, which is represented by\nMetaPropertiesEnsemble. It is useful to have this distinction, because in JBOD mode, even if some\nlog directories are inaccessible, we can still use the ensemble to extract needed information like\nthe cluster ID. (Of course, even when not in JBOD mode, KRaft servers have always been able to\nconfigure a metadata log directory separate from the main log directory.)\n\nSince we recently added a unique directory.id to each meta.properties file, the previous convention\nof passing a \"canonical\" MetaProperties object for the cluster around to various places in the code\nneeds to be revisited. After all, we can no longer assume all of the meta.properties files are the\nsame. This PR fixes these parts of the code. For example, it fixes the constructors of\nControllerApis and RaftManager to just take a cluster ID, rather than a MetaProperties object. It\nfixes some other parts of the code, like the constructor of SharedServer, to take a\nMetaPropertiesEnsemble object.\n\nAnother goal of this PR was to centralize meta.properties validation a bit more and make it\nunit-testable. For this purpose, the PR adds MetaPropertiesEnsemble.verify, and a few other\nverification methods. These enforce invariants like \"the metadata directory must be readable,\" and\nso on.\n\nReviewers: Igor Soarez <soarez@apple.com>, David Arthur <mumrah@gmail.com>, Divij Vaidya <diviv@amazon.com>, Proven Provenzano <pprovenzano@confluent.io>",
        "before_after_code_files": [
          "core/src/main/scala/kafka/log/LogManager.scala||core/src/main/scala/kafka/log/LogManager.scala",
          "core/src/main/scala/kafka/server/BrokerMetadataCheckpoint.scala||core/src/main/scala/kafka/server/BrokerMetadataCheckpoint.scala",
          "core/src/main/scala/kafka/server/BrokerServer.scala||core/src/main/scala/kafka/server/BrokerServer.scala",
          "core/src/main/scala/kafka/server/ControllerServer.scala||core/src/main/scala/kafka/server/ControllerServer.scala",
          "core/src/main/scala/kafka/server/KafkaRaftServer.scala||core/src/main/scala/kafka/server/KafkaRaftServer.scala",
          "core/src/main/scala/kafka/server/KafkaServer.scala||core/src/main/scala/kafka/server/KafkaServer.scala",
          "core/src/main/scala/kafka/server/SharedServer.scala||core/src/main/scala/kafka/server/SharedServer.scala",
          "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
          "core/src/test/java/kafka/testkit/BrokerNode.java||core/src/test/java/kafka/testkit/BrokerNode.java",
          "core/src/test/java/kafka/testkit/ControllerNode.java||core/src/test/java/kafka/testkit/ControllerNode.java",
          "core/src/test/java/kafka/testkit/KafkaClusterTestKit.java||core/src/test/java/kafka/testkit/KafkaClusterTestKit.java",
          "core/src/test/java/kafka/testkit/TestKitNode.java||core/src/test/java/kafka/testkit/TestKitNode.java",
          "core/src/test/java/kafka/testkit/TestKitNodes.java||core/src/test/java/kafka/testkit/TestKitNodes.java",
          "core/src/test/scala/integration/kafka/server/QuorumTestHarness.scala||core/src/test/scala/integration/kafka/server/QuorumTestHarness.scala",
          "core/src/test/scala/kafka/server/BrokerMetadataCheckpointTest.scala||core/src/test/scala/kafka/server/BrokerMetadataCheckpointTest.scala",
          "core/src/test/scala/unit/kafka/log/LogManagerTest.scala||core/src/test/scala/unit/kafka/log/LogManagerTest.scala",
          "core/src/test/scala/unit/kafka/server/KafkaRaftServerTest.scala||core/src/test/scala/unit/kafka/server/KafkaRaftServerTest.scala",
          "core/src/test/scala/unit/kafka/server/ServerGenerateBrokerIdTest.scala||core/src/test/scala/unit/kafka/server/ServerGenerateBrokerIdTest.scala",
          "core/src/test/scala/unit/kafka/server/ServerGenerateClusterIdTest.scala||core/src/test/scala/unit/kafka/server/ServerGenerateClusterIdTest.scala",
          "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala",
          "metadata/src/main/java/org/apache/kafka/metadata/bootstrap/BootstrapDirectory.java||metadata/src/main/java/org/apache/kafka/metadata/bootstrap/BootstrapDirectory.java",
          "metadata/src/main/java/org/apache/kafka/metadata/properties/MetaProperties.java||metadata/src/main/java/org/apache/kafka/metadata/properties/MetaProperties.java",
          "metadata/src/main/java/org/apache/kafka/metadata/properties/MetaPropertiesEnsemble.java||metadata/src/main/java/org/apache/kafka/metadata/properties/MetaPropertiesEnsemble.java",
          "metadata/src/main/java/org/apache/kafka/metadata/properties/MetaPropertiesVersion.java||metadata/src/main/java/org/apache/kafka/metadata/properties/MetaPropertiesVersion.java",
          "metadata/src/main/java/org/apache/kafka/metadata/properties/PropertiesUtils.java||metadata/src/main/java/org/apache/kafka/metadata/properties/PropertiesUtils.java",
          "metadata/src/test/java/org/apache/kafka/metadata/properties/MetaPropertiesEnsembleTest.java||metadata/src/test/java/org/apache/kafka/metadata/properties/MetaPropertiesEnsembleTest.java",
          "metadata/src/test/java/org/apache/kafka/metadata/properties/MetaPropertiesTest.java||metadata/src/test/java/org/apache/kafka/metadata/properties/MetaPropertiesTest.java",
          "metadata/src/test/java/org/apache/kafka/metadata/properties/MetaPropertiesVersionTest.java||metadata/src/test/java/org/apache/kafka/metadata/properties/MetaPropertiesVersionTest.java",
          "metadata/src/test/java/org/apache/kafka/metadata/properties/PropertiesUtilsTest.java||metadata/src/test/java/org/apache/kafka/metadata/properties/PropertiesUtilsTest.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
            "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
          ],
          "candidate": [
            "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
            "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
          ]
        }
      },
      "candidate_diff": {
        "core/src/main/scala/kafka/log/LogManager.scala||core/src/main/scala/kafka/log/LogManager.scala": [
          "File: core/src/main/scala/kafka/log/LogManager.scala -> core/src/main/scala/kafka/log/LogManager.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: package kafka.log",
          "20: import java.io._",
          "22: import java.util.concurrent._",
          "23: import java.util.concurrent.atomic.AtomicInteger",
          "24: import kafka.server.checkpoints.OffsetCheckpointFile",
          "25: import kafka.server.metadata.ConfigRepository",
          "26: import kafka.server._",
          "27: import kafka.utils._",
          "29: import org.apache.kafka.common.utils.{KafkaThread, Time, Utils}",
          "30: import org.apache.kafka.common.errors.{InconsistentTopicIdException, KafkaStorageException, LogDirNotFoundException}",
          "",
          "[Removed Lines]",
          "21: import java.nio.file.Files",
          "28: import org.apache.kafka.common.{DirectoryId, KafkaException, TopicPartition, Uuid}",
          "",
          "[Added Lines]",
          "21: import java.nio.file.{Files, NoSuchFileException}",
          "28: import org.apache.kafka.common.{KafkaException, TopicPartition, Uuid}",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "35: import scala.util.{Failure, Success, Try}",
          "36: import kafka.utils.Implicits._",
          "37: import org.apache.kafka.common.config.TopicConfig",
          "39: import java.util.{OptionalLong, Properties}",
          "40: import org.apache.kafka.server.common.MetadataVersion",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "38: import org.apache.kafka.metadata.properties.{MetaProperties, MetaPropertiesEnsemble, PropertiesUtils}",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "122:   }",
          "124:   private val dirLocks = lockLogDirs(liveLogDirs)",
          "128:   @volatile private var recoveryPointCheckpoints = liveLogDirs.map(dir =>",
          "129:     (dir, new OffsetCheckpointFile(new File(dir, RecoveryPointCheckpointFile), logDirFailureChannel))).toMap",
          "130:   @volatile private var logStartOffsetCheckpoints = liveLogDirs.map(dir =>",
          "",
          "[Removed Lines]",
          "125:   private val dirIds = directoryIds(liveLogDirs)",
          "127:   private[log] val directoryIds: Set[Uuid] = dirIds.values.toSet",
          "",
          "[Added Lines]",
          "126:   val directoryIds: Map[String, Uuid] = loadDirectoryIds(liveLogDirs)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "284:       try {",
          "298:       } catch {",
          "304:   }",
          "306:   private def addLogToBeDeleted(log: UnifiedLog): Unit = {",
          "",
          "[Removed Lines]",
          "275:   def directoryId(dir: String): Option[Uuid] = dirIds.get(dir)",
          "282:   private def directoryIds(dirs: Seq[File]): Map[String, Uuid] = {",
          "283:     dirs.flatMap { dir =>",
          "285:         val metadataCheckpoint = new BrokerMetadataCheckpoint(new File(dir, KafkaServer.brokerMetaPropsFile))",
          "286:         metadataCheckpoint.read().map { props =>",
          "287:           val rawMetaProperties = new RawMetaProperties(props)",
          "288:           val uuid = rawMetaProperties.directoryId match {",
          "289:             case Some(uuidStr) => Uuid.fromString(uuidStr)",
          "290:             case None =>",
          "291:               val uuid = DirectoryId.random()",
          "292:               rawMetaProperties.directoryId = uuid.toString",
          "293:               metadataCheckpoint.write(rawMetaProperties.props)",
          "294:               uuid",
          "295:           }",
          "296:           dir.getAbsolutePath -> uuid",
          "297:         }.toMap",
          "299:         case e: IOException =>",
          "300:           logDirFailureChannel.maybeAddOfflineLogDir(dir.getAbsolutePath, s\"Disk error while loading ID $dir\", e)",
          "301:           None",
          "302:       }",
          "303:     }.toMap",
          "",
          "[Added Lines]",
          "274:   def directoryId(dir: String): Option[Uuid] = directoryIds.get(dir)",
          "281:   private def loadDirectoryIds(logDirs: Seq[File]): Map[String, Uuid] = {",
          "282:     val result = mutable.HashMap[String, Uuid]()",
          "283:     logDirs.foreach(logDir => {",
          "285:         val props = PropertiesUtils.readPropertiesFile(",
          "286:           new File(logDir, MetaPropertiesEnsemble.META_PROPERTIES_NAME).getAbsolutePath)",
          "287:         val metaProps = new MetaProperties.Builder(props).build()",
          "288:         metaProps.directoryId().ifPresent(directoryId => {",
          "289:           result += (logDir.getAbsolutePath -> directoryId)",
          "290:         })",
          "292:         case e: NoSuchFileException =>",
          "293:           info(s\"No meta.properties file found in ${logDir}.\")",
          "294:          case e: IOException =>",
          "295:           logDirFailureChannel.maybeAddOfflineLogDir(logDir.getAbsolutePath, s\"Disk error while loading ID $logDir\", e)",
          "296:        }",
          "297:     })",
          "298:     result",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/server/BrokerMetadataCheckpoint.scala||core/src/main/scala/kafka/server/BrokerMetadataCheckpoint.scala": [
          "File: core/src/main/scala/kafka/server/BrokerMetadataCheckpoint.scala -> core/src/main/scala/kafka/server/BrokerMetadataCheckpoint.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/server/BrokerServer.scala||core/src/main/scala/kafka/server/BrokerServer.scala": [
          "File: core/src/main/scala/kafka/server/BrokerServer.scala -> core/src/main/scala/kafka/server/BrokerServer.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "56: import java.util.concurrent.atomic.AtomicBoolean",
          "57: import java.util.concurrent.locks.ReentrantLock",
          "58: import java.util.concurrent.{CompletableFuture, ExecutionException, TimeUnit, TimeoutException}",
          "60: import scala.compat.java8.OptionConverters.RichOptionForJava8",
          "61: import scala.jdk.CollectionConverters._",
          "",
          "[Removed Lines]",
          "59: import scala.collection.{Map, Seq}",
          "",
          "[Added Lines]",
          "59: import scala.collection.Map",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "67: class BrokerServer(",
          "70: ) extends KafkaBroker {",
          "71:   val config = sharedServer.brokerConfig",
          "72:   val time = sharedServer.time",
          "",
          "[Removed Lines]",
          "68:   val sharedServer: SharedServer,",
          "69:   val initialOfflineDirs: Seq[String],",
          "",
          "[Added Lines]",
          "68:   val sharedServer: SharedServer",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "135:   @volatile var brokerTopicStats: BrokerTopicStats = _",
          "139:   var brokerMetadataPublisher: BrokerMetadataPublisher = _",
          "",
          "[Removed Lines]",
          "137:   val clusterId: String = sharedServer.metaProps.clusterId",
          "",
          "[Added Lines]",
          "136:   val clusterId: String = sharedServer.metaPropsEnsemble.clusterId().get()",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "203:       remoteLogManagerOpt = createRemoteLogManager()",
          "",
          "[Removed Lines]",
          "200:       logManager = LogManager(config, initialOfflineDirs, metadataCache, kafkaScheduler, time,",
          "201:         brokerTopicStats, logDirFailureChannel, keepPartitionMetadataFile = true)",
          "",
          "[Added Lines]",
          "199:       logManager = LogManager(config,",
          "200:         sharedServer.metaPropsEnsemble.errorLogDirs().asScala.toSeq,",
          "201:         metadataCache,",
          "202:         kafkaScheduler,",
          "203:         time,",
          "204:         brokerTopicStats,",
          "205:         logDirFailureChannel,",
          "206:         keepPartitionMetadataFile = true)",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "338:       lifecycleManager.start(",
          "339:         () => sharedServer.loader.lastAppliedOffset(),",
          "340:         brokerLifecycleChannelManager,",
          "342:         listenerInfo.toBrokerRegistrationRequest,",
          "343:         featuresRemapped,",
          "344:         logManager.readBrokerEpochFromCleanShutdownFiles()",
          "",
          "[Removed Lines]",
          "341:         sharedServer.metaProps.clusterId,",
          "",
          "[Added Lines]",
          "346:         clusterId,",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/server/ControllerServer.scala||core/src/main/scala/kafka/server/ControllerServer.scala": [
          "File: core/src/main/scala/kafka/server/ControllerServer.scala -> core/src/main/scala/kafka/server/ControllerServer.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "138:     true",
          "139:   }",
          "143:   def startup(): Unit = {",
          "144:     if (!maybeChangeStatus(SHUTDOWN, STARTING)) return",
          "",
          "[Removed Lines]",
          "141:   def clusterId: String = sharedServer.clusterId()",
          "",
          "[Added Lines]",
          "141:   def clusterId: String = sharedServer.clusterId",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "239:         quorumControllerMetrics = new QuorumControllerMetrics(Optional.of(KafkaYammerMetrics.defaultRegistry), time, config.migrationEnabled)",
          "242:           setTime(time).",
          "243:           setThreadNamePrefix(s\"quorum-controller-${config.nodeId}-\").",
          "244:           setConfigSchema(configSchema).",
          "",
          "[Removed Lines]",
          "241:         new QuorumController.Builder(config.nodeId, sharedServer.metaProps.clusterId).",
          "",
          "[Added Lines]",
          "241:         new QuorumController.Builder(config.nodeId, sharedServer.clusterId).",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/server/KafkaRaftServer.scala||core/src/main/scala/kafka/server/KafkaRaftServer.scala": [
          "File: core/src/main/scala/kafka/server/KafkaRaftServer.scala -> core/src/main/scala/kafka/server/KafkaRaftServer.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: import java.io.File",
          "20: import java.util.concurrent.CompletableFuture",
          "22: import kafka.log.UnifiedLog",
          "23: import kafka.metrics.KafkaMetricsReporter",
          "24: import kafka.server.KafkaRaftServer.{BrokerRole, ControllerRole}",
          "",
          "[Removed Lines]",
          "21: import kafka.common.InconsistentNodeIdException",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "29: import org.apache.kafka.common.{KafkaException, Uuid}",
          "30: import org.apache.kafka.metadata.KafkaConfigSchema",
          "31: import org.apache.kafka.metadata.bootstrap.{BootstrapDirectory, BootstrapMetadata}",
          "32: import org.apache.kafka.raft.RaftConfig",
          "33: import org.apache.kafka.server.config.ServerTopicConfigSynonyms",
          "34: import org.apache.kafka.server.metrics.KafkaYammerMetrics",
          "35: import org.apache.kafka.storage.internals.log.LogConfig",
          "39: import scala.jdk.CollectionConverters._",
          "",
          "[Removed Lines]",
          "37: import java.util.Optional",
          "38: import scala.collection.Seq",
          "",
          "[Added Lines]",
          "31: import org.apache.kafka.metadata.properties.MetaPropertiesEnsemble.VerificationFlag.{REQUIRE_AT_LEAST_ONE_VALID, REQUIRE_METADATA_LOG_DIR}",
          "32: import org.apache.kafka.metadata.properties.{MetaProperties, MetaPropertiesEnsemble}",
          "37: import org.slf4j.Logger",
          "39: import java.util",
          "40: import java.util.{Optional, OptionalInt}",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "54:   KafkaMetricsReporter.startReporters(VerifiableProperties(config.originals))",
          "55:   KafkaYammerMetrics.INSTANCE.configure(config.originals)",
          "59:   private val metrics = Server.initializeMetrics(",
          "60:     config,",
          "61:     time,",
          "63:   )",
          "65:   private val controllerQuorumVotersFuture = CompletableFuture.completedFuture(",
          "",
          "[Removed Lines]",
          "57:   private val (metaProps, bootstrapMetadata, offlineDirs) = KafkaRaftServer.initializeLogDirs(config)",
          "62:     metaProps.clusterId",
          "",
          "[Added Lines]",
          "59:   private val (metaPropsEnsemble, bootstrapMetadata) =",
          "60:     KafkaRaftServer.initializeLogDirs(config, this.logger.underlying, this.logIdent)",
          "65:     metaPropsEnsemble.clusterId().get()",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "68:   private val sharedServer = new SharedServer(",
          "69:     config,",
          "71:     time,",
          "72:     metrics,",
          "73:     controllerQuorumVotersFuture,",
          "",
          "[Removed Lines]",
          "70:     metaProps,",
          "",
          "[Added Lines]",
          "73:     metaPropsEnsemble,",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "75:   )",
          "77:   private val broker: Option[BrokerServer] = if (config.processRoles.contains(BrokerRole)) {",
          "79:   } else {",
          "80:     None",
          "81:   }",
          "",
          "[Removed Lines]",
          "78:     Some(new BrokerServer(sharedServer, offlineDirs))",
          "",
          "[Added Lines]",
          "81:     Some(new BrokerServer(sharedServer))",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "148:     val metadataPartitionDirName = UnifiedLog.logDirName(MetadataPartition)",
          "155:       }",
          "156:     }",
          "166:     val bootstrapDirectory = new BootstrapDirectory(config.metadataLogDir,",
          "167:       Optional.ofNullable(config.interBrokerProtocolVersionString))",
          "168:     val bootstrapMetadata = bootstrapDirectory.read()",
          "171:   }",
          "173:   val configSchema = new KafkaConfigSchema(Map(",
          "",
          "[Removed Lines]",
          "138:   def initializeLogDirs(config: KafkaConfig): (MetaProperties, BootstrapMetadata, Seq[String]) = {",
          "139:     val logDirs = (config.logDirs.toSet + config.metadataLogDir).toSeq",
          "140:     val (rawMetaProperties, offlineDirs) = BrokerMetadataCheckpoint.",
          "141:       getBrokerMetadataAndOfflineDirs(logDirs, ignoreMissing = false, kraftMode = true)",
          "143:     if (offlineDirs.contains(config.metadataLogDir)) {",
          "144:       throw new KafkaException(\"Cannot start server since `meta.properties` could not be \" +",
          "145:         s\"loaded from ${config.metadataLogDir}\")",
          "146:     }",
          "149:     val onlineNonMetadataDirs = logDirs.diff(offlineDirs :+ config.metadataLogDir)",
          "150:     onlineNonMetadataDirs.foreach { logDir =>",
          "151:       val metadataDir = new File(logDir, metadataPartitionDirName)",
          "152:       if (metadataDir.exists) {",
          "153:         throw new KafkaException(s\"Found unexpected metadata location in data directory `$metadataDir` \" +",
          "154:           s\"(the configured metadata directory is ${config.metadataLogDir}).\")",
          "158:     val metaProperties = MetaProperties.parse(rawMetaProperties)",
          "159:     if (config.nodeId != metaProperties.nodeId) {",
          "160:       throw new InconsistentNodeIdException(",
          "161:         s\"Configured node.id `${config.nodeId}` doesn't match stored node.id `${metaProperties.nodeId}' in \" +",
          "162:           \"meta.properties. If you moved your data, make sure your configured controller.id matches. \" +",
          "163:           \"If you intend to create a new broker, you should remove all data in your data directories (log.dirs).\")",
          "164:     }",
          "170:     (metaProperties, bootstrapMetadata, offlineDirs.toSeq)",
          "",
          "[Added Lines]",
          "141:   def initializeLogDirs(",
          "142:     config: KafkaConfig,",
          "143:     log: Logger,",
          "144:     logPrefix: String",
          "145:   ): (MetaPropertiesEnsemble, BootstrapMetadata) = {",
          "147:     val loader = new MetaPropertiesEnsemble.Loader()",
          "148:     loader.addMetadataLogDir(config.metadataLogDir)",
          "149:     config.logDirs.foreach(loader.addLogDir(_))",
          "150:     val initialMetaPropsEnsemble = loader.load()",
          "151:     val verificationFlags = util.EnumSet.of(REQUIRE_AT_LEAST_ONE_VALID, REQUIRE_METADATA_LOG_DIR)",
          "152:     initialMetaPropsEnsemble.verify(Optional.empty(), OptionalInt.of(config.nodeId), verificationFlags);",
          "156:     initialMetaPropsEnsemble.logDirProps().keySet().forEach(logDir => {",
          "157:       if (!logDir.equals(config.metadataLogDir)) {",
          "158:         val clusterMetadataTopic = new File(logDir, metadataPartitionDirName)",
          "159:         if (clusterMetadataTopic.exists) {",
          "160:           throw new KafkaException(s\"Found unexpected metadata location in data directory `$clusterMetadataTopic` \" +",
          "161:             s\"(the configured metadata directory is ${config.metadataLogDir}).\")",
          "162:         }",
          "164:     })",
          "167:     val metaPropsEnsemble = {",
          "168:       val copier = new MetaPropertiesEnsemble.Copier(initialMetaPropsEnsemble)",
          "169:       initialMetaPropsEnsemble.nonFailedDirectoryProps().forEachRemaining(e => {",
          "170:         val logDir = e.getKey",
          "171:         val metaProps = e.getValue",
          "172:         if (!metaProps.isPresent()) {",
          "173:           throw new RuntimeException(s\"No `meta.properties` found in $logDir (have you run `kafka-storage.sh` \" +",
          "174:             \"to format the directory?)\")",
          "175:         }",
          "176:         if (!metaProps.get().nodeId().isPresent()) {",
          "177:           throw new RuntimeException(s\"Error: node ID not found in $logDir\")",
          "178:         }",
          "179:         if (!metaProps.get().clusterId().isPresent()) {",
          "180:           throw new RuntimeException(s\"Error: cluster ID not found in $logDir\")",
          "181:         }",
          "182:         val builder = new MetaProperties.Builder(metaProps.get())",
          "183:         if (!builder.directoryId().isPresent()) {",
          "184:           builder.setDirectoryId(copier.generateValidDirectoryId())",
          "185:         }",
          "186:         copier.setLogDirProps(logDir, builder.build())",
          "187:         copier.setPreWriteHandler((logDir, _, _) => {",
          "188:           log.info(\"{}Rewriting {}{}meta.properties\", logPrefix, logDir, File.separator)",
          "189:         })",
          "190:       })",
          "191:       copier.writeLogDirChanges()",
          "192:       copier.copy()",
          "199:     (metaPropsEnsemble, bootstrapMetadata)",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/server/KafkaServer.scala||core/src/main/scala/kafka/server/KafkaServer.scala": [
          "File: core/src/main/scala/kafka/server/KafkaServer.scala -> core/src/main/scala/kafka/server/KafkaServer.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: package kafka.server",
          "20: import kafka.cluster.{Broker, EndPoint}",
          "22: import kafka.controller.KafkaController",
          "23: import kafka.coordinator.group.GroupCoordinatorAdapter",
          "24: import kafka.coordinator.transaction.{ProducerIdManager, TransactionCoordinator}",
          "",
          "[Removed Lines]",
          "21: import kafka.common.{GenerateBrokerIdException, InconsistentBrokerIdException, InconsistentClusterIdException}",
          "",
          "[Added Lines]",
          "21: import kafka.common.GenerateBrokerIdException",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "47: import org.apache.kafka.common.utils.{AppInfoParser, LogContext, Time, Utils}",
          "48: import org.apache.kafka.common.{Endpoint, KafkaException, Node, TopicPartition}",
          "49: import org.apache.kafka.coordinator.group.GroupCoordinator",
          "50: import org.apache.kafka.metadata.{BrokerState, MetadataRecordSerde, VersionRange}",
          "51: import org.apache.kafka.raft.RaftConfig",
          "52: import org.apache.kafka.server.authorizer.Authorizer",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "50: import org.apache.kafka.metadata.properties.MetaPropertiesEnsemble.VerificationFlag",
          "51: import org.apache.kafka.metadata.properties.MetaPropertiesEnsemble.VerificationFlag.REQUIRE_V0",
          "52: import org.apache.kafka.metadata.properties.{MetaProperties, MetaPropertiesEnsemble}",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "62: import java.io.{File, IOException}",
          "63: import java.net.{InetAddress, SocketTimeoutException}",
          "65: import java.util.concurrent._",
          "66: import java.util.concurrent.atomic.{AtomicBoolean, AtomicInteger}",
          "67: import scala.collection.{Map, Seq}",
          "",
          "[Removed Lines]",
          "64: import java.util.OptionalLong",
          "",
          "[Added Lines]",
          "67: import java.nio.file.{Files, Paths}",
          "68: import java.util",
          "69: import java.util.{Optional, OptionalInt, OptionalLong}",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "69: import scala.jdk.CollectionConverters._",
          "71: object KafkaServer {",
          "75:   def zkClientConfigFromKafkaConfig(config: KafkaConfig, forceZkSslClientEnable: Boolean = false): ZKClientConfig = {",
          "76:     val clientConfig = new ZKClientConfig",
          "77:     if (config.zkSslClientEnable || forceZkSslClientEnable) {",
          "",
          "[Removed Lines]",
          "73:   val brokerMetaPropsFile = \"meta.properties\"",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "168:   private var configRepository: ZkConfigRepository = _",
          "170:   val correlationId: AtomicInteger = new AtomicInteger(0)",
          "175:   private var _clusterId: String = _",
          "176:   @volatile var _brokerTopicStats: BrokerTopicStats = _",
          "",
          "[Removed Lines]",
          "171:   val brokerMetadataCheckpoints = config.logDirs.map { logDir =>",
          "172:     (logDir, new BrokerMetadataCheckpoint(new File(logDir + File.separator + KafkaServer.brokerMetaPropsFile)))",
          "173:   }.toMap",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "229:         info(s\"Cluster ID = $clusterId\")",
          "239:         }",
          "249:         logContext = new LogContext(s\"[KafkaServer id=${config.brokerId}] \")",
          "250:         this.logIdent = logContext.logPrefix",
          "",
          "[Removed Lines]",
          "232:         val (preloadedBrokerMetadataCheckpoint, initialOfflineDirs) =",
          "233:           BrokerMetadataCheckpoint.getBrokerMetadataAndOfflineDirs(config.logDirs, ignoreMissing = true, kraftMode = false)",
          "235:         if (preloadedBrokerMetadataCheckpoint.version != 0) {",
          "236:           throw new RuntimeException(s\"Found unexpected version in loaded `meta.properties`: \" +",
          "237:             s\"$preloadedBrokerMetadataCheckpoint. Zk-based brokers only support version 0 \" +",
          "238:             \"(which is implicit when the `version` field is missing).\")",
          "242:         if (preloadedBrokerMetadataCheckpoint.clusterId.isDefined && preloadedBrokerMetadataCheckpoint.clusterId.get != clusterId)",
          "243:           throw new InconsistentClusterIdException(",
          "244:             s\"The Cluster ID $clusterId doesn't match stored clusterId ${preloadedBrokerMetadataCheckpoint.clusterId} in meta.properties. \" +",
          "245:             s\"The broker is trying to join the wrong cluster. Configured zookeeper.connect may be wrong.\")",
          "248:         config.brokerId = getOrGenerateBrokerId(preloadedBrokerMetadataCheckpoint)",
          "",
          "[Added Lines]",
          "231:         val initialMetaPropsEnsemble = {",
          "232:           val loader = new MetaPropertiesEnsemble.Loader()",
          "233:           config.logDirs.foreach(loader.addLogDir(_))",
          "234:           loader.load()",
          "237:         val verificationId = if (config.brokerId < 0) {",
          "238:           OptionalInt.empty()",
          "239:         } else {",
          "240:           OptionalInt.of(config.brokerId)",
          "241:         }",
          "242:         val verificationFlags = if (config.migrationEnabled) {",
          "243:           util.EnumSet.noneOf(classOf[VerificationFlag])",
          "244:         } else {",
          "245:           util.EnumSet.of(REQUIRE_V0)",
          "246:         }",
          "247:         initialMetaPropsEnsemble.verify(Optional.of(_clusterId), verificationId, verificationFlags)",
          "250:         config.brokerId = getOrGenerateBrokerId(initialMetaPropsEnsemble)",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "271:         logDirFailureChannel = new LogDirFailureChannel(config.logDirs.size)",
          "274:         _logManager = LogManager(",
          "275:           config,",
          "277:           configRepository,",
          "278:           kafkaScheduler,",
          "279:           time,",
          "",
          "[Removed Lines]",
          "276:           initialOfflineDirs,",
          "",
          "[Added Lines]",
          "276:         val metaPropsEnsemble = {",
          "277:           val copier = new MetaPropertiesEnsemble.Copier(initialMetaPropsEnsemble)",
          "278:           initialMetaPropsEnsemble.nonFailedDirectoryProps().forEachRemaining(e => {",
          "279:             val logDir = e.getKey",
          "280:             val builder = new MetaProperties.Builder(e.getValue).",
          "281:               setClusterId(_clusterId).",
          "282:               setNodeId(config.brokerId)",
          "283:             if (!builder.directoryId().isPresent()) {",
          "284:               builder.setDirectoryId(copier.generateValidDirectoryId())",
          "285:             }",
          "286:             copier.setLogDirProps(logDir, builder.build())",
          "287:           })",
          "288:           copier.emptyLogDirs().clear()",
          "289:           copier.setPreWriteHandler((logDir, _, _) => {",
          "290:             info(s\"Rewriting ${logDir}${File.separator}meta.properties\")",
          "291:             Files.createDirectories(Paths.get(logDir))",
          "292:           })",
          "293:           copier.setWriteErrorHandler((logDir, e) => {",
          "294:             logDirFailureChannel.maybeAddOfflineLogDir(logDir, s\"Error while writing meta.properties to $logDir\", e)",
          "295:           })",
          "296:           copier.writeLogDirChanges()",
          "297:           copier.copy()",
          "298:         }",
          "299:         metaPropsEnsemble.verify(Optional.of(_clusterId), OptionalInt.of(config.brokerId), verificationFlags)",
          "304:           metaPropsEnsemble.errorLogDirs().asScala.toSeq,",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "367:         val brokerInfo = createBrokerInfo",
          "368:         val brokerEpoch = zkClient.registerBroker(brokerInfo)",
          "375:         tokenManager = new DelegationTokenManagerZk(config, tokenCache, time , zkClient)",
          "376:         tokenManager.startup()",
          "",
          "[Removed Lines]",
          "371:         val zkMetaProperties = ZkMetaProperties(clusterId, config.brokerId)",
          "372:         checkpointBrokerMetadata(zkMetaProperties)",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "390:           val controllerQuorumVotersFuture = CompletableFuture.completedFuture(",
          "391:             RaftConfig.parseVoterConnections(config.quorumVoters))",
          "392:           val raftManager = new KafkaRaftManager[ApiMessageAndVersion](",
          "394:             config,",
          "395:             new MetadataRecordSerde,",
          "396:             KafkaRaftServer.MetadataPartition,",
          "",
          "[Removed Lines]",
          "393:             clusterId,",
          "",
          "[Added Lines]",
          "417:             metaPropsEnsemble.clusterId().get(),",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "1020:     }",
          "1021:   }",
          "",
          "[Removed Lines]",
          "1028:   private def checkpointBrokerMetadata(brokerMetadata: ZkMetaProperties) = {",
          "1029:     for (logDir <- config.logDirs if logManager.isLogDirOnline(new File(logDir).getAbsolutePath)) {",
          "1030:       val checkpoint = brokerMetadataCheckpoints(logDir)",
          "1031:       try {",
          "1032:         checkpoint.write(brokerMetadata.toProperties)",
          "1033:       } catch {",
          "1034:         case e: IOException =>",
          "1035:           val dirPath = checkpoint.file.getAbsolutePath",
          "1036:           logDirFailureChannel.maybeAddOfflineLogDir(dirPath, s\"Error while writing meta.properties to $dirPath\", e)",
          "1037:       }",
          "1038:     }",
          "1039:   }",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "1062:       generateBrokerId()",
          "1065:   }",
          "",
          "[Removed Lines]",
          "1051:   private def getOrGenerateBrokerId(brokerMetadata: RawMetaProperties): Int = {",
          "1052:     val brokerId = config.brokerId",
          "1054:     if (brokerId >= 0 && brokerMetadata.brokerId.exists(_ != brokerId))",
          "1055:       throw new InconsistentBrokerIdException(",
          "1056:         s\"Configured broker.id $brokerId doesn't match stored broker.id ${brokerMetadata.brokerId} in meta.properties. \" +",
          "1057:           s\"If you moved your data, make sure your configured broker.id matches. \" +",
          "1058:           s\"If you intend to create a new broker, you should remove all data in your data directories (log.dirs).\")",
          "1059:     else if (brokerMetadata.brokerId.isDefined)",
          "1060:       brokerMetadata.brokerId.get",
          "1061:     else if (brokerId < 0 && config.brokerIdGenerationEnable) // generate a new brokerId from Zookeeper",
          "1063:     else",
          "1064:       brokerId",
          "",
          "[Added Lines]",
          "1057:   private def getOrGenerateBrokerId(metaPropsEnsemble: MetaPropertiesEnsemble): Int = {",
          "1058:     if (config.brokerId >= 0) {",
          "1059:       config.brokerId",
          "1060:     } else if (metaPropsEnsemble.nodeId().isPresent) {",
          "1061:       metaPropsEnsemble.nodeId().getAsInt()",
          "1062:     } else if (config.brokerIdGenerationEnable) {",
          "1064:     } else",
          "1065:       throw new RuntimeException(s\"No broker ID found, and ${config.brokerIdGenerationEnable} is disabled.\")",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/server/SharedServer.scala||core/src/main/scala/kafka/server/SharedServer.scala": [
          "File: core/src/main/scala/kafka/server/SharedServer.scala -> core/src/main/scala/kafka/server/SharedServer.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "30: import org.apache.kafka.image.loader.metrics.MetadataLoaderMetrics",
          "31: import org.apache.kafka.image.publisher.{SnapshotEmitter, SnapshotGenerator}",
          "32: import org.apache.kafka.metadata.MetadataRecordSerde",
          "33: import org.apache.kafka.raft.RaftConfig.AddressSpec",
          "34: import org.apache.kafka.server.common.ApiMessageAndVersion",
          "35: import org.apache.kafka.server.fault.{FaultHandler, LoggingFaultHandler, ProcessTerminatingFaultHandler}",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "33: import org.apache.kafka.metadata.properties.MetaPropertiesEnsemble",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "88: class SharedServer(",
          "89:   private val sharedServerConfig: KafkaConfig,",
          "91:   val time: Time,",
          "92:   private val _metrics: Metrics,",
          "93:   val controllerQuorumVotersFuture: CompletableFuture[util.Map[Integer, AddressSpec]],",
          "",
          "[Removed Lines]",
          "90:   val metaProps: MetaProperties,",
          "",
          "[Added Lines]",
          "91:   val metaPropsEnsemble: MetaPropertiesEnsemble,",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "110:   @volatile var snapshotGenerator: SnapshotGenerator = _",
          "111:   @volatile var metadataLoaderMetrics: MetadataLoaderMetrics = _",
          "115:   def isUsed(): Boolean = synchronized {",
          "116:     usedByController || usedByBroker",
          "",
          "[Removed Lines]",
          "113:   def clusterId(): String = metaProps.clusterId",
          "",
          "[Added Lines]",
          "114:   def clusterId: String = metaPropsEnsemble.clusterId().get()",
          "116:   def nodeId: Int = metaPropsEnsemble.nodeId().getAsInt()",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "250:           controllerServerMetrics = new ControllerMetadataMetrics(Optional.of(KafkaYammerMetrics.defaultRegistry()))",
          "251:         }",
          "252:         val _raftManager = new KafkaRaftManager[ApiMessageAndVersion](",
          "254:           sharedServerConfig,",
          "255:           new MetadataRecordSerde,",
          "256:           KafkaRaftServer.MetadataPartition,",
          "",
          "[Removed Lines]",
          "253:           clusterId(),",
          "",
          "[Added Lines]",
          "256:           clusterId,",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "276:             new AtomicReference[MetadataProvenance](MetadataProvenance.EMPTY))",
          "277:         }",
          "278:         val loaderBuilder = new MetadataLoader.Builder().",
          "280:           setTime(time).",
          "281:           setThreadNamePrefix(s\"kafka-${sharedServerConfig.nodeId}-\").",
          "282:           setFaultHandler(metadataLoaderFaultHandler).",
          "",
          "[Removed Lines]",
          "279:           setNodeId(metaProps.nodeId).",
          "",
          "[Added Lines]",
          "282:           setNodeId(nodeId).",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "284:           setMetrics(metadataLoaderMetrics)",
          "285:         loader = loaderBuilder.build()",
          "286:         snapshotEmitter = new SnapshotEmitter.Builder().",
          "288:           setRaftClient(_raftManager.client).",
          "289:           build()",
          "290:         snapshotGenerator = new SnapshotGenerator.Builder(snapshotEmitter).",
          "292:           setTime(time).",
          "293:           setFaultHandler(metadataPublishingFaultHandler).",
          "294:           setMaxBytesSinceLastSnapshot(sharedServerConfig.metadataSnapshotMaxNewRecordBytes).",
          "",
          "[Removed Lines]",
          "287:           setNodeId(metaProps.nodeId).",
          "291:           setNodeId(metaProps.nodeId).",
          "",
          "[Added Lines]",
          "290:           setNodeId(nodeId).",
          "294:           setNodeId(nodeId).",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala": [
          "File: core/src/main/scala/kafka/tools/StorageTool.scala -> core/src/main/scala/kafka/tools/StorageTool.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: package kafka.tools",
          "20: import java.io.PrintStream",
          "21: import java.nio.file.{Files, Paths}",
          "23: import kafka.utils.{Exit, Logging}",
          "24: import net.sourceforge.argparse4j.ArgumentParsers",
          "25: import net.sourceforge.argparse4j.impl.Arguments.{append, store, storeTrue}",
          "26: import net.sourceforge.argparse4j.inf.Namespace",
          "28: import org.apache.kafka.common.utils.Utils",
          "29: import org.apache.kafka.metadata.bootstrap.{BootstrapDirectory, BootstrapMetadata}",
          "30: import org.apache.kafka.server.common.{ApiMessageAndVersion, MetadataVersion}",
          "",
          "[Removed Lines]",
          "22: import kafka.server.{BrokerMetadataCheckpoint, KafkaConfig, KafkaServer, MetaProperties, RawMetaProperties}",
          "27: import org.apache.kafka.common.{DirectoryId, Uuid}",
          "",
          "[Added Lines]",
          "20: import kafka.server.KafkaConfig",
          "28: import org.apache.kafka.common.Uuid",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "32: import org.apache.kafka.common.metadata.UserScramCredentialRecord",
          "33: import org.apache.kafka.common.security.scram.internals.ScramMechanism",
          "34: import org.apache.kafka.common.security.scram.internals.ScramFormatter",
          "36: import java.util",
          "37: import java.util.Base64",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "36: import org.apache.kafka.metadata.properties.MetaPropertiesEnsemble.VerificationFlag",
          "37: import org.apache.kafka.metadata.properties.{MetaProperties, MetaPropertiesEnsemble, MetaPropertiesVersion, PropertiesUtils}",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "60:           if (!metadataVersion.isKRaftSupported) {",
          "61:             throw new TerseFailure(s\"Must specify a valid KRaft metadata version of at least 3.0.\")",
          "62:           }",
          "64:           val metadataRecords : ArrayBuffer[ApiMessageAndVersion] = ArrayBuffer()",
          "65:           getUserScramCredentialRecords(namespace).foreach(userScramCredentialRecords => {",
          "66:             if (!metadataVersion.isScramSupported()) {",
          "",
          "[Removed Lines]",
          "63:           val metaProperties = buildMetadataProperties(clusterId, config.get)",
          "",
          "[Added Lines]",
          "66:           val metaProperties = new MetaProperties.Builder().",
          "67:             setVersion(MetaPropertiesVersion.V1).",
          "68:             setClusterId(clusterId).",
          "69:             setNodeId(config.get.nodeId).",
          "70:             build()",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "269:   def infoCommand(stream: PrintStream, selfManagedMode: Boolean, directories: Seq[String]): Int = {",
          "270:     val problems = new mutable.ArrayBuffer[String]",
          "271:     val foundDirectories = new mutable.ArrayBuffer[String]",
          "273:     directories.sorted.foreach(directory => {",
          "274:       val directoryPath = Paths.get(directory)",
          "275:       if (!Files.isDirectory(directoryPath)) {",
          "",
          "[Removed Lines]",
          "272:     var prevMetadata: Option[RawMetaProperties] = None",
          "",
          "[Added Lines]",
          "279:     var prevMetadata: Option[MetaProperties] = None",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "280:         }",
          "281:       } else {",
          "282:         foundDirectories += directoryPath.toString",
          "284:         if (!Files.exists(metaPath)) {",
          "285:           problems += s\"$directoryPath is not formatted.\"",
          "286:         } else {",
          "303:             }",
          "304:           }",
          "305:         }",
          "306:       }",
          "",
          "[Removed Lines]",
          "283:         val metaPath = directoryPath.resolve(KafkaServer.brokerMetaPropsFile)",
          "287:           val properties = Utils.loadProps(metaPath.toString)",
          "288:           val rawMetaProperties = new RawMetaProperties(properties)",
          "290:           val curMetadata = rawMetaProperties.version match {",
          "291:             case 0 | 1 => Some(rawMetaProperties)",
          "292:             case v =>",
          "293:               problems += s\"Unsupported version for $metaPath: $v\"",
          "294:               None",
          "295:           }",
          "297:           if (prevMetadata.isEmpty) {",
          "298:             prevMetadata = curMetadata",
          "299:           } else {",
          "300:             if (!prevMetadata.get.equals(curMetadata.get)) {",
          "301:               problems += s\"Metadata for $metaPath was ${curMetadata.get}, \" +",
          "302:                 s\"but other directories featured ${prevMetadata.get}\"",
          "",
          "[Added Lines]",
          "290:         val metaPath = directoryPath.resolve(MetaPropertiesEnsemble.META_PROPERTIES_NAME)",
          "294:           val properties = PropertiesUtils.readPropertiesFile(metaPath.toString)",
          "295:           try {",
          "296:             val curMetadata = new MetaProperties.Builder(properties).build()",
          "297:             if (prevMetadata.isEmpty) {",
          "298:               prevMetadata = Some(curMetadata)",
          "299:             } else {",
          "300:               if (!prevMetadata.get.clusterId().equals(curMetadata.clusterId())) {",
          "301:                 problems += s\"Mismatched cluster IDs between storage directories.\"",
          "302:               } else if (!prevMetadata.get.nodeId().equals(curMetadata.nodeId())) {",
          "303:                 problems += s\"Mismatched node IDs between storage directories.\"",
          "304:               }",
          "306:           } catch {",
          "307:             case e: Exception =>",
          "308:               e.printStackTrace(System.out)",
          "309:               problems += s\"Error loading $metaPath: ${e.getMessage}\"",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "309:     prevMetadata.foreach { prev =>",
          "310:       if (selfManagedMode) {",
          "312:           problems += \"The kafka configuration file appears to be for a cluster in KRaft mode, but \" +",
          "313:             \"the directories are formatted for legacy mode.\"",
          "314:         }",
          "316:         problems += \"The kafka configuration file appears to be for a legacy cluster, but \" +",
          "317:           \"the directories are formatted for a cluster in KRaft mode.\"",
          "318:       }",
          "",
          "[Removed Lines]",
          "311:         if (prev.version == 0) {",
          "315:       } else if (prev.version == 1) {",
          "",
          "[Added Lines]",
          "317:         if (prev.version.equals(MetaPropertiesVersion.V0)) {",
          "321:       } else if (prev.version.equals(MetaPropertiesVersion.V1)) {",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "333:       }",
          "335:       prevMetadata.foreach { prev =>",
          "337:         stream.println(\"\")",
          "338:       }",
          "",
          "[Removed Lines]",
          "336:         stream.println(s\"Found metadata: ${prev}\")",
          "",
          "[Added Lines]",
          "342:         val sortedOutput = new util.TreeMap[String, String]()",
          "343:         prev.toProperties().entrySet().forEach(e => sortedOutput.put(e.getKey.toString, e.getValue.toString))",
          "344:         stream.println(s\"Found metadata: ${sortedOutput}\")",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "382:     if (config.nodeId < 0) {",
          "383:       throw new TerseFailure(s\"The node.id must be set to a non-negative integer. We saw ${config.nodeId}\")",
          "384:     }",
          "386:   }",
          "388:   def formatCommand(",
          "",
          "[Removed Lines]",
          "385:     new MetaProperties(effectiveClusterId.toString, config.nodeId)",
          "",
          "[Added Lines]",
          "393:     new MetaProperties.Builder().",
          "394:       setClusterId(effectiveClusterId.toString).",
          "395:       setNodeId(config.nodeId).",
          "396:       build()",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "407:     if (directories.isEmpty) {",
          "408:       throw new TerseFailure(\"No log directories found in the configuration.\")",
          "409:     }",
          "422:       stream.println(\"All of the log directories are already formatted.\")",
          "423:     }",
          "440:     0",
          "441:   }",
          "442: }",
          "",
          "[Removed Lines]",
          "411:     val unformattedDirectories = directories.filter(directory => {",
          "412:       if (!Files.isDirectory(Paths.get(directory)) || !Files.exists(Paths.get(directory, KafkaServer.brokerMetaPropsFile))) {",
          "413:           true",
          "414:       } else if (!ignoreFormatted) {",
          "415:         throw new TerseFailure(s\"Log directory $directory is already formatted. \" +",
          "416:           \"Use --ignore-formatted to ignore this directory and format the others.\")",
          "417:       } else {",
          "418:         false",
          "419:       }",
          "420:     })",
          "421:     if (unformattedDirectories.isEmpty) {",
          "424:     unformattedDirectories.foreach(directory => {",
          "425:       try {",
          "426:         Files.createDirectories(Paths.get(directory))",
          "427:       } catch {",
          "428:         case e: Throwable => throw new TerseFailure(s\"Unable to create storage \" +",
          "429:           s\"directory $directory: ${e.getMessage}\")",
          "430:       }",
          "431:       val metaPropertiesPath = Paths.get(directory, KafkaServer.brokerMetaPropsFile)",
          "432:       val checkpoint = new BrokerMetadataCheckpoint(metaPropertiesPath.toFile)",
          "433:       checkpoint.write(metaProperties.toPropertiesWithDirectoryId(DirectoryId.random().toString))",
          "435:       val bootstrapDirectory = new BootstrapDirectory(directory, Optional.empty())",
          "436:       bootstrapDirectory.writeBinaryFile(bootstrapMetadata)",
          "438:       stream.println(s\"Formatting ${directory} with metadata.version ${metadataVersion}.\")",
          "439:     })",
          "",
          "[Added Lines]",
          "421:     val loader = new MetaPropertiesEnsemble.Loader()",
          "422:     directories.foreach(loader.addLogDir(_))",
          "423:     val metaPropertiesEnsemble = loader.load()",
          "424:     metaPropertiesEnsemble.verify(metaProperties.clusterId(), metaProperties.nodeId(),",
          "425:       util.EnumSet.noneOf(classOf[VerificationFlag]))",
          "427:     System.out.println(s\"metaPropertiesEnsemble=${metaPropertiesEnsemble}\")",
          "428:     val copier = new MetaPropertiesEnsemble.Copier(metaPropertiesEnsemble)",
          "429:     if (!(ignoreFormatted || copier.logDirProps().isEmpty)) {",
          "430:       val firstLogDir = copier.logDirProps().keySet().iterator().next()",
          "431:       throw new TerseFailure(s\"Log directory ${firstLogDir} is already formatted. \" +",
          "432:         \"Use --ignore-formatted to ignore this directory and format the others.\")",
          "433:     }",
          "434:     if (!copier.errorLogDirs().isEmpty) {",
          "435:       val firstLogDir = copier.errorLogDirs().iterator().next()",
          "436:       throw new TerseFailure(s\"I/O error trying to read log directory ${firstLogDir}.\")",
          "437:     }",
          "438:     if (metaPropertiesEnsemble.emptyLogDirs().isEmpty) {",
          "440:     } else {",
          "441:       metaPropertiesEnsemble.emptyLogDirs().forEach(logDir => {",
          "442:         copier.setLogDirProps(logDir, new MetaProperties.Builder(metaProperties).",
          "443:           setDirectoryId(copier.generateValidDirectoryId()).",
          "444:           build())",
          "445:         copier.setPreWriteHandler((logDir, isNew, metaProperties) => {",
          "446:           stream.println(s\"Formatting ${logDir} with metadata.version ${metadataVersion}.\")",
          "447:           Files.createDirectories(Paths.get(logDir))",
          "448:           val bootstrapDirectory = new BootstrapDirectory(logDir, Optional.empty())",
          "449:           bootstrapDirectory.writeBinaryFile(bootstrapMetadata)",
          "450:         })",
          "451:         copier.setWriteErrorHandler((logDir, e) => {",
          "452:           throw new TerseFailure(s\"Error while writing meta.properties file ${logDir}: ${e.getMessage}\")",
          "453:         })",
          "454:         copier.writeLogDirChanges()",
          "455:       })",
          "",
          "---------------"
        ],
        "core/src/test/java/kafka/testkit/BrokerNode.java||core/src/test/java/kafka/testkit/BrokerNode.java": [
          "File: core/src/test/java/kafka/testkit/BrokerNode.java -> core/src/test/java/kafka/testkit/BrokerNode.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: package kafka.testkit;",
          "20: import org.apache.kafka.common.Uuid;",
          "22: import java.util.ArrayList;",
          "23: import java.util.Collections;",
          "24: import java.util.HashMap;",
          "25: import java.util.List;",
          "26: import java.util.Map;",
          "30: public class BrokerNode implements TestKitNode {",
          "31:     public static class Builder {",
          "32:         private int id = -1;",
          "33:         private Uuid incarnationId = null;",
          "35:         private List<String> logDataDirectories = null;",
          "37:         public Builder setId(int id) {",
          "38:             this.id = id;",
          "39:             return this;",
          "40:         }",
          "44:             return this;",
          "45:         }",
          "",
          "[Removed Lines]",
          "28: import static java.util.Collections.emptyMap;",
          "34:         private String metadataDirectory = null;",
          "42:         public Builder setLogDirectories(List<String> logDataDirectories) {",
          "43:             this.logDataDirectories = logDataDirectories;",
          "",
          "[Added Lines]",
          "21: import org.apache.kafka.metadata.properties.MetaProperties;",
          "22: import org.apache.kafka.metadata.properties.MetaPropertiesEnsemble;",
          "23: import org.apache.kafka.metadata.properties.MetaPropertiesVersion;",
          "25: import java.io.File;",
          "26: import java.nio.file.Paths;",
          "32: import java.util.Optional;",
          "37:         private String baseDirectory = null;",
          "38:         private Uuid clusterId = null;",
          "41:         private String metadataDirectory = null;",
          "42:         private Map<String, String> propertyOverrides = new HashMap<>();",
          "44:         public int id() {",
          "45:             return id;",
          "46:         }",
          "53:         public Builder setIncarnationId(Uuid incarnationId) {",
          "54:             this.incarnationId = incarnationId;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "49:             return this;",
          "50:         }",
          "54:         ) {",
          "55:             if (id == -1) {",
          "57:             }",
          "58:             if (incarnationId == null) {",
          "59:                 incarnationId = Uuid.randomUuid();",
          "60:             }",
          "61:             if (logDataDirectories == null) {",
          "64:             }",
          "66:             if (metadataDirectory == null) {",
          "67:                 metadataDirectory = logDataDirectories.get(0);",
          "68:             }",
          "72:         }",
          "73:     }",
          "76:     private final Uuid incarnationId;",
          "79:     private final Map<String, String> propertyOverrides;",
          "94:         this.incarnationId = incarnationId;",
          "97:         this.propertyOverrides = new HashMap<>(propertyOverrides);",
          "98:     }",
          "105:     public Uuid incarnationId() {",
          "106:         return incarnationId;",
          "107:     }",
          "109:     @Override",
          "112:     }",
          "114:     public List<String> logDataDirectories() {",
          "116:     }",
          "118:     public Map<String, String> propertyOverrides() {",
          "",
          "[Removed Lines]",
          "52:         BrokerNode build(",
          "53:             String baseDirectory",
          "56:                 throw new RuntimeException(\"You must set the node id\");",
          "62:                 logDataDirectories = Collections.",
          "63:                     singletonList(String.format(\"broker_%d_data0\", id));",
          "65:             logDataDirectories = TestKitNodes.absolutize(baseDirectory, logDataDirectories);",
          "69:             metadataDirectory = TestKitNodes.absolutize(baseDirectory, metadataDirectory);",
          "70:             return new BrokerNode(id, incarnationId, metadataDirectory,",
          "71:                 logDataDirectories);",
          "75:     private final int id;",
          "77:     private final String metadataDirectory;",
          "78:     private final List<String> logDataDirectories;",
          "81:     BrokerNode(int id,",
          "82:                Uuid incarnationId,",
          "83:                String metadataDirectory,",
          "84:                List<String> logDataDirectories) {",
          "85:         this(id, incarnationId, metadataDirectory, logDataDirectories, emptyMap());",
          "86:     }",
          "88:     BrokerNode(int id,",
          "89:                Uuid incarnationId,",
          "90:                String metadataDirectory,",
          "91:                List<String> logDataDirectories,",
          "92:                Map<String, String> propertyOverrides) {",
          "93:         this.id = id;",
          "95:         this.metadataDirectory = metadataDirectory;",
          "96:         this.logDataDirectories = new ArrayList<>(logDataDirectories);",
          "100:     @Override",
          "101:     public int id() {",
          "102:         return id;",
          "103:     }",
          "110:     public String metadataDirectory() {",
          "111:         return metadataDirectory;",
          "115:         return logDataDirectories;",
          "",
          "[Added Lines]",
          "63:         public Builder setLogDirectories(List<String> logDataDirectories) {",
          "64:             this.logDataDirectories = logDataDirectories;",
          "65:             return this;",
          "66:         }",
          "68:         public BrokerNode build(",
          "69:             String baseDirectory,",
          "70:             Uuid clusterId,",
          "71:             boolean combined",
          "74:                 throw new RuntimeException(\"You must set the node id.\");",
          "80:                 if (combined) {",
          "81:                     logDataDirectories = Collections.",
          "82:                         singletonList(String.format(\"combined_%d\", id));",
          "83:                 } else {",
          "84:                     logDataDirectories = Collections.",
          "85:                         singletonList(String.format(\"broker_%d_data0\", id));",
          "86:                 }",
          "87:             }",
          "88:             List<String> absoluteLogDataDirectories = new ArrayList<>();",
          "89:             for (String logDir : logDataDirectories) {",
          "90:                 if (Paths.get(logDir).isAbsolute()) {",
          "91:                     absoluteLogDataDirectories.add(logDir);",
          "92:                 } else {",
          "93:                     absoluteLogDataDirectories.add(new File(baseDirectory, logDir).getAbsolutePath());",
          "94:                 }",
          "96:             this.logDataDirectories = absoluteLogDataDirectories;",
          "99:             } else if (!Paths.get(metadataDirectory).isAbsolute()) {",
          "100:                 metadataDirectory = new File(baseDirectory, metadataDirectory).getAbsolutePath();",
          "101:             }",
          "102:             MetaPropertiesEnsemble.Copier copier =",
          "103:                     new MetaPropertiesEnsemble.Copier(MetaPropertiesEnsemble.EMPTY);",
          "104:             copier.setMetaLogDir(Optional.of(metadataDirectory));",
          "105:             for (String logDir : logDataDirectories) {",
          "106:                 copier.setLogDirProps(logDir, new MetaProperties.Builder().",
          "107:                     setVersion(MetaPropertiesVersion.V1).",
          "108:                     setClusterId(clusterId.toString()).",
          "109:                     setNodeId(id).",
          "110:                     setDirectoryId(copier.generateValidDirectoryId()).",
          "111:                     build());",
          "113:             copier.setMetaLogDir(Optional.of(metadataDirectory));",
          "114:             return new BrokerNode(incarnationId,",
          "115:                 copier.copy(),",
          "116:                 combined,",
          "117:                 propertyOverrides);",
          "122:     private final MetaPropertiesEnsemble initialMetaPropertiesEnsemble;",
          "123:     private final boolean combined;",
          "126:     BrokerNode(",
          "127:         Uuid incarnationId,",
          "128:         MetaPropertiesEnsemble initialMetaPropertiesEnsemble,",
          "129:         boolean combined,",
          "130:         Map<String, String> propertyOverrides",
          "131:     ) {",
          "133:         this.initialMetaPropertiesEnsemble = initialMetaPropertiesEnsemble;",
          "134:         this.combined = combined;",
          "143:     public MetaPropertiesEnsemble initialMetaPropertiesEnsemble() {",
          "144:         return initialMetaPropertiesEnsemble;",
          "145:     }",
          "147:     @Override",
          "148:     public boolean combined() {",
          "149:         return combined;",
          "153:         return new ArrayList<>(initialMetaPropertiesEnsemble.logDirProps().keySet());",
          "",
          "---------------"
        ],
        "core/src/test/java/kafka/testkit/ControllerNode.java||core/src/test/java/kafka/testkit/ControllerNode.java": [
          "File: core/src/test/java/kafka/testkit/ControllerNode.java -> core/src/test/java/kafka/testkit/ControllerNode.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: package kafka.testkit;",
          "20: public class ControllerNode implements TestKitNode {",
          "21:     public static class Builder {",
          "22:         private int id = -1;",
          "23:         private String metadataDirectory = null;",
          "25:         public Builder setId(int id) {",
          "26:             this.id = id;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "20: import org.apache.kafka.common.Uuid;",
          "21: import org.apache.kafka.metadata.properties.MetaProperties;",
          "22: import org.apache.kafka.metadata.properties.MetaPropertiesEnsemble;",
          "23: import org.apache.kafka.metadata.properties.MetaPropertiesVersion;",
          "25: import java.io.File;",
          "26: import java.nio.file.Paths;",
          "27: import java.util.Optional;",
          "32:         private String baseDirectory = null;",
          "34:         private Uuid clusterId = null;",
          "36:         public int id() {",
          "37:             return id;",
          "38:         }",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "33:         }",
          "35:         public ControllerNode build(",
          "37:         ) {",
          "38:             if (id == -1) {",
          "40:             }",
          "41:             if (metadataDirectory == null) {",
          "43:             }",
          "46:         }",
          "47:     }",
          "55:     }",
          "57:     @Override",
          "60:     }",
          "62:     @Override",
          "65:     }",
          "66: }",
          "",
          "[Removed Lines]",
          "36:             String baseDirectory",
          "39:                 throw new RuntimeException(\"You must set the node id\");",
          "42:                 metadataDirectory = String.format(\"controller_%d\", id);",
          "44:             metadataDirectory = TestKitNodes.absolutize(baseDirectory, metadataDirectory);",
          "45:             return new ControllerNode(id, metadataDirectory);",
          "49:     private final int id;",
          "50:     private final String metadataDirectory;",
          "52:     ControllerNode(int id, String metadataDirectory) {",
          "53:         this.id = id;",
          "54:         this.metadataDirectory = metadataDirectory;",
          "58:     public int id() {",
          "59:         return id;",
          "63:     public String metadataDirectory() {",
          "64:         return metadataDirectory;",
          "",
          "[Added Lines]",
          "51:             String baseDirectory,",
          "52:             Uuid clusterId,",
          "53:             boolean combined",
          "56:                 throw new RuntimeException(\"You must set the node id.\");",
          "57:             }",
          "58:             if (baseDirectory == null) {",
          "59:                 throw new RuntimeException(\"You must set the base directory.\");",
          "62:                 if (combined) {",
          "63:                     metadataDirectory = String.format(\"combined_%d\", id);",
          "64:                 } else {",
          "65:                     metadataDirectory = String.format(\"controller_%d\", id);",
          "66:                 }",
          "67:             }",
          "68:             if (!Paths.get(metadataDirectory).isAbsolute()) {",
          "69:                 metadataDirectory = new File(baseDirectory, metadataDirectory).getAbsolutePath();",
          "71:             MetaPropertiesEnsemble.Copier copier =",
          "72:                 new MetaPropertiesEnsemble.Copier(MetaPropertiesEnsemble.EMPTY);",
          "73:             copier.setMetaLogDir(Optional.of(metadataDirectory));",
          "74:             copier.setLogDirProps(metadataDirectory, new MetaProperties.Builder().",
          "75:                 setVersion(MetaPropertiesVersion.V1).",
          "76:                 setClusterId(clusterId.toString()).",
          "77:                 setNodeId(id).",
          "78:                 setDirectoryId(copier.generateValidDirectoryId()).",
          "79:                 build());",
          "80:             return new ControllerNode(copier.copy(), combined);",
          "84:     private final MetaPropertiesEnsemble initialMetaPropertiesEnsemble;",
          "86:     private final boolean combined;",
          "88:     ControllerNode(",
          "89:         MetaPropertiesEnsemble initialMetaPropertiesEnsemble,",
          "90:         boolean combined",
          "91:     ) {",
          "92:         this.initialMetaPropertiesEnsemble = initialMetaPropertiesEnsemble;",
          "93:         this.combined = combined;",
          "97:     public MetaPropertiesEnsemble initialMetaPropertiesEnsemble() {",
          "98:         return initialMetaPropertiesEnsemble;",
          "102:     public boolean combined() {",
          "103:         return combined;",
          "",
          "---------------"
        ],
        "core/src/test/java/kafka/testkit/KafkaClusterTestKit.java||core/src/test/java/kafka/testkit/KafkaClusterTestKit.java": [
          "File: core/src/test/java/kafka/testkit/KafkaClusterTestKit.java -> core/src/test/java/kafka/testkit/KafkaClusterTestKit.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "25: import kafka.server.KafkaConfig;",
          "26: import kafka.server.KafkaConfig$;",
          "27: import kafka.server.KafkaRaftServer;",
          "31: import org.apache.kafka.clients.CommonClientConfigs;",
          "32: import org.apache.kafka.clients.admin.AdminClientConfig;",
          "33: import org.apache.kafka.common.Node;",
          "",
          "[Removed Lines]",
          "28: import kafka.server.MetaProperties;",
          "29: import kafka.tools.StorageTool;",
          "30: import kafka.utils.Logging;",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "37: import org.apache.kafka.common.utils.Time;",
          "38: import org.apache.kafka.common.utils.Utils;",
          "39: import org.apache.kafka.controller.Controller;",
          "41: import org.apache.kafka.raft.RaftConfig;",
          "42: import org.apache.kafka.server.common.ApiMessageAndVersion;",
          "44: import org.apache.kafka.server.fault.FaultHandler;",
          "45: import org.apache.kafka.server.fault.MockFaultHandler;",
          "46: import org.apache.kafka.test.TestUtils;",
          "",
          "[Removed Lines]",
          "40: import org.apache.kafka.metadata.bootstrap.BootstrapMetadata;",
          "43: import org.apache.kafka.server.common.MetadataVersion;",
          "",
          "[Added Lines]",
          "37: import org.apache.kafka.metadata.bootstrap.BootstrapDirectory;",
          "38: import org.apache.kafka.metadata.properties.MetaProperties;",
          "39: import org.apache.kafka.metadata.properties.MetaPropertiesEnsemble;",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "48: import org.slf4j.LoggerFactory;",
          "49: import org.slf4j.event.Level;",
          "50: import scala.Option;",
          "54: import java.io.File;",
          "57: import java.net.InetSocketAddress;",
          "58: import java.nio.file.Files;",
          "59: import java.nio.file.Paths;",
          "",
          "[Removed Lines]",
          "51: import scala.collection.JavaConverters;",
          "53: import java.io.ByteArrayOutputStream;",
          "55: import java.io.IOException;",
          "56: import java.io.PrintStream;",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "65: import java.util.List;",
          "66: import java.util.Map;",
          "67: import java.util.Map.Entry;",
          "68: import java.util.Properties;",
          "69: import java.util.TreeMap;",
          "70: import java.util.concurrent.CompletableFuture;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "62: import java.util.Optional;",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "74: import java.util.concurrent.Future;",
          "75: import java.util.concurrent.TimeUnit;",
          "76: import java.util.concurrent.atomic.AtomicReference;",
          "78: import java.util.stream.Collectors;",
          "80: import static org.junit.jupiter.api.Assertions.assertNotNull;",
          "",
          "[Removed Lines]",
          "77: import java.util.function.Consumer;",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "173:                 props.put(KafkaConfig$.MODULE$.MetadataLogDirProp(),",
          "174:                         node.metadataDirectory());",
          "175:             }",
          "177:             if (brokerNode != null) {",
          "178:                 props.put(KafkaConfig$.MODULE$.LogDirsProp(),",
          "179:                         String.join(\",\", brokerNode.logDataDirectories()));",
          "180:             }",
          "181:             props.put(KafkaConfig$.MODULE$.ListenerSecurityProtocolMapProp(),",
          "182:                     \"EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT\");",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "174:             } else {",
          "176:                 props.put(KafkaConfig$.MODULE$.LogDirsProp(),",
          "177:                     controllerNode.metadataDirectory());",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "216:             ExecutorService executorService = null;",
          "217:             ControllerQuorumVotersFutureManager connectFutureManager =",
          "218:                 new ControllerQuorumVotersFutureManager(nodes.controllerNodes().size());",
          "221:             try {",
          "222:                 executorService = Executors.newFixedThreadPool(numOfExecutorThreads,",
          "223:                     ThreadUtils.createThreadFactory(\"kafka-cluster-test-kit-executor-%d\", false));",
          "224:                 for (ControllerNode node : nodes.controllerNodes().values()) {",
          "225:                     setupNodeDirectories(baseDirectory, node.metadataDirectory(), Collections.emptyList());",
          "228:                     SharedServer sharedServer = new SharedServer(createNodeConfig(node),",
          "230:                             Time.SYSTEM,",
          "231:                             new Metrics(),",
          "232:                             connectFutureManager.future,",
          "",
          "[Removed Lines]",
          "219:             File baseDirectory = new File(nodes.baseDirectory());",
          "226:                     BootstrapMetadata bootstrapMetadata = BootstrapMetadata.",
          "227:                         fromVersion(nodes.bootstrapMetadataVersion(), \"testkit\");",
          "229:                             MetaProperties.apply(nodes.clusterId().toString(), node.id()),",
          "",
          "[Added Lines]",
          "217:             File baseDirectory = null;",
          "220:                 baseDirectory = new File(nodes.baseDirectory());",
          "226:                             node.initialMetaPropertiesEnsemble(),",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "236:                         controller = new ControllerServer(",
          "237:                                 sharedServer,",
          "238:                                 KafkaRaftServer.configSchema(),",
          "240:                     } catch (Throwable e) {",
          "241:                         log.error(\"Error creating controller {}\", node.id(), e);",
          "242:                         Utils.swallow(log, Level.WARN, \"sharedServer.stopForController error\", () -> sharedServer.stopForController());",
          "",
          "[Removed Lines]",
          "239:                                 bootstrapMetadata);",
          "",
          "[Added Lines]",
          "236:                                 nodes.bootstrapMetadata());",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "256:                 for (BrokerNode node : nodes.brokerNodes().values()) {",
          "257:                     SharedServer sharedServer = jointServers.computeIfAbsent(node.id(),",
          "258:                         id -> new SharedServer(createNodeConfig(node),",
          "260:                             Time.SYSTEM,",
          "261:                             new Metrics(),",
          "262:                             connectFutureManager.future,",
          "263:                             faultHandlerFactory));",
          "264:                     BrokerServer broker = null;",
          "265:                     try {",
          "269:                     } catch (Throwable e) {",
          "270:                         log.error(\"Error creating broker {}\", node.id(), e);",
          "271:                         Utils.swallow(log, Level.WARN, \"sharedServer.stopForBroker error\", () -> sharedServer.stopForBroker());",
          "",
          "[Removed Lines]",
          "259:                             MetaProperties.apply(nodes.clusterId().toString(), id),",
          "266:                         broker = new BrokerServer(",
          "267:                                 sharedServer,",
          "268:                                 JavaConverters.asScalaBuffer(Collections.<String>emptyList()).toSeq());",
          "",
          "[Added Lines]",
          "256:                             node.initialMetaPropertiesEnsemble(),",
          "263:                         broker = new BrokerServer(sharedServer);",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "360:     public void format() throws Exception {",
          "361:         List<Future<?>> futures = new ArrayList<>();",
          "362:         try {",
          "368:             }",
          "369:             for (Entry<Integer, BrokerServer> entry : brokers.entrySet()) {",
          "376:             }",
          "377:             for (Future<?> future: futures) {",
          "378:                 future.get();",
          "",
          "[Removed Lines]",
          "363:             for (Entry<Integer, ControllerServer> entry : controllers.entrySet()) {",
          "364:                 int nodeId = entry.getKey();",
          "365:                 ControllerServer controller = entry.getValue();",
          "366:                 formatNodeAndLog(nodes.controllerProperties(nodeId), controller.config().metadataLogDir(),",
          "367:                     controller, futures::add);",
          "370:                 int nodeId = entry.getKey();",
          "371:                 if (!controllers.containsKey(nodeId)) {",
          "372:                     BrokerServer broker = entry.getValue();",
          "373:                     formatNodeAndLog(nodes.brokerProperties(nodeId), broker.config().metadataLogDir(),",
          "374:                             broker, futures::add);",
          "375:                 }",
          "",
          "[Added Lines]",
          "358:             for (ControllerServer controller : controllers.values()) {",
          "359:                 futures.add(executorService.submit(() -> {",
          "360:                     formatNode(controller.sharedServer().metaPropsEnsemble(), true);",
          "361:                 }));",
          "364:                 BrokerServer broker = entry.getValue();",
          "365:                 futures.add(executorService.submit(() -> {",
          "366:                     formatNode(broker.sharedServer().metaPropsEnsemble(),",
          "367:                         !nodes().brokerNodes().get(entry.getKey()).combined());",
          "368:                 }));",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "385:         }",
          "386:     }",
          "402:                 }",
          "405:             }",
          "407:     }",
          "409:     public void startup() throws ExecutionException, InterruptedException {",
          "",
          "[Removed Lines]",
          "388:     private void formatNodeAndLog(MetaProperties properties, String metadataLogDir, Logging loggingMixin,",
          "389:                                   Consumer<Future<?>> futureConsumer) {",
          "390:         futureConsumer.accept(executorService.submit(() -> {",
          "391:             try (ByteArrayOutputStream stream = new ByteArrayOutputStream()) {",
          "392:                 try (PrintStream out = new PrintStream(stream)) {",
          "393:                     StorageTool.formatCommand(out,",
          "394:                             JavaConverters.asScalaBuffer(Collections.singletonList(metadataLogDir)).toSeq(),",
          "395:                             properties,",
          "396:                             MetadataVersion.MINIMUM_BOOTSTRAP_VERSION,",
          "397:                             false);",
          "398:                 } finally {",
          "399:                     for (String line : stream.toString().split(String.format(\"%n\"))) {",
          "400:                         loggingMixin.info(() -> line);",
          "401:                     }",
          "403:             } catch (IOException e) {",
          "404:                 throw new RuntimeException(e);",
          "406:         }));",
          "",
          "[Added Lines]",
          "381:     private void formatNode(",
          "382:         MetaPropertiesEnsemble ensemble,",
          "383:         boolean writeMetadataDirectory",
          "384:     ) {",
          "385:         try {",
          "386:             MetaPropertiesEnsemble.Copier copier =",
          "387:                 new MetaPropertiesEnsemble.Copier(MetaPropertiesEnsemble.EMPTY);",
          "388:             for (Entry<String, MetaProperties> entry : ensemble.logDirProps().entrySet()) {",
          "389:                 String logDir = entry.getKey();",
          "390:                 if (writeMetadataDirectory || (!ensemble.metadataLogDir().equals(Optional.of(logDir)))) {",
          "391:                     log.trace(\"Adding {} to the list of directories to format.\", logDir);",
          "392:                     copier.setLogDirProps(logDir, entry.getValue());",
          "395:             copier.setPreWriteHandler((logDir, isNew, metaProperties) -> {",
          "396:                 log.info(\"Formatting {}.\", logDir);",
          "397:                 Files.createDirectories(Paths.get(logDir));",
          "398:                 BootstrapDirectory bootstrapDirectory = new BootstrapDirectory(logDir, Optional.empty());",
          "399:                 bootstrapDirectory.writeBinaryFile(nodes.bootstrapMetadata());",
          "400:             });",
          "401:             copier.writeLogDirChanges();",
          "402:         } catch (Exception e) {",
          "403:             throw new RuntimeException(\"Failed to format node \" + ensemble.nodeId(), e);",
          "404:         }",
          "",
          "---------------"
        ],
        "core/src/test/java/kafka/testkit/TestKitNode.java||core/src/test/java/kafka/testkit/TestKitNode.java": [
          "File: core/src/test/java/kafka/testkit/TestKitNode.java -> core/src/test/java/kafka/testkit/TestKitNode.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: package kafka.testkit;",
          "20: public interface TestKitNode {",
          "23: }",
          "",
          "[Removed Lines]",
          "21:     int id();",
          "22:     String metadataDirectory();",
          "",
          "[Added Lines]",
          "20: import org.apache.kafka.metadata.properties.MetaPropertiesEnsemble;",
          "23:     default int id() {",
          "24:         return initialMetaPropertiesEnsemble().nodeId().getAsInt();",
          "25:     }",
          "27:     default String metadataDirectory() {",
          "28:         return initialMetaPropertiesEnsemble().metadataLogDir().get();",
          "29:     }",
          "31:     MetaPropertiesEnsemble initialMetaPropertiesEnsemble();",
          "33:     boolean combined();",
          "",
          "---------------"
        ],
        "core/src/test/java/kafka/testkit/TestKitNodes.java||core/src/test/java/kafka/testkit/TestKitNodes.java": [
          "File: core/src/test/java/kafka/testkit/TestKitNodes.java -> core/src/test/java/kafka/testkit/TestKitNodes.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: package kafka.testkit;",
          "21: import org.apache.kafka.common.Uuid;",
          "22: import org.apache.kafka.common.network.ListenerName;",
          "24: import org.apache.kafka.server.common.MetadataVersion;",
          "25: import org.apache.kafka.test.TestUtils;",
          "29: import java.nio.file.Paths;",
          "33: import java.util.Map;",
          "34: import java.util.NavigableMap;",
          "35: import java.util.TreeMap;",
          "",
          "[Removed Lines]",
          "20: import kafka.server.MetaProperties;",
          "23: import org.apache.kafka.common.utils.Utils;",
          "27: import java.io.File;",
          "28: import java.io.IOException;",
          "30: import java.util.ArrayList;",
          "31: import java.util.Collection;",
          "32: import java.util.List;",
          "",
          "[Added Lines]",
          "22: import org.apache.kafka.metadata.bootstrap.BootstrapMetadata;",
          "26: import java.nio.file.Files;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "70:                 if (!controllerNodeBuilders.isEmpty()) {",
          "71:                     nextId = controllerNodeBuilders.lastKey() + 1;",
          "72:                 }",
          "75:             }",
          "76:             return this;",
          "77:         }",
          "",
          "[Removed Lines]",
          "73:                 controllerNodeBuilders.put(nextId, new ControllerNode.Builder().",
          "74:                     setId(nextId));",
          "",
          "[Added Lines]",
          "68:                 controllerNodeBuilders.put(nextId,",
          "69:                     new ControllerNode.Builder().",
          "70:                         setId(nextId));",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "88:                 if (!brokerNodeBuilders.isEmpty()) {",
          "89:                     nextId = brokerNodeBuilders.lastKey() + 1;",
          "90:                 }",
          "93:             }",
          "94:             return this;",
          "95:         }",
          "97:         public TestKitNodes build() {",
          "105:             try {",
          "111:                     }",
          "112:                 }",
          "118:                     }",
          "119:                 }",
          "120:                 return new TestKitNodes(baseDirectory,",
          "",
          "[Removed Lines]",
          "91:                 brokerNodeBuilders.put(nextId, new BrokerNode.Builder().",
          "92:                     setId(nextId));",
          "98:             if (clusterId == null) {",
          "99:                 clusterId = Uuid.randomUuid();",
          "100:             }",
          "101:             if (bootstrapMetadataVersion == null) {",
          "102:                 bootstrapMetadataVersion = MetadataVersion.latest();",
          "103:             }",
          "104:             String baseDirectory = TestUtils.tempDirectory(\"kafka_\" + clusterId).getAbsolutePath();",
          "106:                 NavigableMap<Integer, ControllerNode> controllerNodes = new TreeMap<>();",
          "107:                 for (ControllerNode.Builder controllerNodeBuilder : controllerNodeBuilders.values()) {",
          "108:                     ControllerNode controllerNode = controllerNodeBuilder.build(baseDirectory);",
          "109:                     if (controllerNodes.put(controllerNode.id(), controllerNode) != null) {",
          "110:                         throw new RuntimeException(\"More than one controller claimed ID \" + controllerNode.id());",
          "113:                 NavigableMap<Integer, BrokerNode> brokerNodes = new TreeMap<>();",
          "114:                 for (BrokerNode.Builder brokerNodeBuilder : brokerNodeBuilders.values()) {",
          "115:                     BrokerNode brokerNode = brokerNodeBuilder.build(baseDirectory);",
          "116:                     if (brokerNodes.put(brokerNode.id(), brokerNode) != null) {",
          "117:                         throw new RuntimeException(\"More than one broker claimed ID \" + brokerNode.id());",
          "",
          "[Added Lines]",
          "87:                 brokerNodeBuilders.put(nextId,",
          "88:                     new BrokerNode.Builder().",
          "89:                         setId(nextId));",
          "95:             String baseDirectory = TestUtils.tempDirectory().getAbsolutePath();",
          "97:                 if (clusterId == null) {",
          "98:                     clusterId = Uuid.randomUuid();",
          "99:                 }",
          "100:                 if (bootstrapMetadataVersion == null) {",
          "101:                     bootstrapMetadataVersion = MetadataVersion.latest();",
          "102:                 }",
          "103:                 TreeMap<Integer, ControllerNode> controllerNodes = new TreeMap<>();",
          "104:                 for (ControllerNode.Builder builder : controllerNodeBuilders.values()) {",
          "105:                     ControllerNode node = builder.",
          "106:                         build(baseDirectory, clusterId, brokerNodeBuilders.containsKey(builder.id()));",
          "107:                     if (controllerNodes.put(node.id(), node) != null) {",
          "108:                         throw new RuntimeException(\"Duplicate builder for controller \" + node.id());",
          "111:                 TreeMap<Integer, BrokerNode> brokerNodes = new TreeMap<>();",
          "112:                 for (BrokerNode.Builder builder : brokerNodeBuilders.values()) {",
          "113:                     BrokerNode node = builder.",
          "114:                         build(baseDirectory, clusterId, controllerNodeBuilders.containsKey(builder.id()));",
          "115:                     if (brokerNodes.put(node.id(), node) != null) {",
          "116:                         throw new RuntimeException(\"Duplicate builder for broker \" + node.id());",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "124:                     brokerNodes);",
          "125:             } catch (Exception e) {",
          "126:                 try {",
          "130:                 }",
          "131:                 throw e;",
          "132:             }",
          "",
          "[Removed Lines]",
          "127:                     Utils.delete(new File(baseDirectory));",
          "128:                 } catch (IOException x) {",
          "129:                     throw new RuntimeException(x);",
          "",
          "[Added Lines]",
          "126:                     Files.delete(Paths.get(baseDirectory));",
          "127:                 } catch (Exception x) {",
          "128:                     throw new RuntimeException(\"Failed to delete base directory \" + baseDirectory, x);",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "150:     private final NavigableMap<Integer, ControllerNode> controllerNodes;",
          "151:     private final NavigableMap<Integer, BrokerNode> brokerNodes;",
          "157:     private TestKitNodes(",
          "158:         String baseDirectory,",
          "159:         Uuid clusterId,",
          "",
          "[Removed Lines]",
          "153:     public boolean isCombined(int node) {",
          "154:         return controllerNodes.containsKey(node) && brokerNodes.containsKey(node);",
          "155:     }",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "168:         this.brokerNodes = brokerNodes;",
          "169:     }",
          "171:     public String baseDirectory() {",
          "172:         return baseDirectory;",
          "173:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "166:     public boolean isCombined(int node) {",
          "167:         return controllerNodes.containsKey(node) && brokerNodes.containsKey(node);",
          "168:     }",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "184:         return controllerNodes;",
          "185:     }",
          "193:     }",
          "197:     }",
          "199:     public ListenerName interBrokerListenerName() {",
          "",
          "[Removed Lines]",
          "187:     public NavigableMap<Integer, BrokerNode> brokerNodes() {",
          "188:         return brokerNodes;",
          "189:     }",
          "191:     public MetaProperties controllerProperties(int id) {",
          "192:         return MetaProperties.apply(clusterId.toString(), id);",
          "195:     public MetaProperties brokerProperties(int id) {",
          "196:         return MetaProperties.apply(clusterId.toString(), id);",
          "",
          "[Added Lines]",
          "186:     public BootstrapMetadata bootstrapMetadata() {",
          "187:         return BootstrapMetadata.fromVersion(bootstrapMetadataVersion(), \"testkit\");",
          "190:     public NavigableMap<Integer, BrokerNode> brokerNodes() {",
          "191:         return brokerNodes;",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "207:     public ListenerName controllerListenerName() {",
          "208:         return new ListenerName(\"CONTROLLER\");",
          "209:     }",
          "225: }",
          "",
          "[Removed Lines]",
          "211:     static List<String> absolutize(String base, Collection<String> directories) {",
          "212:         List<String> newDirectories = new ArrayList<>();",
          "213:         for (String directory : directories) {",
          "214:             newDirectories.add(absolutize(base, directory));",
          "215:         }",
          "216:         return newDirectories;",
          "217:     }",
          "219:     static String absolutize(String base, String directory) {",
          "220:         if (Paths.get(directory).isAbsolute()) {",
          "221:             return directory;",
          "222:         }",
          "223:         return Paths.get(base, directory).toAbsolutePath().toString();",
          "224:     }",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "core/src/test/scala/integration/kafka/server/QuorumTestHarness.scala||core/src/test/scala/integration/kafka/server/QuorumTestHarness.scala": [
          "File: core/src/test/scala/integration/kafka/server/QuorumTestHarness.scala -> core/src/test/scala/integration/kafka/server/QuorumTestHarness.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: import java.io.{ByteArrayOutputStream, File, PrintStream}",
          "21: import java.net.InetSocketAddress",
          "22: import java.util",
          "24: import java.util.concurrent.{CompletableFuture, TimeUnit}",
          "25: import javax.security.auth.login.Configuration",
          "26: import kafka.tools.StorageTool",
          "",
          "[Removed Lines]",
          "23: import java.util.{Collections, Properties}",
          "",
          "[Added Lines]",
          "23: import java.util.{Collections, Optional, OptionalInt, Properties}",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "33: import org.apache.kafka.common.utils.{Exit, Time}",
          "34: import org.apache.kafka.metadata.bootstrap.BootstrapMetadata",
          "35: import org.apache.kafka.common.metadata.FeatureLevelRecord",
          "36: import org.apache.kafka.raft.RaftConfig.{AddressSpec, InetAddressSpec}",
          "37: import org.apache.kafka.server.common.{ApiMessageAndVersion, MetadataVersion}",
          "38: import org.apache.kafka.server.fault.{FaultHandler, MockFaultHandler}",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "36: import org.apache.kafka.metadata.properties.MetaPropertiesEnsemble.VerificationFlag.{REQUIRE_AT_LEAST_ONE_VALID, REQUIRE_METADATA_LOG_DIR}",
          "37: import org.apache.kafka.metadata.properties.{MetaProperties, MetaPropertiesEnsemble, MetaPropertiesVersion}",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "41: import org.junit.jupiter.api.Assertions._",
          "42: import org.junit.jupiter.api.{AfterAll, AfterEach, BeforeAll, BeforeEach, Tag, TestInfo}",
          "44: import scala.collection.mutable.ArrayBuffer",
          "45: import scala.collection.mutable.ListBuffer",
          "46: import scala.collection.{Seq, immutable}",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "46: import java.nio.file.{Files, Paths}",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "96:     startup: Boolean,",
          "97:     threadNamePrefix: Option[String],",
          "98:   ): KafkaBroker = {",
          "99:     val sharedServer = new SharedServer(config,",
          "101:       Time.SYSTEM,",
          "102:       new Metrics(),",
          "103:       controllerQuorumVotersFuture,",
          "104:       faultHandlerFactory)",
          "105:     var broker: BrokerServer = null",
          "106:     try {",
          "109:       if (startup) broker.startup()",
          "110:       broker",
          "111:     } catch {",
          "",
          "[Removed Lines]",
          "100:       new MetaProperties(clusterId, config.nodeId),",
          "107:       broker = new BrokerServer(sharedServer,",
          "108:         initialOfflineDirs = Seq())",
          "",
          "[Added Lines]",
          "102:     val metaPropertiesEnsemble = {",
          "103:       val loader = new MetaPropertiesEnsemble.Loader()",
          "104:       config.logDirs.foreach(loader.addLogDir(_))",
          "105:       loader.addMetadataLogDir(config.metadataLogDir)",
          "106:       val ensemble = loader.load()",
          "107:       val copier = new MetaPropertiesEnsemble.Copier(ensemble)",
          "108:       ensemble.emptyLogDirs().forEach(logDir => {",
          "109:         copier.setLogDirProps(logDir, new MetaProperties.Builder().",
          "110:           setVersion(MetaPropertiesVersion.V1).",
          "111:           setClusterId(clusterId).",
          "112:           setNodeId(config.nodeId).",
          "113:           build())",
          "114:       })",
          "115:       copier.setPreWriteHandler((logDir, _, _) => {",
          "116:         Files.createDirectories(Paths.get(logDir));",
          "117:       })",
          "118:       copier.writeLogDirChanges()",
          "119:       copier.copy()",
          "120:     }",
          "121:     metaPropertiesEnsemble.verify(Optional.of(clusterId),",
          "122:       OptionalInt.of(config.nodeId),",
          "123:       util.EnumSet.of(REQUIRE_AT_LEAST_ONE_VALID, REQUIRE_METADATA_LOG_DIR))",
          "125:       metaPropertiesEnsemble,",
          "132:       broker = new BrokerServer(sharedServer)",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "308:     }",
          "309:     val nodeId = Integer.parseInt(props.getProperty(KafkaConfig.NodeIdProp))",
          "310:     val metadataDir = TestUtils.tempDir()",
          "312:     formatDirectories(immutable.Seq(metadataDir.getAbsolutePath), metaProperties)",
          "314:     val metadataRecords = new util.ArrayList[ApiMessageAndVersion]",
          "",
          "[Removed Lines]",
          "311:     val metaProperties = new MetaProperties(Uuid.randomUuid().toString, nodeId)",
          "",
          "[Added Lines]",
          "335:     val metaProperties = new MetaProperties.Builder().",
          "336:       setVersion(MetaPropertiesVersion.V1).",
          "337:       setClusterId(Uuid.randomUuid().toString).",
          "338:       setNodeId(nodeId).",
          "339:       build()",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "330:     props.setProperty(KafkaConfig.QuorumVotersProp, s\"${nodeId}@localhost:0\")",
          "331:     val config = new KafkaConfig(props)",
          "332:     val controllerQuorumVotersFuture = new CompletableFuture[util.Map[Integer, AddressSpec]]",
          "333:     val sharedServer = new SharedServer(config,",
          "335:       Time.SYSTEM,",
          "336:       new Metrics(),",
          "337:       controllerQuorumVotersFuture,",
          "",
          "[Removed Lines]",
          "334:       metaProperties,",
          "",
          "[Added Lines]",
          "361:     val metaPropertiesEnsemble = new MetaPropertiesEnsemble.Loader().",
          "362:       addMetadataLogDir(metadataDir.getAbsolutePath).",
          "363:       load()",
          "364:     metaPropertiesEnsemble.verify(Optional.of(metaProperties.clusterId().get()),",
          "365:       OptionalInt.of(nodeId),",
          "366:       util.EnumSet.of(REQUIRE_AT_LEAST_ONE_VALID, REQUIRE_METADATA_LOG_DIR))",
          "368:       metaPropertiesEnsemble,",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "363:       faultHandlerFactory,",
          "364:       metadataDir,",
          "365:       controllerQuorumVotersFuture,",
          "367:       this,",
          "368:       faultHandler)",
          "369:   }",
          "",
          "[Removed Lines]",
          "366:       metaProperties.clusterId,",
          "",
          "[Added Lines]",
          "400:       metaProperties.clusterId.get(),",
          "",
          "---------------"
        ],
        "core/src/test/scala/kafka/server/BrokerMetadataCheckpointTest.scala||core/src/test/scala/kafka/server/BrokerMetadataCheckpointTest.scala": [
          "File: core/src/test/scala/kafka/server/BrokerMetadataCheckpointTest.scala -> core/src/test/scala/kafka/server/BrokerMetadataCheckpointTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/log/LogManagerTest.scala||core/src/test/scala/unit/kafka/log/LogManagerTest.scala": [
          "File: core/src/test/scala/unit/kafka/log/LogManagerTest.scala -> core/src/test/scala/unit/kafka/log/LogManagerTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: import com.yammer.metrics.core.{Gauge, MetricName}",
          "21: import kafka.server.checkpoints.OffsetCheckpointFile",
          "22: import kafka.server.metadata.{ConfigRepository, MockConfigRepository}",
          "24: import kafka.utils._",
          "25: import org.apache.directory.api.util.FileUtils",
          "26: import org.apache.kafka.common.config.TopicConfig",
          "27: import org.apache.kafka.common.errors.OffsetOutOfRangeException",
          "28: import org.apache.kafka.common.utils.Utils",
          "29: import org.apache.kafka.common.{KafkaException, TopicPartition, Uuid}",
          "30: import org.junit.jupiter.api.Assertions._",
          "31: import org.junit.jupiter.api.{AfterEach, BeforeEach, Test}",
          "32: import org.mockito.ArgumentMatchers.any",
          "",
          "[Removed Lines]",
          "23: import kafka.server.{BrokerMetadataCheckpoint, BrokerTopicStats, KafkaServer, RawMetaProperties}",
          "",
          "[Added Lines]",
          "23: import kafka.server.BrokerTopicStats",
          "30: import org.apache.kafka.metadata.properties.{MetaProperties, MetaPropertiesEnsemble, MetaPropertiesVersion, PropertiesUtils}",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "36: import java.io._",
          "37: import java.nio.file.Files",
          "38: import java.util.concurrent.{ConcurrentHashMap, ConcurrentMap, Future}",
          "40: import org.apache.kafka.server.metrics.KafkaYammerMetrics",
          "41: import org.apache.kafka.server.util.MockTime",
          "42: import org.apache.kafka.storage.internals.log.{FetchDataInfo, FetchIsolation, LogConfig, LogDirFailureChannel, ProducerStateManagerConfig, RemoteIndexCache}",
          "",
          "[Removed Lines]",
          "39: import java.util.{Collections, OptionalLong, Properties}",
          "",
          "[Added Lines]",
          "40: import java.util.{Collections, Optional, OptionalLong, Properties}",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "1044:   @Test",
          "1045:   def testLoadDirectoryIds(): Unit = {",
          "1052:     }",
          "1053:     val dirs: Seq[File] = Seq.fill(5)(TestUtils.tempDir())",
          "1054:     writeMetaProperties(dirs(0))",
          "1058:     writeMetaProperties(dirs(4))",
          "1060:     logManager = createLogManager(dirs)",
          "1063:     assertEquals(Some(Uuid.fromString(\"ZwkGXjB0TvSF6mjVh6gO7Q\")), logManager.directoryId(dirs(1).getAbsolutePath))",
          "1064:     assertEquals(None, logManager.directoryId(dirs(2).getAbsolutePath))",
          "1065:     assertEquals(Some(Uuid.fromString(\"kQfNPJ2FTHq_6Qlyyv6Jqg\")), logManager.directoryId(dirs(3).getAbsolutePath))",
          "1068:   }",
          "1069: }",
          "",
          "[Removed Lines]",
          "1046:     def writeMetaProperties(dir: File, id: Option[String] = None): Unit = {",
          "1047:       val rawProps = new RawMetaProperties()",
          "1048:       rawProps.nodeId = 1",
          "1049:       rawProps.clusterId = \"IVT1Seu3QjacxS7oBTKhDQ\"",
          "1050:       id.foreach(v => rawProps.directoryId = v)",
          "1051:       new BrokerMetadataCheckpoint(new File(dir, KafkaServer.brokerMetaPropsFile)).write(rawProps.props)",
          "1055:     writeMetaProperties(dirs(1), Some(\"ZwkGXjB0TvSF6mjVh6gO7Q\"))",
          "1057:     writeMetaProperties(dirs(3), Some(\"kQfNPJ2FTHq_6Qlyyv6Jqg\"))",
          "1062:     assertTrue(logManager.directoryId(dirs(0).getAbsolutePath).isDefined)",
          "1066:     assertTrue(logManager.directoryId(dirs(4).getAbsolutePath).isDefined)",
          "1067:     assertEquals(4, logManager.directoryIds.size)",
          "",
          "[Added Lines]",
          "1047:     def writeMetaProperties(",
          "1048:       dir: File,",
          "1049:       directoryId: Optional[Uuid] = Optional.empty()",
          "1050:     ): Unit = {",
          "1051:       val metaProps = new MetaProperties.Builder().",
          "1052:         setVersion(MetaPropertiesVersion.V0).",
          "1053:         setClusterId(\"IVT1Seu3QjacxS7oBTKhDQ\").",
          "1054:         setNodeId(1).",
          "1055:         setDirectoryId(directoryId).",
          "1056:         build()",
          "1057:       PropertiesUtils.writePropertiesFile(metaProps.toProperties,",
          "1058:         new File(dir, MetaPropertiesEnsemble.META_PROPERTIES_NAME).getAbsolutePath, false)",
          "1062:     writeMetaProperties(dirs(1), Optional.of(Uuid.fromString(\"ZwkGXjB0TvSF6mjVh6gO7Q\")))",
          "1064:     writeMetaProperties(dirs(3), Optional.of(Uuid.fromString(\"kQfNPJ2FTHq_6Qlyyv6Jqg\")))",
          "1069:     assertFalse(logManager.directoryId(dirs(0).getAbsolutePath).isDefined)",
          "1070:     assertTrue(logManager.directoryId(dirs(1).getAbsolutePath).isDefined)",
          "1074:     assertTrue(logManager.directoryId(dirs(3).getAbsolutePath).isDefined)",
          "1075:     assertEquals(2, logManager.directoryIds.size)",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/server/KafkaRaftServerTest.scala||core/src/test/scala/unit/kafka/server/KafkaRaftServerTest.scala": [
          "File: core/src/test/scala/unit/kafka/server/KafkaRaftServerTest.scala -> core/src/test/scala/unit/kafka/server/KafkaRaftServerTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: import java.io.File",
          "20: import java.nio.file.Files",
          "21: import java.util.{Optional, Properties}",
          "23: import kafka.log.UnifiedLog",
          "24: import org.apache.kafka.common.{KafkaException, Uuid}",
          "25: import org.apache.kafka.common.utils.Utils",
          "26: import org.apache.kafka.metadata.bootstrap.{BootstrapDirectory, BootstrapMetadata}",
          "27: import org.apache.kafka.server.common.MetadataVersion",
          "28: import org.apache.kafka.test.TestUtils",
          "29: import org.junit.jupiter.api.Assertions._",
          "",
          "[Removed Lines]",
          "22: import kafka.common.{InconsistentBrokerMetadataException, InconsistentNodeIdException}",
          "",
          "[Added Lines]",
          "26: import org.apache.kafka.metadata.properties.{MetaProperties, MetaPropertiesEnsemble, MetaPropertiesVersion, PropertiesUtils}",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "36:   def testSuccessfulLoadMetaProperties(): Unit = {",
          "37:     val clusterId = clusterIdBase64",
          "38:     val nodeId = 0",
          "41:     val configProperties = new Properties",
          "42:     configProperties.put(KafkaConfig.ProcessRolesProp, \"broker,controller\")",
          "",
          "[Removed Lines]",
          "39:     val metaProperties = MetaProperties(clusterId, nodeId)",
          "",
          "[Added Lines]",
          "39:     val metaProperties = new MetaProperties.Builder().",
          "40:       setVersion(MetaPropertiesVersion.V1).",
          "41:       setClusterId(clusterId).",
          "42:       setNodeId(nodeId).",
          "43:       build()",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "45:     configProperties.put(KafkaConfig.QuorumVotersProp, s\"$nodeId@localhost:9093\")",
          "46:     configProperties.put(KafkaConfig.ControllerListenerNamesProp, \"SSL\")",
          "53:   }",
          "55:   @Test",
          "",
          "[Removed Lines]",
          "48:     val (loadedMetaProperties, _, offlineDirs) =",
          "49:       invokeLoadMetaProperties(metaProperties, configProperties)",
          "51:     assertEquals(metaProperties, loadedMetaProperties)",
          "52:     assertEquals(Seq.empty, offlineDirs)",
          "",
          "[Added Lines]",
          "52:     val metaPropertiesEnsemble =",
          "53:       invokeLoadMetaProperties(metaProperties, configProperties)._1",
          "55:     val loadedMetaProperties = metaPropertiesEnsemble.logDirProps().values().iterator().next()",
          "56:     assertEquals(metaProperties, new MetaProperties.Builder(loadedMetaProperties).",
          "57:       setDirectoryId(Optional.empty[Uuid]).build())",
          "58:     assertTrue(loadedMetaProperties.directoryId().isPresent)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "58:     val metaNodeId = 1",
          "59:     val configNodeId = 0",
          "62:     val configProperties = new Properties",
          "64:     configProperties.put(KafkaConfig.ProcessRolesProp, \"controller\")",
          "",
          "[Removed Lines]",
          "61:     val metaProperties = MetaProperties(clusterId, metaNodeId)",
          "",
          "[Added Lines]",
          "67:     val metaProperties = new MetaProperties.Builder().",
          "68:       setVersion(MetaPropertiesVersion.V1).",
          "69:       setClusterId(clusterId).",
          "70:       setNodeId(metaNodeId).",
          "71:       build()",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "66:     configProperties.put(KafkaConfig.QuorumVotersProp, s\"$configNodeId@localhost:9092\")",
          "67:     configProperties.put(KafkaConfig.ControllerListenerNamesProp, \"PLAINTEXT\")",
          "70:       invokeLoadMetaProperties(metaProperties, configProperties))",
          "71:   }",
          "",
          "[Removed Lines]",
          "69:     assertThrows(classOf[InconsistentNodeIdException], () =>",
          "",
          "[Added Lines]",
          "79:     assertThrows(classOf[RuntimeException], () =>",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "74:     metaProperties: MetaProperties,",
          "75:     configProperties: Properties,",
          "76:     metadataVersion: Option[MetadataVersion] = Some(MetadataVersion.latest())",
          "78:     val tempLogDir = TestUtils.tempDirectory()",
          "79:     try {",
          "80:       writeMetaProperties(tempLogDir, metaProperties)",
          "81:       metadataVersion.foreach(mv => writeBootstrapMetadata(tempLogDir, mv))",
          "82:       configProperties.put(KafkaConfig.LogDirProp, tempLogDir.getAbsolutePath)",
          "83:       val config = KafkaConfig.fromProps(configProperties)",
          "85:     } finally {",
          "86:       Utils.delete(tempLogDir)",
          "87:     }",
          "",
          "[Removed Lines]",
          "77:   ): (MetaProperties, BootstrapMetadata, collection.Seq[String]) = {",
          "84:       KafkaRaftServer.initializeLogDirs(config)",
          "",
          "[Added Lines]",
          "87:   ): (MetaPropertiesEnsemble, BootstrapMetadata) = {",
          "94:       KafkaRaftServer.initializeLogDirs(config, MetaPropertiesEnsemble.LOG, \"\")",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "91:     logDir: File,",
          "92:     metaProperties: MetaProperties",
          "93:   ): Unit = {",
          "97:   }",
          "99:   private def writeBootstrapMetadata(logDir: File, metadataVersion: MetadataVersion): Unit = {",
          "",
          "[Removed Lines]",
          "94:     val metaPropertiesFile = new File(logDir.getAbsolutePath, KafkaServer.brokerMetaPropsFile)",
          "95:     val checkpoint = new BrokerMetadataCheckpoint(metaPropertiesFile)",
          "96:     checkpoint.write(metaProperties.toProperties)",
          "",
          "[Added Lines]",
          "104:     val metaPropertiesFile = new File(logDir.getAbsolutePath, MetaPropertiesEnsemble.META_PROPERTIES_NAME)",
          "105:     PropertiesUtils.writePropertiesFile(metaProperties.toProperties(), metaPropertiesFile.getAbsolutePath, false)",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "111:     val logDir1 = TestUtils.tempDirectory()",
          "112:     val logDir2 = TestUtils.tempDirectory()",
          "115:     val configProperties = new Properties",
          "116:     configProperties.put(KafkaConfig.ProcessRolesProp, \"broker\")",
          "",
          "[Removed Lines]",
          "113:     writeMetaProperties(logDir1, MetaProperties(clusterId, nodeId))",
          "",
          "[Added Lines]",
          "122:     writeMetaProperties(logDir1, new MetaProperties.Builder().",
          "123:       setVersion(MetaPropertiesVersion.V1).",
          "124:       setClusterId(clusterId).",
          "125:       setNodeId(nodeId).",
          "126:       build())",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "120:     configProperties.put(KafkaConfig.ControllerListenerNamesProp, \"SSL\")",
          "121:     val config = KafkaConfig.fromProps(configProperties)",
          "124:   }",
          "126:   @Test",
          "",
          "[Removed Lines]",
          "123:     assertThrows(classOf[KafkaException], () => KafkaRaftServer.initializeLogDirs(config))",
          "",
          "[Added Lines]",
          "136:     assertThrows(classOf[RuntimeException],",
          "137:       () => KafkaRaftServer.initializeLogDirs(config, MetaPropertiesEnsemble.LOG, \"\"))",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "132:     val validDir = TestUtils.tempDirectory()",
          "136:     val invalidDir = TestUtils.tempFile(\"blah\")",
          "",
          "[Removed Lines]",
          "133:     writeMetaProperties(validDir, MetaProperties(clusterId, nodeId))",
          "",
          "[Added Lines]",
          "147:     writeMetaProperties(validDir, new MetaProperties.Builder().",
          "148:       setVersion(MetaPropertiesVersion.V1).",
          "149:       setClusterId(clusterId).",
          "150:       setNodeId(nodeId).",
          "151:       build())",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "143:     configProperties.put(KafkaConfig.ControllerListenerNamesProp, \"SSL\")",
          "144:     val config = KafkaConfig.fromProps(configProperties)",
          "147:   }",
          "149:   @Test",
          "",
          "[Removed Lines]",
          "146:     assertThrows(classOf[KafkaException], () => KafkaRaftServer.initializeLogDirs(config))",
          "",
          "[Added Lines]",
          "164:     assertThrows(classOf[RuntimeException],",
          "165:       () => KafkaRaftServer.initializeLogDirs(config, MetaPropertiesEnsemble.LOG, \"\"))",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "155:     val validDir = TestUtils.tempDirectory()",
          "157:     writeBootstrapMetadata(validDir, MetadataVersion.latest())",
          "",
          "[Removed Lines]",
          "156:     writeMetaProperties(validDir, MetaProperties(clusterId, nodeId))",
          "",
          "[Added Lines]",
          "175:     writeMetaProperties(validDir, new MetaProperties.Builder().",
          "176:       setVersion(MetaPropertiesVersion.V1).",
          "177:       setClusterId(clusterId).",
          "178:       setNodeId(nodeId).",
          "179:       build())",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "167:     configProperties.put(KafkaConfig.ControllerListenerNamesProp, \"SSL\")",
          "168:     val config = KafkaConfig.fromProps(configProperties)",
          "173:   }",
          "175:   @Test",
          "",
          "[Removed Lines]",
          "170:     val (loadedProperties, _, offlineDirs) = KafkaRaftServer.initializeLogDirs(config)",
          "171:     assertEquals(nodeId, loadedProperties.nodeId)",
          "172:     assertEquals(Seq(invalidDir.getAbsolutePath), offlineDirs)",
          "",
          "[Added Lines]",
          "194:     val (metaPropertiesEnsemble, _) =",
          "195:       KafkaRaftServer.initializeLogDirs(config, MetaPropertiesEnsemble.LOG, \"\")",
          "196:     assertEquals(nodeId, metaPropertiesEnsemble.nodeId().getAsInt())",
          "197:     assertEquals(invalidDir.getAbsolutePath,",
          "198:       String.join(\", \", metaPropertiesEnsemble.errorLogDirs()))",
          "",
          "---------------",
          "--- Hunk 14 ---",
          "[Context before]",
          "182:     val dataDir = TestUtils.tempDirectory()",
          "184:     Seq(metadataDir, dataDir).foreach { dir =>",
          "186:     }",
          "",
          "[Removed Lines]",
          "185:       writeMetaProperties(dir, MetaProperties(clusterId, nodeId))",
          "",
          "[Added Lines]",
          "211:       writeMetaProperties(dir, new MetaProperties.Builder().",
          "212:         setVersion(MetaPropertiesVersion.V1).",
          "213:         setClusterId(clusterId).",
          "214:         setNodeId(nodeId).",
          "215:         build())",
          "",
          "---------------",
          "--- Hunk 15 ---",
          "[Context before]",
          "197:     configProperties.put(KafkaConfig.ControllerListenerNamesProp, \"SSL\")",
          "198:     val config = KafkaConfig.fromProps(configProperties)",
          "201:   }",
          "203:   @Test",
          "",
          "[Removed Lines]",
          "200:     assertThrows(classOf[KafkaException], () => KafkaRaftServer.initializeLogDirs(config))",
          "",
          "[Added Lines]",
          "230:     assertThrows(classOf[KafkaException],",
          "231:       () => KafkaRaftServer.initializeLogDirs(config, MetaPropertiesEnsemble.LOG, \"\"))",
          "",
          "---------------",
          "--- Hunk 16 ---",
          "[Context before]",
          "210:     Seq(logDir1, logDir2).foreach { dir =>",
          "212:     }",
          "214:     val configProperties = new Properties",
          "",
          "[Removed Lines]",
          "211:       writeMetaProperties(dir, MetaProperties(clusterId = Uuid.randomUuid().toString, nodeId))",
          "",
          "[Added Lines]",
          "242:       writeMetaProperties(dir, new MetaProperties.Builder().",
          "243:         setVersion(MetaPropertiesVersion.V1).",
          "244:         setClusterId(Uuid.randomUuid().toString).",
          "245:         setNodeId(nodeId).",
          "246:         build())",
          "",
          "---------------",
          "--- Hunk 17 ---",
          "[Context before]",
          "219:     configProperties.put(KafkaConfig.ControllerListenerNamesProp, \"SSL\")",
          "220:     val config = KafkaConfig.fromProps(configProperties)",
          "224:   }",
          "226:   @Test",
          "227:   def testKRaftUpdateWithIBP(): Unit = {",
          "228:     val clusterId = clusterIdBase64",
          "229:     val nodeId = 0",
          "232:     val configProperties = new Properties",
          "233:     configProperties.put(KafkaConfig.ProcessRolesProp, \"broker,controller\")",
          "",
          "[Removed Lines]",
          "222:     assertThrows(classOf[InconsistentBrokerMetadataException],",
          "223:       () => KafkaRaftServer.initializeLogDirs(config))",
          "230:     val metaProperties = MetaProperties(clusterId, nodeId)",
          "",
          "[Added Lines]",
          "257:     assertThrows(classOf[RuntimeException],",
          "258:       () => KafkaRaftServer.initializeLogDirs(config, MetaPropertiesEnsemble.LOG, \"\"))",
          "265:     val metaProperties = new MetaProperties.Builder().",
          "266:       setVersion(MetaPropertiesVersion.V1).",
          "267:       setClusterId(clusterId).",
          "268:       setNodeId(nodeId).",
          "269:       setDirectoryId(Uuid.fromString(\"4jm0e-YRYeB6CCKBvwoS8w\")).",
          "270:       build()",
          "",
          "---------------",
          "--- Hunk 18 ---",
          "[Context before]",
          "237:     configProperties.put(KafkaConfig.ControllerListenerNamesProp, \"SSL\")",
          "238:     configProperties.put(KafkaConfig.InterBrokerProtocolVersionProp, \"3.3-IV1\")",
          "241:       invokeLoadMetaProperties(metaProperties, configProperties, None)",
          "245:     assertEquals(bootstrapMetadata.metadataVersion(), MetadataVersion.IBP_3_3_IV1)",
          "246:   }",
          "",
          "[Removed Lines]",
          "240:     val (loadedMetaProperties, bootstrapMetadata, offlineDirs) =",
          "243:     assertEquals(metaProperties, loadedMetaProperties)",
          "244:     assertEquals(Seq.empty, offlineDirs)",
          "",
          "[Added Lines]",
          "280:     val (metaPropertiesEnsemble, bootstrapMetadata) =",
          "283:     assertEquals(metaProperties, metaPropertiesEnsemble.logDirProps().values().iterator().next())",
          "284:     assertTrue(metaPropertiesEnsemble.errorLogDirs().isEmpty())",
          "285:     assertTrue(metaPropertiesEnsemble.emptyLogDirs().isEmpty())",
          "",
          "---------------",
          "--- Hunk 19 ---",
          "[Context before]",
          "249:   def testKRaftUpdateWithoutIBP(): Unit = {",
          "250:     val clusterId = clusterIdBase64",
          "251:     val nodeId = 0",
          "254:     val logDir = TestUtils.tempDirectory()",
          "255:     writeMetaProperties(logDir, metaProperties)",
          "",
          "[Removed Lines]",
          "252:     val metaProperties = MetaProperties(clusterId, nodeId)",
          "",
          "[Added Lines]",
          "293:     val metaProperties = new MetaProperties.Builder().",
          "294:       setVersion(MetaPropertiesVersion.V1).",
          "295:       setClusterId(clusterId).",
          "296:       setNodeId(nodeId).",
          "297:       setDirectoryId(Uuid.fromString(\"4jm0e-YRYeB6CCKBvwoS8w\")).",
          "298:       build()",
          "",
          "---------------",
          "--- Hunk 20 ---",
          "[Context before]",
          "262:     configProperties.put(KafkaConfig.ControllerListenerNamesProp, \"SSL\")",
          "263:     configProperties.put(KafkaConfig.LogDirProp, logDir.getAbsolutePath)",
          "266:       invokeLoadMetaProperties(metaProperties, configProperties, None)",
          "270:     assertEquals(bootstrapMetadata.metadataVersion(), MetadataVersion.latest())",
          "271:   }",
          "272: }",
          "",
          "[Removed Lines]",
          "265:     val (loadedMetaProperties, bootstrapMetadata, offlineDirs) =",
          "268:     assertEquals(metaProperties, loadedMetaProperties)",
          "269:     assertEquals(Seq.empty, offlineDirs)",
          "",
          "[Added Lines]",
          "311:     val (metaPropertiesEnsemble, bootstrapMetadata) =",
          "314:     assertEquals(metaProperties, metaPropertiesEnsemble.logDirProps().values().iterator().next())",
          "315:     assertTrue(metaPropertiesEnsemble.errorLogDirs().isEmpty())",
          "316:     assertTrue(metaPropertiesEnsemble.emptyLogDirs().isEmpty())",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/server/ServerGenerateBrokerIdTest.scala||core/src/test/scala/unit/kafka/server/ServerGenerateBrokerIdTest.scala": [
          "File: core/src/test/scala/unit/kafka/server/ServerGenerateBrokerIdTest.scala -> core/src/test/scala/unit/kafka/server/ServerGenerateBrokerIdTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: package kafka.server",
          "21: import scala.collection.Seq",
          "24: import kafka.utils.TestUtils",
          "25: import org.junit.jupiter.api.{AfterEach, BeforeEach, Test, TestInfo}",
          "26: import org.junit.jupiter.api.Assertions._",
          "29: import org.apache.zookeeper.KeeperException.NodeExistsException",
          "31: class ServerGenerateBrokerIdTest extends QuorumTestHarness {",
          "",
          "[Removed Lines]",
          "19: import java.util.Properties",
          "23: import kafka.server.QuorumTestHarness",
          "27: import java.io.File",
          "",
          "[Added Lines]",
          "19: import java.util.{OptionalInt, Properties}",
          "22: import org.apache.kafka.common.utils.Utils",
          "23: import org.apache.kafka.metadata.properties.{MetaProperties, MetaPropertiesEnsemble, PropertiesUtils}",
          "27: import java.io.File",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "155:     assertThrows(classOf[NodeExistsException], () => serverB.startup())",
          "156:     servers = Seq(serverA)",
          "165:     propsB.setProperty(KafkaConfig.BrokerIdProp, \"2\")",
          "170:     serverA.shutdown()",
          "174:     assertTrue(verifyBrokerMetadata(serverA.config.logDirs, 1))",
          "176:     TestUtils.assertNoNonDaemonThreads(this.getClass.getName)",
          "177:   }",
          "179:   def verifyBrokerMetadata(logDirs: Seq[String], brokerId: Int): Boolean = {",
          "180:     for (logDir <- logDirs) {",
          "188:       }",
          "189:     }",
          "190:     true",
          "",
          "[Removed Lines]",
          "159:     serverB.config.logDirs.foreach { logDir =>",
          "160:       val brokerMetaFile = new File(logDir + File.separator + KafkaServer.brokerMetaPropsFile)",
          "161:       assertFalse(brokerMetaFile.exists())",
          "162:     }",
          "166:     val newConfigB = KafkaConfig.fromProps(propsB)",
          "167:     val newServerB = TestUtils.createServer(newConfigB, threadNamePrefix = Option(this.getClass.getName))",
          "168:     servers = Seq(serverA, newServerB)",
          "171:     newServerB.shutdown()",
          "175:     assertTrue(verifyBrokerMetadata(newServerB.config.logDirs, 2))",
          "181:       val brokerMetadataOpt = new BrokerMetadataCheckpoint(",
          "182:         new File(logDir + File.separator + KafkaServer.brokerMetaPropsFile)).read()",
          "183:       brokerMetadataOpt match {",
          "184:         case Some(properties) =>",
          "185:           val brokerMetadata = new RawMetaProperties(properties)",
          "186:           if (brokerMetadata.brokerId.exists(_ != brokerId)) return false",
          "187:         case _ => return false",
          "",
          "[Added Lines]",
          "159:     val serverB2 = new KafkaServer(KafkaConfig.fromProps(propsB),",
          "160:       threadNamePrefix = Option(this.getClass.getName))",
          "161:     val startupException = assertThrows(classOf[RuntimeException], () => serverB2.startup())",
          "162:     assertTrue(startupException.getMessage.startsWith(\"Stored node id 1 doesn't match previous node id 2\"),",
          "163:       \"Unexpected exception message \" + startupException.getMessage())",
          "164:     serverB2.config.logDirs.foreach(logDir => Utils.delete(new File(logDir)))",
          "165:     propsB.setProperty(KafkaConfig.BrokerIdProp, \"3\")",
          "166:     val serverB3 = new KafkaServer(KafkaConfig.fromProps(propsB),",
          "167:       threadNamePrefix = Option(this.getClass.getName))",
          "168:     serverB3.startup()",
          "169:     servers = Seq(serverA, serverB3)",
          "172:     serverB3.shutdown()",
          "176:     assertTrue(verifyBrokerMetadata(serverB3.config.logDirs, 3))",
          "182:       val properties = PropertiesUtils.readPropertiesFile(",
          "183:         new File(logDir, MetaPropertiesEnsemble.META_PROPERTIES_NAME).getAbsolutePath)",
          "184:       val metaProps = new MetaProperties.Builder(properties).build()",
          "185:       if (!metaProps.nodeId().equals(OptionalInt.of(brokerId))) {",
          "186:         return false",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/server/ServerGenerateClusterIdTest.scala||core/src/test/scala/unit/kafka/server/ServerGenerateClusterIdTest.scala": [
          "File: core/src/test/scala/unit/kafka/server/ServerGenerateClusterIdTest.scala -> core/src/test/scala/unit/kafka/server/ServerGenerateClusterIdTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: package kafka.server",
          "19: import java.io.File",
          "22: import scala.collection.Seq",
          "23: import scala.concurrent._",
          "24: import scala.concurrent.duration._",
          "25: import ExecutionContext.Implicits._",
          "28: import kafka.utils.TestUtils",
          "31: import org.junit.jupiter.api.Assertions._",
          "32: import org.junit.jupiter.api.{AfterEach, BeforeEach, Test, TestInfo}",
          "33: import org.apache.kafka.test.TestUtils.isValidClusterId",
          "36: class ServerGenerateClusterIdTest extends QuorumTestHarness {",
          "37:   var config1: KafkaConfig = _",
          "",
          "[Removed Lines]",
          "27: import kafka.common.{InconsistentBrokerMetadataException, InconsistentClusterIdException}",
          "29: import kafka.server.QuorumTestHarness",
          "",
          "[Added Lines]",
          "25: import org.apache.kafka.metadata.properties.{MetaProperties, MetaPropertiesEnsemble, MetaPropertiesVersion, PropertiesUtils}",
          "30: import java.util.Optional",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "173:     val server = new KafkaServer(config1, threadNamePrefix = Option(this.getClass.getName))",
          "178:     server.shutdown()",
          "",
          "[Removed Lines]",
          "176:     assertThrows(classOf[InconsistentClusterIdException], () => server.startup())",
          "",
          "[Added Lines]",
          "173:     assertThrows(classOf[RuntimeException], () => server.startup())",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "197:     val server = new KafkaServer(config, threadNamePrefix = Option(this.getClass.getName))",
          "202:     server.shutdown()",
          "",
          "[Removed Lines]",
          "200:     assertThrows(classOf[InconsistentBrokerMetadataException], () => server.startup())",
          "",
          "[Added Lines]",
          "197:     assertThrows(classOf[RuntimeException], () => server.startup())",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "211:   }",
          "213:   def forgeBrokerMetadata(logDir: String, brokerId: Int, clusterId: String): Unit = {",
          "217:   }",
          "219:   def verifyBrokerMetadata(logDirs: Seq[String], clusterId: String): Boolean = {",
          "220:     for (logDir <- logDirs) {",
          "228:       }",
          "229:     }",
          "230:     true",
          "231:   }",
          "233: }",
          "",
          "[Removed Lines]",
          "214:     val checkpoint = new BrokerMetadataCheckpoint(",
          "215:       new File(logDir + File.separator + KafkaServer.brokerMetaPropsFile))",
          "216:     checkpoint.write(ZkMetaProperties(clusterId, brokerId).toProperties)",
          "221:       val brokerMetadataOpt = new BrokerMetadataCheckpoint(",
          "222:         new File(logDir + File.separator + KafkaServer.brokerMetaPropsFile)).read()",
          "223:       brokerMetadataOpt match {",
          "224:         case Some(properties) =>",
          "225:           val brokerMetadata = new RawMetaProperties(properties)",
          "226:           if (brokerMetadata.clusterId.exists(_ != clusterId)) return false",
          "227:         case _ => return false",
          "",
          "[Added Lines]",
          "211:     val metaProps = new MetaProperties.Builder().",
          "212:       setVersion(MetaPropertiesVersion.V0).",
          "213:       setNodeId(brokerId).",
          "214:       setClusterId(clusterId).",
          "215:       build()",
          "216:     PropertiesUtils.writePropertiesFile(metaProps.toProperties(),",
          "217:       new File(logDir, MetaPropertiesEnsemble.META_PROPERTIES_NAME).getAbsolutePath, false)",
          "222:       val properties = PropertiesUtils.readPropertiesFile(",
          "223:         new File(logDir, MetaPropertiesEnsemble.META_PROPERTIES_NAME).getAbsolutePath)",
          "224:       val metaProps = new MetaProperties.Builder(properties).build()",
          "225:       if (!metaProps.clusterId().equals(Optional.of(clusterId))) {",
          "226:         return false",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala": [
          "File: core/src/test/scala/unit/kafka/tools/StorageToolTest.scala -> core/src/test/scala/unit/kafka/tools/StorageToolTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: import java.nio.file.{Files, Paths}",
          "23: import java.util",
          "24: import java.util.Properties",
          "27: import kafka.utils.Exit",
          "28: import kafka.utils.TestUtils",
          "29: import org.apache.commons.io.output.NullOutputStream",
          "30: import org.apache.kafka.common.utils.Utils",
          "31: import org.apache.kafka.server.common.MetadataVersion",
          "32: import org.apache.kafka.common.metadata.UserScramCredentialRecord",
          "33: import org.junit.jupiter.api.Assertions.{assertEquals, assertFalse, assertThrows, assertTrue}",
          "34: import org.junit.jupiter.api.{Test, Timeout}",
          "",
          "[Removed Lines]",
          "25: import org.apache.kafka.common.{KafkaException, Uuid}",
          "26: import kafka.server.{BrokerMetadataCheckpoint, KafkaConfig, KafkaServer, MetaProperties}",
          "",
          "[Added Lines]",
          "25: import org.apache.kafka.common.{DirectoryId, KafkaException}",
          "26: import kafka.server.KafkaConfig",
          "33: import org.apache.kafka.metadata.properties.{MetaProperties, MetaPropertiesEnsemble, MetaPropertiesVersion, PropertiesUtils}",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "115:     val stream = new ByteArrayOutputStream()",
          "116:     val tempDir = TestUtils.tempDir()",
          "117:     try {",
          "119:         String.join(\"\\n\", util.Arrays.asList(",
          "120:           \"version=1\",",
          "121:           \"cluster.id=XcZZOzUqS4yHOjhMQB6JLQ\")).",
          "122:             getBytes(StandardCharsets.UTF_8))",
          "123:       assertEquals(1, StorageTool.",
          "",
          "[Removed Lines]",
          "118:       Files.write(tempDir.toPath.resolve(KafkaServer.brokerMetaPropsFile),",
          "",
          "[Added Lines]",
          "119:       Files.write(tempDir.toPath.resolve(MetaPropertiesEnsemble.META_PROPERTIES_NAME),",
          "122:           \"node.id=1\",",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "125:       assertEquals(s\"\"\"Found log directory:",
          "126:   ${tempDir.toString}",
          "130: Found problem:",
          "131:   The kafka configuration file appears to be for a legacy cluster, but the directories are formatted for a cluster in KRaft mode.",
          "",
          "[Removed Lines]",
          "128: Found metadata: {cluster.id=XcZZOzUqS4yHOjhMQB6JLQ, version=1}",
          "",
          "[Added Lines]",
          "130: Found metadata: {cluster.id=XcZZOzUqS4yHOjhMQB6JLQ, node.id=1, version=1}",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "139:     val stream = new ByteArrayOutputStream()",
          "140:     val tempDir = TestUtils.tempDir()",
          "141:     try {",
          "143:         String.join(\"\\n\", util.Arrays.asList(",
          "144:           \"version=0\",",
          "145:           \"broker.id=1\",",
          "",
          "[Removed Lines]",
          "142:       Files.write(tempDir.toPath.resolve(KafkaServer.brokerMetaPropsFile),",
          "",
          "[Added Lines]",
          "144:       Files.write(tempDir.toPath.resolve(MetaPropertiesEnsemble.META_PROPERTIES_NAME),",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "163:   def testFormatEmptyDirectory(): Unit = {",
          "164:     val tempDir = TestUtils.tempDir()",
          "165:     try {",
          "168:       val stream = new ByteArrayOutputStream()",
          "169:       val bootstrapMetadata = StorageTool.buildBootstrapMetadata(MetadataVersion.latest(), None, \"test format command\")",
          "170:       assertEquals(0, StorageTool.",
          "",
          "[Removed Lines]",
          "166:       val metaProperties = MetaProperties(",
          "167:         clusterId = \"XcZZOzUqS4yHOjhMQB6JLQ\", nodeId = 2)",
          "",
          "[Added Lines]",
          "168:       val metaProperties = new MetaProperties.Builder().",
          "169:         setVersion(MetaPropertiesVersion.V1).",
          "170:         setClusterId(\"XcZZOzUqS4yHOjhMQB6JLQ\").",
          "171:         setNodeId(2).",
          "172:         build()",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "367:   def testDirUuidGeneration(): Unit = {",
          "368:     val tempDir = TestUtils.tempDir()",
          "369:     try {",
          "373:       assertEquals(0, StorageTool.",
          "374:         formatCommand(new PrintStream(NullOutputStream.NULL_OUTPUT_STREAM), Seq(tempDir.toString), metaProperties, bootstrapMetadata, MetadataVersion.latest(), ignoreFormatted = false))",
          "377:       assertTrue(metaPropertiesFile.exists())",
          "382:     } finally Utils.delete(tempDir)",
          "383:   }",
          "384: }",
          "",
          "[Removed Lines]",
          "370:       val metaProperties = MetaProperties(",
          "371:         clusterId = \"XcZZOzUqS4yHOjhMQB6JLQ\", nodeId = 2)",
          "372:       val bootstrapMetadata = StorageTool.buildBootstrapMetadata(MetadataVersion.latest(), None, \"test format command\")",
          "376:       val metaPropertiesFile = Paths.get(tempDir.toURI).resolve(KafkaServer.brokerMetaPropsFile).toFile",
          "378:       val properties = new BrokerMetadataCheckpoint(metaPropertiesFile).read().get",
          "379:       assertTrue(properties.containsKey(\"directory.id\"))",
          "380:       val directoryId = Uuid.fromString(properties.getProperty(\"directory.id\"))",
          "381:       assertFalse(Uuid.RESERVED.contains(directoryId))",
          "",
          "[Added Lines]",
          "375:       val metaProperties = new MetaProperties.Builder().",
          "376:         setClusterId(\"XcZZOzUqS4yHOjhMQB6JLQ\").",
          "377:         setNodeId(2).",
          "378:         build()",
          "379:       val bootstrapMetadata = StorageTool.",
          "380:         buildBootstrapMetadata(MetadataVersion.latest(), None, \"test format command\")",
          "384:       val metaPropertiesFile = Paths.get(tempDir.toURI).resolve(MetaPropertiesEnsemble.META_PROPERTIES_NAME).toFile",
          "386:       val metaProps = new MetaProperties.Builder(",
          "387:         PropertiesUtils.readPropertiesFile(metaPropertiesFile.getAbsolutePath())).",
          "388:           build()",
          "389:       assertTrue(metaProps.directoryId().isPresent())",
          "390:       assertFalse(DirectoryId.reserved(metaProps.directoryId().get()))",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/bootstrap/BootstrapDirectory.java||metadata/src/main/java/org/apache/kafka/metadata/bootstrap/BootstrapDirectory.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/bootstrap/BootstrapDirectory.java -> metadata/src/main/java/org/apache/kafka/metadata/bootstrap/BootstrapDirectory.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "23: import org.apache.kafka.server.common.ApiMessageAndVersion;",
          "24: import org.apache.kafka.server.common.MetadataVersion;",
          "26: import java.nio.file.Files;",
          "27: import java.nio.file.Path;",
          "28: import java.nio.file.Paths;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "26: import java.io.IOException;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "107:                 \"the binary bootstrap metadata file: \" + binaryPath);",
          "108:     }",
          "111:         if (!Files.isDirectory(Paths.get(directoryPath))) {",
          "112:             throw new RuntimeException(\"No such directory as \" + directoryPath);",
          "113:         }",
          "",
          "[Removed Lines]",
          "110:     public void writeBinaryFile(BootstrapMetadata bootstrapMetadata) throws Exception {",
          "",
          "[Added Lines]",
          "111:     public void writeBinaryFile(BootstrapMetadata bootstrapMetadata) throws IOException {",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/properties/MetaProperties.java||metadata/src/main/java/org/apache/kafka/metadata/properties/MetaProperties.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/properties/MetaProperties.java -> metadata/src/main/java/org/apache/kafka/metadata/properties/MetaProperties.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.metadata.properties;",
          "20: import org.apache.kafka.common.Uuid;",
          "22: import java.util.Objects;",
          "23: import java.util.Optional;",
          "24: import java.util.OptionalInt;",
          "25: import java.util.Properties;",
          "31: public final class MetaProperties {",
          "35:     static final String VERSION_PROP = \"version\";",
          "40:     static final String CLUSTER_ID_PROP = \"cluster.id\";",
          "45:     static final String BROKER_ID_PROP = \"broker.id\";",
          "50:     static final String NODE_ID_PROP = \"node.id\";",
          "55:     static final String DIRECTORY_ID_PROP = \"directory.id\";",
          "60:     private final MetaPropertiesVersion version;",
          "65:     private final Optional<String> clusterId;",
          "70:     private final OptionalInt nodeId;",
          "75:     private final Optional<Uuid> directoryId;",
          "80:     public static class Builder {",
          "81:         private MetaPropertiesVersion version = MetaPropertiesVersion.V0;",
          "82:         private Optional<String> clusterId = Optional.empty();",
          "83:         private OptionalInt nodeId = OptionalInt.empty();",
          "84:         private Optional<Uuid> directoryId = Optional.empty();",
          "86:         public Builder() {",
          "87:         }",
          "89:         public Builder(Optional<MetaProperties> metaProps) {",
          "90:             if (metaProps.isPresent()) {",
          "91:                 this.version = metaProps.get().version();",
          "92:                 this.clusterId = metaProps.get().clusterId();",
          "93:                 this.nodeId = metaProps.get().nodeId();",
          "94:                 this.directoryId = metaProps.get().directoryId();",
          "95:             }",
          "96:         }",
          "98:         public Builder(MetaProperties metaProps) {",
          "99:             this(Optional.of(metaProps));",
          "100:         }",
          "102:         public Builder(Properties props) {",
          "103:             this.version = MetaPropertiesVersion.fromNumberString(",
          "104:                 props.getProperty(VERSION_PROP,",
          "105:                     MetaPropertiesVersion.V0.numberString()));",
          "106:             if (version.hasBrokerId()) {",
          "107:                 if (props.containsKey(BROKER_ID_PROP)) {",
          "108:                     this.nodeId = OptionalInt.of(PropertiesUtils.loadRequiredIntProp(props, BROKER_ID_PROP));",
          "109:                 }",
          "110:             } else {",
          "111:                 this.nodeId = OptionalInt.of(PropertiesUtils.loadRequiredIntProp(props, NODE_ID_PROP));",
          "112:             }",
          "113:             this.clusterId = Optional.ofNullable(props.getProperty(CLUSTER_ID_PROP));",
          "114:             if (props.containsKey(DIRECTORY_ID_PROP)) {",
          "115:                 try {",
          "116:                     this.directoryId = Optional.of(Uuid.fromString(props.getProperty(DIRECTORY_ID_PROP)));",
          "117:                 } catch (Exception e) {",
          "118:                     throw new RuntimeException(\"Unable to read \" + DIRECTORY_ID_PROP + \" as a Uuid: \" +",
          "119:                             e.getMessage(), e);",
          "120:                 }",
          "121:             } else {",
          "122:                 this.directoryId = Optional.empty();",
          "123:             }",
          "124:         }",
          "126:         public MetaPropertiesVersion version() {",
          "127:             return version;",
          "128:         }",
          "130:         public Builder setVersion(MetaPropertiesVersion version) {",
          "131:             this.version = version;",
          "132:             return this;",
          "133:         }",
          "135:         public Optional<String> clusterId() {",
          "136:             return clusterId;",
          "137:         }",
          "139:         public Builder setClusterId(String clusterId) {",
          "140:             return setClusterId(Optional.of(clusterId));",
          "141:         }",
          "143:         public Builder setClusterId(Optional<String> clusterId) {",
          "144:             this.clusterId = clusterId;",
          "145:             return this;",
          "146:         }",
          "148:         public OptionalInt nodeId() {",
          "149:             return nodeId;",
          "150:         }",
          "152:         public Builder setNodeId(OptionalInt nodeId) {",
          "153:             this.nodeId = nodeId;",
          "154:             return this;",
          "155:         }",
          "157:         public Builder setNodeId(int nodeId) {",
          "158:             return setNodeId(OptionalInt.of(nodeId));",
          "159:         }",
          "161:         public Optional<Uuid> directoryId() {",
          "162:             return directoryId;",
          "163:         }",
          "165:         public Builder setDirectoryId(Optional<Uuid> directoryId) {",
          "166:             this.directoryId = directoryId;",
          "167:             return this;",
          "168:         }",
          "170:         public Builder setDirectoryId(Uuid directoryId) {",
          "171:             return setDirectoryId(Optional.of(directoryId));",
          "172:         }",
          "174:         public MetaProperties build() {",
          "175:             if (!version.equals(MetaPropertiesVersion.V0)) {",
          "176:                 if (!clusterId.isPresent()) {",
          "177:                     throw new RuntimeException(\"cluster.id was not found.\");",
          "178:                 }",
          "179:                 if (!nodeId.isPresent()) {",
          "180:                     throw new RuntimeException(\"node.id was not found.\");",
          "181:                 }",
          "182:             }",
          "183:             return new MetaProperties(version,",
          "184:                 clusterId,",
          "185:                 nodeId,",
          "186:                 directoryId);",
          "187:         }",
          "188:     }",
          "190:     private MetaProperties(",
          "191:         MetaPropertiesVersion version,",
          "192:         Optional<String> clusterId,",
          "193:         OptionalInt nodeId,",
          "194:         Optional<Uuid> directoryId",
          "195:     ) {",
          "196:         this.version = version;",
          "197:         this.clusterId = clusterId;",
          "198:         this.nodeId = nodeId;",
          "199:         this.directoryId = directoryId;",
          "200:     }",
          "202:     public MetaPropertiesVersion version() {",
          "203:         return version;",
          "204:     }",
          "206:     public Optional<String> clusterId() {",
          "207:         return clusterId;",
          "208:     }",
          "210:     public OptionalInt nodeId() {",
          "211:         return nodeId;",
          "212:     }",
          "214:     public Optional<Uuid> directoryId() {",
          "215:         return directoryId;",
          "216:     }",
          "218:     @Override",
          "219:     public int hashCode() {",
          "220:         return Objects.hash(version,",
          "221:             clusterId,",
          "222:             nodeId,",
          "223:             directoryId);",
          "224:     }",
          "226:     @Override",
          "227:     public boolean equals(Object o) {",
          "228:         if (o == null || !(o.getClass().equals(MetaProperties.class))) return false;",
          "229:         MetaProperties other = (MetaProperties) o;",
          "230:         return version.equals(other.version) &&",
          "231:             clusterId.equals(other.clusterId) &&",
          "232:             nodeId.equals(other.nodeId) &&",
          "233:             directoryId.equals(other.directoryId);",
          "234:     }",
          "236:     @Override",
          "237:     public String toString() {",
          "238:         StringBuilder bld = new StringBuilder();",
          "239:         bld.append(\"MetaProperties\");",
          "240:         bld.append(\"(version=\").append(version.number());",
          "241:         if (clusterId.isPresent()) {",
          "242:             bld.append(\", clusterId=\").append(clusterId.get());",
          "243:         }",
          "244:         if (nodeId.isPresent()) {",
          "245:             bld.append(\", nodeId=\").append(nodeId.getAsInt());",
          "246:         }",
          "247:         if (directoryId.isPresent()) {",
          "248:             bld.append(\", directoryId=\").append(directoryId.get());",
          "249:         }",
          "250:         bld.append(\")\");",
          "251:         return bld.toString();",
          "252:     }",
          "254:     public Properties toProperties() {",
          "255:         Properties props = new Properties();",
          "256:         props.setProperty(VERSION_PROP, version.numberString());",
          "257:         if (clusterId.isPresent()) {",
          "258:             props.setProperty(CLUSTER_ID_PROP, clusterId.get());",
          "259:         }",
          "260:         if (version.hasBrokerId()) {",
          "261:             if (nodeId.isPresent()) {",
          "262:                 props.setProperty(BROKER_ID_PROP, \"\" + nodeId.getAsInt());",
          "263:             }",
          "264:         } else {",
          "265:             props.setProperty(NODE_ID_PROP, \"\" + nodeId.getAsInt());",
          "266:         }",
          "267:         if (directoryId.isPresent()) {",
          "268:             props.setProperty(DIRECTORY_ID_PROP, directoryId.get().toString());",
          "269:         }",
          "270:         return props;",
          "271:     }",
          "272: }",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/properties/MetaPropertiesEnsemble.java||metadata/src/main/java/org/apache/kafka/metadata/properties/MetaPropertiesEnsemble.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/properties/MetaPropertiesEnsemble.java -> metadata/src/main/java/org/apache/kafka/metadata/properties/MetaPropertiesEnsemble.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.metadata.properties;",
          "20: import org.apache.kafka.common.DirectoryId;",
          "21: import org.apache.kafka.common.Uuid;",
          "22: import org.slf4j.Logger;",
          "23: import org.slf4j.LoggerFactory;",
          "25: import java.io.File;",
          "26: import java.io.FileNotFoundException;",
          "27: import java.io.IOException;",
          "28: import java.nio.file.NoSuchFileException;",
          "29: import java.util.AbstractMap.SimpleImmutableEntry;",
          "30: import java.util.Collection;",
          "31: import java.util.Collections;",
          "32: import java.util.EnumSet;",
          "33: import java.util.HashMap;",
          "34: import java.util.HashSet;",
          "35: import java.util.Iterator;",
          "36: import java.util.Map;",
          "37: import java.util.Map.Entry;",
          "38: import java.util.Objects;",
          "39: import java.util.Optional;",
          "40: import java.util.OptionalInt;",
          "41: import java.util.Properties;",
          "42: import java.util.Random;",
          "43: import java.util.Set;",
          "44: import java.util.TreeMap;",
          "45: import java.util.TreeSet;",
          "46: import java.util.function.BiConsumer;",
          "47: import java.util.stream.Collectors;",
          "57: public final class MetaPropertiesEnsemble {",
          "61:     public static final Logger LOG = LoggerFactory.getLogger(MetaPropertiesEnsemble.class);",
          "66:     public static final MetaPropertiesEnsemble EMPTY = new MetaPropertiesEnsemble(Collections.emptySet(),",
          "67:         Collections.emptySet(),",
          "68:         Collections.emptyMap(),",
          "69:         Optional.empty());",
          "74:     public static final String META_PROPERTIES_NAME = \"meta.properties\";",
          "79:     private final Set<String> emptyLogDirs;",
          "84:     private final Set<String> errorLogDirs;",
          "89:     private final Map<String, MetaProperties> logDirProps;",
          "94:     private final Optional<String> metadataLogDir;",
          "99:     public static class Loader {",
          "100:         private final TreeSet<String> logDirs = new TreeSet<>();",
          "101:         private Optional<String> metadataLogDir = Optional.empty();",
          "103:         public Loader addLogDirs(Collection<String> logDirs) {",
          "104:             for (String logDir : logDirs) {",
          "105:                 this.logDirs.add(logDir);",
          "106:             }",
          "107:             return this;",
          "108:         }",
          "110:         public Loader addLogDir(String logDir) {",
          "111:             this.logDirs.add(logDir);",
          "112:             return this;",
          "113:         }",
          "115:         public Loader addMetadataLogDir(String metadataLogDir) {",
          "116:             if (this.metadataLogDir.isPresent()) {",
          "117:                 throw new RuntimeException(\"Cannot specify more than one metadata log directory. \" +",
          "118:                     \"Already specified \" + this.metadataLogDir.get());",
          "119:             }",
          "120:             this.metadataLogDir = Optional.of(metadataLogDir);",
          "121:             logDirs.add(metadataLogDir);",
          "122:             return this;",
          "123:         }",
          "125:         public MetaPropertiesEnsemble load() throws IOException  {",
          "126:             if (logDirs.isEmpty()) {",
          "127:                 throw new RuntimeException(\"You must specify at least one log directory.\");",
          "128:             }",
          "129:             Set<String> emptyLogDirs = new HashSet<>();",
          "130:             Set<String> errorLogDirs = new HashSet<>();",
          "131:             Map<String, MetaProperties> logDirProps = new HashMap<>();",
          "132:             for (String logDir : logDirs) {",
          "133:                 String metaPropsFile = new File(logDir, META_PROPERTIES_NAME).getAbsolutePath();",
          "134:                 try {",
          "135:                     Properties props = PropertiesUtils.readPropertiesFile(metaPropsFile);",
          "136:                     MetaProperties meta = new MetaProperties.Builder(props).build();",
          "137:                     logDirProps.put(logDir, meta);",
          "138:                 } catch (NoSuchFileException | FileNotFoundException e) {",
          "139:                     emptyLogDirs.add(logDir);",
          "140:                 } catch (Exception e) {",
          "141:                     LOG.error(\"Error while reading meta.properties file {}\", metaPropsFile, e);",
          "142:                     errorLogDirs.add(logDir);",
          "143:                 }",
          "144:             }",
          "145:             return new MetaPropertiesEnsemble(emptyLogDirs, errorLogDirs, logDirProps, metadataLogDir);",
          "146:         }",
          "147:     }",
          "149:     public interface WriteErrorHandler {",
          "150:         void handle(",
          "151:             String logDir,",
          "152:             IOException e",
          "153:         ) throws IOException;",
          "154:     }",
          "156:     public interface PreWriteHandler {",
          "157:         void handle(",
          "158:             String logDir,",
          "159:             boolean isNew,",
          "160:             MetaProperties metaProperties",
          "161:         ) throws IOException;",
          "162:     }",
          "167:     public static class Copier {",
          "168:         public static final BiConsumer<String, IOException> LOGGING_ERROR_HANDLER = new BiConsumer<String, IOException>() {",
          "169:             @Override",
          "170:             public void accept(String logDir, IOException e) {",
          "171:                 MetaPropertiesEnsemble.LOG.error(\"Error while writing meta.properties to {}\", logDir, e);",
          "172:             }",
          "173:         };",
          "175:         private final MetaPropertiesEnsemble prev;",
          "176:         private Random random = new Random();",
          "177:         private Set<String> emptyLogDirs;",
          "178:         private Set<String> errorLogDirs;",
          "179:         private Map<String, MetaProperties> logDirProps;",
          "180:         private Optional<String> metaLogDir;",
          "182:         private PreWriteHandler preWriteHandler = (logDir, isNew, metaProperties) -> {",
          "183:             LOG.info(\"Writing out {} {}{}meta.properties file containing {}\",",
          "184:                     isNew ? \"new\" : \"changed\",",
          "185:                     logDir,",
          "186:                     File.separator,",
          "187:                     metaProperties);",
          "188:         };",
          "190:         private WriteErrorHandler writeErrorHandler = (logDir, e) -> {",
          "191:             LOG.error(\"Error while writing meta.properties to {}\", logDir, e);",
          "192:             throw e;",
          "193:         };",
          "195:         public Copier(MetaPropertiesEnsemble prev) {",
          "196:             this.prev = prev;",
          "197:             this.emptyLogDirs = new HashSet<>(prev.emptyLogDirs());",
          "198:             this.errorLogDirs = new HashSet<>(prev.errorLogDirs());",
          "199:             this.logDirProps = new HashMap<>(prev.logDirProps());",
          "200:             this.metaLogDir = prev.metadataLogDir;",
          "201:         }",
          "209:         public Copier setRandom(Random random) {",
          "210:             this.random = random;",
          "211:             return this;",
          "212:         }",
          "219:         public Set<String> emptyLogDirs() {",
          "220:             return emptyLogDirs;",
          "221:         }",
          "228:         public Set<String> errorLogDirs() {",
          "229:             return errorLogDirs;",
          "230:         }",
          "237:         public Map<String, MetaProperties> logDirProps() {",
          "238:             return logDirProps;",
          "239:         }",
          "249:         public Copier setLogDirProps(String logDir, MetaProperties metaProps) {",
          "250:             emptyLogDirs.remove(logDir);",
          "251:             errorLogDirs.remove(logDir);",
          "252:             logDirProps.put(logDir, metaProps);",
          "253:             return this;",
          "254:         }",
          "256:         public Optional<String> metaLogDir() {",
          "257:             return metaLogDir;",
          "258:         }",
          "267:         public Copier setMetaLogDir(Optional<String> metaLogDir) {",
          "268:             this.metaLogDir = metaLogDir;",
          "269:             return this;",
          "270:         }",
          "277:         public Uuid generateValidDirectoryId() {",
          "278:             while (true) {",
          "279:                 Uuid uuid = new Uuid(random.nextLong(), random.nextLong());",
          "280:                 if (!(uuid.toString().startsWith(\"-\") || DirectoryId.reserved(uuid))) {",
          "281:                     boolean duplicate = false;",
          "282:                     for (MetaProperties metaProps : logDirProps.values()) {",
          "283:                         if (metaProps.directoryId().equals(Optional.of(uuid))) {",
          "284:                             duplicate = true;",
          "285:                             break;",
          "286:                         }",
          "287:                     }",
          "288:                     if (!duplicate) {",
          "289:                         return uuid;",
          "290:                     }",
          "291:                 }",
          "292:             }",
          "293:         }",
          "301:         public Copier setPreWriteHandler(PreWriteHandler preWriteHandler) {",
          "302:             this.preWriteHandler = preWriteHandler;",
          "303:             return this;",
          "304:         }",
          "312:         public Copier setWriteErrorHandler(WriteErrorHandler writeErrorHandler) {",
          "313:             this.writeErrorHandler = writeErrorHandler;",
          "314:             return this;",
          "315:         }",
          "322:         public void verify() {",
          "323:             for (String logDir : emptyLogDirs) {",
          "324:                 if (errorLogDirs.contains(logDir)) {",
          "325:                     throw new RuntimeException(\"Error: log directory \" + logDir +",
          "326:                         \" is in both emptyLogDirs and errorLogDirs.\");",
          "327:                 }",
          "328:                 if (logDirProps.containsKey(logDir)) {",
          "329:                     throw new RuntimeException(\"Error: log directory \" + logDir +",
          "330:                         \" is in both emptyLogDirs and logDirProps.\");",
          "331:                 }",
          "332:             }",
          "333:             for (String logDir : errorLogDirs) {",
          "334:                 if (logDirProps.containsKey(logDir)) {",
          "335:                     throw new RuntimeException(\"Error: log directory \" + logDir +",
          "336:                             \" is in both errorLogDirs and logDirProps.\");",
          "337:                 }",
          "338:             }",
          "339:             metaLogDir().ifPresent(m -> {",
          "340:                 if (!(emptyLogDirs.contains(m) ||",
          "341:                         logDirProps.containsKey(m) ||",
          "342:                         errorLogDirs.contains(m))) {",
          "343:                     throw new RuntimeException(\"Error: metaLogDir \" + m + \" does not appear \" +",
          "344:                         \"in emptyLogDirs, errorLogDirs, or logDirProps.\");",
          "345:                 }",
          "346:             });",
          "347:         }",
          "352:         public void writeLogDirChanges() throws IOException {",
          "353:             Map<String, MetaProperties> newOrChanged = new HashMap<>();",
          "354:             HashSet<String> newSet = new HashSet<>();",
          "355:             for (Entry<String, MetaProperties> entry : prev.logDirProps().entrySet()) {",
          "356:                 MetaProperties prevMetaProps = entry.getValue();",
          "357:                 MetaProperties metaProps = logDirProps.get(entry.getKey());",
          "358:                 if (!prevMetaProps.equals(metaProps)) {",
          "359:                     newOrChanged.put(entry.getKey(), metaProps);",
          "360:                 }",
          "361:             }",
          "362:             for (Entry<String, MetaProperties> entry : logDirProps.entrySet()) {",
          "363:                 if (!prev.logDirProps().containsKey(entry.getKey())) {",
          "364:                     newOrChanged.put(entry.getKey(), entry.getValue());",
          "365:                     newSet.add(entry.getKey());",
          "366:                 }",
          "367:             }",
          "368:             for (Entry<String, MetaProperties> entry : newOrChanged.entrySet()) {",
          "369:                 String logDir = entry.getKey();",
          "370:                 MetaProperties metaProps = entry.getValue();",
          "371:                 String metaPropsPath = new File(logDir, META_PROPERTIES_NAME).getAbsolutePath();",
          "372:                 try {",
          "373:                     preWriteHandler.handle(logDir, newSet.contains(logDir), metaProps);",
          "374:                     PropertiesUtils.writePropertiesFile(metaProps.toProperties(),",
          "375:                         metaPropsPath, true);",
          "376:                 } catch (IOException e) {",
          "377:                     errorLogDirs.add(logDir);",
          "378:                     logDirProps.remove(logDir);",
          "379:                     writeErrorHandler.handle(logDir, e);",
          "380:                 }",
          "381:             }",
          "382:         }",
          "389:         public MetaPropertiesEnsemble copy() {",
          "390:             return new MetaPropertiesEnsemble(emptyLogDirs,",
          "391:                 errorLogDirs,",
          "392:                 logDirProps,",
          "393:                 metaLogDir);",
          "394:         }",
          "395:     }",
          "397:     MetaPropertiesEnsemble(",
          "398:         Set<String> emptyLogDirs,",
          "399:         Set<String> errorLogDirs,",
          "400:         Map<String, MetaProperties> logDirProps,",
          "401:         Optional<String> metadataLogDir",
          "402:     ) {",
          "403:         this.emptyLogDirs = Collections.unmodifiableSet(new TreeSet<>(emptyLogDirs));",
          "404:         this.errorLogDirs = Collections.unmodifiableSet(new TreeSet<>(errorLogDirs));",
          "405:         this.logDirProps = Collections.unmodifiableMap(new TreeMap<>(logDirProps));",
          "406:         this.metadataLogDir = metadataLogDir;",
          "407:     }",
          "412:     public Set<String> emptyLogDirs() {",
          "413:         return emptyLogDirs;",
          "414:     }",
          "419:     public Set<String> errorLogDirs() {",
          "420:         return errorLogDirs;",
          "421:     }",
          "426:     public Map<String, MetaProperties> logDirProps() {",
          "427:         return logDirProps;",
          "428:     }",
          "433:     public Iterator<Entry<String, Optional<MetaProperties>>> nonFailedDirectoryProps() {",
          "434:         return new Iterator<Entry<String, Optional<MetaProperties>>>() {",
          "435:             private Iterator<String> emptyLogDirsIterator = emptyLogDirs.iterator();",
          "436:             private Iterator<Entry<String, MetaProperties>> logDirsIterator =",
          "437:                     logDirProps.entrySet().iterator();",
          "439:             @Override",
          "440:             public boolean hasNext() {",
          "441:                 return emptyLogDirsIterator.hasNext() || logDirsIterator.hasNext();",
          "442:             }",
          "444:             @Override",
          "445:             public Entry<String, Optional<MetaProperties>> next() {",
          "446:                 if (emptyLogDirsIterator.hasNext()) {",
          "447:                     return new SimpleImmutableEntry<>(emptyLogDirsIterator.next(), Optional.empty());",
          "448:                 }",
          "449:                 Entry<String, MetaProperties> entry = logDirsIterator.next();",
          "450:                 return new SimpleImmutableEntry<>(entry.getKey(), Optional.of(entry.getValue()));",
          "451:             }",
          "452:         };",
          "453:     }",
          "458:     public Optional<String> metadataLogDir() {",
          "459:         return metadataLogDir;",
          "460:     }",
          "462:     public enum VerificationFlag {",
          "463:         REQUIRE_V0,",
          "464:         REQUIRE_METADATA_LOG_DIR,",
          "465:         REQUIRE_AT_LEAST_ONE_VALID",
          "466:     }",
          "485:     public void verify(",
          "486:         Optional<String> expectedClusterId,",
          "487:         OptionalInt expectedNodeId,",
          "488:         EnumSet<VerificationFlag> verificationFlags",
          "489:     ) {",
          "490:         Map<Uuid, String> seenUuids = new HashMap<>();",
          "491:         if (verificationFlags.contains(VerificationFlag.REQUIRE_AT_LEAST_ONE_VALID)) {",
          "492:             if (logDirProps.isEmpty()) {",
          "493:                 throw new RuntimeException(\"No readable meta.properties files found.\");",
          "494:             }",
          "495:         }",
          "496:         for (Entry<String, MetaProperties> entry : logDirProps.entrySet()) {",
          "497:             String logDir = entry.getKey();",
          "498:             String path = new File(logDir, META_PROPERTIES_NAME).toString();",
          "499:             MetaProperties metaProps = entry.getValue();",
          "500:             if (verificationFlags.contains(VerificationFlag.REQUIRE_V0)) {",
          "501:                 if (!metaProps.version().equals(MetaPropertiesVersion.V0)) {",
          "502:                     throw new RuntimeException(\"Found unexpected version in \" + path + \". \" +",
          "503:                         \"ZK-based brokers that are not migrating only support version 0 \" +",
          "504:                         \"(which is implicit when the `version` field is missing).\");",
          "505:                 }",
          "506:             }",
          "507:             if (!metaProps.clusterId().isPresent()) {",
          "508:                 if (metaProps.version().alwaysHasClusterId()) {",
          "509:                     throw new RuntimeException(\"cluster.id was not specified in the v1 file: \" +",
          "510:                         path);",
          "511:                 }",
          "512:             } else if (!expectedClusterId.isPresent()) {",
          "513:                 expectedClusterId = metaProps.clusterId();",
          "514:             } else if (!metaProps.clusterId().get().equals(expectedClusterId.get())) {",
          "515:                 throw new RuntimeException(\"Invalid cluster.id in: \" + path + \". Expected \" +",
          "516:                     expectedClusterId.get() + \", but read \" + metaProps.clusterId().get());",
          "517:             }",
          "518:             if (!metaProps.nodeId().isPresent()) {",
          "519:                 if (metaProps.version().alwaysHasNodeId()) {",
          "520:                     throw new RuntimeException(\"node.id was not specified in \" + path);",
          "521:                 }",
          "522:             } else if (!expectedNodeId.isPresent()) {",
          "523:                 expectedNodeId = metaProps.nodeId();",
          "524:             } else if (metaProps.nodeId().getAsInt() != expectedNodeId.getAsInt()) {",
          "525:                 throw new RuntimeException(\"Stored node id \" + metaProps.nodeId().getAsInt() +",
          "526:                     \" doesn't match previous node id \" + expectedNodeId.getAsInt() + \" in \" + path +",
          "527:                     \". If you moved your data, make sure your configured node id matches. If you \" +",
          "528:                     \"intend to create a new node, you should remove all data in your data \" +",
          "529:                     \"directories.\");",
          "530:             }",
          "531:             if (metaProps.directoryId().isPresent()) {",
          "532:                 if (DirectoryId.reserved(metaProps.directoryId().get())) {",
          "533:                     throw new RuntimeException(\"Invalid resrved directory ID \" +",
          "534:                         metaProps.directoryId().get() + \" found in \" + logDir);",
          "535:                 }",
          "536:                 String prevLogDir = seenUuids.put(metaProps.directoryId().get(), logDir);",
          "537:                 if (prevLogDir != null) {",
          "538:                     throw new RuntimeException(\"Duplicate directory ID \" + metaProps.directoryId() +",
          "539:                         \" found. It was the ID of \" + prevLogDir + \", \" + \"but also of \" +",
          "540:                         logDir);",
          "541:                 }",
          "542:             }",
          "543:         }",
          "544:         if (verificationFlags.contains(VerificationFlag.REQUIRE_METADATA_LOG_DIR)) {",
          "545:             if (!metadataLogDir.isPresent()) {",
          "546:                 throw new RuntimeException(\"No metadata log directory was specified.\");",
          "547:             }",
          "548:         }",
          "549:         if (metadataLogDir.isPresent()) {",
          "550:             if (errorLogDirs.contains(metadataLogDir.get())) {",
          "551:                 throw new RuntimeException(\"Encountered I/O error in metadata log directory \" +",
          "552:                         metadataLogDir.get() + \". Cannot continue.\");",
          "553:             }",
          "554:         }",
          "555:     }",
          "562:     public OptionalInt nodeId() {",
          "563:         for (MetaProperties metaProps : logDirProps.values()) {",
          "564:             if (metaProps.nodeId().isPresent()) {",
          "565:                 return metaProps.nodeId();",
          "566:             }",
          "567:         }",
          "568:         return OptionalInt.empty();",
          "569:     }",
          "576:     public Optional<String> clusterId() {",
          "577:         for (MetaProperties metaProps : logDirProps.values()) {",
          "578:             if (metaProps.clusterId().isPresent()) {",
          "579:                 return metaProps.clusterId();",
          "580:             }",
          "581:         }",
          "582:         return Optional.empty();",
          "583:     }",
          "585:     @Override",
          "586:     public boolean equals(Object o) {",
          "587:         if (o == null || (!(o.getClass().equals(MetaPropertiesEnsemble.class)))) {",
          "588:             return false;",
          "589:         }",
          "590:         MetaPropertiesEnsemble other = (MetaPropertiesEnsemble) o;",
          "591:         return emptyLogDirs.equals(other.emptyLogDirs) &&",
          "592:             errorLogDirs.equals(other.errorLogDirs) &&",
          "593:             logDirProps.equals(other.logDirProps) &&",
          "594:             metadataLogDir.equals(other.metadataLogDir);",
          "595:     }",
          "597:     @Override",
          "598:     public int hashCode() {",
          "599:         return Objects.hash(emptyLogDirs,",
          "600:             errorLogDirs,",
          "601:             logDirProps,",
          "602:             metadataLogDir);",
          "603:     }",
          "605:     @Override",
          "606:     public String toString() {",
          "607:         TreeMap<String, String> outputMap = new TreeMap<>();",
          "608:         emptyLogDirs.forEach(e -> outputMap.put(e, \"EMPTY\"));",
          "609:         errorLogDirs.forEach(e -> outputMap.put(e, \"ERROR\"));",
          "610:         logDirProps.entrySet().forEach(",
          "611:             e -> outputMap.put(e.getKey(), e.getValue().toString()));",
          "612:         return \"MetaPropertiesEnsemble\" +",
          "613:             \"(metadataLogDir=\" + metadataLogDir +",
          "614:             \", dirs={\" + outputMap.entrySet().stream().",
          "615:             map(e -> e.getKey() + \": \" + e.getValue()).",
          "616:             collect(Collectors.joining(\", \")) +",
          "617:             \"})\";",
          "618:     }",
          "619: }",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/properties/MetaPropertiesVersion.java||metadata/src/main/java/org/apache/kafka/metadata/properties/MetaPropertiesVersion.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/properties/MetaPropertiesVersion.java -> metadata/src/main/java/org/apache/kafka/metadata/properties/MetaPropertiesVersion.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.metadata.properties;",
          "23: public enum MetaPropertiesVersion {",
          "28:     V0(0),",
          "34:     V1(1);",
          "36:     private final int number;",
          "38:     public static MetaPropertiesVersion fromNumberString(String numberString) {",
          "39:         int number;",
          "40:         try {",
          "41:             number = Integer.parseInt(numberString.trim());",
          "42:         } catch (NumberFormatException  e) {",
          "43:             throw new RuntimeException(\"Invalid meta.properties version string '\" +",
          "44:                     numberString + \"'\");",
          "45:         }",
          "46:         return fromNumber(number);",
          "47:     }",
          "49:     public static MetaPropertiesVersion fromNumber(int number) {",
          "50:         switch (number) {",
          "51:             case 0: return V0;",
          "52:             case 1: return V1;",
          "53:             default: throw new RuntimeException(\"Unknown meta.properties version number \" + number);",
          "54:         }",
          "55:     }",
          "57:     MetaPropertiesVersion(int number) {",
          "58:         this.number = number;",
          "59:     }",
          "61:     public int number() {",
          "62:         return number;",
          "63:     }",
          "65:     public String numberString() {",
          "66:         return Integer.toString(number);",
          "67:     }",
          "69:     public boolean hasBrokerId() {",
          "70:         return this == V0;",
          "71:     }",
          "73:     public boolean alwaysHasNodeId() {",
          "74:         return this != V0;",
          "75:     }",
          "77:     public boolean alwaysHasClusterId() {",
          "78:         return this != V0;",
          "79:     }",
          "80: }",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/properties/PropertiesUtils.java||metadata/src/main/java/org/apache/kafka/metadata/properties/PropertiesUtils.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/properties/PropertiesUtils.java -> metadata/src/main/java/org/apache/kafka/metadata/properties/PropertiesUtils.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.metadata.properties;",
          "20: import org.apache.kafka.common.utils.Utils;",
          "22: import java.io.File;",
          "23: import java.io.FileOutputStream;",
          "24: import java.io.IOException;",
          "25: import java.io.InputStream;",
          "26: import java.io.OutputStreamWriter;",
          "27: import java.io.PrintWriter;",
          "28: import java.nio.charset.StandardCharsets;",
          "29: import java.nio.file.Files;",
          "30: import java.nio.file.Paths;",
          "31: import java.util.Properties;",
          "33: public final class PropertiesUtils {",
          "41:     public static void writePropertiesFile(",
          "42:         Properties props,",
          "43:         String path,",
          "44:         boolean fsync",
          "45:     ) throws IOException {",
          "46:         File tempFile = new File(path + \".tmp\");",
          "47:         try (",
          "48:             FileOutputStream fos = new FileOutputStream(tempFile, false);",
          "49:             OutputStreamWriter osw = new OutputStreamWriter(fos, StandardCharsets.UTF_8);",
          "50:             PrintWriter pw = new PrintWriter(osw)",
          "51:         ) {",
          "52:             props.store(pw, \"\");",
          "53:             fos.flush();",
          "54:             if (fsync) {",
          "55:                 fos.getFD().sync();",
          "56:             }",
          "57:         }",
          "58:         File targetFile = new File(path);",
          "59:         try {",
          "60:             Utils.atomicMoveWithFallback(tempFile.toPath(), targetFile.toPath(), fsync);",
          "61:         } catch (Throwable e) {",
          "62:             Utils.delete(tempFile);",
          "63:             throw e;",
          "64:         }",
          "65:     }",
          "75:     public static Properties readPropertiesFile(String path) throws IOException {",
          "76:         Properties props = new Properties();",
          "77:         try (InputStream propStream = Files.newInputStream(Paths.get(path))) {",
          "78:             props.load(propStream);",
          "79:         }",
          "80:         return props;",
          "81:     }",
          "91:     static int loadRequiredIntProp(",
          "92:         Properties props,",
          "93:         String keyName",
          "94:     ) {",
          "95:         String value = props.getProperty(keyName);",
          "96:         if (value == null) {",
          "97:             throw new RuntimeException(\"Failed to find \" + keyName);",
          "98:         }",
          "99:         try {",
          "100:             return Integer.parseInt(value);",
          "101:         } catch (NumberFormatException e) {",
          "102:             throw new RuntimeException(\"Unable to read \" + keyName + \" as a base-10 number.\", e);",
          "103:         }",
          "104:     }",
          "105: }",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/metadata/properties/MetaPropertiesEnsembleTest.java||metadata/src/test/java/org/apache/kafka/metadata/properties/MetaPropertiesEnsembleTest.java": [
          "File: metadata/src/test/java/org/apache/kafka/metadata/properties/MetaPropertiesEnsembleTest.java -> metadata/src/test/java/org/apache/kafka/metadata/properties/MetaPropertiesEnsembleTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.metadata.properties;",
          "20: import java.io.File;",
          "21: import java.io.IOException;",
          "22: import java.nio.file.Files;",
          "23: import java.util.AbstractMap.SimpleImmutableEntry;",
          "24: import java.util.Arrays;",
          "25: import java.util.Collections;",
          "26: import java.util.EnumSet;",
          "27: import java.util.HashMap;",
          "28: import java.util.HashSet;",
          "29: import java.util.List;",
          "30: import java.util.Map;",
          "31: import java.util.Map.Entry;",
          "32: import java.util.Optional;",
          "33: import java.util.OptionalInt;",
          "34: import java.util.Random;",
          "35: import java.util.concurrent.atomic.AtomicInteger;",
          "36: import java.util.stream.Collectors;",
          "38: import org.apache.kafka.common.Uuid;",
          "39: import org.apache.kafka.test.TestUtils;",
          "40: import org.junit.jupiter.api.Test;",
          "42: import static org.apache.kafka.metadata.properties.MetaPropertiesEnsemble.EMPTY;",
          "43: import static org.apache.kafka.metadata.properties.MetaPropertiesEnsemble.META_PROPERTIES_NAME;",
          "44: import static org.apache.kafka.metadata.properties.MetaPropertiesEnsemble.VerificationFlag.REQUIRE_AT_LEAST_ONE_VALID;",
          "45: import static org.apache.kafka.metadata.properties.MetaPropertiesEnsemble.VerificationFlag.REQUIRE_METADATA_LOG_DIR;",
          "46: import static org.apache.kafka.metadata.properties.MetaPropertiesEnsemble.VerificationFlag.REQUIRE_V0;",
          "47: import static org.junit.jupiter.api.Assertions.assertEquals;",
          "48: import static org.junit.jupiter.api.Assertions.assertFalse;",
          "49: import static org.junit.jupiter.api.Assertions.assertNull;",
          "50: import static org.junit.jupiter.api.Assertions.assertThrows;",
          "52: final public class MetaPropertiesEnsembleTest {",
          "53:     private static final MetaPropertiesEnsemble FOO =",
          "54:         new MetaPropertiesEnsemble(",
          "55:             new HashSet<>(Arrays.asList(\"/tmp/empty1\", \"/tmp/empty2\")),",
          "56:             new HashSet<>(Arrays.asList(\"/tmp/error3\")),",
          "57:             Arrays.asList(",
          "58:                 new SimpleImmutableEntry<>(\"/tmp/dir4\",",
          "59:                     new MetaProperties.Builder().",
          "60:                         setVersion(MetaPropertiesVersion.V1).",
          "61:                         setClusterId(\"fooClusterId\").",
          "62:                         setNodeId(2).",
          "63:                         build()),",
          "64:                 new SimpleImmutableEntry<>(\"/tmp/dir5\",",
          "65:                     new MetaProperties.Builder().",
          "66:                         setVersion(MetaPropertiesVersion.V1).",
          "67:                         setClusterId(\"fooClusterId\").",
          "68:                         setNodeId(2).",
          "69:                         build())).stream().collect(Collectors.",
          "70:                             toMap(Entry::getKey, Entry::getValue)),",
          "71:                 Optional.of(\"/tmp/dir4\"));",
          "73:     private static String createLogDir(MetaProperties metaProps) throws IOException {",
          "74:         File logDir = TestUtils.tempDirectory();",
          "75:         PropertiesUtils.writePropertiesFile(metaProps.toProperties(),",
          "76:             new File(logDir, META_PROPERTIES_NAME).getAbsolutePath(), false);",
          "77:         return logDir.getAbsolutePath();",
          "78:     }",
          "80:     private static String createEmptyLogDir() throws IOException {",
          "81:         File logDir = TestUtils.tempDirectory();",
          "82:         return logDir.getAbsolutePath();",
          "83:     }",
          "85:     private static String createErrorLogDir() throws IOException {",
          "86:         File logDir = TestUtils.tempDirectory();",
          "87:         File metaPath = new File(logDir, META_PROPERTIES_NAME);",
          "88:         Files.write(metaPath.toPath(), new byte[] {(byte) 0});",
          "89:         metaPath.setReadable(false);",
          "90:         return logDir.getAbsolutePath();",
          "91:     }",
          "93:     @Test",
          "94:     public void testEmptyLogDirsForFoo() {",
          "95:         assertEquals(new HashSet<>(Arrays.asList(\"/tmp/empty1\", \"/tmp/empty2\")),",
          "96:             FOO.emptyLogDirs());",
          "97:     }",
          "99:     @Test",
          "100:     public void testEmptyLogDirsForEmpty() {",
          "101:         assertEquals(new HashSet<>(), EMPTY.emptyLogDirs());",
          "102:     }",
          "104:     @Test",
          "105:     public void testErrorLogDirsForFoo() {",
          "106:         assertEquals(new HashSet<>(Arrays.asList(\"/tmp/error3\")), FOO.errorLogDirs());",
          "107:     }",
          "109:     @Test",
          "110:     public void testErrorLogDirsForEmpty() {",
          "111:         assertEquals(new HashSet<>(), EMPTY.errorLogDirs());",
          "112:     }",
          "114:     @Test",
          "115:     public void testLogDirPropsForFoo() {",
          "116:         assertEquals(new HashSet<>(Arrays.asList(\"/tmp/dir4\", \"/tmp/dir5\")),",
          "117:             FOO.logDirProps().keySet());",
          "118:     }",
          "120:     @Test",
          "121:     public void testLogDirPropsForEmpty() {",
          "122:         assertEquals(new HashSet<>(),",
          "123:             EMPTY.logDirProps().keySet());",
          "124:     }",
          "126:     @Test",
          "127:     public void testNonFailedDirectoryPropsForFoo() {",
          "128:         Map<String, Optional<MetaProperties>> results = new HashMap<>();",
          "129:         FOO.nonFailedDirectoryProps().forEachRemaining(entry -> {",
          "130:             results.put(entry.getKey(), entry.getValue());",
          "131:         });",
          "132:         assertEquals(Optional.empty(), results.get(\"/tmp/empty1\"));",
          "133:         assertEquals(Optional.empty(), results.get(\"/tmp/empty2\"));",
          "134:         assertNull(results.get(\"/tmp/error3\"));",
          "135:         assertEquals(Optional.of(new MetaProperties.Builder().",
          "136:             setVersion(MetaPropertiesVersion.V1).",
          "137:             setClusterId(\"fooClusterId\").",
          "138:             setNodeId(2).",
          "139:             build()), results.get(\"/tmp/dir4\"));",
          "140:         assertEquals(Optional.of(new MetaProperties.Builder().",
          "141:             setVersion(MetaPropertiesVersion.V1).",
          "142:             setClusterId(\"fooClusterId\").",
          "143:             setNodeId(2).",
          "144:             build()), results.get(\"/tmp/dir5\"));",
          "145:         assertEquals(4, results.size());",
          "146:     }",
          "148:     @Test",
          "149:     public void testNonFailedDirectoryPropsForEmpty() {",
          "150:         assertFalse(EMPTY.nonFailedDirectoryProps().hasNext());",
          "151:     }",
          "153:     @Test",
          "154:     public void testMetadataLogDirForFoo() {",
          "155:         assertEquals(Optional.of(\"/tmp/dir4\"), FOO.metadataLogDir());",
          "156:     }",
          "158:     @Test",
          "159:     public void testMetadataLogDirForEmpty() {",
          "160:         assertEquals(Optional.empty(), EMPTY.metadataLogDir());",
          "161:     }",
          "163:     @Test",
          "164:     public void testNodeIdForFoo() {",
          "165:         assertEquals(OptionalInt.of(2), FOO.nodeId());",
          "166:     }",
          "168:     @Test",
          "169:     public void testNodeIdForEmpty() {",
          "170:         assertEquals(OptionalInt.empty(), EMPTY.nodeId());",
          "171:     }",
          "173:     @Test",
          "174:     public void testClusterIdForFoo() {",
          "175:         assertEquals(Optional.of(\"fooClusterId\"), FOO.clusterId());",
          "176:     }",
          "178:     @Test",
          "179:     public void testClusterIdForEmpty() {",
          "180:         assertEquals(Optional.empty(), EMPTY.clusterId());",
          "181:     }",
          "183:     @Test",
          "184:     public void testSuccessfulVerification() {",
          "185:         FOO.verify(Optional.empty(),",
          "186:             OptionalInt.empty(),",
          "187:             EnumSet.of(REQUIRE_AT_LEAST_ONE_VALID, REQUIRE_METADATA_LOG_DIR));",
          "188:     }",
          "190:     @Test",
          "191:     public void testSuccessfulVerificationWithClusterId() {",
          "192:         FOO.verify(Optional.of(\"fooClusterId\"),",
          "193:             OptionalInt.empty(),",
          "194:             EnumSet.of(REQUIRE_AT_LEAST_ONE_VALID, REQUIRE_METADATA_LOG_DIR));",
          "195:     }",
          "197:     @Test",
          "198:     public void testSuccessfulVerificationWithClusterIdAndNodeId() {",
          "199:         FOO.verify(Optional.of(\"fooClusterId\"),",
          "200:             OptionalInt.of(2),",
          "201:             EnumSet.of(REQUIRE_AT_LEAST_ONE_VALID, REQUIRE_METADATA_LOG_DIR));",
          "202:     }",
          "204:     @Test",
          "205:     public void testVerificationFailureOnRequireV0() {",
          "206:         assertEquals(\"Found unexpected version in /tmp/dir4/meta.properties. ZK-based brokers \" +",
          "207:             \"that are not migrating only support version 0 (which is implicit when the \" +",
          "208:             \"`version` field is missing).\",",
          "209:                 assertThrows(RuntimeException.class, () ->",
          "210:                     FOO.verify(Optional.empty(), OptionalInt.empty(), EnumSet.of(REQUIRE_V0))).",
          "211:                         getMessage());",
          "212:     }",
          "214:     @Test",
          "215:     public void testVerificationFailureOnRequireAtLeastOneValid() {",
          "216:         assertEquals(\"No readable meta.properties files found.\",",
          "217:             assertThrows(RuntimeException.class,",
          "218:                 () -> EMPTY.verify(Optional.empty(),",
          "219:                     OptionalInt.empty(),",
          "220:                     EnumSet.of(REQUIRE_AT_LEAST_ONE_VALID))).",
          "221:                         getMessage());",
          "222:     }",
          "224:     @Test",
          "225:     public void testVerificationFailureOnLackOfMetadataLogDir() throws IOException {",
          "226:         MetaPropertiesEnsemble ensemble = new MetaPropertiesEnsemble(",
          "227:             Collections.singleton(\"/tmp/foo1\"),",
          "228:             Collections.emptySet(),",
          "229:             Collections.emptyMap(),",
          "230:             Optional.empty());",
          "231:         assertEquals(\"No metadata log directory was specified.\",",
          "232:             assertThrows(RuntimeException.class,",
          "233:                 () -> ensemble.verify(Optional.empty(),",
          "234:                     OptionalInt.empty(),",
          "235:                     EnumSet.of(REQUIRE_METADATA_LOG_DIR))).",
          "236:                         getMessage());",
          "237:     }",
          "239:     @Test",
          "240:     public void testVerificationFailureOnMetadataLogDirWithError() throws IOException {",
          "241:         MetaPropertiesEnsemble ensemble = new MetaPropertiesEnsemble(",
          "242:             Collections.emptySet(),",
          "243:             Collections.singleton(\"/tmp/foo1\"),",
          "244:             Collections.emptyMap(),",
          "245:             Optional.of(\"/tmp/foo1\"));",
          "246:         assertEquals(\"Encountered I/O error in metadata log directory /tmp/foo1. Cannot continue.\",",
          "247:             assertThrows(RuntimeException.class,",
          "248:                 () -> ensemble.verify(Optional.empty(),",
          "249:                     OptionalInt.empty(),",
          "250:                     EnumSet.of(REQUIRE_METADATA_LOG_DIR))).",
          "251:                         getMessage());",
          "252:     }",
          "254:     @Test",
          "255:     public void testMetaPropertiesEnsembleLoad() throws IOException {",
          "256:         MetaPropertiesEnsemble.Loader loader = new MetaPropertiesEnsemble.Loader();",
          "257:         MetaProperties metaProps = new MetaProperties.Builder().",
          "258:             setVersion(MetaPropertiesVersion.V1).",
          "259:             setClusterId(\"AtgGav8yQjiaJ3rTXE7VCA\").",
          "260:             setNodeId(1).",
          "261:             build();",
          "262:         loader.addMetadataLogDir(createLogDir(metaProps));",
          "263:         MetaPropertiesEnsemble metaPropertiesEnsemble = loader.load();",
          "264:         metaPropertiesEnsemble.verify(Optional.of(\"AtgGav8yQjiaJ3rTXE7VCA\"),",
          "265:             OptionalInt.of(1),",
          "266:             EnumSet.of(REQUIRE_METADATA_LOG_DIR, REQUIRE_AT_LEAST_ONE_VALID));",
          "267:         assertEquals(1, metaPropertiesEnsemble.logDirProps().values().size());",
          "268:         assertEquals(metaProps, metaPropertiesEnsemble.logDirProps().values().iterator().next());",
          "269:     }",
          "271:     @Test",
          "272:     public void testMetaPropertiesEnsembleLoadEmpty() throws IOException {",
          "273:         MetaPropertiesEnsemble.Loader loader = new MetaPropertiesEnsemble.Loader();",
          "274:         loader.addMetadataLogDir(createEmptyLogDir());",
          "275:         MetaPropertiesEnsemble metaPropertiesEnsemble = loader.load();",
          "276:         metaPropertiesEnsemble.verify(Optional.of(\"AtgGav8yQjiaJ3rTXE7VCA\"),",
          "277:             OptionalInt.of(1),",
          "278:             EnumSet.of(REQUIRE_METADATA_LOG_DIR));",
          "279:         assertEquals(1, metaPropertiesEnsemble.emptyLogDirs().size());",
          "280:     }",
          "282:     @Test",
          "283:     public void testMetaPropertiesEnsembleLoadError() throws IOException {",
          "284:         MetaPropertiesEnsemble.Loader loader = new MetaPropertiesEnsemble.Loader();",
          "285:         loader.addMetadataLogDir(createErrorLogDir());",
          "286:         loader.addLogDir(createLogDir(new MetaProperties.Builder().",
          "287:             setVersion(MetaPropertiesVersion.V1).",
          "288:             setClusterId(\"AtgGav8yQjiaJ3rTXE7VCA\").",
          "289:             setNodeId(1).",
          "290:             build()));",
          "291:         MetaPropertiesEnsemble metaPropertiesEnsemble = loader.load();",
          "292:         assertEquals(1, metaPropertiesEnsemble.errorLogDirs().size());",
          "293:         assertEquals(1, metaPropertiesEnsemble.logDirProps().size());",
          "294:     }",
          "296:     static private void verifyCopy(",
          "297:         MetaPropertiesEnsemble expected,",
          "298:         MetaPropertiesEnsemble.Copier copier",
          "299:     ) {",
          "300:         copier.verify();",
          "301:         MetaPropertiesEnsemble foo2 = copier.copy();",
          "302:         assertEquals(expected, foo2);",
          "303:         assertEquals(expected.hashCode(), foo2.hashCode());",
          "304:         assertEquals(expected.toString(), foo2.toString());",
          "305:     }",
          "307:     @Test",
          "308:     public void testCopierWithoutModifications() {",
          "309:         verifyCopy(FOO, new MetaPropertiesEnsemble.Copier(FOO));",
          "310:     }",
          "312:     @Test",
          "313:     public void testCopyFooItemByItem() {",
          "314:         MetaPropertiesEnsemble.Copier copier = new MetaPropertiesEnsemble.Copier(EMPTY);",
          "315:         copier.setMetaLogDir(FOO.metadataLogDir());",
          "316:         FOO.emptyLogDirs().forEach(e -> copier.emptyLogDirs().add(e));",
          "317:         FOO.logDirProps().entrySet().",
          "318:             forEach(e -> copier.logDirProps().put(e.getKey(), e.getValue()));",
          "319:         FOO.errorLogDirs().forEach(e -> copier.errorLogDirs().add(e));",
          "320:         verifyCopy(FOO, copier);",
          "321:     }",
          "323:     static class MetaPropertiesMockRandom extends Random {",
          "324:         private final AtomicInteger index = new AtomicInteger(0);",
          "326:         private List<Long> results = Arrays.asList(",
          "327:             0L,",
          "328:             0L,",
          "329:             2336837413447398698L,",
          "330:             1758400403264101670L,",
          "331:             4341931186263415792L,",
          "332:             6389410885970711333L,",
          "333:             7265008559332826740L,",
          "334:             3478747443029687715L",
          "335:         );",
          "337:         @Override",
          "338:         public long nextLong() {",
          "339:             int curIndex = index.getAndIncrement();",
          "340:             return results.get(curIndex % results.size());",
          "341:         }",
          "342:     }",
          "344:     @Test",
          "345:     public void testCopierGenerateValidDirectoryId() {",
          "346:         MetaPropertiesMockRandom random = new MetaPropertiesMockRandom();",
          "347:         MetaPropertiesEnsemble.Copier copier = new MetaPropertiesEnsemble.Copier(EMPTY);",
          "348:         copier.setRandom(random);",
          "349:         copier.logDirProps().put(\"/tmp/dir1\",",
          "350:             new MetaProperties.Builder().",
          "351:                 setVersion(MetaPropertiesVersion.V1).",
          "352:                 setClusterId(\"PpYMbsoRQV-589isZzNzEw\").",
          "353:                 setNodeId(0).",
          "354:                 setDirectoryId(new Uuid(2336837413447398698L, 1758400403264101670L)).",
          "355:                 build());",
          "356:         copier.logDirProps().put(\"/tmp/dir2\",",
          "357:             new MetaProperties.Builder().",
          "358:                 setVersion(MetaPropertiesVersion.V1).",
          "359:                 setClusterId(\"PpYMbsoRQV-589isZzNzEw\").",
          "360:                 setNodeId(0).",
          "361:                 setDirectoryId(new Uuid(4341931186263415792L, 6389410885970711333L)).",
          "362:                 build());",
          "365:         assertEquals(new Uuid(7265008559332826740L, 3478747443029687715L),",
          "366:             copier.generateValidDirectoryId());",
          "367:     }",
          "369:     @Test",
          "370:     public void testCopierVerificationFailsOnEmptyAndErrorOverlap() {",
          "371:         MetaPropertiesEnsemble.Copier copier = new MetaPropertiesEnsemble.Copier(EMPTY);",
          "372:         copier.emptyLogDirs().add(\"/tmp/foo\");",
          "373:         copier.errorLogDirs().add(\"/tmp/foo\");",
          "374:         assertEquals(\"Error: log directory /tmp/foo is in both emptyLogDirs and errorLogDirs.\",",
          "375:             assertThrows(RuntimeException.class, () -> copier.verify()).getMessage());",
          "376:     }",
          "378:     @Test",
          "379:     public void testCopierVerificationFailsOnEmptyAndLogDirsOverlap() {",
          "380:         MetaPropertiesEnsemble.Copier copier = new MetaPropertiesEnsemble.Copier(EMPTY);",
          "381:         copier.emptyLogDirs().add(\"/tmp/foo\");",
          "382:         copier.logDirProps().put(\"/tmp/foo\", new MetaProperties.Builder().build());",
          "383:         assertEquals(\"Error: log directory /tmp/foo is in both emptyLogDirs and logDirProps.\",",
          "384:             assertThrows(RuntimeException.class, () -> copier.verify()).getMessage());",
          "385:     }",
          "387:     @Test",
          "388:     public void testCopierVerificationFailsOnErrorAndLogDirsOverlap() {",
          "389:         MetaPropertiesEnsemble.Copier copier = new MetaPropertiesEnsemble.Copier(EMPTY);",
          "390:         copier.errorLogDirs().add(\"/tmp/foo\");",
          "391:         copier.logDirProps().put(\"/tmp/foo\", new MetaProperties.Builder().build());",
          "392:         assertEquals(\"Error: log directory /tmp/foo is in both errorLogDirs and logDirProps.\",",
          "393:             assertThrows(RuntimeException.class, () -> copier.verify()).getMessage());",
          "394:     }",
          "396:     private final static List<MetaProperties> SAMPLE_META_PROPS_LIST = Arrays.asList(",
          "397:         new MetaProperties.Builder().",
          "398:             setVersion(MetaPropertiesVersion.V1).",
          "399:             setClusterId(\"AtgGav8yQjiaJ3rTXE7VCA\").",
          "400:             setNodeId(1).",
          "401:             setDirectoryId(Uuid.fromString(\"s33AdXtkR8Gf_xRO-R_dpA\")).",
          "402:             build(),",
          "403:         new MetaProperties.Builder().",
          "404:             setVersion(MetaPropertiesVersion.V1).",
          "405:             setClusterId(\"AtgGav8yQjiaJ3rTXE7VCA\").",
          "406:             setNodeId(1).",
          "407:             setDirectoryId(Uuid.fromString(\"oTM53yT_SbSfzlvkh_PfVA\")).",
          "408:             build(),",
          "409:         new MetaProperties.Builder().",
          "410:             setVersion(MetaPropertiesVersion.V1).",
          "411:             setClusterId(\"AtgGav8yQjiaJ3rTXE7VCA\").",
          "412:             setNodeId(1).",
          "413:             setDirectoryId(Uuid.fromString(\"FcUhIv2mTzmLqGkVEabyag\")).",
          "414:             build());",
          "416:     @Test",
          "417:     public void testCopierWriteLogDirChanges() throws Exception {",
          "418:         MetaPropertiesEnsemble.Loader loader = new MetaPropertiesEnsemble.Loader();",
          "419:         loader.addMetadataLogDir(createLogDir(SAMPLE_META_PROPS_LIST.get(0)));",
          "420:         MetaPropertiesEnsemble ensemble = loader.load();",
          "421:         MetaPropertiesEnsemble.Copier copier = new MetaPropertiesEnsemble.Copier(ensemble);",
          "422:         String newLogDir1 = createEmptyLogDir();",
          "423:         copier.logDirProps().put(newLogDir1, SAMPLE_META_PROPS_LIST.get(1));",
          "424:         String newLogDir2 = createEmptyLogDir();",
          "425:         copier.logDirProps().put(newLogDir2, SAMPLE_META_PROPS_LIST.get(2));",
          "426:         copier.writeLogDirChanges();",
          "427:         assertEquals(SAMPLE_META_PROPS_LIST.get(1).toProperties(), PropertiesUtils.readPropertiesFile(",
          "428:             new File(newLogDir1, META_PROPERTIES_NAME).getAbsolutePath()));",
          "429:         assertEquals(SAMPLE_META_PROPS_LIST.get(2).toProperties(), PropertiesUtils.readPropertiesFile(",
          "430:             new File(newLogDir2, META_PROPERTIES_NAME).getAbsolutePath()));",
          "431:     }",
          "433:     @Test",
          "434:     public void testCopierWriteChanged() throws Exception {",
          "435:         MetaPropertiesEnsemble.Loader loader = new MetaPropertiesEnsemble.Loader();",
          "436:         String dir0 = createLogDir(SAMPLE_META_PROPS_LIST.get(0));",
          "437:         loader.addMetadataLogDir(dir0);",
          "438:         loader.addLogDir(dir0);",
          "439:         String dir1 = createLogDir(SAMPLE_META_PROPS_LIST.get(1));",
          "440:         loader.addLogDir(dir1);",
          "441:         MetaPropertiesEnsemble ensemble = loader.load();",
          "442:         MetaPropertiesEnsemble.Copier copier = new MetaPropertiesEnsemble.Copier(ensemble);",
          "443:         copier.setLogDirProps(dir0, SAMPLE_META_PROPS_LIST.get(2));",
          "444:         copier.writeLogDirChanges();",
          "445:         assertEquals(SAMPLE_META_PROPS_LIST.get(2).toProperties(), PropertiesUtils.readPropertiesFile(",
          "446:                 new File(dir0, META_PROPERTIES_NAME).getAbsolutePath()));",
          "447:         assertEquals(SAMPLE_META_PROPS_LIST.get(1).toProperties(), PropertiesUtils.readPropertiesFile(",
          "448:                 new File(dir1, META_PROPERTIES_NAME).getAbsolutePath()));",
          "449:     }",
          "450: }",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/metadata/properties/MetaPropertiesTest.java||metadata/src/test/java/org/apache/kafka/metadata/properties/MetaPropertiesTest.java": [
          "File: metadata/src/test/java/org/apache/kafka/metadata/properties/MetaPropertiesTest.java -> metadata/src/test/java/org/apache/kafka/metadata/properties/MetaPropertiesTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.metadata.properties;",
          "20: import java.util.Optional;",
          "21: import java.util.OptionalInt;",
          "22: import java.util.Properties;",
          "24: import org.apache.kafka.common.Uuid;",
          "25: import org.junit.jupiter.api.Test;",
          "26: import static org.junit.jupiter.api.Assertions.assertEquals;",
          "27: import static org.junit.jupiter.api.Assertions.assertThrows;",
          "29: final public class MetaPropertiesTest {",
          "30:     @Test",
          "31:     public void testV0SerializationWithNothing() {",
          "32:         testV0Serialization(Optional.empty(),",
          "33:             OptionalInt.empty(),",
          "34:              Optional.empty(),",
          "35:             \"MetaProperties(version=0)\");",
          "36:     }",
          "38:     @Test",
          "39:     public void testV0SerializationWithJustClusterId() {",
          "40:         testV0Serialization(Optional.of(\"zd2vLVrZQlCLJj8-k7A10w\"),",
          "41:             OptionalInt.empty(),",
          "42:             Optional.empty(),",
          "43:             \"MetaProperties(version=0, clusterId=zd2vLVrZQlCLJj8-k7A10w)\");",
          "44:     }",
          "46:     @Test",
          "47:     public void testV0SerializationWithJustNodeId() {",
          "48:         testV0Serialization(Optional.empty(),",
          "49:             OptionalInt.of(0),",
          "50:             Optional.empty(),",
          "51:             \"MetaProperties(version=0, nodeId=0)\");",
          "52:     }",
          "54:     @Test",
          "55:     public void testV0SerializationWithJustClusterIdAndNodeId() {",
          "56:         testV0Serialization(Optional.of(\"zd2vLVrZQlCLJj8-k7A10w\"),",
          "57:             OptionalInt.of(0),",
          "58:             Optional.empty(),",
          "59:             \"MetaProperties(version=0, clusterId=zd2vLVrZQlCLJj8-k7A10w, nodeId=0)\");",
          "60:     }",
          "62:     @Test",
          "63:     public void testV0SerializationWithAll() {",
          "64:         testV0Serialization(Optional.of(\"zd2vLVrZQlCLJj8-k7A10w\"),",
          "65:             OptionalInt.of(0),",
          "66:             Optional.of(Uuid.fromString(\"3Adc4FjfTeypRWROmQDNIQ\")),",
          "67:             \"MetaProperties(version=0, clusterId=zd2vLVrZQlCLJj8-k7A10w, nodeId=0, \" +",
          "68:                 \"directoryId=3Adc4FjfTeypRWROmQDNIQ)\");",
          "69:     }",
          "71:     private void testV0Serialization(",
          "72:         Optional<String> clusterId,",
          "73:         OptionalInt nodeId,",
          "74:         Optional<Uuid> directoryId,",
          "75:         String expectedToStringOutput",
          "76:     ) {",
          "77:         MetaProperties metaProperties = new MetaProperties.Builder().",
          "78:                 setVersion(MetaPropertiesVersion.V0).",
          "79:                 setClusterId(clusterId).",
          "80:                 setNodeId(nodeId).",
          "81:                 setDirectoryId(directoryId).",
          "82:                 build();",
          "83:         assertEquals(MetaPropertiesVersion.V0, metaProperties.version());",
          "84:         assertEquals(clusterId, metaProperties.clusterId());",
          "85:         assertEquals(nodeId, metaProperties.nodeId());",
          "86:         assertEquals(directoryId, metaProperties.directoryId());",
          "87:         Properties props = new Properties();",
          "88:         props.setProperty(\"version\", \"0\");",
          "89:         if (clusterId.isPresent()) {",
          "90:             props.setProperty(\"cluster.id\", clusterId.get());",
          "91:         }",
          "92:         if (nodeId.isPresent()) {",
          "93:             props.setProperty(\"broker.id\", \"\" + nodeId.getAsInt());",
          "94:         }",
          "95:         if (directoryId.isPresent()) {",
          "96:             props.setProperty(\"directory.id\", directoryId.get().toString());",
          "97:         }",
          "98:         Properties props2 = metaProperties.toProperties();",
          "99:         assertEquals(props, props2);",
          "100:         MetaProperties metaProperties2 = new MetaProperties.Builder(props2).build();",
          "101:         System.out.println(\"metaProperties = \" + metaProperties.toString());",
          "102:         System.out.println(\"metaProperties2 = \" + metaProperties2.toString());",
          "103:         assertEquals(metaProperties, metaProperties2);",
          "104:         assertEquals(metaProperties.hashCode(), metaProperties2.hashCode());",
          "105:         assertEquals(metaProperties.toString(), metaProperties2.toString());",
          "106:         assertEquals(expectedToStringOutput, metaProperties.toString());",
          "107:     }",
          "109:     @Test",
          "110:     public void testV1SerializationWithoutDirectoryId() {",
          "111:         testV1Serialization(\"zd2vLVrZQlCLJj8-k7A10w\",",
          "112:             0,",
          "113:             Optional.empty(),",
          "114:             \"MetaProperties(version=1, clusterId=zd2vLVrZQlCLJj8-k7A10w, nodeId=0)\");",
          "115:     }",
          "117:     @Test",
          "118:     public void testV1SerializationWithDirectoryId() {",
          "119:         testV1Serialization(\"zd2vLVrZQlCLJj8-k7A10w\",",
          "120:             1,",
          "121:             Optional.of(Uuid.fromString(\"3Adc4FjfTeypRWROmQDNIQ\")),",
          "122:             \"MetaProperties(version=1, clusterId=zd2vLVrZQlCLJj8-k7A10w, nodeId=1, \" +",
          "123:                 \"directoryId=3Adc4FjfTeypRWROmQDNIQ)\");",
          "124:     }",
          "126:     @Test",
          "127:     public void testV1SerializationWithNonUuidClusterId() {",
          "128:         testV1Serialization(\"my@cluster@id\",",
          "129:             2,",
          "130:             Optional.empty(),",
          "131:             \"MetaProperties(version=1, clusterId=my@cluster@id, nodeId=2)\");",
          "132:     }",
          "134:     private void testV1Serialization(",
          "135:         String clusterId,",
          "136:         int nodeId,",
          "137:         Optional<Uuid> directoryId,",
          "138:         String expectedToStringOutput",
          "139:     ) {",
          "140:         MetaProperties metaProperties = new MetaProperties.Builder().",
          "141:             setVersion(MetaPropertiesVersion.V1).",
          "142:             setClusterId(clusterId).",
          "143:             setNodeId(nodeId).",
          "144:             setDirectoryId(directoryId).",
          "145:             build();",
          "146:         assertEquals(MetaPropertiesVersion.V1, metaProperties.version());",
          "147:         assertEquals(Optional.of(clusterId), metaProperties.clusterId());",
          "148:         assertEquals(OptionalInt.of(nodeId), metaProperties.nodeId());",
          "149:         assertEquals(directoryId, metaProperties.directoryId());",
          "150:         Properties props = new Properties();",
          "151:         props.setProperty(\"version\", \"1\");",
          "152:         props.setProperty(\"cluster.id\", clusterId);",
          "153:         props.setProperty(\"node.id\", \"\" + nodeId);",
          "154:         if (directoryId.isPresent()) {",
          "155:             props.setProperty(\"directory.id\", directoryId.get().toString());",
          "156:         }",
          "157:         Properties props2 = metaProperties.toProperties();",
          "158:         assertEquals(props, props2);",
          "159:         MetaProperties metaProperties2 = new MetaProperties.Builder(props2).build();",
          "160:         assertEquals(metaProperties, metaProperties2);",
          "161:         assertEquals(metaProperties.hashCode(), metaProperties2.hashCode());",
          "162:         assertEquals(metaProperties.toString(), metaProperties2.toString());",
          "163:         assertEquals(expectedToStringOutput, metaProperties.toString());",
          "164:     }",
          "166:     @Test",
          "167:     public void testClusterIdRequiredInV1() {",
          "168:         assertEquals(\"cluster.id was not found.\", assertThrows(RuntimeException.class,",
          "169:             () -> new MetaProperties.Builder().",
          "170:                 setVersion(MetaPropertiesVersion.V1).",
          "171:                 setNodeId(1).",
          "172:                 build()).getMessage());",
          "173:     }",
          "175:     @Test",
          "176:     public void testNodeIdRequiredInV1() {",
          "177:         assertEquals(\"node.id was not found.\", assertThrows(RuntimeException.class,",
          "178:             () -> new MetaProperties.Builder().",
          "179:                 setVersion(MetaPropertiesVersion.V1).",
          "180:                 setClusterId(\"zd2vLVrZQlCLJj8-k7A10w\").",
          "181:                 build()).getMessage());",
          "182:     }",
          "183: }",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/metadata/properties/MetaPropertiesVersionTest.java||metadata/src/test/java/org/apache/kafka/metadata/properties/MetaPropertiesVersionTest.java": [
          "File: metadata/src/test/java/org/apache/kafka/metadata/properties/MetaPropertiesVersionTest.java -> metadata/src/test/java/org/apache/kafka/metadata/properties/MetaPropertiesVersionTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.metadata.properties;",
          "20: import org.junit.jupiter.api.Test;",
          "21: import static org.junit.jupiter.api.Assertions.assertEquals;",
          "22: import static org.junit.jupiter.api.Assertions.assertFalse;",
          "23: import static org.junit.jupiter.api.Assertions.assertThrows;",
          "24: import static org.junit.jupiter.api.Assertions.assertTrue;",
          "26: final public class MetaPropertiesVersionTest {",
          "27:     @Test",
          "28:     public void testV0ToNumber() {",
          "29:         assertEquals(0, MetaPropertiesVersion.V0.number());",
          "30:     }",
          "32:     @Test",
          "33:     public void testV0ToNumberString() {",
          "34:         assertEquals(\"0\", MetaPropertiesVersion.V0.numberString());",
          "35:     }",
          "37:     @Test",
          "38:     public void testV0FromNumber() {",
          "39:         assertEquals(MetaPropertiesVersion.V0, MetaPropertiesVersion.fromNumber(0));",
          "40:     }",
          "42:     @Test",
          "43:     public void testV0FromNumberString() {",
          "44:         assertEquals(MetaPropertiesVersion.V0, MetaPropertiesVersion.fromNumberString(\"0\"));",
          "45:     }",
          "47:     @Test",
          "48:     public void testV1ToNumber() {",
          "49:         assertEquals(1, MetaPropertiesVersion.V1.number());",
          "50:     }",
          "52:     @Test",
          "53:     public void testV1ToNumberString() {",
          "54:         assertEquals(\"1\", MetaPropertiesVersion.V1.numberString());",
          "55:     }",
          "57:     @Test",
          "58:     public void testV1FromNumber() {",
          "59:         assertEquals(MetaPropertiesVersion.V1, MetaPropertiesVersion.fromNumber(1));",
          "60:     }",
          "62:     @Test",
          "63:     public void testV1FromNumberString() {",
          "64:         assertEquals(MetaPropertiesVersion.V1, MetaPropertiesVersion.fromNumberString(\"1\"));",
          "65:     }",
          "67:     @Test",
          "68:     public void testFromInvalidNumber() {",
          "69:         assertEquals(\"Unknown meta.properties version number 2\",",
          "70:             assertThrows(RuntimeException.class,",
          "71:                 () -> MetaPropertiesVersion.fromNumber(2)).getMessage());",
          "72:     }",
          "74:     @Test",
          "75:     public void testFromInvalidString() {",
          "76:         assertEquals(\"Invalid meta.properties version string 'orange'\",",
          "77:             assertThrows(RuntimeException.class,",
          "78:                 () -> MetaPropertiesVersion.fromNumberString(\"orange\")).getMessage());",
          "79:     }",
          "81:     @Test",
          "82:     public void testHasBrokerId() {",
          "83:         assertTrue(MetaPropertiesVersion.V0.hasBrokerId());",
          "84:         assertFalse(MetaPropertiesVersion.V1.hasBrokerId());",
          "85:     }",
          "87:     @Test",
          "88:     public void testAlwaysHasNodeId() {",
          "89:         assertFalse(MetaPropertiesVersion.V0.alwaysHasNodeId());",
          "90:         assertTrue(MetaPropertiesVersion.V1.alwaysHasNodeId());",
          "91:     }",
          "93:     @Test",
          "94:     public void testAlwaysHasClusterId() {",
          "95:         assertFalse(MetaPropertiesVersion.V0.alwaysHasClusterId());",
          "96:         assertTrue(MetaPropertiesVersion.V1.alwaysHasClusterId());",
          "97:     }",
          "98: }",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/metadata/properties/PropertiesUtilsTest.java||metadata/src/test/java/org/apache/kafka/metadata/properties/PropertiesUtilsTest.java": [
          "File: metadata/src/test/java/org/apache/kafka/metadata/properties/PropertiesUtilsTest.java -> metadata/src/test/java/org/apache/kafka/metadata/properties/PropertiesUtilsTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.metadata.properties;",
          "20: import java.io.File;",
          "21: import java.io.IOException;",
          "22: import java.nio.file.Files;",
          "23: import java.util.Properties;",
          "25: import org.apache.kafka.test.TestUtils;",
          "26: import org.junit.jupiter.api.Test;",
          "27: import org.junit.jupiter.params.ParameterizedTest;",
          "28: import org.junit.jupiter.params.provider.ValueSource;",
          "30: import static org.junit.jupiter.api.Assertions.assertEquals;",
          "31: import static org.junit.jupiter.api.Assertions.assertThrows;",
          "33: final public class PropertiesUtilsTest {",
          "34:     @Test",
          "35:     public void testReadPropertiesFile() throws IOException {",
          "36:         File tempFile = TestUtils.tempFile();",
          "37:         try {",
          "38:             String testContent = \"a=1\\nb=2\\n#a comment\\n\\nc=3\\nd=\";",
          "39:             Files.write(tempFile.toPath(), testContent.getBytes());",
          "40:             Properties props = PropertiesUtils.readPropertiesFile(tempFile.getAbsolutePath());",
          "41:             assertEquals(4, props.size());",
          "42:             assertEquals(\"1\", props.get(\"a\"));",
          "43:             assertEquals(\"2\", props.get(\"b\"));",
          "44:             assertEquals(\"3\", props.get(\"c\"));",
          "45:             assertEquals(\"\", props.get(\"d\"));",
          "46:         } finally {",
          "47:             Files.deleteIfExists(tempFile.toPath());",
          "48:         }",
          "49:     }",
          "51:     @ParameterizedTest",
          "52:     @ValueSource(booleans = {false, true})",
          "53:     public void testWritePropertiesFile(boolean fsync) throws IOException {",
          "54:         File tempFile = TestUtils.tempFile();",
          "55:         try {",
          "56:             Properties props = new Properties();",
          "57:             props.setProperty(\"abc\", \"123\");",
          "58:             props.setProperty(\"def\", \"456\");",
          "59:             PropertiesUtils.writePropertiesFile(props, tempFile.getAbsolutePath(), fsync);",
          "60:             Properties props2 = PropertiesUtils.readPropertiesFile(tempFile.getAbsolutePath());",
          "61:             assertEquals(props, props2);",
          "62:         } finally {",
          "63:             Files.deleteIfExists(tempFile.toPath());",
          "64:         }",
          "65:     }",
          "67:     @Test",
          "68:     public void loadRequiredIntProp() throws IOException {",
          "69:         Properties props = new Properties();",
          "70:         props.setProperty(\"foo.bar\", \"123\");",
          "71:         assertEquals(123, PropertiesUtils.loadRequiredIntProp(props, \"foo.bar\"));",
          "72:     }",
          "74:     @Test",
          "75:     public void loadMissingRequiredIntProp() throws IOException {",
          "76:         Properties props = new Properties();",
          "77:         assertEquals(\"Failed to find foo.bar\",",
          "78:             assertThrows(RuntimeException.class,",
          "79:                 () -> PropertiesUtils.loadRequiredIntProp(props, \"foo.bar\")).",
          "80:                     getMessage());",
          "81:     }",
          "83:     @Test",
          "84:     public void loadNonIntegerRequiredIntProp() throws IOException {",
          "85:         Properties props = new Properties();",
          "86:         props.setProperty(\"foo.bar\", \"b\");",
          "87:         assertEquals(\"Unable to read foo.bar as a base-10 number.\",",
          "88:             assertThrows(RuntimeException.class,",
          "89:                 () -> PropertiesUtils.loadRequiredIntProp(props, \"foo.bar\")).",
          "90:                     getMessage());",
          "91:     }",
          "92: }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "c821449fb7c1e2c0f398eeb5cfc4a8abc210c0a4",
      "candidate_info": {
        "commit_hash": "c821449fb7c1e2c0f398eeb5cfc4a8abc210c0a4",
        "repo": "apache/kafka",
        "commit_url": "https://github.com/apache/kafka/commit/c821449fb7c1e2c0f398eeb5cfc4a8abc210c0a4",
        "files": [
          "core/src/main/scala/kafka/tools/StorageTool.scala",
          "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala",
          "docs/ops.html",
          "metadata/src/main/java/org/apache/kafka/metadata/storage/Formatter.java",
          "metadata/src/test/java/org/apache/kafka/metadata/storage/FormatterTest.java",
          "tests/kafkatest/services/kafka/kafka.py"
        ],
        "message": "KAFKA-17794: Add some formatting safeguards for KIP-853 (#17504)\n\nKIP-853 adds support for dynamic KRaft quorums. This means that the quorum topology is\nno longer statically determined by the controller.quorum.voters configuration. Instead, it\nis contained in the storage directories of each controller and broker.\n\nUsers of dynamic quorums must format at least one controller storage directory with either\nthe --initial-controllers or --standalone flags.  If they fail to do this, no quorum can be\nestablished. This PR changes the storage tool to warn about the case where a KIP-853 flag has\nnot been supplied to format a KIP-853 controller. (Note that broker storage directories\ncan continue to be formatted without a KIP-853 flag.)\n\nThere are cases where we don't want to specify initial voters when formatting a controller. One\nexample is where we format a single controller with --standalone, and then dynamically add 4\nmore controllers with no initial topology. In this case, we want the 4 later controllers to grab\nthe quorum topology from the initial one. To support this case, this PR adds the\n--no-initial-controllers flag.\n\nReviewers: Jos\u00e9 Armando Garc\u00eda Sancio <jsancio@apache.org>, Federico Valeri <fvaleri@redhat.com>",
        "before_after_code_files": [
          "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
          "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala",
          "metadata/src/main/java/org/apache/kafka/metadata/storage/Formatter.java||metadata/src/main/java/org/apache/kafka/metadata/storage/Formatter.java",
          "metadata/src/test/java/org/apache/kafka/metadata/storage/FormatterTest.java||metadata/src/test/java/org/apache/kafka/metadata/storage/FormatterTest.java",
          "tests/kafkatest/services/kafka/kafka.py||tests/kafkatest/services/kafka/kafka.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
            "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
          ],
          "candidate": [
            "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
            "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
          ]
        }
      },
      "candidate_diff": {
        "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala": [
          "File: core/src/main/scala/kafka/tools/StorageTool.scala -> core/src/main/scala/kafka/tools/StorageTool.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "31: import org.apache.kafka.server.common.MetadataVersion",
          "32: import org.apache.kafka.metadata.properties.{MetaProperties, MetaPropertiesEnsemble, MetaPropertiesVersion, PropertiesUtils}",
          "33: import org.apache.kafka.metadata.storage.{Formatter, FormatterException}",
          "35: import org.apache.kafka.server.ProcessRole",
          "36: import org.apache.kafka.server.config.ReplicationConfigs",
          "",
          "[Removed Lines]",
          "34: import org.apache.kafka.raft.DynamicVoters",
          "",
          "[Added Lines]",
          "33: import org.apache.kafka.raft.{DynamicVoters, QuorumConfig}",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "126:         foreach(v => formatter.setReleaseVersion(MetadataVersion.fromVersionString(v.toString)))",
          "127:     }",
          "128:     Option(namespace.getString(\"initial_controllers\")).",
          "130:     if (namespace.getBoolean(\"standalone\")) {",
          "132:     }",
          "133:     Option(namespace.getList(\"add_scram\")).",
          "134:       foreach(scramArgs => formatter.setScramArguments(scramArgs.asInstanceOf[util.List[String]]))",
          "",
          "[Removed Lines]",
          "129:       foreach(v => formatter.setInitialVoters(DynamicVoters.parse(v)))",
          "131:       formatter.setInitialVoters(createStandaloneDynamicVoters(config))",
          "",
          "[Added Lines]",
          "128:       foreach(v => formatter.setInitialControllers(DynamicVoters.parse(v)))",
          "130:       formatter.setInitialControllers(createStandaloneDynamicVoters(config))",
          "131:     }",
          "132:     if (!namespace.getBoolean(\"no_initial_controllers\")) {",
          "133:       if (config.processRoles.contains(ProcessRole.ControllerRole)) {",
          "134:         if (config.quorumVoters.isEmpty) {",
          "135:           if (!formatter.initialVoters().isPresent()) {",
          "136:             throw new TerseFailure(\"Because \" + QuorumConfig.QUORUM_VOTERS_CONFIG +",
          "137:               \" is not set on this controller, you must specify one of the following: \" +",
          "138:               \"--standalone, --initial-controllers, or --no-initial-controllers.\");",
          "139:           }",
          "140:         }",
          "141:       }",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "140:     config: KafkaConfig",
          "141:   ): DynamicVoters = {",
          "142:     if (!config.processRoles.contains(ProcessRole.ControllerRole)) {",
          "144:     }",
          "145:     if (config.effectiveAdvertisedControllerListeners.isEmpty) {",
          "146:       throw new RuntimeException(\"No controller listeners found.\")",
          "",
          "[Removed Lines]",
          "143:       throw new TerseFailure(\"You cannot use --standalone on a broker node.\")",
          "",
          "[Added Lines]",
          "153:       throw new TerseFailure(\"You can only use --standalone on a controller.\")",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "191:       help(\"The setting to use for a specific feature, in feature=level format. For example: `kraft.version=1`.\").",
          "192:       action(append())",
          "193:     val reconfigurableQuorumOptions = formatParser.addMutuallyExclusiveGroup()",
          "201:     parser.parseArgs(args)",
          "202:   }",
          "",
          "[Removed Lines]",
          "194:     reconfigurableQuorumOptions.addArgument(\"--standalone\", \"-s\").",
          "195:       help(\"Used to initialize a single-node quorum controller quorum.\").",
          "196:       action(storeTrue())",
          "197:     reconfigurableQuorumOptions.addArgument(\"--initial-controllers\", \"-I\").",
          "198:       help(\"The initial controllers, as a comma-separated list of id@hostname:port:directory. The same values must be used to format all nodes. For example:\\n\" +",
          "199:         \"0@example.com:8082:JEXY6aqzQY-32P5TStzaFg,1@example.com:8083:MvDxzVmcRsaTz33bUuRU6A,2@example.com:8084:07R5amHmR32VDA6jHkGbTA\\n\").",
          "200:       action(store())",
          "",
          "[Added Lines]",
          "204:     reconfigurableQuorumOptions.addArgument(\"--standalone\", \"-s\")",
          "205:       .help(\"Used to initialize a controller as a single-node dynamic quorum.\")",
          "206:       .action(storeTrue())",
          "208:     reconfigurableQuorumOptions.addArgument(\"--no-initial-controllers\", \"-N\")",
          "209:       .help(\"Used to initialize a server without a dynamic quorum topology.\")",
          "210:       .action(storeTrue())",
          "212:     reconfigurableQuorumOptions.addArgument(\"--initial-controllers\", \"-I\")",
          "213:       .help(\"Used to initialize a server with a specific dynamic quorum topology. The argument \" +",
          "214:         \"is a comma-separated list of id@hostname:port:directory. The same values must be used to \" +",
          "215:         \"format all nodes. For example:\\n0@example.com:8082:JEXY6aqzQY-32P5TStzaFg,1@example.com:8083:\" +",
          "216:         \"MvDxzVmcRsaTz33bUuRU6A,2@example.com:8084:07R5amHmR32VDA6jHkGbTA\\n\")",
          "217:       .action(store())",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala": [
          "File: core/src/test/scala/unit/kafka/tools/StorageToolTest.scala -> core/src/test/scala/unit/kafka/tools/StorageToolTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "177:   defaultDynamicQuorumProperties.setProperty(\"process.roles\", \"controller\")",
          "178:   defaultDynamicQuorumProperties.setProperty(\"node.id\", \"0\")",
          "179:   defaultDynamicQuorumProperties.setProperty(\"controller.listener.names\", \"CONTROLLER\")",
          "182:   defaultDynamicQuorumProperties.setProperty(ServerConfigs.UNSTABLE_API_VERSIONS_ENABLE_CONFIG, \"true\")",
          "183:   defaultDynamicQuorumProperties.setProperty(ServerConfigs.UNSTABLE_FEATURE_VERSIONS_ENABLE_CONFIG , \"true\")",
          "",
          "[Removed Lines]",
          "180:   defaultDynamicQuorumProperties.setProperty(\"controller.quorum.voters\", \"0@localhost:9093\")",
          "181:   defaultDynamicQuorumProperties.setProperty(\"listeners\", \"CONTROLLER://127.0.0.1:9093\")",
          "",
          "[Added Lines]",
          "180:   defaultDynamicQuorumProperties.setProperty(\"controller.quorum.bootstrap.servers\", \"localhost:9093\")",
          "181:   defaultDynamicQuorumProperties.setProperty(\"listeners\", \"CONTROLLER://:9093\")",
          "182:   defaultDynamicQuorumProperties.setProperty(\"advertised.listeners\", \"CONTROLLER://127.0.0.1:9093\")",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "378:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
          "379:     val stream = new ByteArrayOutputStream()",
          "380:     val arguments = ListBuffer[String](\"--release-version\", \"3.9-IV0\", \"--standalone\")",
          "382:       assertThrows(classOf[TerseFailure],",
          "383:         () => runFormatCommand(stream, properties, arguments.toSeq)).getMessage)",
          "384:   }",
          "",
          "[Removed Lines]",
          "381:     assertEquals(\"You cannot use --standalone on a broker node.\",",
          "",
          "[Added Lines]",
          "382:     assertEquals(\"You can only use --standalone on a controller.\",",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "437:       \"Failed to find content in output: \" + stream.toString())",
          "438:   }",
          "440:   @Test",
          "442:     val availableDirs = Seq(TestUtils.tempDir())",
          "443:     val properties = new Properties()",
          "444:     properties.putAll(defaultDynamicQuorumProperties)",
          "445:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
          "446:     val stream = new ByteArrayOutputStream()",
          "447:     val arguments = ListBuffer[String](",
          "",
          "[Removed Lines]",
          "441:   def testBootstrapScramRecords(): Unit = {",
          "",
          "[Added Lines]",
          "441:   @ParameterizedTest",
          "442:   @ValueSource(strings = Array(\"controller\", \"broker,controller\"))",
          "443:   def testFormatWithoutStaticQuorumFailsWithoutInitialControllersOnController(processRoles: String): Unit = {",
          "444:     val availableDirs = Seq(TestUtils.tempDir())",
          "445:     val properties = new Properties()",
          "446:     properties.putAll(defaultDynamicQuorumProperties)",
          "447:     if (processRoles.contains(\"broker\")) {",
          "448:       properties.setProperty(\"listeners\", \"PLAINTEXT://:9092,CONTROLLER://:9093\")",
          "449:       properties.setProperty(\"advertised.listeners\", \"PLAINTEXT://127.0.0.1:9092,CONTROLLER://127.0.0.1:9093\")",
          "450:     }",
          "451:     properties.setProperty(\"process.roles\", processRoles)",
          "452:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
          "453:     assertEquals(\"Because controller.quorum.voters is not set on this controller, you must \" +",
          "454:       \"specify one of the following: --standalone, --initial-controllers, or \" +",
          "455:         \"--no-initial-controllers.\",",
          "456:           assertThrows(classOf[TerseFailure],",
          "457:             () => runFormatCommand(new ByteArrayOutputStream(), properties,",
          "458:               Seq(\"--release-version\", \"3.9-IV0\"))).getMessage)",
          "459:   }",
          "462:   def testFormatWithNoInitialControllersSucceedsOnController(): Unit = {",
          "463:     val availableDirs = Seq(TestUtils.tempDir())",
          "464:     val properties = new Properties()",
          "465:     properties.putAll(defaultDynamicQuorumProperties)",
          "466:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
          "467:     val stream = new ByteArrayOutputStream()",
          "468:     assertEquals(0, runFormatCommand(stream, properties,",
          "469:       Seq(\"--no-initial-controllers\", \"--release-version\", \"3.9-IV0\")))",
          "470:     assertTrue(stream.toString().",
          "471:       contains(\"Formatting metadata directory %s\".format(availableDirs.head)),",
          "472:       \"Failed to find content in output: \" + stream.toString())",
          "473:   }",
          "475:   @Test",
          "476:   def testFormatWithoutStaticQuorumSucceedsWithoutInitialControllersOnBroker(): Unit = {",
          "480:     properties.setProperty(\"listeners\", \"PLAINTEXT://:9092\")",
          "481:     properties.setProperty(\"advertised.listeners\", \"PLAINTEXT://127.0.0.1:9092\")",
          "482:     properties.setProperty(\"process.roles\", \"broker\")",
          "483:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
          "484:     val stream = new ByteArrayOutputStream()",
          "485:     assertEquals(0, runFormatCommand(stream, properties, Seq(\"--release-version\", \"3.9-IV0\")))",
          "486:     assertTrue(stream.toString().",
          "487:       contains(\"Formatting metadata directory %s\".format(availableDirs.head)),",
          "488:       \"Failed to find content in output: \" + stream.toString())",
          "489:   }",
          "491:   @Test",
          "492:   def testBootstrapScramRecords(): Unit = {",
          "493:     val availableDirs = Seq(TestUtils.tempDir())",
          "494:     val properties = new Properties()",
          "495:     properties.putAll(defaultStaticQuorumProperties)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "468:   def testScramRecordsOldReleaseVersion(): Unit = {",
          "469:     val availableDirs = Seq(TestUtils.tempDir())",
          "470:     val properties = new Properties()",
          "472:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
          "473:     val stream = new ByteArrayOutputStream()",
          "474:     val arguments = ListBuffer[String](",
          "",
          "[Removed Lines]",
          "471:     properties.putAll(defaultDynamicQuorumProperties)",
          "",
          "[Added Lines]",
          "522:     properties.putAll(defaultStaticQuorumProperties)",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/storage/Formatter.java||metadata/src/main/java/org/apache/kafka/metadata/storage/Formatter.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/storage/Formatter.java -> metadata/src/main/java/org/apache/kafka/metadata/storage/Formatter.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "202:         return this;",
          "203:     }",
          "206:         this.initialControllers = Optional.of(initialControllers);",
          "207:         return this;",
          "208:     }",
          "210:     boolean hasDynamicQuorum() {",
          "211:         if (initialControllers.isPresent()) {",
          "212:             return true;",
          "",
          "[Removed Lines]",
          "205:     public Formatter setInitialVoters(DynamicVoters initialControllers) {",
          "",
          "[Added Lines]",
          "205:     public Formatter setInitialControllers(DynamicVoters initialControllers) {",
          "210:     public Optional<DynamicVoters> initialVoters() {",
          "211:         return initialControllers;",
          "212:     }",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/metadata/storage/FormatterTest.java||metadata/src/test/java/org/apache/kafka/metadata/storage/FormatterTest.java": [
          "File: metadata/src/test/java/org/apache/kafka/metadata/storage/FormatterTest.java -> metadata/src/test/java/org/apache/kafka/metadata/storage/FormatterTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "372:                 formatter1.formatter.setFeatureLevel(\"kraft.version\", (short) 1);",
          "373:             }",
          "374:             formatter1.formatter.setUnstableFeatureVersionsEnabled(true);",
          "376:                 parse(\"1@localhost:8020:4znU-ou9Taa06bmEJxsjnw\"));",
          "377:             formatter1.formatter.run();",
          "378:             assertEquals(Arrays.asList(",
          "",
          "[Removed Lines]",
          "375:             formatter1.formatter.setInitialVoters(DynamicVoters.",
          "",
          "[Added Lines]",
          "375:             formatter1.formatter.setInitialControllers(DynamicVoters.",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "403:             FormatterContext formatter1 = testEnv.newFormatter();",
          "404:             formatter1.formatter.setFeatureLevel(\"kraft.version\", (short) 0);",
          "405:             formatter1.formatter.setUnstableFeatureVersionsEnabled(true);",
          "407:                     parse(\"1@localhost:8020:4znU-ou9Taa06bmEJxsjnw\"));",
          "408:             assertTrue(formatter1.formatter.hasDynamicQuorum());",
          "409:             assertEquals(\"Cannot set kraft.version to 0 if KIP-853 configuration is present. \" +",
          "",
          "[Removed Lines]",
          "406:             formatter1.formatter.setInitialVoters(DynamicVoters.",
          "",
          "[Added Lines]",
          "406:             formatter1.formatter.setInitialControllers(DynamicVoters.",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "433:             FormatterContext formatter1 = testEnv.newFormatter();",
          "434:             formatter1.formatter.setReleaseVersion(MetadataVersion.IBP_3_8_IV0);",
          "435:             formatter1.formatter.setFeatureLevel(\"kraft.version\", (short) 1);",
          "437:                     parse(\"1@localhost:8020:4znU-ou9Taa06bmEJxsjnw\"));",
          "438:             formatter1.formatter.setUnstableFeatureVersionsEnabled(true);",
          "439:             assertEquals(\"kraft.version could not be set to 1 because it depends on \" +",
          "",
          "[Removed Lines]",
          "436:             formatter1.formatter.setInitialVoters(DynamicVoters.",
          "",
          "[Added Lines]",
          "436:             formatter1.formatter.setInitialControllers(DynamicVoters.",
          "",
          "---------------"
        ],
        "tests/kafkatest/services/kafka/kafka.py||tests/kafkatest/services/kafka/kafka.py": [
          "File: tests/kafkatest/services/kafka/kafka.py -> tests/kafkatest/services/kafka/kafka.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "914:             cmd = \"%s format --ignore-formatted --config %s --cluster-id %s\" % (kafka_storage_script, KafkaService.CONFIG_FILE, config_property.CLUSTER_ID)",
          "915:             if self.dynamicRaftQuorum:",
          "916:                 cmd += \" --feature kraft.version=1\"",
          "920:             self.logger.info(\"Running log directory format command...\\n%s\" % cmd)",
          "921:             node.account.ssh(cmd)",
          "",
          "[Removed Lines]",
          "917:                 if not self.standalone_controller_bootstrapped and self.node_quorum_info.has_controller_role:",
          "918:                     cmd += \" --standalone\"",
          "919:                     self.standalone_controller_bootstrapped = True",
          "",
          "[Added Lines]",
          "917:                 if self.node_quorum_info.has_controller_role:",
          "918:                     if self.standalone_controller_bootstrapped:",
          "919:                         cmd += \" --no-initial-controllers\"",
          "920:                     else:",
          "921:                         cmd += \" --standalone\"",
          "922:                         self.standalone_controller_bootstrapped = True",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "16cac978735eb2e73421247e74f7e09fec6d0410",
      "candidate_info": {
        "commit_hash": "16cac978735eb2e73421247e74f7e09fec6d0410",
        "repo": "apache/kafka",
        "commit_url": "https://github.com/apache/kafka/commit/16cac978735eb2e73421247e74f7e09fec6d0410",
        "files": [
          "core/src/main/scala/kafka/tools/StorageTool.scala",
          "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
        ],
        "message": "KAFKA-17636 Fix missing SCRAM bootstrap records (#17305)\n\nFixes a regression introduced by #16669 which inadvertently stopped processing SCRAM arguments from kafka-storage.sh\n\nReviewers: Colin P. McCabe <cmccabe@apache.org>, Federico Valeri <fedevaleri@gmail.com>",
        "before_after_code_files": [
          "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
          "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
            "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
          ],
          "candidate": [
            "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
            "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
          ]
        }
      },
      "candidate_diff": {
        "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala": [
          "File: core/src/main/scala/kafka/tools/StorageTool.scala -> core/src/main/scala/kafka/tools/StorageTool.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "139:     if (namespace.getBoolean(\"standalone\")) {",
          "140:       formatter.setInitialVoters(createStandaloneDynamicVoters(config))",
          "141:     }",
          "142:     configToLogDirectories(config).foreach(formatter.addDirectory(_))",
          "143:     formatter.run()",
          "144:   }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "142:     Option(namespace.getList(\"add_scram\")).",
          "143:       foreach(scramArgs => formatter.setScramArguments(scramArgs.asInstanceOf[util.List[String]]))",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala": [
          "File: core/src/test/scala/unit/kafka/tools/StorageToolTest.scala -> core/src/test/scala/unit/kafka/tools/StorageToolTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: import java.nio.charset.StandardCharsets",
          "22: import java.nio.file.Files",
          "23: import java.util",
          "25: import kafka.server.KafkaConfig",
          "26: import kafka.utils.TestUtils",
          "27: import net.sourceforge.argparse4j.inf.ArgumentParserException",
          "28: import org.apache.kafka.common.utils.Utils",
          "29: import org.apache.kafka.server.common.{Features, MetadataVersion}",
          "30: import org.apache.kafka.metadata.properties.{MetaPropertiesEnsemble, PropertiesUtils}",
          "31: import org.apache.kafka.metadata.storage.FormatterException",
          "32: import org.apache.kafka.raft.QuorumConfig",
          "",
          "[Removed Lines]",
          "24: import java.util.Properties",
          "",
          "[Added Lines]",
          "24: import java.util.{Optional, Properties}",
          "28: import org.apache.kafka.common.metadata.UserScramCredentialRecord",
          "31: import org.apache.kafka.metadata.bootstrap.BootstrapDirectory",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "37: import org.junit.jupiter.params.provider.ValueSource",
          "39: import scala.collection.mutable.ListBuffer",
          "41: @Timeout(value = 40)",
          "42: class StorageToolTest {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "42: import scala.jdk.CollectionConverters.IterableHasAsScala",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "620:     assertEquals(\"Invalid version format: invalid for feature metadata.version\", exception.getMessage)",
          "621:   }",
          "622: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "626:   @Test",
          "627:   def testBootstrapScramRecords(): Unit = {",
          "628:     val availableDirs = Seq(TestUtils.tempDir())",
          "629:     val properties = new Properties()",
          "630:     properties.putAll(defaultDynamicQuorumProperties)",
          "631:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
          "632:     val stream = new ByteArrayOutputStream()",
          "633:     val arguments = ListBuffer[String](",
          "634:       \"--release-version\", \"3.9-IV0\",",
          "635:       \"--add-scram\", \"SCRAM-SHA-512=[name=alice,password=changeit]\",",
          "636:       \"--add-scram\", \"SCRAM-SHA-512=[name=bob,password=changeit]\"",
          "637:     )",
          "639:     assertEquals(0, runFormatCommand(stream, properties, arguments.toSeq))",
          "643:     val bootstrapMetadata = new BootstrapDirectory(availableDirs.head.toString, Optional.empty).read",
          "644:     val scramRecords = bootstrapMetadata.records().asScala",
          "645:       .filter(apiMessageAndVersion => apiMessageAndVersion.message().isInstanceOf[UserScramCredentialRecord])",
          "646:       .map(apiMessageAndVersion => apiMessageAndVersion.message().asInstanceOf[UserScramCredentialRecord])",
          "647:       .toList",
          "648:     assertEquals(2, scramRecords.size)",
          "649:     assertEquals(\"alice\", scramRecords.head.name())",
          "650:     assertEquals(\"bob\", scramRecords.last.name())",
          "651:   }",
          "653:   @Test",
          "654:   def testScramRecordsOldReleaseVersion(): Unit = {",
          "655:     val availableDirs = Seq(TestUtils.tempDir())",
          "656:     val properties = new Properties()",
          "657:     properties.putAll(defaultDynamicQuorumProperties)",
          "658:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
          "659:     val stream = new ByteArrayOutputStream()",
          "660:     val arguments = ListBuffer[String](",
          "661:       \"--release-version\", \"3.4\",",
          "662:       \"--add-scram\", \"SCRAM-SHA-512=[name=alice,password=changeit]\",",
          "663:       \"--add-scram\", \"SCRAM-SHA-512=[name=bob,password=changeit]\"",
          "664:     )",
          "666:     assertEquals(",
          "667:       \"SCRAM is only supported in metadata.version 3.5-IV2 or later.\",",
          "668:       assertThrows(classOf[FormatterException], () => runFormatCommand(stream, properties, arguments.toSeq)).getMessage)",
          "669:   }",
          "",
          "---------------"
        ]
      }
    }
  ]
}