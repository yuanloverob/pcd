{
  "cve_id": "CVE-2024-27309",
  "cve_desc": "While an Apache Kafka cluster is being migrated from ZooKeeper mode to KRaft mode, in some cases ACLs will not be correctly enforced.\n\nTwo preconditions are needed to trigger the bug:\n1. The administrator decides to remove an ACL\n2. The resource associated with the removed ACL continues to have two or more other ACLs associated with it after the removal.\n\nWhen those two preconditions are met, Kafka will treat the resource as if it had only one ACL associated with it after the removal, rather than the two or more that would be correct.\n\nThe incorrect condition is cleared by removing all brokers in ZK mode, or by adding a new ACL to the affected resource. Once the migration is completed, there is no metadata loss (the ACLs all remain).\n\nThe full impact depends on the ACLs in use. If only ALLOW ACLs were configured during the migration, the impact would be limited to availability impact. if DENY ACLs were configured, the impact could include confidentiality and integrity impact depending on the ACLs configured, as the DENY ACLs might be ignored due to this vulnerability during the migration period.",
  "repo": "apache/kafka",
  "patch_hash": "c000b1fae2bd7d4b76713a53508f128a13431ab6",
  "patch_info": {
    "commit_hash": "c000b1fae2bd7d4b76713a53508f128a13431ab6",
    "repo": "apache/kafka",
    "commit_url": "https://github.com/apache/kafka/commit/c000b1fae2bd7d4b76713a53508f128a13431ab6",
    "files": [
      "core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala",
      "core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala",
      "core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala",
      "metadata/src/main/java/org/apache/kafka/image/AclsDelta.java",
      "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java",
      "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java",
      "metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriterTest.java"
    ],
    "message": "MINOR: Fix some MetadataDelta handling issues during ZK migration (#15327)\n\nReviewers: Colin P. McCabe <cmccabe@apache.org>",
    "before_after_code_files": [
      "core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala",
      "core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala",
      "core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala",
      "metadata/src/main/java/org/apache/kafka/image/AclsDelta.java||metadata/src/main/java/org/apache/kafka/image/AclsDelta.java",
      "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java",
      "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java",
      "metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriterTest.java||metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriterTest.java"
    ]
  },
  "patch_diff": {
    "core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala": [
      "File: core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala -> core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala",
      "--- Hunk 1 ---",
      "[Context before]",
      "21: import kafka.utils.TestUtils",
      "22: import org.apache.kafka.common.Uuid",
      "23: import org.apache.kafka.common.acl._",
      "25: import org.apache.kafka.common.resource.{PatternType, ResourcePattern, ResourcePatternFilter, ResourceType}",
      "26: import org.apache.kafka.common.security.auth.KafkaPrincipal",
      "27: import org.apache.kafka.common.utils.SecurityUtils",
      "28: import org.apache.kafka.image.{MetadataDelta, MetadataImage, MetadataProvenance}",
      "29: import org.apache.kafka.metadata.migration.KRaftMigrationZkWriter",
      "30: import org.apache.kafka.server.common.ApiMessageAndVersion",
      "32: import org.junit.jupiter.api.Test",
      "34: import scala.collection.mutable",
      "",
      "[Removed Lines]",
      "24: import org.apache.kafka.common.metadata.AccessControlEntryRecord",
      "31: import org.junit.jupiter.api.Assertions.{assertEquals, assertTrue}",
      "",
      "[Added Lines]",
      "24: import org.apache.kafka.common.metadata.{AccessControlEntryRecord, RemoveAccessControlEntryRecord}",
      "31: import org.junit.jupiter.api.Assertions.{assertEquals, assertTrue, fail}",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "169:     val image = delta.apply(MetadataProvenance.EMPTY)",
      "173:     kraftMigrationZkWriter.handleSnapshot(image, (_, _, operation) => { migrationState = operation.apply(migrationState) })",
      "",
      "[Removed Lines]",
      "172:     val kraftMigrationZkWriter = new KRaftMigrationZkWriter(migrationClient)",
      "",
      "[Added Lines]",
      "172:     val kraftMigrationZkWriter = new KRaftMigrationZkWriter(migrationClient, fail(_))",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "189:         AclPermissionType.fromCode(acl1Resource3.permissionType())),",
      "190:       resource3AclsInZk.head.ace)",
      "191:   }",
      "192: }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "193:   def user(user: String): String = {",
      "194:     new KafkaPrincipal(KafkaPrincipal.USER_TYPE, user).toString",
      "195:   }",
      "197:   def acl(resourceName: String,",
      "198:           resourceType: ResourceType,",
      "199:           resourcePattern: PatternType,",
      "200:           principal: String,",
      "201:           host: String = \"*\",",
      "202:           operation: AclOperation = AclOperation.READ,",
      "203:           permissionType: AclPermissionType = AclPermissionType.ALLOW",
      "204:   ): AccessControlEntryRecord = {",
      "205:     new AccessControlEntryRecord()",
      "206:       .setId(Uuid.randomUuid())",
      "207:       .setHost(host)",
      "208:       .setOperation(operation.code())",
      "209:       .setPrincipal(principal)",
      "210:       .setPermissionType(permissionType.code())",
      "211:       .setPatternType(resourcePattern.code())",
      "212:       .setResourceName(resourceName)",
      "213:       .setResourceType(resourceType.code())",
      "214:   }",
      "216:   @Test",
      "217:   def testDeleteOneAclOfMany(): Unit = {",
      "218:     zkClient.createAclPaths()",
      "219:     val topicName = \"topic-\" + Uuid.randomUuid()",
      "220:     val resource = new ResourcePattern(ResourceType.TOPIC, topicName, PatternType.LITERAL)",
      "223:     val delta = new MetadataDelta(MetadataImage.EMPTY)",
      "224:     val acl1 = acl(topicName, ResourceType.TOPIC, PatternType.LITERAL, user(\"alice\"))",
      "225:     val acl2 = acl(topicName, ResourceType.TOPIC, PatternType.LITERAL, user(\"bob\"))",
      "226:     val acl3 = acl(topicName, ResourceType.TOPIC, PatternType.LITERAL, user(\"carol\"))",
      "227:     delta.replay(acl1)",
      "228:     delta.replay(acl2)",
      "229:     delta.replay(acl3)",
      "230:     val image = delta.apply(MetadataProvenance.EMPTY)",
      "233:     val errorLogs = mutable.Buffer[String]()",
      "234:     val kraftMigrationZkWriter = new KRaftMigrationZkWriter(migrationClient, errorLogs.append)",
      "235:     kraftMigrationZkWriter.handleSnapshot(image, (_, _, operation) => {",
      "236:       migrationState = operation.apply(migrationState)",
      "237:     })",
      "240:     val aclsInZk = zkClient.getVersionedAclsForResource(resource).acls",
      "241:     assertEquals(3, aclsInZk.size)",
      "244:     val delta2 = new MetadataDelta.Builder()",
      "245:       .setImage(image)",
      "246:       .build()",
      "247:     delta2.replay(new RemoveAccessControlEntryRecord().setId(acl3.id()))",
      "248:     val image2 = delta2.apply(MetadataProvenance.EMPTY)",
      "249:     kraftMigrationZkWriter.handleDelta(image, image2, delta2, (_, _, operation) => {",
      "250:       migrationState = operation.apply(migrationState)",
      "251:     })",
      "254:     val aclsInZk2 = zkClient.getVersionedAclsForResource(resource).acls",
      "255:     assertEquals(2, aclsInZk2.size)",
      "256:     assertEquals(0, errorLogs.size)",
      "259:     val acl4 = acl(topicName, ResourceType.TOPIC, PatternType.LITERAL, user(\"carol\"))",
      "260:     delta2.replay(acl4)",
      "261:     val image3 = delta2.apply(MetadataProvenance.EMPTY)",
      "265:     kraftMigrationZkWriter.handleDelta(image3, image3, delta2, (_, _, operation) => {",
      "266:       migrationState = operation.apply(migrationState)",
      "267:     })",
      "269:     val aclsInZk3 = zkClient.getVersionedAclsForResource(resource).acls",
      "270:     assertEquals(3, aclsInZk3.size)",
      "271:     assertEquals(1, errorLogs.size)",
      "272:     assertEquals(s\"Cannot delete ACL ${acl3.id()} from ZK since it is missing from previous AclImage\", errorLogs.head)",
      "273:   }",
      "275:   @Test",
      "276:   def testAclUpdateAndDelete(): Unit = {",
      "277:     zkClient.createAclPaths()",
      "278:     val errorLogs = mutable.Buffer[String]()",
      "279:     val kraftMigrationZkWriter = new KRaftMigrationZkWriter(migrationClient, errorLogs.append)",
      "281:     val topicName = \"topic-\" + Uuid.randomUuid()",
      "282:     val otherName = \"other-\" + Uuid.randomUuid()",
      "283:     val literalResource = new ResourcePattern(ResourceType.TOPIC, topicName, PatternType.LITERAL)",
      "284:     val prefixedResource = new ResourcePattern(ResourceType.TOPIC, topicName, PatternType.PREFIXED)",
      "285:     val otherResource = new ResourcePattern(ResourceType.TOPIC, otherName, PatternType.LITERAL)",
      "288:     val acl1 = acl(topicName, ResourceType.TOPIC, PatternType.LITERAL, user(\"alice\"))",
      "289:     val acl2 = acl(topicName, ResourceType.TOPIC, PatternType.LITERAL, user(\"bob\"))",
      "290:     val acl3 = acl(topicName, ResourceType.TOPIC, PatternType.LITERAL, user(\"carol\"))",
      "291:     val acl4 = acl(topicName, ResourceType.TOPIC, PatternType.LITERAL, user(\"dave\"))",
      "293:     val delta1 = new MetadataDelta(MetadataImage.EMPTY)",
      "294:     delta1.replay(acl1)",
      "295:     delta1.replay(acl2)",
      "296:     delta1.replay(acl3)",
      "297:     delta1.replay(acl4)",
      "299:     val image1 = delta1.apply(MetadataProvenance.EMPTY)",
      "300:     kraftMigrationZkWriter.handleDelta(MetadataImage.EMPTY, image1, delta1, (_, _, operation) => {",
      "301:       migrationState = operation.apply(migrationState)",
      "302:     })",
      "303:     assertEquals(4, zkClient.getVersionedAclsForResource(literalResource).acls.size)",
      "304:     assertEquals(0, zkClient.getVersionedAclsForResource(prefixedResource).acls.size)",
      "305:     assertEquals(0, zkClient.getVersionedAclsForResource(otherResource).acls.size)",
      "306:     assertEquals(0, errorLogs.size)",
      "308:     val acl5 = acl(topicName, ResourceType.TOPIC, PatternType.PREFIXED, user(\"alice\"))",
      "309:     val acl6 = acl(topicName, ResourceType.TOPIC, PatternType.PREFIXED, user(\"bob\"))",
      "310:     val acl7 = acl(otherName, ResourceType.TOPIC, PatternType.LITERAL, user(\"carol\"))",
      "311:     val acl8 = acl(otherName, ResourceType.TOPIC, PatternType.LITERAL, user(\"dave\"))",
      "314:     val delta2 = new MetadataDelta.Builder().setImage(image1).build()",
      "315:     delta2.replay(acl5)",
      "316:     delta2.replay(acl6)",
      "317:     delta2.replay(acl7)",
      "318:     delta2.replay(acl8)",
      "319:     delta2.replay(new RemoveAccessControlEntryRecord().setId(acl1.id()))",
      "321:     val image2 = delta2.apply(MetadataProvenance.EMPTY)",
      "322:     kraftMigrationZkWriter.handleDelta(image1, image2, delta2, (_, _, operation) => {",
      "323:       migrationState = operation.apply(migrationState)",
      "324:     })",
      "325:     assertEquals(3, zkClient.getVersionedAclsForResource(literalResource).acls.size)",
      "326:     assertEquals(2, zkClient.getVersionedAclsForResource(prefixedResource).acls.size)",
      "327:     assertEquals(2, zkClient.getVersionedAclsForResource(otherResource).acls.size)",
      "328:     assertEquals(0, errorLogs.size)",
      "331:     val acl9 = acl(otherName, ResourceType.TOPIC, PatternType.LITERAL, user(\"eve\"))",
      "332:     val delta3 = new MetadataDelta.Builder().setImage(image2).build()",
      "333:     delta3.replay(acl1)",
      "334:     delta3.replay(new RemoveAccessControlEntryRecord().setId(acl2.id()))",
      "335:     delta3.replay(new RemoveAccessControlEntryRecord().setId(acl5.id()))",
      "336:     delta3.replay(new RemoveAccessControlEntryRecord().setId(acl6.id()))",
      "337:     delta3.replay(acl9)",
      "339:     val image3 = delta3.apply(MetadataProvenance.EMPTY)",
      "340:     kraftMigrationZkWriter.handleDelta(image2, image3, delta3, (_, _, operation) => {",
      "341:       migrationState = operation.apply(migrationState)",
      "342:     })",
      "343:     assertEquals(3, zkClient.getVersionedAclsForResource(literalResource).acls.size)",
      "344:     assertEquals(0, zkClient.getVersionedAclsForResource(prefixedResource).acls.size)",
      "345:     assertEquals(3, zkClient.getVersionedAclsForResource(otherResource).acls.size)",
      "346:     assertEquals(0, errorLogs.size)",
      "347:   }",
      "",
      "---------------"
    ],
    "core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala": [
      "File: core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala -> core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala",
      "--- Hunk 1 ---",
      "[Context before]",
      "40: import org.apache.kafka.server.common.ApiMessageAndVersion",
      "41: import org.apache.kafka.server.config.ConfigType",
      "42: import org.apache.kafka.server.util.MockRandom",
      "44: import org.junit.jupiter.api.Test",
      "46: import java.util",
      "",
      "[Removed Lines]",
      "43: import org.junit.jupiter.api.Assertions.{assertEquals, assertTrue}",
      "",
      "[Added Lines]",
      "43: import org.junit.jupiter.api.Assertions.{assertEquals, assertTrue, fail}",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "326:     val image = delta.apply(MetadataProvenance.EMPTY)",
      "330:     kraftMigrationZkWriter.handleSnapshot(image, (_, _, operation) => {",
      "331:       migrationState = operation.apply(migrationState)",
      "332:     })",
      "",
      "[Removed Lines]",
      "329:     val kraftMigrationZkWriter = new KRaftMigrationZkWriter(migrationClient)",
      "",
      "[Added Lines]",
      "329:     val kraftMigrationZkWriter = new KRaftMigrationZkWriter(migrationClient, fail(_))",
      "",
      "---------------"
    ],
    "core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala": [
      "File: core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala -> core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala",
      "--- Hunk 1 ---",
      "[Context before]",
      "318:   @Test",
      "319:   def testTopicAndBrokerConfigsMigrationWithSnapshots(): Unit = {",
      "323:     val topicName = \"testTopic\"",
      "",
      "[Removed Lines]",
      "320:     val kraftWriter = new KRaftMigrationZkWriter(migrationClient)",
      "",
      "[Added Lines]",
      "320:     val kraftWriter = new KRaftMigrationZkWriter(migrationClient, fail(_))",
      "",
      "---------------"
    ],
    "metadata/src/main/java/org/apache/kafka/image/AclsDelta.java||metadata/src/main/java/org/apache/kafka/image/AclsDelta.java": [
      "File: metadata/src/main/java/org/apache/kafka/image/AclsDelta.java -> metadata/src/main/java/org/apache/kafka/image/AclsDelta.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "25: import org.apache.kafka.server.common.MetadataVersion;",
      "27: import java.util.HashMap;",
      "29: import java.util.LinkedHashMap;",
      "30: import java.util.Map;",
      "31: import java.util.Map.Entry;",
      "32: import java.util.Optional;",
      "34: import java.util.stream.Collectors;",
      "",
      "[Removed Lines]",
      "28: import java.util.HashSet;",
      "33: import java.util.Set;",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "40: public final class AclsDelta {",
      "41:     private final AclsImage image;",
      "42:     private final Map<Uuid, Optional<StandardAcl>> changes = new LinkedHashMap<>();",
      "45:     public AclsDelta(AclsImage image) {",
      "46:         this.image = image;",
      "",
      "[Removed Lines]",
      "43:     private final Set<StandardAcl> deleted = new HashSet<>();",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "56:         return changes;",
      "57:     }",
      "68:     void finishSnapshot() {",
      "69:         for (Entry<Uuid, StandardAcl> entry : image.acls().entrySet()) {",
      "70:             if (!changes.containsKey(entry.getKey())) {",
      "",
      "[Removed Lines]",
      "64:     public Set<StandardAcl> deleted() {",
      "65:         return deleted;",
      "66:     }",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "93:     public void replay(RemoveAccessControlEntryRecord record) {",
      "94:         if (image.acls().containsKey(record.id())) {",
      "95:             changes.put(record.id(), Optional.empty());",
      "97:         } else if (changes.containsKey(record.id())) {",
      "98:             changes.remove(record.id());",
      "",
      "[Removed Lines]",
      "96:             deleted.add(image.acls().get(record.id()));",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------"
    ],
    "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java": [
      "File: metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java -> metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "134:         this.time = time;",
      "135:         LogContext logContext = new LogContext(\"[KRaftMigrationDriver id=\" + nodeId + \"] \");",
      "136:         this.controllerMetrics = controllerMetrics;",
      "138:         this.migrationState = MigrationDriverState.UNINITIALIZED;",
      "139:         this.migrationLeadershipState = ZkMigrationLeadershipState.EMPTY;",
      "140:         this.eventQueue = new KafkaEventQueue(Time.SYSTEM, logContext, \"controller-\" + nodeId + \"-migration-driver-\");",
      "",
      "[Removed Lines]",
      "137:         this.log = logContext.logger(KRaftMigrationDriver.class);",
      "",
      "[Added Lines]",
      "137:         Logger log = logContext.logger(KRaftMigrationDriver.class);",
      "138:         this.log = log;",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "144:         this.initialZkLoadHandler = initialZkLoadHandler;",
      "145:         this.faultHandler = faultHandler;",
      "146:         this.quorumFeatures = quorumFeatures;",
      "148:         this.recordRedactor = new RecordRedactor(configSchema);",
      "149:         this.minBatchSize = minBatchSize;",
      "150:     }",
      "",
      "[Removed Lines]",
      "147:         this.zkMetadataWriter = new KRaftMigrationZkWriter(zkMigrationClient);",
      "",
      "[Added Lines]",
      "148:         this.zkMetadataWriter = new KRaftMigrationZkWriter(zkMigrationClient, log::error);",
      "",
      "---------------"
    ],
    "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java": [
      "File: metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java -> metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "60: import java.util.Optional;",
      "61: import java.util.Set;",
      "62: import java.util.function.BiConsumer;",
      "63: import java.util.function.Function;",
      "66: public class KRaftMigrationZkWriter {",
      "",
      "[Removed Lines]",
      "64: import java.util.stream.Collectors;",
      "",
      "[Added Lines]",
      "63: import java.util.function.Consumer;",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "84:     private final MigrationClient migrationClient;",
      "86:     public KRaftMigrationZkWriter(",
      "88:     ) {",
      "89:         this.migrationClient = migrationClient;",
      "90:     }",
      "92:     public void handleSnapshot(MetadataImage image, KRaftMigrationOperationConsumer operationConsumer) {",
      "",
      "[Removed Lines]",
      "87:         MigrationClient migrationClient",
      "",
      "[Added Lines]",
      "85:     private final Consumer<String> errorLogger;",
      "88:         MigrationClient migrationClient,",
      "89:         Consumer<String> errorLogger",
      "92:         this.errorLogger = errorLogger;",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "122:             updated = true;",
      "123:         }",
      "124:         if (delta.aclsDelta() != null) {",
      "126:             updated = true;",
      "127:         }",
      "128:         if (delta.delegationTokenDelta() != null) {",
      "",
      "[Removed Lines]",
      "125:             handleAclsDelta(image.acls(), delta.aclsDelta(), operationConsumer);",
      "",
      "[Added Lines]",
      "128:             handleAclsDelta(previousImage.acls(), image.acls(), delta.aclsDelta(), operationConsumer);",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "612:         });",
      "613:     }",
      "630:         Map<ResourcePattern, List<AccessControlEntry>> aclsToWrite = new HashMap<>();",
      "639:             }",
      "640:         });",
      "646:         });",
      "648:         aclsToWrite.forEach((resourcePattern, accessControlEntries) -> {",
      "652:         });",
      "653:     }",
      "",
      "[Removed Lines]",
      "615:     void handleAclsDelta(AclsImage image, AclsDelta delta, KRaftMigrationOperationConsumer operationConsumer) {",
      "617:         Set<ResourcePattern> resourcesWithChangedAcls = delta.changes().values()",
      "618:             .stream()",
      "619:             .filter(Optional::isPresent)",
      "620:             .map(Optional::get)",
      "621:             .map(this::resourcePatternFromAcl)",
      "622:             .collect(Collectors.toSet());",
      "624:         Set<ResourcePattern> resourcesWithDeletedAcls = delta.deleted()",
      "625:             .stream()",
      "626:             .map(this::resourcePatternFromAcl)",
      "627:             .collect(Collectors.toSet());",
      "631:         image.acls().forEach((uuid, standardAcl) -> {",
      "632:             ResourcePattern resourcePattern = resourcePatternFromAcl(standardAcl);",
      "633:             boolean removed = resourcesWithDeletedAcls.remove(resourcePattern);",
      "635:             if (resourcesWithChangedAcls.contains(resourcePattern) || removed) {",
      "636:                 aclsToWrite.computeIfAbsent(resourcePattern, __ -> new ArrayList<>()).add(",
      "637:                     new AccessControlEntry(standardAcl.principal(), standardAcl.host(), standardAcl.operation(), standardAcl.permissionType())",
      "638:                 );",
      "642:         resourcesWithDeletedAcls.forEach(deletedResource -> {",
      "643:             String name = \"Deleting resource \" + deletedResource + \" which has no more ACLs\";",
      "644:             operationConsumer.accept(DELETE_ACL, name, migrationState ->",
      "645:                 migrationClient.aclClient().deleteResource(deletedResource, migrationState));",
      "649:             String name = \"Writing \" + accessControlEntries.size() + \" for resource \" + resourcePattern;",
      "650:             operationConsumer.accept(UPDATE_ACL, name, migrationState ->",
      "651:                 migrationClient.aclClient().writeResourceAcls(resourcePattern, accessControlEntries, migrationState));",
      "",
      "[Added Lines]",
      "619:     void handleAclsDelta(AclsImage prevImage, AclsImage image, AclsDelta delta, KRaftMigrationOperationConsumer operationConsumer) {",
      "622:         delta.changes().forEach((aclId, aclChange) -> {",
      "623:             if (aclChange.isPresent()) {",
      "624:                 ResourcePattern resourcePattern = resourcePatternFromAcl(aclChange.get());",
      "625:                 aclsToWrite.put(resourcePattern, new ArrayList<>());",
      "626:             } else {",
      "628:                 StandardAcl deletedAcl = prevImage.acls().get(aclId);",
      "629:                 if (deletedAcl == null) {",
      "630:                     errorLogger.accept(\"Cannot delete ACL \" + aclId + \" from ZK since it is missing from previous AclImage\");",
      "631:                 } else {",
      "632:                     ResourcePattern resourcePattern = resourcePatternFromAcl(deletedAcl);",
      "633:                     aclsToWrite.put(resourcePattern, new ArrayList<>());",
      "634:                 }",
      "639:         image.acls().forEach((uuid, standardAcl) -> {",
      "640:             ResourcePattern resourcePattern = resourcePatternFromAcl(standardAcl);",
      "641:             List<AccessControlEntry> entries = aclsToWrite.get(resourcePattern);",
      "642:             if (entries != null) {",
      "643:                 entries.add(new AccessControlEntry(standardAcl.principal(), standardAcl.host(), standardAcl.operation(), standardAcl.permissionType()));",
      "644:             }",
      "649:             if (accessControlEntries.isEmpty()) {",
      "650:                 String name = \"Deleting resource \" + resourcePattern + \" which has no more ACLs\";",
      "651:                 operationConsumer.accept(DELETE_ACL, name, migrationState ->",
      "652:                     migrationClient.aclClient().deleteResource(resourcePattern, migrationState));",
      "653:             } else {",
      "654:                 String name = \"Writing \" + accessControlEntries.size() + \" for resource \" + resourcePattern;",
      "655:                 operationConsumer.accept(UPDATE_ACL, name, migrationState ->",
      "656:                     migrationClient.aclClient().writeResourceAcls(resourcePattern, accessControlEntries, migrationState));",
      "657:             }",
      "",
      "---------------"
    ],
    "metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriterTest.java||metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriterTest.java": [
      "File: metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriterTest.java -> metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriterTest.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "80:             .setConfigMigrationClient(configClient)",
      "81:             .build();",
      "85:         MetadataImage image = new MetadataImage(",
      "86:             MetadataProvenance.EMPTY,",
      "",
      "[Removed Lines]",
      "83:         KRaftMigrationZkWriter writer = new KRaftMigrationZkWriter(migrationClient);",
      "",
      "[Added Lines]",
      "83:         KRaftMigrationZkWriter writer = new KRaftMigrationZkWriter(migrationClient, __ -> { });",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "120:             .setAclMigrationClient(aclClient)",
      "121:             .build();",
      "125:         MetadataImage image = new MetadataImage(",
      "126:             MetadataProvenance.EMPTY,",
      "",
      "[Removed Lines]",
      "123:         KRaftMigrationZkWriter writer = new KRaftMigrationZkWriter(migrationClient);",
      "",
      "[Added Lines]",
      "123:         KRaftMigrationZkWriter writer = new KRaftMigrationZkWriter(migrationClient, __ -> { });",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "179:             .setAclMigrationClient(aclClient)",
      "180:             .build();",
      "184:         MetadataImage image = new MetadataImage(",
      "185:             MetadataProvenance.EMPTY,",
      "",
      "[Removed Lines]",
      "182:         KRaftMigrationZkWriter writer = new KRaftMigrationZkWriter(migrationClient);",
      "",
      "[Added Lines]",
      "182:         KRaftMigrationZkWriter writer = new KRaftMigrationZkWriter(migrationClient, __ -> { });",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "8aee314a4664bee46a351a21ec2ebb64a0d193e9",
      "candidate_info": {
        "commit_hash": "8aee314a4664bee46a351a21ec2ebb64a0d193e9",
        "repo": "apache/kafka",
        "commit_url": "https://github.com/apache/kafka/commit/8aee314a4664bee46a351a21ec2ebb64a0d193e9",
        "files": [
          "core/src/main/scala/kafka/zk/KafkaZkClient.scala",
          "core/src/test/scala/integration/kafka/zk/ZkMigrationFailoverTest.scala",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java",
          "tests/kafkatest/tests/core/zookeeper_migration_test.py"
        ],
        "message": "KAFKA-16667 Avoid stale read in KRaftMigrationDriver (#15918)\n\nWhen becoming the active KRaftMigrationDriver, there is another race condition similar to KAFKA-16171. This time, the race is due to a stale read from ZK. After writing to /controller and /controller_epoch, it is possible that a read on /migration is not linearized with the writes that were just made. In other words, we get a stale read on /migration. This leads to an inability to sync metadata to ZK due to incorrect zkVersion on the migration ZNode.\n\nThe non-linearizability of reads is in fact documented behavior for ZK, so we need to handle it.\n\nTo fix the stale read, this patch adds a write to /migration after updating /controller and /controller_epoch. This allows us to learn the correct zkVersion for the migration ZNode before leaving the BECOME_CONTROLLER state.\n\nThis patch also adds a check on the current leader epoch when running certain events in KRaftMigrationDriver. Historically, we did not include this check because it is not necessary for correctness. Writes to ZK are gated on the /controller_epoch zkVersion, and RPCs sent to brokers are gated on the controller epoch. However, during a time of rapid failover, there is a lot of processing happening on the controller (i.e., full metadata sync to ZK and full UMRs sent to brokers), so it is best to avoid running events we know will fail.\n\nThere is also a small fix in here to improve the logging of ZK operations. The log message are changed to past tense to reflect the fact that they have already happened by the time the log message is created.\n\nReviewers: Igor Soarez <soarez@apple.com>",
        "before_after_code_files": [
          "core/src/main/scala/kafka/zk/KafkaZkClient.scala||core/src/main/scala/kafka/zk/KafkaZkClient.scala",
          "core/src/test/scala/integration/kafka/zk/ZkMigrationFailoverTest.scala||core/src/test/scala/integration/kafka/zk/ZkMigrationFailoverTest.scala",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java",
          "tests/kafkatest/tests/core/zookeeper_migration_test.py||tests/kafkatest/tests/core/zookeeper_migration_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java",
            "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java"
          ],
          "candidate": [
            "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java",
            "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java"
          ]
        }
      },
      "candidate_diff": {
        "core/src/main/scala/kafka/zk/KafkaZkClient.scala||core/src/main/scala/kafka/zk/KafkaZkClient.scala": [
          "File: core/src/main/scala/kafka/zk/KafkaZkClient.scala -> core/src/main/scala/kafka/zk/KafkaZkClient.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "2043:                 case Some(value) =>",
          "2044:                   val failedPayload = MigrationZNode.decode(value, version, -1)",
          "2045:                   throw new RuntimeException(",
          "2047:                     s\"write was: $failedPayload. This indicates that another KRaft controller is making writes to ZooKeeper.\")",
          "2048:                 case None =>",
          "2050:                     s\"This indicates that another KRaft controller is making writes to ZooKeeper.\")",
          "2051:               }",
          "2052:             } else if (errorCode == Code.OK) {",
          "",
          "[Removed Lines]",
          "2046:                     s\"Conditional update on KRaft Migration ZNode failed. Expected zkVersion = $version. The failed \" +",
          "2049:                   throw new RuntimeException(s\"Check op on KRaft Migration ZNode failed. Expected zkVersion = $version. \" +",
          "",
          "[Added Lines]",
          "2046:                     s\"Conditional update on KRaft Migration ZNode failed. Sent zkVersion = $version. The failed \" +",
          "2049:                   throw new RuntimeException(s\"Check op on KRaft Migration ZNode failed. Sent zkVersion = $version. \" +",
          "",
          "---------------"
        ],
        "core/src/test/scala/integration/kafka/zk/ZkMigrationFailoverTest.scala||core/src/test/scala/integration/kafka/zk/ZkMigrationFailoverTest.scala": [
          "File: core/src/test/scala/integration/kafka/zk/ZkMigrationFailoverTest.scala -> core/src/test/scala/integration/kafka/zk/ZkMigrationFailoverTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: package kafka.zk",
          "19: import kafka.utils.{Logging, TestUtils}",
          "20: import org.apache.kafka.common.Uuid",
          "21: import org.apache.kafka.common.metadata.{FeatureLevelRecord, TopicRecord}",
          "22: import org.apache.kafka.common.utils.{Time, Utils}",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "20: import kafka.zk.migration.{ZkAclMigrationClient, ZkConfigMigrationClient, ZkDelegationTokenMigrationClient, ZkTopicMigrationClient}",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "25: import org.apache.kafka.image.loader.LogDeltaManifest",
          "26: import org.apache.kafka.image.publisher.MetadataPublisher",
          "27: import org.apache.kafka.image.{MetadataDelta, MetadataImage, MetadataProvenance}",
          "29: import org.apache.kafka.metadata.migration._",
          "30: import org.apache.kafka.raft.{LeaderAndEpoch, OffsetAndEpoch}",
          "31: import org.apache.kafka.security.PasswordEncoder",
          "32: import org.apache.kafka.server.common.{ApiMessageAndVersion, MetadataVersion}",
          "33: import org.apache.kafka.server.fault.FaultHandler",
          "34: import org.apache.zookeeper.client.ZKClientConfig",
          "36: import org.junit.jupiter.api.Test",
          "38: import java.util",
          "",
          "[Removed Lines]",
          "28: import org.apache.kafka.metadata.KafkaConfigSchema",
          "35: import org.junit.jupiter.api.Assertions.{assertTrue, fail}",
          "",
          "[Added Lines]",
          "29: import org.apache.kafka.metadata.{KafkaConfigSchema, PartitionRegistration}",
          "36: import org.junit.jupiter.api.Assertions.{assertTrue, assertEquals, fail}",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "72:     }",
          "73:   }",
          "75:   def buildMigrationDriver(nodeId: Int, zkMigrationClient: ZkMigrationClient): (KRaftMigrationDriver, CapturingFaultHandler) = {",
          "76:     val faultHandler = new CapturingFaultHandler(nodeId)",
          "77:     val driver = KRaftMigrationDriver.newBuilder",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "76:   class CapturingZkTopicMigrationClient(zkClient: KafkaZkClient) extends ZkTopicMigrationClient(zkClient) {",
          "77:     val createdTopics = mutable.Set[String]()",
          "78:     override def createTopic(",
          "79:       topicName: String,",
          "80:       topicId: Uuid,",
          "81:       partitions: util.Map[Integer, PartitionRegistration],",
          "82:       state: ZkMigrationLeadershipState",
          "83:     ): ZkMigrationLeadershipState = {",
          "84:       createdTopics.add(topicName)",
          "85:       super.createTopic(topicName, topicId, partitions, state)",
          "86:     }",
          "87:   }",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "269:     } finally {",
          "270:       driver1.close()",
          "271:       driver2.close()",
          "273:       zookeeper.shutdown()",
          "274:       if (zkClient != null) Utils.closeQuietly(zkClient, \"KafkaZkClient\")",
          "275:     }",
          "",
          "[Removed Lines]",
          "272:       Utils.closeQuietly(zookeeper, \"EmbeddedZookeeper\")",
          "",
          "[Added Lines]",
          "286:       zookeeper.shutdown()",
          "287:       if (zkClient != null) Utils.closeQuietly(zkClient, \"KafkaZkClient\")",
          "288:     }",
          "289:   }",
          "291:   @Test",
          "292:   def testDriverSkipsEventsFromOlderEpoch(): Unit = {",
          "293:     val zookeeper = new EmbeddedZookeeper()",
          "294:     var zkClient: KafkaZkClient = null",
          "295:     val zkConnect = s\"127.0.0.1:${zookeeper.port}\"",
          "296:     try {",
          "297:       zkClient = KafkaZkClient(",
          "298:         zkConnect,",
          "299:         isSecure = false,",
          "300:         30000,",
          "301:         60000,",
          "302:         1,",
          "303:         Time.SYSTEM,",
          "304:         name = \"ZkMigrationFailoverTest\",",
          "305:         new ZKClientConfig)",
          "306:     } catch {",
          "307:       case t: Throwable =>",
          "308:         zookeeper.shutdown()",
          "309:         if (zkClient != null) Utils.closeQuietly(zkClient, \"KafkaZkClient\")",
          "310:         throw t",
          "311:     }",
          "313:     val topicClient1 = new CapturingZkTopicMigrationClient(zkClient)",
          "314:     val topicClient2 = new CapturingZkTopicMigrationClient(zkClient)",
          "316:     def buildZkMigrationClient(topicClient: TopicMigrationClient): ZkMigrationClient = {",
          "317:       val configClient = new ZkConfigMigrationClient(zkClient, PasswordEncoder.NOOP)",
          "318:       val aclClient = new ZkAclMigrationClient(zkClient)",
          "319:       val delegationTokenClient = new ZkDelegationTokenMigrationClient(zkClient)",
          "320:       new ZkMigrationClient(zkClient, topicClient, configClient, aclClient, delegationTokenClient)",
          "321:     }",
          "323:     val zkMigrationClient1 = buildZkMigrationClient(topicClient1)",
          "324:     val zkMigrationClient2 = buildZkMigrationClient(topicClient2)",
          "326:     val (driver1, faultHandler1) = buildMigrationDriver(3000, zkMigrationClient1)",
          "327:     val (driver2, faultHandler2) = buildMigrationDriver(3001, zkMigrationClient2)",
          "330:     zkClient.registerControllerAndIncrementControllerEpoch(0)",
          "331:     var zkState = zkMigrationClient1.claimControllerLeadership(",
          "332:       ZkMigrationLeadershipState.EMPTY.withNewKRaftController(3000, 1)",
          "333:     )",
          "336:     zkState = zkState.withKRaftMetadataOffsetAndEpoch(100, 10)",
          "337:     zkState = zkMigrationClient1.getOrCreateMigrationRecoveryState(zkState)",
          "339:     try {",
          "340:       driver1.start()",
          "341:       driver2.start()",
          "343:       val leader1 = new LeaderAndEpoch(OptionalInt.of(3000), 2)",
          "344:       var image = MetadataImage.EMPTY",
          "345:       val delta = new MetadataDelta(image)",
          "346:       delta.replay(new FeatureLevelRecord()",
          "347:         .setName(MetadataVersion.FEATURE_NAME)",
          "348:         .setFeatureLevel(MetadataVersion.latestProduction().featureLevel))",
          "349:       delta.replay(ZkMigrationState.MIGRATION.toRecord.message)",
          "351:       val provenance = new MetadataProvenance(210, 11, 1)",
          "352:       image = delta.apply(provenance)",
          "354:       val manifest = LogDeltaManifest.newBuilder()",
          "355:         .provenance(provenance)",
          "356:         .leaderAndEpoch(leader1)",
          "357:         .numBatches(1)",
          "358:         .elapsedNs(100)",
          "359:         .numBytes(42)",
          "360:         .build()",
          "363:       driver1.onMetadataUpdate(delta, image, manifest)",
          "364:       driver1.onControllerChange(leader1)",
          "365:       driver2.onControllerChange(leader1)",
          "368:       TestUtils.waitUntilTrue(",
          "369:         () => safeGet(driver1.migrationState()).equals(MigrationDriverState.DUAL_WRITE),",
          "370:         \"waiting for driver to enter DUAL_WRITE\"",
          "371:       )",
          "374:       for (i <- 1 to 1000) {",
          "375:         val delta = new MetadataDelta(image)",
          "376:         delta.replay(new TopicRecord().setTopicId(Uuid.randomUuid()).setName(s\"topic-$i\"))",
          "377:         val provenance = new MetadataProvenance(210 + i, 11, 1)",
          "378:         image = delta.apply(provenance)",
          "379:         val manifest = LogDeltaManifest.newBuilder()",
          "380:           .provenance(provenance)",
          "381:           .leaderAndEpoch(leader1)",
          "382:           .numBatches(1)",
          "383:           .elapsedNs(100)",
          "384:           .numBytes(42)",
          "385:           .build()",
          "386:         driver1.onMetadataUpdate(delta, image, manifest)",
          "387:         driver2.onMetadataUpdate(delta, image, manifest)",
          "388:       }",
          "389:       Thread.sleep(50) // Give some events a chance to run",
          "391:       val leader2 = new LeaderAndEpoch(OptionalInt.of(3001), 3)",
          "392:       driver1.onControllerChange(leader2)",
          "394:       Thread.sleep(50) // Artificial delay for 3001 to see the leader change.",
          "395:       driver2.onControllerChange(leader2)",
          "398:       TestUtils.waitUntilTrue(() => zkClient.getControllerId match {",
          "399:         case Some(nodeId) => nodeId == 3001",
          "400:         case None => false",
          "401:       }, \"waiting for 3001 to claim ZK leadership\")",
          "403:       TestUtils.waitUntilTrue(() => {",
          "404:         val topics = zkClient.getAllTopicsInCluster(false)",
          "405:         topics.size == 1000",
          "406:       }, \"waiting for topics to be created in ZK.\")",
          "408:       assertTrue(topicClient1.createdTopics.nonEmpty, \"Expect first leader to write some topics\")",
          "409:       assertTrue(topicClient2.createdTopics.nonEmpty, \"Expect second leader to write some topics\")",
          "410:       assertEquals(1000, topicClient1.createdTopics.size + topicClient2.createdTopics.size,",
          "411:         \"Expect drivers to only write to ZK if they are the leader\")",
          "412:     } finally {",
          "413:       driver1.close()",
          "414:       driver2.close()",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java -> metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "115:     private volatile MetadataImage image;",
          "116:     private volatile boolean firstPublish;",
          "118:     KRaftMigrationDriver(",
          "119:         int nodeId,",
          "120:         ZkRecordConsumer zkRecordConsumer,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "120:     private volatile LeaderAndEpoch curLeaderAndEpoch;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "234:     private void applyMigrationOperation(String name, KRaftMigrationOperation migrationOp) {",
          "235:         ZkMigrationLeadershipState beforeState = this.migrationLeadershipState;",
          "236:         ZkMigrationLeadershipState afterState = migrationOp.apply(beforeState);",
          "239:         } else if (afterState.equals(beforeState)) {",
          "241:         } else {",
          "244:         }",
          "245:         this.migrationLeadershipState = afterState;",
          "246:     }",
          "",
          "[Removed Lines]",
          "237:         if (afterState.loggableChangeSinceState(beforeState)) {",
          "238:             log.info(\"{}. Transitioned migration state from {} to {}\", name, beforeState, afterState);",
          "240:             log.trace(\"{}. Kept migration state as {}\", name, afterState);",
          "242:             log.trace(\"{}. Transitioned migration state from {} to {}\", name, beforeState, afterState);",
          "",
          "[Added Lines]",
          "240:         applyMigrationOperation(name, migrationOp, false);",
          "241:     }",
          "243:     private void applyMigrationOperation(String name, KRaftMigrationOperation migrationOp, boolean alwaysLog) {",
          "245:         long startTimeNs = time.nanoseconds();",
          "247:         long durationNs = time.nanoseconds() - startTimeNs;",
          "248:         if (afterState.loggableChangeSinceState(beforeState) || alwaysLog) {",
          "249:             log.info(\"{} in {} ns. Transitioned migration state from {} to {}\",",
          "250:                 name, durationNs, beforeState, afterState);",
          "252:             log.trace(\"{} in {} ns. Kept migration state as {}\", name, durationNs, afterState);",
          "254:             log.trace(\"{} in {} ns. Transitioned migration state from {} to {}\",",
          "255:                 name, durationNs, beforeState, afterState);",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "291:         }",
          "292:     }",
          "294:     private boolean checkDriverState(MigrationDriverState expectedState, MigrationEvent migrationEvent) {",
          "298:             log.info(\"Expected driver state {} but found {}. Not running this event {}.\",",
          "300:             return false;",
          "301:         }",
          "302:     }",
          "",
          "[Removed Lines]",
          "295:         if (migrationState.equals(expectedState)) {",
          "296:             return true;",
          "297:         } else {",
          "299:                 expectedState, migrationState, migrationEvent.getClass().getSimpleName());",
          "",
          "[Added Lines]",
          "311:         if (migrationEvent instanceof MigrationWriteEvent) {",
          "312:             LeaderAndEpoch curLeaderAndEpoch = KRaftMigrationDriver.this.curLeaderAndEpoch;",
          "313:             LeaderAndEpoch eventLeaderAndEpoch = ((MigrationWriteEvent) migrationEvent).eventLeaderAndEpoch();",
          "314:             if (!eventLeaderAndEpoch.equals(curLeaderAndEpoch)) {",
          "315:                 log.info(\"Current leader epoch is {}, but event was created with epoch {}. Not running this event {}.\",",
          "316:                         curLeaderAndEpoch, eventLeaderAndEpoch, migrationEvent);",
          "317:                 return false;",
          "318:             }",
          "319:         }",
          "321:         if (!migrationState.equals(expectedState)) {",
          "323:                 expectedState, migrationState, migrationEvent);",
          "327:         return true;",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "333:     @Override",
          "334:     public void onControllerChange(LeaderAndEpoch newLeaderAndEpoch) {",
          "335:         eventQueue.append(new KRaftLeaderEvent(newLeaderAndEpoch));",
          "336:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "361:         curLeaderAndEpoch = newLeaderAndEpoch;",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "367:         boolean isSnapshot,",
          "368:         Consumer<Throwable> completionHandler",
          "369:     ) {",
          "370:         MetadataChangeEvent metadataChangeEvent = new MetadataChangeEvent(",
          "371:             delta,",
          "372:             newImage,",
          "373:             provenance,",
          "374:             isSnapshot,",
          "376:         );",
          "377:         eventQueue.append(metadataChangeEvent);",
          "378:     }",
          "",
          "[Removed Lines]",
          "375:             completionHandler",
          "",
          "[Added Lines]",
          "397:         LeaderAndEpoch eventLeaderAndEpoch = KRaftMigrationDriver.this.curLeaderAndEpoch;",
          "403:             completionHandler,",
          "404:             eventLeaderAndEpoch",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "399:         }",
          "400:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "436:     interface MigrationWriteEvent {",
          "440:         LeaderAndEpoch eventLeaderAndEpoch();",
          "441:     }",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "420:                 applyMigrationOperation(\"Became inactive migration driver\", state ->",
          "421:                     state.withNewKRaftController(",
          "422:                         leaderAndEpoch.leaderId().orElse(ZkMigrationLeadershipState.EMPTY.kraftControllerId()),",
          "424:                 );",
          "425:                 transitionTo(MigrationDriverState.INACTIVE);",
          "426:             } else {",
          "428:                 applyMigrationOperation(\"Became active migration driver\", state -> {",
          "429:                     ZkMigrationLeadershipState recoveredState = zkMigrationClient.getOrCreateMigrationRecoveryState(state);",
          "431:                 });",
          "",
          "[Removed Lines]",
          "423:                         leaderAndEpoch.epoch())",
          "430:                     return recoveredState.withNewKRaftController(nodeId, leaderAndEpoch.epoch());",
          "",
          "[Added Lines]",
          "464:                         leaderAndEpoch.epoch()",
          "465:                     ).withUnknownZkController()",
          "472:                     return recoveredState.withNewKRaftController(nodeId, leaderAndEpoch.epoch()).withUnknownZkController();",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "443:         private final MetadataProvenance provenance;",
          "444:         private final boolean isSnapshot;",
          "445:         private final Consumer<Throwable> completionHandler;",
          "447:         MetadataChangeEvent(",
          "448:                 MetadataDelta delta,",
          "449:                 MetadataImage image,",
          "450:                 MetadataProvenance provenance,",
          "451:                 boolean isSnapshot,",
          "453:         ) {",
          "454:             this.delta = delta;",
          "455:             this.image = image;",
          "456:             this.provenance = provenance;",
          "457:             this.isSnapshot = isSnapshot;",
          "458:             this.completionHandler = completionHandler;",
          "459:         }",
          "461:         @Override",
          "",
          "[Removed Lines]",
          "452:                 Consumer<Throwable> completionHandler",
          "",
          "[Added Lines]",
          "488:         private final LeaderAndEpoch leaderAndEpoch;",
          "495:                 Consumer<Throwable> completionHandler,",
          "496:                 LeaderAndEpoch leaderAndEpoch",
          "503:             this.leaderAndEpoch = leaderAndEpoch;",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "468:                 completionHandler.accept(null);",
          "469:                 return;",
          "470:             }",
          "472:             KRaftMigrationDriver.this.firstPublish = true;",
          "473:             MetadataImage prevImage = KRaftMigrationDriver.this.image;",
          "474:             KRaftMigrationDriver.this.image = image;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "516:             LeaderAndEpoch curLeaderAndEpoch = KRaftMigrationDriver.this.curLeaderAndEpoch;",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "483:             if (!migrationState.allowDualWrite()) {",
          "484:                 log.trace(\"Received metadata {}, but the controller is not in dual-write \" +",
          "486:                 completionHandler.accept(null);",
          "",
          "[Removed Lines]",
          "485:                         \"mode. Ignoring the change to be replicated to Zookeeper\", metadataType);",
          "",
          "[Added Lines]",
          "530:                     \"mode. Ignoring this metadata update.\", metadataType);",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "492:                 return;",
          "493:             }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "540:             if (!curLeaderAndEpoch.equals(leaderAndEpoch)) {",
          "541:                 log.trace(\"Received metadata {} with {}, but the current leader and epoch is {}.\" +",
          "542:                     \"Ignoring this metadata update.\", metadataType, leaderAndEpoch, curLeaderAndEpoch);",
          "543:                 completionHandler.accept(null);",
          "544:                 return;",
          "545:             }",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "535:             controllerMetrics.updateDualWriteOffset(image.highestOffsetAndEpoch().offset());",
          "540:             if (isSnapshot) {",
          "",
          "[Removed Lines]",
          "537:             applyMigrationOperation(\"Updating ZK migration state after \" + metadataType,",
          "538:                     state -> zkMigrationClient.setMigrationRecoveryState(zkStateAfterDualWrite));",
          "",
          "[Added Lines]",
          "589:             applyMigrationOperation(\"Updated ZK migration state after \" + metadataType,",
          "590:                 state -> zkMigrationClient.setMigrationRecoveryState(zkStateAfterDualWrite));",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "559:             completionHandler.accept(e);",
          "560:             super.handleException(e);",
          "561:         }",
          "562:     }",
          "564:     class WaitForControllerQuorumEvent extends MigrationEvent {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "615:         @Override",
          "616:         public String toString() {",
          "617:             return \"MetadataChangeEvent{\" +",
          "618:                 \"provenance=\" + provenance +",
          "619:                 \", isSnapshot=\" + isSnapshot +",
          "620:                 '}';",
          "621:         }",
          "",
          "---------------",
          "--- Hunk 14 ---",
          "[Context before]",
          "620:         }",
          "621:     }",
          "624:         @Override",
          "625:         public void run() throws Exception {",
          "626:             if (checkDriverState(MigrationDriverState.BECOME_CONTROLLER, this)) {",
          "628:                 if (migrationLeadershipState.zkControllerEpochZkVersion() == ZkMigrationLeadershipState.UNKNOWN_ZK_VERSION) {",
          "629:                     log.info(\"Unable to claim leadership, will retry until we learn of a different KRaft leader\");",
          "631:                 } else {",
          "648:                 }",
          "649:             }",
          "650:         }",
          "651:     }",
          "653:     private BufferingBatchConsumer<ApiMessageAndVersion> buildMigrationBatchConsumer(",
          "",
          "[Removed Lines]",
          "623:     class BecomeZkControllerEvent extends MigrationEvent {",
          "627:                 applyMigrationOperation(\"Claiming ZK controller leadership\", zkMigrationClient::claimControllerLeadership);",
          "632:                     if (!migrationLeadershipState.initialZkMigrationComplete()) {",
          "633:                         transitionTo(MigrationDriverState.ZK_MIGRATION);",
          "634:                     } else {",
          "637:                         applyMigrationOperation(\"Re-reading migration state\", state -> {",
          "638:                             ZkMigrationLeadershipState reloadedState =",
          "639:                                 zkMigrationClient.getOrCreateMigrationRecoveryState(ZkMigrationLeadershipState.EMPTY);",
          "640:                             return KRaftMigrationDriver.this.migrationLeadershipState",
          "641:                                 .withMigrationZkVersion(reloadedState.migrationZkVersion())",
          "642:                                 .withKRaftMetadataOffsetAndEpoch(",
          "643:                                     reloadedState.kraftMetadataOffset(),",
          "644:                                     reloadedState.kraftMetadataEpoch());",
          "645:                         });",
          "646:                         transitionTo(MigrationDriverState.SYNC_KRAFT_TO_ZK);",
          "647:                     }",
          "",
          "[Added Lines]",
          "683:     class BecomeZkControllerEvent extends MigrationEvent implements MigrationWriteEvent {",
          "684:         private final LeaderAndEpoch leaderAndEpoch;",
          "686:         BecomeZkControllerEvent(LeaderAndEpoch leaderAndEpoch) {",
          "687:             this.leaderAndEpoch = leaderAndEpoch;",
          "688:         }",
          "695:                 applyMigrationOperation(\"Claimed ZK controller leadership\", zkMigrationClient::claimControllerLeadership, true);",
          "698:                     return; // Stay in BECOME_CONTROLLER state and retry",
          "699:                 }",
          "705:                 applyMigrationOperation(\"Updated migration state\", state -> {",
          "707:                     state = state.withMigrationZkVersion(-1);",
          "708:                     return zkMigrationClient.setMigrationRecoveryState(state);",
          "709:                 });",
          "711:                 if (!migrationLeadershipState.initialZkMigrationComplete()) {",
          "712:                     transitionTo(MigrationDriverState.ZK_MIGRATION);",
          "714:                     transitionTo(MigrationDriverState.SYNC_KRAFT_TO_ZK);",
          "719:         @Override",
          "720:         public LeaderAndEpoch eventLeaderAndEpoch() {",
          "721:             return leaderAndEpoch;",
          "722:         }",
          "",
          "---------------",
          "--- Hunk 15 ---",
          "[Context before]",
          "673:         }, minBatchSize);",
          "674:     }",
          "677:         @Override",
          "678:         public void run() throws Exception {",
          "679:             if (!checkDriverState(MigrationDriverState.ZK_MIGRATION, this)) {",
          "",
          "[Removed Lines]",
          "676:     class MigrateMetadataEvent extends MigrationEvent {",
          "",
          "[Added Lines]",
          "748:     class MigrateMetadataEvent extends MigrationEvent implements MigrationWriteEvent {",
          "750:         private final LeaderAndEpoch leaderAndEpoch;",
          "752:         MigrateMetadataEvent(LeaderAndEpoch leaderAndEpoch) {",
          "753:             this.leaderAndEpoch = leaderAndEpoch;",
          "754:         }",
          "",
          "---------------",
          "--- Hunk 16 ---",
          "[Context before]",
          "715:                 ZkMigrationLeadershipState newState = migrationLeadershipState.withKRaftMetadataOffsetAndEpoch(",
          "716:                     offsetAndEpochAfterMigration.offset(),",
          "717:                     offsetAndEpochAfterMigration.epoch());",
          "",
          "[Removed Lines]",
          "718:                 applyMigrationOperation(\"Finished initial migration of ZK metadata to KRaft\", state -> zkMigrationClient.setMigrationRecoveryState(newState));",
          "",
          "[Added Lines]",
          "797:                 applyMigrationOperation(",
          "798:                     \"Finished initial migration of ZK metadata to KRaft\",",
          "799:                     state -> zkMigrationClient.setMigrationRecoveryState(newState),",
          "800:                     true",
          "801:                 );",
          "",
          "---------------",
          "--- Hunk 17 ---",
          "[Context before]",
          "727:                 super.handleException(t);",
          "728:             }",
          "729:         }",
          "730:     }",
          "733:         @Override",
          "734:         public void run() throws Exception {",
          "735:             if (checkDriverState(MigrationDriverState.SYNC_KRAFT_TO_ZK, this)) {",
          "",
          "[Removed Lines]",
          "732:     class SyncKRaftMetadataEvent extends MigrationEvent {",
          "",
          "[Added Lines]",
          "814:         @Override",
          "815:         public LeaderAndEpoch eventLeaderAndEpoch() {",
          "816:             return leaderAndEpoch;",
          "817:         }",
          "820:     class SyncKRaftMetadataEvent extends MigrationEvent implements MigrationWriteEvent {",
          "821:         private final LeaderAndEpoch leaderAndEpoch;",
          "823:         SyncKRaftMetadataEvent(LeaderAndEpoch leaderAndEpoch) {",
          "824:             this.leaderAndEpoch = leaderAndEpoch;",
          "825:         }",
          "",
          "---------------",
          "--- Hunk 18 ---",
          "[Context before]",
          "747:                     dualWriteCounts, KRaftMigrationDriver.this::applyMigrationOperation));",
          "748:                 long endTime = time.nanoseconds();",
          "749:                 controllerMetrics.updateZkWriteSnapshotTimeMs(NANOSECONDS.toMillis(startTime - endTime));",
          "751:                 transitionTo(MigrationDriverState.KRAFT_CONTROLLER_TO_BROKER_COMM);",
          "752:             }",
          "753:         }",
          "754:     }",
          "758:         @Override",
          "759:         public void run() throws Exception {",
          "",
          "[Removed Lines]",
          "750:                 log.info(\"Made the following ZK writes when reconciling with KRaft state: {}\", dualWriteCounts);",
          "756:     class SendRPCsToBrokersEvent extends MigrationEvent {",
          "",
          "[Added Lines]",
          "844:                 if (dualWriteCounts.isEmpty()) {",
          "845:                     log.info(\"Did not make any ZK writes when reconciling with KRaft state.\");",
          "846:                 } else {",
          "847:                     log.info(\"Made the following ZK writes when reconciling with KRaft state: {}\", dualWriteCounts);",
          "848:                 }",
          "853:         @Override",
          "854:         public LeaderAndEpoch eventLeaderAndEpoch() {",
          "855:             return leaderAndEpoch;",
          "856:         }",
          "859:     class SendRPCsToBrokersEvent extends MigrationEvent implements MigrationWriteEvent {",
          "861:         private final LeaderAndEpoch leaderAndEpoch;",
          "863:         SendRPCsToBrokersEvent(LeaderAndEpoch leaderAndEpoch) {",
          "864:             this.leaderAndEpoch = leaderAndEpoch;",
          "865:         }",
          "",
          "---------------",
          "--- Hunk 19 ---",
          "[Context before]",
          "772:                 }",
          "773:             }",
          "774:         }",
          "775:     }",
          "777:     class RecoverMigrationStateFromZKEvent extends MigrationEvent {",
          "778:         @Override",
          "779:         public void run() throws Exception {",
          "780:             if (checkDriverState(MigrationDriverState.UNINITIALIZED, this)) {",
          "782:                 String maybeDone = migrationLeadershipState.initialZkMigrationComplete() ? \"done\" : \"not done\";",
          "783:                 log.info(\"Initial migration of ZK metadata is {}.\", maybeDone);",
          "",
          "[Removed Lines]",
          "781:                 applyMigrationOperation(\"Recovering migration state from ZK\", zkMigrationClient::getOrCreateMigrationRecoveryState);",
          "",
          "[Added Lines]",
          "885:         @Override",
          "886:         public LeaderAndEpoch eventLeaderAndEpoch() {",
          "887:             return leaderAndEpoch;",
          "888:         }",
          "895:                 applyMigrationOperation(\"Recovered migration state from ZK\", zkMigrationClient::getOrCreateMigrationRecoveryState);",
          "",
          "---------------",
          "--- Hunk 20 ---",
          "[Context before]",
          "797:         @Override",
          "798:         public void run() throws Exception {",
          "799:             switch (migrationState) {",
          "800:                 case UNINITIALIZED:",
          "801:                     eventQueue.append(new RecoverMigrationStateFromZKEvent());",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "913:             LeaderAndEpoch eventLeaderAndEpoch = KRaftMigrationDriver.this.curLeaderAndEpoch;",
          "",
          "---------------",
          "--- Hunk 21 ---",
          "[Context before]",
          "811:                     eventQueue.append(new WaitForZkBrokersEvent());",
          "812:                     break;",
          "813:                 case BECOME_CONTROLLER:",
          "815:                     break;",
          "816:                 case ZK_MIGRATION:",
          "818:                     break;",
          "819:                 case SYNC_KRAFT_TO_ZK:",
          "821:                     break;",
          "822:                 case KRAFT_CONTROLLER_TO_BROKER_COMM:",
          "824:                     break;",
          "825:                 case DUAL_WRITE:",
          "",
          "[Removed Lines]",
          "814:                     eventQueue.append(new BecomeZkControllerEvent());",
          "817:                     eventQueue.append(new MigrateMetadataEvent());",
          "820:                     eventQueue.append(new SyncKRaftMetadataEvent());",
          "823:                     eventQueue.append(new SendRPCsToBrokersEvent());",
          "",
          "[Added Lines]",
          "929:                     eventQueue.append(new BecomeZkControllerEvent(eventLeaderAndEpoch));",
          "932:                     eventQueue.append(new MigrateMetadataEvent(eventLeaderAndEpoch));",
          "935:                     eventQueue.append(new SyncKRaftMetadataEvent(eventLeaderAndEpoch));",
          "938:                     eventQueue.append(new SendRPCsToBrokersEvent(eventLeaderAndEpoch));",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java -> metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "154:         if (!pendingTopicDeletions.isEmpty()) {",
          "155:             operationConsumer.accept(",
          "156:                 DELETE_PENDING_TOPIC_DELETION,",
          "158:                 migrationState -> migrationClient.topicClient().clearPendingTopicDeletions(pendingTopicDeletions, migrationState)",
          "159:             );",
          "160:         }",
          "",
          "[Removed Lines]",
          "157:                 \"Delete pending topic deletions\",",
          "",
          "[Added Lines]",
          "157:                 \"Deleted pending topic deletions\",",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "229:             TopicImage topic = topicsImage.getTopic(topicId);",
          "230:             operationConsumer.accept(",
          "231:                 CREATE_TOPIC,",
          "233:                 migrationState -> migrationClient.topicClient().createTopic(topic.name(), topicId, topic.partitions(), migrationState)",
          "234:             );",
          "235:         });",
          "",
          "[Removed Lines]",
          "232:                 \"Create Topic \" + topic.name() + \", ID \" + topicId,",
          "",
          "[Added Lines]",
          "232:                 \"Created Topic \" + topic.name() + \", ID \" + topicId,",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "246:         deletedTopics.forEach((topicId, topicName) -> {",
          "247:             operationConsumer.accept(",
          "248:                 DELETE_TOPIC,",
          "250:                 migrationState -> migrationClient.topicClient().deleteTopic(topicName, migrationState)",
          "251:             );",
          "252:             ConfigResource resource = new ConfigResource(ConfigResource.Type.TOPIC, topicName);",
          "",
          "[Removed Lines]",
          "249:                 \"Delete Topic \" + topicName + \", ID \" + topicId,",
          "",
          "[Added Lines]",
          "249:                 \"Deleted Topic \" + topicName + \", ID \" + topicId,",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "256:             TopicImage topic = topicsImage.getTopic(topicId);",
          "257:             operationConsumer.accept(",
          "258:                 UPDATE_PARTITION,",
          "260:                 migrationState -> migrationClient.topicClient().updateTopicPartitions(",
          "261:                     Collections.singletonMap(topic.name(), partitionMap),",
          "262:                     migrationState));",
          "",
          "[Removed Lines]",
          "259:                 \"Creating additional partitions for Topic \" + topic.name() + \", ID \" + topicId,",
          "",
          "[Added Lines]",
          "259:                 \"Created additional partitions for Topic \" + topic.name() + \", ID \" + topicId,",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "266:             TopicImage topic = topicsImage.getTopic(topicId);",
          "267:             operationConsumer.accept(",
          "268:                 UPDATE_PARTITION,",
          "270:                 migrationState -> migrationClient.topicClient().updateTopicPartitions(",
          "271:                     Collections.singletonMap(topic.name(), partitionMap),",
          "272:                     migrationState));",
          "",
          "[Removed Lines]",
          "269:                 \"Updating Partitions for Topic \" + topic.name() + \", ID \" + topicId,",
          "",
          "[Added Lines]",
          "269:                 \"Updated Partitions for Topic \" + topic.name() + \", ID \" + topicId,",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "275:         extraneousPartitionsInZk.forEach((topicName, partitions) -> {",
          "276:             operationConsumer.accept(",
          "277:                 DELETE_PARTITION,",
          "279:                 migrationState -> migrationClient.topicClient().deleteTopicPartitions(",
          "280:                     Collections.singletonMap(topicName, partitions),",
          "281:                     migrationState));",
          "",
          "[Removed Lines]",
          "278:                 \"Deleting extraneous Partitions \" + partitions + \" for Topic \" + topicName,",
          "",
          "[Added Lines]",
          "278:                 \"Deleted extraneous Partitions \" + partitions + \" for Topic \" + topicName,",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "290:     ) {",
          "291:         topicsDelta.deletedTopicIds().forEach(topicId -> {",
          "292:             String name = deletedTopicNameResolver.apply(topicId);",
          "294:                 migrationState -> migrationClient.topicClient().deleteTopic(name, migrationState));",
          "295:         });",
          "",
          "[Removed Lines]",
          "293:             operationConsumer.accept(DELETE_TOPIC, \"Deleting topic \" + name + \", ID \" + topicId,",
          "",
          "[Added Lines]",
          "293:             operationConsumer.accept(DELETE_TOPIC, \"Deleted topic \" + name + \", ID \" + topicId,",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "298:             if (topicsDelta.createdTopicIds().contains(topicId)) {",
          "299:                 operationConsumer.accept(",
          "300:                     CREATE_TOPIC,",
          "302:                     migrationState -> migrationClient.topicClient().createTopic(",
          "303:                         topicDelta.name(),",
          "304:                         topicId,",
          "",
          "[Removed Lines]",
          "301:                     \"Create Topic \" + topicDelta.name() + \", ID \" + topicId,",
          "",
          "[Added Lines]",
          "301:                     \"Created Topic \" + topicDelta.name() + \", ID \" + topicId,",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "308:                 if (topicDelta.hasPartitionsWithAssignmentChanges())",
          "309:                     operationConsumer.accept(",
          "310:                         UPDATE_TOPIC,",
          "312:                         migrationState -> migrationClient.topicClient().updateTopic(",
          "313:                             topicDelta.name(),",
          "314:                             topicId,",
          "",
          "[Removed Lines]",
          "311:                         \"Updating Topic \" + topicDelta.name() + \", ID \" + topicId,",
          "",
          "[Added Lines]",
          "311:                         \"Updated Topic \" + topicDelta.name() + \", ID \" + topicId,",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "319:                 if (!newPartitions.isEmpty()) {",
          "320:                     operationConsumer.accept(",
          "321:                         UPDATE_PARTITION,",
          "323:                         migrationState -> migrationClient.topicClient().createTopicPartitions(",
          "324:                             Collections.singletonMap(topicDelta.name(), newPartitions),",
          "325:                             migrationState));",
          "",
          "[Removed Lines]",
          "322:                         \"Create new partitions for Topic \" + topicDelta.name() + \", ID \" + topicId,",
          "",
          "[Added Lines]",
          "322:                         \"Created new partitions for Topic \" + topicDelta.name() + \", ID \" + topicId,",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "330:                     final Map<Integer, PartitionRegistration> finalChangedPartitions = changedPartitions;",
          "331:                     operationConsumer.accept(",
          "332:                         UPDATE_PARTITION,",
          "334:                         migrationState -> migrationClient.topicClient().updateTopicPartitions(",
          "335:                             Collections.singletonMap(topicDelta.name(), finalChangedPartitions),",
          "336:                             migrationState));",
          "",
          "[Removed Lines]",
          "333:                         \"Updating Partitions for Topic \" + topicDelta.name() + \", ID \" + topicId,",
          "",
          "[Added Lines]",
          "333:                         \"Updated Partitions for Topic \" + topicDelta.name() + \", ID \" + topicId,",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "378:             Map<String, String> props = configsImage.configMapForResource(resource);",
          "379:             if (!props.isEmpty()) {",
          "380:                 String opType = brokerOrTopicOpType(resource, UPDATE_BROKER_CONFIG, UPDATE_TOPIC_CONFIG);",
          "382:                     migrationState -> migrationClient.configClient().writeConfigs(resource, props, migrationState));",
          "383:             }",
          "384:         });",
          "",
          "[Removed Lines]",
          "381:                 operationConsumer.accept(opType, \"Create configs for \" + resource.type().name() + \" \" + resource.name(),",
          "",
          "[Added Lines]",
          "381:                 operationConsumer.accept(opType, \"Created configs for \" + resource.type().name() + \" \" + resource.name(),",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "387:             Map<String, String> props = configsImage.configMapForResource(resource);",
          "388:             if (props.isEmpty()) {",
          "389:                 String opType = brokerOrTopicOpType(resource, DELETE_BROKER_CONFIG, DELETE_TOPIC_CONFIG);",
          "391:                     migrationState -> migrationClient.configClient().deleteConfigs(resource, migrationState));",
          "392:             } else {",
          "393:                 String opType = brokerOrTopicOpType(resource, UPDATE_BROKER_CONFIG, UPDATE_TOPIC_CONFIG);",
          "395:                     migrationState -> migrationClient.configClient().writeConfigs(resource, props, migrationState));",
          "396:             }",
          "397:         });",
          "",
          "[Removed Lines]",
          "390:                 operationConsumer.accept(opType, \"Delete configs for \" + resource.type().name() + \" \" + resource.name(),",
          "394:                 operationConsumer.accept(opType, \"Update configs for \" + resource.type().name() + \" \" + resource.name(),",
          "",
          "[Added Lines]",
          "390:                 operationConsumer.accept(opType, \"Deleted configs for \" + resource.type().name() + \" \" + resource.name(),",
          "394:                 operationConsumer.accept(opType, \"Updated configs for \" + resource.type().name() + \" \" + resource.name(),",
          "",
          "---------------",
          "--- Hunk 14 ---",
          "[Context before]",
          "465:         changedNonUserEntities.forEach(entity -> {",
          "466:             Map<String, Double> quotaMap = clientQuotasImage.entities().getOrDefault(entity, ClientQuotaImage.EMPTY).quotaMap();",
          "468:                 migrationClient.configClient().writeClientQuotas(entity.entries(), quotaMap, Collections.emptyMap(), migrationState));",
          "469:         });",
          "",
          "[Removed Lines]",
          "467:             opConsumer.accept(UPDATE_CLIENT_QUOTA, \"Update client quotas for \" + entity, migrationState ->",
          "",
          "[Added Lines]",
          "467:             opConsumer.accept(UPDATE_CLIENT_QUOTA, \"Updated client quotas for \" + entity, migrationState ->",
          "",
          "---------------",
          "--- Hunk 15 ---",
          "[Context before]",
          "473:             Map<String, Double> quotaMap = clientQuotasImage.entities().",
          "474:                 getOrDefault(entity, ClientQuotaImage.EMPTY).quotaMap();",
          "475:             Map<String, String> scramMap = getScramCredentialStringsForUser(scramImage, userName);",
          "477:                 migrationClient.configClient().writeClientQuotas(entity.entries(), quotaMap, scramMap, migrationState));",
          "478:         });",
          "479:     }",
          "",
          "[Removed Lines]",
          "476:             opConsumer.accept(UPDATE_CLIENT_QUOTA, \"Update client quotas for \" + userName, migrationState ->",
          "",
          "[Added Lines]",
          "476:             opConsumer.accept(UPDATE_CLIENT_QUOTA, \"Updated client quotas for \" + userName, migrationState ->",
          "",
          "---------------",
          "--- Hunk 16 ---",
          "[Context before]",
          "486:         Optional<ProducerIdsBlock> zkProducerId = migrationClient.readProducerId();",
          "487:         if (zkProducerId.isPresent()) {",
          "488:             if (zkProducerId.get().nextBlockFirstId() != image.nextProducerId()) {",
          "490:                     migrationClient.writeProducerId(image.nextProducerId(), migrationState));",
          "491:             }",
          "492:         } else {",
          "494:                 migrationClient.writeProducerId(image.nextProducerId(), migrationState));",
          "495:         }",
          "496:     }",
          "",
          "[Removed Lines]",
          "489:                 operationConsumer.accept(UPDATE_PRODUCER_ID, \"Setting next producer ID\", migrationState ->",
          "493:             operationConsumer.accept(UPDATE_PRODUCER_ID, \"Setting next producer ID\", migrationState ->",
          "",
          "[Added Lines]",
          "489:                 operationConsumer.accept(UPDATE_PRODUCER_ID, \"Set next producer ID\", migrationState ->",
          "493:             operationConsumer.accept(UPDATE_PRODUCER_ID, \"Set next producer ID\", migrationState ->",
          "",
          "---------------",
          "--- Hunk 17 ---",
          "[Context before]",
          "500:         updatedResources.forEach(configResource -> {",
          "501:             Map<String, String> props = configsImage.configMapForResource(configResource);",
          "502:             if (props.isEmpty()) {",
          "504:                     migrationClient.configClient().deleteConfigs(configResource, migrationState));",
          "505:             } else {",
          "507:                     migrationClient.configClient().writeConfigs(configResource, props, migrationState));",
          "508:             }",
          "509:         });",
          "",
          "[Removed Lines]",
          "503:                 operationConsumer.accept(\"DeleteConfig\", \"Delete configs for \" + configResource, migrationState ->",
          "506:                 operationConsumer.accept(\"UpdateConfig\", \"Update configs for \" + configResource, migrationState ->",
          "",
          "[Added Lines]",
          "503:                 operationConsumer.accept(\"DeleteConfig\", \"Deleted configs for \" + configResource, migrationState ->",
          "506:                 operationConsumer.accept(\"UpdateConfig\", \"Updated configs for \" + configResource, migrationState ->",
          "",
          "---------------",
          "--- Hunk 18 ---",
          "[Context before]",
          "532:                         users.add(userName);",
          "533:                     } else {",
          "534:                         Map<String, Double> quotaMap = metadataImage.clientQuotas().entities().get(clientQuotaEntity).quotaMap();",
          "536:                             migrationClient.configClient().writeClientQuotas(clientQuotaEntity.entries(), quotaMap, Collections.emptyMap(), migrationState));",
          "537:                     }",
          "538:                 });",
          "",
          "[Removed Lines]",
          "535:                         operationConsumer.accept(UPDATE_CLIENT_QUOTA, \"Updating client quota \" + clientQuotaEntity, migrationState ->",
          "",
          "[Added Lines]",
          "535:                         operationConsumer.accept(UPDATE_CLIENT_QUOTA, \"Updated client quota \" + clientQuotaEntity, migrationState ->",
          "",
          "---------------",
          "--- Hunk 19 ---",
          "[Context before]",
          "544:                 ClientQuotaEntity clientQuotaEntity = new ClientQuotaEntity(Collections.singletonMap(ClientQuotaEntity.USER, userName));",
          "545:                 if ((metadataImage.clientQuotas() == null) ||",
          "546:                     (metadataImage.clientQuotas().entities().get(clientQuotaEntity) == null)) {",
          "548:                         migrationClient.configClient().writeClientQuotas(clientQuotaEntity.entries(), Collections.emptyMap(), userScramMap, migrationState));",
          "549:                 } else {",
          "550:                     Map<String, Double> quotaMap = metadataImage.clientQuotas().entities().get(clientQuotaEntity).quotaMap();",
          "552:                         migrationClient.configClient().writeClientQuotas(clientQuotaEntity.entries(), quotaMap, userScramMap, migrationState));",
          "553:                 }",
          "554:             });",
          "",
          "[Removed Lines]",
          "547:                     operationConsumer.accept(UPDATE_CLIENT_QUOTA, \"Updating scram credentials for \" + clientQuotaEntity, migrationState ->",
          "551:                     operationConsumer.accept(UPDATE_CLIENT_QUOTA, \"Updating client quota for \" + clientQuotaEntity, migrationState ->",
          "",
          "[Added Lines]",
          "547:                     operationConsumer.accept(UPDATE_CLIENT_QUOTA, \"Updated scram credentials for \" + clientQuotaEntity, migrationState ->",
          "551:                     operationConsumer.accept(UPDATE_CLIENT_QUOTA, \"Updated client quota for \" + clientQuotaEntity, migrationState ->",
          "",
          "---------------",
          "--- Hunk 20 ---",
          "[Context before]",
          "556:     }",
          "558:     void handleProducerIdDelta(ProducerIdsDelta delta, KRaftMigrationOperationConsumer operationConsumer) {",
          "560:             migrationClient.writeProducerId(delta.nextProducerId(), migrationState));",
          "561:     }",
          "",
          "[Removed Lines]",
          "559:         operationConsumer.accept(UPDATE_PRODUCER_ID, \"Setting next producer ID\", migrationState ->",
          "",
          "[Added Lines]",
          "559:         operationConsumer.accept(UPDATE_PRODUCER_ID, \"Set next producer ID\", migrationState ->",
          "",
          "---------------",
          "--- Hunk 21 ---",
          "[Context before]",
          "593:         newResources.forEach(resourcePattern -> {",
          "595:             Set<AccessControlEntry> accessControlEntries = allAclsInSnapshot.get(resourcePattern);",
          "598:                 migrationClient.aclClient().writeResourceAcls(resourcePattern, accessControlEntries, migrationState));",
          "599:         });",
          "601:         resourcesToDelete.forEach(deletedResource -> {",
          "604:                 migrationClient.aclClient().deleteResource(deletedResource, migrationState));",
          "605:         });",
          "607:         changedResources.forEach((resourcePattern, accessControlEntries) -> {",
          "610:                 migrationClient.aclClient().writeResourceAcls(resourcePattern, accessControlEntries, migrationState));",
          "611:         });",
          "612:     }",
          "",
          "[Removed Lines]",
          "596:             String name = \"Writing \" + accessControlEntries.size() + \" for resource \" + resourcePattern;",
          "597:             operationConsumer.accept(UPDATE_ACL, name, migrationState ->",
          "602:             String name = \"Deleting resource \" + deletedResource + \" which has no ACLs in snapshot\";",
          "603:             operationConsumer.accept(DELETE_ACL, name, migrationState ->",
          "608:             String name = \"Writing \" + accessControlEntries.size() + \" for resource \" + resourcePattern;",
          "609:             operationConsumer.accept(UPDATE_ACL, name, migrationState ->",
          "",
          "[Added Lines]",
          "596:             String logMsg = \"Wrote \" + accessControlEntries.size() + \" for resource \" + resourcePattern;",
          "597:             operationConsumer.accept(UPDATE_ACL, logMsg, migrationState ->",
          "602:             String logMsg = \"Deleted resource \" + deletedResource + \" which has no ACLs in snapshot\";",
          "603:             operationConsumer.accept(DELETE_ACL, logMsg, migrationState ->",
          "608:             String logMsg = \"Wrote \" + accessControlEntries.size() + \" for resource \" + resourcePattern;",
          "609:             operationConsumer.accept(UPDATE_ACL, logMsg, migrationState ->",
          "",
          "---------------",
          "--- Hunk 22 ---",
          "[Context before]",
          "643:         aclsToWrite.forEach((resourcePattern, accessControlEntries) -> {",
          "644:             if (accessControlEntries.isEmpty()) {",
          "647:                     migrationClient.aclClient().deleteResource(resourcePattern, migrationState));",
          "648:             } else {",
          "651:                     migrationClient.aclClient().writeResourceAcls(resourcePattern, accessControlEntries, migrationState));",
          "652:             }",
          "653:         });",
          "",
          "[Removed Lines]",
          "645:                 String name = \"Deleting resource \" + resourcePattern + \" which has no more ACLs\";",
          "646:                 operationConsumer.accept(DELETE_ACL, name, migrationState ->",
          "649:                 String name = \"Writing \" + accessControlEntries.size() + \" for resource \" + resourcePattern;",
          "650:                 operationConsumer.accept(UPDATE_ACL, name, migrationState ->",
          "",
          "[Added Lines]",
          "645:                 String logMsg = \"Deleted resource \" + resourcePattern + \" which has no more ACLs\";",
          "646:                 operationConsumer.accept(DELETE_ACL, logMsg, migrationState ->",
          "649:                 String logMsg = \"Wrote \" + accessControlEntries.size() + \" for resource \" + resourcePattern;",
          "650:                 operationConsumer.accept(UPDATE_ACL, logMsg, migrationState ->",
          "",
          "---------------",
          "--- Hunk 23 ---",
          "[Context before]",
          "658:         updatedTokens.forEach(tokenId -> {",
          "659:             DelegationTokenData tokenData = image.tokens().get(tokenId);",
          "660:             if (tokenData == null) {",
          "662:                     migrationClient.delegationTokenClient().deleteDelegationToken(tokenId, migrationState));",
          "663:             } else {",
          "665:                     migrationClient.delegationTokenClient().writeDelegationToken(tokenId, tokenData.tokenInformation(), migrationState));",
          "666:             }",
          "667:         });",
          "",
          "[Removed Lines]",
          "661:                 operationConsumer.accept(\"DeleteDelegationToken\", \"Delete DelegationToken for \" + tokenId, migrationState ->",
          "664:                 operationConsumer.accept(\"UpdateDelegationToken\", \"Update DelegationToken for \" + tokenId, migrationState ->",
          "",
          "[Added Lines]",
          "661:                 operationConsumer.accept(\"DeleteDelegationToken\", \"Deleted DelegationToken for \" + tokenId, migrationState ->",
          "664:                 operationConsumer.accept(\"UpdateDelegationToken\", \"Updated DelegationToken for \" + tokenId, migrationState ->",
          "",
          "---------------",
          "--- Hunk 24 ---",
          "[Context before]",
          "670:     void handleDelegationTokenSnapshot(DelegationTokenImage image, KRaftMigrationOperationConsumer operationConsumer) {",
          "671:         image.tokens().keySet().forEach(tokenId -> {",
          "672:             DelegationTokenData tokenData = image.tokens().get(tokenId);",
          "674:                 migrationClient.delegationTokenClient().writeDelegationToken(tokenId, tokenData.tokenInformation(), migrationState));",
          "675:         });",
          "677:         List<String> tokens = migrationClient.delegationTokenClient().getDelegationTokens();",
          "678:         tokens.forEach(tokenId -> {",
          "679:             if (!image.tokens().containsKey(tokenId)) {",
          "681:                     migrationClient.delegationTokenClient().deleteDelegationToken(tokenId, migrationState));",
          "682:             }",
          "683:         });",
          "",
          "[Removed Lines]",
          "673:             operationConsumer.accept(\"UpdateDelegationToken\", \"Update DelegationToken for \" + tokenId, migrationState ->",
          "680:                 operationConsumer.accept(\"DeleteDelegationToken\", \"Delete DelegationToken for \" + tokenId, migrationState ->",
          "",
          "[Added Lines]",
          "673:             operationConsumer.accept(\"UpdateDelegationToken\", \"Updated DelegationToken for \" + tokenId, migrationState ->",
          "680:                 operationConsumer.accept(\"DeleteDelegationToken\", \"Deleted DelegationToken for \" + tokenId, migrationState ->",
          "",
          "---------------"
        ],
        "tests/kafkatest/tests/core/zookeeper_migration_test.py||tests/kafkatest/tests/core/zookeeper_migration_test.py": [
          "File: tests/kafkatest/tests/core/zookeeper_migration_test.py -> tests/kafkatest/tests/core/zookeeper_migration_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "204:         assert saw_expected_error, \"Did not see expected ERROR log in the controller logs\"",
          "284:     @cluster(num_nodes=5)",
          "285:     def test_reconcile_kraft_to_zk(self):",
          "286:         \"\"\"",
          "",
          "[Removed Lines]",
          "206:     @cluster(num_nodes=5)",
          "207:     def test_upgrade_after_3_4_migration(self):",
          "208:         \"\"\"",
          "209:         Perform a migration on version 3.4.0. Then do a rolling upgrade to 3.5+ and ensure we see",
          "210:         the correct migration state in the log.",
          "211:         \"\"\"",
          "212:         zk_quorum = partial(ServiceQuorumInfo, zk)",
          "213:         self.zk = ZookeeperService(self.test_context, num_nodes=1, version=LATEST_3_4)",
          "214:         self.kafka = KafkaService(self.test_context,",
          "215:                                   num_nodes=3,",
          "216:                                   zk=self.zk,",
          "217:                                   version=LATEST_3_4,",
          "218:                                   quorum_info_provider=zk_quorum,",
          "219:                                   allow_zk_with_kraft=True,",
          "220:                                   server_prop_overrides=[",
          "221:                                       [\"zookeeper.metadata.migration.enable\", \"true\"],",
          "222:                                   ])",
          "224:         remote_quorum = partial(ServiceQuorumInfo, isolated_kraft)",
          "225:         controller = KafkaService(self.test_context, num_nodes=1, zk=self.zk, version=LATEST_3_4,",
          "226:                                   allow_zk_with_kraft=True,",
          "227:                                   isolated_kafka=self.kafka,",
          "228:                                   server_prop_overrides=[[\"zookeeper.connect\", self.zk.connect_setting()],",
          "229:                                                          [\"zookeeper.metadata.migration.enable\", \"true\"]],",
          "230:                                   quorum_info_provider=remote_quorum)",
          "232:         self.kafka.security_protocol = \"PLAINTEXT\"",
          "233:         self.kafka.interbroker_security_protocol = \"PLAINTEXT\"",
          "234:         self.zk.start()",
          "236:         controller.start()",
          "238:         self.logger.info(\"Pre-generating clusterId for ZK.\")",
          "239:         cluster_id_json = \"\"\"{\"version\": \"1\", \"id\": \"%s\"}\"\"\" % CLUSTER_ID",
          "240:         self.zk.create(path=\"/cluster\")",
          "241:         self.zk.create(path=\"/cluster/id\", value=cluster_id_json)",
          "242:         self.kafka.reconfigure_zk_for_migration(controller)",
          "243:         self.kafka.start()",
          "245:         topic_cfg = {",
          "246:             \"topic\": self.topic,",
          "247:             \"partitions\": self.partitions,",
          "248:             \"replication-factor\": self.replication_factor,",
          "249:             \"configs\": {\"min.insync.replicas\": 2}",
          "250:         }",
          "251:         self.kafka.create_topic(topic_cfg)",
          "253:         # Now we're in dual-write mode. The 3.4 controller will have written a PRE_MIGRATION record (1) into the log.",
          "254:         # We now upgrade the controller to 3.5+ where 1 is redefined as MIGRATION.",
          "255:         for node in controller.nodes:",
          "256:             self.logger.info(\"Stopping controller node %s\" % node.account.hostname)",
          "257:             self.kafka.controller_quorum.stop_node(node)",
          "258:             node.version = DEV_BRANCH",
          "259:             self.logger.info(\"Restarting controller node %s\" % node.account.hostname)",
          "260:             self.kafka.controller_quorum.start_node(node)",
          "261:             self.wait_until_rejoin()",
          "262:             self.logger.info(\"Successfully restarted controller node %s\" % node.account.hostname)",
          "264:         # Check the controller's logs for the INFO message that we're still in the migration state",
          "265:         saw_expected_log = False",
          "266:         for node in self.kafka.controller_quorum.nodes:",
          "267:             with node.account.monitor_log(KafkaService.STDOUT_STDERR_CAPTURE) as monitor:",
          "268:                 monitor.offset = 0",
          "269:                 try:",
          "270:                     # Shouldn't have to wait too long to see this log message after startup",
          "271:                     monitor.wait_until(",
          "272:                         \"Staying in ZK migration\",",
          "273:                         timeout_sec=10.0, backoff_sec=.25,",
          "274:                         err_msg=\"\"",
          "275:                     )",
          "276:                     saw_expected_log = True",
          "277:                     break",
          "278:                 except TimeoutError:",
          "279:                     continue",
          "281:         assert saw_expected_log, \"Did not see expected INFO log after upgrading from a 3.4 migration\"",
          "282:         self.kafka.stop()",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "d796480fe87fd819fc0ac560ca318759180d4644",
      "candidate_info": {
        "commit_hash": "d796480fe87fd819fc0ac560ca318759180d4644",
        "repo": "apache/kafka",
        "commit_url": "https://github.com/apache/kafka/commit/d796480fe87fd819fc0ac560ca318759180d4644",
        "files": [
          "checkstyle/import-control-metadata.xml",
          "clients/src/main/java/org/apache/kafka/clients/NetworkClient.java",
          "clients/src/main/java/org/apache/kafka/clients/NodeApiVersions.java",
          "clients/src/main/java/org/apache/kafka/common/requests/ApiVersionsResponse.java",
          "clients/src/test/java/org/apache/kafka/clients/NodeApiVersionsTest.java",
          "clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java",
          "clients/src/test/java/org/apache/kafka/common/requests/ApiVersionsResponseTest.java",
          "core/src/main/scala/kafka/admin/BrokerApiVersionsCommand.scala",
          "core/src/main/scala/kafka/server/ApiVersionManager.scala",
          "core/src/main/scala/kafka/server/ControllerServer.scala",
          "core/src/main/scala/kafka/tools/TestRaftServer.scala",
          "core/src/test/scala/unit/kafka/network/SocketServerTest.scala",
          "core/src/test/scala/unit/kafka/server/ControllerApisTest.scala",
          "core/src/test/scala/unit/kafka/server/KafkaApisTest.scala",
          "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/KRaftMetadataRequestBenchmark.java",
          "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/MetadataRequestBenchmark.java",
          "metadata/src/main/java/org/apache/kafka/controller/QuorumFeatures.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java",
          "metadata/src/test/java/org/apache/kafka/controller/QuorumFeaturesTest.java",
          "metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationDriverTest.java"
        ],
        "message": "KAFKA-14909: check zkMigrationReady tag before migration (#13631)\n\n1. add ZkMigrationReady in apiVersionsResponse\n2. check all nodes if ZkMigrationReady are ready before moving to next migration state\n\nReviewers: David Arthur <mumrah@gmail.com>, dengziming <dengziming1993@gmail.com>",
        "before_after_code_files": [
          "clients/src/main/java/org/apache/kafka/clients/NetworkClient.java||clients/src/main/java/org/apache/kafka/clients/NetworkClient.java",
          "clients/src/main/java/org/apache/kafka/clients/NodeApiVersions.java||clients/src/main/java/org/apache/kafka/clients/NodeApiVersions.java",
          "clients/src/main/java/org/apache/kafka/common/requests/ApiVersionsResponse.java||clients/src/main/java/org/apache/kafka/common/requests/ApiVersionsResponse.java",
          "clients/src/test/java/org/apache/kafka/clients/NodeApiVersionsTest.java||clients/src/test/java/org/apache/kafka/clients/NodeApiVersionsTest.java",
          "clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java||clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java",
          "clients/src/test/java/org/apache/kafka/common/requests/ApiVersionsResponseTest.java||clients/src/test/java/org/apache/kafka/common/requests/ApiVersionsResponseTest.java",
          "core/src/main/scala/kafka/admin/BrokerApiVersionsCommand.scala||core/src/main/scala/kafka/admin/BrokerApiVersionsCommand.scala",
          "core/src/main/scala/kafka/server/ApiVersionManager.scala||core/src/main/scala/kafka/server/ApiVersionManager.scala",
          "core/src/main/scala/kafka/server/ControllerServer.scala||core/src/main/scala/kafka/server/ControllerServer.scala",
          "core/src/main/scala/kafka/tools/TestRaftServer.scala||core/src/main/scala/kafka/tools/TestRaftServer.scala",
          "core/src/test/scala/unit/kafka/network/SocketServerTest.scala||core/src/test/scala/unit/kafka/network/SocketServerTest.scala",
          "core/src/test/scala/unit/kafka/server/ControllerApisTest.scala||core/src/test/scala/unit/kafka/server/ControllerApisTest.scala",
          "core/src/test/scala/unit/kafka/server/KafkaApisTest.scala||core/src/test/scala/unit/kafka/server/KafkaApisTest.scala",
          "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/KRaftMetadataRequestBenchmark.java||jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/KRaftMetadataRequestBenchmark.java",
          "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/MetadataRequestBenchmark.java||jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/MetadataRequestBenchmark.java",
          "metadata/src/main/java/org/apache/kafka/controller/QuorumFeatures.java||metadata/src/main/java/org/apache/kafka/controller/QuorumFeatures.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java",
          "metadata/src/test/java/org/apache/kafka/controller/QuorumFeaturesTest.java||metadata/src/test/java/org/apache/kafka/controller/QuorumFeaturesTest.java",
          "metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationDriverTest.java||metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationDriverTest.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java"
          ],
          "candidate": [
            "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java"
          ]
        }
      },
      "candidate_diff": {
        "clients/src/main/java/org/apache/kafka/clients/NetworkClient.java||clients/src/main/java/org/apache/kafka/clients/NetworkClient.java": [
          "File: clients/src/main/java/org/apache/kafka/clients/NetworkClient.java -> clients/src/main/java/org/apache/kafka/clients/NetworkClient.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "956:         }",
          "957:         NodeApiVersions nodeVersionInfo = new NodeApiVersions(",
          "958:             apiVersionsResponse.data().apiKeys(),",
          "960:         apiVersions.update(node, nodeVersionInfo);",
          "961:         this.connectionStates.ready(node);",
          "963:                 node, apiVersionsResponse.data().finalizedFeaturesEpoch(), apiVersionsResponse.data().finalizedFeatures(),",
          "965:     }",
          "",
          "[Removed Lines]",
          "959:             apiVersionsResponse.data().supportedFeatures());",
          "962:         log.debug(\"Node {} has finalized features epoch: {}, finalized features: {}, supported features: {}, API versions: {}.\",",
          "964:                 apiVersionsResponse.data().supportedFeatures(), nodeVersionInfo);",
          "",
          "[Added Lines]",
          "959:             apiVersionsResponse.data().supportedFeatures(),",
          "960:             apiVersionsResponse.data().zkMigrationReady());",
          "963:         log.debug(\"Node {} has finalized features epoch: {}, finalized features: {}, supported features: {}, ZK migration ready: {}, API versions: {}.\",",
          "965:                 apiVersionsResponse.data().supportedFeatures(), apiVersionsResponse.data().zkMigrationReady(), nodeVersionInfo);",
          "",
          "---------------"
        ],
        "clients/src/main/java/org/apache/kafka/clients/NodeApiVersions.java||clients/src/main/java/org/apache/kafka/clients/NodeApiVersions.java": [
          "File: clients/src/main/java/org/apache/kafka/clients/NodeApiVersions.java -> clients/src/main/java/org/apache/kafka/clients/NodeApiVersions.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "49:     private final Map<String, SupportedVersionRange> supportedFeatures;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "51:     private final boolean zkMigrationEnabled;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "76:             }",
          "77:             if (!exists) apiVersions.add(ApiVersionsResponse.toApiVersion(apiKey));",
          "78:         }",
          "80:     }",
          "",
          "[Removed Lines]",
          "79:         return new NodeApiVersions(apiVersions, Collections.emptyList());",
          "",
          "[Added Lines]",
          "81:         return new NodeApiVersions(apiVersions, Collections.emptyList(), false);",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "95:                 .setMaxVersion(maxVersion)));",
          "96:     }",
          "99:         for (ApiVersion nodeApiVersion : nodeApiVersions) {",
          "100:             if (ApiKeys.hasId(nodeApiVersion.apiKey())) {",
          "101:                 ApiKeys nodeApiKey = ApiKeys.forId(nodeApiVersion.apiKey());",
          "",
          "[Removed Lines]",
          "98:     public NodeApiVersions(Collection<ApiVersion> nodeApiVersions, Collection<SupportedFeatureKey> nodeSupportedFeatures) {",
          "",
          "[Added Lines]",
          "100:     public NodeApiVersions(Collection<ApiVersion> nodeApiVersions, Collection<SupportedFeatureKey> nodeSupportedFeatures, boolean zkMigrationEnabled) {",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "112:                     new SupportedVersionRange(supportedFeature.minVersion(), supportedFeature.maxVersion()));",
          "113:         }",
          "114:         this.supportedFeatures = Collections.unmodifiableMap(supportedFeaturesBuilder);",
          "115:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "117:         this.zkMigrationEnabled = zkMigrationEnabled;",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "236:     public Map<String, SupportedVersionRange> supportedFeatures() {",
          "237:         return supportedFeatures;",
          "238:     }",
          "239: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "243:     public boolean zkMigrationEnabled() {",
          "244:         return zkMigrationEnabled;",
          "245:     }",
          "",
          "---------------"
        ],
        "clients/src/main/java/org/apache/kafka/common/requests/ApiVersionsResponse.java||clients/src/main/java/org/apache/kafka/common/requests/ApiVersionsResponse.java": [
          "File: clients/src/main/java/org/apache/kafka/common/requests/ApiVersionsResponse.java -> clients/src/main/java/org/apache/kafka/common/requests/ApiVersionsResponse.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "119:         return createApiVersionsResponse(",
          "120:             throttleTimeMs,",
          "121:             filterApis(RecordVersion.current(), listenerType, true),",
          "123:         );",
          "124:     }",
          "",
          "[Removed Lines]",
          "122:             Features.emptySupportedFeatures()",
          "",
          "[Added Lines]",
          "122:             Features.emptySupportedFeatures(),",
          "123:             false",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "131:         return createApiVersionsResponse(",
          "132:             throttleTimeMs,",
          "133:             filterApis(RecordVersion.current(), listenerType, enableUnstableLastVersion),",
          "135:         );",
          "136:     }",
          "",
          "[Removed Lines]",
          "134:             Features.emptySupportedFeatures()",
          "",
          "[Added Lines]",
          "135:             Features.emptySupportedFeatures(),",
          "136:             false",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "139:         int throttleTimeMs,",
          "140:         ApiVersionCollection apiVersions",
          "141:     ) {",
          "143:     }",
          "145:     public static ApiVersionsResponse createApiVersionsResponse(",
          "146:         int throttleTimeMs,",
          "147:         ApiVersionCollection apiVersions,",
          "149:     ) {",
          "150:         return createApiVersionsResponse(",
          "151:             throttleTimeMs,",
          "152:             apiVersions,",
          "153:             latestSupportedFeatures,",
          "154:             Collections.emptyMap(),",
          "156:     }",
          "158:     public static ApiVersionsResponse createApiVersionsResponse(",
          "",
          "[Removed Lines]",
          "142:         return createApiVersionsResponse(throttleTimeMs, apiVersions, Features.emptySupportedFeatures());",
          "148:         Features<SupportedVersionRange> latestSupportedFeatures",
          "155:             UNKNOWN_FINALIZED_FEATURES_EPOCH);",
          "",
          "[Added Lines]",
          "144:         return createApiVersionsResponse(throttleTimeMs, apiVersions, Features.emptySupportedFeatures(), false);",
          "150:         Features<SupportedVersionRange> latestSupportedFeatures,",
          "151:         boolean zkMigrationEnabled",
          "158:             UNKNOWN_FINALIZED_FEATURES_EPOCH,",
          "159:             zkMigrationEnabled);",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "163:         long finalizedFeaturesEpoch,",
          "164:         NodeApiVersions controllerApiVersions,",
          "165:         ListenerType listenerType,",
          "167:     ) {",
          "168:         ApiVersionCollection apiKeys;",
          "169:         if (controllerApiVersions != null) {",
          "",
          "[Removed Lines]",
          "166:         boolean enableUnstableLastVersion",
          "",
          "[Added Lines]",
          "170:         boolean enableUnstableLastVersion,",
          "171:         boolean zkMigrationEnabled",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "186:             apiKeys,",
          "187:             latestSupportedFeatures,",
          "188:             finalizedFeatures,",
          "190:         );",
          "191:     }",
          "",
          "[Removed Lines]",
          "189:             finalizedFeaturesEpoch",
          "",
          "[Added Lines]",
          "194:             finalizedFeaturesEpoch,",
          "195:             zkMigrationEnabled",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "195:         ApiVersionCollection apiVersions,",
          "196:         Features<SupportedVersionRange> latestSupportedFeatures,",
          "197:         Map<String, Short> finalizedFeatures,",
          "199:     ) {",
          "200:         return new ApiVersionsResponse(",
          "201:             createApiVersionsResponseData(",
          "",
          "[Removed Lines]",
          "198:         long finalizedFeaturesEpoch",
          "",
          "[Added Lines]",
          "204:         long finalizedFeaturesEpoch,",
          "205:         boolean zkMigrationEnabled",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "204:                 apiVersions,",
          "205:                 latestSupportedFeatures,",
          "206:                 finalizedFeatures,",
          "208:             )",
          "209:         );",
          "210:     }",
          "",
          "[Removed Lines]",
          "207:                 finalizedFeaturesEpoch",
          "",
          "[Added Lines]",
          "214:                 finalizedFeaturesEpoch,",
          "215:                 zkMigrationEnabled",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "294:         final ApiVersionCollection apiKeys,",
          "295:         final Features<SupportedVersionRange> latestSupportedFeatures,",
          "296:         final Map<String, Short> finalizedFeatures,",
          "298:     ) {",
          "299:         final ApiVersionsResponseData data = new ApiVersionsResponseData();",
          "300:         data.setThrottleTimeMs(throttleTimeMs);",
          "",
          "[Removed Lines]",
          "297:         final long finalizedFeaturesEpoch",
          "",
          "[Added Lines]",
          "305:         final long finalizedFeaturesEpoch,",
          "306:         final boolean zkMigrationEnabled",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "303:         data.setSupportedFeatures(createSupportedFeatureKeys(latestSupportedFeatures));",
          "304:         data.setFinalizedFeatures(createFinalizedFeatureKeys(finalizedFeatures));",
          "305:         data.setFinalizedFeaturesEpoch(finalizedFeaturesEpoch);",
          "307:         return data;",
          "308:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "315:         data.setZkMigrationReady(zkMigrationEnabled);",
          "",
          "---------------"
        ],
        "clients/src/test/java/org/apache/kafka/clients/NodeApiVersionsTest.java||clients/src/test/java/org/apache/kafka/clients/NodeApiVersionsTest.java": [
          "File: clients/src/test/java/org/apache/kafka/clients/NodeApiVersionsTest.java -> clients/src/test/java/org/apache/kafka/clients/NodeApiVersionsTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "40:     @Test",
          "41:     public void testUnsupportedVersionsToString() {",
          "43:         StringBuilder bld = new StringBuilder();",
          "44:         String prefix = \"(\";",
          "45:         for (ApiKeys apiKey : ApiKeys.zkBrokerApis()) {",
          "",
          "[Removed Lines]",
          "42:         NodeApiVersions versions = new NodeApiVersions(new ApiVersionCollection(), Collections.emptyList());",
          "",
          "[Added Lines]",
          "42:         NodeApiVersions versions = new NodeApiVersions(new ApiVersionCollection(), Collections.emptyList(), false);",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "68:                         .setMaxVersion((short) 10001));",
          "69:             } else versionList.add(ApiVersionsResponse.toApiVersion(apiKey));",
          "70:         }",
          "72:         StringBuilder bld = new StringBuilder();",
          "73:         String prefix = \"(\";",
          "74:         for (ApiKeys apiKey : ApiKeys.values()) {",
          "",
          "[Removed Lines]",
          "71:         NodeApiVersions versions = new NodeApiVersions(versionList, Collections.emptyList());",
          "",
          "[Added Lines]",
          "71:         NodeApiVersions versions = new NodeApiVersions(versionList, Collections.emptyList(), false);",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "126:     @Test",
          "127:     public void testUsableVersionCalculationNoKnownVersions() {",
          "129:         assertThrows(UnsupportedVersionException.class,",
          "130:             () -> versions.latestUsableVersion(ApiKeys.FETCH));",
          "131:     }",
          "",
          "[Removed Lines]",
          "128:         NodeApiVersions versions = new NodeApiVersions(new ApiVersionCollection(), Collections.emptyList());",
          "",
          "[Added Lines]",
          "128:         NodeApiVersions versions = new NodeApiVersions(new ApiVersionCollection(), Collections.emptyList(), false);",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "147:                 .setApiKey((short) 100)",
          "148:                 .setMinVersion((short) 0)",
          "149:                 .setMaxVersion((short) 1));",
          "151:         for (ApiKeys apiKey: ApiKeys.apisForListener(scope)) {",
          "152:             assertEquals(apiKey.latestVersion(), versions.latestUsableVersion(apiKey));",
          "153:         }",
          "",
          "[Removed Lines]",
          "150:         NodeApiVersions versions = new NodeApiVersions(versionList, Collections.emptyList());",
          "",
          "[Added Lines]",
          "150:         NodeApiVersions versions = new NodeApiVersions(versionList, Collections.emptyList(), false);",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "157:     @EnumSource(ApiMessageType.ListenerType.class)",
          "158:     public void testConstructionFromApiVersionsResponse(ApiMessageType.ListenerType scope) {",
          "159:         ApiVersionsResponse apiVersionsResponse = ApiVersionsResponse.defaultApiVersionsResponse(scope);",
          "162:         for (ApiVersion apiVersionKey : apiVersionsResponse.data().apiKeys()) {",
          "163:             ApiVersion apiVersion = versions.apiVersion(ApiKeys.forId(apiVersionKey.apiKey()));",
          "",
          "[Removed Lines]",
          "160:         NodeApiVersions versions = new NodeApiVersions(apiVersionsResponse.data().apiKeys(), Collections.emptyList());",
          "",
          "[Added Lines]",
          "160:         NodeApiVersions versions = new NodeApiVersions(apiVersionsResponse.data().apiKeys(), Collections.emptyList(), false);",
          "",
          "---------------"
        ],
        "clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java||clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java": [
          "File: clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java -> clients/src/test/java/org/apache/kafka/clients/admin/KafkaAdminClientTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "634:                 ApiVersionsResponse.filterApis(RecordVersion.current(), ApiMessageType.ListenerType.ZK_BROKER),",
          "635:                 convertSupportedFeaturesMap(defaultFeatureMetadata().supportedFeatures()),",
          "636:                 Collections.singletonMap(\"test_feature_1\", (short) 2),",
          "638:             );",
          "639:         }",
          "640:         return new ApiVersionsResponse(",
          "",
          "[Removed Lines]",
          "637:                 defaultFeatureMetadata().finalizedFeaturesEpoch().get()",
          "",
          "[Added Lines]",
          "637:                 defaultFeatureMetadata().finalizedFeaturesEpoch().get(),",
          "638:                 false",
          "",
          "---------------"
        ],
        "clients/src/test/java/org/apache/kafka/common/requests/ApiVersionsResponseTest.java||clients/src/test/java/org/apache/kafka/common/requests/ApiVersionsResponseTest.java": [
          "File: clients/src/test/java/org/apache/kafka/common/requests/ApiVersionsResponseTest.java -> clients/src/test/java/org/apache/kafka/common/requests/ApiVersionsResponseTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "121:             ApiVersionsResponse.UNKNOWN_FINALIZED_FEATURES_EPOCH,",
          "122:             null,",
          "123:             ListenerType.ZK_BROKER,",
          "125:         );",
          "126:         verifyApiKeysForMagic(response, RecordBatch.MAGIC_VALUE_V1);",
          "127:         assertEquals(10, response.throttleTimeMs());",
          "",
          "[Removed Lines]",
          "124:             true",
          "",
          "[Added Lines]",
          "124:             true,",
          "125:             false",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "141:             10L,",
          "142:             null,",
          "143:             ListenerType.ZK_BROKER,",
          "145:         );",
          "147:         verifyApiKeysForMagic(response, RecordBatch.MAGIC_VALUE_V1);",
          "",
          "[Removed Lines]",
          "144:             true",
          "",
          "[Added Lines]",
          "145:             true,",
          "146:             false",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "169:             ApiVersionsResponse.UNKNOWN_FINALIZED_FEATURES_EPOCH,",
          "170:             null,",
          "171:             ListenerType.ZK_BROKER,",
          "173:         );",
          "174:         assertEquals(new HashSet<>(ApiKeys.zkBrokerApis()), apiKeysInResponse(response));",
          "175:         assertEquals(AbstractResponse.DEFAULT_THROTTLE_TIME, response.throttleTimeMs());",
          "",
          "[Removed Lines]",
          "172:             true",
          "",
          "[Added Lines]",
          "174:             true,",
          "175:             false",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "188:             ApiVersionsResponse.UNKNOWN_FINALIZED_FEATURES_EPOCH,",
          "189:             null,",
          "190:             ListenerType.ZK_BROKER,",
          "192:         );",
          "",
          "[Removed Lines]",
          "191:             true",
          "",
          "[Added Lines]",
          "194:             true,",
          "195:             false",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/admin/BrokerApiVersionsCommand.scala||core/src/main/scala/kafka/admin/BrokerApiVersionsCommand.scala": [
          "File: core/src/main/scala/kafka/admin/BrokerApiVersionsCommand.scala -> core/src/main/scala/kafka/admin/BrokerApiVersionsCommand.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "158:     private def getNodeApiVersions(node: Node): NodeApiVersions = {",
          "159:       val response = send(node, new ApiVersionsRequest.Builder()).asInstanceOf[ApiVersionsResponse]",
          "160:       Errors.forCode(response.data.errorCode).maybeThrow()",
          "162:     }",
          "",
          "[Removed Lines]",
          "161:       new NodeApiVersions(response.data.apiKeys, response.data.supportedFeatures)",
          "",
          "[Added Lines]",
          "161:       new NodeApiVersions(response.data.apiKeys, response.data.supportedFeatures, response.data.zkMigrationReady)",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/server/ApiVersionManager.scala||core/src/main/scala/kafka/server/ApiVersionManager.scala": [
          "File: core/src/main/scala/kafka/server/ApiVersionManager.scala -> core/src/main/scala/kafka/server/ApiVersionManager.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "49:       forwardingManager,",
          "50:       supportedFeatures,",
          "51:       metadataCache,",
          "53:     )",
          "54:   }",
          "55: }",
          "",
          "[Removed Lines]",
          "52:       config.unstableApiVersionsEnabled",
          "",
          "[Added Lines]",
          "52:       config.unstableApiVersionsEnabled,",
          "53:       config.migrationEnabled",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "58:   val listenerType: ListenerType,",
          "59:   val enabledApis: collection.Set[ApiKeys],",
          "60:   brokerFeatures: Features[SupportedVersionRange],",
          "62: ) extends ApiVersionManager {",
          "64:   def this(",
          "65:     listenerType: ListenerType,",
          "67:   ) = {",
          "68:     this(",
          "69:       listenerType,",
          "70:       ApiKeys.apisForListener(listenerType).asScala,",
          "71:       BrokerFeatures.defaultSupportedFeatures(),",
          "73:     )",
          "74:   }",
          "76:   private val apiVersions = ApiVersionsResponse.collectApis(enabledApis.asJava, enableUnstableLastVersion)",
          "78:   override def apiVersionResponse(requestThrottleMs: Int): ApiVersionsResponse = {",
          "80:   }",
          "81: }",
          "",
          "[Removed Lines]",
          "61:   val enableUnstableLastVersion: Boolean",
          "66:     enableUnstableLastVersion: Boolean",
          "72:       enableUnstableLastVersion",
          "79:     ApiVersionsResponse.createApiVersionsResponse(requestThrottleMs, apiVersions, brokerFeatures)",
          "",
          "[Added Lines]",
          "62:   val enableUnstableLastVersion: Boolean,",
          "63:   val zkMigrationEnabled: Boolean",
          "68:     enableUnstableLastVersion: Boolean,",
          "69:     zkMigrationEnabled: Boolean",
          "75:       enableUnstableLastVersion,",
          "76:       zkMigrationEnabled",
          "83:     ApiVersionsResponse.createApiVersionsResponse(requestThrottleMs, apiVersions, brokerFeatures, zkMigrationEnabled)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "85:   forwardingManager: Option[ForwardingManager],",
          "86:   features: BrokerFeatures,",
          "87:   metadataCache: MetadataCache,",
          "89: ) extends ApiVersionManager {",
          "91:   val enabledApis = ApiKeys.apisForListener(listenerType).asScala",
          "",
          "[Removed Lines]",
          "88:   val enableUnstableLastVersion: Boolean",
          "",
          "[Added Lines]",
          "92:   val enableUnstableLastVersion: Boolean,",
          "93:   val zkMigrationEnabled: Boolean = false",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "103:       finalizedFeatures.epoch,",
          "104:       controllerApiVersions.orNull,",
          "105:       listenerType,",
          "107:     )",
          "108:   }",
          "109: }",
          "",
          "[Removed Lines]",
          "106:       enableUnstableLastVersion",
          "",
          "[Added Lines]",
          "111:       enableUnstableLastVersion,",
          "112:       zkMigrationEnabled",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/server/ControllerServer.scala||core/src/main/scala/kafka/server/ControllerServer.scala": [
          "File: core/src/main/scala/kafka/server/ControllerServer.scala -> core/src/main/scala/kafka/server/ControllerServer.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "176:       val apiVersionManager = new SimpleApiVersionManager(",
          "177:         ListenerType.CONTROLLER,",
          "179:       )",
          "181:       tokenCache = new DelegationTokenCache(ScramMechanism.mechanismNames)",
          "",
          "[Removed Lines]",
          "178:         config.unstableApiVersionsEnabled",
          "",
          "[Added Lines]",
          "178:         config.unstableApiVersionsEnabled,",
          "179:         config.migrationEnabled",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "270:             \"zk migration\",",
          "271:             fatal = false,",
          "272:             () => {}",
          "274:         )",
          "275:         migrationDriver.start()",
          "276:         migrationSupport = Some(ControllerMigrationSupport(zkClient, migrationDriver, propagator))",
          "",
          "[Removed Lines]",
          "273:           )",
          "",
          "[Added Lines]",
          "274:           ),",
          "275:           quorumFeatures",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/tools/TestRaftServer.scala||core/src/main/scala/kafka/tools/TestRaftServer.scala": [
          "File: core/src/main/scala/kafka/tools/TestRaftServer.scala -> core/src/main/scala/kafka/tools/TestRaftServer.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "74:     tokenCache = new DelegationTokenCache(ScramMechanism.mechanismNames)",
          "75:     credentialProvider = new CredentialProvider(ScramMechanism.mechanismNames, tokenCache)",
          "78:     socketServer = new SocketServer(config, metrics, time, credentialProvider, apiVersionManager)",
          "80:     val metaProperties = MetaProperties(",
          "",
          "[Removed Lines]",
          "77:     val apiVersionManager = new SimpleApiVersionManager(ListenerType.CONTROLLER, true)",
          "",
          "[Added Lines]",
          "77:     val apiVersionManager = new SimpleApiVersionManager(ListenerType.CONTROLLER, true, false)",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/network/SocketServerTest.scala||core/src/test/scala/unit/kafka/network/SocketServerTest.scala": [
          "File: core/src/test/scala/unit/kafka/network/SocketServerTest.scala -> core/src/test/scala/unit/kafka/network/SocketServerTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "78:   TestUtils.clearYammerMetrics()",
          "81:   val server = new SocketServer(config, metrics, Time.SYSTEM, credentialProvider, apiVersionManager)",
          "82:   server.enableRequestProcessing(Map.empty).get(1, TimeUnit.MINUTES)",
          "83:   val sockets = new ArrayBuffer[Socket]",
          "",
          "[Removed Lines]",
          "80:   private val apiVersionManager = new SimpleApiVersionManager(ListenerType.ZK_BROKER, true)",
          "",
          "[Added Lines]",
          "80:   private val apiVersionManager = new SimpleApiVersionManager(ListenerType.ZK_BROKER, true, false)",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/server/ControllerApisTest.scala||core/src/test/scala/unit/kafka/server/ControllerApisTest.scala": [
          "File: core/src/test/scala/unit/kafka/server/ControllerApisTest.scala -> core/src/test/scala/unit/kafka/server/ControllerApisTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "154:       new KafkaConfig(props),",
          "155:       MetaProperties(\"JgxuGe9URy-E-ceaL04lEw\", nodeId = nodeId),",
          "156:       Seq.empty,",
          "158:     )",
          "159:   }",
          "",
          "[Removed Lines]",
          "157:       new SimpleApiVersionManager(ListenerType.CONTROLLER, true)",
          "",
          "[Added Lines]",
          "157:       new SimpleApiVersionManager(ListenerType.CONTROLLER, true, false)",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/server/KafkaApisTest.scala||core/src/test/scala/unit/kafka/server/KafkaApisTest.scala": [
          "File: core/src/test/scala/unit/kafka/server/KafkaApisTest.scala -> core/src/test/scala/unit/kafka/server/KafkaApisTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "184:     } else {",
          "185:       ApiKeys.apisForListener(listenerType).asScala.toSet",
          "186:     }",
          "189:     new KafkaApis(",
          "190:       requestChannel = requestChannel,",
          "",
          "[Removed Lines]",
          "187:     val apiVersionManager = new SimpleApiVersionManager(listenerType, enabledApis, BrokerFeatures.defaultSupportedFeatures(), true)",
          "",
          "[Added Lines]",
          "187:     val apiVersionManager = new SimpleApiVersionManager(listenerType, enabledApis, BrokerFeatures.defaultSupportedFeatures(), true, false)",
          "",
          "---------------"
        ],
        "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/KRaftMetadataRequestBenchmark.java||jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/KRaftMetadataRequestBenchmark.java": [
          "File: jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/KRaftMetadataRequestBenchmark.java -> jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/KRaftMetadataRequestBenchmark.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "197:                 setClusterId(\"clusterId\").",
          "198:                 setTime(Time.SYSTEM).",
          "199:                 setTokenManager(null).",
          "201:                 build();",
          "202:     }",
          "",
          "[Removed Lines]",
          "200:                 setApiVersionManager(new SimpleApiVersionManager(ApiMessageType.ListenerType.BROKER, false)).",
          "",
          "[Added Lines]",
          "200:                 setApiVersionManager(new SimpleApiVersionManager(ApiMessageType.ListenerType.BROKER, false, false)).",
          "",
          "---------------"
        ],
        "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/MetadataRequestBenchmark.java||jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/MetadataRequestBenchmark.java": [
          "File: jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/MetadataRequestBenchmark.java -> jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/MetadataRequestBenchmark.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "199:             setClusterId(\"clusterId\").",
          "200:             setTime(Time.SYSTEM).",
          "201:             setTokenManager(null).",
          "203:             build();",
          "204:     }",
          "",
          "[Removed Lines]",
          "202:             setApiVersionManager(new SimpleApiVersionManager(ApiMessageType.ListenerType.ZK_BROKER, false)).",
          "",
          "[Added Lines]",
          "202:             setApiVersionManager(new SimpleApiVersionManager(ApiMessageType.ListenerType.ZK_BROKER, false, false)).",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/controller/QuorumFeatures.java||metadata/src/main/java/org/apache/kafka/controller/QuorumFeatures.java": [
          "File: metadata/src/main/java/org/apache/kafka/controller/QuorumFeatures.java -> metadata/src/main/java/org/apache/kafka/controller/QuorumFeatures.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "128:     boolean isControllerId(int nodeId) {",
          "129:         return quorumNodeIds.contains(nodeId);",
          "130:     }",
          "131: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "133:     public Optional<String> reasonAllControllersZkMigrationNotReady() {",
          "134:         List<String> missingApiVers = new ArrayList<>();",
          "135:         List<String> zkMigrationNotReady = new ArrayList<>();",
          "136:         for (int id : quorumNodeIds) {",
          "137:             if (nodeId == id) {",
          "138:                 continue; // No need to check local node because the KraftMigrationDriver will be created only when migration config set",
          "139:             }",
          "140:             NodeApiVersions nodeVersions = apiVersions.get(Integer.toString(id));",
          "141:             if (nodeVersions == null) {",
          "142:                 missingApiVers.add(String.valueOf(id));",
          "143:             } else if (!nodeVersions.zkMigrationEnabled()) {",
          "144:                 zkMigrationNotReady.add(String.valueOf(id));",
          "145:             }",
          "146:         }",
          "148:         boolean isReady = missingApiVers.isEmpty() && zkMigrationNotReady.isEmpty();",
          "149:         if (!isReady) {",
          "150:             String zkMigrationNotReadyMsg = zkMigrationNotReady.isEmpty() ? \"\" : \"Nodes don't enable `zookeeper.metadata.migration.enable`: \" + zkMigrationNotReady + \".\";",
          "151:             String missingApiVersionMsg = missingApiVers.isEmpty() ? \"\" : \" Missing apiVersion from nodes: \" + missingApiVers;",
          "152:             return Optional.of(zkMigrationNotReadyMsg + missingApiVersionMsg);",
          "153:         }",
          "155:         return Optional.empty();",
          "156:     }",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java -> metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: import org.apache.kafka.common.resource.ResourcePattern;",
          "23: import org.apache.kafka.common.utils.LogContext;",
          "24: import org.apache.kafka.common.utils.Time;",
          "25: import org.apache.kafka.image.MetadataDelta;",
          "26: import org.apache.kafka.image.MetadataImage;",
          "27: import org.apache.kafka.image.MetadataProvenance;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "25: import org.apache.kafka.controller.QuorumFeatures;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "47: import java.util.HashSet;",
          "48: import java.util.List;",
          "49: import java.util.Map;",
          "50: import java.util.Set;",
          "51: import java.util.concurrent.CompletableFuture;",
          "52: import java.util.concurrent.RejectedExecutionException;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "51: import java.util.Optional;",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "91:     private volatile MigrationDriverState migrationState;",
          "92:     private volatile ZkMigrationLeadershipState migrationLeadershipState;",
          "93:     private volatile MetadataImage image;",
          "94:     private volatile boolean firstPublish;",
          "96:     public KRaftMigrationDriver(",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "96:     private volatile QuorumFeatures quorumFeatures;",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "99:         MigrationClient zkMigrationClient,",
          "100:         LegacyPropagator propagator,",
          "101:         Consumer<MetadataPublisher> initialZkLoadHandler,",
          "103:     ) {",
          "104:         this.nodeId = nodeId;",
          "105:         this.zkRecordConsumer = zkRecordConsumer;",
          "106:         this.zkMigrationClient = zkMigrationClient;",
          "107:         this.propagator = propagator;",
          "109:         this.logContext = new LogContext(\"[KRaftMigrationDriver id=\" + nodeId + \"] \");",
          "111:         this.migrationState = MigrationDriverState.UNINITIALIZED;",
          "112:         this.migrationLeadershipState = ZkMigrationLeadershipState.EMPTY;",
          "113:         this.eventQueue = new KafkaEventQueue(Time.SYSTEM, logContext, \"controller-\" + nodeId + \"-migration-driver-\");",
          "",
          "[Removed Lines]",
          "102:         FaultHandler faultHandler",
          "108:         this.time = Time.SYSTEM;",
          "110:         this.log = this.logContext.logger(KRaftMigrationDriver.class);",
          "",
          "[Added Lines]",
          "105:         FaultHandler faultHandler,",
          "106:         QuorumFeatures quorumFeatures,",
          "107:         Time time",
          "113:         this.time = time;",
          "115:         this.log = logContext.logger(KRaftMigrationDriver.class);",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "116:         this.leaderAndEpoch = LeaderAndEpoch.UNKNOWN;",
          "117:         this.initialZkLoadHandler = initialZkLoadHandler;",
          "118:         this.faultHandler = faultHandler;",
          "119:     }",
          "121:     public void start() {",
          "122:         eventQueue.prepend(new PollEvent());",
          "123:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "124:         this.quorumFeatures = quorumFeatures;",
          "127:     public KRaftMigrationDriver(",
          "128:         int nodeId,",
          "129:         ZkRecordConsumer zkRecordConsumer,",
          "130:         MigrationClient zkMigrationClient,",
          "131:         LegacyPropagator propagator,",
          "132:         Consumer<MetadataPublisher> initialZkLoadHandler,",
          "133:         FaultHandler faultHandler,",
          "134:         QuorumFeatures quorumFeatures",
          "135:     ) {",
          "136:         this(nodeId, zkRecordConsumer, zkMigrationClient, propagator, initialZkLoadHandler, faultHandler, quorumFeatures, Time.SYSTEM);",
          "137:     }",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "149:         transitionTo(MigrationDriverState.INACTIVE);",
          "150:     }",
          "152:     private boolean imageDoesNotContainAllBrokers(MetadataImage image, Set<Integer> brokerIds) {",
          "153:         for (BrokerRegistration broker : image.cluster().brokers().values()) {",
          "154:             if (broker.isMigratingZkBroker()) {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "171:     private boolean isControllerQuorumReadyForMigration() {",
          "172:         Optional<String> notReadyMsg = this.quorumFeatures.reasonAllControllersZkMigrationNotReady();",
          "173:         if (notReadyMsg.isPresent()) {",
          "174:             log.info(\"Still waiting for all controller nodes ready to begin the migration. due to:\" + notReadyMsg.get());",
          "175:             return false;",
          "176:         }",
          "177:         return true;",
          "178:     }",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "432:                         transitionTo(MigrationDriverState.INACTIVE);",
          "433:                         break;",
          "434:                     case PRE_MIGRATION:",
          "438:                         break;",
          "439:                     case MIGRATION:",
          "440:                         if (!migrationLeadershipState.zkMigrationComplete()) {",
          "",
          "[Removed Lines]",
          "436:                         log.debug(\"Controller Quorum is ready for Zk to KRaft migration. Now waiting for ZK brokers.\");",
          "437:                         transitionTo(MigrationDriverState.WAIT_FOR_BROKERS);",
          "",
          "[Added Lines]",
          "463:                         if (isControllerQuorumReadyForMigration()) {",
          "465:                             log.debug(\"Controller Quorum is ready for Zk to KRaft migration. Now waiting for ZK brokers.\");",
          "466:                             transitionTo(MigrationDriverState.WAIT_FOR_BROKERS);",
          "467:                         }",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/controller/QuorumFeaturesTest.java||metadata/src/test/java/org/apache/kafka/controller/QuorumFeaturesTest.java": [
          "File: metadata/src/test/java/org/apache/kafka/controller/QuorumFeaturesTest.java -> metadata/src/test/java/org/apache/kafka/controller/QuorumFeaturesTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "89:                     setMinVersion(entry.getValue().min()).",
          "90:                     setMaxVersion(entry.getValue().max()));",
          "91:         });",
          "93:     }",
          "95:     @Test",
          "",
          "[Removed Lines]",
          "92:         return new NodeApiVersions(Collections.emptyList(), features);",
          "",
          "[Added Lines]",
          "92:         return new NodeApiVersions(Collections.emptyList(), features, false);",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "100:         assertTrue(quorumFeatures.isControllerId(2));",
          "101:         assertFalse(quorumFeatures.isControllerId(3));",
          "102:     }",
          "103: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "104:     @Test",
          "105:     public void testZkMigrationReady() {",
          "106:         ApiVersions apiVersions = new ApiVersions();",
          "107:         QuorumFeatures quorumFeatures = new QuorumFeatures(0, apiVersions, LOCAL, Arrays.asList(0, 1, 2));",
          "110:         apiVersions.update(\"0\", new NodeApiVersions(Collections.emptyList(), Collections.emptyList(), true));",
          "111:         assertTrue(quorumFeatures.reasonAllControllersZkMigrationNotReady().isPresent());",
          "112:         assertTrue(quorumFeatures.reasonAllControllersZkMigrationNotReady().get().contains(\"Missing apiVersion from nodes: [1, 2]\"));",
          "115:         apiVersions.update(\"1\", new NodeApiVersions(Collections.emptyList(), Collections.emptyList(), true));",
          "116:         assertTrue(quorumFeatures.reasonAllControllersZkMigrationNotReady().isPresent());",
          "117:         assertTrue(quorumFeatures.reasonAllControllersZkMigrationNotReady().get().contains(\"Missing apiVersion from nodes: [2]\"));",
          "120:         apiVersions.update(\"2\", NodeApiVersions.create());",
          "121:         assertTrue(quorumFeatures.reasonAllControllersZkMigrationNotReady().isPresent());",
          "122:         assertTrue(quorumFeatures.reasonAllControllersZkMigrationNotReady().get().contains(\"Nodes don't enable `zookeeper.metadata.migration.enable`: [2]\"));",
          "125:         apiVersions.update(\"2\", new NodeApiVersions(Collections.emptyList(), Collections.emptyList(), true));",
          "126:         assertFalse(quorumFeatures.reasonAllControllersZkMigrationNotReady().isPresent());",
          "129:         apiVersions.update(\"3\", NodeApiVersions.create());",
          "130:         assertFalse(quorumFeatures.reasonAllControllersZkMigrationNotReady().isPresent());",
          "131:     }",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationDriverTest.java||metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationDriverTest.java": [
          "File: metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationDriverTest.java -> metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationDriverTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: package org.apache.kafka.metadata.migration;",
          "19: import org.apache.kafka.common.Uuid;",
          "20: import org.apache.kafka.common.acl.AccessControlEntry;",
          "21: import org.apache.kafka.common.config.ConfigResource;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19: import org.apache.kafka.clients.ApiVersions;",
          "20: import org.apache.kafka.clients.NodeApiVersions;",
          "21: import org.apache.kafka.common.Node;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "23: import org.apache.kafka.common.metadata.ConfigRecord;",
          "24: import org.apache.kafka.common.metadata.RegisterBrokerRecord;",
          "25: import org.apache.kafka.common.resource.ResourcePattern;",
          "26: import org.apache.kafka.image.MetadataDelta;",
          "27: import org.apache.kafka.image.MetadataImage;",
          "28: import org.apache.kafka.image.MetadataProvenance;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "29: import org.apache.kafka.common.utils.MockTime;",
          "30: import org.apache.kafka.common.utils.Time;",
          "31: import org.apache.kafka.controller.QuorumFeatures;",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "37: import org.apache.kafka.server.fault.MockFaultHandler;",
          "38: import org.apache.kafka.test.TestUtils;",
          "39: import org.junit.jupiter.api.Assertions;",
          "40: import org.junit.jupiter.api.Test;",
          "41: import org.junit.jupiter.params.ParameterizedTest;",
          "42: import org.junit.jupiter.params.provider.ValueSource;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "46: import org.junit.jupiter.api.BeforeEach;",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "55: import java.util.function.BiConsumer;",
          "56: import java.util.function.Consumer;",
          "58: public class KRaftMigrationDriverTest {",
          "59:     static class NoOpRecordConsumer implements ZkRecordConsumer {",
          "60:         @Override",
          "61:         public void beginMigration() {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "65: import static java.util.concurrent.TimeUnit.MILLISECONDS;",
          "66: import static java.util.concurrent.TimeUnit.NANOSECONDS;",
          "69:     List<Node> controllerNodes = Arrays.asList(",
          "70:         new Node(4, \"host4\", 0),",
          "71:         new Node(5, \"host5\", 0),",
          "72:         new Node(6, \"host6\", 0)",
          "73:     );",
          "74:     ApiVersions apiVersions = new ApiVersions();",
          "75:     QuorumFeatures quorumFeatures = QuorumFeatures.create(4,",
          "76:         apiVersions,",
          "77:         QuorumFeatures.defaultFeatureMap(),",
          "78:         controllerNodes);",
          "79:     Time mockTime = new MockTime(1) {",
          "80:         public long nanoseconds() {",
          "82:             return System.nanoTime() - NANOSECONDS.convert(990, MILLISECONDS);",
          "83:         }",
          "84:     };",
          "86:     @BeforeEach",
          "87:     public void setup() {",
          "88:         apiVersions.update(\"4\", new NodeApiVersions(Collections.emptyList(), Collections.emptyList(), true));",
          "89:         apiVersions.update(\"5\", new NodeApiVersions(Collections.emptyList(), Collections.emptyList(), true));",
          "90:         apiVersions.update(\"6\", new NodeApiVersions(Collections.emptyList(), Collections.emptyList(), true));",
          "91:     }",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "292:     public void testOnlySendNeededRPCsToBrokers() throws Exception {",
          "293:         CountingMetadataPropagator metadataPropagator = new CountingMetadataPropagator();",
          "294:         CapturingMigrationClient migrationClient = new CapturingMigrationClient(new HashSet<>(Arrays.asList(1, 2, 3)));",
          "296:             3000,",
          "297:             new NoOpRecordConsumer(),",
          "298:             migrationClient,",
          "299:             metadataPropagator,",
          "300:             metadataPublisher -> { },",
          "354:     }",
          "356:     @ParameterizedTest",
          "",
          "[Removed Lines]",
          "295:         KRaftMigrationDriver driver = new KRaftMigrationDriver(",
          "301:             new MockFaultHandler(\"test\")",
          "302:         );",
          "304:         MetadataImage image = MetadataImage.EMPTY;",
          "305:         MetadataDelta delta = new MetadataDelta(image);",
          "307:         driver.start();",
          "308:         delta.replay(ZkMigrationState.PRE_MIGRATION.toRecord().message());",
          "309:         delta.replay(zkBrokerRecord(1));",
          "310:         delta.replay(zkBrokerRecord(2));",
          "311:         delta.replay(zkBrokerRecord(3));",
          "312:         MetadataProvenance provenance = new MetadataProvenance(100, 1, 1);",
          "313:         image = delta.apply(provenance);",
          "316:         LeaderAndEpoch newLeader = new LeaderAndEpoch(OptionalInt.of(3000), 1);",
          "317:         driver.onControllerChange(newLeader);",
          "318:         driver.onMetadataUpdate(delta, image, new LogDeltaManifest(provenance, newLeader, 1, 100, 42));",
          "320:         TestUtils.waitForCondition(() -> driver.migrationState().get(1, TimeUnit.MINUTES).equals(MigrationDriverState.DUAL_WRITE),",
          "321:             \"Waiting for KRaftMigrationDriver to enter DUAL_WRITE state\");",
          "323:         Assertions.assertEquals(1, metadataPropagator.images);",
          "324:         Assertions.assertEquals(0, metadataPropagator.deltas);",
          "326:         delta = new MetadataDelta(image);",
          "327:         delta.replay(new ConfigRecord()",
          "328:             .setResourceType(ConfigResource.Type.BROKER.id())",
          "329:             .setResourceName(\"1\")",
          "330:             .setName(\"foo\")",
          "331:             .setValue(\"bar\"));",
          "332:         provenance = new MetadataProvenance(120, 1, 2);",
          "333:         image = delta.apply(provenance);",
          "334:         enqueueMetadataChangeEventWithFuture(driver, delta, image, provenance).get(1, TimeUnit.MINUTES);",
          "336:         Assertions.assertEquals(1, migrationClient.capturedConfigs.size());",
          "337:         Assertions.assertEquals(1, metadataPropagator.images);",
          "338:         Assertions.assertEquals(0, metadataPropagator.deltas);",
          "340:         delta = new MetadataDelta(image);",
          "341:         delta.replay(new BrokerRegistrationChangeRecord()",
          "342:             .setBrokerId(1)",
          "343:             .setBrokerEpoch(0)",
          "344:             .setFenced(BrokerRegistrationFencingChange.NONE.value())",
          "345:             .setInControlledShutdown(BrokerRegistrationInControlledShutdownChange.IN_CONTROLLED_SHUTDOWN.value()));",
          "346:         provenance = new MetadataProvenance(130, 1, 3);",
          "347:         image = delta.apply(provenance);",
          "348:         enqueueMetadataChangeEventWithFuture(driver, delta, image, provenance).get(1, TimeUnit.MINUTES);",
          "350:         Assertions.assertEquals(1, metadataPropagator.images);",
          "351:         Assertions.assertEquals(1, metadataPropagator.deltas);",
          "353:         driver.close();",
          "",
          "[Added Lines]",
          "329:         try (KRaftMigrationDriver driver = new KRaftMigrationDriver(",
          "335:             new MockFaultHandler(\"test\"),",
          "336:             quorumFeatures,",
          "337:             mockTime",
          "338:         )) {",
          "340:             MetadataImage image = MetadataImage.EMPTY;",
          "341:             MetadataDelta delta = new MetadataDelta(image);",
          "343:             driver.start();",
          "344:             delta.replay(ZkMigrationState.PRE_MIGRATION.toRecord().message());",
          "345:             delta.replay(zkBrokerRecord(1));",
          "346:             delta.replay(zkBrokerRecord(2));",
          "347:             delta.replay(zkBrokerRecord(3));",
          "348:             MetadataProvenance provenance = new MetadataProvenance(100, 1, 1);",
          "349:             image = delta.apply(provenance);",
          "352:             LeaderAndEpoch newLeader = new LeaderAndEpoch(OptionalInt.of(3000), 1);",
          "353:             driver.onControllerChange(newLeader);",
          "354:             driver.onMetadataUpdate(delta, image, new LogDeltaManifest(provenance, newLeader, 1, 100, 42));",
          "356:             TestUtils.waitForCondition(() -> driver.migrationState().get(1, TimeUnit.MINUTES).equals(MigrationDriverState.DUAL_WRITE),",
          "357:                 \"Waiting for KRaftMigrationDriver to enter DUAL_WRITE state\");",
          "359:             Assertions.assertEquals(1, metadataPropagator.images);",
          "360:             Assertions.assertEquals(0, metadataPropagator.deltas);",
          "362:             delta = new MetadataDelta(image);",
          "363:             delta.replay(new ConfigRecord()",
          "364:                 .setResourceType(ConfigResource.Type.BROKER.id())",
          "365:                 .setResourceName(\"1\")",
          "366:                 .setName(\"foo\")",
          "367:                 .setValue(\"bar\"));",
          "368:             provenance = new MetadataProvenance(120, 1, 2);",
          "369:             image = delta.apply(provenance);",
          "370:             enqueueMetadataChangeEventWithFuture(driver, delta, image, provenance).get(1, TimeUnit.MINUTES);",
          "372:             Assertions.assertEquals(1, migrationClient.capturedConfigs.size());",
          "373:             Assertions.assertEquals(1, metadataPropagator.images);",
          "374:             Assertions.assertEquals(0, metadataPropagator.deltas);",
          "376:             delta = new MetadataDelta(image);",
          "377:             delta.replay(new BrokerRegistrationChangeRecord()",
          "378:                 .setBrokerId(1)",
          "379:                 .setBrokerEpoch(0)",
          "380:                 .setFenced(BrokerRegistrationFencingChange.NONE.value())",
          "381:                 .setInControlledShutdown(BrokerRegistrationInControlledShutdownChange.IN_CONTROLLED_SHUTDOWN.value()));",
          "382:             provenance = new MetadataProvenance(130, 1, 3);",
          "383:             image = delta.apply(provenance);",
          "384:             enqueueMetadataChangeEventWithFuture(driver, delta, image, provenance).get(1, TimeUnit.MINUTES);",
          "386:             Assertions.assertEquals(1, metadataPropagator.images);",
          "387:             Assertions.assertEquals(1, metadataPropagator.deltas);",
          "388:         }",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "381:             migrationClient,",
          "382:             metadataPropagator,",
          "383:             metadataPublisher -> { },",
          "385:         )) {",
          "386:             MetadataImage image = MetadataImage.EMPTY;",
          "387:             MetadataDelta delta = new MetadataDelta(image);",
          "",
          "[Removed Lines]",
          "384:             faultHandler",
          "",
          "[Added Lines]",
          "419:             faultHandler,",
          "420:             quorumFeatures,",
          "421:             mockTime",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "400:             driver.onMetadataUpdate(delta, image, new LogDeltaManifest(provenance,",
          "401:                 new LeaderAndEpoch(OptionalInt.of(3000), 1), 1, 100, 42));",
          "402:             Assertions.assertTrue(claimLeaderAttempts.await(1, TimeUnit.MINUTES));",
          "406:             if (authException) {",
          "407:                 Assertions.assertEquals(MigrationClientAuthException.class, faultHandler.firstException().getCause().getClass());",
          "",
          "[Removed Lines]",
          "403:             TestUtils.waitForCondition(() -> driver.migrationState().get(1, TimeUnit.MINUTES).equals(MigrationDriverState.ZK_MIGRATION),",
          "404:                 \"Waiting for KRaftMigrationDriver to enter ZK_MIGRATION state\");",
          "",
          "[Added Lines]",
          "440:             TestUtils.waitForCondition(() -> driver.migrationState().get(1, TimeUnit.MINUTES).equals(MigrationDriverState.DUAL_WRITE),",
          "441:                 \"Waiting for KRaftMigrationDriver to enter DUAL_WRITE state\");",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "412:     }",
          "414:     @Test",
          "415:     public void testSkipWaitForBrokersInDualWrite() throws Exception {",
          "416:         CountingMetadataPropagator metadataPropagator = new CountingMetadataPropagator();",
          "417:         CapturingMigrationClient migrationClient = new CapturingMigrationClient(Collections.emptySet());",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "452:     public void testShouldNotMoveToNextStateIfControllerNodesAreNotReadyToMigrate() throws Exception {",
          "453:         CountingMetadataPropagator metadataPropagator = new CountingMetadataPropagator();",
          "454:         CapturingMigrationClient migrationClient = new CapturingMigrationClient(new HashSet<>(Arrays.asList(1)));",
          "455:         apiVersions.remove(\"6\");",
          "457:         try (KRaftMigrationDriver driver = new KRaftMigrationDriver(",
          "458:             3000,",
          "459:             new NoOpRecordConsumer(),",
          "460:             migrationClient,",
          "461:             metadataPropagator,",
          "462:             metadataPublisher -> {",
          "463:             },",
          "464:             new MockFaultHandler(\"test\"),",
          "465:             quorumFeatures,",
          "466:             mockTime",
          "467:         )) {",
          "469:             MetadataImage image = MetadataImage.EMPTY;",
          "470:             MetadataDelta delta = new MetadataDelta(image);",
          "472:             driver.start();",
          "473:             delta.replay(ZkMigrationState.PRE_MIGRATION.toRecord().message());",
          "474:             delta.replay(zkBrokerRecord(1));",
          "475:             MetadataProvenance provenance = new MetadataProvenance(100, 1, 1);",
          "476:             image = delta.apply(provenance);",
          "479:             LeaderAndEpoch newLeader = new LeaderAndEpoch(OptionalInt.of(3000), 1);",
          "480:             driver.onControllerChange(newLeader);",
          "481:             driver.onMetadataUpdate(delta, image, new LogDeltaManifest(provenance, newLeader, 1, 100, 42));",
          "484:             TestUtils.waitForCondition(() -> driver.migrationState().get(1, TimeUnit.MINUTES).equals(MigrationDriverState.WAIT_FOR_CONTROLLER_QUORUM),",
          "485:                 \"Waiting for KRaftMigrationDriver to enter WAIT_FOR_CONTROLLER_QUORUM state\");",
          "488:             apiVersions.update(\"6\", NodeApiVersions.create());",
          "489:             driver.migrationState().get(1, TimeUnit.MINUTES).equals(MigrationDriverState.WAIT_FOR_CONTROLLER_QUORUM);",
          "492:             apiVersions.update(\"6\", new NodeApiVersions(Collections.emptyList(), Collections.emptyList(), true));",
          "493:             TestUtils.waitForCondition(() -> driver.migrationState().get(1, TimeUnit.MINUTES).equals(MigrationDriverState.DUAL_WRITE),",
          "494:                 \"Waiting for KRaftMigrationDriver to enter DUAL_WRITE state\");",
          "495:         }",
          "496:     }",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "422:                 migrationClient,",
          "423:                 metadataPropagator,",
          "424:                 metadataPublisher -> { },",
          "426:         )) {",
          "427:             MetadataImage image = MetadataImage.EMPTY;",
          "428:             MetadataDelta delta = new MetadataDelta(image);",
          "",
          "[Removed Lines]",
          "425:                 faultHandler",
          "",
          "[Added Lines]",
          "508:                 faultHandler,",
          "509:                 quorumFeatures,",
          "510:                 mockTime",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "0822ce0ed1a106a510930bc9ac53a266f54684d7",
      "candidate_info": {
        "commit_hash": "0822ce0ed1a106a510930bc9ac53a266f54684d7",
        "repo": "apache/kafka",
        "commit_url": "https://github.com/apache/kafka/commit/0822ce0ed1a106a510930bc9ac53a266f54684d7",
        "files": [
          "checkstyle/suppressions.xml",
          "core/src/main/scala/kafka/server/ControllerServer.scala",
          "core/src/main/scala/kafka/zk/ZkMigrationClient.scala",
          "core/src/main/scala/kafka/zk/migration/ZkAclMigrationClient.scala",
          "core/src/main/scala/kafka/zk/migration/ZkConfigMigrationClient.scala",
          "core/src/main/scala/kafka/zk/migration/ZkTopicMigrationClient.scala",
          "core/src/test/scala/integration/kafka/zk/ZkMigrationIntegrationTest.scala",
          "core/src/test/scala/unit/kafka/zk/ZkMigrationClientTest.scala",
          "core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala",
          "core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala",
          "core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala",
          "core/src/test/scala/unit/kafka/zk/migration/ZkMigrationTestHarness.scala",
          "metadata/src/main/java/org/apache/kafka/image/AclsDelta.java",
          "metadata/src/main/java/org/apache/kafka/image/ConfigurationsImage.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/AclMigrationClient.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/ConfigMigrationClient.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationOperation.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/MigrationClient.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/TopicMigrationClient.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/ZkMigrationLeadershipState.java",
          "metadata/src/test/java/org/apache/kafka/image/TopicsImageTest.java",
          "metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingAclMigrationClient.java",
          "metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingConfigMigrationClient.java",
          "metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingMigrationClient.java",
          "metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingTopicMigrationClient.java",
          "metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationDriverTest.java",
          "tests/kafkatest/tests/core/zookeeper_migration_test.py"
        ],
        "message": "KAFKA-14840: Support for snapshots during ZK migration (#13461)\n\nThis patch adds support for handling metadata snapshots while in dual-write mode. Prior to this change, if the active\ncontroller loaded a snapshot, it would get out of sync with the ZK state.\n\nIn order to reconcile the snapshot state with ZK, several methods were added to scan through the metadata in ZK to\ncompute differences with the MetadataImage. Since this introduced a lot of code, I opted to split out a lot of methods\nfrom ZkMigrationClient into their own client interfaces, such as TopicMigrationClient, ConfigMigrationClient, and\nAclMigrationClient. Each of these has some iterator method that lets the caller examine the ZK state in a single pass\nand without using too much memory.\n\nReviewers: Colin P. McCabe <cmccabe@apache.org>, Luke Chen <showuon@gmail.com>",
        "before_after_code_files": [
          "core/src/main/scala/kafka/server/ControllerServer.scala||core/src/main/scala/kafka/server/ControllerServer.scala",
          "core/src/main/scala/kafka/zk/ZkMigrationClient.scala||core/src/main/scala/kafka/zk/ZkMigrationClient.scala",
          "core/src/main/scala/kafka/zk/migration/ZkAclMigrationClient.scala||core/src/main/scala/kafka/zk/migration/ZkAclMigrationClient.scala",
          "core/src/main/scala/kafka/zk/migration/ZkConfigMigrationClient.scala||core/src/main/scala/kafka/zk/migration/ZkConfigMigrationClient.scala",
          "core/src/main/scala/kafka/zk/migration/ZkTopicMigrationClient.scala||core/src/main/scala/kafka/zk/migration/ZkTopicMigrationClient.scala",
          "core/src/test/scala/integration/kafka/zk/ZkMigrationIntegrationTest.scala||core/src/test/scala/integration/kafka/zk/ZkMigrationIntegrationTest.scala",
          "core/src/test/scala/unit/kafka/zk/ZkMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/ZkMigrationClientTest.scala",
          "core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala",
          "core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala",
          "core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala",
          "core/src/test/scala/unit/kafka/zk/migration/ZkMigrationTestHarness.scala||core/src/test/scala/unit/kafka/zk/migration/ZkMigrationTestHarness.scala",
          "metadata/src/main/java/org/apache/kafka/image/AclsDelta.java||metadata/src/main/java/org/apache/kafka/image/AclsDelta.java",
          "metadata/src/main/java/org/apache/kafka/image/ConfigurationsImage.java||metadata/src/main/java/org/apache/kafka/image/ConfigurationsImage.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/AclMigrationClient.java||metadata/src/main/java/org/apache/kafka/metadata/migration/AclMigrationClient.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/ConfigMigrationClient.java||metadata/src/main/java/org/apache/kafka/metadata/migration/ConfigMigrationClient.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationOperation.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationOperation.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/MigrationClient.java||metadata/src/main/java/org/apache/kafka/metadata/migration/MigrationClient.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/TopicMigrationClient.java||metadata/src/main/java/org/apache/kafka/metadata/migration/TopicMigrationClient.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/ZkMigrationLeadershipState.java||metadata/src/main/java/org/apache/kafka/metadata/migration/ZkMigrationLeadershipState.java",
          "metadata/src/test/java/org/apache/kafka/image/TopicsImageTest.java||metadata/src/test/java/org/apache/kafka/image/TopicsImageTest.java",
          "metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingAclMigrationClient.java||metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingAclMigrationClient.java",
          "metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingConfigMigrationClient.java||metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingConfigMigrationClient.java",
          "metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingMigrationClient.java||metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingMigrationClient.java",
          "metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingTopicMigrationClient.java||metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingTopicMigrationClient.java",
          "metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationDriverTest.java||metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationDriverTest.java",
          "tests/kafkatest/tests/core/zookeeper_migration_test.py||tests/kafkatest/tests/core/zookeeper_migration_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala",
            "core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala",
            "core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala",
            "metadata/src/main/java/org/apache/kafka/image/AclsDelta.java||metadata/src/main/java/org/apache/kafka/image/AclsDelta.java",
            "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java",
            "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java"
          ],
          "candidate": [
            "core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala",
            "core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala",
            "core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala",
            "metadata/src/main/java/org/apache/kafka/image/AclsDelta.java||metadata/src/main/java/org/apache/kafka/image/AclsDelta.java",
            "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java",
            "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java"
          ]
        }
      },
      "candidate_diff": {
        "core/src/main/scala/kafka/server/ControllerServer.scala||core/src/main/scala/kafka/server/ControllerServer.scala": [
          "File: core/src/main/scala/kafka/server/ControllerServer.scala -> core/src/main/scala/kafka/server/ControllerServer.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "259:             config.passwordEncoderIterations)",
          "260:           case None => PasswordEncoder.noop()",
          "261:         }",
          "263:         val propagator: LegacyPropagator = new MigrationPropagator(config.nodeId, config)",
          "264:         val migrationDriver = new KRaftMigrationDriver(",
          "265:           config.nodeId,",
          "",
          "[Removed Lines]",
          "262:         val migrationClient = new ZkMigrationClient(zkClient, zkConfigEncoder)",
          "",
          "[Added Lines]",
          "262:         val migrationClient = ZkMigrationClient(zkClient, zkConfigEncoder)",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/zk/ZkMigrationClient.scala||core/src/main/scala/kafka/zk/ZkMigrationClient.scala": [
          "File: core/src/main/scala/kafka/zk/ZkMigrationClient.scala -> core/src/main/scala/kafka/zk/ZkMigrationClient.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: package kafka.zk",
          "24: import kafka.utils.{Logging, PasswordEncoder}",
          "26: import kafka.zookeeper._",
          "27: import org.apache.kafka.clients.admin.ScramMechanism",
          "28: import org.apache.kafka.common.acl.AccessControlEntry",
          "29: import org.apache.kafka.common.config.ConfigResource",
          "30: import org.apache.kafka.common.errors.ControllerMovedException",
          "32: import org.apache.kafka.common.metadata._",
          "34: import org.apache.kafka.common.resource.ResourcePattern",
          "39: import org.apache.kafka.server.common.{ApiMessageAndVersion, ProducerIdsBlock}",
          "44: import java.util.Properties",
          "46: import scala.collection.Seq",
          "47: import scala.jdk.CollectionConverters._",
          "49: object ZkMigrationClient {",
          "50:   val MaxBatchSize = 100",
          "",
          "[Removed Lines]",
          "19: import kafka.api.LeaderAndIsr",
          "20: import kafka.controller.{LeaderIsrAndControllerEpoch, ReplicaAssignment}",
          "21: import kafka.security.authorizer.{AclAuthorizer, AclEntry}",
          "22: import kafka.security.authorizer.AclAuthorizer.{ResourceOrdering, VersionedAcls}",
          "23: import kafka.server.{ConfigEntityName, ConfigType, DynamicBrokerConfig, ZkAdminManager}",
          "25: import kafka.zk.TopicZNode.TopicIdReplicaAssignment",
          "31: import org.apache.kafka.common.metadata.ClientQuotaRecord.EntityData",
          "33: import org.apache.kafka.common.quota.ClientQuotaEntity",
          "35: import org.apache.kafka.common.{TopicPartition, Uuid}",
          "36: import org.apache.kafka.common.security.scram.internals.ScramCredentialUtils",
          "37: import org.apache.kafka.metadata.{LeaderRecoveryState, PartitionRegistration}",
          "38: import org.apache.kafka.metadata.migration.{MigrationClient, MigrationClientAuthException, MigrationClientException, ZkMigrationLeadershipState}",
          "40: import org.apache.zookeeper.KeeperException.{AuthFailedException, Code, NoAuthException, SessionClosedRequireAuthException}",
          "41: import org.apache.zookeeper.{CreateMode, KeeperException}",
          "43: import java.util",
          "45: import java.util.function.{BiConsumer, Consumer}",
          "51: }",
          "58: class ZkMigrationClient(",
          "59:   zkClient: KafkaZkClient,",
          "60:   zkConfigEncoder: PasswordEncoder",
          "61: ) extends MigrationClient with Logging {",
          "",
          "[Added Lines]",
          "20: import kafka.zk.ZkMigrationClient.wrapZkException",
          "21: import kafka.zk.migration.{ZkAclMigrationClient, ZkConfigMigrationClient, ZkTopicMigrationClient}",
          "29: import org.apache.kafka.common.security.scram.ScramCredential",
          "30: import org.apache.kafka.common.{TopicIdPartition, Uuid}",
          "31: import org.apache.kafka.metadata.PartitionRegistration",
          "32: import org.apache.kafka.metadata.migration.ConfigMigrationClient.ClientQuotaVisitor",
          "33: import org.apache.kafka.metadata.migration.TopicMigrationClient.{TopicVisitor, TopicVisitorInterest}",
          "34: import org.apache.kafka.metadata.migration._",
          "36: import org.apache.zookeeper.KeeperException",
          "37: import org.apache.zookeeper.KeeperException.{AuthFailedException, NoAuthException, SessionClosedRequireAuthException}",
          "39: import java.{lang, util}",
          "41: import java.util.function.Consumer",
          "49:   def apply(",
          "50:     zkClient: KafkaZkClient,",
          "51:     zkConfigEncoder: PasswordEncoder",
          "52:   ): ZkMigrationClient = {",
          "53:     val topicClient = new ZkTopicMigrationClient(zkClient)",
          "54:     val configClient = new ZkConfigMigrationClient(zkClient, zkConfigEncoder)",
          "55:     val aclClient = new ZkAclMigrationClient(zkClient)",
          "56:     new ZkMigrationClient(zkClient, topicClient, configClient, aclClient)",
          "57:   }",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "68:   @throws(classOf[MigrationClientException])",
          "70:     try {",
          "71:       fn",
          "72:     } catch {",
          "",
          "[Removed Lines]",
          "69:   private def wrapZkException[T](fn: => T): T = {",
          "",
          "[Added Lines]",
          "65:   def wrapZkException[T](fn: => T): T = {",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "78:     }",
          "79:   }",
          "81:   override def getOrCreateMigrationRecoveryState(",
          "82:     initialState: ZkMigrationLeadershipState",
          "83:   ): ZkMigrationLeadershipState = wrapZkException {",
          "84:       zkClient.createTopLevelPaths()",
          "86:       zkClient.getOrCreateMigrationState(initialState)",
          "87:     }",
          "",
          "[Removed Lines]",
          "85:       zkClient.createAclPaths()",
          "",
          "[Added Lines]",
          "77:   @throws(classOf[MigrationClientException])",
          "78:   def logAndRethrow[T](logger: Logging, msg: String)(fn: => T): T = {",
          "79:     try {",
          "80:       fn",
          "81:     } catch {",
          "82:       case e: Throwable =>",
          "83:         logger.error(msg, e)",
          "84:         throw e",
          "85:     }",
          "86:   }",
          "87: }",
          "95: class ZkMigrationClient(",
          "96:   zkClient: KafkaZkClient,",
          "97:   topicClient: TopicMigrationClient,",
          "98:   configClient: ConfigMigrationClient,",
          "99:   aclClient: AclMigrationClient",
          "100: ) extends MigrationClient with Logging {",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "121:     recordConsumer: Consumer[util.List[ApiMessageAndVersion]],",
          "122:     brokerIdConsumer: Consumer[Integer]",
          "123:   ): Unit = wrapZkException {",
          "139:         val record = new PartitionRecord()",
          "162:         topicBatch.add(new ApiMessageAndVersion(record, 0.toShort))",
          "163:       }",
          "172:       }",
          "173:       recordConsumer.accept(topicBatch)",
          "174:     }",
          "175:   }",
          "177:   def migrateBrokerConfigs(",
          "179:   ): Unit = wrapZkException {",
          "195:         batch.add(new ApiMessageAndVersion(new ConfigRecord()",
          "196:           .setResourceType(ConfigResource.Type.BROKER.id)",
          "198:           .setName(key)",
          "200:       }",
          "205:   }",
          "207:   def migrateClientQuotas(",
          "208:     recordConsumer: Consumer[util.List[ApiMessageAndVersion]]",
          "209:   ): Unit = wrapZkException {",
          "215:         val batch = new util.ArrayList[ApiMessageAndVersion]()",
          "231:           batch.add(new ApiMessageAndVersion(new ClientQuotaRecord()",
          "233:             .setKey(key)",
          "234:             .setValue(value), 0.toShort))",
          "236:         recordConsumer.accept(batch)",
          "237:       }",
          "258:       }",
          "263:   }",
          "265:   def migrateProducerId(",
          "",
          "[Removed Lines]",
          "124:     val topics = zkClient.getAllTopicsInCluster()",
          "125:     val topicConfigs = zkClient.getEntitiesConfigs(ConfigType.Topic, topics)",
          "126:     val replicaAssignmentAndTopicIds = zkClient.getReplicaAssignmentAndTopicIdForTopics(topics)",
          "127:     replicaAssignmentAndTopicIds.foreach { case TopicIdReplicaAssignment(topic, topicIdOpt, partitionAssignments) =>",
          "128:       val partitions = partitionAssignments.keys.toSeq",
          "129:       val leaderIsrAndControllerEpochs = zkClient.getTopicPartitionStates(partitions)",
          "130:       val topicBatch = new util.ArrayList[ApiMessageAndVersion]()",
          "131:       topicBatch.add(new ApiMessageAndVersion(new TopicRecord()",
          "132:         .setName(topic)",
          "133:         .setTopicId(topicIdOpt.get), 0.toShort))",
          "135:       partitionAssignments.foreach { case (topicPartition, replicaAssignment) =>",
          "136:         replicaAssignment.replicas.foreach(brokerIdConsumer.accept(_))",
          "137:         replicaAssignment.addingReplicas.foreach(brokerIdConsumer.accept(_))",
          "138:         val replicaList = replicaAssignment.replicas.map(Integer.valueOf).asJava",
          "140:           .setTopicId(topicIdOpt.get)",
          "141:           .setPartitionId(topicPartition.partition)",
          "142:           .setReplicas(replicaList)",
          "143:           .setAddingReplicas(replicaAssignment.addingReplicas.map(Integer.valueOf).asJava)",
          "144:           .setRemovingReplicas(replicaAssignment.removingReplicas.map(Integer.valueOf).asJava)",
          "145:         leaderIsrAndControllerEpochs.get(topicPartition) match {",
          "146:           case Some(leaderIsrAndEpoch) => record",
          "147:               .setIsr(leaderIsrAndEpoch.leaderAndIsr.isr.map(Integer.valueOf).asJava)",
          "148:               .setLeader(leaderIsrAndEpoch.leaderAndIsr.leader)",
          "149:               .setLeaderEpoch(leaderIsrAndEpoch.leaderAndIsr.leaderEpoch)",
          "150:               .setPartitionEpoch(leaderIsrAndEpoch.leaderAndIsr.partitionEpoch)",
          "151:               .setLeaderRecoveryState(leaderIsrAndEpoch.leaderAndIsr.leaderRecoveryState.value())",
          "152:           case None =>",
          "153:             warn(s\"Could not find partition state in ZK for $topicPartition. Initializing this partition \" +",
          "154:               s\"with ISR={$replicaList} and leaderEpoch=0.\")",
          "155:             record",
          "156:               .setIsr(replicaList)",
          "157:               .setLeader(replicaList.get(0))",
          "158:               .setLeaderEpoch(0)",
          "159:               .setPartitionEpoch(0)",
          "160:               .setLeaderRecoveryState(LeaderRecoveryState.RECOVERED.value())",
          "161:         }",
          "165:       val props = topicConfigs(topic)",
          "166:       props.forEach { case (key: Object, value: Object) =>",
          "167:         topicBatch.add(new ApiMessageAndVersion(new ConfigRecord()",
          "168:           .setResourceType(ConfigResource.Type.TOPIC.id)",
          "169:           .setResourceName(topic)",
          "170:           .setName(key.toString)",
          "171:           .setValue(value.toString), 0.toShort))",
          "178:     recordConsumer: Consumer[util.List[ApiMessageAndVersion]]",
          "180:     val batch = new util.ArrayList[ApiMessageAndVersion]()",
          "182:     val brokerEntities = zkClient.getAllEntitiesWithConfig(ConfigType.Broker)",
          "183:     zkClient.getEntitiesConfigs(ConfigType.Broker, brokerEntities.toSet).foreach { case (broker, props) =>",
          "184:       val brokerResource = if (broker == ConfigEntityName.Default) {",
          "185:         \"\"",
          "186:       } else {",
          "187:         broker",
          "188:       }",
          "189:       props.asScala.foreach { case (key, value) =>",
          "190:         val newValue = if (DynamicBrokerConfig.isPasswordConfig(key))",
          "191:           zkConfigEncoder.decode(value).value",
          "192:         else",
          "193:           value",
          "197:           .setResourceName(brokerResource)",
          "199:           .setValue(newValue), 0.toShort))",
          "201:     }",
          "202:     if (!batch.isEmpty) {",
          "203:       recordConsumer.accept(batch)",
          "204:     }",
          "210:     val adminZkClient = new AdminZkClient(zkClient)",
          "212:     def migrateEntityType(entityType: String): Unit = {",
          "213:       adminZkClient.fetchAllEntityConfigs(entityType).foreach { case (name, props) =>",
          "214:         val entity = new EntityData().setEntityType(entityType).setEntityName(name)",
          "216:         ScramMechanism.values().filter(_ != ScramMechanism.UNKNOWN).foreach { mechanism =>",
          "217:           val propertyValue = props.getProperty(mechanism.mechanismName)",
          "218:           if (propertyValue != null) {",
          "219:             val scramCredentials =  ScramCredentialUtils.credentialFromString(propertyValue)",
          "220:             batch.add(new ApiMessageAndVersion(new UserScramCredentialRecord()",
          "221:               .setName(name)",
          "222:               .setMechanism(mechanism.`type`)",
          "223:               .setSalt(scramCredentials.salt)",
          "224:               .setStoredKey(scramCredentials.storedKey)",
          "225:               .setServerKey(scramCredentials.serverKey)",
          "226:               .setIterations(scramCredentials.iterations), 0.toShort))",
          "227:             props.remove(mechanism.mechanismName)",
          "228:           }",
          "229:         }",
          "230:         ZkAdminManager.clientQuotaPropsToDoubleMap(props.asScala).foreach { case (key: String, value: Double) =>",
          "232:             .setEntity(List(entity).asJava)",
          "235:         }",
          "238:     }",
          "240:     migrateEntityType(ConfigType.User)",
          "241:     migrateEntityType(ConfigType.Client)",
          "242:     adminZkClient.fetchAllChildEntityConfigs(ConfigType.User, ConfigType.Client).foreach { case (name, props) =>",
          "244:       val components = name.split(\"/\")",
          "245:       if (components.size != 3 || components(1) != \"clients\")",
          "246:         throw new IllegalArgumentException(s\"Unexpected config path: ${name}\")",
          "247:       val entity = List(",
          "248:         new EntityData().setEntityType(ConfigType.User).setEntityName(components(0)),",
          "249:         new EntityData().setEntityType(ConfigType.Client).setEntityName(components(2))",
          "250:       )",
          "252:       val batch = new util.ArrayList[ApiMessageAndVersion]()",
          "253:       ZkAdminManager.clientQuotaPropsToDoubleMap(props.asScala).foreach { case (key: String, value: Double) =>",
          "254:         batch.add(new ApiMessageAndVersion(new ClientQuotaRecord()",
          "255:           .setEntity(entity.asJava)",
          "256:           .setKey(key)",
          "257:           .setValue(value), 0.toShort))",
          "259:       recordConsumer.accept(batch)",
          "260:     }",
          "262:     migrateEntityType(ConfigType.Ip)",
          "",
          "[Added Lines]",
          "144:     var topicBatch = new util.ArrayList[ApiMessageAndVersion]()",
          "145:     topicClient.iterateTopics(",
          "146:       util.EnumSet.allOf(classOf[TopicVisitorInterest]),",
          "147:       new TopicVisitor() {",
          "148:       override def visitTopic(topicName: String, topicId: Uuid, assignments: util.Map[Integer, util.List[Integer]]): Unit = {",
          "149:         if (!topicBatch.isEmpty) {",
          "150:           recordConsumer.accept(topicBatch)",
          "151:           topicBatch = new util.ArrayList[ApiMessageAndVersion]()",
          "152:         }",
          "154:         topicBatch.add(new ApiMessageAndVersion(new TopicRecord()",
          "155:           .setName(topicName)",
          "156:           .setTopicId(topicId), 0.toShort))",
          "157:       }",
          "159:       override def visitPartition(topicIdPartition: TopicIdPartition, partitionRegistration: PartitionRegistration): Unit = {",
          "161:           .setTopicId(topicIdPartition.topicId())",
          "162:           .setPartitionId(topicIdPartition.partition())",
          "163:           .setReplicas(partitionRegistration.replicas.map(Integer.valueOf).toList.asJava)",
          "164:           .setAddingReplicas(partitionRegistration.addingReplicas.map(Integer.valueOf).toList.asJava)",
          "165:           .setRemovingReplicas(partitionRegistration.removingReplicas.map(Integer.valueOf).toList.asJava)",
          "166:           .setIsr(partitionRegistration.isr.map(Integer.valueOf).toList.asJava)",
          "167:           .setLeader(partitionRegistration.leader)",
          "168:           .setLeaderEpoch(partitionRegistration.leaderEpoch)",
          "169:           .setPartitionEpoch(partitionRegistration.partitionEpoch)",
          "170:           .setLeaderRecoveryState(partitionRegistration.leaderRecoveryState.value())",
          "171:         partitionRegistration.replicas.foreach(brokerIdConsumer.accept(_))",
          "172:         partitionRegistration.addingReplicas.foreach(brokerIdConsumer.accept(_))",
          "176:       override def visitConfigs(topicName: String, topicProps: Properties): Unit = {",
          "177:         topicProps.forEach((key: Any, value: Any) => {",
          "178:           topicBatch.add(new ApiMessageAndVersion(new ConfigRecord()",
          "179:             .setResourceType(ConfigResource.Type.TOPIC.id)",
          "180:             .setResourceName(topicName)",
          "181:             .setName(key.toString)",
          "182:             .setValue(value.toString), 0.toShort))",
          "183:         })",
          "185:     })",
          "187:     if (!topicBatch.isEmpty) {",
          "193:     recordConsumer: Consumer[util.List[ApiMessageAndVersion]],",
          "194:     brokerIdConsumer: Consumer[Integer]",
          "196:     configClient.iterateBrokerConfigs((broker, props) => {",
          "197:       brokerIdConsumer.accept(Integer.valueOf(broker))",
          "198:       val batch = new util.ArrayList[ApiMessageAndVersion]()",
          "199:       props.forEach((key, value) => {",
          "202:           .setResourceName(broker)",
          "204:           .setValue(value), 0.toShort))",
          "205:       })",
          "206:       if (!batch.isEmpty) {",
          "207:         recordConsumer.accept(batch)",
          "209:     })",
          "215:     configClient.iterateClientQuotas(new ClientQuotaVisitor {",
          "216:       override def visitClientQuota(",
          "217:         entityDataList: util.List[ClientQuotaRecord.EntityData],",
          "218:         quotas: util.Map[String, lang.Double]",
          "219:       ): Unit = {",
          "221:         quotas.forEach((key, value) => {",
          "223:             .setEntity(entityDataList)",
          "226:         })",
          "230:       override def visitScramCredential(",
          "231:         userName: String,",
          "232:         scramMechanism: ScramMechanism,",
          "233:         scramCredential: ScramCredential",
          "234:       ): Unit = {",
          "235:         val batch = new util.ArrayList[ApiMessageAndVersion]()",
          "236:         batch.add(new ApiMessageAndVersion(new UserScramCredentialRecord()",
          "237:           .setName(userName)",
          "238:           .setMechanism(scramMechanism.`type`)",
          "239:           .setSalt(scramCredential.salt)",
          "240:           .setStoredKey(scramCredential.storedKey)",
          "241:           .setServerKey(scramCredential.serverKey)",
          "242:           .setIterations(scramCredential.iterations), 0.toShort))",
          "243:         recordConsumer.accept(batch)",
          "245:     })",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "277:     }",
          "278:   }",
          "292:   def migrateAcls(recordConsumer: Consumer[util.List[ApiMessageAndVersion]]): Unit = {",
          "294:       override def accept(resourcePattern: ResourcePattern, acls: util.Set[AccessControlEntry]): Unit = {",
          "295:         val batch = new util.ArrayList[ApiMessageAndVersion]()",
          "296:         acls.asScala.foreach { entry =>",
          "",
          "[Removed Lines]",
          "280:   override def iterateAcls(aclConsumer: BiConsumer[ResourcePattern, util.Set[AccessControlEntry]]): Unit = {",
          "282:     var allAcls = new scala.collection.immutable.TreeMap[ResourcePattern, VersionedAcls]()(new ResourceOrdering)",
          "283:     def updateAcls(resourcePattern: ResourcePattern, versionedAcls: VersionedAcls): Unit = {",
          "284:       allAcls = allAcls.updated(resourcePattern, versionedAcls)",
          "285:     }",
          "286:     AclAuthorizer.loadAllAcls(zkClient, this, updateAcls)",
          "287:     allAcls.foreach { case (resourcePattern, versionedAcls) =>",
          "288:       aclConsumer.accept(resourcePattern, versionedAcls.acls.map(_.ace).asJava)",
          "289:     }",
          "290:   }",
          "293:     iterateAcls(new util.function.BiConsumer[ResourcePattern, util.Set[AccessControlEntry]]() {",
          "",
          "[Added Lines]",
          "264:     aclClient.iterateAcls(new util.function.BiConsumer[ResourcePattern, util.Set[AccessControlEntry]]() {",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "320:     brokerIdConsumer: Consumer[Integer]",
          "321:   ): Unit = {",
          "322:     migrateTopics(batchConsumer, brokerIdConsumer)",
          "324:     migrateClientQuotas(batchConsumer)",
          "325:     migrateProducerId(batchConsumer)",
          "326:     migrateAcls(batchConsumer)",
          "",
          "[Removed Lines]",
          "323:     migrateBrokerConfigs(batchConsumer)",
          "",
          "[Added Lines]",
          "294:     migrateBrokerConfigs(batchConsumer, brokerIdConsumer)",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "330:     new util.HashSet[Integer](zkClient.getSortedBrokerList.map(Integer.valueOf).toSet.asJava)",
          "331:   }",
          "540:   override def writeProducerId(",
          "541:     nextProducerId: Long,",
          "542:     state: ZkMigrationLeadershipState",
          "",
          "[Removed Lines]",
          "333:   override def readBrokerIdsFromTopicAssignments(): util.Set[Integer] = wrapZkException {",
          "334:     val topics = zkClient.getAllTopicsInCluster()",
          "335:     val replicaAssignmentAndTopicIds = zkClient.getReplicaAssignmentAndTopicIdForTopics(topics)",
          "336:     val brokersWithAssignments = new util.HashSet[Integer]()",
          "337:     replicaAssignmentAndTopicIds.foreach { case TopicIdReplicaAssignment(_, _, assignments) =>",
          "338:       assignments.values.foreach { assignment =>",
          "339:         assignment.replicas.foreach { brokerId => brokersWithAssignments.add(brokerId) }",
          "340:       }",
          "341:     }",
          "342:     brokersWithAssignments",
          "343:   }",
          "345:   override def createTopic(",
          "346:     topicName: String,",
          "347:     topicId: Uuid,",
          "348:     partitions: util.Map[Integer, PartitionRegistration],",
          "349:     state: ZkMigrationLeadershipState",
          "350:   ): ZkMigrationLeadershipState = wrapZkException {",
          "351:     val assignments = partitions.asScala.map { case (partitionId, partition) =>",
          "352:       new TopicPartition(topicName, partitionId) ->",
          "353:         ReplicaAssignment(partition.replicas, partition.addingReplicas, partition.removingReplicas)",
          "354:     }",
          "356:     val createTopicZNode = {",
          "357:       val path = TopicZNode.path(topicName)",
          "358:       CreateRequest(",
          "359:         path,",
          "360:         TopicZNode.encode(Some(topicId), assignments),",
          "361:         zkClient.defaultAcls(path),",
          "362:         CreateMode.PERSISTENT)",
          "363:     }",
          "364:     val createPartitionsZNode = {",
          "365:       val path = TopicPartitionsZNode.path(topicName)",
          "366:       CreateRequest(",
          "367:         path,",
          "368:         null,",
          "369:         zkClient.defaultAcls(path),",
          "370:         CreateMode.PERSISTENT)",
          "371:     }",
          "373:     val createPartitionZNodeReqs = partitions.asScala.flatMap { case (partitionId, partition) =>",
          "374:       val topicPartition = new TopicPartition(topicName, partitionId)",
          "375:       Seq(",
          "376:         createTopicPartition(topicPartition),",
          "377:         createTopicPartitionState(topicPartition, partition, state.kraftControllerEpoch())",
          "378:       )",
          "379:     }",
          "381:     val requests = Seq(createTopicZNode, createPartitionsZNode) ++ createPartitionZNodeReqs",
          "382:     val (migrationZkVersion, responses) = zkClient.retryMigrationRequestsUntilConnected(requests, state)",
          "383:     val resultCodes = responses.map { response => response.path -> response.resultCode }.toMap",
          "384:     if (resultCodes(TopicZNode.path(topicName)).equals(Code.NODEEXISTS)) {",
          "386:       state",
          "387:     } else if (resultCodes.forall { case (_, code) => code.equals(Code.OK) } ) {",
          "389:       state.withMigrationZkVersion(migrationZkVersion)",
          "390:     } else {",
          "392:       throw new MigrationClientException(s\"Failed to create or update topic $topicName. ZK operation had results $resultCodes\")",
          "393:     }",
          "394:   }",
          "396:   private def createTopicPartition(",
          "397:     topicPartition: TopicPartition",
          "398:   ): CreateRequest = wrapZkException {",
          "399:     val path = TopicPartitionZNode.path(topicPartition)",
          "400:     CreateRequest(path, null, zkClient.defaultAcls(path), CreateMode.PERSISTENT, Some(topicPartition))",
          "401:   }",
          "403:   private def partitionStatePathAndData(",
          "404:     topicPartition: TopicPartition,",
          "405:     partitionRegistration: PartitionRegistration,",
          "406:     controllerEpoch: Int",
          "407:   ): (String, Array[Byte]) = {",
          "408:     val path = TopicPartitionStateZNode.path(topicPartition)",
          "409:     val data = TopicPartitionStateZNode.encode(LeaderIsrAndControllerEpoch(LeaderAndIsr(",
          "410:       partitionRegistration.leader,",
          "411:       partitionRegistration.leaderEpoch,",
          "412:       partitionRegistration.isr.toList,",
          "413:       partitionRegistration.leaderRecoveryState,",
          "414:       partitionRegistration.partitionEpoch), controllerEpoch))",
          "415:     (path, data)",
          "416:   }",
          "418:   private def createTopicPartitionState(",
          "419:     topicPartition: TopicPartition,",
          "420:     partitionRegistration: PartitionRegistration,",
          "421:     controllerEpoch: Int",
          "422:   ): CreateRequest = {",
          "423:     val (path, data) = partitionStatePathAndData(topicPartition, partitionRegistration, controllerEpoch)",
          "424:     CreateRequest(path, data, zkClient.defaultAcls(path), CreateMode.PERSISTENT, Some(topicPartition))",
          "425:   }",
          "427:   private def updateTopicPartitionState(",
          "428:     topicPartition: TopicPartition,",
          "429:     partitionRegistration: PartitionRegistration,",
          "430:     controllerEpoch: Int",
          "431:   ): SetDataRequest = {",
          "432:     val (path, data) = partitionStatePathAndData(topicPartition, partitionRegistration, controllerEpoch)",
          "433:     SetDataRequest(path, data, ZkVersion.MatchAnyVersion, Some(topicPartition))",
          "434:   }",
          "436:   override def updateTopicPartitions(",
          "437:     topicPartitions: util.Map[String, util.Map[Integer, PartitionRegistration]],",
          "438:     state: ZkMigrationLeadershipState",
          "439:   ): ZkMigrationLeadershipState = wrapZkException {",
          "440:     val requests = topicPartitions.asScala.flatMap { case (topicName, partitionRegistrations) =>",
          "441:       partitionRegistrations.asScala.flatMap { case (partitionId, partitionRegistration) =>",
          "442:         val topicPartition = new TopicPartition(topicName, partitionId)",
          "443:         Seq(updateTopicPartitionState(topicPartition, partitionRegistration, state.kraftControllerEpoch()))",
          "444:       }",
          "445:     }",
          "446:     if (requests.isEmpty) {",
          "447:       state",
          "448:     } else {",
          "449:       val (migrationZkVersion, responses) = zkClient.retryMigrationRequestsUntilConnected(requests.toSeq, state)",
          "450:       val resultCodes = responses.map { response => response.path -> response.resultCode }.toMap",
          "451:       if (resultCodes.forall { case (_, code) => code.equals(Code.OK) } ) {",
          "452:         state.withMigrationZkVersion(migrationZkVersion)",
          "453:       } else {",
          "454:         throw new MigrationClientException(s\"Failed to update partition states: $topicPartitions. ZK transaction had results $resultCodes\")",
          "455:       }",
          "456:     }",
          "457:   }",
          "461:   def tryWriteEntityConfig(",
          "462:     entityType: String,",
          "463:     path: String,",
          "464:     props: Properties,",
          "465:     create: Boolean,",
          "466:     state: ZkMigrationLeadershipState",
          "467:   ): Option[ZkMigrationLeadershipState] = wrapZkException {",
          "468:     val configData = ConfigEntityZNode.encode(props)",
          "470:     val requests = if (create) {",
          "471:       Seq(CreateRequest(ConfigEntityZNode.path(entityType, path), configData, zkClient.defaultAcls(path), CreateMode.PERSISTENT))",
          "472:     } else {",
          "473:       Seq(SetDataRequest(ConfigEntityZNode.path(entityType, path), configData, ZkVersion.MatchAnyVersion))",
          "474:     }",
          "475:     val (migrationZkVersion, responses) = zkClient.retryMigrationRequestsUntilConnected(requests, state)",
          "476:     if (!create && responses.head.resultCode.equals(Code.NONODE)) {",
          "478:       None",
          "479:     } else if (responses.head.resultCode.equals(Code.OK)) {",
          "480:       Some(state.withMigrationZkVersion(migrationZkVersion))",
          "481:     } else {",
          "482:       throw KeeperException.create(responses.head.resultCode, path)",
          "483:     }",
          "484:   }",
          "486:   override def writeClientQuotas(",
          "487:     entity: util.Map[String, String],",
          "488:     quotas: util.Map[String, java.lang.Double],",
          "489:     scram: util.Map[String, String],",
          "490:     state: ZkMigrationLeadershipState",
          "491:   ): ZkMigrationLeadershipState = wrapZkException {",
          "492:     val entityMap = entity.asScala",
          "493:     val hasUser = entityMap.contains(ClientQuotaEntity.USER)",
          "494:     val hasClient = entityMap.contains(ClientQuotaEntity.CLIENT_ID)",
          "495:     val hasIp = entityMap.contains(ClientQuotaEntity.IP)",
          "496:     val props = new Properties()",
          "498:     scram.forEach { case (key, value) => props.put(key, value.toString) }",
          "499:     quotas.forEach { case (key, value) => props.put(key, value.toString) }",
          "500:     val (configType, path) = if (hasUser && !hasClient) {",
          "501:       (Some(ConfigType.User), Some(entityMap(ClientQuotaEntity.USER)))",
          "502:     } else if (hasUser && hasClient) {",
          "503:       (Some(ConfigType.User), Some(s\"${entityMap(ClientQuotaEntity.USER)}/clients/${entityMap(ClientQuotaEntity.CLIENT_ID)}\"))",
          "504:     } else if (hasClient) {",
          "505:       (Some(ConfigType.Client), Some(entityMap(ClientQuotaEntity.CLIENT_ID)))",
          "506:     } else if (hasIp) {",
          "507:       (Some(ConfigType.Ip), Some(entityMap(ClientQuotaEntity.IP)))",
          "508:     } else {",
          "509:       (None, None)",
          "510:     }",
          "512:     if (path.isEmpty) {",
          "513:       error(s\"Skipping unknown client quota entity $entity\")",
          "514:       return state",
          "515:     }",
          "518:     tryWriteEntityConfig(configType.get, path.get, props, create=false, state) match {",
          "519:       case Some(newState) =>",
          "520:         newState",
          "521:       case None =>",
          "524:         val createPath = if (hasUser && hasClient) {",
          "525:           s\"${ConfigEntityTypeZNode.path(configType.get)}/${entityMap(ClientQuotaEntity.USER)}/clients\"",
          "526:         } else {",
          "527:           ConfigEntityTypeZNode.path(configType.get)",
          "528:         }",
          "529:         zkClient.createRecursive(createPath, throwIfPathExists=false)",
          "530:         debug(s\"Recursively creating ZNode $createPath and attempting to write $entity quotas a second time.\")",
          "532:         tryWriteEntityConfig(configType.get, path.get, props, create=true, state) match {",
          "533:           case Some(newStateSecondTry) => newStateSecondTry",
          "534:           case None => throw new MigrationClientException(",
          "535:             s\"Could not write client quotas for $entity on second attempt when using Create instead of SetData\")",
          "536:         }",
          "537:     }",
          "538:   }",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "549:     state.withMigrationZkVersion(migrationZkVersion)",
          "550:   }",
          "664: }",
          "",
          "[Removed Lines]",
          "552:   override def writeConfigs(",
          "553:     resource: ConfigResource,",
          "554:     configs: util.Map[String, String],",
          "555:     state: ZkMigrationLeadershipState",
          "556:   ): ZkMigrationLeadershipState = wrapZkException {",
          "557:     val configType = resource.`type`() match {",
          "558:       case ConfigResource.Type.BROKER => Some(ConfigType.Broker)",
          "559:       case ConfigResource.Type.TOPIC => Some(ConfigType.Topic)",
          "560:       case _ => None",
          "561:     }",
          "563:     val configName = resource.name()",
          "564:     if (configType.isDefined) {",
          "565:       val props = new Properties()",
          "566:       configs.forEach { case (key, value) => props.put(key, value) }",
          "567:       tryWriteEntityConfig(configType.get, configName, props, create=false, state) match {",
          "568:         case Some(newState) =>",
          "569:           newState",
          "570:         case None =>",
          "571:           val createPath = ConfigEntityTypeZNode.path(configType.get)",
          "572:           debug(s\"Recursively creating ZNode $createPath and attempting to write $resource configs a second time.\")",
          "573:           zkClient.createRecursive(createPath, throwIfPathExists=false)",
          "575:           tryWriteEntityConfig(configType.get, configName, props, create=true, state) match {",
          "576:             case Some(newStateSecondTry) => newStateSecondTry",
          "577:             case None => throw new MigrationClientException(",
          "578:               s\"Could not write ${configType.get} configs on second attempt when using Create instead of SetData.\")",
          "579:           }",
          "580:       }",
          "581:     } else {",
          "582:       debug(s\"Not updating ZK for $resource since it is not a Broker or Topic entity.\")",
          "583:       state",
          "584:     }",
          "585:   }",
          "587:   private def aclChangeNotificationRequest(resourcePattern: ResourcePattern): CreateRequest = {",
          "589:     val aclChange = ZkAclStore(resourcePattern.patternType).changeStore.createChangeNode(resourcePattern)",
          "590:     CreateRequest(aclChange.path, aclChange.bytes, zkClient.defaultAcls(aclChange.path), CreateMode.PERSISTENT_SEQUENTIAL)",
          "591:   }",
          "593:   private def tryWriteAcls(",
          "594:     resourcePattern: ResourcePattern,",
          "595:     aclEntries: Set[AclEntry],",
          "596:     create: Boolean,",
          "597:     state: ZkMigrationLeadershipState",
          "598:   ): Option[ZkMigrationLeadershipState] = wrapZkException {",
          "599:     val aclData = ResourceZNode.encode(aclEntries)",
          "601:     val request = if (create) {",
          "602:       val path = ResourceZNode.path(resourcePattern)",
          "603:       CreateRequest(path, aclData, zkClient.defaultAcls(path), CreateMode.PERSISTENT)",
          "604:     } else {",
          "605:       SetDataRequest(ResourceZNode.path(resourcePattern), aclData, ZkVersion.MatchAnyVersion)",
          "606:     }",
          "608:     val (migrationZkVersion, responses) = zkClient.retryMigrationRequestsUntilConnected(Seq(request), state)",
          "609:     if (responses.head.resultCode.equals(Code.NONODE)) {",
          "611:       None",
          "612:     } else {",
          "614:       zkClient.retryRequestUntilConnected(aclChangeNotificationRequest(resourcePattern))",
          "615:       Some(state.withMigrationZkVersion(migrationZkVersion))",
          "616:     }",
          "617:   }",
          "619:   override def writeAddedAcls(",
          "620:     resourcePattern: ResourcePattern,",
          "621:     newAcls: util.List[AccessControlEntry],",
          "622:     state: ZkMigrationLeadershipState",
          "623:   ): ZkMigrationLeadershipState = {",
          "625:     val existingAcls = AclAuthorizer.getAclsFromZk(zkClient, resourcePattern)",
          "626:     val addedAcls = newAcls.asScala.map(new AclEntry(_)).toSet",
          "627:     val updatedAcls = existingAcls.acls ++ addedAcls",
          "629:     tryWriteAcls(resourcePattern, updatedAcls, create=false, state) match {",
          "630:       case Some(newState) => newState",
          "631:       case None => tryWriteAcls(resourcePattern, updatedAcls, create=true, state) match {",
          "632:         case Some(newState) => newState",
          "633:         case None => throw new MigrationClientException(s\"Could not write ACLs for resource pattern $resourcePattern\")",
          "634:       }",
          "635:     }",
          "636:   }",
          "638:   override def removeDeletedAcls(",
          "639:     resourcePattern: ResourcePattern,",
          "640:     deletedAcls: util.List[AccessControlEntry],",
          "641:     state: ZkMigrationLeadershipState",
          "642:   ): ZkMigrationLeadershipState = wrapZkException {",
          "644:     val existingAcls = AclAuthorizer.getAclsFromZk(zkClient, resourcePattern)",
          "645:     val removedAcls = deletedAcls.asScala.map(new AclEntry(_)).toSet",
          "646:     val remainingAcls = existingAcls.acls -- removedAcls",
          "648:     val request = if (remainingAcls.isEmpty) {",
          "649:       DeleteRequest(ResourceZNode.path(resourcePattern), ZkVersion.MatchAnyVersion)",
          "650:     } else {",
          "651:       val aclData = ResourceZNode.encode(remainingAcls)",
          "652:       SetDataRequest(ResourceZNode.path(resourcePattern), aclData, ZkVersion.MatchAnyVersion)",
          "653:     }",
          "655:     val (migrationZkVersion, responses) = zkClient.retryMigrationRequestsUntilConnected(Seq(request), state)",
          "656:     if (responses.head.resultCode.equals(Code.OK) || responses.head.resultCode.equals(Code.NONODE)) {",
          "658:       zkClient.retryRequestUntilConnected(aclChangeNotificationRequest(resourcePattern))",
          "659:       state.withMigrationZkVersion(migrationZkVersion)",
          "660:     } else {",
          "661:       throw new MigrationClientException(s\"Could not delete ACL for resource pattern $resourcePattern\")",
          "662:     }",
          "663:   }",
          "",
          "[Added Lines]",
          "316:   override def topicClient(): TopicMigrationClient = topicClient",
          "318:   override def configClient(): ConfigMigrationClient = configClient",
          "320:   override def aclClient(): AclMigrationClient = aclClient",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/zk/migration/ZkAclMigrationClient.scala||core/src/main/scala/kafka/zk/migration/ZkAclMigrationClient.scala": [
          "File: core/src/main/scala/kafka/zk/migration/ZkAclMigrationClient.scala -> core/src/main/scala/kafka/zk/migration/ZkAclMigrationClient.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package kafka.zk.migration",
          "20: import kafka.security.authorizer.AclAuthorizer.{ResourceOrdering, VersionedAcls}",
          "21: import kafka.security.authorizer.{AclAuthorizer, AclEntry}",
          "22: import kafka.utils.Logging",
          "23: import kafka.zk.ZkMigrationClient.{logAndRethrow, wrapZkException}",
          "24: import kafka.zk.{KafkaZkClient, ResourceZNode, ZkAclStore, ZkVersion}",
          "25: import kafka.zookeeper.{CreateRequest, DeleteRequest, SetDataRequest}",
          "26: import org.apache.kafka.common.acl.AccessControlEntry",
          "27: import org.apache.kafka.common.resource.ResourcePattern",
          "28: import org.apache.kafka.metadata.migration.{AclMigrationClient, MigrationClientException, ZkMigrationLeadershipState}",
          "29: import org.apache.zookeeper.CreateMode",
          "30: import org.apache.zookeeper.KeeperException.Code",
          "32: import java.util",
          "33: import java.util.function.BiConsumer",
          "34: import scala.jdk.CollectionConverters._",
          "36: class ZkAclMigrationClient(",
          "37:   zkClient: KafkaZkClient",
          "38: ) extends AclMigrationClient with Logging {",
          "40:   private def aclChangeNotificationRequest(resourcePattern: ResourcePattern): CreateRequest = {",
          "42:     val aclChange = ZkAclStore(resourcePattern.patternType).changeStore.createChangeNode(resourcePattern)",
          "43:     CreateRequest(aclChange.path, aclChange.bytes, zkClient.defaultAcls(aclChange.path), CreateMode.PERSISTENT_SEQUENTIAL)",
          "44:   }",
          "46:   private def tryWriteAcls(",
          "47:     resourcePattern: ResourcePattern,",
          "48:     aclEntries: Set[AclEntry],",
          "49:     create: Boolean,",
          "50:     state: ZkMigrationLeadershipState",
          "51:   ): Option[ZkMigrationLeadershipState] = wrapZkException {",
          "52:     val aclData = ResourceZNode.encode(aclEntries)",
          "54:     val request = if (create) {",
          "55:       val path = ResourceZNode.path(resourcePattern)",
          "56:       CreateRequest(path, aclData, zkClient.defaultAcls(path), CreateMode.PERSISTENT)",
          "57:     } else {",
          "58:       SetDataRequest(ResourceZNode.path(resourcePattern), aclData, ZkVersion.MatchAnyVersion)",
          "59:     }",
          "61:     val (migrationZkVersion, responses) = zkClient.retryMigrationRequestsUntilConnected(Seq(request), state)",
          "62:     if (responses.head.resultCode.equals(Code.NONODE)) {",
          "64:       None",
          "65:     } else {",
          "67:       zkClient.retryRequestUntilConnected(aclChangeNotificationRequest(resourcePattern))",
          "68:       Some(state.withMigrationZkVersion(migrationZkVersion))",
          "69:     }",
          "70:   }",
          "72:   override def writeResourceAcls(",
          "73:     resourcePattern: ResourcePattern,",
          "74:     aclsToWrite: util.Collection[AccessControlEntry],",
          "75:     state: ZkMigrationLeadershipState",
          "76:   ): ZkMigrationLeadershipState = {",
          "77:     val acls = aclsToWrite.asScala.map(new AclEntry(_)).toSet",
          "78:     tryWriteAcls(resourcePattern, acls, create = false, state) match {",
          "79:       case Some(newState) => newState",
          "80:       case None => tryWriteAcls(resourcePattern, acls, create = true, state) match {",
          "81:         case Some(newState) => newState",
          "82:         case None => throw new MigrationClientException(s\"Could not write ACLs for resource pattern $resourcePattern\")",
          "83:       }",
          "84:     }",
          "85:   }",
          "87:   override def deleteResource(",
          "88:     resourcePattern: ResourcePattern,",
          "89:     state: ZkMigrationLeadershipState",
          "90:   ): ZkMigrationLeadershipState = {",
          "91:     val request = DeleteRequest(ResourceZNode.path(resourcePattern), ZkVersion.MatchAnyVersion)",
          "92:     val (migrationZkVersion, responses) = zkClient.retryMigrationRequestsUntilConnected(Seq(request), state)",
          "93:     if (responses.head.resultCode.equals(Code.OK) || responses.head.resultCode.equals(Code.NONODE)) {",
          "95:       zkClient.retryRequestUntilConnected(aclChangeNotificationRequest(resourcePattern))",
          "96:       state.withMigrationZkVersion(migrationZkVersion)",
          "97:     } else {",
          "98:       throw new MigrationClientException(s\"Could not delete ACL for resource pattern $resourcePattern\")",
          "99:     }",
          "100:   }",
          "102:   override def iterateAcls(",
          "103:     aclConsumer: BiConsumer[ResourcePattern, util.Set[AccessControlEntry]]",
          "104:   ): Unit = {",
          "106:     var allAcls = new scala.collection.immutable.TreeMap[ResourcePattern, VersionedAcls]()(new ResourceOrdering)",
          "107:     def updateAcls(resourcePattern: ResourcePattern, versionedAcls: VersionedAcls): Unit = {",
          "108:       allAcls = allAcls.updated(resourcePattern, versionedAcls)",
          "109:     }",
          "110:     AclAuthorizer.loadAllAcls(zkClient, this, updateAcls)",
          "111:     allAcls.foreach { case (resourcePattern, versionedAcls) =>",
          "112:       logAndRethrow(this, s\"Error in ACL consumer. Resource was $resourcePattern.\") {",
          "113:         aclConsumer.accept(resourcePattern, versionedAcls.acls.map(_.ace).asJava)",
          "114:       }",
          "115:     }",
          "116:   }",
          "117: }",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/zk/migration/ZkConfigMigrationClient.scala||core/src/main/scala/kafka/zk/migration/ZkConfigMigrationClient.scala": [
          "File: core/src/main/scala/kafka/zk/migration/ZkConfigMigrationClient.scala -> core/src/main/scala/kafka/zk/migration/ZkConfigMigrationClient.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package kafka.zk.migration",
          "20: import kafka.server.{ConfigEntityName, ConfigType, DynamicBrokerConfig, DynamicConfig, ZkAdminManager}",
          "21: import kafka.utils.{Logging, PasswordEncoder}",
          "22: import kafka.zk.ZkMigrationClient.{logAndRethrow, wrapZkException}",
          "23: import kafka.zk._",
          "24: import kafka.zookeeper.{CreateRequest, DeleteRequest, SetDataRequest}",
          "25: import org.apache.kafka.clients.admin.ScramMechanism",
          "26: import org.apache.kafka.common.config.{ConfigDef, ConfigResource}",
          "27: import org.apache.kafka.common.errors.InvalidRequestException",
          "28: import org.apache.kafka.common.metadata.ClientQuotaRecord.EntityData",
          "29: import org.apache.kafka.common.quota.ClientQuotaEntity",
          "30: import org.apache.kafka.common.security.scram.internals.ScramCredentialUtils",
          "31: import org.apache.kafka.metadata.migration.ConfigMigrationClient.ClientQuotaVisitor",
          "32: import org.apache.kafka.metadata.migration.{ConfigMigrationClient, MigrationClientException, ZkMigrationLeadershipState}",
          "33: import org.apache.zookeeper.KeeperException.Code",
          "34: import org.apache.zookeeper.{CreateMode, KeeperException}",
          "36: import java.{lang, util}",
          "37: import java.util.Properties",
          "38: import java.util.function.BiConsumer",
          "39: import scala.collection.Seq",
          "40: import scala.jdk.CollectionConverters._",
          "42: class ZkConfigMigrationClient(",
          "43:   zkClient: KafkaZkClient,",
          "44:   passwordEncoder: PasswordEncoder",
          "45: ) extends ConfigMigrationClient with Logging {",
          "47:   val adminZkClient = new AdminZkClient(zkClient)",
          "55:   private def fromZkEntityName(entityName: String): String = {",
          "56:     if (entityName.equals(ConfigEntityName.Default)) {",
          "57:       \"\"",
          "58:     } else {",
          "59:       entityName",
          "60:     }",
          "61:   }",
          "63:   private def toZkEntityName(entityName: String): String = {",
          "64:     if (entityName.isEmpty) {",
          "65:       ConfigEntityName.Default",
          "66:     } else {",
          "67:       entityName",
          "68:     }",
          "69:   }",
          "71:   private def buildEntityData(entityType: String, entityName: String): EntityData = {",
          "72:     new EntityData().setEntityType(entityType).setEntityName(fromZkEntityName(entityName))",
          "73:   }",
          "76:   override def iterateClientQuotas(visitor: ClientQuotaVisitor): Unit = {",
          "77:     def migrateEntityType(zkEntityType: String, entityType: String): Unit = {",
          "78:       adminZkClient.fetchAllEntityConfigs(zkEntityType).foreach { case (name, props) =>",
          "79:         val entity = List(buildEntityData(entityType, name)).asJava",
          "81:         ScramMechanism.values().filter(_ != ScramMechanism.UNKNOWN).foreach { mechanism =>",
          "82:           val propertyValue = props.getProperty(mechanism.mechanismName)",
          "83:           if (propertyValue != null) {",
          "84:             val scramCredentials = ScramCredentialUtils.credentialFromString(propertyValue)",
          "85:             logAndRethrow(this, s\"Error in client quota visitor for SCRAM credential. User was $entity.\") {",
          "86:               visitor.visitScramCredential(name, mechanism, scramCredentials)",
          "87:             }",
          "88:             props.remove(mechanism.mechanismName)",
          "89:           }",
          "90:         }",
          "92:         val quotaMap = ZkAdminManager.clientQuotaPropsToDoubleMap(props.asScala).map {",
          "93:           case (key, value) => key -> lang.Double.valueOf(value)",
          "94:         }.toMap.asJava",
          "96:         if (!quotaMap.isEmpty) {",
          "97:           logAndRethrow(this, s\"Error in client quota visitor. Entity was $entity.\") {",
          "98:             visitor.visitClientQuota(entity, quotaMap)",
          "99:           }",
          "100:         }",
          "101:       }",
          "102:     }",
          "104:     migrateEntityType(ConfigType.User, ClientQuotaEntity.USER)",
          "105:     migrateEntityType(ConfigType.Client, ClientQuotaEntity.CLIENT_ID)",
          "107:     adminZkClient.fetchAllChildEntityConfigs(ConfigType.User, ConfigType.Client).foreach { case (name, props) =>",
          "109:       val components = name.split(\"/\")",
          "110:       if (components.size != 3 || components(1) != \"clients\")",
          "111:         throw new IllegalArgumentException(s\"Unexpected config path: ${name}\")",
          "112:       val entity = List(",
          "113:         buildEntityData(ClientQuotaEntity.USER, components(0)),",
          "114:         buildEntityData(ClientQuotaEntity.CLIENT_ID, components(2))",
          "115:       )",
          "116:       val quotaMap = props.asScala.map { case (key, value) =>",
          "117:         val doubleValue = try lang.Double.valueOf(value) catch {",
          "118:           case _: NumberFormatException =>",
          "119:             throw new IllegalStateException(s\"Unexpected client quota configuration value: $key -> $value\")",
          "120:         }",
          "121:         key -> doubleValue",
          "122:       }.asJava",
          "123:       logAndRethrow(this, s\"Error in client quota entity visitor. Entity was $entity.\") {",
          "124:         visitor.visitClientQuota(entity.asJava, quotaMap)",
          "125:       }",
          "126:     }",
          "128:     migrateEntityType(ConfigType.Ip, ClientQuotaEntity.IP)",
          "129:   }",
          "131:   override def iterateBrokerConfigs(configConsumer: BiConsumer[String, util.Map[String, String]]): Unit = {",
          "132:     val brokerEntities = zkClient.getAllEntitiesWithConfig(ConfigType.Broker)",
          "133:     zkClient.getEntitiesConfigs(ConfigType.Broker, brokerEntities.toSet).foreach { case (broker, props) =>",
          "134:       val brokerResource = fromZkEntityName(broker)",
          "135:       val decodedProps = props.asScala.map { case (key, value) =>",
          "136:         if (DynamicBrokerConfig.isPasswordConfig(key))",
          "137:           key -> passwordEncoder.decode(value).value",
          "138:         else",
          "139:           key -> value",
          "140:       }.toMap.asJava",
          "142:       logAndRethrow(this, s\"Error in broker config consumer. Broker was $brokerResource.\") {",
          "143:         configConsumer.accept(brokerResource, decodedProps)",
          "144:       }",
          "145:     }",
          "146:   }",
          "148:   override def writeConfigs(",
          "149:     configResource: ConfigResource,",
          "150:     configMap: util.Map[String, String],",
          "151:     state: ZkMigrationLeadershipState",
          "152:   ): ZkMigrationLeadershipState = wrapZkException {",
          "153:     val configType = configResource.`type`() match {",
          "154:       case ConfigResource.Type.BROKER => Some(ConfigType.Broker)",
          "155:       case ConfigResource.Type.TOPIC => Some(ConfigType.Topic)",
          "156:       case _ => None",
          "157:     }",
          "159:     val configName = toZkEntityName(configResource.name())",
          "160:     if (configType.isDefined) {",
          "161:       val props = new Properties()",
          "162:       configMap.forEach { case (key, value) => props.put(key, value) }",
          "163:       tryWriteEntityConfig(configType.get, configName, props, create = false, state) match {",
          "164:         case Some(newState) =>",
          "165:           newState",
          "166:         case None =>",
          "167:           val createPath = ConfigEntityTypeZNode.path(configType.get)",
          "168:           debug(s\"Recursively creating ZNode $createPath and attempting to write $configResource configs a second time.\")",
          "169:           zkClient.createRecursive(createPath, throwIfPathExists = false)",
          "171:           tryWriteEntityConfig(configType.get, configName, props, create = true, state) match {",
          "172:             case Some(newStateSecondTry) => newStateSecondTry",
          "173:             case None => throw new MigrationClientException(",
          "174:               s\"Could not write ${configType.get} configs on second attempt when using Create instead of SetData.\")",
          "175:           }",
          "176:       }",
          "177:     } else {",
          "178:       error(s\"Not updating ZK for $configResource since it is not a Broker or Topic entity.\")",
          "179:       state",
          "180:     }",
          "181:   }",
          "183:   override def deleteConfigs(",
          "184:     configResource: ConfigResource,",
          "185:     state: ZkMigrationLeadershipState",
          "186:   ): ZkMigrationLeadershipState = wrapZkException {",
          "187:     val configType = configResource.`type`() match {",
          "188:       case ConfigResource.Type.BROKER => Some(ConfigType.Broker)",
          "189:       case ConfigResource.Type.TOPIC => Some(ConfigType.Topic)",
          "190:       case _ => None",
          "191:     }",
          "193:     val configName = toZkEntityName(configResource.name())",
          "194:     if (configType.isDefined) {",
          "195:       val path = ConfigEntityZNode.path(configType.get, configName)",
          "196:       val requests = Seq(DeleteRequest(path, ZkVersion.MatchAnyVersion))",
          "197:       val (migrationZkVersion, responses) = zkClient.retryMigrationRequestsUntilConnected(requests, state)",
          "199:       if (responses.head.resultCode.equals(Code.NONODE)) {",
          "201:         error(s\"Did not delete $configResource since the node did not exist.\")",
          "202:         state",
          "203:       } else if (responses.head.resultCode.equals(Code.OK)) {",
          "205:         zkClient.createConfigChangeNotification(s\"$configType/$configName\")",
          "206:         state.withMigrationZkVersion(migrationZkVersion)",
          "207:       } else {",
          "208:         throw KeeperException.create(responses.head.resultCode, path)",
          "209:       }",
          "210:     } else {",
          "211:       error(s\"Not updating ZK for $configResource since it is not a Broker or Topic entity.\")",
          "212:       state",
          "213:     }",
          "214:   }",
          "216:   override def writeClientQuotas(",
          "217:     entity: util.Map[String, String],",
          "218:     quotas: util.Map[String, java.lang.Double],",
          "219:     scram: util.Map[String, String],",
          "220:     state: ZkMigrationLeadershipState",
          "221:   ): ZkMigrationLeadershipState = wrapZkException {",
          "222:     val entityMap = entity.asScala",
          "223:     val user = entityMap.get(ClientQuotaEntity.USER).map(toZkEntityName)",
          "224:     val client = entityMap.get(ClientQuotaEntity.CLIENT_ID).map(toZkEntityName)",
          "225:     val ip = entityMap.get(ClientQuotaEntity.IP).map(toZkEntityName)",
          "226:     val props = new Properties()",
          "228:     val (configType, path, configKeys) = if (user.isDefined && client.isEmpty) {",
          "229:       (Some(ConfigType.User), user, DynamicConfig.User.configKeys)",
          "230:     } else if (user.isDefined && client.isDefined) {",
          "231:       (Some(ConfigType.User), Some(s\"${user.get}/clients/${client.get}\"),",
          "232:         DynamicConfig.User.configKeys)",
          "233:     } else if (client.isDefined) {",
          "234:       (Some(ConfigType.Client), client, DynamicConfig.Client.configKeys)",
          "235:     } else if (ip.isDefined) {",
          "236:       (Some(ConfigType.Ip), ip, DynamicConfig.Ip.configKeys)",
          "237:     } else {",
          "238:       (None, None, Map.empty.asJava)",
          "239:     }",
          "241:     if (path.isEmpty) {",
          "242:       error(s\"Skipping unknown client quota entity $entity\")",
          "243:       return state",
          "244:     }",
          "247:     quotas.forEach { case (key, value) =>",
          "248:       val configKey = configKeys.get(key)",
          "249:       if (configKey == null) {",
          "250:         throw new MigrationClientException(s\"Invalid configuration key ${key}\")",
          "251:       } else {",
          "252:         configKey.`type` match {",
          "253:           case ConfigDef.Type.DOUBLE =>",
          "254:             props.setProperty(key, value.toString)",
          "255:           case ConfigDef.Type.LONG | ConfigDef.Type.INT =>",
          "256:             val epsilon = 1e-6",
          "257:             val intValue = if (configKey.`type` == ConfigDef.Type.LONG)",
          "258:               (value + epsilon).toLong",
          "259:             else",
          "260:               (value + epsilon).toInt",
          "261:             if ((intValue.toDouble - value).abs > epsilon)",
          "262:               throw new InvalidRequestException(s\"Configuration ${key} must be a ${configKey.`type`} value\")",
          "263:             props.setProperty(key, intValue.toString)",
          "264:           case _ =>",
          "265:             throw new MigrationClientException(s\"Unexpected config type ${configKey.`type`}\")",
          "266:         }",
          "267:       }",
          "268:     }",
          "269:     scram.forEach { case (key, value) => props.put(key, value) }",
          "272:     tryWriteEntityConfig(configType.get, path.get, props, create = false, state) match {",
          "273:       case Some(newState) =>",
          "274:         newState",
          "275:       case None =>",
          "278:         val createPath = if (user.isDefined && client.isDefined) {",
          "279:           s\"${ConfigEntityTypeZNode.path(configType.get)}/${user.get}/clients\"",
          "280:         } else {",
          "281:           ConfigEntityTypeZNode.path(configType.get)",
          "282:         }",
          "283:         zkClient.createRecursive(createPath, throwIfPathExists = false)",
          "284:         debug(s\"Recursively creating ZNode $createPath and attempting to write $entity quotas a second time.\")",
          "286:         tryWriteEntityConfig(configType.get, path.get, props, create = true, state) match {",
          "287:           case Some(newStateSecondTry) => newStateSecondTry",
          "288:           case None => throw new MigrationClientException(",
          "289:             s\"Could not write client quotas for $entity on second attempt when using Create instead of SetData\")",
          "290:         }",
          "291:     }",
          "292:   }",
          "296:   private def tryWriteEntityConfig(",
          "297:     entityType: String,",
          "298:     path: String,",
          "299:     props: Properties,",
          "300:     create: Boolean,",
          "301:     state: ZkMigrationLeadershipState",
          "302:   ): Option[ZkMigrationLeadershipState] = wrapZkException {",
          "303:     val configData = ConfigEntityZNode.encode(props)",
          "304:     val requests = if (create) {",
          "305:       Seq(CreateRequest(ConfigEntityZNode.path(entityType, path), configData, zkClient.defaultAcls(path), CreateMode.PERSISTENT))",
          "306:     } else {",
          "307:       Seq(SetDataRequest(ConfigEntityZNode.path(entityType, path), configData, ZkVersion.MatchAnyVersion))",
          "308:     }",
          "309:     val (migrationZkVersion, responses) = zkClient.retryMigrationRequestsUntilConnected(requests, state)",
          "310:     if (!create && responses.head.resultCode.equals(Code.NONODE)) {",
          "312:       None",
          "313:     } else if (responses.head.resultCode.equals(Code.OK)) {",
          "315:       zkClient.createConfigChangeNotification(s\"$entityType/$path\")",
          "316:       Some(state.withMigrationZkVersion(migrationZkVersion))",
          "317:     } else {",
          "318:       throw KeeperException.create(responses.head.resultCode, path)",
          "319:     }",
          "320:   }",
          "321: }",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/zk/migration/ZkTopicMigrationClient.scala||core/src/main/scala/kafka/zk/migration/ZkTopicMigrationClient.scala": [
          "File: core/src/main/scala/kafka/zk/migration/ZkTopicMigrationClient.scala -> core/src/main/scala/kafka/zk/migration/ZkTopicMigrationClient.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package kafka.zk.migration",
          "20: import kafka.api.LeaderAndIsr",
          "21: import kafka.controller.{LeaderIsrAndControllerEpoch, ReplicaAssignment}",
          "22: import kafka.server.ConfigType",
          "23: import kafka.utils.Logging",
          "24: import kafka.zk.TopicZNode.TopicIdReplicaAssignment",
          "25: import kafka.zk.ZkMigrationClient.{logAndRethrow, wrapZkException}",
          "26: import kafka.zk._",
          "27: import kafka.zookeeper.{CreateRequest, DeleteRequest, GetChildrenRequest, SetDataRequest}",
          "28: import org.apache.kafka.common.metadata.PartitionRecord",
          "29: import org.apache.kafka.common.{TopicIdPartition, TopicPartition, Uuid}",
          "30: import org.apache.kafka.metadata.migration.TopicMigrationClient.TopicVisitorInterest",
          "31: import org.apache.kafka.metadata.migration.{MigrationClientException, TopicMigrationClient, ZkMigrationLeadershipState}",
          "32: import org.apache.kafka.metadata.{LeaderRecoveryState, PartitionRegistration}",
          "33: import org.apache.zookeeper.CreateMode",
          "34: import org.apache.zookeeper.KeeperException.Code",
          "36: import java.util",
          "37: import scala.collection.Seq",
          "38: import scala.collection.mutable.ArrayBuffer",
          "39: import scala.jdk.CollectionConverters._",
          "42: class ZkTopicMigrationClient(zkClient: KafkaZkClient) extends TopicMigrationClient with Logging {",
          "43:   override def iterateTopics(",
          "44:     interests: util.EnumSet[TopicVisitorInterest],",
          "45:     visitor: TopicMigrationClient.TopicVisitor,",
          "46:   ): Unit = wrapZkException {",
          "47:     if (!interests.contains(TopicVisitorInterest.TOPICS)) {",
          "48:       throw new IllegalArgumentException(\"Must specify at least TOPICS in topic visitor interests.\")",
          "49:     }",
          "50:     val topics = zkClient.getAllTopicsInCluster()",
          "51:     val topicConfigs = zkClient.getEntitiesConfigs(ConfigType.Topic, topics)",
          "52:     val replicaAssignmentAndTopicIds = zkClient.getReplicaAssignmentAndTopicIdForTopics(topics)",
          "53:     replicaAssignmentAndTopicIds.foreach { case TopicIdReplicaAssignment(topic, topicIdOpt, partitionAssignments) =>",
          "54:       val topicAssignment = partitionAssignments.map { case (partition, assignment) =>",
          "55:         partition.partition().asInstanceOf[Integer] -> assignment.replicas.map(Integer.valueOf).asJava",
          "56:       }.toMap.asJava",
          "57:       logAndRethrow(this, s\"Error in topic consumer. Topic was $topic.\") {",
          "58:         visitor.visitTopic(topic, topicIdOpt.get, topicAssignment)",
          "59:       }",
          "60:       if (interests.contains(TopicVisitorInterest.PARTITIONS)) {",
          "61:         val partitions = partitionAssignments.keys.toSeq",
          "62:         val leaderIsrAndControllerEpochs = zkClient.getTopicPartitionStates(partitions)",
          "63:         partitionAssignments.foreach { case (topicPartition, replicaAssignment) =>",
          "64:           val replicaList = replicaAssignment.replicas.map(Integer.valueOf).asJava",
          "65:           val record = new PartitionRecord()",
          "66:             .setTopicId(topicIdOpt.get)",
          "67:             .setPartitionId(topicPartition.partition)",
          "68:             .setReplicas(replicaList)",
          "69:             .setAddingReplicas(replicaAssignment.addingReplicas.map(Integer.valueOf).asJava)",
          "70:             .setRemovingReplicas(replicaAssignment.removingReplicas.map(Integer.valueOf).asJava)",
          "71:           leaderIsrAndControllerEpochs.get(topicPartition) match {",
          "72:             case Some(leaderIsrAndEpoch) =>",
          "73:               record",
          "74:                 .setIsr(leaderIsrAndEpoch.leaderAndIsr.isr.map(Integer.valueOf).asJava)",
          "75:                 .setLeader(leaderIsrAndEpoch.leaderAndIsr.leader)",
          "76:                 .setLeaderEpoch(leaderIsrAndEpoch.leaderAndIsr.leaderEpoch)",
          "77:                 .setPartitionEpoch(leaderIsrAndEpoch.leaderAndIsr.partitionEpoch)",
          "78:                 .setLeaderRecoveryState(leaderIsrAndEpoch.leaderAndIsr.leaderRecoveryState.value())",
          "79:             case None =>",
          "80:               warn(s\"Could not find partition state in ZK for $topicPartition. Initializing this partition \" +",
          "81:                 s\"with ISR={$replicaList} and leaderEpoch=0.\")",
          "82:               record",
          "83:                 .setIsr(replicaList)",
          "84:                 .setLeader(replicaList.get(0))",
          "85:                 .setLeaderEpoch(0)",
          "86:                 .setPartitionEpoch(0)",
          "87:                 .setLeaderRecoveryState(LeaderRecoveryState.RECOVERED.value())",
          "88:           }",
          "89:           logAndRethrow(this, s\"Error in partition consumer. TopicPartition was $topicPartition.\") {",
          "90:             visitor.visitPartition(new TopicIdPartition(topicIdOpt.get, topicPartition), new PartitionRegistration(record))",
          "91:           }",
          "92:         }",
          "93:       }",
          "94:       if (interests.contains(TopicVisitorInterest.CONFIGS)) {",
          "95:         val props = topicConfigs(topic)",
          "96:         logAndRethrow(this, s\"Error in topic config consumer. Topic was $topic.\") {",
          "97:           visitor.visitConfigs(topic, props)",
          "98:         }",
          "99:       }",
          "100:     }",
          "101:   }",
          "103:   override def createTopic(",
          "104:     topicName: String,",
          "105:     topicId: Uuid,",
          "106:     partitions: util.Map[Integer, PartitionRegistration],",
          "107:     state: ZkMigrationLeadershipState",
          "108:   ): ZkMigrationLeadershipState = wrapZkException {",
          "110:     val assignments = partitions.asScala.map { case (partitionId, partition) =>",
          "111:       new TopicPartition(topicName, partitionId) ->",
          "112:         ReplicaAssignment(partition.replicas, partition.addingReplicas, partition.removingReplicas)",
          "113:     }",
          "115:     val createTopicZNode = {",
          "116:       val path = TopicZNode.path(topicName)",
          "117:       CreateRequest(",
          "118:         path,",
          "119:         TopicZNode.encode(Some(topicId), assignments),",
          "120:         zkClient.defaultAcls(path),",
          "121:         CreateMode.PERSISTENT)",
          "122:     }",
          "123:     val createPartitionsZNode = {",
          "124:       val path = TopicPartitionsZNode.path(topicName)",
          "125:       CreateRequest(",
          "126:         path,",
          "127:         null,",
          "128:         zkClient.defaultAcls(path),",
          "129:         CreateMode.PERSISTENT)",
          "130:     }",
          "132:     val createPartitionZNodeReqs = partitions.asScala.flatMap { case (partitionId, partition) =>",
          "133:       val topicPartition = new TopicPartition(topicName, partitionId)",
          "134:       Seq(",
          "135:         createTopicPartition(topicPartition),",
          "136:         createTopicPartitionState(topicPartition, partition, state.kraftControllerEpoch())",
          "137:       )",
          "138:     }",
          "140:     val requests = Seq(createTopicZNode, createPartitionsZNode) ++ createPartitionZNodeReqs",
          "141:     val (migrationZkVersion, responses) = zkClient.retryMigrationRequestsUntilConnected(requests, state)",
          "142:     val resultCodes = responses.map { response => response.path -> response.resultCode }.toMap",
          "143:     if (resultCodes(TopicZNode.path(topicName)).equals(Code.NODEEXISTS)) {",
          "145:       state",
          "146:     } else if (resultCodes.forall { case (_, code) => code.equals(Code.OK) }) {",
          "148:       state.withMigrationZkVersion(migrationZkVersion)",
          "149:     } else {",
          "151:       throw new MigrationClientException(s\"Failed to create or update topic $topicName. ZK operations had results $resultCodes\")",
          "152:     }",
          "153:   }",
          "155:   private def recursiveChildren(path: String, acc: ArrayBuffer[String]): Unit = {",
          "156:     val topicChildZNodes = zkClient.retryRequestUntilConnected(GetChildrenRequest(path, registerWatch = false))",
          "157:     topicChildZNodes.children.foreach { child =>",
          "158:       recursiveChildren(s\"$path/$child\", acc)",
          "159:       acc.append(s\"$path/$child\")",
          "160:     }",
          "161:   }",
          "163:   private def recursiveChildren(path: String): Seq[String] = {",
          "164:     val buffer = new ArrayBuffer[String]()",
          "165:     recursiveChildren(path, buffer)",
          "166:     buffer.toSeq",
          "167:   }",
          "169:   override def deleteTopic(",
          "170:     topicName: String,",
          "171:     state: ZkMigrationLeadershipState",
          "172:   ): ZkMigrationLeadershipState = wrapZkException {",
          "174:     val topicPath = TopicZNode.path(topicName)",
          "175:     val topicChildZNodes = recursiveChildren(topicPath)",
          "176:     val deleteRequests = topicChildZNodes.map { childPath =>",
          "177:       DeleteRequest(childPath, ZkVersion.MatchAnyVersion)",
          "178:     } ++ Seq(",
          "179:       DeleteRequest(ConfigEntityZNode.path(ConfigType.Topic, topicName), ZkVersion.MatchAnyVersion),",
          "180:       DeleteRequest(TopicZNode.path(topicName), ZkVersion.MatchAnyVersion)",
          "181:     )",
          "182:     val (migrationZkVersion, responses) = zkClient.retryMigrationRequestsUntilConnected(deleteRequests, state)",
          "183:     val resultCodes = responses.map { response => response.path -> response.resultCode }.toMap",
          "184:     if (responses.last.resultCode.equals(Code.OK)) {",
          "185:       state.withMigrationZkVersion(migrationZkVersion)",
          "186:     } else {",
          "187:       throw new MigrationClientException(s\"Failed to delete topic $topicName. ZK operations had results $resultCodes\")",
          "188:     }",
          "189:   }",
          "191:   override def updateTopicPartitions(",
          "192:     topicPartitions: util.Map[String, util.Map[Integer, PartitionRegistration]],",
          "193:     state: ZkMigrationLeadershipState",
          "194:   ): ZkMigrationLeadershipState = wrapZkException {",
          "195:     val requests = topicPartitions.asScala.flatMap { case (topicName, partitionRegistrations) =>",
          "196:       partitionRegistrations.asScala.flatMap { case (partitionId, partitionRegistration) =>",
          "197:         val topicPartition = new TopicPartition(topicName, partitionId)",
          "198:         Seq(updateTopicPartitionState(topicPartition, partitionRegistration, state.kraftControllerEpoch()))",
          "199:       }",
          "200:     }",
          "201:     if (requests.isEmpty) {",
          "202:       state",
          "203:     } else {",
          "204:       val (migrationZkVersion, responses) = zkClient.retryMigrationRequestsUntilConnected(requests.toSeq, state)",
          "205:       val resultCodes = responses.map { response => response.path -> response.resultCode }.toMap",
          "206:       if (resultCodes.forall { case (_, code) => code.equals(Code.OK) }) {",
          "207:         state.withMigrationZkVersion(migrationZkVersion)",
          "208:       } else {",
          "209:         throw new MigrationClientException(s\"Failed to update partition states: $topicPartitions. ZK transaction had results $resultCodes\")",
          "210:       }",
          "211:     }",
          "212:   }",
          "214:   private def createTopicPartition(",
          "215:     topicPartition: TopicPartition",
          "216:   ): CreateRequest = wrapZkException {",
          "217:     val path = TopicPartitionZNode.path(topicPartition)",
          "218:     CreateRequest(path, null, zkClient.defaultAcls(path), CreateMode.PERSISTENT, Some(topicPartition))",
          "219:   }",
          "221:   private def partitionStatePathAndData(",
          "222:     topicPartition: TopicPartition,",
          "223:     partitionRegistration: PartitionRegistration,",
          "224:     controllerEpoch: Int",
          "225:   ): (String, Array[Byte]) = {",
          "226:     val path = TopicPartitionStateZNode.path(topicPartition)",
          "227:     val data = TopicPartitionStateZNode.encode(LeaderIsrAndControllerEpoch(LeaderAndIsr(",
          "228:       partitionRegistration.leader,",
          "229:       partitionRegistration.leaderEpoch,",
          "230:       partitionRegistration.isr.toList,",
          "231:       partitionRegistration.leaderRecoveryState,",
          "232:       partitionRegistration.partitionEpoch), controllerEpoch))",
          "233:     (path, data)",
          "234:   }",
          "236:   private def createTopicPartitionState(",
          "237:     topicPartition: TopicPartition,",
          "238:     partitionRegistration: PartitionRegistration,",
          "239:     controllerEpoch: Int",
          "240:   ): CreateRequest = {",
          "241:     val (path, data) = partitionStatePathAndData(topicPartition, partitionRegistration, controllerEpoch)",
          "242:     CreateRequest(path, data, zkClient.defaultAcls(path), CreateMode.PERSISTENT, Some(topicPartition))",
          "243:   }",
          "245:   private def updateTopicPartitionState(",
          "246:     topicPartition: TopicPartition,",
          "247:     partitionRegistration: PartitionRegistration,",
          "248:     controllerEpoch: Int",
          "249:   ): SetDataRequest = {",
          "250:     val (path, data) = partitionStatePathAndData(topicPartition, partitionRegistration, controllerEpoch)",
          "251:     SetDataRequest(path, data, ZkVersion.MatchAnyVersion, Some(topicPartition))",
          "252:   }",
          "253: }",
          "",
          "---------------"
        ],
        "core/src/test/scala/integration/kafka/zk/ZkMigrationIntegrationTest.scala||core/src/test/scala/integration/kafka/zk/ZkMigrationIntegrationTest.scala": [
          "File: core/src/test/scala/integration/kafka/zk/ZkMigrationIntegrationTest.scala -> core/src/test/scala/integration/kafka/zk/ZkMigrationIntegrationTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "106:     val underlying = clusterInstance.asInstanceOf[ZkClusterInstance].getUnderlying()",
          "107:     val zkClient = underlying.zkClient",
          "109:     val verifier = new MetadataDeltaVerifier()",
          "110:     migrationClient.readAllMetadata(batch => verifier.accept(batch), _ => { })",
          "111:     verifier.verify { image =>",
          "",
          "[Removed Lines]",
          "108:     val migrationClient = new ZkMigrationClient(zkClient, PasswordEncoder.noop())",
          "",
          "[Added Lines]",
          "108:     val migrationClient = ZkMigrationClient(zkClient, PasswordEncoder.noop())",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "160:       case None => PasswordEncoder.noop()",
          "161:     }",
          "164:     var migrationState = migrationClient.getOrCreateMigrationRecoveryState(ZkMigrationLeadershipState.EMPTY)",
          "165:     migrationState = migrationState.withNewKRaftController(3000, 42)",
          "166:     migrationState = migrationClient.claimControllerLeadership(migrationState)",
          "",
          "[Removed Lines]",
          "163:     val migrationClient = new ZkMigrationClient(zkClient, zkConfigEncoder)",
          "",
          "[Added Lines]",
          "163:     val migrationClient = ZkMigrationClient(zkClient, zkConfigEncoder)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "316:   def verifyClientQuotas(zkClient: KafkaZkClient): Unit = {",
          "317:     TestUtils.retry(10000) {",
          "322:     }",
          "323:   }",
          "",
          "[Removed Lines]",
          "318:       assertEquals(\"1000.0\", zkClient.getEntityConfigs(ConfigType.User, \"user1\").getProperty(\"consumer_byte_rate\"))",
          "319:       assertEquals(\"800.0\", zkClient.getEntityConfigs(\"users/user1/clients\", \"clientA\").getProperty(\"consumer_byte_rate\"))",
          "320:       assertEquals(\"100.0\", zkClient.getEntityConfigs(\"users/user1/clients\", \"clientA\").getProperty(\"producer_byte_rate\"))",
          "321:       assertEquals(\"10.0\", zkClient.getEntityConfigs(ConfigType.Ip, \"8.8.8.8\").getProperty(\"connection_creation_rate\"))",
          "",
          "[Added Lines]",
          "318:       assertEquals(\"1000\", zkClient.getEntityConfigs(ConfigType.User, \"user1\").getProperty(\"consumer_byte_rate\"))",
          "319:       assertEquals(\"800\", zkClient.getEntityConfigs(\"users/user1/clients\", \"clientA\").getProperty(\"consumer_byte_rate\"))",
          "320:       assertEquals(\"100\", zkClient.getEntityConfigs(\"users/user1/clients\", \"clientA\").getProperty(\"producer_byte_rate\"))",
          "321:       assertEquals(\"10\", zkClient.getEntityConfigs(ConfigType.Ip, \"8.8.8.8\").getProperty(\"connection_creation_rate\"))",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/zk/ZkMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/ZkMigrationClientTest.scala": [
          "File: core/src/test/scala/unit/kafka/zk/ZkMigrationClientTest.scala -> core/src/test/scala/unit/kafka/zk/ZkMigrationClientTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala": [
          "File: core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala -> core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "17: package kafka.zk.migration",
          "19: import kafka.security.authorizer.AclAuthorizer",
          "20: import kafka.security.authorizer.AclEntry.{WildcardHost, WildcardPrincipalString}",
          "21: import kafka.utils.TestUtils",
          "22: import org.apache.kafka.common.acl._",
          "23: import org.apache.kafka.common.metadata.AccessControlEntryRecord",
          "24: import org.apache.kafka.common.resource.{PatternType, ResourcePattern, ResourcePatternFilter, ResourceType}",
          "25: import org.apache.kafka.common.security.auth.KafkaPrincipal",
          "26: import org.apache.kafka.common.utils.SecurityUtils",
          "27: import org.apache.kafka.server.common.ApiMessageAndVersion",
          "28: import org.junit.jupiter.api.Assertions.{assertEquals, assertTrue}",
          "29: import org.junit.jupiter.api.Test",
          "31: import java.util.UUID",
          "32: import scala.collection.mutable",
          "33: import scala.jdk.CollectionConverters._",
          "35: class ZkAclMigrationClientTest extends ZkMigrationTestHarness {",
          "36:   def migrateAclsAndVerify(authorizer: AclAuthorizer, acls: Seq[AclBinding]): Unit = {",
          "37:     authorizer.createAcls(null, acls.asJava)",
          "38:     val batches = new mutable.ArrayBuffer[mutable.Buffer[ApiMessageAndVersion]]()",
          "39:     migrationClient.migrateAcls(batch => batches.append(batch.asScala))",
          "40:     val records = batches.flatten.map(_.message().asInstanceOf[AccessControlEntryRecord])",
          "41:     assertEquals(acls.size, records.size, \"Expected one record for each ACLBinding\")",
          "42:   }",
          "44:   def replaceAclsAndReadWithAuthorizer(",
          "45:     authorizer: AclAuthorizer,",
          "46:     resourcePattern: ResourcePattern,",
          "47:     aces: Seq[AccessControlEntry],",
          "48:     pred: Seq[AclBinding] => Boolean",
          "49:   ): Seq[AclBinding] = {",
          "50:     val resourceFilter = new AclBindingFilter(",
          "51:       new ResourcePatternFilter(resourcePattern.resourceType(), resourcePattern.name(), resourcePattern.patternType()),",
          "52:       AclBindingFilter.ANY.entryFilter()",
          "53:     )",
          "54:     migrationState = migrationClient.aclClient().writeResourceAcls(resourcePattern, aces.asJava, migrationState)",
          "55:     val (acls, ok) = TestUtils.computeUntilTrue(authorizer.acls(resourceFilter).asScala.toSeq)(pred)",
          "56:     assertTrue(ok)",
          "57:     acls",
          "58:   }",
          "60:   def deleteResourceAndReadWithAuthorizer(",
          "61:     authorizer: AclAuthorizer,",
          "62:     resourcePattern: ResourcePattern",
          "63:   ): Unit = {",
          "64:     val resourceFilter = new AclBindingFilter(",
          "65:       new ResourcePatternFilter(resourcePattern.resourceType(), resourcePattern.name(), resourcePattern.patternType()),",
          "66:       AclBindingFilter.ANY.entryFilter()",
          "67:     )",
          "68:     migrationState = migrationClient.aclClient().deleteResource(resourcePattern, migrationState)",
          "69:     val (_, ok) = TestUtils.computeUntilTrue(authorizer.acls(resourceFilter).asScala.toSeq)(_.isEmpty)",
          "70:     assertTrue(ok)",
          "71:   }",
          "74:   @Test",
          "75:   def testAclsMigrateAndDualWrite(): Unit = {",
          "76:     val resource1 = new ResourcePattern(ResourceType.TOPIC, \"foo-\" + UUID.randomUUID(), PatternType.LITERAL)",
          "77:     val resource2 = new ResourcePattern(ResourceType.TOPIC, \"bar-\" + UUID.randomUUID(), PatternType.LITERAL)",
          "78:     val prefixedResource = new ResourcePattern(ResourceType.TOPIC, \"bar-\", PatternType.PREFIXED)",
          "79:     val username = \"alice\"",
          "80:     val principal = new KafkaPrincipal(KafkaPrincipal.USER_TYPE, username)",
          "81:     val wildcardPrincipal = SecurityUtils.parseKafkaPrincipal(WildcardPrincipalString)",
          "83:     val ace1 = new AccessControlEntry(principal.toString, WildcardHost, AclOperation.READ, AclPermissionType.ALLOW)",
          "84:     val acl1 = new AclBinding(resource1, ace1)",
          "85:     val ace2 = new AccessControlEntry(principal.toString, \"192.168.0.1\", AclOperation.WRITE, AclPermissionType.ALLOW)",
          "86:     val acl2 = new AclBinding(resource1, ace2)",
          "87:     val acl3 = new AclBinding(resource2, new AccessControlEntry(principal.toString, WildcardHost, AclOperation.DESCRIBE, AclPermissionType.ALLOW))",
          "88:     val acl4 = new AclBinding(prefixedResource, new AccessControlEntry(wildcardPrincipal.toString, WildcardHost, AclOperation.READ, AclPermissionType.ALLOW))",
          "90:     val authorizer = new AclAuthorizer()",
          "91:     try {",
          "92:       authorizer.configure(Map(\"zookeeper.connect\" -> this.zkConnect).asJava)",
          "95:       migrateAclsAndVerify(authorizer, Seq(acl1, acl2, acl3, acl4))",
          "98:       var resource1Acls = replaceAclsAndReadWithAuthorizer(authorizer, resource1, Seq(ace1), acls => acls.size == 1)",
          "99:       assertEquals(acl1, resource1Acls.head)",
          "102:       deleteResourceAndReadWithAuthorizer(authorizer, resource1)",
          "105:       val newAce1 = new AccessControlEntry(principal.toString, \"10.0.0.1\", AclOperation.WRITE, AclPermissionType.ALLOW)",
          "106:       resource1Acls = replaceAclsAndReadWithAuthorizer(authorizer, resource1, Seq(newAce1), acls => acls.size == 1)",
          "107:       assertEquals(newAce1, resource1Acls.head.entry())",
          "110:       val newAce2 = new AccessControlEntry(principal.toString, \"10.0.0.1\", AclOperation.WRITE, AclPermissionType.ALLOW)",
          "111:       val resource2Acls = replaceAclsAndReadWithAuthorizer(authorizer, resource2, Seq(acl3.entry(), newAce2), acls => acls.size == 2)",
          "112:       assertEquals(acl3, resource2Acls.head)",
          "113:       assertEquals(newAce2, resource2Acls.last.entry())",
          "114:     } finally {",
          "115:       authorizer.close()",
          "116:     }",
          "117:   }",
          "118: }",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala": [
          "File: core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala -> core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "17: package kafka.zk.migration",
          "19: import kafka.server.{ConfigType, KafkaConfig, ZkAdminManager}",
          "20: import kafka.zk.{AdminZkClient, ZkMigrationClient}",
          "21: import org.apache.kafka.common.config.internals.QuotaConfigs",
          "22: import org.apache.kafka.common.config.types.Password",
          "23: import org.apache.kafka.common.config.{ConfigResource, TopicConfig}",
          "24: import org.apache.kafka.common.metadata.ConfigRecord",
          "25: import org.apache.kafka.common.quota.ClientQuotaEntity",
          "26: import org.apache.kafka.common.security.scram.ScramCredential",
          "27: import org.apache.kafka.common.security.scram.internals.ScramCredentialUtils",
          "28: import org.apache.kafka.image.{ClientQuotasDelta, ClientQuotasImage}",
          "29: import org.apache.kafka.metadata.RecordTestUtils",
          "30: import org.apache.kafka.metadata.migration.ZkMigrationLeadershipState",
          "31: import org.apache.kafka.server.common.ApiMessageAndVersion",
          "32: import org.apache.kafka.server.util.MockRandom",
          "33: import org.junit.jupiter.api.Assertions.{assertEquals, assertTrue}",
          "34: import org.junit.jupiter.api.Test",
          "36: import java.util.Properties",
          "37: import scala.collection.Map",
          "38: import scala.jdk.CollectionConverters._",
          "40: class ZkConfigMigrationClientTest extends ZkMigrationTestHarness {",
          "41:   @Test",
          "42:   def testMigrationBrokerConfigs(): Unit = {",
          "43:     val brokers = new java.util.ArrayList[Integer]()",
          "44:     val batches = new java.util.ArrayList[java.util.List[ApiMessageAndVersion]]()",
          "47:     val props = new Properties()",
          "48:     props.put(KafkaConfig.DefaultReplicationFactorProp, \"1\") // normal config",
          "49:     props.put(KafkaConfig.SslKeystorePasswordProp, encoder.encode(new Password(SECRET))) // sensitive config",
          "50:     zkClient.setOrCreateEntityConfigs(ConfigType.Broker, \"1\", props)",
          "52:     migrationClient.migrateBrokerConfigs(batch => batches.add(batch), brokerId => brokers.add(brokerId))",
          "53:     assertEquals(1, brokers.size())",
          "54:     assertEquals(1, batches.size())",
          "55:     assertEquals(2, batches.get(0).size)",
          "57:     batches.get(0).forEach(record => {",
          "58:       val message = record.message().asInstanceOf[ConfigRecord]",
          "59:       val name = message.name",
          "60:       val value = message.value",
          "62:       assertTrue(props.containsKey(name))",
          "64:       if (name == KafkaConfig.SslKeystorePasswordProp) {",
          "65:         assertEquals(SECRET, value)",
          "66:       } else {",
          "67:         assertEquals(props.getProperty(name), value)",
          "68:       }",
          "69:     })",
          "71:     migrationState = migrationClient.configClient().deleteConfigs(",
          "72:       new ConfigResource(ConfigResource.Type.BROKER, \"1\"), migrationState)",
          "73:     assertEquals(0, zkClient.getEntityConfigs(ConfigType.Broker, \"1\").size())",
          "74:   }",
          "76:   @Test",
          "77:   def testMigrateClientQuotas(): Unit = {",
          "78:     val props = new Properties()",
          "79:     props.put(QuotaConfigs.PRODUCER_BYTE_RATE_OVERRIDE_CONFIG, \"100000\")",
          "80:     adminZkClient.changeConfigs(ConfigType.User, \"<default>\", props)",
          "81:     adminZkClient.changeConfigs(ConfigType.User, \"user1\", props)",
          "82:     adminZkClient.changeConfigs(ConfigType.User, \"user1/clients/clientA\", props)",
          "83:     adminZkClient.changeConfigs(ConfigType.User, \"<default>/clients/<default>\", props)",
          "84:     adminZkClient.changeConfigs(ConfigType.User, \"<default>/clients/clientA\", props)",
          "85:     adminZkClient.changeConfigs(ConfigType.Client, \"<default>\", props)",
          "86:     adminZkClient.changeConfigs(ConfigType.Client, \"clientB\", props)",
          "87:     props.remove(QuotaConfigs.PRODUCER_BYTE_RATE_OVERRIDE_CONFIG)",
          "88:     props.put(QuotaConfigs.IP_CONNECTION_RATE_OVERRIDE_CONFIG, \"10\")",
          "89:     adminZkClient.changeConfigs(ConfigType.Ip, \"1.1.1.1\", props)",
          "90:     adminZkClient.changeConfigs(ConfigType.Ip, \"<default>\", props)",
          "92:     val batches = new java.util.ArrayList[java.util.List[ApiMessageAndVersion]]()",
          "93:     migrationClient.migrateClientQuotas(batch => batches.add(batch))",
          "95:     assertEquals(9, batches.size())",
          "96:     val delta = new ClientQuotasDelta(ClientQuotasImage.EMPTY)",
          "97:     RecordTestUtils.replayAllBatches(delta, batches)",
          "98:     val image = delta.apply()",
          "100:     assertTrue(image.entities().containsKey(new ClientQuotaEntity(Map(\"user\" -> \"\").asJava)))",
          "101:     assertTrue(image.entities().containsKey(new ClientQuotaEntity(Map(\"user\" -> \"user1\").asJava)))",
          "102:     assertTrue(image.entities().containsKey(new ClientQuotaEntity(Map(\"user\" -> \"user1\", \"client-id\" -> \"clientA\").asJava)))",
          "103:     assertTrue(image.entities().containsKey(new ClientQuotaEntity(Map(\"user\" -> \"\", \"client-id\" -> \"\").asJava)))",
          "104:     assertTrue(image.entities().containsKey(new ClientQuotaEntity(Map(\"user\" -> \"\", \"client-id\" -> \"clientA\").asJava)))",
          "105:     assertTrue(image.entities().containsKey(new ClientQuotaEntity(Map(\"client-id\" -> \"\").asJava)))",
          "106:     assertTrue(image.entities().containsKey(new ClientQuotaEntity(Map(\"client-id\" -> \"clientB\").asJava)))",
          "107:     assertTrue(image.entities().containsKey(new ClientQuotaEntity(Map(\"ip\" -> \"1.1.1.1\").asJava)))",
          "108:     assertTrue(image.entities().containsKey(new ClientQuotaEntity(Map(\"ip\" -> \"\").asJava)))",
          "109:   }",
          "111:   @Test",
          "112:   def testWriteExistingClientQuotas(): Unit = {",
          "113:     val props = new Properties()",
          "114:     props.put(QuotaConfigs.PRODUCER_BYTE_RATE_OVERRIDE_CONFIG, \"100000\")",
          "115:     adminZkClient.changeConfigs(ConfigType.User, \"user1\", props)",
          "116:     adminZkClient.changeConfigs(ConfigType.User, \"user1/clients/clientA\", props)",
          "118:     assertEquals(0, migrationState.migrationZkVersion())",
          "119:     migrationState = writeClientQuotaAndVerify(migrationClient, adminZkClient, migrationState,",
          "120:       Map(ClientQuotaEntity.USER -> \"user1\"),",
          "121:       Map(QuotaConfigs.PRODUCER_BYTE_RATE_OVERRIDE_CONFIG -> 20000.0),",
          "122:       ConfigType.User, \"user1\")",
          "123:     assertEquals(1, migrationState.migrationZkVersion())",
          "125:     migrationState = writeClientQuotaAndVerify(migrationClient, adminZkClient, migrationState,",
          "126:       Map(ClientQuotaEntity.USER -> \"user1\"),",
          "127:       Map(QuotaConfigs.PRODUCER_BYTE_RATE_OVERRIDE_CONFIG -> 10000.0),",
          "128:       ConfigType.User, \"user1\")",
          "129:     assertEquals(2, migrationState.migrationZkVersion())",
          "131:     migrationState = writeClientQuotaAndVerify(migrationClient, adminZkClient, migrationState,",
          "132:       Map(ClientQuotaEntity.USER -> \"user1\"),",
          "133:       Map.empty,",
          "134:       ConfigType.User, \"user1\")",
          "135:     assertEquals(3, migrationState.migrationZkVersion())",
          "137:     migrationState = writeClientQuotaAndVerify(migrationClient, adminZkClient, migrationState,",
          "138:       Map(ClientQuotaEntity.USER -> \"user1\"),",
          "139:       Map(QuotaConfigs.CONSUMER_BYTE_RATE_OVERRIDE_CONFIG -> 100.0),",
          "140:       ConfigType.User, \"user1\")",
          "141:     assertEquals(4, migrationState.migrationZkVersion())",
          "143:     migrationState = writeClientQuotaAndVerify(migrationClient, adminZkClient, migrationState,",
          "144:       Map(ClientQuotaEntity.USER -> \"\"),",
          "145:       Map(QuotaConfigs.CONSUMER_BYTE_RATE_OVERRIDE_CONFIG -> 200.0),",
          "146:       ConfigType.User, \"<default>\")",
          "147:     assertEquals(5, migrationState.migrationZkVersion())",
          "148:   }",
          "151:   private def writeClientQuotaAndVerify(",
          "152:     migrationClient: ZkMigrationClient,",
          "153:     adminZkClient: AdminZkClient,",
          "154:     migrationState: ZkMigrationLeadershipState,",
          "155:     entity: Map[String, String],",
          "156:     quotas: Map[String, java.lang.Double],",
          "157:     zkEntityType: String,",
          "158:     zkEntityName: String",
          "159:   ): ZkMigrationLeadershipState = {",
          "160:     val nextMigrationState = migrationClient.configClient().writeClientQuotas(",
          "161:       entity.asJava,",
          "162:       quotas.asJava,",
          "163:       Map.empty[String, String].asJava,",
          "164:       migrationState)",
          "165:     val newProps = ZkAdminManager.clientQuotaPropsToDoubleMap(",
          "166:       adminZkClient.fetchEntityConfig(zkEntityType, zkEntityName).asScala)",
          "167:     assertEquals(quotas, newProps)",
          "168:     nextMigrationState",
          "169:   }",
          "171:   @Test",
          "172:   def testWriteNewClientQuotas(): Unit = {",
          "173:     assertEquals(0, migrationState.migrationZkVersion())",
          "174:     migrationState = writeClientQuotaAndVerify(migrationClient, adminZkClient, migrationState,",
          "175:       Map(ClientQuotaEntity.USER -> \"user2\"),",
          "176:       Map(QuotaConfigs.PRODUCER_BYTE_RATE_OVERRIDE_CONFIG -> 20000.0, QuotaConfigs.CONSUMER_BYTE_RATE_OVERRIDE_CONFIG -> 100.0),",
          "177:       ConfigType.User, \"user2\")",
          "179:     assertEquals(1, migrationState.migrationZkVersion())",
          "181:     migrationState = writeClientQuotaAndVerify(migrationClient, adminZkClient, migrationState,",
          "182:       Map(ClientQuotaEntity.USER -> \"user2\", ClientQuotaEntity.CLIENT_ID -> \"clientA\"),",
          "183:       Map(QuotaConfigs.PRODUCER_BYTE_RATE_OVERRIDE_CONFIG -> 10000.0, QuotaConfigs.CONSUMER_BYTE_RATE_OVERRIDE_CONFIG -> 200.0),",
          "184:       ConfigType.User, \"user2/clients/clientA\")",
          "186:     assertEquals(2, migrationState.migrationZkVersion())",
          "187:   }",
          "189:   @Test",
          "190:   def testWriteNewTopicConfigs(): Unit = {",
          "191:     migrationState = migrationClient.configClient().writeConfigs(new ConfigResource(ConfigResource.Type.TOPIC, \"test\"),",
          "192:       java.util.Collections.singletonMap(TopicConfig.SEGMENT_MS_CONFIG, \"100000\"), migrationState)",
          "193:     assertEquals(1, migrationState.migrationZkVersion())",
          "195:     val newProps = zkClient.getEntityConfigs(ConfigType.Topic, \"test\")",
          "196:     assertEquals(1, newProps.size())",
          "197:     assertEquals(\"100000\", newProps.getProperty(TopicConfig.SEGMENT_MS_CONFIG))",
          "198:   }",
          "200:   @Test",
          "201:   def testWriteExistingTopicConfigs(): Unit = {",
          "202:     val props = new Properties()",
          "203:     props.put(TopicConfig.FLUSH_MS_CONFIG, \"60000\")",
          "204:     props.put(TopicConfig.RETENTION_MS_CONFIG, \"300000\")",
          "205:     zkClient.setOrCreateEntityConfigs(ConfigType.Topic, \"test\", props)",
          "207:     migrationState = migrationClient.configClient().writeConfigs(new ConfigResource(ConfigResource.Type.TOPIC, \"test\"),",
          "208:       java.util.Collections.singletonMap(TopicConfig.SEGMENT_MS_CONFIG, \"100000\"), migrationState)",
          "209:     assertEquals(1, migrationState.migrationZkVersion())",
          "211:     val newProps = zkClient.getEntityConfigs(ConfigType.Topic, \"test\")",
          "212:     assertEquals(1, newProps.size())",
          "213:     assertEquals(\"100000\", newProps.getProperty(TopicConfig.SEGMENT_MS_CONFIG))",
          "214:   }",
          "216:   @Test",
          "217:   def testScram(): Unit = {",
          "218:     val random = new MockRandom()",
          "220:     def randomBuffer(random: MockRandom, length: Int): Array[Byte] = {",
          "221:       val buf = new Array[Byte](length)",
          "222:       random.nextBytes(buf)",
          "223:       buf",
          "224:     }",
          "226:     val scramCredential = new ScramCredential(",
          "227:       randomBuffer(random, 1024),",
          "228:       randomBuffer(random, 1024),",
          "229:       randomBuffer(random, 1024),",
          "230:       4096)",
          "232:     val props = new Properties()",
          "233:     props.put(\"SCRAM-SHA-256\", ScramCredentialUtils.credentialToString(scramCredential))",
          "234:     adminZkClient.changeConfigs(ConfigType.User, \"alice\", props)",
          "236:     val brokers = new java.util.ArrayList[Integer]()",
          "237:     val batches = new java.util.ArrayList[java.util.List[ApiMessageAndVersion]]()",
          "239:     migrationClient.readAllMetadata(batch => batches.add(batch), brokerId => brokers.add(brokerId))",
          "240:     assertEquals(0, brokers.size())",
          "241:     assertEquals(1, batches.size())",
          "242:     assertEquals(1, batches.get(0).size)",
          "243:   }",
          "244: }",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala": [
          "File: core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala -> core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "17: package kafka.zk.migration",
          "19: import kafka.api.LeaderAndIsr",
          "20: import kafka.controller.LeaderIsrAndControllerEpoch",
          "21: import kafka.coordinator.transaction.ProducerIdManager",
          "22: import kafka.zk.migration.ZkMigrationTestHarness",
          "23: import org.apache.kafka.common.config.TopicConfig",
          "24: import org.apache.kafka.common.errors.ControllerMovedException",
          "25: import org.apache.kafka.common.metadata.{ConfigRecord, MetadataRecordType, ProducerIdsRecord}",
          "26: import org.apache.kafka.common.{TopicPartition, Uuid}",
          "27: import org.apache.kafka.metadata.migration.ZkMigrationLeadershipState",
          "28: import org.apache.kafka.metadata.{LeaderRecoveryState, PartitionRegistration}",
          "29: import org.apache.kafka.server.common.ApiMessageAndVersion",
          "30: import org.junit.jupiter.api.Assertions.{assertEquals, assertThrows, assertTrue, fail}",
          "31: import org.junit.jupiter.api.Test",
          "33: import java.util.Properties",
          "34: import scala.collection.Map",
          "35: import scala.jdk.CollectionConverters._",
          "40: class ZkMigrationClientTest extends ZkMigrationTestHarness {",
          "42:   @Test",
          "43:   def testMigrateEmptyZk(): Unit = {",
          "44:     val brokers = new java.util.ArrayList[Integer]()",
          "45:     val batches = new java.util.ArrayList[java.util.List[ApiMessageAndVersion]]()",
          "47:     migrationClient.readAllMetadata(batch => batches.add(batch), brokerId => brokers.add(brokerId))",
          "48:     assertEquals(0, brokers.size())",
          "49:     assertEquals(0, batches.size())",
          "50:   }",
          "52:   @Test",
          "53:   def testEmptyWrite(): Unit = {",
          "54:     val (zkVersion, responses) = zkClient.retryMigrationRequestsUntilConnected(Seq(), migrationState)",
          "55:     assertEquals(migrationState.migrationZkVersion(), zkVersion)",
          "56:     assertTrue(responses.isEmpty)",
          "57:   }",
          "59:   @Test",
          "60:   def testUpdateExistingPartitions(): Unit = {",
          "62:     val assignment = Map(",
          "63:       new TopicPartition(\"test\", 0) -> List(0, 1, 2),",
          "64:       new TopicPartition(\"test\", 1) -> List(1, 2, 3)",
          "65:     )",
          "66:     zkClient.createTopicAssignment(\"test\", Some(Uuid.randomUuid()), assignment)",
          "68:     val leaderAndIsrs = Map(",
          "69:       new TopicPartition(\"test\", 0) -> LeaderIsrAndControllerEpoch(",
          "70:         LeaderAndIsr(0, 5, List(0, 1, 2), LeaderRecoveryState.RECOVERED, -1), 1),",
          "71:       new TopicPartition(\"test\", 1) -> LeaderIsrAndControllerEpoch(",
          "72:         LeaderAndIsr(1, 5, List(1, 2, 3), LeaderRecoveryState.RECOVERED, -1), 1)",
          "73:     )",
          "74:     zkClient.createTopicPartitionStatesRaw(leaderAndIsrs, 0)",
          "77:     assertEquals(0, migrationState.migrationZkVersion())",
          "79:     val partitions = Map(",
          "80:       0 -> new PartitionRegistration(Array(0, 1, 2), Array(1, 2), Array(), Array(), 1, LeaderRecoveryState.RECOVERED, 6, -1),",
          "81:       1 -> new PartitionRegistration(Array(1, 2, 3), Array(3), Array(), Array(), 3, LeaderRecoveryState.RECOVERED, 7, -1)",
          "82:     ).map { case (k, v) => Integer.valueOf(k) -> v }.asJava",
          "83:     migrationState = migrationClient.topicClient().updateTopicPartitions(Map(\"test\" -> partitions).asJava, migrationState)",
          "84:     assertEquals(1, migrationState.migrationZkVersion())",
          "87:     val partition0 = zkClient.getTopicPartitionState(new TopicPartition(\"test\", 0)).get.leaderAndIsr",
          "88:     assertEquals(1, partition0.leader)",
          "89:     assertEquals(6, partition0.leaderEpoch)",
          "90:     assertEquals(List(1, 2), partition0.isr)",
          "92:     val partition1 = zkClient.getTopicPartitionState(new TopicPartition(\"test\", 1)).get.leaderAndIsr",
          "93:     assertEquals(3, partition1.leader)",
          "94:     assertEquals(7, partition1.leaderEpoch)",
          "95:     assertEquals(List(3), partition1.isr)",
          "98:     migrationState = migrationClient.topicClient().deleteTopic(\"test\", migrationState)",
          "99:     assertEquals(2, migrationState.migrationZkVersion())",
          "100:   }",
          "102:   @Test",
          "103:   def testCreateNewPartitions(): Unit = {",
          "104:     assertEquals(0, migrationState.migrationZkVersion())",
          "106:     val partitions = Map(",
          "107:       0 -> new PartitionRegistration(Array(0, 1, 2), Array(0, 1, 2), Array(), Array(), 0, LeaderRecoveryState.RECOVERED, 0, -1),",
          "108:       1 -> new PartitionRegistration(Array(1, 2, 3), Array(1, 2, 3), Array(), Array(), 1, LeaderRecoveryState.RECOVERED, 0, -1)",
          "109:     ).map { case (k, v) => Integer.valueOf(k) -> v }.asJava",
          "110:     migrationState = migrationClient.topicClient().createTopic(\"test\", Uuid.randomUuid(), partitions, migrationState)",
          "111:     assertEquals(1, migrationState.migrationZkVersion())",
          "114:     val partition0 = zkClient.getTopicPartitionState(new TopicPartition(\"test\", 0)).get.leaderAndIsr",
          "115:     assertEquals(0, partition0.leader)",
          "116:     assertEquals(0, partition0.leaderEpoch)",
          "117:     assertEquals(List(0, 1, 2), partition0.isr)",
          "119:     val partition1 = zkClient.getTopicPartitionState(new TopicPartition(\"test\", 1)).get.leaderAndIsr",
          "120:     assertEquals(1, partition1.leader)",
          "121:     assertEquals(0, partition1.leaderEpoch)",
          "122:     assertEquals(List(1, 2, 3), partition1.isr)",
          "123:   }",
          "125:   @Test",
          "126:   def testIdempotentCreateTopics(): Unit = {",
          "127:     assertEquals(0, migrationState.migrationZkVersion())",
          "129:     val partitions = Map(",
          "130:       0 -> new PartitionRegistration(Array(0, 1, 2), Array(0, 1, 2), Array(), Array(), 0, LeaderRecoveryState.RECOVERED, 0, -1),",
          "131:       1 -> new PartitionRegistration(Array(1, 2, 3), Array(1, 2, 3), Array(), Array(), 1, LeaderRecoveryState.RECOVERED, 0, -1)",
          "132:     ).map { case (k, v) => Integer.valueOf(k) -> v }.asJava",
          "133:     val topicId = Uuid.randomUuid()",
          "134:     migrationState = migrationClient.topicClient().createTopic(\"test\", topicId, partitions, migrationState)",
          "135:     assertEquals(1, migrationState.migrationZkVersion())",
          "137:     migrationState = migrationClient.topicClient().createTopic(\"test\", topicId, partitions, migrationState)",
          "138:     assertEquals(1, migrationState.migrationZkVersion())",
          "139:   }",
          "141:   @Test",
          "142:   def testClaimAbsentController(): Unit = {",
          "143:     assertEquals(0, migrationState.migrationZkVersion())",
          "144:     migrationState = migrationClient.claimControllerLeadership(migrationState)",
          "145:     assertEquals(1, migrationState.zkControllerEpochZkVersion())",
          "146:   }",
          "148:   @Test",
          "149:   def testExistingKRaftControllerClaim(): Unit = {",
          "150:     assertEquals(0, migrationState.migrationZkVersion())",
          "151:     migrationState = migrationClient.claimControllerLeadership(migrationState)",
          "152:     assertEquals(1, migrationState.zkControllerEpochZkVersion())",
          "156:     var otherNodeState = ZkMigrationLeadershipState.EMPTY",
          "157:       .withNewKRaftController(3001, 43)",
          "158:       .withKRaftMetadataOffsetAndEpoch(100, 42);",
          "159:     otherNodeState = migrationClient.claimControllerLeadership(otherNodeState)",
          "160:     assertEquals(2, otherNodeState.zkControllerEpochZkVersion())",
          "161:     assertEquals(3001, otherNodeState.kraftControllerId())",
          "162:     assertEquals(43, otherNodeState.kraftControllerEpoch())",
          "163:   }",
          "165:   @Test",
          "166:   def testNonIncreasingKRaftEpoch(): Unit = {",
          "167:     assertEquals(0, migrationState.migrationZkVersion())",
          "169:     migrationState = migrationState.withNewKRaftController(3001, InitialControllerEpoch)",
          "170:     migrationState = migrationClient.claimControllerLeadership(migrationState)",
          "171:     assertEquals(1, migrationState.zkControllerEpochZkVersion())",
          "173:     migrationState = migrationState.withNewKRaftController(3001, InitialControllerEpoch - 1)",
          "174:     val t1 = assertThrows(classOf[ControllerMovedException], () => migrationClient.claimControllerLeadership(migrationState))",
          "175:     assertEquals(\"Cannot register KRaft controller 3001 with epoch 41 as the current controller register in ZK has the same or newer epoch 42.\", t1.getMessage)",
          "177:     migrationState = migrationState.withNewKRaftController(3001, InitialControllerEpoch)",
          "178:     val t2 = assertThrows(classOf[ControllerMovedException], () => migrationClient.claimControllerLeadership(migrationState))",
          "179:     assertEquals(\"Cannot register KRaft controller 3001 with epoch 42 as the current controller register in ZK has the same or newer epoch 42.\", t2.getMessage)",
          "181:     migrationState = migrationState.withNewKRaftController(3001, 100)",
          "182:     migrationState = migrationClient.claimControllerLeadership(migrationState)",
          "183:     assertEquals(migrationState.kraftControllerEpoch(), 100)",
          "184:     assertEquals(migrationState.kraftControllerId(), 3001)",
          "185:   }",
          "187:   @Test",
          "188:   def testClaimAndReleaseExistingController(): Unit = {",
          "189:     assertEquals(0, migrationState.migrationZkVersion())",
          "191:     val (epoch, zkVersion) = zkClient.registerControllerAndIncrementControllerEpoch(100)",
          "192:     assertEquals(epoch, 2)",
          "193:     assertEquals(zkVersion, 1)",
          "195:     migrationState = migrationClient.claimControllerLeadership(migrationState)",
          "196:     assertEquals(2, migrationState.zkControllerEpochZkVersion())",
          "197:     zkClient.getControllerEpoch match {",
          "198:       case Some((zkEpoch, stat)) =>",
          "199:         assertEquals(3, zkEpoch)",
          "200:         assertEquals(2, stat.getVersion)",
          "201:       case None => fail()",
          "202:     }",
          "203:     assertEquals(3000, zkClient.getControllerId.get)",
          "204:     assertThrows(classOf[ControllerMovedException], () => zkClient.registerControllerAndIncrementControllerEpoch(100))",
          "206:     migrationState = migrationClient.releaseControllerLeadership(migrationState)",
          "207:     val (epoch1, zkVersion1) = zkClient.registerControllerAndIncrementControllerEpoch(100)",
          "208:     assertEquals(epoch1, 4)",
          "209:     assertEquals(zkVersion1, 3)",
          "210:   }",
          "212:   @Test",
          "213:   def testReadAndWriteProducerId(): Unit = {",
          "214:     def generateNextProducerIdWithZkAndRead(): Long = {",
          "216:       val manager = ProducerIdManager.zk(1, zkClient)",
          "217:       manager.generateProducerId()",
          "219:       val records = new java.util.ArrayList[java.util.List[ApiMessageAndVersion]]()",
          "220:       migrationClient.migrateProducerId(batch => records.add(batch))",
          "221:       assertEquals(1, records.size())",
          "222:       assertEquals(1, records.get(0).size())",
          "224:       val record = records.get(0).get(0).message().asInstanceOf[ProducerIdsRecord]",
          "225:       record.nextProducerId()",
          "226:     }",
          "229:     assertEquals(0, generateNextProducerIdWithZkAndRead())",
          "232:     migrationState = migrationClient.writeProducerId(6000, migrationState)",
          "233:     assertEquals(1, migrationState.migrationZkVersion())",
          "236:     assertEquals(7000, generateNextProducerIdWithZkAndRead())",
          "237:   }",
          "239:   @Test",
          "240:   def testMigrateTopicConfigs(): Unit = {",
          "241:     val props = new Properties()",
          "242:     props.put(TopicConfig.FLUSH_MS_CONFIG, \"60000\")",
          "243:     props.put(TopicConfig.RETENTION_MS_CONFIG, \"300000\")",
          "244:     adminZkClient.createTopicWithAssignment(\"test\", props, Map(0 -> Seq(0, 1, 2), 1 -> Seq(1, 2, 0), 2 -> Seq(2, 0, 1)), usesTopicId = true)",
          "246:     val brokers = new java.util.ArrayList[Integer]()",
          "247:     val batches = new java.util.ArrayList[java.util.List[ApiMessageAndVersion]]()",
          "248:     migrationClient.migrateTopics(batch => batches.add(batch), brokerId => brokers.add(brokerId))",
          "249:     assertEquals(1, batches.size())",
          "250:     val configs = batches.get(0)",
          "251:       .asScala",
          "252:       .map {_.message() }",
          "253:       .filter(message => MetadataRecordType.fromId(message.apiKey()).equals(MetadataRecordType.CONFIG_RECORD))",
          "254:       .map { _.asInstanceOf[ConfigRecord] }",
          "255:       .toSeq",
          "256:     assertEquals(2, configs.size)",
          "257:     assertEquals(TopicConfig.FLUSH_MS_CONFIG, configs.head.name())",
          "258:     assertEquals(\"60000\", configs.head.value())",
          "259:     assertEquals(TopicConfig.RETENTION_MS_CONFIG, configs.last.name())",
          "260:     assertEquals(\"300000\", configs.last.value())",
          "261:   }",
          "262: }",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/zk/migration/ZkMigrationTestHarness.scala||core/src/test/scala/unit/kafka/zk/migration/ZkMigrationTestHarness.scala": [
          "File: core/src/test/scala/unit/kafka/zk/migration/ZkMigrationTestHarness.scala -> core/src/test/scala/unit/kafka/zk/migration/ZkMigrationTestHarness.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "17: package kafka.zk.migration",
          "19: import kafka.server.{KafkaConfig, QuorumTestHarness}",
          "20: import kafka.utils.PasswordEncoder",
          "21: import kafka.zk.ZkMigrationClient",
          "22: import org.apache.kafka.common.utils.Time",
          "23: import org.apache.kafka.metadata.migration.ZkMigrationLeadershipState",
          "24: import org.junit.jupiter.api.{BeforeEach, TestInfo}",
          "26: import java.util.Properties",
          "28: class ZkMigrationTestHarness extends QuorumTestHarness {",
          "29:   val InitialControllerEpoch: Int = 42",
          "31:   val InitialKRaftEpoch: Int = 0",
          "33:   var migrationClient: ZkMigrationClient = _",
          "35:   var migrationState: ZkMigrationLeadershipState = _",
          "37:   val SECRET = \"secret\"",
          "39:   val encoder: PasswordEncoder = {",
          "40:     val encoderProps = new Properties()",
          "41:     encoderProps.put(KafkaConfig.ZkConnectProp, \"localhost:1234\") // Get around the config validation",
          "42:     encoderProps.put(KafkaConfig.PasswordEncoderSecretProp, SECRET) // Zk secret to encrypt the",
          "43:     val encoderConfig = new KafkaConfig(encoderProps)",
          "44:     PasswordEncoder.encrypting(encoderConfig.passwordEncoderSecret.get,",
          "45:       encoderConfig.passwordEncoderKeyFactoryAlgorithm,",
          "46:       encoderConfig.passwordEncoderCipherAlgorithm,",
          "47:       encoderConfig.passwordEncoderKeyLength,",
          "48:       encoderConfig.passwordEncoderIterations)",
          "49:   }",
          "51:   @BeforeEach",
          "52:   override def setUp(testInfo: TestInfo): Unit = {",
          "53:     super.setUp(testInfo)",
          "54:     zkClient.createControllerEpochRaw(1)",
          "55:     migrationClient = ZkMigrationClient(zkClient, encoder)",
          "56:     migrationState = initialMigrationState",
          "57:     migrationState = migrationClient.getOrCreateMigrationRecoveryState(migrationState)",
          "58:   }",
          "60:   private def initialMigrationState: ZkMigrationLeadershipState = {",
          "61:     val (epoch, stat) = zkClient.getControllerEpoch.get",
          "62:     new ZkMigrationLeadershipState(3000, InitialControllerEpoch, 100, InitialKRaftEpoch, Time.SYSTEM.milliseconds(), -1, epoch, stat.getVersion)",
          "63:   }",
          "64: }",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/image/AclsDelta.java||metadata/src/main/java/org/apache/kafka/image/AclsDelta.java": [
          "File: metadata/src/main/java/org/apache/kafka/image/AclsDelta.java -> metadata/src/main/java/org/apache/kafka/image/AclsDelta.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "25: import org.apache.kafka.server.common.MetadataVersion;",
          "27: import java.util.HashMap;",
          "28: import java.util.LinkedHashMap;",
          "29: import java.util.Map;",
          "30: import java.util.Map.Entry;",
          "31: import java.util.Optional;",
          "32: import java.util.stream.Collectors;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "28: import java.util.HashSet;",
          "33: import java.util.Set;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "38: public final class AclsDelta {",
          "39:     private final AclsImage image;",
          "40:     private final Map<Uuid, Optional<StandardAcl>> changes = new LinkedHashMap<>();",
          "41:     private boolean isSnapshotDelta = false;",
          "43:     public AclsDelta(AclsImage image) {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "43:     private final Set<StandardAcl> deleted = new HashSet<>();",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "54:         return changes;",
          "55:     }",
          "57:     void finishSnapshot() {",
          "58:         this.isSnapshotDelta = true;",
          "59:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "65:     public Set<StandardAcl> deleted() {",
          "66:         return deleted;",
          "67:     }",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "82:     public void replay(RemoveAccessControlEntryRecord record) {",
          "83:         if (image.acls().containsKey(record.id())) {",
          "84:             changes.put(record.id(), Optional.empty());",
          "85:         } else if (changes.containsKey(record.id())) {",
          "86:             changes.remove(record.id());",
          "87:         } else {",
          "88:             throw new IllegalStateException(\"Failed to find existing ACL with ID \" + record.id() + \" in either image or changes\");",
          "89:         }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "97:             deleted.add(image.acls().get(record.id()));",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/image/ConfigurationsImage.java||metadata/src/main/java/org/apache/kafka/image/ConfigurationsImage.java": [
          "File: metadata/src/main/java/org/apache/kafka/image/ConfigurationsImage.java -> metadata/src/main/java/org/apache/kafka/image/ConfigurationsImage.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "48:         return data.isEmpty();",
          "49:     }",
          "52:         return data;",
          "53:     }",
          "",
          "[Removed Lines]",
          "51:     Map<ConfigResource, ConfigurationImage> resourceData() {",
          "",
          "[Added Lines]",
          "51:     public Map<ConfigResource, ConfigurationImage> resourceData() {",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/migration/AclMigrationClient.java||metadata/src/main/java/org/apache/kafka/metadata/migration/AclMigrationClient.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/migration/AclMigrationClient.java -> metadata/src/main/java/org/apache/kafka/metadata/migration/AclMigrationClient.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.metadata.migration;",
          "20: import org.apache.kafka.common.acl.AccessControlEntry;",
          "21: import org.apache.kafka.common.resource.ResourcePattern;",
          "23: import java.util.Collection;",
          "24: import java.util.Set;",
          "25: import java.util.function.BiConsumer;",
          "27: public interface AclMigrationClient {",
          "28:     ZkMigrationLeadershipState deleteResource(",
          "29:         ResourcePattern resourcePattern,",
          "30:         ZkMigrationLeadershipState state",
          "31:     );",
          "33:     ZkMigrationLeadershipState writeResourceAcls(",
          "34:         ResourcePattern resourcePattern,",
          "35:         Collection<AccessControlEntry> aclsToWrite,",
          "36:         ZkMigrationLeadershipState state",
          "37:     );",
          "39:     void iterateAcls(BiConsumer<ResourcePattern, Set<AccessControlEntry>> aclConsumer);",
          "40: }",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/migration/ConfigMigrationClient.java||metadata/src/main/java/org/apache/kafka/metadata/migration/ConfigMigrationClient.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/migration/ConfigMigrationClient.java -> metadata/src/main/java/org/apache/kafka/metadata/migration/ConfigMigrationClient.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.metadata.migration;",
          "20: import org.apache.kafka.clients.admin.ScramMechanism;",
          "21: import org.apache.kafka.common.config.ConfigResource;",
          "22: import org.apache.kafka.common.metadata.ClientQuotaRecord;",
          "23: import org.apache.kafka.common.security.scram.ScramCredential;",
          "25: import java.util.List;",
          "26: import java.util.Map;",
          "27: import java.util.function.BiConsumer;",
          "29: public interface ConfigMigrationClient {",
          "31:     interface ClientQuotaVisitor {",
          "32:         void visitClientQuota(List<ClientQuotaRecord.EntityData> entityDataList, Map<String, Double> quotas);",
          "34:         void visitScramCredential(String userName, ScramMechanism scramMechanism, ScramCredential scramCredential);",
          "35:     }",
          "37:     void iterateClientQuotas(ClientQuotaVisitor visitor);",
          "39:     void iterateBrokerConfigs(BiConsumer<String, Map<String, String>> configConsumer);",
          "41:     ZkMigrationLeadershipState writeConfigs(",
          "42:         ConfigResource configResource,",
          "43:         Map<String, String> configMap,",
          "44:         ZkMigrationLeadershipState state",
          "45:     );",
          "47:     ZkMigrationLeadershipState writeClientQuotas(",
          "48:         Map<String, String> clientQuotaEntity,",
          "49:         Map<String, Double> quotas,",
          "50:         Map<String, String> scram,",
          "51:         ZkMigrationLeadershipState state",
          "52:     );",
          "54:     ZkMigrationLeadershipState deleteConfigs(",
          "55:         ConfigResource configResource,",
          "56:         ZkMigrationLeadershipState state",
          "57:     );",
          "58: }",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java -> metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: package org.apache.kafka.metadata.migration;",
          "20: import org.apache.kafka.common.metadata.ConfigRecord;",
          "21: import org.apache.kafka.common.metadata.MetadataRecordType;",
          "24: import org.apache.kafka.common.utils.LogContext;",
          "25: import org.apache.kafka.common.utils.Time;",
          "27: import org.apache.kafka.controller.QuorumFeatures;",
          "28: import org.apache.kafka.image.MetadataDelta;",
          "29: import org.apache.kafka.image.MetadataImage;",
          "",
          "[Removed Lines]",
          "19: import org.apache.kafka.common.acl.AccessControlEntry;",
          "22: import org.apache.kafka.common.quota.ClientQuotaEntity;",
          "23: import org.apache.kafka.common.resource.ResourcePattern;",
          "26: import org.apache.kafka.common.security.scram.internals.ScramCredentialUtils;",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "32: import org.apache.kafka.image.loader.LoaderManifestType;",
          "33: import org.apache.kafka.image.publisher.MetadataPublisher;",
          "34: import org.apache.kafka.metadata.BrokerRegistration;",
          "37: import org.apache.kafka.queue.EventQueue;",
          "38: import org.apache.kafka.queue.KafkaEventQueue;",
          "39: import org.apache.kafka.raft.LeaderAndEpoch;",
          "",
          "[Removed Lines]",
          "35: import org.apache.kafka.metadata.authorizer.StandardAcl;",
          "36: import org.apache.kafka.metadata.ScramCredentialData;",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "44: import org.apache.kafka.server.util.FutureUtils;",
          "45: import org.slf4j.Logger;",
          "48: import java.util.Collection;",
          "51: import java.util.HashSet;",
          "54: import java.util.Optional;",
          "55: import java.util.Set;",
          "56: import java.util.concurrent.CompletableFuture;",
          "",
          "[Removed Lines]",
          "47: import java.util.ArrayList;",
          "49: import java.util.Collections;",
          "50: import java.util.HashMap;",
          "52: import java.util.List;",
          "53: import java.util.Map;",
          "",
          "[Added Lines]",
          "42: import java.util.EnumSet;",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "58: import java.util.concurrent.TimeUnit;",
          "59: import java.util.concurrent.atomic.AtomicInteger;",
          "60: import java.util.function.Consumer;",
          "62: import java.util.stream.Collectors;",
          "64: import static java.util.concurrent.TimeUnit.NANOSECONDS;",
          "",
          "[Removed Lines]",
          "61: import java.util.function.Function;",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "83:     private final Logger log;",
          "84:     private final int nodeId;",
          "85:     private final MigrationClient zkMigrationClient;",
          "86:     private final LegacyPropagator propagator;",
          "87:     private final ZkRecordConsumer zkRecordConsumer;",
          "88:     private final KafkaEventQueue eventQueue;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "75:     private final KRaftMigrationZkWriter zkMetadataWriter;",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "125:         this.initialZkLoadHandler = initialZkLoadHandler;",
          "126:         this.faultHandler = faultHandler;",
          "127:         this.quorumFeatures = quorumFeatures;",
          "128:     }",
          "130:     public KRaftMigrationDriver(",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "118:         this.zkMetadataWriter = new KRaftMigrationZkWriter(zkMigrationClient, this::applyMigrationOperation);",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "160:     private void recoverMigrationStateFromZK() {",
          "161:         log.info(\"Recovering migration state from ZK\");",
          "163:         String maybeDone = migrationLeadershipState.zkMigrationComplete() ? \"done\" : \"not done\";",
          "164:         log.info(\"Recovered migration state {}. ZK migration is {}.\", migrationLeadershipState, maybeDone);",
          "",
          "[Removed Lines]",
          "162:         apply(\"Recovery\", zkMigrationClient::getOrCreateMigrationRecoveryState);",
          "",
          "[Added Lines]",
          "153:         applyMigrationOperation(\"Recovery\", zkMigrationClient::getOrCreateMigrationRecoveryState);",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "215:         }",
          "219:         if (imageDoesNotContainAllBrokers(image, zkBrokersWithAssignments)) {",
          "221:             return false;",
          "222:         }",
          "",
          "[Removed Lines]",
          "218:         Set<Integer> zkBrokersWithAssignments = zkMigrationClient.readBrokerIdsFromTopicAssignments();",
          "220:             log.info(\"Still waiting for ZK brokers {} to register with KRaft.\", zkBrokersWithAssignments);",
          "",
          "[Added Lines]",
          "209:         Set<Integer> zkBrokersWithAssignments = new HashSet<>();",
          "210:         zkMigrationClient.topicClient().iterateTopics(",
          "211:             EnumSet.of(TopicMigrationClient.TopicVisitorInterest.TOPICS),",
          "212:             (topicName, topicId, assignments) -> assignments.values().forEach(zkBrokersWithAssignments::addAll)",
          "213:         );",
          "216:             log.info(\"Still waiting for ZK brokers {} found in metadata to register with KRaft.\", zkBrokersWithAssignments);",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "234:         ZkMigrationLeadershipState beforeState = this.migrationLeadershipState;",
          "237:         this.migrationLeadershipState = afterState;",
          "238:     }",
          "",
          "[Removed Lines]",
          "233:     private void apply(String name, Function<ZkMigrationLeadershipState, ZkMigrationLeadershipState> stateMutator) {",
          "235:         ZkMigrationLeadershipState afterState = stateMutator.apply(beforeState);",
          "236:         log.trace(\"{} transitioned from {} to {}\", name, beforeState, afterState);",
          "",
          "[Added Lines]",
          "229:     private void applyMigrationOperation(String name, KRaftMigrationOperation migrationOp) {",
          "231:         ZkMigrationLeadershipState afterState = migrationOp.apply(beforeState);",
          "232:         if (afterState.loggableChangeSinceState(beforeState)) {",
          "233:             log.info(\"{} transitioned migration state from {} to {}\", name, beforeState, afterState);",
          "234:         } else if (afterState.equals(beforeState)) {",
          "235:             log.trace(\"{} kept migration state as {}\", name, afterState);",
          "236:         } else {",
          "237:             log.trace(\"{} transitioned migration state from {} to {}\", name, beforeState, afterState);",
          "239:         }",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "426:             boolean isActive = leaderAndEpoch.isLeader(KRaftMigrationDriver.this.nodeId);",
          "428:             if (!isActive) {",
          "430:                     state.withNewKRaftController(",
          "431:                         leaderAndEpoch.leaderId().orElse(ZkMigrationLeadershipState.EMPTY.kraftControllerId()),",
          "432:                         leaderAndEpoch.epoch())",
          "",
          "[Removed Lines]",
          "429:                 apply(\"KRaftLeaderEvent is not active\", state ->",
          "",
          "[Added Lines]",
          "432:                 applyMigrationOperation(\"KRaftLeaderEvent is not active\", state ->",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "434:                 transitionTo(MigrationDriverState.INACTIVE);",
          "435:             } else {",
          "",
          "[Removed Lines]",
          "437:                 apply(\"KRaftLeaderEvent is active\", state -> state.withNewKRaftController(nodeId, leaderAndEpoch.epoch()));",
          "",
          "[Added Lines]",
          "440:                 applyMigrationOperation(\"KRaftLeaderEvent is active\", state -> state.withNewKRaftController(nodeId, leaderAndEpoch.epoch()));",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "492:         @Override",
          "493:         public void run() throws Exception {",
          "494:             if (migrationState == MigrationDriverState.BECOME_CONTROLLER) {",
          "496:                 if (migrationLeadershipState.zkControllerEpochZkVersion() == -1) {",
          "497:                     log.debug(\"Unable to claim leadership, will retry until we learn of a different KRaft leader\");",
          "498:                 } else {",
          "",
          "[Removed Lines]",
          "495:                 apply(\"BecomeZkLeaderEvent\", zkMigrationClient::claimControllerLeadership);",
          "",
          "[Added Lines]",
          "498:                 applyMigrationOperation(\"BecomeZkLeaderEvent\", zkMigrationClient::claimControllerLeadership);",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "563:                 ZkMigrationLeadershipState newState = migrationLeadershipState.withKRaftMetadataOffsetAndEpoch(",
          "564:                     offsetAndEpochAfterMigration.offset(),",
          "565:                     offsetAndEpochAfterMigration.epoch());",
          "567:                 transitionTo(MigrationDriverState.KRAFT_CONTROLLER_TO_BROKER_COMM);",
          "568:             } catch (Throwable t) {",
          "569:                 zkRecordConsumer.abortMigration();",
          "",
          "[Removed Lines]",
          "566:                 apply(\"Finished migrating ZK data\", state -> zkMigrationClient.setMigrationRecoveryState(newState));",
          "",
          "[Added Lines]",
          "569:                 applyMigrationOperation(\"Finished migrating ZK data\", state -> zkMigrationClient.setMigrationRecoveryState(newState));",
          "",
          "---------------",
          "--- Hunk 14 ---",
          "[Context before]",
          "630:                 propagator.setMetadataVersion(image.features().metadataVersion());",
          "631:             }",
          "750:             } else {",
          "752:             }",
          "767:             }",
          "776:         }",
          "778:         @Override",
          "",
          "[Removed Lines]",
          "633:             if (image.highestOffsetAndEpoch().compareTo(migrationLeadershipState.offsetAndEpoch()) >= 0) {",
          "634:                 if (delta.topicsDelta() != null) {",
          "635:                     delta.topicsDelta().changedTopics().forEach((topicId, topicDelta) -> {",
          "636:                         if (delta.topicsDelta().createdTopicIds().contains(topicId)) {",
          "637:                             apply(\"Create topic \" + topicDelta.name(), migrationState ->",
          "638:                                 zkMigrationClient.createTopic(",
          "639:                                     topicDelta.name(),",
          "640:                                     topicId,",
          "641:                                     topicDelta.partitionChanges(),",
          "642:                                     migrationState));",
          "643:                         } else {",
          "644:                             apply(\"Updating topic \" + topicDelta.name(), migrationState ->",
          "645:                                 zkMigrationClient.updateTopicPartitions(",
          "646:                                     Collections.singletonMap(topicDelta.name(), topicDelta.partitionChanges()),",
          "647:                                     migrationState));",
          "648:                         }",
          "649:                     });",
          "650:                 }",
          "654:                 if (delta.configsDelta() != null) {",
          "655:                     delta.configsDelta().changes().forEach((configResource, configDelta) ->",
          "656:                         apply(\"Updating config resource \" + configResource, migrationState ->",
          "657:                             zkMigrationClient.writeConfigs(configResource, image.configs().configMapForResource(configResource), migrationState)));",
          "658:                 }",
          "660:                 if ((delta.clientQuotasDelta() != null) || (delta.scramDelta() != null)) {",
          "662:                     HashSet<String> users = new HashSet<String>();",
          "665:                     if (delta.scramDelta() != null) {",
          "666:                         delta.scramDelta().changes().forEach((scramMechanism, changes) -> {",
          "667:                             changes.forEach((userName, changeOpt) -> users.add(userName));",
          "668:                         });",
          "669:                     }",
          "673:                     if (delta.clientQuotasDelta() != null) {",
          "674:                         Map<String, String> scramMap = new HashMap<String, String>();",
          "675:                         delta.clientQuotasDelta().changes().forEach((clientQuotaEntity, clientQuotaDelta) -> {",
          "677:                             if ((clientQuotaEntity.entries().containsKey(ClientQuotaEntity.USER)) &&",
          "678:                                 (!clientQuotaEntity.entries().containsKey(ClientQuotaEntity.CLIENT_ID))) {",
          "679:                                 String userName = clientQuotaEntity.entries().get(ClientQuotaEntity.USER);",
          "681:                                 users.add(userName);",
          "682:                             } else {",
          "683:                                 Map<String, Double> quotaMap = image.clientQuotas().entities().get(clientQuotaEntity).quotaMap();",
          "684:                                 apply(\"Updating client quota \" + clientQuotaEntity, migrationState ->",
          "685:                                     zkMigrationClient.writeClientQuotas(clientQuotaEntity.entries(), quotaMap, scramMap, migrationState));",
          "686:                             }",
          "687:                         });",
          "688:                     }",
          "690:                     users.forEach(userName -> {",
          "691:                         Map<String, String> userScramMap = getScramCredentialStringsForUser(userName);",
          "692:                         ClientQuotaEntity clientQuotaEntity = new",
          "693:                             ClientQuotaEntity(Collections.singletonMap(ClientQuotaEntity.USER, userName));",
          "694:                         if (image.clientQuotas() == null) {",
          "695:                             Map<String, Double> quotaMap = new HashMap<String, Double>();",
          "696:                             apply(\"Updating client quota \" + clientQuotaEntity, migrationState ->",
          "697:                                 zkMigrationClient.writeClientQuotas(clientQuotaEntity.entries(), quotaMap, userScramMap, migrationState));",
          "698:                         } else {",
          "699:                             Map<String, Double> quotaMap = image.clientQuotas().entities().get(clientQuotaEntity).quotaMap();",
          "700:                             apply(\"Updating client quota \" + clientQuotaEntity, migrationState ->",
          "701:                                 zkMigrationClient.writeClientQuotas(clientQuotaEntity.entries(), quotaMap, userScramMap, migrationState));",
          "702:                         }",
          "703:                     });",
          "704:                 }",
          "706:                 if (delta.producerIdsDelta() != null) {",
          "707:                     apply(\"Updating next producer ID\", migrationState ->",
          "708:                         zkMigrationClient.writeProducerId(delta.producerIdsDelta().nextProducerId(), migrationState));",
          "709:                 }",
          "711:                 if (delta.aclsDelta() != null) {",
          "712:                     Map<ResourcePattern, List<AccessControlEntry>> deletedAcls = new HashMap<>();",
          "713:                     Map<ResourcePattern, List<AccessControlEntry>> addedAcls = new HashMap<>();",
          "714:                     delta.aclsDelta().changes().forEach((uuid, standardAclOpt) -> {",
          "715:                         if (!standardAclOpt.isPresent()) {",
          "716:                             StandardAcl acl = prevImage.acls().acls().get(uuid);",
          "717:                             if (acl != null) {",
          "718:                                 addStandardAclToMap(deletedAcls, acl);",
          "719:                             } else {",
          "720:                                 throw new RuntimeException(\"Cannot remove deleted ACL \" + uuid + \" from ZK since it is \" +",
          "721:                                     \"not present in the previous AclsImage\");",
          "722:                             }",
          "723:                         } else {",
          "724:                             StandardAcl acl = standardAclOpt.get();",
          "725:                             addStandardAclToMap(addedAcls, acl);",
          "726:                         }",
          "727:                     });",
          "728:                     deletedAcls.forEach((resourcePattern, accessControlEntries) -> {",
          "729:                         String name = \"Deleting \" + accessControlEntries.size() + \" for resource \" + resourcePattern;",
          "730:                         apply(name, migrationState ->",
          "731:                             zkMigrationClient.removeDeletedAcls(resourcePattern, accessControlEntries, migrationState));",
          "732:                     });",
          "734:                     addedAcls.forEach((resourcePattern, accessControlEntries) -> {",
          "735:                         String name = \"Adding \" + accessControlEntries.size() + \" for resource \" + resourcePattern;",
          "736:                         apply(name, migrationState ->",
          "737:                             zkMigrationClient.writeAddedAcls(resourcePattern, accessControlEntries, migrationState));",
          "738:                     });",
          "739:                 }",
          "743:                 if (delta.topicsDelta() != null || delta.clusterDelta() != null) {",
          "744:                     log.trace(\"Sending RPCs to brokers for metadata {}.\", metadataType);",
          "745:                     propagator.sendRPCsToBrokersFromMetadataDelta(delta, image,",
          "746:                         migrationLeadershipState.zkControllerEpoch());",
          "747:                 } else {",
          "748:                     log.trace(\"Not sending RPCs to brokers for metadata {} since no relevant metadata has changed\", metadataType);",
          "749:                 }",
          "751:                 log.info(\"Ignoring {} {} which contains metadata that has already been written to ZK.\", metadataType, provenance);",
          "753:             completionHandler.accept(null);",
          "754:         }",
          "756:         private Map<String, String> getScramCredentialStringsForUser(String userName) {",
          "757:             Map<String, String> userScramCredentialStrings = new HashMap<String, String>();",
          "758:             if (image.scram() != null) {",
          "759:                 image.scram().mechanisms().forEach((scramMechanism, scramMechanismMap) -> {",
          "760:                     ScramCredentialData scramCredentialData = scramMechanismMap.get(userName);",
          "761:                     if (scramCredentialData != null) {",
          "762:                         userScramCredentialStrings.put(scramMechanism.mechanismName(),",
          "763:                             ScramCredentialUtils.credentialToString(",
          "764:                                 scramCredentialData.toCredential(scramMechanism)));",
          "765:                     }",
          "766:                 });",
          "768:             return userScramCredentialStrings;",
          "769:         }",
          "771:         private void addStandardAclToMap(Map<ResourcePattern, List<AccessControlEntry>> aclMap, StandardAcl acl) {",
          "772:             ResourcePattern resource = new ResourcePattern(acl.resourceType(), acl.resourceName(), acl.patternType());",
          "773:             aclMap.computeIfAbsent(resource, __ -> new ArrayList<>()).add(",
          "774:                 new AccessControlEntry(acl.principal(), acl.host(), acl.operation(), acl.permissionType())",
          "775:             );",
          "",
          "[Added Lines]",
          "636:             if (image.highestOffsetAndEpoch().compareTo(migrationLeadershipState.offsetAndEpoch()) < 0) {",
          "637:                 log.info(\"Ignoring {} {} which contains metadata that has already been written to ZK.\", metadataType, provenance);",
          "638:                 completionHandler.accept(null);",
          "639:             }",
          "641:             if (isSnapshot) {",
          "642:                 zkMetadataWriter.handleSnapshot(image);",
          "644:                 zkMetadataWriter.handleDelta(prevImage, image, delta);",
          "649:             if (delta.topicsDelta() != null || delta.clusterDelta() != null) {",
          "650:                 log.trace(\"Sending RPCs to brokers for metadata {}.\", metadataType);",
          "651:                 propagator.sendRPCsToBrokersFromMetadataDelta(delta, image,",
          "652:                         migrationLeadershipState.zkControllerEpoch());",
          "653:             } else {",
          "654:                 log.trace(\"Not sending RPCs to brokers for metadata {} since no relevant metadata has changed\", metadataType);",
          "657:             completionHandler.accept(null);",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationOperation.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationOperation.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationOperation.java -> metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationOperation.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.metadata.migration;",
          "20: @FunctionalInterface",
          "21: public interface KRaftMigrationOperation {",
          "22:     ZkMigrationLeadershipState apply(ZkMigrationLeadershipState migrationState);",
          "23: }",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java -> metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.metadata.migration;",
          "20: import org.apache.kafka.clients.admin.ScramMechanism;",
          "21: import org.apache.kafka.common.TopicIdPartition;",
          "22: import org.apache.kafka.common.Uuid;",
          "23: import org.apache.kafka.common.acl.AccessControlEntry;",
          "24: import org.apache.kafka.common.config.ConfigResource;",
          "25: import org.apache.kafka.common.metadata.ClientQuotaRecord;",
          "26: import org.apache.kafka.common.quota.ClientQuotaEntity;",
          "27: import org.apache.kafka.common.resource.ResourcePattern;",
          "28: import org.apache.kafka.common.security.scram.ScramCredential;",
          "29: import org.apache.kafka.common.security.scram.internals.ScramCredentialUtils;",
          "30: import org.apache.kafka.image.AclsDelta;",
          "31: import org.apache.kafka.image.AclsImage;",
          "32: import org.apache.kafka.image.ClientQuotaImage;",
          "33: import org.apache.kafka.image.ClientQuotasImage;",
          "34: import org.apache.kafka.image.ConfigurationsDelta;",
          "35: import org.apache.kafka.image.ConfigurationsImage;",
          "36: import org.apache.kafka.image.MetadataDelta;",
          "37: import org.apache.kafka.image.MetadataImage;",
          "38: import org.apache.kafka.image.ScramImage;",
          "39: import org.apache.kafka.image.TopicImage;",
          "40: import org.apache.kafka.image.TopicsDelta;",
          "41: import org.apache.kafka.image.TopicsImage;",
          "42: import org.apache.kafka.metadata.PartitionRegistration;",
          "43: import org.apache.kafka.metadata.ScramCredentialData;",
          "44: import org.apache.kafka.metadata.authorizer.StandardAcl;",
          "46: import java.util.ArrayList;",
          "47: import java.util.Collections;",
          "48: import java.util.EnumSet;",
          "49: import java.util.HashMap;",
          "50: import java.util.HashSet;",
          "51: import java.util.List;",
          "52: import java.util.Map;",
          "53: import java.util.Optional;",
          "54: import java.util.Set;",
          "55: import java.util.function.BiConsumer;",
          "56: import java.util.function.Function;",
          "57: import java.util.stream.Collectors;",
          "59: public class KRaftMigrationZkWriter {",
          "60:     private final MigrationClient migrationClient;",
          "61:     private final BiConsumer<String, KRaftMigrationOperation> operationConsumer;",
          "63:     public KRaftMigrationZkWriter(",
          "64:         MigrationClient migrationClient,",
          "65:         BiConsumer<String, KRaftMigrationOperation>  operationConsumer",
          "66:     ) {",
          "67:         this.migrationClient = migrationClient;",
          "68:         this.operationConsumer = operationConsumer;",
          "69:     }",
          "71:     public void handleSnapshot(MetadataImage image) {",
          "72:         handleTopicsSnapshot(image.topics());",
          "73:         handleConfigsSnapshot(image.configs());",
          "74:         handleClientQuotasSnapshot(image.clientQuotas(), image.scram());",
          "75:         operationConsumer.accept(\"Setting next producer ID\", migrationState ->",
          "76:             migrationClient.writeProducerId(image.producerIds().highestSeenProducerId(), migrationState));",
          "77:         handleAclsSnapshot(image.acls());",
          "78:     }",
          "80:     public void handleDelta(MetadataImage previousImage, MetadataImage image, MetadataDelta delta) {",
          "81:         if (delta.topicsDelta() != null) {",
          "82:             handleTopicsDelta(previousImage.topics().topicIdToNameView()::get, delta.topicsDelta());",
          "83:         }",
          "84:         if (delta.configsDelta() != null) {",
          "85:             handleConfigsDelta(image.configs(), delta.configsDelta());",
          "86:         }",
          "87:         if (delta.clientQuotasDelta() != null) {",
          "88:             handleClientQuotasDelta(image, delta);",
          "89:         }",
          "90:         if (delta.producerIdsDelta() != null) {",
          "91:             operationConsumer.accept(\"Updating next producer ID\", migrationState ->",
          "92:                 migrationClient.writeProducerId(delta.producerIdsDelta().nextProducerId(), migrationState));",
          "93:         }",
          "94:         if (delta.aclsDelta() != null) {",
          "95:             handleAclsDelta(image.acls(), delta.aclsDelta());",
          "96:         }",
          "97:     }",
          "103:     void handleTopicsSnapshot(TopicsImage topicsImage) {",
          "104:         Map<Uuid, String> deletedTopics = new HashMap<>();",
          "105:         Set<Uuid> createdTopics = new HashSet<>(topicsImage.topicsById().keySet());",
          "106:         Map<Uuid, Map<Integer, PartitionRegistration>> changedPartitions = new HashMap<>();",
          "108:         migrationClient.topicClient().iterateTopics(",
          "109:             EnumSet.of(",
          "110:                 TopicMigrationClient.TopicVisitorInterest.TOPICS,",
          "111:                 TopicMigrationClient.TopicVisitorInterest.PARTITIONS),",
          "112:             new TopicMigrationClient.TopicVisitor() {",
          "113:                 @Override",
          "114:                 public void visitTopic(String topicName, Uuid topicId, Map<Integer, List<Integer>> assignments) {",
          "115:                     TopicImage topic = topicsImage.getTopic(topicId);",
          "116:                     if (topic == null) {",
          "118:                         deletedTopics.put(topicId, topicName);",
          "119:                     } else {",
          "120:                         createdTopics.remove(topicId);",
          "121:                     }",
          "122:                 }",
          "124:                 @Override",
          "125:                 public void visitPartition(TopicIdPartition topicIdPartition, PartitionRegistration partitionRegistration) {",
          "126:                     TopicImage topic = topicsImage.getTopic(topicIdPartition.topicId());",
          "127:                     if (topic == null) {",
          "128:                         return; // topic deleted in KRaft",
          "129:                     }",
          "132:                     PartitionRegistration kraftPartition = topic.partitions().get(topicIdPartition.partition());",
          "133:                     if (!kraftPartition.equals(partitionRegistration)) {",
          "134:                         changedPartitions.computeIfAbsent(topicIdPartition.topicId(), __ -> new HashMap<>())",
          "135:                             .put(topicIdPartition.partition(), kraftPartition);",
          "136:                     }",
          "137:                 }",
          "138:             });",
          "140:         createdTopics.forEach(topicId -> {",
          "141:             TopicImage topic = topicsImage.getTopic(topicId);",
          "142:             operationConsumer.accept(",
          "143:                 \"Create Topic \" + topic.name() + \", ID \" + topicId,",
          "144:                 migrationState -> migrationClient.topicClient().createTopic(topic.name(), topicId, topic.partitions(), migrationState)",
          "145:             );",
          "146:         });",
          "148:         deletedTopics.forEach((topicId, topicName) -> {",
          "149:             operationConsumer.accept(",
          "150:                 \"Delete Topic \" + topicName + \", ID \" + topicId,",
          "151:                 migrationState -> migrationClient.topicClient().deleteTopic(topicName, migrationState)",
          "152:             );",
          "153:             ConfigResource resource = new ConfigResource(ConfigResource.Type.TOPIC, topicName);",
          "154:             operationConsumer.accept(",
          "155:                 \"Updating Configs for Topic \" + topicName + \", ID \" + topicId,",
          "156:                 migrationState -> migrationClient.configClient().deleteConfigs(resource, migrationState)",
          "157:             );",
          "158:         });",
          "160:         changedPartitions.forEach((topicId, paritionMap) -> {",
          "161:             TopicImage topic = topicsImage.getTopic(topicId);",
          "162:             operationConsumer.accept(",
          "163:                 \"Updating Partitions for Topic \" + topic.name() + \", ID \" + topicId,",
          "164:                 migrationState -> migrationClient.topicClient().updateTopicPartitions(",
          "165:                     Collections.singletonMap(topic.name(), paritionMap),",
          "166:                     migrationState));",
          "167:         });",
          "168:     }",
          "170:     void handleTopicsDelta(Function<Uuid, String> deletedTopicNameResolver, TopicsDelta topicsDelta) {",
          "171:         topicsDelta.deletedTopicIds().forEach(topicId -> {",
          "172:             String name = deletedTopicNameResolver.apply(topicId);",
          "173:             operationConsumer.accept(\"Deleting topic \" + name + \", ID \" + topicId,",
          "174:                 migrationState -> migrationClient.topicClient().deleteTopic(name, migrationState));",
          "175:         });",
          "177:         topicsDelta.changedTopics().forEach((topicId, topicDelta) -> {",
          "178:             if (topicsDelta.createdTopicIds().contains(topicId)) {",
          "179:                 operationConsumer.accept(",
          "180:                     \"Create Topic \" + topicDelta.name() + \", ID \" + topicId,",
          "181:                     migrationState -> migrationClient.topicClient().createTopic(",
          "182:                         topicDelta.name(),",
          "183:                         topicId,",
          "184:                         topicDelta.partitionChanges(),",
          "185:                         migrationState));",
          "186:             } else {",
          "187:                 operationConsumer.accept(",
          "188:                     \"Updating Partitions for Topic \" + topicDelta.name() + \", ID \" + topicId,",
          "189:                     migrationState -> migrationClient.topicClient().updateTopicPartitions(",
          "190:                         Collections.singletonMap(topicDelta.name(), topicDelta.partitionChanges()),",
          "191:                         migrationState));",
          "192:             }",
          "193:         });",
          "194:     }",
          "196:     void handleConfigsSnapshot(ConfigurationsImage configsImage) {",
          "197:         Set<ConfigResource> brokersToUpdate = new HashSet<>();",
          "198:         migrationClient.configClient().iterateBrokerConfigs((broker, configs) -> {",
          "199:             ConfigResource brokerResource = new ConfigResource(ConfigResource.Type.BROKER, broker);",
          "200:             Map<String, String> kraftProps = configsImage.configMapForResource(brokerResource);",
          "201:             if (!kraftProps.equals(configs)) {",
          "202:                 brokersToUpdate.add(brokerResource);",
          "203:             }",
          "204:         });",
          "206:         brokersToUpdate.forEach(brokerResource -> {",
          "207:             Map<String, String> props = configsImage.configMapForResource(brokerResource);",
          "208:             if (props.isEmpty()) {",
          "209:                 operationConsumer.accept(\"Delete configs for broker \" + brokerResource.name(), migrationState ->",
          "210:                     migrationClient.configClient().deleteConfigs(brokerResource, migrationState));",
          "211:             } else {",
          "212:                 operationConsumer.accept(\"Update configs for broker \" + brokerResource.name(), migrationState ->",
          "213:                     migrationClient.configClient().writeConfigs(brokerResource, props, migrationState));",
          "214:             }",
          "215:         });",
          "216:     }",
          "218:     private Map<String, String> getScramCredentialStringsForUser(ScramImage image, String userName) {",
          "219:         Map<String, String> userScramCredentialStrings = new HashMap<>();",
          "220:         if (image != null) {",
          "221:             image.mechanisms().forEach((scramMechanism, scramMechanismMap) -> {",
          "222:                 ScramCredentialData scramCredentialData = scramMechanismMap.get(userName);",
          "223:                 if (scramCredentialData != null) {",
          "224:                     userScramCredentialStrings.put(scramMechanism.mechanismName(),",
          "225:                         ScramCredentialUtils.credentialToString(scramCredentialData.toCredential(scramMechanism)));",
          "226:                 }",
          "227:             });",
          "228:         }",
          "229:         return userScramCredentialStrings;",
          "230:     }",
          "232:     void handleClientQuotasSnapshot(ClientQuotasImage clientQuotasImage, ScramImage scramImage) {",
          "233:         Set<ClientQuotaEntity> changedNonUserEntities = new HashSet<>();",
          "234:         Set<String> changedUsers = new HashSet<>();",
          "235:         migrationClient.configClient().iterateClientQuotas(new ConfigMigrationClient.ClientQuotaVisitor() {",
          "236:             @Override",
          "237:             public void visitClientQuota(List<ClientQuotaRecord.EntityData> entityDataList, Map<String, Double> quotas) {",
          "238:                 Map<String, String> entityMap = new HashMap<>(2);",
          "239:                 entityDataList.forEach(entityData -> entityMap.put(entityData.entityType(), entityData.entityName()));",
          "240:                 ClientQuotaEntity entity = new ClientQuotaEntity(entityMap);",
          "241:                 if (!clientQuotasImage.entities().getOrDefault(entity, ClientQuotaImage.EMPTY).quotaMap().equals(quotas)) {",
          "242:                     if (entity.entries().containsKey(ClientQuotaEntity.USER) &&",
          "243:                         !entity.entries().containsKey(ClientQuotaEntity.CLIENT_ID)) {",
          "245:                         changedUsers.add(entityMap.get(ClientQuotaEntity.USER));",
          "246:                     } else {",
          "247:                         changedNonUserEntities.add(entity);",
          "248:                     }",
          "249:                 }",
          "250:             }",
          "252:             @Override",
          "253:             public void visitScramCredential(String userName, ScramMechanism scramMechanism, ScramCredential scramCredential) {",
          "255:                 ScramCredentialData data = scramImage.mechanisms().getOrDefault(scramMechanism, Collections.emptyMap()).get(userName);",
          "256:                 if (data == null || !data.toCredential(scramMechanism).equals(scramCredential)) {",
          "257:                     changedUsers.add(userName);",
          "258:                 }",
          "259:             }",
          "260:         });",
          "262:         changedNonUserEntities.forEach(entity -> {",
          "263:             Map<String, Double> quotaMap = clientQuotasImage.entities().get(entity).quotaMap();",
          "264:             operationConsumer.accept(\"Update client quotas for \" + entity, migrationState ->",
          "265:                 migrationClient.configClient().writeClientQuotas(entity.entries(), quotaMap, Collections.emptyMap(), migrationState));",
          "266:         });",
          "268:         changedUsers.forEach(userName -> {",
          "269:             ClientQuotaEntity entity = new ClientQuotaEntity(Collections.singletonMap(ClientQuotaEntity.USER, userName));",
          "270:             Map<String, Double> quotaMap = clientQuotasImage.entities().get(entity).quotaMap();",
          "271:             Map<String, String> scramMap = getScramCredentialStringsForUser(scramImage, userName);",
          "272:             operationConsumer.accept(\"Update scram credentials for \" + userName, migrationState ->",
          "273:                 migrationClient.configClient().writeClientQuotas(entity.entries(), quotaMap, scramMap, migrationState));",
          "274:         });",
          "277:     }",
          "279:     void handleConfigsDelta(ConfigurationsImage configsImage, ConfigurationsDelta configsDelta) {",
          "280:         Set<ConfigResource> updatedResources = configsDelta.changes().keySet();",
          "281:         updatedResources.forEach(configResource -> {",
          "282:             Map<String, String> props = configsImage.configMapForResource(configResource);",
          "283:             if (props.isEmpty()) {",
          "284:                 operationConsumer.accept(\"Delete configs for \" + configResource, migrationState ->",
          "285:                     migrationClient.configClient().deleteConfigs(configResource, migrationState));",
          "286:             } else {",
          "287:                 operationConsumer.accept(\"Update configs for \" + configResource, migrationState ->",
          "288:                     migrationClient.configClient().writeConfigs(configResource, props, migrationState));",
          "289:             }",
          "290:         });",
          "291:     }",
          "293:     void handleClientQuotasDelta(MetadataImage metadataImage, MetadataDelta metadataDelta) {",
          "294:         if ((metadataDelta.clientQuotasDelta() != null) || (metadataDelta.scramDelta() != null)) {",
          "296:             HashSet<String> users = new HashSet<>();",
          "299:             if (metadataDelta.scramDelta() != null) {",
          "300:                 metadataDelta.scramDelta().changes().forEach((scramMechanism, changes) -> {",
          "301:                     changes.forEach((userName, changeOpt) -> users.add(userName));",
          "302:                 });",
          "303:             }",
          "307:             if (metadataDelta.clientQuotasDelta() != null) {",
          "308:                 metadataDelta.clientQuotasDelta().changes().forEach((clientQuotaEntity, clientQuotaDelta) -> {",
          "309:                     if ((clientQuotaEntity.entries().containsKey(ClientQuotaEntity.USER)) &&",
          "310:                             (!clientQuotaEntity.entries().containsKey(ClientQuotaEntity.CLIENT_ID))) {",
          "311:                         String userName = clientQuotaEntity.entries().get(ClientQuotaEntity.USER);",
          "313:                         users.add(userName);",
          "314:                     } else {",
          "315:                         Map<String, Double> quotaMap = metadataImage.clientQuotas().entities().get(clientQuotaEntity).quotaMap();",
          "316:                         operationConsumer.accept(\"Updating client quota \" + clientQuotaEntity, migrationState ->",
          "317:                             migrationClient.configClient().writeClientQuotas(clientQuotaEntity.entries(), quotaMap, Collections.emptyMap(), migrationState));",
          "318:                     }",
          "319:                 });",
          "320:             }",
          "323:             users.forEach(userName -> {",
          "324:                 Map<String, String> userScramMap = getScramCredentialStringsForUser(metadataImage.scram(), userName);",
          "325:                 ClientQuotaEntity clientQuotaEntity = new ClientQuotaEntity(Collections.singletonMap(ClientQuotaEntity.USER, userName));",
          "326:                 if (metadataImage.clientQuotas() == null) {",
          "327:                     operationConsumer.accept(\"Updating client quota \" + clientQuotaEntity, migrationState ->",
          "328:                         migrationClient.configClient().writeClientQuotas(clientQuotaEntity.entries(), Collections.emptyMap(), userScramMap, migrationState));",
          "329:                 } else {",
          "330:                     Map<String, Double> quotaMap = metadataImage.clientQuotas().entities().get(clientQuotaEntity).quotaMap();",
          "331:                     operationConsumer.accept(\"Updating client quota \" + clientQuotaEntity, migrationState ->",
          "332:                         migrationClient.configClient().writeClientQuotas(clientQuotaEntity.entries(), quotaMap, userScramMap, migrationState));",
          "333:                 }",
          "334:             });",
          "335:         }",
          "336:     }",
          "338:     private ResourcePattern resourcePatternFromAcl(StandardAcl acl) {",
          "339:         return new ResourcePattern(acl.resourceType(), acl.resourceName(), acl.patternType());",
          "340:     }",
          "342:     void handleAclsSnapshot(AclsImage image) {",
          "344:         Map<ResourcePattern, Set<AccessControlEntry>> allAclsInSnapshot = new HashMap<>();",
          "346:         image.acls().values().forEach(standardAcl -> {",
          "347:             ResourcePattern resourcePattern = resourcePatternFromAcl(standardAcl);",
          "348:             allAclsInSnapshot.computeIfAbsent(resourcePattern, __ -> new HashSet<>()).add(",
          "349:                 new AccessControlEntry(standardAcl.principal(), standardAcl.host(), standardAcl.operation(), standardAcl.permissionType())",
          "350:             );",
          "351:         });",
          "353:         Set<ResourcePattern> resourcesToDelete = new HashSet<>();",
          "354:         Map<ResourcePattern, Set<AccessControlEntry>> changedResources = new HashMap<>();",
          "355:         migrationClient.aclClient().iterateAcls((resourcePattern, accessControlEntries) -> {",
          "356:             if (!allAclsInSnapshot.containsKey(resourcePattern)) {",
          "357:                 resourcesToDelete.add(resourcePattern);",
          "358:             } else {",
          "359:                 Set<AccessControlEntry> snapshotEntries = allAclsInSnapshot.get(resourcePattern);",
          "360:                 if (!snapshotEntries.equals(accessControlEntries)) {",
          "361:                     changedResources.put(resourcePattern, snapshotEntries);",
          "362:                 }",
          "363:             }",
          "364:         });",
          "366:         resourcesToDelete.forEach(deletedResource -> {",
          "367:             String name = \"Deleting resource \" + deletedResource + \" which has no ACLs in snapshot\";",
          "368:             operationConsumer.accept(name, migrationState ->",
          "369:                 migrationClient.aclClient().deleteResource(deletedResource, migrationState));",
          "370:         });",
          "372:         changedResources.forEach((resourcePattern, accessControlEntries) -> {",
          "373:             String name = \"Writing \" + accessControlEntries.size() + \" for resource \" + resourcePattern;",
          "374:             operationConsumer.accept(name, migrationState ->",
          "375:                 migrationClient.aclClient().writeResourceAcls(resourcePattern, accessControlEntries, migrationState));",
          "376:         });",
          "377:     }",
          "379:     void handleAclsDelta(AclsImage image, AclsDelta delta) {",
          "381:         Set<ResourcePattern> resourcesWithChangedAcls = delta.changes().values()",
          "382:             .stream()",
          "383:             .filter(Optional::isPresent)",
          "384:             .map(Optional::get)",
          "385:             .map(this::resourcePatternFromAcl)",
          "386:             .collect(Collectors.toSet());",
          "388:         Set<ResourcePattern> resourcesWithDeletedAcls = delta.deleted()",
          "389:             .stream()",
          "390:             .map(this::resourcePatternFromAcl)",
          "391:             .collect(Collectors.toSet());",
          "394:         Map<ResourcePattern, List<AccessControlEntry>> aclsToWrite = new HashMap<>();",
          "395:         image.acls().forEach((uuid, standardAcl) -> {",
          "396:             ResourcePattern resourcePattern = resourcePatternFromAcl(standardAcl);",
          "397:             boolean removed = resourcesWithDeletedAcls.remove(resourcePattern);",
          "399:             if (resourcesWithChangedAcls.contains(resourcePattern) || removed) {",
          "400:                 aclsToWrite.computeIfAbsent(resourcePattern, __ -> new ArrayList<>()).add(",
          "401:                     new AccessControlEntry(standardAcl.principal(), standardAcl.host(), standardAcl.operation(), standardAcl.permissionType())",
          "402:                 );",
          "403:             }",
          "404:         });",
          "406:         resourcesWithDeletedAcls.forEach(deletedResource -> {",
          "407:             String name = \"Deleting resource \" + deletedResource + \" which has no more ACLs\";",
          "408:             operationConsumer.accept(name, migrationState ->",
          "409:                 migrationClient.aclClient().deleteResource(deletedResource, migrationState));",
          "410:         });",
          "412:         aclsToWrite.forEach((resourcePattern, accessControlEntries) -> {",
          "413:             String name = \"Writing \" + accessControlEntries.size() + \" for resource \" + resourcePattern;",
          "414:             operationConsumer.accept(name, migrationState ->",
          "415:                 migrationClient.aclClient().writeResourceAcls(resourcePattern, accessControlEntries, migrationState));",
          "416:         });",
          "417:     }",
          "418: }",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/migration/MigrationClient.java||metadata/src/main/java/org/apache/kafka/metadata/migration/MigrationClient.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/migration/MigrationClient.java -> metadata/src/main/java/org/apache/kafka/metadata/migration/MigrationClient.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: package org.apache.kafka.metadata.migration;",
          "24: import org.apache.kafka.server.common.ApiMessageAndVersion;",
          "26: import java.util.List;",
          "28: import java.util.Set;",
          "30: import java.util.function.Consumer;",
          "",
          "[Removed Lines]",
          "19: import org.apache.kafka.common.Uuid;",
          "20: import org.apache.kafka.common.acl.AccessControlEntry;",
          "21: import org.apache.kafka.common.config.ConfigResource;",
          "22: import org.apache.kafka.common.resource.ResourcePattern;",
          "23: import org.apache.kafka.metadata.PartitionRegistration;",
          "27: import java.util.Map;",
          "29: import java.util.function.BiConsumer;",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "76:     ZkMigrationLeadershipState releaseControllerLeadership(ZkMigrationLeadershipState state);",
          "103:     ZkMigrationLeadershipState writeProducerId(",
          "104:         long nextProducerId,",
          "105:         ZkMigrationLeadershipState state",
          "106:     );",
          "122:     void readAllMetadata(Consumer<List<ApiMessageAndVersion>> batchConsumer, Consumer<Integer> brokerIdConsumer);",
          "124:     Set<Integer> readBrokerIds();",
          "127: }",
          "",
          "[Removed Lines]",
          "78:     ZkMigrationLeadershipState createTopic(",
          "79:         String topicName,",
          "80:         Uuid topicId,",
          "81:         Map<Integer, PartitionRegistration> topicPartitions,",
          "82:         ZkMigrationLeadershipState state",
          "83:     );",
          "85:     ZkMigrationLeadershipState updateTopicPartitions(",
          "86:         Map<String, Map<Integer, PartitionRegistration>> topicPartitions,",
          "87:         ZkMigrationLeadershipState state",
          "88:     );",
          "90:     ZkMigrationLeadershipState writeConfigs(",
          "91:         ConfigResource configResource,",
          "92:         Map<String, String> configMap,",
          "93:         ZkMigrationLeadershipState state",
          "94:     );",
          "96:     ZkMigrationLeadershipState writeClientQuotas(",
          "97:         Map<String, String> clientQuotaEntity,",
          "98:         Map<String, Double> quotas,",
          "99:         Map<String, String> scram,",
          "100:         ZkMigrationLeadershipState state",
          "101:     );",
          "108:     ZkMigrationLeadershipState removeDeletedAcls(",
          "109:         ResourcePattern resourcePattern,",
          "110:         List<AccessControlEntry> deletedAcls,",
          "111:         ZkMigrationLeadershipState state",
          "112:     );",
          "114:     ZkMigrationLeadershipState writeAddedAcls(",
          "115:         ResourcePattern resourcePattern,",
          "116:         List<AccessControlEntry> addedAcls,",
          "117:         ZkMigrationLeadershipState state",
          "118:     );",
          "120:     void iterateAcls(BiConsumer<ResourcePattern, Set<AccessControlEntry>> aclConsumer);",
          "126:     Set<Integer> readBrokerIdsFromTopicAssignments();",
          "",
          "[Added Lines]",
          "71:     TopicMigrationClient topicClient();",
          "73:     ConfigMigrationClient configClient();",
          "75:     AclMigrationClient aclClient();",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/migration/TopicMigrationClient.java||metadata/src/main/java/org/apache/kafka/metadata/migration/TopicMigrationClient.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/migration/TopicMigrationClient.java -> metadata/src/main/java/org/apache/kafka/metadata/migration/TopicMigrationClient.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.metadata.migration;",
          "20: import org.apache.kafka.common.TopicIdPartition;",
          "21: import org.apache.kafka.common.Uuid;",
          "22: import org.apache.kafka.metadata.PartitionRegistration;",
          "24: import java.util.EnumSet;",
          "25: import java.util.List;",
          "26: import java.util.Map;",
          "27: import java.util.Properties;",
          "29: public interface TopicMigrationClient {",
          "31:     enum TopicVisitorInterest {",
          "32:         TOPICS,",
          "33:         PARTITIONS,",
          "34:         CONFIGS",
          "35:     }",
          "37:     interface TopicVisitor {",
          "38:         void visitTopic(String topicName, Uuid topicId, Map<Integer, List<Integer>> assignments);",
          "39:         default void visitPartition(TopicIdPartition topicIdPartition, PartitionRegistration partitionRegistration) {",
          "41:         }",
          "42:         default void visitConfigs(String topicName, Properties topicProps) {",
          "44:         }",
          "45:     }",
          "47:     void iterateTopics(EnumSet<TopicVisitorInterest> interests, TopicVisitor visitor);",
          "49:     ZkMigrationLeadershipState deleteTopic(",
          "50:         String topicName,",
          "51:         ZkMigrationLeadershipState state",
          "52:     );",
          "54:     ZkMigrationLeadershipState createTopic(",
          "55:         String topicName,",
          "56:         Uuid topicId,",
          "57:         Map<Integer, PartitionRegistration> topicPartitions,",
          "58:         ZkMigrationLeadershipState state",
          "59:     );",
          "61:     ZkMigrationLeadershipState updateTopicPartitions(",
          "62:         Map<String, Map<Integer, PartitionRegistration>> topicPartitions,",
          "63:         ZkMigrationLeadershipState state",
          "64:     );",
          "65: }",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/migration/ZkMigrationLeadershipState.java||metadata/src/main/java/org/apache/kafka/metadata/migration/ZkMigrationLeadershipState.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/migration/ZkMigrationLeadershipState.java -> metadata/src/main/java/org/apache/kafka/metadata/migration/ZkMigrationLeadershipState.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "138:         return new OffsetAndEpoch(kraftMetadataOffset, kraftMetadataEpoch);",
          "139:     }",
          "141:     @Override",
          "142:     public String toString() {",
          "143:         return \"ZkMigrationLeadershipState{\" +",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "141:     public boolean loggableChangeSinceState(ZkMigrationLeadershipState other) {",
          "142:         if (other == null) {",
          "143:             return false;",
          "144:         }",
          "145:         if (this.equals(other)) {",
          "146:             return false;",
          "147:         } else {",
          "149:             return",
          "150:                 this.kraftControllerId != other.kraftControllerId ||",
          "151:                 this.kraftControllerEpoch != other.kraftControllerEpoch ||",
          "152:                 (!other.zkMigrationComplete() && this.zkMigrationComplete());",
          "153:         }",
          "154:     }",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "176:             kraftMetadataEpoch,",
          "177:             lastUpdatedTimeMs,",
          "178:             migrationZkVersion,",
          "181:     }",
          "182: }",
          "",
          "[Removed Lines]",
          "179:                 zkControllerEpoch,",
          "180:                 zkControllerEpochZkVersion);",
          "",
          "[Added Lines]",
          "194:             zkControllerEpoch,",
          "195:             zkControllerEpochZkVersion);",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/image/TopicsImageTest.java||metadata/src/test/java/org/apache/kafka/image/TopicsImageTest.java": [
          "File: metadata/src/test/java/org/apache/kafka/image/TopicsImageTest.java -> metadata/src/test/java/org/apache/kafka/image/TopicsImageTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "57: @Timeout(value = 40)",
          "58: public class TopicsImageTest {",
          "63:     static final TopicsDelta DELTA1;",
          "",
          "[Removed Lines]",
          "59:     static final TopicsImage IMAGE1;",
          "61:     static final List<ApiMessageAndVersion> DELTA1_RECORDS;",
          "",
          "[Added Lines]",
          "59:     public static final TopicsImage IMAGE1;",
          "61:     public static final List<ApiMessageAndVersion> DELTA1_RECORDS;",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingAclMigrationClient.java||metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingAclMigrationClient.java": [
          "File: metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingAclMigrationClient.java -> metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingAclMigrationClient.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.metadata.migration;",
          "20: import org.apache.kafka.common.acl.AccessControlEntry;",
          "21: import org.apache.kafka.common.resource.ResourcePattern;",
          "23: import java.util.ArrayList;",
          "24: import java.util.Collection;",
          "25: import java.util.LinkedHashMap;",
          "26: import java.util.List;",
          "27: import java.util.Set;",
          "28: import java.util.function.BiConsumer;",
          "30: public class CapturingAclMigrationClient implements AclMigrationClient {",
          "32:     public List<ResourcePattern> deletedResources = new ArrayList<>();",
          "33:     public LinkedHashMap<ResourcePattern, Collection<AccessControlEntry>> updatedResources = new LinkedHashMap<>();",
          "35:     public void reset() {",
          "36:         deletedResources.clear();",
          "37:         updatedResources.clear();",
          "38:     }",
          "40:     @Override",
          "41:     public ZkMigrationLeadershipState deleteResource(ResourcePattern resourcePattern, ZkMigrationLeadershipState state) {",
          "42:         deletedResources.add(resourcePattern);",
          "43:         return state;",
          "44:     }",
          "46:     @Override",
          "47:     public ZkMigrationLeadershipState writeResourceAcls(ResourcePattern resourcePattern, Collection<AccessControlEntry> aclsToWrite, ZkMigrationLeadershipState state) {",
          "48:         updatedResources.put(resourcePattern, aclsToWrite);",
          "49:         return state;",
          "50:     }",
          "52:     @Override",
          "53:     public void iterateAcls(BiConsumer<ResourcePattern, Set<AccessControlEntry>> aclConsumer) {",
          "55:     }",
          "56: }",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingConfigMigrationClient.java||metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingConfigMigrationClient.java": [
          "File: metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingConfigMigrationClient.java -> metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingConfigMigrationClient.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.metadata.migration;",
          "20: import org.apache.kafka.common.config.ConfigResource;",
          "22: import java.util.ArrayList;",
          "23: import java.util.LinkedHashMap;",
          "24: import java.util.List;",
          "25: import java.util.Map;",
          "26: import java.util.function.BiConsumer;",
          "28: public class CapturingConfigMigrationClient implements ConfigMigrationClient {",
          "29:     public List<ConfigResource> deletedResources = new ArrayList<>();",
          "30:     public LinkedHashMap<ConfigResource, Map<String, String>> writtenConfigs = new LinkedHashMap<>();",
          "32:     public void reset() {",
          "33:         deletedResources.clear();",
          "34:         writtenConfigs.clear();",
          "35:     }",
          "37:     @Override",
          "38:     public void iterateClientQuotas(ClientQuotaVisitor visitor) {",
          "40:     }",
          "42:     @Override",
          "43:     public void iterateBrokerConfigs(BiConsumer<String, Map<String, String>> configConsumer) {",
          "45:     }",
          "47:     @Override",
          "48:     public ZkMigrationLeadershipState writeConfigs(ConfigResource configResource, Map<String, String> configMap, ZkMigrationLeadershipState state) {",
          "49:         writtenConfigs.put(configResource, configMap);",
          "50:         return state;",
          "51:     }",
          "53:     @Override",
          "54:     public ZkMigrationLeadershipState writeClientQuotas(Map<String, String> clientQuotaEntity, Map<String, Double> quotas, Map<String, String> scram, ZkMigrationLeadershipState state) {",
          "55:         return null;",
          "56:     }",
          "59:     @Override",
          "60:     public ZkMigrationLeadershipState deleteConfigs(ConfigResource configResource, ZkMigrationLeadershipState state) {",
          "61:         deletedResources.add(configResource);",
          "62:         return state;",
          "63:     }",
          "65: }",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingMigrationClient.java||metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingMigrationClient.java": [
          "File: metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingMigrationClient.java -> metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingMigrationClient.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.metadata.migration;",
          "20: import org.apache.kafka.server.common.ApiMessageAndVersion;",
          "22: import java.util.Collections;",
          "23: import java.util.List;",
          "24: import java.util.Set;",
          "25: import java.util.function.Consumer;",
          "26: import java.util.stream.Collectors;",
          "27: import java.util.stream.IntStream;",
          "29: class CapturingMigrationClient implements MigrationClient {",
          "31:     static Builder newBuilder() {",
          "32:         return new Builder();",
          "33:     }",
          "35:     public static class Builder {",
          "36:         Set<Integer> brokersInZk = Collections.emptySet();",
          "37:         TopicMigrationClient topicMigrationClient = new CapturingTopicMigrationClient();",
          "38:         ConfigMigrationClient configMigrationClient = new CapturingConfigMigrationClient();",
          "39:         AclMigrationClient aclMigrationClient = new CapturingAclMigrationClient();",
          "41:         public Builder setBrokersInZk(int... brokerIds) {",
          "42:             brokersInZk = IntStream.of(brokerIds).boxed().collect(Collectors.toSet());",
          "43:             return this;",
          "44:         }",
          "46:         public Builder setTopicMigrationClient(TopicMigrationClient topicMigrationClient) {",
          "47:             this.topicMigrationClient = topicMigrationClient;",
          "48:             return this;",
          "49:         }",
          "51:         public Builder setConfigMigrationClient(ConfigMigrationClient configMigrationClient) {",
          "52:             this.configMigrationClient = configMigrationClient;",
          "53:             return this;",
          "54:         }",
          "56:         public CapturingMigrationClient build() {",
          "57:             return new CapturingMigrationClient(",
          "58:                 brokersInZk,",
          "59:                 topicMigrationClient,",
          "60:                 configMigrationClient,",
          "61:                 aclMigrationClient",
          "62:             );",
          "63:         }",
          "64:     }",
          "66:     private final Set<Integer> brokerIds;",
          "67:     private final TopicMigrationClient topicMigrationClient;",
          "68:     private final ConfigMigrationClient configMigrationClient;",
          "69:     private final AclMigrationClient aclMigrationClient;",
          "71:     private ZkMigrationLeadershipState state = null;",
          "73:     CapturingMigrationClient(",
          "74:         Set<Integer> brokerIdsInZk,",
          "75:         TopicMigrationClient topicMigrationClient,",
          "76:         ConfigMigrationClient configMigrationClient,",
          "77:         AclMigrationClient aclMigrationClient",
          "78:     ) {",
          "79:         this.brokerIds = brokerIdsInZk;",
          "80:         this.topicMigrationClient = topicMigrationClient;",
          "81:         this.configMigrationClient = configMigrationClient;",
          "82:         this.aclMigrationClient = aclMigrationClient;",
          "83:     }",
          "85:     @Override",
          "86:     public ZkMigrationLeadershipState getOrCreateMigrationRecoveryState(ZkMigrationLeadershipState initialState) {",
          "87:         if (this.state == null) {",
          "88:             this.state = initialState;",
          "89:         }",
          "90:         return this.state;",
          "91:     }",
          "93:     @Override",
          "94:     public ZkMigrationLeadershipState setMigrationRecoveryState(ZkMigrationLeadershipState state) {",
          "95:         this.state = state;",
          "96:         return state;",
          "97:     }",
          "99:     @Override",
          "100:     public ZkMigrationLeadershipState claimControllerLeadership(ZkMigrationLeadershipState state) {",
          "101:         this.state = state;",
          "102:         return state;",
          "103:     }",
          "105:     @Override",
          "106:     public ZkMigrationLeadershipState releaseControllerLeadership(ZkMigrationLeadershipState state) {",
          "107:         this.state = state;",
          "108:         return state;",
          "109:     }",
          "112:     @Override",
          "113:     public TopicMigrationClient topicClient() {",
          "114:         return topicMigrationClient;",
          "115:     }",
          "117:     @Override",
          "118:     public ConfigMigrationClient configClient() {",
          "119:         return configMigrationClient;",
          "120:     }",
          "122:     @Override",
          "123:     public AclMigrationClient aclClient() {",
          "124:         return aclMigrationClient;",
          "125:     }",
          "127:     @Override",
          "128:     public ZkMigrationLeadershipState writeProducerId(",
          "129:         long nextProducerId,",
          "130:         ZkMigrationLeadershipState state",
          "131:     ) {",
          "132:         this.state = state;",
          "133:         return state;",
          "134:     }",
          "136:     @Override",
          "137:     public void readAllMetadata(",
          "138:         Consumer<List<ApiMessageAndVersion>> batchConsumer,",
          "139:         Consumer<Integer> brokerIdConsumer",
          "140:     ) {",
          "142:     }",
          "144:     @Override",
          "145:     public Set<Integer> readBrokerIds() {",
          "146:         return brokerIds;",
          "147:     }",
          "148: }",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingTopicMigrationClient.java||metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingTopicMigrationClient.java": [
          "File: metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingTopicMigrationClient.java -> metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingTopicMigrationClient.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.metadata.migration;",
          "20: import org.apache.kafka.common.Uuid;",
          "21: import org.apache.kafka.metadata.PartitionRegistration;",
          "23: import java.util.ArrayList;",
          "24: import java.util.EnumSet;",
          "25: import java.util.LinkedHashMap;",
          "26: import java.util.List;",
          "27: import java.util.Map;",
          "28: import java.util.Set;",
          "30: public class CapturingTopicMigrationClient implements TopicMigrationClient {",
          "31:     public List<String> deletedTopics = new ArrayList<>();",
          "32:     public List<String> createdTopics = new ArrayList<>();",
          "33:     public LinkedHashMap<String, Set<Integer>> updatedTopicPartitions = new LinkedHashMap<>();",
          "35:     public void reset() {",
          "36:         createdTopics.clear();",
          "37:         updatedTopicPartitions.clear();",
          "38:         deletedTopics.clear();",
          "39:     }",
          "42:     @Override",
          "43:     public void iterateTopics(EnumSet<TopicVisitorInterest> interests, TopicVisitor visitor) {",
          "45:     }",
          "47:     @Override",
          "48:     public ZkMigrationLeadershipState deleteTopic(String topicName, ZkMigrationLeadershipState state) {",
          "49:         deletedTopics.add(topicName);",
          "50:         return state;",
          "51:     }",
          "53:     @Override",
          "54:     public ZkMigrationLeadershipState createTopic(String topicName, Uuid topicId, Map<Integer, PartitionRegistration> topicPartitions, ZkMigrationLeadershipState state) {",
          "55:         createdTopics.add(topicName);",
          "56:         return state;",
          "57:     }",
          "59:     @Override",
          "60:     public ZkMigrationLeadershipState updateTopicPartitions(Map<String, Map<Integer, PartitionRegistration>> topicPartitions, ZkMigrationLeadershipState state) {",
          "61:         topicPartitions.forEach((topicName, partitionMap) ->",
          "62:             updatedTopicPartitions.put(topicName, partitionMap.keySet())",
          "63:         );",
          "64:         return state;",
          "65:     }",
          "66: }",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationDriverTest.java||metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationDriverTest.java": [
          "File: metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationDriverTest.java -> metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationDriverTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: import org.apache.kafka.clients.ApiVersions;",
          "20: import org.apache.kafka.clients.NodeApiVersions;",
          "21: import org.apache.kafka.common.Node;",
          "24: import org.apache.kafka.common.config.ConfigResource;",
          "25: import org.apache.kafka.common.metadata.BrokerRegistrationChangeRecord;",
          "26: import org.apache.kafka.common.metadata.ConfigRecord;",
          "27: import org.apache.kafka.common.metadata.RegisterBrokerRecord;",
          "29: import org.apache.kafka.common.utils.MockTime;",
          "30: import org.apache.kafka.common.utils.Time;",
          "31: import org.apache.kafka.controller.QuorumFeatures;",
          "32: import org.apache.kafka.image.MetadataDelta;",
          "33: import org.apache.kafka.image.MetadataImage;",
          "34: import org.apache.kafka.image.MetadataProvenance;",
          "35: import org.apache.kafka.image.loader.LogDeltaManifest;",
          "36: import org.apache.kafka.metadata.BrokerRegistrationFencingChange;",
          "37: import org.apache.kafka.metadata.BrokerRegistrationInControlledShutdownChange;",
          "39: import org.apache.kafka.raft.LeaderAndEpoch;",
          "40: import org.apache.kafka.raft.OffsetAndEpoch;",
          "41: import org.apache.kafka.server.common.ApiMessageAndVersion;",
          "",
          "[Removed Lines]",
          "22: import org.apache.kafka.common.Uuid;",
          "23: import org.apache.kafka.common.acl.AccessControlEntry;",
          "28: import org.apache.kafka.common.resource.ResourcePattern;",
          "38: import org.apache.kafka.metadata.PartitionRegistration;",
          "",
          "[Added Lines]",
          "22: import org.apache.kafka.common.TopicIdPartition;",
          "23: import org.apache.kafka.common.TopicPartition;",
          "31: import org.apache.kafka.image.AclsImage;",
          "32: import org.apache.kafka.image.ClientQuotasImage;",
          "33: import org.apache.kafka.image.ClusterImage;",
          "34: import org.apache.kafka.image.ConfigurationsImage;",
          "35: import org.apache.kafka.image.FeaturesImage;",
          "39: import org.apache.kafka.image.ProducerIdsImage;",
          "40: import org.apache.kafka.image.ScramImage;",
          "42: import org.apache.kafka.image.loader.SnapshotManifest;",
          "45: import org.apache.kafka.metadata.RecordTestUtils;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "51: import java.util.Arrays;",
          "52: import java.util.Collections;",
          "53: import java.util.HashMap;",
          "54: import java.util.HashSet;",
          "55: import java.util.List;",
          "56: import java.util.Map;",
          "57: import java.util.OptionalInt;",
          "59: import java.util.concurrent.CompletableFuture;",
          "60: import java.util.concurrent.CountDownLatch;",
          "61: import java.util.concurrent.TimeUnit;",
          "63: import java.util.function.Consumer;",
          "65: import static java.util.concurrent.TimeUnit.MILLISECONDS;",
          "66: import static java.util.concurrent.TimeUnit.NANOSECONDS;",
          "",
          "[Removed Lines]",
          "58: import java.util.Set;",
          "62: import java.util.function.BiConsumer;",
          "",
          "[Added Lines]",
          "60: import java.util.EnumSet;",
          "70: import java.util.stream.Collectors;",
          "71: import java.util.stream.IntStream;",
          "73: import static org.apache.kafka.image.TopicsImageTest.DELTA1_RECORDS;",
          "74: import static org.apache.kafka.image.TopicsImageTest.IMAGE1;",
          "75: import static org.junit.jupiter.api.Assertions.assertEquals;",
          "76: import static org.junit.jupiter.api.Assertions.assertTrue;",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "112:         }",
          "113:     }",
          "246:     static class CountingMetadataPropagator implements LegacyPropagator {",
          "248:         public int deltas = 0;",
          "",
          "[Removed Lines]",
          "115:     static class CapturingMigrationClient implements MigrationClient {",
          "117:         private final Set<Integer> brokerIds;",
          "118:         public final Map<ConfigResource, Map<String, String>> capturedConfigs = new HashMap<>();",
          "119:         private ZkMigrationLeadershipState state = null;",
          "121:         public CapturingMigrationClient(Set<Integer> brokerIdsInZk) {",
          "122:             this.brokerIds = brokerIdsInZk;",
          "123:         }",
          "125:         @Override",
          "126:         public ZkMigrationLeadershipState getOrCreateMigrationRecoveryState(ZkMigrationLeadershipState initialState) {",
          "127:             if (state == null) {",
          "128:                 state = initialState;",
          "129:             }",
          "130:             return state;",
          "131:         }",
          "133:         @Override",
          "134:         public ZkMigrationLeadershipState setMigrationRecoveryState(ZkMigrationLeadershipState state) {",
          "135:             this.state = state;",
          "136:             return state;",
          "137:         }",
          "139:         @Override",
          "140:         public ZkMigrationLeadershipState claimControllerLeadership(ZkMigrationLeadershipState state) {",
          "141:             this.state = state;",
          "142:             return state;",
          "143:         }",
          "145:         @Override",
          "146:         public ZkMigrationLeadershipState releaseControllerLeadership(ZkMigrationLeadershipState state) {",
          "147:             this.state = state;",
          "148:             return state;",
          "149:         }",
          "151:         @Override",
          "152:         public ZkMigrationLeadershipState createTopic(",
          "153:             String topicName,",
          "154:             Uuid topicId,",
          "155:             Map<Integer, PartitionRegistration> topicPartitions,",
          "156:             ZkMigrationLeadershipState state",
          "157:         ) {",
          "158:             this.state = state;",
          "159:             return state;",
          "160:         }",
          "162:         @Override",
          "163:         public ZkMigrationLeadershipState updateTopicPartitions(",
          "164:             Map<String, Map<Integer, PartitionRegistration>> topicPartitions,",
          "165:             ZkMigrationLeadershipState state",
          "166:         ) {",
          "167:             this.state = state;",
          "168:             return state;",
          "169:         }",
          "171:         @Override",
          "172:         public ZkMigrationLeadershipState writeConfigs(",
          "173:             ConfigResource configResource,",
          "174:             Map<String, String> configMap,",
          "175:             ZkMigrationLeadershipState state",
          "176:         ) {",
          "177:             capturedConfigs.computeIfAbsent(configResource, __ -> new HashMap<>()).putAll(configMap);",
          "178:             this.state = state;",
          "179:             return state;",
          "180:         }",
          "182:         @Override",
          "183:         public ZkMigrationLeadershipState writeClientQuotas(",
          "184:             Map<String, String> clientQuotaEntity,",
          "185:             Map<String, Double> quotas,",
          "186:             Map<String, String> scram,",
          "187:             ZkMigrationLeadershipState state",
          "188:         ) {",
          "189:             this.state = state;",
          "190:             return state;",
          "191:         }",
          "193:         @Override",
          "194:         public ZkMigrationLeadershipState writeProducerId(",
          "195:             long nextProducerId,",
          "196:             ZkMigrationLeadershipState state",
          "197:         ) {",
          "198:             this.state = state;",
          "199:             return state;",
          "200:         }",
          "202:         @Override",
          "203:         public ZkMigrationLeadershipState removeDeletedAcls(",
          "204:             ResourcePattern resourcePattern,",
          "205:             List<AccessControlEntry> deletedAcls,",
          "206:             ZkMigrationLeadershipState state",
          "207:         ) {",
          "208:             this.state = state;",
          "209:             return state;",
          "210:         }",
          "212:         @Override",
          "213:         public ZkMigrationLeadershipState writeAddedAcls(",
          "214:             ResourcePattern resourcePattern,",
          "215:             List<AccessControlEntry> addedAcls,",
          "216:             ZkMigrationLeadershipState state",
          "217:         ) {",
          "218:             this.state = state;",
          "219:             return state;",
          "220:         }",
          "222:         @Override",
          "223:         public void iterateAcls(BiConsumer<ResourcePattern, Set<AccessControlEntry>> aclConsumer) {",
          "225:         }",
          "227:         @Override",
          "228:         public void readAllMetadata(",
          "229:             Consumer<List<ApiMessageAndVersion>> batchConsumer,",
          "230:             Consumer<Integer> brokerIdConsumer",
          "231:         ) {",
          "233:         }",
          "235:         @Override",
          "236:         public Set<Integer> readBrokerIds() {",
          "237:             return brokerIds;",
          "238:         }",
          "240:         @Override",
          "241:         public Set<Integer> readBrokerIdsFromTopicAssignments() {",
          "242:             return brokerIds;",
          "243:         }",
          "244:     }",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "326:     @Test",
          "327:     public void testOnlySendNeededRPCsToBrokers() throws Exception {",
          "328:         CountingMetadataPropagator metadataPropagator = new CountingMetadataPropagator();",
          "330:         try (KRaftMigrationDriver driver = new KRaftMigrationDriver(",
          "331:             3000,",
          "332:             new NoOpRecordConsumer(),",
          "",
          "[Removed Lines]",
          "329:         CapturingMigrationClient migrationClient = new CapturingMigrationClient(new HashSet<>(Arrays.asList(1, 2, 3)));",
          "",
          "[Added Lines]",
          "211:         CapturingConfigMigrationClient configClient = new CapturingConfigMigrationClient();",
          "212:         CapturingMigrationClient migrationClient = CapturingMigrationClient.newBuilder()",
          "213:             .setBrokersInZk(1, 2, 3)",
          "214:             .setConfigMigrationClient(configClient)",
          "215:             .build();",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "357:             TestUtils.waitForCondition(() -> driver.migrationState().get(1, TimeUnit.MINUTES).equals(MigrationDriverState.DUAL_WRITE),",
          "358:                 \"Waiting for KRaftMigrationDriver to enter DUAL_WRITE state\");",
          "363:             delta = new MetadataDelta(image);",
          "364:             delta.replay(new ConfigRecord()",
          "",
          "[Removed Lines]",
          "360:             Assertions.assertEquals(1, metadataPropagator.images);",
          "361:             Assertions.assertEquals(0, metadataPropagator.deltas);",
          "",
          "[Added Lines]",
          "246:             assertEquals(1, metadataPropagator.images);",
          "247:             assertEquals(0, metadataPropagator.deltas);",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "370:             image = delta.apply(provenance);",
          "371:             enqueueMetadataChangeEventWithFuture(driver, delta, image, provenance).get(1, TimeUnit.MINUTES);",
          "377:             delta = new MetadataDelta(image);",
          "378:             delta.replay(new BrokerRegistrationChangeRecord()",
          "",
          "[Removed Lines]",
          "373:             Assertions.assertEquals(1, migrationClient.capturedConfigs.size());",
          "374:             Assertions.assertEquals(1, metadataPropagator.images);",
          "375:             Assertions.assertEquals(0, metadataPropagator.deltas);",
          "",
          "[Added Lines]",
          "259:             assertEquals(1, configClient.writtenConfigs.size());",
          "260:             assertEquals(1, metadataPropagator.images);",
          "261:             assertEquals(0, metadataPropagator.deltas);",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "384:             image = delta.apply(provenance);",
          "385:             enqueueMetadataChangeEventWithFuture(driver, delta, image, provenance).get(1, TimeUnit.MINUTES);",
          "389:         }",
          "390:     }",
          "",
          "[Removed Lines]",
          "387:             Assertions.assertEquals(1, metadataPropagator.images);",
          "388:             Assertions.assertEquals(1, metadataPropagator.deltas);",
          "",
          "[Added Lines]",
          "273:             assertEquals(1, metadataPropagator.images);",
          "274:             assertEquals(1, metadataPropagator.deltas);",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "394:     public void testMigrationWithClientException(boolean authException) throws Exception {",
          "395:         CountingMetadataPropagator metadataPropagator = new CountingMetadataPropagator();",
          "396:         CountDownLatch claimLeaderAttempts = new CountDownLatch(3);",
          "398:             @Override",
          "399:             public ZkMigrationLeadershipState claimControllerLeadership(ZkMigrationLeadershipState state) {",
          "400:                 if (claimLeaderAttempts.getCount() == 0) {",
          "",
          "[Removed Lines]",
          "397:         CapturingMigrationClient migrationClient = new CapturingMigrationClient(new HashSet<>(Arrays.asList(1, 2, 3))) {",
          "",
          "[Added Lines]",
          "283:         CapturingMigrationClient migrationClient = new CapturingMigrationClient(new HashSet<>(Arrays.asList(1, 2, 3)), new CapturingTopicMigrationClient(), null, null) {",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "438:             driver.onMetadataUpdate(delta, image, new LogDeltaManifest(provenance,",
          "439:                 new LeaderAndEpoch(OptionalInt.of(3000), 1), 1, 100, 42));",
          "441:             TestUtils.waitForCondition(() -> driver.migrationState().get(1, TimeUnit.MINUTES).equals(MigrationDriverState.DUAL_WRITE),",
          "442:                 \"Waiting for KRaftMigrationDriver to enter DUAL_WRITE state\");",
          "444:             if (authException) {",
          "446:             } else {",
          "447:                 Assertions.assertNull(faultHandler.firstException());",
          "448:             }",
          "",
          "[Removed Lines]",
          "440:             Assertions.assertTrue(claimLeaderAttempts.await(1, TimeUnit.MINUTES));",
          "445:                 Assertions.assertEquals(MigrationClientAuthException.class, faultHandler.firstException().getCause().getClass());",
          "",
          "[Added Lines]",
          "326:             assertTrue(claimLeaderAttempts.await(1, TimeUnit.MINUTES));",
          "331:                 assertEquals(MigrationClientAuthException.class, faultHandler.firstException().getCause().getClass());",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "452:     @Test",
          "453:     public void testShouldNotMoveToNextStateIfControllerNodesAreNotReadyToMigrate() throws Exception {",
          "454:         CountingMetadataPropagator metadataPropagator = new CountingMetadataPropagator();",
          "456:         apiVersions.remove(\"6\");",
          "458:         try (KRaftMigrationDriver driver = new KRaftMigrationDriver(",
          "",
          "[Removed Lines]",
          "455:         CapturingMigrationClient migrationClient = new CapturingMigrationClient(new HashSet<>(Arrays.asList(1)));",
          "",
          "[Added Lines]",
          "341:         CapturingMigrationClient migrationClient = CapturingMigrationClient.newBuilder().setBrokersInZk(1).build();",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "496:         }",
          "497:     }",
          "499:     public void testSkipWaitForBrokersInDualWrite() throws Exception {",
          "500:         CountingMetadataPropagator metadataPropagator = new CountingMetadataPropagator();",
          "502:         MockFaultHandler faultHandler = new MockFaultHandler(\"testMigrationClientExpiration\");",
          "503:         try (KRaftMigrationDriver driver = new KRaftMigrationDriver(",
          "504:                 3000,",
          "",
          "[Removed Lines]",
          "501:         CapturingMigrationClient migrationClient = new CapturingMigrationClient(Collections.emptySet());",
          "",
          "[Added Lines]",
          "385:     @Test",
          "388:         CapturingMigrationClient migrationClient = new CapturingMigrationClient(Collections.emptySet(), null, null, null);",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "534:                 \"Waiting for KRaftMigrationDriver to enter ZK_MIGRATION state\");",
          "535:         }",
          "536:     }",
          "",
          "[Removed Lines]",
          "537: }",
          "",
          "[Added Lines]",
          "425:     @FunctionalInterface",
          "426:     interface TopicDualWriteVerifier {",
          "427:         void verify(",
          "428:             KRaftMigrationDriver driver,",
          "429:             CapturingTopicMigrationClient topicClient,",
          "430:             CapturingConfigMigrationClient configClient",
          "431:         ) throws Exception;",
          "432:     }",
          "434:     public void setupTopicDualWrite(TopicDualWriteVerifier verifier) throws Exception {",
          "435:         CountingMetadataPropagator metadataPropagator = new CountingMetadataPropagator();",
          "437:         CapturingTopicMigrationClient topicClient = new CapturingTopicMigrationClient() {",
          "438:             @Override",
          "439:             public void iterateTopics(EnumSet<TopicVisitorInterest> interests, TopicVisitor visitor) {",
          "440:                 IMAGE1.topicsByName().forEach((topicName, topicImage) -> {",
          "441:                     Map<Integer, List<Integer>> assignment = new HashMap<>();",
          "442:                     topicImage.partitions().forEach((partitionId, partitionRegistration) ->",
          "443:                         assignment.put(partitionId, IntStream.of(partitionRegistration.replicas).boxed().collect(Collectors.toList()))",
          "444:                     );",
          "445:                     visitor.visitTopic(topicName, topicImage.id(), assignment);",
          "447:                     topicImage.partitions().forEach((partitionId, partitionRegistration) ->",
          "448:                         visitor.visitPartition(new TopicIdPartition(topicImage.id(), new TopicPartition(topicName, partitionId)), partitionRegistration)",
          "449:                     );",
          "450:                 });",
          "451:             }",
          "452:         };",
          "453:         CapturingConfigMigrationClient configClient = new CapturingConfigMigrationClient();",
          "454:         CapturingMigrationClient migrationClient = CapturingMigrationClient.newBuilder()",
          "455:             .setBrokersInZk(0, 1, 2, 3, 4, 5)",
          "456:             .setTopicMigrationClient(topicClient)",
          "457:             .setConfigMigrationClient(configClient)",
          "458:             .build();",
          "460:         try (KRaftMigrationDriver driver = new KRaftMigrationDriver(",
          "461:             3000,",
          "462:             new NoOpRecordConsumer(),",
          "463:             migrationClient,",
          "464:             metadataPropagator,",
          "465:             metadataPublisher -> { },",
          "466:             new MockFaultHandler(\"test\"),",
          "467:             quorumFeatures,",
          "468:             mockTime",
          "469:         )) {",
          "470:             verifier.verify(driver, topicClient, configClient);",
          "471:         }",
          "472:     }",
          "474:     @Test",
          "475:     public void testTopicDualWriteSnapshot() throws Exception {",
          "476:         setupTopicDualWrite((driver, topicClient, configClient) -> {",
          "477:             MetadataImage image = new MetadataImage(",
          "478:                 MetadataProvenance.EMPTY,",
          "479:                 FeaturesImage.EMPTY,",
          "480:                 ClusterImage.EMPTY,",
          "481:                 IMAGE1,",
          "482:                 ConfigurationsImage.EMPTY,",
          "483:                 ClientQuotasImage.EMPTY,",
          "484:                 ProducerIdsImage.EMPTY,",
          "485:                 AclsImage.EMPTY,",
          "486:                 ScramImage.EMPTY);",
          "487:             MetadataDelta delta = new MetadataDelta(image);",
          "489:             driver.start();",
          "490:             delta.replay(ZkMigrationState.PRE_MIGRATION.toRecord().message());",
          "491:             delta.replay(zkBrokerRecord(0));",
          "492:             delta.replay(zkBrokerRecord(1));",
          "493:             delta.replay(zkBrokerRecord(2));",
          "494:             delta.replay(zkBrokerRecord(3));",
          "495:             delta.replay(zkBrokerRecord(4));",
          "496:             delta.replay(zkBrokerRecord(5));",
          "497:             MetadataProvenance provenance = new MetadataProvenance(100, 1, 1);",
          "498:             image = delta.apply(provenance);",
          "501:             LeaderAndEpoch newLeader = new LeaderAndEpoch(OptionalInt.of(3000), 1);",
          "502:             driver.onControllerChange(newLeader);",
          "503:             driver.onMetadataUpdate(delta, image, new LogDeltaManifest(provenance, newLeader, 1, 100, 42));",
          "506:             TestUtils.waitForCondition(() -> driver.migrationState().get(1, TimeUnit.MINUTES).equals(MigrationDriverState.DUAL_WRITE),",
          "507:                 \"Waiting for KRaftMigrationDriver to enter ZK_MIGRATION state\");",
          "510:             provenance = new MetadataProvenance(200, 1, 1);",
          "511:             delta = new MetadataDelta(image);",
          "512:             RecordTestUtils.replayAll(delta, DELTA1_RECORDS);",
          "513:             image = delta.apply(provenance);",
          "514:             driver.onMetadataUpdate(delta, image, new SnapshotManifest(provenance, 100));",
          "515:             driver.migrationState().get(1, TimeUnit.MINUTES);",
          "517:             assertEquals(1, topicClient.deletedTopics.size());",
          "518:             assertEquals(\"foo\", topicClient.deletedTopics.get(0));",
          "519:             assertEquals(1, topicClient.createdTopics.size());",
          "520:             assertEquals(\"baz\", topicClient.createdTopics.get(0));",
          "521:             assertTrue(topicClient.updatedTopicPartitions.get(\"bar\").contains(0));",
          "522:             assertEquals(new ConfigResource(ConfigResource.Type.TOPIC, \"foo\"), configClient.deletedResources.get(0));",
          "523:         });",
          "524:     }",
          "526:     @Test",
          "527:     public void testTopicDualWriteDelta() throws Exception {",
          "528:         setupTopicDualWrite((driver, topicClient, configClient) -> {",
          "529:             MetadataImage image = new MetadataImage(",
          "530:                 MetadataProvenance.EMPTY,",
          "531:                 FeaturesImage.EMPTY,",
          "532:                 ClusterImage.EMPTY,",
          "533:                 IMAGE1,",
          "534:                 ConfigurationsImage.EMPTY,",
          "535:                 ClientQuotasImage.EMPTY,",
          "536:                 ProducerIdsImage.EMPTY,",
          "537:                 AclsImage.EMPTY,",
          "538:                 ScramImage.EMPTY);",
          "539:             MetadataDelta delta = new MetadataDelta(image);",
          "541:             driver.start();",
          "542:             delta.replay(ZkMigrationState.PRE_MIGRATION.toRecord().message());",
          "543:             delta.replay(zkBrokerRecord(0));",
          "544:             delta.replay(zkBrokerRecord(1));",
          "545:             delta.replay(zkBrokerRecord(2));",
          "546:             delta.replay(zkBrokerRecord(3));",
          "547:             delta.replay(zkBrokerRecord(4));",
          "548:             delta.replay(zkBrokerRecord(5));",
          "549:             MetadataProvenance provenance = new MetadataProvenance(100, 1, 1);",
          "550:             image = delta.apply(provenance);",
          "553:             LeaderAndEpoch newLeader = new LeaderAndEpoch(OptionalInt.of(3000), 1);",
          "554:             driver.onControllerChange(newLeader);",
          "555:             driver.onMetadataUpdate(delta, image, new LogDeltaManifest(provenance, newLeader, 1, 100, 42));",
          "558:             TestUtils.waitForCondition(() -> driver.migrationState().get(1, TimeUnit.MINUTES).equals(MigrationDriverState.DUAL_WRITE),",
          "559:                     \"Waiting for KRaftMigrationDriver to enter ZK_MIGRATION state\");",
          "562:             provenance = new MetadataProvenance(200, 1, 1);",
          "563:             delta = new MetadataDelta(image);",
          "564:             RecordTestUtils.replayAll(delta, DELTA1_RECORDS);",
          "565:             image = delta.apply(provenance);",
          "566:             driver.onMetadataUpdate(delta, image, new LogDeltaManifest(provenance, newLeader, 1, 100, 42));",
          "567:             driver.migrationState().get(1, TimeUnit.MINUTES);",
          "569:             assertEquals(1, topicClient.deletedTopics.size());",
          "570:             assertEquals(\"foo\", topicClient.deletedTopics.get(0));",
          "571:             assertEquals(1, topicClient.createdTopics.size());",
          "572:             assertEquals(\"baz\", topicClient.createdTopics.get(0));",
          "573:             assertTrue(topicClient.updatedTopicPartitions.get(\"bar\").contains(0));",
          "574:             assertEquals(new ConfigResource(ConfigResource.Type.TOPIC, \"foo\"), configClient.deletedResources.get(0));",
          "575:         });",
          "576:     }",
          "577: }",
          "",
          "---------------"
        ],
        "tests/kafkatest/tests/core/zookeeper_migration_test.py||tests/kafkatest/tests/core/zookeeper_migration_test.py": [
          "File: tests/kafkatest/tests/core/zookeeper_migration_test.py -> tests/kafkatest/tests/core/zookeeper_migration_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "117:                                         message_validator=is_int, version=DEV_BRANCH)",
          "119:         self.run_produce_consume_validate(core_test_action=self.do_migration)",
          "121:     @parametrize(metadata_quorum=isolated_kraft)",
          "122:     def test_pre_migration_mode_3_4(self, metadata_quorum):",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "120:         self.kafka.stop()",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "254:                     continue",
          "256:         assert saw_expected_log, \"Did not see expected INFO log after upgrading from a 3.4 migration\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "258:         self.kafka.stop()",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "d27ba5bfba46647401218d5c1b5d6a1a51a6b631",
      "candidate_info": {
        "commit_hash": "d27ba5bfba46647401218d5c1b5d6a1a51a6b631",
        "repo": "apache/kafka",
        "commit_url": "https://github.com/apache/kafka/commit/d27ba5bfba46647401218d5c1b5d6a1a51a6b631",
        "files": [
          "core/src/main/scala/kafka/zk/ZkMigrationClient.scala",
          "core/src/test/scala/integration/kafka/zk/ZkMigrationIntegrationTest.scala",
          "core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala",
          "core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala",
          "core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationOperationConsumer.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/MigrationClient.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/MigrationDriverState.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/ZkMigrationLeadershipState.java",
          "metadata/src/test/java/org/apache/kafka/image/AclsImageTest.java",
          "metadata/src/test/java/org/apache/kafka/image/ClientQuotasImageTest.java",
          "metadata/src/test/java/org/apache/kafka/image/ConfigurationsImageTest.java",
          "metadata/src/test/java/org/apache/kafka/image/FeaturesImageTest.java",
          "metadata/src/test/java/org/apache/kafka/image/ProducerIdsImageTest.java",
          "metadata/src/test/java/org/apache/kafka/image/ScramImageTest.java",
          "metadata/src/test/java/org/apache/kafka/image/TopicsImageTest.java",
          "metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingMigrationClient.java",
          "metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationDriverTest.java",
          "metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriterTest.java",
          "tests/kafkatest/services/zookeeper.py",
          "tests/kafkatest/tests/core/zookeeper_migration_test.py"
        ],
        "message": "KAFKA-15010 ZK migration failover support (#13758)\n\nThis patch adds snapshot reconciliation during ZK to KRaft migration. This reconciliation happens whenever a snapshot is loaded by KRaft, or during a controller failover. Prior to this patch, it was possible to miss metadata updates coming from KRaft when dual-writing to ZK.\n\nInternally this adds a new state SYNC_KRAFT_TO_ZK to the KRaftMigrationDriver state machine. The controller passes through this state after the initial ZK migration and each time a controller becomes active. \n\nLogging during dual-write was enhanced to include a count of write operations happening.\n\nReviewers: Colin P. McCabe <cmccabe@apache.org>",
        "before_after_code_files": [
          "core/src/main/scala/kafka/zk/ZkMigrationClient.scala||core/src/main/scala/kafka/zk/ZkMigrationClient.scala",
          "core/src/test/scala/integration/kafka/zk/ZkMigrationIntegrationTest.scala||core/src/test/scala/integration/kafka/zk/ZkMigrationIntegrationTest.scala",
          "core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala",
          "core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala",
          "core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationOperationConsumer.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationOperationConsumer.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/MigrationClient.java||metadata/src/main/java/org/apache/kafka/metadata/migration/MigrationClient.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/MigrationDriverState.java||metadata/src/main/java/org/apache/kafka/metadata/migration/MigrationDriverState.java",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/ZkMigrationLeadershipState.java||metadata/src/main/java/org/apache/kafka/metadata/migration/ZkMigrationLeadershipState.java",
          "metadata/src/test/java/org/apache/kafka/image/AclsImageTest.java||metadata/src/test/java/org/apache/kafka/image/AclsImageTest.java",
          "metadata/src/test/java/org/apache/kafka/image/ClientQuotasImageTest.java||metadata/src/test/java/org/apache/kafka/image/ClientQuotasImageTest.java",
          "metadata/src/test/java/org/apache/kafka/image/ConfigurationsImageTest.java||metadata/src/test/java/org/apache/kafka/image/ConfigurationsImageTest.java",
          "metadata/src/test/java/org/apache/kafka/image/FeaturesImageTest.java||metadata/src/test/java/org/apache/kafka/image/FeaturesImageTest.java",
          "metadata/src/test/java/org/apache/kafka/image/ProducerIdsImageTest.java||metadata/src/test/java/org/apache/kafka/image/ProducerIdsImageTest.java",
          "metadata/src/test/java/org/apache/kafka/image/ScramImageTest.java||metadata/src/test/java/org/apache/kafka/image/ScramImageTest.java",
          "metadata/src/test/java/org/apache/kafka/image/TopicsImageTest.java||metadata/src/test/java/org/apache/kafka/image/TopicsImageTest.java",
          "metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingMigrationClient.java||metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingMigrationClient.java",
          "metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationDriverTest.java||metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationDriverTest.java",
          "metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriterTest.java||metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriterTest.java",
          "tests/kafkatest/services/zookeeper.py||tests/kafkatest/services/zookeeper.py",
          "tests/kafkatest/tests/core/zookeeper_migration_test.py||tests/kafkatest/tests/core/zookeeper_migration_test.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala",
            "core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala",
            "core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala",
            "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java",
            "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java",
            "metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriterTest.java||metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriterTest.java"
          ],
          "candidate": [
            "core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala",
            "core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala",
            "core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala",
            "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java",
            "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java",
            "metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriterTest.java||metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriterTest.java"
          ]
        }
      },
      "candidate_diff": {
        "core/src/main/scala/kafka/zk/ZkMigrationClient.scala||core/src/main/scala/kafka/zk/ZkMigrationClient.scala": [
          "File: core/src/main/scala/kafka/zk/ZkMigrationClient.scala -> core/src/main/scala/kafka/zk/ZkMigrationClient.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "39: import java.{lang, util}",
          "40: import java.util.function.Consumer",
          "41: import scala.collection.Seq",
          "42: import scala.jdk.CollectionConverters._",
          "44: object ZkMigrationClient {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "42: import scala.compat.java8.OptionConverters._",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "303:     new util.HashSet[Integer](zkClient.getSortedBrokerList.map(Integer.valueOf).toSet.asJava)",
          "304:   }",
          "306:   override def writeProducerId(",
          "307:     nextProducerId: Long,",
          "308:     state: ZkMigrationLeadershipState",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "307:   override def readProducerId(): util.Optional[ProducerIdsBlock] = {",
          "308:     val (dataOpt, _) = zkClient.getDataAndVersion(ProducerIdBlockZNode.path)",
          "309:     dataOpt.map(ProducerIdBlockZNode.parseProducerIdBlockData).asJava",
          "310:   }",
          "",
          "---------------"
        ],
        "core/src/test/scala/integration/kafka/zk/ZkMigrationIntegrationTest.scala||core/src/test/scala/integration/kafka/zk/ZkMigrationIntegrationTest.scala": [
          "File: core/src/test/scala/integration/kafka/zk/ZkMigrationIntegrationTest.scala -> core/src/test/scala/integration/kafka/zk/ZkMigrationIntegrationTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "59: @ExtendWith(value = Array(classOf[ClusterTestExtensions]))",
          "61: class ZkMigrationIntegrationTest {",
          "63:   val log = LoggerFactory.getLogger(classOf[ZkMigrationIntegrationTest])",
          "",
          "[Removed Lines]",
          "60: @Timeout(120)",
          "",
          "[Added Lines]",
          "60: @Timeout(300)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "243:       log.info(\"Verifying metadata changes with ZK\")",
          "244:       verifyUserScramCredentials(zkClient)",
          "245:     } finally {",
          "248:     }",
          "249:   }",
          "",
          "[Removed Lines]",
          "246:       zkCluster.stop()",
          "247:       kraftCluster.close()",
          "",
          "[Added Lines]",
          "246:       shutdownInSequence(zkCluster, kraftCluster)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "321:       verifyProducerId(producerIdBlock, zkClient)",
          "323:     } finally {",
          "326:     }",
          "327:   }",
          "",
          "[Removed Lines]",
          "324:       zkCluster.stop()",
          "325:       kraftCluster.close()",
          "",
          "[Added Lines]",
          "323:       shutdownInSequence(zkCluster, kraftCluster)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "383:       verifyUserScramCredentials(zkClient)",
          "384:       verifyClientQuotas(zkClient)",
          "385:     } finally {",
          "388:     }",
          "389:   }",
          "",
          "[Removed Lines]",
          "386:       zkCluster.stop()",
          "387:       kraftCluster.close()",
          "",
          "[Added Lines]",
          "384:       shutdownInSequence(zkCluster, kraftCluster)",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "481:       assertTrue(firstProducerIdBlock.firstProducerId() < producerIdBlock.firstProducerId())",
          "482:     }",
          "483:   }",
          "484: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "482:   def shutdownInSequence(zkCluster: ClusterInstance, kraftCluster: KafkaClusterTestKit): Unit = {",
          "483:     zkCluster.brokerIds().forEach(zkCluster.shutdownBroker(_))",
          "484:     kraftCluster.close()",
          "485:     zkCluster.stop()",
          "486:   }",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala": [
          "File: core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala -> core/src/test/scala/unit/kafka/zk/migration/ZkAclMigrationClientTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "170:     val image = delta.apply(MetadataProvenance.EMPTY)",
          "178:     val resource1AclsInZk = zkClient.getVersionedAclsForResource(resource1).acls",
          "",
          "[Removed Lines]",
          "173:     val kraftMigrationZkWriter = new KRaftMigrationZkWriter(migrationClient,",
          "174:       (_, operation) => { migrationState = operation.apply(migrationState) })",
          "175:     kraftMigrationZkWriter.handleLoadSnapshot(image)",
          "",
          "[Added Lines]",
          "173:     val kraftMigrationZkWriter = new KRaftMigrationZkWriter(migrationClient)",
          "174:     kraftMigrationZkWriter.handleSnapshot(image, (_, _, operation) => { migrationState = operation.apply(migrationState) })",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala": [
          "File: core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala -> core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "311:     val image = delta.apply(MetadataProvenance.EMPTY)",
          "318:     val user1Props = zkClient.getEntityConfigs(ConfigType.User, \"user1\")",
          "319:     assertEquals(0, user1Props.size())",
          "",
          "[Removed Lines]",
          "314:     val kraftMigrationZkWriter = new KRaftMigrationZkWriter(migrationClient,",
          "315:       (_, operation) => { migrationState = operation.apply(migrationState) })",
          "316:     kraftMigrationZkWriter.handleLoadSnapshot(image)",
          "",
          "[Added Lines]",
          "314:     val kraftMigrationZkWriter = new KRaftMigrationZkWriter(migrationClient)",
          "315:     kraftMigrationZkWriter.handleSnapshot(image, (_, _, operation) => {",
          "316:       migrationState = operation.apply(migrationState)",
          "317:     })",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala": [
          "File: core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala -> core/src/test/scala/unit/kafka/zk/migration/ZkMigrationClientTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "265:   @Test",
          "266:   def testTopicAndBrokerConfigsMigrationWithSnapshots(): Unit = {",
          "272:     val topicName = \"testTopic\"",
          "",
          "[Removed Lines]",
          "267:     val kraftWriter = new KRaftMigrationZkWriter(migrationClient, (_, operation) => {",
          "268:       migrationState = operation.apply(migrationState)",
          "269:     })",
          "",
          "[Added Lines]",
          "267:     val kraftWriter = new KRaftMigrationZkWriter(migrationClient)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "320:     val image = delta.apply(MetadataProvenance.EMPTY)",
          "326:     val topicIdReplicaAssignment =",
          "",
          "[Removed Lines]",
          "323:     kraftWriter.handleLoadSnapshot(image)",
          "",
          "[Added Lines]",
          "321:     kraftWriter.handleSnapshot(image, (_, _, operation) => {",
          "322:       migrationState = operation(migrationState)",
          "323:     })",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java -> metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationDriver.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "41: import java.util.Collection;",
          "42: import java.util.EnumSet;",
          "43: import java.util.HashSet;",
          "44: import java.util.Optional;",
          "45: import java.util.Set;",
          "46: import java.util.concurrent.CompletableFuture;",
          "47: import java.util.concurrent.RejectedExecutionException;",
          "48: import java.util.concurrent.TimeUnit;",
          "49: import java.util.concurrent.atomic.AtomicInteger;",
          "50: import java.util.function.Consumer;",
          "51: import java.util.stream.Collectors;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "44: import java.util.Map;",
          "47: import java.util.TreeMap;",
          "52: import java.util.function.BiConsumer;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "115:         this.initialZkLoadHandler = initialZkLoadHandler;",
          "116:         this.faultHandler = faultHandler;",
          "117:         this.quorumFeatures = quorumFeatures;",
          "119:     }",
          "121:     public KRaftMigrationDriver(",
          "",
          "[Removed Lines]",
          "118:         this.zkMetadataWriter = new KRaftMigrationZkWriter(zkMigrationClient, this::applyMigrationOperation);",
          "",
          "[Added Lines]",
          "121:         this.zkMetadataWriter = new KRaftMigrationZkWriter(zkMigrationClient);",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "149:     }",
          "151:     private void recoverMigrationStateFromZK() {",
          "",
          "[Removed Lines]",
          "152:         log.info(\"Recovering migration state from ZK\");",
          "153:         applyMigrationOperation(\"Recovery\", zkMigrationClient::getOrCreateMigrationRecoveryState);",
          "154:         String maybeDone = migrationLeadershipState.zkMigrationComplete() ? \"done\" : \"not done\";",
          "155:         log.info(\"Recovered migration state {}. ZK migration is {}.\", migrationLeadershipState, maybeDone);",
          "",
          "[Added Lines]",
          "155:         applyMigrationOperation(\"Recovering migration state from ZK\", zkMigrationClient::getOrCreateMigrationRecoveryState);",
          "156:         String maybeDone = migrationLeadershipState.initialZkMigrationComplete() ? \"done\" : \"not done\";",
          "157:         log.info(\"Initial migration of ZK metadata is {}.\", maybeDone);",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "230:         ZkMigrationLeadershipState beforeState = this.migrationLeadershipState;",
          "231:         ZkMigrationLeadershipState afterState = migrationOp.apply(beforeState);",
          "232:         if (afterState.loggableChangeSinceState(beforeState)) {",
          "234:         } else if (afterState.equals(beforeState)) {",
          "236:         } else {",
          "239:         }",
          "240:         this.migrationLeadershipState = afterState;",
          "",
          "[Removed Lines]",
          "233:             log.info(\"{} transitioned migration state from {} to {}\", name, beforeState, afterState);",
          "235:             log.trace(\"{} kept migration state as {}\", name, afterState);",
          "237:             log.trace(\"{} transitioned migration state from {} to {}\", name, beforeState, afterState);",
          "",
          "[Added Lines]",
          "235:             log.info(\"{}. Transitioned migration state from {} to {}\", name, beforeState, afterState);",
          "237:             log.trace(\"{}. Kept migration state as {}\", name, afterState);",
          "239:             log.trace(\"{}. Transitioned migration state from {} to {}\", name, beforeState, afterState);",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "267:                 return",
          "268:                     newState == MigrationDriverState.INACTIVE ||",
          "269:                     newState == MigrationDriverState.ZK_MIGRATION ||",
          "271:             case ZK_MIGRATION:",
          "272:                 return",
          "273:                     newState == MigrationDriverState.INACTIVE ||",
          "274:                     newState == MigrationDriverState.KRAFT_CONTROLLER_TO_BROKER_COMM;",
          "",
          "[Removed Lines]",
          "270:                     newState == MigrationDriverState.KRAFT_CONTROLLER_TO_BROKER_COMM;",
          "",
          "[Added Lines]",
          "272:                     newState == MigrationDriverState.SYNC_KRAFT_TO_ZK;",
          "274:                 return",
          "275:                     newState == MigrationDriverState.INACTIVE ||",
          "276:                     newState == MigrationDriverState.SYNC_KRAFT_TO_ZK;",
          "277:             case SYNC_KRAFT_TO_ZK:",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "392:                 case ZK_MIGRATION:",
          "393:                     eventQueue.append(new MigrateMetadataEvent());",
          "394:                     break;",
          "395:                 case KRAFT_CONTROLLER_TO_BROKER_COMM:",
          "396:                     eventQueue.append(new SendRPCsToBrokersEvent());",
          "397:                     break;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "401:                 case SYNC_KRAFT_TO_ZK:",
          "402:                     eventQueue.append(new SyncKRaftMetadataEvent());",
          "403:                     break;",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "429:             boolean isActive = leaderAndEpoch.isLeader(KRaftMigrationDriver.this.nodeId);",
          "431:             if (!isActive) {",
          "433:                     state.withNewKRaftController(",
          "434:                         leaderAndEpoch.leaderId().orElse(ZkMigrationLeadershipState.EMPTY.kraftControllerId()),",
          "435:                         leaderAndEpoch.epoch())",
          "436:                 );",
          "437:                 transitionTo(MigrationDriverState.INACTIVE);",
          "438:             } else {",
          "",
          "[Removed Lines]",
          "432:                 applyMigrationOperation(\"KRaftLeaderEvent is not active\", state ->",
          "440:                 applyMigrationOperation(\"KRaftLeaderEvent is active\", state -> state.withNewKRaftController(nodeId, leaderAndEpoch.epoch()));",
          "",
          "[Added Lines]",
          "441:                 applyMigrationOperation(\"Became inactive migration driver\", state ->",
          "449:                 applyMigrationOperation(\"Became active migration driver\", state -> {",
          "450:                     ZkMigrationLeadershipState recoveredState = zkMigrationClient.getOrCreateMigrationRecoveryState(state);",
          "451:                     return recoveredState.withNewKRaftController(nodeId, leaderAndEpoch.epoch());",
          "452:                 });",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "473:                         }",
          "474:                         break;",
          "475:                     case MIGRATION:",
          "477:                             log.error(\"KRaft controller indicates an active migration, but the ZK state does not.\");",
          "478:                             transitionTo(MigrationDriverState.INACTIVE);",
          "479:                         } else {",
          "",
          "[Removed Lines]",
          "476:                         if (!migrationLeadershipState.zkMigrationComplete()) {",
          "",
          "[Added Lines]",
          "488:                         if (!migrationLeadershipState.initialZkMigrationComplete()) {",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "495:         @Override",
          "496:         public void run() throws Exception {",
          "497:             if (migrationState == MigrationDriverState.BECOME_CONTROLLER) {",
          "499:                 if (migrationLeadershipState.zkControllerEpochZkVersion() == -1) {",
          "500:                     log.debug(\"Unable to claim leadership, will retry until we learn of a different KRaft leader\");",
          "501:                 } else {",
          "503:                         transitionTo(MigrationDriverState.ZK_MIGRATION);",
          "504:                     } else {",
          "506:                     }",
          "507:                 }",
          "508:             }",
          "",
          "[Removed Lines]",
          "498:                 applyMigrationOperation(\"BecomeZkLeaderEvent\", zkMigrationClient::claimControllerLeadership);",
          "502:                     if (!migrationLeadershipState.zkMigrationComplete()) {",
          "505:                         transitionTo(MigrationDriverState.KRAFT_CONTROLLER_TO_BROKER_COMM);",
          "",
          "[Added Lines]",
          "510:                 applyMigrationOperation(\"Claiming ZK controller leadership\", zkMigrationClient::claimControllerLeadership);",
          "514:                     if (!migrationLeadershipState.initialZkMigrationComplete()) {",
          "517:                         transitionTo(MigrationDriverState.SYNC_KRAFT_TO_ZK);",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "542:                             log.info(\"Migrating {} records from ZK\", batch.size());",
          "543:                         }",
          "544:                         CompletableFuture<?> future = zkRecordConsumer.acceptBatch(batch);",
          "546:                             \"the metadata layer to commit migration record batch\",",
          "547:                             future, Deadline.fromDelay(time, METADATA_COMMIT_MAX_WAIT_MS, TimeUnit.MILLISECONDS), time);",
          "548:                         count.addAndGet(batch.size());",
          "",
          "[Removed Lines]",
          "545:                         FutureUtils.waitWithLogging(KRaftMigrationDriver.this.log, KRaftMigrationDriver.this.logContext.logPrefix(),",
          "",
          "[Added Lines]",
          "557:                         FutureUtils.waitWithLogging(KRaftMigrationDriver.this.log, \"\",",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "552:                 }, brokersInMetadata::add);",
          "553:                 CompletableFuture<OffsetAndEpoch> completeMigrationFuture = zkRecordConsumer.completeMigration();",
          "554:                 OffsetAndEpoch offsetAndEpochAfterMigration = FutureUtils.waitWithLogging(",
          "556:                     \"the metadata layer to complete the migration\",",
          "557:                     completeMigrationFuture, Deadline.fromDelay(time, METADATA_COMMIT_MAX_WAIT_MS, TimeUnit.MILLISECONDS), time);",
          "558:                 log.info(\"Completed migration of metadata from Zookeeper to KRaft. A total of {} metadata records were \" +",
          "",
          "[Removed Lines]",
          "555:                     KRaftMigrationDriver.this.log, KRaftMigrationDriver.this.logContext.logPrefix(),",
          "",
          "[Added Lines]",
          "567:                     KRaftMigrationDriver.this.log, \"\",",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "566:                 ZkMigrationLeadershipState newState = migrationLeadershipState.withKRaftMetadataOffsetAndEpoch(",
          "567:                     offsetAndEpochAfterMigration.offset(),",
          "568:                     offsetAndEpochAfterMigration.epoch());",
          "571:             } catch (Throwable t) {",
          "572:                 zkRecordConsumer.abortMigration();",
          "573:                 super.handleException(t);",
          "",
          "[Removed Lines]",
          "569:                 applyMigrationOperation(\"Finished migrating ZK data\", state -> zkMigrationClient.setMigrationRecoveryState(newState));",
          "570:                 transitionTo(MigrationDriverState.KRAFT_CONTROLLER_TO_BROKER_COMM);",
          "",
          "[Added Lines]",
          "581:                 applyMigrationOperation(\"Finished initial migration of ZK metadata to KRaft\", state -> zkMigrationClient.setMigrationRecoveryState(newState));",
          "585:                 transitionTo(MigrationDriverState.SYNC_KRAFT_TO_ZK);",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "575:         }",
          "576:     }",
          "578:     class SendRPCsToBrokersEvent extends MigrationEvent {",
          "580:         @Override",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "593:     static KRaftMigrationOperationConsumer countingOperationConsumer(",
          "594:         Map<String, Integer> dualWriteCounts,",
          "595:         BiConsumer<String, KRaftMigrationOperation> operationConsumer",
          "596:     ) {",
          "597:         return (opType, logMsg, operation) -> {",
          "598:             dualWriteCounts.compute(opType, (key, value) -> {",
          "599:                 if (value == null) {",
          "600:                     return 1;",
          "601:                 } else {",
          "602:                     return value + 1;",
          "603:                 }",
          "604:             });",
          "605:             operationConsumer.accept(logMsg, operation);",
          "606:         };",
          "607:     }",
          "610:     class SyncKRaftMetadataEvent extends MigrationEvent {",
          "611:         @Override",
          "612:         public void run() throws Exception {",
          "613:             if (migrationState == MigrationDriverState.SYNC_KRAFT_TO_ZK) {",
          "614:                 log.info(\"Performing a full metadata sync from KRaft to ZK.\");",
          "615:                 Map<String, Integer> dualWriteCounts = new TreeMap<>();",
          "616:                 zkMetadataWriter.handleSnapshot(image, countingOperationConsumer(",
          "617:                     dualWriteCounts, KRaftMigrationDriver.this::applyMigrationOperation));",
          "618:                 log.info(\"Made the following ZK writes when reconciling with KRaft state: {}\", dualWriteCounts);",
          "619:                 transitionTo(MigrationDriverState.KRAFT_CONTROLLER_TO_BROKER_COMM);",
          "620:             }",
          "621:         }",
          "622:     }",
          "",
          "---------------",
          "--- Hunk 14 ---",
          "[Context before]",
          "623:             KRaftMigrationDriver.this.image = image;",
          "624:             String metadataType = isSnapshot ? \"snapshot\" : \"delta\";",
          "627:                 log.trace(\"Received metadata {}, but the controller is not in dual-write \" +",
          "628:                     \"mode. Ignoring the change to be replicated to Zookeeper\", metadataType);",
          "629:                 completionHandler.accept(null);",
          "",
          "[Removed Lines]",
          "626:             if (migrationState != MigrationDriverState.DUAL_WRITE) {",
          "",
          "[Added Lines]",
          "672:             if (!migrationState.allowDualWrite()) {",
          "",
          "---------------",
          "--- Hunk 15 ---",
          "[Context before]",
          "633:             if (image.highestOffsetAndEpoch().compareTo(migrationLeadershipState.offsetAndEpoch()) < 0) {",
          "634:                 log.info(\"Ignoring {} {} which contains metadata that has already been written to ZK.\", metadataType, provenance);",
          "635:                 completionHandler.accept(null);",
          "636:             }",
          "638:             if (isSnapshot) {",
          "640:             } else {",
          "642:             }",
          "646:             if (delta.topicsDelta() != null || delta.clusterDelta() != null) {",
          "647:                 log.trace(\"Sending RPCs to brokers for metadata {}.\", metadataType);",
          "650:             } else {",
          "651:                 log.trace(\"Not sending RPCs to brokers for metadata {} since no relevant metadata has changed\", metadataType);",
          "652:             }",
          "",
          "[Removed Lines]",
          "639:                 zkMetadataWriter.handleLoadSnapshot(image);",
          "641:                 zkMetadataWriter.handleDelta(prevImage, image, delta);",
          "648:                 propagator.sendRPCsToBrokersFromMetadataDelta(delta, image,",
          "649:                         migrationLeadershipState.zkControllerEpoch());",
          "",
          "[Added Lines]",
          "682:                 return;",
          "685:             Map<String, Integer> dualWriteCounts = new TreeMap<>();",
          "687:                 zkMetadataWriter.handleSnapshot(image, countingOperationConsumer(",
          "688:                     dualWriteCounts, KRaftMigrationDriver.this::applyMigrationOperation));",
          "690:                 zkMetadataWriter.handleDelta(prevImage, image, delta, countingOperationConsumer(",
          "691:                     dualWriteCounts, KRaftMigrationDriver.this::applyMigrationOperation));",
          "693:             if (dualWriteCounts.isEmpty()) {",
          "694:                 log.trace(\"Did not make any ZK writes when handling KRaft {}\", isSnapshot ? \"snapshot\" : \"delta\");",
          "695:             } else {",
          "696:                 log.debug(\"Made the following ZK writes when handling KRaft {}: {}\", isSnapshot ? \"snapshot\" : \"delta\", dualWriteCounts);",
          "697:             }",
          "700:             ZkMigrationLeadershipState zkStateAfterDualWrite = migrationLeadershipState.withKRaftMetadataOffsetAndEpoch(",
          "701:                 image.highestOffsetAndEpoch().offset(), image.highestOffsetAndEpoch().epoch());",
          "702:             applyMigrationOperation(\"Updating ZK migration state after \" + metadataType,",
          "703:                 state -> zkMigrationClient.setMigrationRecoveryState(zkStateAfterDualWrite));",
          "709:                 propagator.sendRPCsToBrokersFromMetadataDelta(delta, image, migrationLeadershipState.zkControllerEpoch());",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationOperationConsumer.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationOperationConsumer.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationOperationConsumer.java -> metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationOperationConsumer.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.metadata.migration;",
          "20: @FunctionalInterface",
          "21: public interface KRaftMigrationOperationConsumer {",
          "22:     void accept(String opType, String logMsg, KRaftMigrationOperation operation);",
          "23: }",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java -> metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "35: import org.apache.kafka.image.ConfigurationsImage;",
          "36: import org.apache.kafka.image.MetadataDelta;",
          "37: import org.apache.kafka.image.MetadataImage;",
          "38: import org.apache.kafka.image.ScramImage;",
          "39: import org.apache.kafka.image.TopicImage;",
          "40: import org.apache.kafka.image.TopicsDelta;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "38: import org.apache.kafka.image.ProducerIdsDelta;",
          "39: import org.apache.kafka.image.ProducerIdsImage;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "42: import org.apache.kafka.metadata.PartitionRegistration;",
          "43: import org.apache.kafka.metadata.ScramCredentialData;",
          "44: import org.apache.kafka.metadata.authorizer.StandardAcl;",
          "46: import java.util.ArrayList;",
          "47: import java.util.Collections;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "47: import org.apache.kafka.server.common.ProducerIdsBlock;",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "58: import java.util.stream.Collectors;",
          "60: public class KRaftMigrationZkWriter {",
          "61:     private final MigrationClient migrationClient;",
          "64:     public KRaftMigrationZkWriter(",
          "67:     ) {",
          "68:         this.migrationClient = migrationClient;",
          "70:     }",
          "79:     }",
          "82:         if (delta.topicsDelta() != null) {",
          "84:         }",
          "85:         if (delta.configsDelta() != null) {",
          "87:         }",
          "88:         if ((delta.clientQuotasDelta() != null) || (delta.scramDelta() != null)) {",
          "90:         }",
          "91:         if (delta.producerIdsDelta() != null) {",
          "94:         }",
          "95:         if (delta.aclsDelta() != null) {",
          "97:         }",
          "98:     }",
          "",
          "[Removed Lines]",
          "62:     private final BiConsumer<String, KRaftMigrationOperation> operationConsumer;",
          "65:         MigrationClient migrationClient,",
          "66:         BiConsumer<String, KRaftMigrationOperation>  operationConsumer",
          "69:         this.operationConsumer = operationConsumer;",
          "72:     public void handleLoadSnapshot(MetadataImage image) {",
          "73:         handleTopicsSnapshot(image.topics());",
          "74:         handleConfigsSnapshot(image.configs());",
          "75:         handleClientQuotasSnapshot(image.clientQuotas(), image.scram());",
          "76:         operationConsumer.accept(\"Setting next producer ID\", migrationState ->",
          "77:             migrationClient.writeProducerId(image.producerIds().nextProducerId(), migrationState));",
          "78:         handleAclsSnapshot(image.acls());",
          "81:     public void handleDelta(MetadataImage previousImage, MetadataImage image, MetadataDelta delta) {",
          "83:             handleTopicsDelta(previousImage.topics().topicIdToNameView()::get, delta.topicsDelta());",
          "86:             handleConfigsDelta(image.configs(), delta.configsDelta());",
          "89:             handleClientQuotasDelta(image, delta);",
          "92:             operationConsumer.accept(\"Updating next producer ID\", migrationState ->",
          "93:                 migrationClient.writeProducerId(delta.producerIdsDelta().nextProducerId(), migrationState));",
          "96:             handleAclsDelta(image.acls(), delta.aclsDelta());",
          "",
          "[Added Lines]",
          "65:     private static final String UPDATE_PRODUCER_ID = \"UpdateProducerId\";",
          "66:     private static final String CREATE_TOPIC = \"CreateTopic\";",
          "67:     private static final String DELETE_TOPIC = \"DeleteTopic\";",
          "68:     private static final String UPDATE_PARTITON = \"UpdatePartition\";",
          "69:     private static final String UPDATE_BROKER_CONFIG = \"UpdateBrokerConfig\";",
          "70:     private static final String DELETE_BROKER_CONFIG = \"DeleteBrokerConfig\";",
          "71:     private static final String UPDATE_TOPIC_CONFIG = \"UpdateTopicConfig\";",
          "72:     private static final String DELETE_TOPIC_CONFIG = \"DeleteTopicConfig\";",
          "73:     private static final String UPDATE_CLIENT_QUOTA = \"UpdateClientQuota\";",
          "74:     private static final String UPDATE_ACL = \"UpdateAcl\";",
          "75:     private static final String DELETE_ACL = \"DeleteAcl\";",
          "81:         MigrationClient migrationClient",
          "86:     public void handleSnapshot(MetadataImage image, KRaftMigrationOperationConsumer operationConsumer) {",
          "87:         handleTopicsSnapshot(image.topics(), operationConsumer);",
          "88:         handleConfigsSnapshot(image.configs(), operationConsumer);",
          "89:         handleClientQuotasSnapshot(image.clientQuotas(), image.scram(), operationConsumer);",
          "90:         handleProducerIdSnapshot(image.producerIds(), operationConsumer);",
          "91:         handleAclsSnapshot(image.acls(), operationConsumer);",
          "94:     public void handleDelta(",
          "95:         MetadataImage previousImage,",
          "96:         MetadataImage image,",
          "97:         MetadataDelta delta,",
          "98:         KRaftMigrationOperationConsumer operationConsumer",
          "99:     ) {",
          "101:             handleTopicsDelta(previousImage.topics().topicIdToNameView()::get, delta.topicsDelta(), operationConsumer);",
          "104:             handleConfigsDelta(image.configs(), delta.configsDelta(), operationConsumer);",
          "107:             handleClientQuotasDelta(image, delta, operationConsumer);",
          "110:             handleProducerIdDelta(delta.producerIdsDelta(), operationConsumer);",
          "113:             handleAclsDelta(image.acls(), delta.aclsDelta(), operationConsumer);",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "106:         Map<Uuid, String> deletedTopics = new HashMap<>();",
          "107:         Set<Uuid> createdTopics = new HashSet<>(topicsImage.topicsById().keySet());",
          "108:         Map<Uuid, Map<Integer, PartitionRegistration>> changedPartitions = new HashMap<>();",
          "",
          "[Removed Lines]",
          "105:     void handleTopicsSnapshot(TopicsImage topicsImage) {",
          "",
          "[Added Lines]",
          "122:     void handleTopicsSnapshot(TopicsImage topicsImage, KRaftMigrationOperationConsumer operationConsumer) {",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "142:         createdTopics.forEach(topicId -> {",
          "143:             TopicImage topic = topicsImage.getTopic(topicId);",
          "144:             operationConsumer.accept(",
          "145:                 \"Create Topic \" + topic.name() + \", ID \" + topicId,",
          "146:                 migrationState -> migrationClient.topicClient().createTopic(topic.name(), topicId, topic.partitions(), migrationState)",
          "147:             );",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "162:                 CREATE_TOPIC,",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "150:         deletedTopics.forEach((topicId, topicName) -> {",
          "151:             operationConsumer.accept(",
          "152:                 \"Delete Topic \" + topicName + \", ID \" + topicId,",
          "153:                 migrationState -> migrationClient.topicClient().deleteTopic(topicName, migrationState)",
          "154:             );",
          "155:             ConfigResource resource = new ConfigResource(ConfigResource.Type.TOPIC, topicName);",
          "156:             operationConsumer.accept(",
          "157:                 \"Updating Configs for Topic \" + topicName + \", ID \" + topicId,",
          "158:                 migrationState -> migrationClient.configClient().deleteConfigs(resource, migrationState)",
          "159:             );",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "170:                 DELETE_TOPIC,",
          "176:                 UPDATE_TOPIC_CONFIG,",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "162:         changedPartitions.forEach((topicId, paritionMap) -> {",
          "163:             TopicImage topic = topicsImage.getTopic(topicId);",
          "164:             operationConsumer.accept(",
          "165:                 \"Updating Partitions for Topic \" + topic.name() + \", ID \" + topicId,",
          "166:                 migrationState -> migrationClient.topicClient().updateTopicPartitions(",
          "167:                     Collections.singletonMap(topic.name(), paritionMap),",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "185:                 UPDATE_PARTITON,",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "169:         });",
          "170:     }",
          "173:         topicsDelta.deletedTopicIds().forEach(topicId -> {",
          "174:             String name = deletedTopicNameResolver.apply(topicId);",
          "176:                 migrationState -> migrationClient.topicClient().deleteTopic(name, migrationState));",
          "177:         });",
          "179:         topicsDelta.changedTopics().forEach((topicId, topicDelta) -> {",
          "180:             if (topicsDelta.createdTopicIds().contains(topicId)) {",
          "181:                 operationConsumer.accept(",
          "182:                     \"Create Topic \" + topicDelta.name() + \", ID \" + topicId,",
          "183:                     migrationState -> migrationClient.topicClient().createTopic(",
          "184:                         topicDelta.name(),",
          "",
          "[Removed Lines]",
          "172:     void handleTopicsDelta(Function<Uuid, String> deletedTopicNameResolver, TopicsDelta topicsDelta) {",
          "175:             operationConsumer.accept(\"Deleting topic \" + name + \", ID \" + topicId,",
          "",
          "[Added Lines]",
          "193:     void handleTopicsDelta(",
          "194:         Function<Uuid, String> deletedTopicNameResolver,",
          "195:         TopicsDelta topicsDelta,",
          "196:         KRaftMigrationOperationConsumer operationConsumer",
          "197:     ) {",
          "200:             operationConsumer.accept(DELETE_TOPIC, \"Deleting topic \" + name + \", ID \" + topicId,",
          "207:                     CREATE_TOPIC,",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "187:                         migrationState));",
          "188:             } else {",
          "189:                 operationConsumer.accept(",
          "190:                     \"Updating Partitions for Topic \" + topicDelta.name() + \", ID \" + topicId,",
          "191:                     migrationState -> migrationClient.topicClient().updateTopicPartitions(",
          "192:                         Collections.singletonMap(topicDelta.name(), topicDelta.partitionChanges()),",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "216:                     UPDATE_PARTITON,",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "195:         });",
          "196:     }",
          "199:         Set<ConfigResource> newResources = new HashSet<>();",
          "200:         configsImage.resourceData().keySet().forEach(resource -> {",
          "201:             if (EnumSet.of(ConfigResource.Type.BROKER, ConfigResource.Type.TOPIC).contains(resource.type())) {",
          "",
          "[Removed Lines]",
          "198:     void handleConfigsSnapshot(ConfigurationsImage configsImage) {",
          "",
          "[Added Lines]",
          "225:     private String brokerOrTopicOpType(ConfigResource resource, String brokerOp, String topicOp) {",
          "226:         if (resource.type().equals(ConfigResource.Type.BROKER)) {",
          "227:             return brokerOp;",
          "228:         } else {",
          "229:             return topicOp;",
          "230:         }",
          "231:     }",
          "233:     void handleConfigsSnapshot(ConfigurationsImage configsImage, KRaftMigrationOperationConsumer operationConsumer) {",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "225:         newResources.forEach(resource -> {",
          "226:             Map<String, String> props = configsImage.configMapForResource(resource);",
          "227:             if (!props.isEmpty()) {",
          "229:                     migrationState -> migrationClient.configClient().writeConfigs(resource, props, migrationState));",
          "230:             }",
          "231:         });",
          "",
          "[Removed Lines]",
          "228:                 operationConsumer.accept(\"Create configs for \" + resource.type().name() + \" \" + resource.name(),",
          "",
          "[Added Lines]",
          "263:                 String opType = brokerOrTopicOpType(resource, UPDATE_BROKER_CONFIG, UPDATE_TOPIC_CONFIG);",
          "264:                 operationConsumer.accept(opType, \"Create configs for \" + resource.type().name() + \" \" + resource.name(),",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "233:         resourcesToUpdate.forEach(resource -> {",
          "234:             Map<String, String> props = configsImage.configMapForResource(resource);",
          "235:             if (props.isEmpty()) {",
          "237:                     migrationState -> migrationClient.configClient().deleteConfigs(resource, migrationState));",
          "238:             } else {",
          "240:                     migrationState -> migrationClient.configClient().writeConfigs(resource, props, migrationState));",
          "241:             }",
          "242:         });",
          "",
          "[Removed Lines]",
          "236:                 operationConsumer.accept(\"Delete configs for \" + resource.type().name() + \" \" + resource.name(),",
          "239:                 operationConsumer.accept(\"Update configs for \" + resource.type().name() + \" \" + resource.name(),",
          "",
          "[Added Lines]",
          "272:                 String opType = brokerOrTopicOpType(resource, DELETE_BROKER_CONFIG, DELETE_TOPIC_CONFIG);",
          "273:                 operationConsumer.accept(opType, \"Delete configs for \" + resource.type().name() + \" \" + resource.name(),",
          "276:                 String opType = brokerOrTopicOpType(resource, UPDATE_BROKER_CONFIG, UPDATE_TOPIC_CONFIG);",
          "277:                 operationConsumer.accept(opType, \"Update configs for \" + resource.type().name() + \" \" + resource.name(),",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "256:         return userScramCredentialStrings;",
          "257:     }",
          "260:         Set<ClientQuotaEntity> changedNonUserEntities = new HashSet<>();",
          "261:         Set<String> changedUsers = new HashSet<>();",
          "",
          "[Removed Lines]",
          "259:     void handleClientQuotasSnapshot(ClientQuotasImage clientQuotasImage, ScramImage scramImage) {",
          "",
          "[Added Lines]",
          "297:     void handleClientQuotasSnapshot(ClientQuotasImage clientQuotasImage, ScramImage scramImage, KRaftMigrationOperationConsumer opConsumer) {",
          "",
          "---------------",
          "--- Hunk 14 ---",
          "[Context before]",
          "308:         });",
          "310:         changedNonUserEntities.forEach(entity -> {",
          "313:                 migrationClient.configClient().writeClientQuotas(entity.entries(), quotaMap, Collections.emptyMap(), migrationState));",
          "314:         });",
          "",
          "[Removed Lines]",
          "311:             Map<String, Double> quotaMap = clientQuotasImage.entities().get(entity).quotaMap();",
          "312:             operationConsumer.accept(\"Update client quotas for \" + entity, migrationState ->",
          "",
          "[Added Lines]",
          "349:             Map<String, Double> quotaMap = clientQuotasImage.entities().getOrDefault(entity, ClientQuotaImage.EMPTY).quotaMap();",
          "350:             opConsumer.accept(UPDATE_CLIENT_QUOTA, \"Update client quotas for \" + entity, migrationState ->",
          "",
          "---------------",
          "--- Hunk 15 ---",
          "[Context before]",
          "318:             Map<String, Double> quotaMap = clientQuotasImage.entities().",
          "319:                 getOrDefault(entity, ClientQuotaImage.EMPTY).quotaMap();",
          "320:             Map<String, String> scramMap = getScramCredentialStringsForUser(scramImage, userName);",
          "322:                 migrationClient.configClient().writeClientQuotas(entity.entries(), quotaMap, scramMap, migrationState));",
          "323:         });",
          "325:     }",
          "328:         Set<ConfigResource> updatedResources = configsDelta.changes().keySet();",
          "329:         updatedResources.forEach(configResource -> {",
          "330:             Map<String, String> props = configsImage.configMapForResource(configResource);",
          "331:             if (props.isEmpty()) {",
          "333:                     migrationClient.configClient().deleteConfigs(configResource, migrationState));",
          "334:             } else {",
          "336:                     migrationClient.configClient().writeConfigs(configResource, props, migrationState));",
          "337:             }",
          "338:         });",
          "339:     }",
          "342:         if ((metadataDelta.clientQuotasDelta() != null) || (metadataDelta.scramDelta() != null)) {",
          "344:             HashSet<String> users = new HashSet<>();",
          "",
          "[Removed Lines]",
          "321:             operationConsumer.accept(\"Update scram credentials for \" + userName, migrationState ->",
          "327:     void handleConfigsDelta(ConfigurationsImage configsImage, ConfigurationsDelta configsDelta) {",
          "332:                 operationConsumer.accept(\"Delete configs for \" + configResource, migrationState ->",
          "335:                 operationConsumer.accept(\"Update configs for \" + configResource, migrationState ->",
          "341:     void handleClientQuotasDelta(MetadataImage metadataImage, MetadataDelta metadataDelta) {",
          "",
          "[Added Lines]",
          "359:             opConsumer.accept(UPDATE_CLIENT_QUOTA, \"Update client quotas for \" + userName, migrationState ->",
          "362:     }",
          "364:     void handleProducerIdSnapshot(ProducerIdsImage image, KRaftMigrationOperationConsumer operationConsumer) {",
          "365:         if (image.isEmpty()) {",
          "367:             return;",
          "368:         }",
          "369:         Optional<ProducerIdsBlock> zkProducerId = migrationClient.readProducerId();",
          "370:         if (zkProducerId.isPresent()) {",
          "371:             if (zkProducerId.get().nextBlockFirstId() != image.nextProducerId()) {",
          "372:                 operationConsumer.accept(UPDATE_PRODUCER_ID, \"Setting next producer ID\", migrationState ->",
          "373:                     migrationClient.writeProducerId(image.nextProducerId(), migrationState));",
          "374:             }",
          "375:         } else {",
          "376:             operationConsumer.accept(UPDATE_PRODUCER_ID, \"Setting next producer ID\", migrationState ->",
          "377:                 migrationClient.writeProducerId(image.nextProducerId(), migrationState));",
          "378:         }",
          "381:     void handleConfigsDelta(ConfigurationsImage configsImage, ConfigurationsDelta configsDelta, KRaftMigrationOperationConsumer operationConsumer) {",
          "386:                 operationConsumer.accept(\"DeleteConfig\", \"Delete configs for \" + configResource, migrationState ->",
          "389:                 operationConsumer.accept(\"UpdateConfig\", \"Update configs for \" + configResource, migrationState ->",
          "395:     void handleClientQuotasDelta(MetadataImage metadataImage, MetadataDelta metadataDelta, KRaftMigrationOperationConsumer operationConsumer) {",
          "",
          "---------------",
          "--- Hunk 16 ---",
          "[Context before]",
          "361:                         users.add(userName);",
          "362:                     } else {",
          "363:                         Map<String, Double> quotaMap = metadataImage.clientQuotas().entities().get(clientQuotaEntity).quotaMap();",
          "365:                             migrationClient.configClient().writeClientQuotas(clientQuotaEntity.entries(), quotaMap, Collections.emptyMap(), migrationState));",
          "366:                     }",
          "367:                 });",
          "",
          "[Removed Lines]",
          "364:                         operationConsumer.accept(\"Updating client quota \" + clientQuotaEntity, migrationState ->",
          "",
          "[Added Lines]",
          "418:                         operationConsumer.accept(UPDATE_CLIENT_QUOTA, \"Updating client quota \" + clientQuotaEntity, migrationState ->",
          "",
          "---------------",
          "--- Hunk 17 ---",
          "[Context before]",
          "373:                 ClientQuotaEntity clientQuotaEntity = new ClientQuotaEntity(Collections.singletonMap(ClientQuotaEntity.USER, userName));",
          "374:                 if ((metadataImage.clientQuotas() == null) ||",
          "375:                     (metadataImage.clientQuotas().entities().get(clientQuotaEntity) == null)) {",
          "377:                         migrationClient.configClient().writeClientQuotas(clientQuotaEntity.entries(), Collections.emptyMap(), userScramMap, migrationState));",
          "378:                 } else {",
          "379:                     Map<String, Double> quotaMap = metadataImage.clientQuotas().entities().get(clientQuotaEntity).quotaMap();",
          "381:                         migrationClient.configClient().writeClientQuotas(clientQuotaEntity.entries(), quotaMap, userScramMap, migrationState));",
          "382:                 }",
          "383:             });",
          "384:         }",
          "385:     }",
          "387:     private ResourcePattern resourcePatternFromAcl(StandardAcl acl) {",
          "388:         return new ResourcePattern(acl.resourceType(), acl.resourceName(), acl.patternType());",
          "389:     }",
          "393:         Map<ResourcePattern, Set<AccessControlEntry>> allAclsInSnapshot = new HashMap<>();",
          "",
          "[Removed Lines]",
          "376:                     operationConsumer.accept(\"Updating client quota \" + clientQuotaEntity, migrationState ->",
          "380:                     operationConsumer.accept(\"Updating client quota \" + clientQuotaEntity, migrationState ->",
          "391:     void handleAclsSnapshot(AclsImage image) {",
          "",
          "[Added Lines]",
          "430:                     operationConsumer.accept(UPDATE_CLIENT_QUOTA, \"Updating scram credentials for \" + clientQuotaEntity, migrationState ->",
          "434:                     operationConsumer.accept(UPDATE_CLIENT_QUOTA, \"Updating client quota for \" + clientQuotaEntity, migrationState ->",
          "441:     void handleProducerIdDelta(ProducerIdsDelta delta, KRaftMigrationOperationConsumer operationConsumer) {",
          "442:         operationConsumer.accept(UPDATE_PRODUCER_ID, \"Setting next producer ID\", migrationState ->",
          "443:             migrationClient.writeProducerId(delta.nextProducerId(), migrationState));",
          "444:     }",
          "450:     void handleAclsSnapshot(AclsImage image, KRaftMigrationOperationConsumer operationConsumer) {",
          "",
          "---------------",
          "--- Hunk 18 ---",
          "[Context before]",
          "417:         newResources.forEach(resourcePattern -> {",
          "418:             Set<AccessControlEntry> accessControlEntries = allAclsInSnapshot.get(resourcePattern);",
          "419:             String name = \"Writing \" + accessControlEntries.size() + \" for resource \" + resourcePattern;",
          "421:                 migrationClient.aclClient().writeResourceAcls(resourcePattern, accessControlEntries, migrationState));",
          "422:         });",
          "424:         resourcesToDelete.forEach(deletedResource -> {",
          "425:             String name = \"Deleting resource \" + deletedResource + \" which has no ACLs in snapshot\";",
          "427:                 migrationClient.aclClient().deleteResource(deletedResource, migrationState));",
          "428:         });",
          "430:         changedResources.forEach((resourcePattern, accessControlEntries) -> {",
          "431:             String name = \"Writing \" + accessControlEntries.size() + \" for resource \" + resourcePattern;",
          "433:                 migrationClient.aclClient().writeResourceAcls(resourcePattern, accessControlEntries, migrationState));",
          "434:         });",
          "435:     }",
          "439:         Set<ResourcePattern> resourcesWithChangedAcls = delta.changes().values()",
          "440:             .stream()",
          "",
          "[Removed Lines]",
          "420:             operationConsumer.accept(name, migrationState ->",
          "426:             operationConsumer.accept(name, migrationState ->",
          "432:             operationConsumer.accept(name, migrationState ->",
          "437:     void handleAclsDelta(AclsImage image, AclsDelta delta) {",
          "",
          "[Added Lines]",
          "479:             operationConsumer.accept(UPDATE_ACL, name, migrationState ->",
          "485:             operationConsumer.accept(DELETE_ACL, name, migrationState ->",
          "491:             operationConsumer.accept(UPDATE_ACL, name, migrationState ->",
          "496:     void handleAclsDelta(AclsImage image, AclsDelta delta, KRaftMigrationOperationConsumer operationConsumer) {",
          "",
          "---------------",
          "--- Hunk 19 ---",
          "[Context before]",
          "464:         resourcesWithDeletedAcls.forEach(deletedResource -> {",
          "465:             String name = \"Deleting resource \" + deletedResource + \" which has no more ACLs\";",
          "467:                 migrationClient.aclClient().deleteResource(deletedResource, migrationState));",
          "468:         });",
          "470:         aclsToWrite.forEach((resourcePattern, accessControlEntries) -> {",
          "471:             String name = \"Writing \" + accessControlEntries.size() + \" for resource \" + resourcePattern;",
          "473:                 migrationClient.aclClient().writeResourceAcls(resourcePattern, accessControlEntries, migrationState));",
          "474:         });",
          "475:     }",
          "",
          "[Removed Lines]",
          "466:             operationConsumer.accept(name, migrationState ->",
          "472:             operationConsumer.accept(name, migrationState ->",
          "",
          "[Added Lines]",
          "525:             operationConsumer.accept(DELETE_ACL, name, migrationState ->",
          "531:             operationConsumer.accept(UPDATE_ACL, name, migrationState ->",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/migration/MigrationClient.java||metadata/src/main/java/org/apache/kafka/metadata/migration/MigrationClient.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/migration/MigrationClient.java -> metadata/src/main/java/org/apache/kafka/metadata/migration/MigrationClient.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: package org.apache.kafka.metadata.migration;",
          "19: import org.apache.kafka.server.common.ApiMessageAndVersion;",
          "21: import java.util.List;",
          "22: import java.util.Set;",
          "23: import java.util.function.Consumer;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "20: import org.apache.kafka.server.common.ProducerIdsBlock;",
          "23: import java.util.Optional;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "75:     AclMigrationClient aclClient();",
          "77:     ZkMigrationLeadershipState writeProducerId(",
          "78:         long nextProducerId,",
          "79:         ZkMigrationLeadershipState state",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "79:     Optional<ProducerIdsBlock> readProducerId();",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/migration/MigrationDriverState.java||metadata/src/main/java/org/apache/kafka/metadata/migration/MigrationDriverState.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/migration/MigrationDriverState.java -> metadata/src/main/java/org/apache/kafka/metadata/migration/MigrationDriverState.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "44:     WAIT_FOR_CONTROLLER_QUORUM(false),     // Ensure all the quorum nodes are ready for migration.",
          "45:     WAIT_FOR_BROKERS(false),                // Wait for Zk brokers to be ready for migration.",
          "46:     BECOME_CONTROLLER(false),              // Become controller for the Zk Brokers.",
          "48:     KRAFT_CONTROLLER_TO_BROKER_COMM(true), // First communication from Controller to send full RPCs to the Zk brokers.",
          "49:     DUAL_WRITE(true);                      // The data has been migrated",
          "55:     }",
          "59:     }",
          "60: }",
          "",
          "[Removed Lines]",
          "47:     ZK_MIGRATION(true),                    // The cluster has satisfied the migration criteria",
          "51:     private final boolean isActiveController;",
          "53:     MigrationDriverState(boolean isActiveController) {",
          "54:         this.isActiveController = isActiveController;",
          "57:     boolean isActiveController() {",
          "58:         return isActiveController;",
          "",
          "[Added Lines]",
          "47:     ZK_MIGRATION(false),                   // The cluster has satisfied the migration criteria",
          "48:     SYNC_KRAFT_TO_ZK(false),               // A full sync of metadata from KRaft to ZK.",
          "52:     private final boolean allowDualWrite;",
          "54:     MigrationDriverState(boolean allowDualWrite) {",
          "55:         this.allowDualWrite = allowDualWrite;",
          "58:     boolean allowDualWrite() {",
          "59:         return allowDualWrite;",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/migration/ZkMigrationLeadershipState.java||metadata/src/main/java/org/apache/kafka/metadata/migration/ZkMigrationLeadershipState.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/migration/ZkMigrationLeadershipState.java -> metadata/src/main/java/org/apache/kafka/metadata/migration/ZkMigrationLeadershipState.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "130:         return zkControllerEpochZkVersion;",
          "131:     }",
          "134:         return kraftMetadataOffset > 0;",
          "135:     }",
          "",
          "[Removed Lines]",
          "133:     public boolean zkMigrationComplete() {",
          "",
          "[Added Lines]",
          "133:     public boolean initialZkMigrationComplete() {",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "149:             return",
          "150:                 this.kraftControllerId != other.kraftControllerId ||",
          "151:                 this.kraftControllerEpoch != other.kraftControllerEpoch ||",
          "153:         }",
          "154:     }",
          "",
          "[Removed Lines]",
          "152:                 (!other.zkMigrationComplete() && this.zkMigrationComplete());",
          "",
          "[Added Lines]",
          "152:                 (!other.initialZkMigrationComplete() && this.initialZkMigrationComplete());",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/image/AclsImageTest.java||metadata/src/test/java/org/apache/kafka/image/AclsImageTest.java": [
          "File: metadata/src/test/java/org/apache/kafka/image/AclsImageTest.java -> metadata/src/test/java/org/apache/kafka/image/AclsImageTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "40: @Timeout(value = 40)",
          "41: public class AclsImageTest {",
          "46:     final static AclsDelta DELTA1;",
          "",
          "[Removed Lines]",
          "42:     final static AclsImage IMAGE1;",
          "44:     final static List<ApiMessageAndVersion> DELTA1_RECORDS;",
          "",
          "[Added Lines]",
          "42:     public final static AclsImage IMAGE1;",
          "44:     public final static List<ApiMessageAndVersion> DELTA1_RECORDS;",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/image/ClientQuotasImageTest.java||metadata/src/test/java/org/apache/kafka/image/ClientQuotasImageTest.java": [
          "File: metadata/src/test/java/org/apache/kafka/image/ClientQuotasImageTest.java -> metadata/src/test/java/org/apache/kafka/image/ClientQuotasImageTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "41: @Timeout(value = 40)",
          "42: public class ClientQuotasImageTest {",
          "47:     final static ClientQuotasDelta DELTA1;",
          "",
          "[Removed Lines]",
          "43:     final static ClientQuotasImage IMAGE1;",
          "45:     final static List<ApiMessageAndVersion> DELTA1_RECORDS;",
          "",
          "[Added Lines]",
          "43:     public final static ClientQuotasImage IMAGE1;",
          "45:     public final static List<ApiMessageAndVersion> DELTA1_RECORDS;",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/image/ConfigurationsImageTest.java||metadata/src/test/java/org/apache/kafka/image/ConfigurationsImageTest.java": [
          "File: metadata/src/test/java/org/apache/kafka/image/ConfigurationsImageTest.java -> metadata/src/test/java/org/apache/kafka/image/ConfigurationsImageTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "39: @Timeout(value = 40)",
          "40: public class ConfigurationsImageTest {",
          "45:     final static ConfigurationsDelta DELTA1;",
          "",
          "[Removed Lines]",
          "41:     final static ConfigurationsImage IMAGE1;",
          "43:     final static List<ApiMessageAndVersion> DELTA1_RECORDS;",
          "",
          "[Added Lines]",
          "41:     public final static ConfigurationsImage IMAGE1;",
          "43:     public final static List<ApiMessageAndVersion> DELTA1_RECORDS;",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/image/FeaturesImageTest.java||metadata/src/test/java/org/apache/kafka/image/FeaturesImageTest.java": [
          "File: metadata/src/test/java/org/apache/kafka/image/FeaturesImageTest.java -> metadata/src/test/java/org/apache/kafka/image/FeaturesImageTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "41: @Timeout(value = 40)",
          "42: public class FeaturesImageTest {",
          "45:     final static FeaturesDelta DELTA1;",
          "46:     final static FeaturesImage IMAGE2;",
          "",
          "[Removed Lines]",
          "43:     final static FeaturesImage IMAGE1;",
          "44:     final static List<ApiMessageAndVersion> DELTA1_RECORDS;",
          "",
          "[Added Lines]",
          "43:     public final static FeaturesImage IMAGE1;",
          "44:     public final static List<ApiMessageAndVersion> DELTA1_RECORDS;",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/image/ProducerIdsImageTest.java||metadata/src/test/java/org/apache/kafka/image/ProducerIdsImageTest.java": [
          "File: metadata/src/test/java/org/apache/kafka/image/ProducerIdsImageTest.java -> metadata/src/test/java/org/apache/kafka/image/ProducerIdsImageTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "34: @Timeout(value = 40)",
          "35: public class ProducerIdsImageTest {",
          "38:     final static List<ApiMessageAndVersion> DELTA1_RECORDS;",
          "",
          "[Removed Lines]",
          "36:     final static ProducerIdsImage IMAGE1;",
          "",
          "[Added Lines]",
          "36:     public final static ProducerIdsImage IMAGE1;",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/image/ScramImageTest.java||metadata/src/test/java/org/apache/kafka/image/ScramImageTest.java": [
          "File: metadata/src/test/java/org/apache/kafka/image/ScramImageTest.java -> metadata/src/test/java/org/apache/kafka/image/ScramImageTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "45: @Timeout(value = 40)",
          "46: public class ScramImageTest {",
          "51:     final static ScramDelta DELTA1;",
          "",
          "[Removed Lines]",
          "47:     final static ScramImage IMAGE1;",
          "49:     final static List<ApiMessageAndVersion> DELTA1_RECORDS;",
          "",
          "[Added Lines]",
          "47:     public final static ScramImage IMAGE1;",
          "49:     public final static List<ApiMessageAndVersion> DELTA1_RECORDS;",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/image/TopicsImageTest.java||metadata/src/test/java/org/apache/kafka/image/TopicsImageTest.java": [
          "File: metadata/src/test/java/org/apache/kafka/image/TopicsImageTest.java -> metadata/src/test/java/org/apache/kafka/image/TopicsImageTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "91:         return map;",
          "92:     }",
          "96:     private static final Uuid BAR_UUID = Uuid.fromString(\"f62ptyETTjet8SL5ZeREiw\");",
          "",
          "[Removed Lines]",
          "94:     private static final Uuid FOO_UUID = Uuid.fromString(\"ThIaNwRnSM2Nt9Mx1v0RvA\");",
          "",
          "[Added Lines]",
          "94:     public static final Uuid FOO_UUID = Uuid.fromString(\"ThIaNwRnSM2Nt9Mx1v0RvA\");",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingMigrationClient.java||metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingMigrationClient.java": [
          "File: metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingMigrationClient.java -> metadata/src/test/java/org/apache/kafka/metadata/migration/CapturingMigrationClient.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: package org.apache.kafka.metadata.migration;",
          "20: import org.apache.kafka.server.common.ApiMessageAndVersion;",
          "22: import java.util.Collections;",
          "23: import java.util.List;",
          "24: import java.util.Set;",
          "25: import java.util.function.Consumer;",
          "26: import java.util.stream.Collectors;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "21: import org.apache.kafka.server.common.ProducerIdsBlock;",
          "25: import java.util.Optional;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "53:             return this;",
          "54:         }",
          "56:         public CapturingMigrationClient build() {",
          "57:             return new CapturingMigrationClient(",
          "58:                 brokersInZk,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "58:         public Builder setAclMigrationClient(AclMigrationClient aclMigrationClient) {",
          "59:             this.aclMigrationClient = aclMigrationClient;",
          "60:             return this;",
          "61:         }",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "124:         return aclMigrationClient;",
          "125:     }",
          "127:     @Override",
          "128:     public ZkMigrationLeadershipState writeProducerId(",
          "129:         long nextProducerId,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "134:     @Override",
          "135:     public Optional<ProducerIdsBlock> readProducerId() {",
          "136:         return Optional.empty();",
          "137:     }",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationDriverTest.java||metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationDriverTest.java": [
          "File: metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationDriverTest.java -> metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationDriverTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "69: import java.util.stream.Collectors;",
          "70: import java.util.stream.IntStream;",
          "72: import static org.apache.kafka.image.TopicsImageTest.DELTA1_RECORDS;",
          "73: import static org.apache.kafka.image.TopicsImageTest.IMAGE1;",
          "74: import static org.junit.jupiter.api.Assertions.assertEquals;",
          "75: import static org.junit.jupiter.api.Assertions.assertTrue;",
          "80: public class KRaftMigrationDriverTest {",
          "81:     List<Node> controllerNodes = Arrays.asList(",
          "82:         new Node(4, \"host4\", 0),",
          "",
          "[Removed Lines]",
          "77: import static java.util.concurrent.TimeUnit.MILLISECONDS;",
          "78: import static java.util.concurrent.TimeUnit.NANOSECONDS;",
          "",
          "[Added Lines]",
          "72: import static java.util.concurrent.TimeUnit.MILLISECONDS;",
          "73: import static java.util.concurrent.TimeUnit.NANOSECONDS;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "274:     public void testMigrationWithClientException(boolean authException) throws Exception {",
          "275:         CountingMetadataPropagator metadataPropagator = new CountingMetadataPropagator();",
          "276:         CountDownLatch claimLeaderAttempts = new CountDownLatch(3);",
          "278:             @Override",
          "279:             public ZkMigrationLeadershipState claimControllerLeadership(ZkMigrationLeadershipState state) {",
          "280:                 if (claimLeaderAttempts.getCount() == 0) {",
          "",
          "[Removed Lines]",
          "277:         CapturingMigrationClient migrationClient = new CapturingMigrationClient(new HashSet<>(Arrays.asList(1, 2, 3)), new CapturingTopicMigrationClient(), null, null) {",
          "",
          "[Added Lines]",
          "276:         CapturingMigrationClient migrationClient = new CapturingMigrationClient(new HashSet<>(Arrays.asList(1, 2, 3)),",
          "277:                 new CapturingTopicMigrationClient(), new CapturingConfigMigrationClient(), new CapturingAclMigrationClient()) {",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "369:             apiVersions.update(\"6\", NodeApiVersions.create());",
          "373:             apiVersions.update(\"6\", new NodeApiVersions(Collections.emptyList(), Collections.emptyList(), true));",
          "",
          "[Removed Lines]",
          "370:             driver.migrationState().get(1, TimeUnit.MINUTES).equals(MigrationDriverState.WAIT_FOR_CONTROLLER_QUORUM);",
          "",
          "[Added Lines]",
          "370:             assertEquals(MigrationDriverState.WAIT_FOR_CONTROLLER_QUORUM, driver.migrationState().get(1, TimeUnit.MINUTES));",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "379:     @Test",
          "380:     public void testSkipWaitForBrokersInDualWrite() throws Exception {",
          "381:         CountingMetadataPropagator metadataPropagator = new CountingMetadataPropagator();",
          "383:         MockFaultHandler faultHandler = new MockFaultHandler(\"testMigrationClientExpiration\");",
          "384:         try (KRaftMigrationDriver driver = new KRaftMigrationDriver(",
          "385:                 3000,",
          "",
          "[Removed Lines]",
          "382:         CapturingMigrationClient migrationClient = new CapturingMigrationClient(Collections.emptySet(), null, null, null);",
          "",
          "[Added Lines]",
          "382:         CapturingMigrationClient migrationClient = new CapturingMigrationClient(Collections.emptySet(),",
          "383:             new CapturingTopicMigrationClient(), new CapturingConfigMigrationClient(), new CapturingAclMigrationClient());",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "420:     interface TopicDualWriteVerifier {",
          "421:         void verify(",
          "422:             KRaftMigrationDriver driver,",
          "423:             CapturingTopicMigrationClient topicClient,",
          "424:             CapturingConfigMigrationClient configClient",
          "425:         ) throws Exception;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "424:             CapturingMigrationClient migrationClient,",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "461:             quorumFeatures,",
          "462:             mockTime",
          "463:         )) {",
          "465:         }",
          "466:     }",
          "468:     @Test",
          "469:     public void testTopicDualWriteSnapshot() throws Exception {",
          "471:             MetadataImage image = new MetadataImage(",
          "472:                 MetadataProvenance.EMPTY,",
          "473:                 FeaturesImage.EMPTY,",
          "",
          "[Removed Lines]",
          "464:             verifier.verify(driver, topicClient, configClient);",
          "470:         setupTopicDualWrite((driver, topicClient, configClient) -> {",
          "",
          "[Added Lines]",
          "466:             verifier.verify(driver, migrationClient, topicClient, configClient);",
          "472:         setupTopicDualWrite((driver, migrationClient, topicClient, configClient) -> {",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "520:     @Test",
          "521:     public void testTopicDualWriteDelta() throws Exception {",
          "523:             MetadataImage image = new MetadataImage(",
          "524:                 MetadataProvenance.EMPTY,",
          "525:                 FeaturesImage.EMPTY,",
          "",
          "[Removed Lines]",
          "522:         setupTopicDualWrite((driver, topicClient, configClient) -> {",
          "",
          "[Added Lines]",
          "524:         setupTopicDualWrite((driver, migrationClient, topicClient, configClient) -> {",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "568:             assertEquals(new ConfigResource(ConfigResource.Type.TOPIC, \"foo\"), configClient.deletedResources.get(0));",
          "569:         });",
          "570:     }",
          "571: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "574:     @Test",
          "575:     public void testControllerFailover() throws Exception {",
          "576:         setupTopicDualWrite((driver, migrationClient, topicClient, configClient) -> {",
          "577:             MetadataImage image = new MetadataImage(",
          "578:                 MetadataProvenance.EMPTY,",
          "579:                 FeaturesImage.EMPTY,",
          "580:                 ClusterImage.EMPTY,",
          "581:                 IMAGE1,",
          "582:                 ConfigurationsImage.EMPTY,",
          "583:                 ClientQuotasImage.EMPTY,",
          "584:                 ProducerIdsImage.EMPTY,",
          "585:                 AclsImage.EMPTY,",
          "586:                 ScramImage.EMPTY);",
          "587:             MetadataDelta delta = new MetadataDelta(image);",
          "589:             driver.start();",
          "590:             delta.replay(ZkMigrationState.PRE_MIGRATION.toRecord().message());",
          "591:             delta.replay(zkBrokerRecord(0));",
          "592:             delta.replay(zkBrokerRecord(1));",
          "593:             delta.replay(zkBrokerRecord(2));",
          "594:             delta.replay(zkBrokerRecord(3));",
          "595:             delta.replay(zkBrokerRecord(4));",
          "596:             delta.replay(zkBrokerRecord(5));",
          "597:             MetadataProvenance provenance = new MetadataProvenance(100, 1, 1);",
          "598:             image = delta.apply(provenance);",
          "601:             LeaderAndEpoch newLeader = new LeaderAndEpoch(OptionalInt.of(3001), 1);",
          "602:             driver.onControllerChange(newLeader);",
          "603:             driver.onMetadataUpdate(delta, image, new LogDeltaManifest(provenance, newLeader, 1, 100, 42));",
          "606:             migrationClient.setMigrationRecoveryState(",
          "607:                 ZkMigrationLeadershipState.EMPTY.withKRaftMetadataOffsetAndEpoch(100, 1));",
          "610:             provenance = new MetadataProvenance(200, 1, 1);",
          "611:             delta = new MetadataDelta(image);",
          "612:             RecordTestUtils.replayAll(delta, DELTA1_RECORDS);",
          "613:             image = delta.apply(provenance);",
          "616:             driver.onMetadataUpdate(delta, image, new LogDeltaManifest(provenance, newLeader, 1, 100, 42));",
          "619:             newLeader = new LeaderAndEpoch(OptionalInt.of(3000), 1);",
          "620:             driver.onControllerChange(newLeader);",
          "621:             TestUtils.waitForCondition(() -> driver.migrationState().get(1, TimeUnit.MINUTES).equals(MigrationDriverState.DUAL_WRITE),",
          "622:                 \"\");",
          "623:             assertEquals(1, topicClient.deletedTopics.size());",
          "624:             assertEquals(\"foo\", topicClient.deletedTopics.get(0));",
          "625:             assertEquals(1, topicClient.createdTopics.size());",
          "626:             assertEquals(\"baz\", topicClient.createdTopics.get(0));",
          "627:             assertTrue(topicClient.updatedTopicPartitions.get(\"bar\").contains(0));",
          "628:             assertEquals(new ConfigResource(ConfigResource.Type.TOPIC, \"foo\"), configClient.deletedResources.get(0));",
          "629:         });",
          "630:     }",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriterTest.java||metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriterTest.java": [
          "File: metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriterTest.java -> metadata/src/test/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriterTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "17: package org.apache.kafka.metadata.migration;",
          "19: import org.apache.kafka.common.config.ConfigResource;",
          "20: import org.apache.kafka.image.AclsImage;",
          "21: import org.apache.kafka.image.AclsImageTest;",
          "22: import org.apache.kafka.image.ClientQuotasImage;",
          "23: import org.apache.kafka.image.ClusterImage;",
          "24: import org.apache.kafka.image.ConfigurationsImage;",
          "25: import org.apache.kafka.image.ConfigurationsImageTest;",
          "26: import org.apache.kafka.image.FeaturesImage;",
          "27: import org.apache.kafka.image.MetadataImage;",
          "28: import org.apache.kafka.image.MetadataProvenance;",
          "29: import org.apache.kafka.image.ProducerIdsImage;",
          "30: import org.apache.kafka.image.ProducerIdsImageTest;",
          "31: import org.apache.kafka.image.ScramImage;",
          "32: import org.apache.kafka.image.TopicsImageTest;",
          "33: import org.junit.jupiter.api.Test;",
          "35: import java.util.Arrays;",
          "36: import java.util.EnumSet;",
          "37: import java.util.HashMap;",
          "38: import java.util.List;",
          "39: import java.util.Map;",
          "41: import static org.junit.jupiter.api.Assertions.assertEquals;",
          "42: import static org.junit.jupiter.api.Assertions.assertTrue;",
          "45: public class KRaftMigrationZkWriterTest {",
          "49:     @Test",
          "50:     public void testReconcileSnapshotEmptyZk() {",
          "53:         CapturingTopicMigrationClient topicClient = new CapturingTopicMigrationClient();",
          "54:         CapturingConfigMigrationClient configClient = new CapturingConfigMigrationClient();",
          "55:         CapturingAclMigrationClient aclClient = new CapturingAclMigrationClient();",
          "56:         CapturingMigrationClient migrationClient = CapturingMigrationClient.newBuilder()",
          "57:             .setBrokersInZk(0)",
          "58:             .setTopicMigrationClient(topicClient)",
          "59:             .setConfigMigrationClient(configClient)",
          "60:             .setAclMigrationClient(aclClient)",
          "61:             .build();",
          "63:         KRaftMigrationZkWriter writer = new KRaftMigrationZkWriter(migrationClient);",
          "65:         MetadataImage image = new MetadataImage(",
          "66:             MetadataProvenance.EMPTY,",
          "67:             FeaturesImage.EMPTY,        // Features are not used in ZK mode, so we don't migrate or dual-write them",
          "68:             ClusterImage.EMPTY,         // Broker registrations are not dual-written",
          "69:             TopicsImageTest.IMAGE1,",
          "70:             ConfigurationsImageTest.IMAGE1,",
          "71:             ClientQuotasImage.EMPTY,    // TODO KAFKA-15017",
          "72:             ProducerIdsImageTest.IMAGE1,",
          "73:             AclsImageTest.IMAGE1,",
          "74:             ScramImage.EMPTY            // TODO KAFKA-15017",
          "75:         );",
          "77:         Map<String, Integer> opCounts = new HashMap<>();",
          "78:         KRaftMigrationOperationConsumer consumer = KRaftMigrationDriver.countingOperationConsumer(opCounts,",
          "79:             (logMsg, operation) -> operation.apply(ZkMigrationLeadershipState.EMPTY));",
          "80:         writer.handleSnapshot(image, consumer);",
          "81:         assertEquals(2, opCounts.remove(\"CreateTopic\"));",
          "82:         assertEquals(2, opCounts.remove(\"UpdateBrokerConfig\"));",
          "83:         assertEquals(1, opCounts.remove(\"UpdateProducerId\"));",
          "84:         assertEquals(4, opCounts.remove(\"UpdateAcl\"));",
          "85:         assertEquals(0, opCounts.size());",
          "87:         assertEquals(2, topicClient.createdTopics.size());",
          "88:         assertTrue(topicClient.createdTopics.contains(\"foo\"));",
          "89:         assertTrue(topicClient.createdTopics.contains(\"bar\"));",
          "90:         assertEquals(\"bar\", configClient.writtenConfigs.get(new ConfigResource(ConfigResource.Type.BROKER, \"0\")).get(\"foo\"));",
          "91:         assertEquals(\"quux\", configClient.writtenConfigs.get(new ConfigResource(ConfigResource.Type.BROKER, \"0\")).get(\"baz\"));",
          "92:         assertEquals(\"foobaz\", configClient.writtenConfigs.get(new ConfigResource(ConfigResource.Type.BROKER, \"1\")).get(\"foobar\"));",
          "93:         assertEquals(4, aclClient.updatedResources.size());",
          "94:     }",
          "99:     @Test",
          "100:     public void testReconcileSnapshotTopics() {",
          "101:         CapturingTopicMigrationClient topicClient = new CapturingTopicMigrationClient() {",
          "102:             @Override",
          "103:             public void iterateTopics(EnumSet<TopicVisitorInterest> interests, TopicVisitor visitor) {",
          "104:                 Map<Integer, List<Integer>> assignments = new HashMap<>();",
          "105:                 assignments.put(0, Arrays.asList(2, 3, 4));",
          "106:                 assignments.put(1, Arrays.asList(3, 4, 5));",
          "107:                 assignments.put(2, Arrays.asList(2, 4, 5));",
          "108:                 visitor.visitTopic(\"foo\", TopicsImageTest.FOO_UUID, assignments);",
          "109:             }",
          "110:         };",
          "112:         CapturingConfigMigrationClient configClient = new CapturingConfigMigrationClient();",
          "113:         CapturingAclMigrationClient aclClient = new CapturingAclMigrationClient();",
          "114:         CapturingMigrationClient migrationClient = CapturingMigrationClient.newBuilder()",
          "115:             .setBrokersInZk(0)",
          "116:             .setTopicMigrationClient(topicClient)",
          "117:             .setConfigMigrationClient(configClient)",
          "118:             .setAclMigrationClient(aclClient)",
          "119:             .build();",
          "121:         KRaftMigrationZkWriter writer = new KRaftMigrationZkWriter(migrationClient);",
          "123:         MetadataImage image = new MetadataImage(",
          "124:             MetadataProvenance.EMPTY,",
          "125:             FeaturesImage.EMPTY,",
          "126:             ClusterImage.EMPTY,",
          "127:             TopicsImageTest.IMAGE1,     // Two topics, foo and bar",
          "128:             ConfigurationsImage.EMPTY,",
          "129:             ClientQuotasImage.EMPTY,",
          "130:             ProducerIdsImage.EMPTY,",
          "131:             AclsImage.EMPTY,",
          "132:             ScramImage.EMPTY",
          "133:         );",
          "135:         Map<String, Integer> opCounts = new HashMap<>();",
          "136:         KRaftMigrationOperationConsumer consumer = KRaftMigrationDriver.countingOperationConsumer(opCounts,",
          "137:             (logMsg, operation) -> operation.apply(ZkMigrationLeadershipState.EMPTY));",
          "138:         writer.handleSnapshot(image, consumer);",
          "139:         assertEquals(1, opCounts.remove(\"CreateTopic\"));",
          "140:         assertEquals(0, opCounts.size());",
          "141:         assertEquals(\"bar\", topicClient.createdTopics.get(0));",
          "142:     }",
          "143: }",
          "",
          "---------------"
        ],
        "tests/kafkatest/services/zookeeper.py||tests/kafkatest/services/zookeeper.py": [
          "File: tests/kafkatest/services/zookeeper.py -> tests/kafkatest/services/zookeeper.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "203:                     result = match.groups()[0]",
          "204:         return result",
          "206:     def create(self, path, chroot=None, value=\"\"):",
          "207:         \"\"\"",
          "208:         Create an znode at the given path",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "206:     def get_children(self, path, chroot=None):",
          "207:         \"\"\"",
          "208:         Queries zookeeper for data associated with 'path' and returns all fields in the schema",
          "209:         \"\"\"",
          "210:         self._check_chroot(chroot)",
          "212:         chroot_path = ('' if chroot is None else chroot) + path",
          "214:         kafka_run_class = self.path.script(\"kafka-run-class.sh\", DEV_BRANCH)",
          "215:         cmd = \"%s %s -server %s %s ls %s\" % \\",
          "216:               (kafka_run_class, self.java_cli_class_name(), self.connect_setting(force_tls=self.zk_client_secure_port),",
          "217:                self.zkTlsConfigFileOption(True),",
          "218:                chroot_path)",
          "219:         self.logger.debug(cmd)",
          "221:         node = self.nodes[0]",
          "222:         result = None",
          "223:         for line in node.account.ssh_capture(cmd, allow_fail=True):",
          "224:             # loop through all lines in the output, but only hold on to the first match",
          "225:             if result is None:",
          "226:                 match = re.match(\"^(\\\\[.+\\\\])$\", line)",
          "227:                 if match is not None:",
          "228:                     result = match.groups()[0]",
          "229:         if result is None:",
          "230:             return []",
          "231:         else:",
          "232:             return result.strip(\"[]\").split(\", \")",
          "234:     def delete(self, path, recursive, chroot=None):",
          "235:         \"\"\"",
          "236:         Queries zookeeper for data associated with 'path' and returns all fields in the schema",
          "237:         \"\"\"",
          "238:         self._check_chroot(chroot)",
          "240:         chroot_path = ('' if chroot is None else chroot) + path",
          "242:         kafka_run_class = self.path.script(\"kafka-run-class.sh\", DEV_BRANCH)",
          "243:         if recursive:",
          "244:             op = \"deleteall\"",
          "245:         else:",
          "246:             op = \"delete\"",
          "247:         cmd = \"%s %s -server %s %s %s %s\" % \\",
          "248:               (kafka_run_class, self.java_cli_class_name(), self.connect_setting(force_tls=self.zk_client_secure_port),",
          "249:                self.zkTlsConfigFileOption(True),",
          "250:                op, chroot_path)",
          "251:         self.logger.debug(cmd)",
          "253:         node = self.nodes[0]",
          "254:         node.account.ssh_capture(cmd)",
          "",
          "---------------"
        ],
        "tests/kafkatest/tests/core/zookeeper_migration_test.py||tests/kafkatest/tests/core/zookeeper_migration_test.py": [
          "File: tests/kafkatest/tests/core/zookeeper_migration_test.py -> tests/kafkatest/tests/core/zookeeper_migration_test.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "50:             wait_until(lambda: len(self.kafka.isr_idx_list(self.topic, partition)) == self.replication_factor, timeout_sec=60,",
          "51:                        backoff_sec=1, err_msg=\"Replicas did not rejoin the ISR in a reasonable amount of time\")",
          "54:         # Start up KRaft controller in migration mode",
          "55:         remote_quorum = partial(ServiceQuorumInfo, isolated_kraft)",
          "56:         controller = KafkaService(self.test_context, num_nodes=1, zk=self.zk, version=DEV_BRANCH,",
          "",
          "[Removed Lines]",
          "53:     def do_migration(self):",
          "",
          "[Added Lines]",
          "53:     def do_migration(self, roll_controller = False, downgrade_to_zk = False):",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "78:             self.kafka.start_node(node)",
          "79:             self.wait_until_rejoin()",
          "82:         zk_quorum = partial(ServiceQuorumInfo, zk)",
          "83:         self.zk = ZookeeperService(self.test_context, num_nodes=1, version=DEV_BRANCH)",
          "84:         self.kafka = KafkaService(self.test_context,",
          "",
          "[Removed Lines]",
          "81:     def test_online_migration(self):",
          "",
          "[Added Lines]",
          "81:         if roll_controller:",
          "82:             self.logger.info(\"Restarting KRaft quorum\")",
          "83:             for node in controller.nodes:",
          "84:                 controller.stop_node(node)",
          "85:                 controller.start_node(node)",
          "87:     @parametrize(roll_controller = True)",
          "88:     @parametrize(roll_controller = False)",
          "89:     def test_online_migration(self, roll_controller):",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "116:                                         self.topic, consumer_timeout_ms=30000,",
          "117:                                         message_validator=is_int, version=DEV_BRANCH)",
          "120:         self.kafka.stop()",
          "122:     @parametrize(metadata_quorum=isolated_kraft)",
          "",
          "[Removed Lines]",
          "119:         self.run_produce_consume_validate(core_test_action=self.do_migration)",
          "",
          "[Added Lines]",
          "127:         self.run_produce_consume_validate(core_test_action=partial(self.do_migration, roll_controller = roll_controller))",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "164:         # Check the controller's logs for the error message about the migration state",
          "165:         saw_expected_error = False",
          "166:         for node in self.kafka.controller_quorum.nodes:",
          "169:             with node.account.monitor_log(KafkaService.STDOUT_STDERR_CAPTURE) as monitor:",
          "170:                 monitor.offset = 0",
          "171:                 try:",
          "",
          "[Removed Lines]",
          "167:             wait_until(lambda: not self.kafka.controller_quorum.alive(node), timeout_sec=60,",
          "168:                        backoff_sec=1, err_msg=\"Controller did not halt in the expected amount of time\")",
          "",
          "[Added Lines]",
          "174:         self.logger.info(\"Waiting for controller to crash\")",
          "176:         for node in self.kafka.nodes:",
          "177:             self.kafka.stop_node(node, clean_shutdown=False)",
          "179:         for node in self.kafka.controller_quorum.nodes:",
          "180:             self.kafka.controller_quorum.stop_node(node, clean_shutdown=False)",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "257:         assert saw_expected_log, \"Did not see expected INFO log after upgrading from a 3.4 migration\"",
          "258:         self.kafka.stop()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "274:     def test_reconcile_kraft_to_zk(self):",
          "275:         \"\"\"",
          "276:         Perform a migration and delete a topic directly from ZK. Ensure that the topic is added back",
          "277:         by KRaft during a failover. This exercises the snapshot reconciliation.",
          "278:         \"\"\"",
          "279:         zk_quorum = partial(ServiceQuorumInfo, zk)",
          "280:         self.zk = ZookeeperService(self.test_context, num_nodes=1, version=DEV_BRANCH)",
          "281:         self.kafka = KafkaService(self.test_context,",
          "282:                                   num_nodes=3,",
          "283:                                   zk=self.zk,",
          "284:                                   version=DEV_BRANCH,",
          "285:                                   quorum_info_provider=zk_quorum,",
          "286:                                   allow_zk_with_kraft=True,",
          "287:                                   server_prop_overrides=[[\"zookeeper.metadata.migration.enable\", \"false\"]])",
          "289:         remote_quorum = partial(ServiceQuorumInfo, isolated_kraft)",
          "290:         controller = KafkaService(self.test_context, num_nodes=1, zk=self.zk, version=DEV_BRANCH,",
          "291:                                   allow_zk_with_kraft=True,",
          "292:                                   isolated_kafka=self.kafka,",
          "293:                                   server_prop_overrides=[[\"zookeeper.connect\", self.zk.connect_setting()],",
          "294:                                                          [\"zookeeper.metadata.migration.enable\", \"true\"]],",
          "295:                                   quorum_info_provider=remote_quorum)",
          "297:         self.kafka.security_protocol = \"PLAINTEXT\"",
          "298:         self.kafka.interbroker_security_protocol = \"PLAINTEXT\"",
          "299:         self.zk.start()",
          "300:         self.logger.info(\"Pre-generating clusterId for ZK.\")",
          "301:         cluster_id_json = \"\"\"{\"version\": \"1\", \"id\": \"%s\"}\"\"\" % CLUSTER_ID",
          "302:         self.zk.create(path=\"/cluster\")",
          "303:         self.zk.create(path=\"/cluster/id\", value=cluster_id_json)",
          "304:         self.kafka.start()",
          "306:         topic_cfg = {",
          "307:             \"topic\": self.topic,",
          "308:             \"partitions\": self.partitions,",
          "309:             \"replication-factor\": self.replication_factor,",
          "310:             \"configs\": {\"min.insync.replicas\": 2}",
          "311:         }",
          "312:         self.kafka.create_topic(topic_cfg)",
          "314:         # Create topics in ZK mode",
          "315:         for i in range(10):",
          "316:             topic_cfg = {",
          "317:                 \"topic\": f\"zk-topic-{i}\",",
          "318:                 \"partitions\": self.partitions,",
          "319:                 \"replication-factor\": self.replication_factor,",
          "320:                 \"configs\": {\"min.insync.replicas\": 2}",
          "321:             }",
          "322:             self.kafka.create_topic(topic_cfg)",
          "324:         controller.start()",
          "325:         self.kafka.reconfigure_zk_for_migration(controller)",
          "326:         for node in self.kafka.nodes:",
          "327:             self.kafka.stop_node(node)",
          "328:             self.kafka.start_node(node)",
          "329:             self.wait_until_rejoin()",
          "331:         # Check the controller's logs for the INFO message that we're done with migration",
          "332:         saw_expected_log = False",
          "333:         for node in self.kafka.controller_quorum.nodes:",
          "334:             with node.account.monitor_log(KafkaService.STDOUT_STDERR_CAPTURE) as monitor:",
          "335:                 monitor.offset = 0",
          "336:                 try:",
          "337:                     # Shouldn't have to wait too long to see this log message after startup",
          "338:                     monitor.wait_until(",
          "339:                         \"Finished initial migration of ZK metadata to KRaft\",",
          "340:                         timeout_sec=10.0, backoff_sec=.25,",
          "341:                         err_msg=\"\"",
          "342:                     )",
          "343:                     saw_expected_log = True",
          "344:                     break",
          "345:                 except TimeoutError:",
          "346:                     continue",
          "348:         assert saw_expected_log, \"Did not see expected INFO log after migration\"",
          "350:         # Manually delete a topic from ZK to simulate a missed dual-write",
          "351:         self.zk.delete(path=\"/brokers/topics/zk-topic-0\", recursive=True)",
          "353:         # Roll the controller nodes to force a failover, this causes a snapshot reconciliation",
          "354:         for node in controller.nodes:",
          "355:             controller.stop_node(node)",
          "356:             controller.start_node(node)",
          "358:         def topic_in_zk():",
          "359:             topics_in_zk = self.zk.get_children(path=\"/brokers/topics\")",
          "360:             return \"zk-topic-0\" in topics_in_zk",
          "362:         wait_until(topic_in_zk, timeout_sec=60,",
          "363:             backoff_sec=1, err_msg=\"Topic did not appear in ZK in time.\")",
          "365:         self.kafka.stop()",
          "366:         controller.stop()",
          "367:         self.zk.stop()",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "731c8c967e04ffe212e8b4d8ea15e67f22a60e65",
      "candidate_info": {
        "commit_hash": "731c8c967e04ffe212e8b4d8ea15e67f22a60e65",
        "repo": "apache/kafka",
        "commit_url": "https://github.com/apache/kafka/commit/731c8c967e04ffe212e8b4d8ea15e67f22a60e65",
        "files": [
          "core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java"
        ],
        "message": "KAFKA-15017 Fix snapshot load in dual write mode for ClientQuotas and SCRAM  (#13757)\n\nThis patch fixes the case where a ClientQuota or SCRAM credential was added in KRaft, but not written back to ZK. This missed write only occurred when handling a KRaft snapshot. If the changed quota was processed in a metadata delta (which is the typical case), it would be written to ZK.\n\nReviewers: David Arthur <mumrah@gmail.com>",
        "before_after_code_files": [
          "core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala",
          "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala",
            "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java"
          ],
          "candidate": [
            "core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala",
            "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java"
          ]
        }
      },
      "candidate_diff": {
        "core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala||core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala": [
          "File: core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala -> core/src/test/scala/unit/kafka/zk/migration/ZkConfigMigrationClientTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: import kafka.server.{ConfigType, KafkaConfig, ZkAdminManager}",
          "20: import kafka.zk.{AdminZkClient, ZkMigrationClient}",
          "21: import org.apache.kafka.common.config.internals.QuotaConfigs",
          "22: import org.apache.kafka.common.config.types.Password",
          "23: import org.apache.kafka.common.config.{ConfigResource, TopicConfig}",
          "24: import org.apache.kafka.common.metadata.ConfigRecord",
          "25: import org.apache.kafka.common.quota.ClientQuotaEntity",
          "26: import org.apache.kafka.common.security.scram.ScramCredential",
          "27: import org.apache.kafka.common.security.scram.internals.ScramCredentialUtils",
          "28: import org.apache.kafka.image.{ClientQuotasDelta, ClientQuotasImage}",
          "29: import org.apache.kafka.metadata.RecordTestUtils",
          "30: import org.apache.kafka.metadata.migration.ZkMigrationLeadershipState",
          "31: import org.apache.kafka.server.common.ApiMessageAndVersion",
          "32: import org.apache.kafka.server.util.MockRandom",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "21: import org.apache.kafka.clients.admin.ScramMechanism",
          "25: import org.apache.kafka.common.metadata.ClientQuotaRecord",
          "26: import org.apache.kafka.common.metadata.ClientQuotaRecord.EntityData",
          "28: import org.apache.kafka.common.metadata.UserScramCredentialRecord",
          "33: import org.apache.kafka.image.{MetadataDelta, MetadataImage, MetadataProvenance}",
          "35: import org.apache.kafka.metadata.migration.KRaftMigrationZkWriter",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "39: import scala.jdk.CollectionConverters._",
          "41: class ZkConfigMigrationClientTest extends ZkMigrationTestHarness {",
          "42:   @Test",
          "43:   def testMigrationBrokerConfigs(): Unit = {",
          "44:     val brokers = new java.util.ArrayList[Integer]()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "48:   def randomBuffer(random: MockRandom, length: Int): Array[Byte] = {",
          "49:     val buf = new Array[Byte](length)",
          "50:     random.nextBytes(buf)",
          "51:     buf",
          "52:   }",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "235:   def testScram(): Unit = {",
          "236:     val random = new MockRandom()",
          "244:     val scramCredential = new ScramCredential(",
          "245:       randomBuffer(random, 1024),",
          "246:       randomBuffer(random, 1024),",
          "",
          "[Removed Lines]",
          "238:     def randomBuffer(random: MockRandom, length: Int): Array[Byte] = {",
          "239:       val buf = new Array[Byte](length)",
          "240:       random.nextBytes(buf)",
          "241:       buf",
          "242:     }",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "259:     assertEquals(1, batches.size())",
          "260:     assertEquals(1, batches.get(0).size)",
          "261:   }",
          "262: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "269:   @Test",
          "270:   def testScramAndQuotaChangesInSnapshot(): Unit = {",
          "271:     val random = new MockRandom()",
          "273:     val props = new Properties()",
          "274:     props.put(QuotaConfigs.PRODUCER_BYTE_RATE_OVERRIDE_CONFIG, \"100000\")",
          "275:     adminZkClient.changeConfigs(ConfigType.User, \"user1\", props)",
          "278:     val aliceScramCredential = new ScramCredential(",
          "279:       randomBuffer(random, 1024),",
          "280:       randomBuffer(random, 1024),",
          "281:       randomBuffer(random, 1024),",
          "282:       4096)",
          "284:     val alicePropsInit = new Properties()",
          "285:     alicePropsInit.put(\"SCRAM-SHA-256\", ScramCredentialUtils.credentialToString(aliceScramCredential))",
          "286:     adminZkClient.changeConfigs(ConfigType.User, \"alice\", alicePropsInit)",
          "288:     val delta = new MetadataDelta(MetadataImage.EMPTY)",
          "291:     val entityData = new EntityData().setEntityType(\"user\").setEntityName(\"user2\")",
          "292:     val clientQuotaRecord = new ClientQuotaRecord()",
          "293:       .setEntity(List(entityData).asJava)",
          "294:       .setKey(\"request_percentage\")",
          "295:       .setValue(58.58)",
          "296:       .setRemove(false)",
          "297:     delta.replay(clientQuotaRecord)",
          "300:     val scramCredentialRecord = new UserScramCredentialRecord()",
          "301:       .setName(\"george\")",
          "302:       .setMechanism(ScramMechanism.SCRAM_SHA_256.`type`)",
          "303:       .setSalt(randomBuffer(random, 1024))",
          "304:       .setStoredKey(randomBuffer(random, 1024))",
          "305:       .setServerKey(randomBuffer(random, 1024))",
          "306:       .setIterations(8192)",
          "307:     delta.replay(scramCredentialRecord)",
          "311:     val image = delta.apply(MetadataProvenance.EMPTY)",
          "314:     val kraftMigrationZkWriter = new KRaftMigrationZkWriter(migrationClient,",
          "315:       (_, operation) => { migrationState = operation.apply(migrationState) })",
          "316:     kraftMigrationZkWriter.handleLoadSnapshot(image)",
          "318:     val user1Props = zkClient.getEntityConfigs(ConfigType.User, \"user1\")",
          "319:     assertEquals(0, user1Props.size())",
          "320:     val user2Props = zkClient.getEntityConfigs(ConfigType.User, \"user2\")",
          "321:     assertEquals(1, user2Props.size())",
          "323:     val georgeProps = zkClient.getEntityConfigs(ConfigType.User, \"george\")",
          "324:     assertEquals(1, georgeProps.size())",
          "325:     val aliceProps = zkClient.getEntityConfigs(ConfigType.User, \"alice\")",
          "326:     assertEquals(0, aliceProps.size())",
          "327:   }",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java||metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java -> metadata/src/main/java/org/apache/kafka/metadata/migration/KRaftMigrationZkWriter.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "50: import java.util.HashSet;",
          "51: import java.util.List;",
          "52: import java.util.Map;",
          "53: import java.util.Optional;",
          "54: import java.util.Set;",
          "55: import java.util.function.BiConsumer;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "53: import java.util.Map.Entry;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "258:     void handleClientQuotasSnapshot(ClientQuotasImage clientQuotasImage, ScramImage scramImage) {",
          "259:         Set<ClientQuotaEntity> changedNonUserEntities = new HashSet<>();",
          "260:         Set<String> changedUsers = new HashSet<>();",
          "261:         migrationClient.configClient().iterateClientQuotas(new ConfigMigrationClient.ClientQuotaVisitor() {",
          "262:             @Override",
          "263:             public void visitClientQuota(List<ClientQuotaRecord.EntityData> entityDataList, Map<String, Double> quotas) {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "263:         if (clientQuotasImage != null) {",
          "264:             for (Entry<ClientQuotaEntity, ClientQuotaImage> entry : clientQuotasImage.entities().entrySet()) {",
          "265:                 ClientQuotaEntity entity = entry.getKey();",
          "266:                 if (entity.entries().containsKey(ClientQuotaEntity.USER) &&",
          "267:                     !entity.entries().containsKey(ClientQuotaEntity.CLIENT_ID)) {",
          "270:                     changedUsers.add(entity.entries().get(ClientQuotaEntity.USER));",
          "271:                 } else {",
          "272:                     changedNonUserEntities.add(entity);",
          "273:                 }",
          "274:             }",
          "275:         }",
          "276:         if (scramImage != null) {",
          "277:             for (Entry<ScramMechanism, Map<String, ScramCredentialData>> mechanismEntry : scramImage.mechanisms().entrySet()) {",
          "278:                 for (Entry<String, ScramCredentialData> userEntry : mechanismEntry.getValue().entrySet()) {",
          "279:                     changedUsers.add(userEntry.getKey());",
          "280:                 }",
          "281:             }",
          "282:         }",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "294:         changedUsers.forEach(userName -> {",
          "295:             ClientQuotaEntity entity = new ClientQuotaEntity(Collections.singletonMap(ClientQuotaEntity.USER, userName));",
          "297:             Map<String, String> scramMap = getScramCredentialStringsForUser(scramImage, userName);",
          "298:             operationConsumer.accept(\"Update scram credentials for \" + userName, migrationState ->",
          "299:                 migrationClient.configClient().writeClientQuotas(entity.entries(), quotaMap, scramMap, migrationState));",
          "300:         });",
          "303:     }",
          "305:     void handleConfigsDelta(ConfigurationsImage configsImage, ConfigurationsDelta configsDelta) {",
          "",
          "[Removed Lines]",
          "296:             Map<String, Double> quotaMap = clientQuotasImage.entities().get(entity).quotaMap();",
          "",
          "[Added Lines]",
          "318:             Map<String, Double> quotaMap = clientQuotasImage.entities().",
          "319:                 getOrDefault(entity, ClientQuotaImage.EMPTY).quotaMap();",
          "",
          "---------------"
        ]
      }
    }
  ]
}