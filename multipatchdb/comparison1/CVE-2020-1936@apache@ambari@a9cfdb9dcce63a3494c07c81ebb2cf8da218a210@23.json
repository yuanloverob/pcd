{
  "cve_id": "CVE-2020-1936",
  "cve_desc": "A cross-site scripting issue was found in Apache Ambari Views. This was addressed in Apache Ambari 2.7.4.",
  "repo": "apache/ambari",
  "patch_hash": "a9cfdb9dcce63a3494c07c81ebb2cf8da218a210",
  "patch_info": {
    "commit_hash": "a9cfdb9dcce63a3494c07c81ebb2cf8da218a210",
    "repo": "apache/ambari",
    "commit_url": "https://github.com/apache/ambari/pull/3040/commits/a9cfdb9dcce63a3494c07c81ebb2cf8da218a210",
    "files": [
      "ambari-web/app/views/common/breadcrumbs_view.js"
    ],
    "message": "AMBARI-25329. Ambari breadcrumbs xss vulnerability",
    "before_after_code_files": [
      "ambari-web/app/views/common/breadcrumbs_view.js||ambari-web/app/views/common/breadcrumbs_view.js"
    ]
  },
  "patch_diff": {
    "ambari-web/app/views/common/breadcrumbs_view.js||ambari-web/app/views/common/breadcrumbs_view.js": [
      "File: ambari-web/app/views/common/breadcrumbs_view.js -> ambari-web/app/views/common/breadcrumbs_view.js",
      "--- Hunk 1 ---",
      "[Context before]",
      "149:   createLabel() {",
      "150:     let label = this.get('label');",
      "151:     let labelBindingPath = this.get('labelBindingPath');",
      "154:     this.set('formattedLabel', this.labelPostFormat(formattedLabel));",
      "155:   },",
      "",
      "[Removed Lines]",
      "153:     let formattedLabel = labelBindingPath ? App.get(_getLabelPathWithoutApp(labelBindingPath)) : label;",
      "",
      "[Added Lines]",
      "152:     let formattedLabel;",
      "154:     if (labelBindingPath) {",
      "155:       formattedLabel = Ember.Handlebars.Utils.escapeExpression(App.get(_getLabelPathWithoutApp(labelBindingPath)));",
      "156:     } else{",
      "157:       formattedLabel = label;",
      "158:     }",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "216:       }",
      "217:       currentState = currentState.get('parentState');",
      "218:     }",
      "220:     if (items.length) {",
      "221:       items.get('lastObject').setProperties({",
      "222:         disabled: true,",
      "",
      "[Removed Lines]",
      "219:     items = items.reverse().map(item => App.BreadcrumbItem.extend(item).create());",
      "",
      "[Added Lines]",
      "227:     items.reverse();",
      "228:     items.slice(1).forEach(item => item.label = Ember.Handlebars.Utils.escapeExpression(item.label));",
      "229:     items = items.map(item => App.BreadcrumbItem.extend(item).create());",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "853d753eac97c4b8de155dacde2019d4af53d7d2",
      "candidate_info": {
        "commit_hash": "853d753eac97c4b8de155dacde2019d4af53d7d2",
        "repo": "apache/ambari",
        "commit_url": "https://github.com/apache/ambari/commit/853d753eac97c4b8de155dacde2019d4af53d7d2",
        "files": [
          "ambari-server/src/main/resources/common-services/OOZIE/4.0.0.2.0/package/scripts/service_check.py"
        ],
        "message": "AMBARI-25162. Fix Oozie Service Check (#2827)",
        "before_after_code_files": [
          "ambari-server/src/main/resources/common-services/OOZIE/4.0.0.2.0/package/scripts/service_check.py||ambari-server/src/main/resources/common-services/OOZIE/4.0.0.2.0/package/scripts/service_check.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/ambari/pull/3633",
          "https://github.com/apache/ambari/pull/3631",
          "https://github.com/apache/ambari/pull/3637",
          "https://github.com/apache/ambari/pull/3632",
          "https://github.com/apache/ambari/pull/3634",
          "https://github.com/apache/ambari/pull/3635"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "ambari-server/src/main/resources/common-services/OOZIE/4.0.0.2.0/package/scripts/service_check.py||ambari-server/src/main/resources/common-services/OOZIE/4.0.0.2.0/package/scripts/service_check.py": [
          "File: ambari-server/src/main/resources/common-services/OOZIE/4.0.0.2.0/package/scripts/service_check.py -> ambari-server/src/main/resources/common-services/OOZIE/4.0.0.2.0/package/scripts/service_check.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: import os",
          "21: import glob",
          "23: from resource_management.core.resources.system import Execute",
          "24: from resource_management.core.resources import File",
          "25: from resource_management.core.source import StaticFile",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "23: from resource_management.core.exceptions import Fail",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "1f897a61ebf52d054ddcb1225eeb7253aca620fd",
      "candidate_info": {
        "commit_hash": "1f897a61ebf52d054ddcb1225eeb7253aca620fd",
        "repo": "apache/ambari",
        "commit_url": "https://github.com/apache/ambari/commit/1f897a61ebf52d054ddcb1225eeb7253aca620fd",
        "files": [
          "ambari-web/app/controllers/main/service/reassign/step3_controller.js",
          "ambari-web/app/controllers/main/service/reassign_controller.js"
        ],
        "message": "AMBARI-24767. Error while starting Timeline v2 Reader during Move operation (amagyar) (#2447) (#2450)",
        "before_after_code_files": [
          "ambari-web/app/controllers/main/service/reassign/step3_controller.js||ambari-web/app/controllers/main/service/reassign/step3_controller.js",
          "ambari-web/app/controllers/main/service/reassign_controller.js||ambari-web/app/controllers/main/service/reassign_controller.js"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/ambari/pull/3633",
          "https://github.com/apache/ambari/pull/3631",
          "https://github.com/apache/ambari/pull/3637",
          "https://github.com/apache/ambari/pull/3632",
          "https://github.com/apache/ambari/pull/3634",
          "https://github.com/apache/ambari/pull/3635"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "ambari-web/app/controllers/main/service/reassign/step3_controller.js||ambari-web/app/controllers/main/service/reassign/step3_controller.js": [
          "File: ambari-web/app/controllers/main/service/reassign/step3_controller.js -> ambari-web/app/controllers/main/service/reassign/step3_controller.js",
          "--- Hunk 1 ---",
          "[Context before]",
          "117:         }",
          "118:       }",
          "119:     },",
          "120:     {",
          "121:       componentName: 'OOZIE_SERVER',",
          "122:       configs: {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "120:     {",
          "121:       componentName: 'TIMELINE_READER',",
          "122:       configs: {",
          "123:         'yarn-site': {",
          "124:           'yarn.timeline-service.reader.webapp.address': '<replace-value>:8198',",
          "125:           'yarn.timeline-service.reader.webapp.https.address': '<replace-value>:8199'",
          "126:         }",
          "127:       }",
          "128:     },",
          "",
          "---------------"
        ],
        "ambari-web/app/controllers/main/service/reassign_controller.js||ambari-web/app/controllers/main/service/reassign_controller.js": [
          "File: ambari-web/app/controllers/main/service/reassign_controller.js -> ambari-web/app/controllers/main/service/reassign_controller.js",
          "--- Hunk 1 ---",
          "[Context before]",
          "160:     'HIVE_SERVER': ['hive-site', 'webhcat-site', 'hive-env', 'core-site'],",
          "161:     'HIVE_METASTORE': ['hive-site', 'webhcat-site', 'hive-env', 'core-site'],",
          "162:     'MYSQL_SERVER': ['hive-site'],",
          "164:   },",
          "",
          "[Removed Lines]",
          "163:     'HISTORYSERVER': ['mapred-site']",
          "",
          "[Added Lines]",
          "163:     'HISTORYSERVER': ['mapred-site'],",
          "164:     'TIMELINE_READER' : ['yarn-site']",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "b13ed674486e7eeb70cc6f529904b93dbd85dd55",
      "candidate_info": {
        "commit_hash": "b13ed674486e7eeb70cc6f529904b93dbd85dd55",
        "repo": "apache/ambari",
        "commit_url": "https://github.com/apache/ambari/commit/b13ed674486e7eeb70cc6f529904b93dbd85dd55",
        "files": [
          "ambari-metrics/ambari-metrics-kafka-sink/src/main/java/org/apache/hadoop/metrics2/sink/kafka/JvmMetricSet.java",
          "ambari-metrics/ambari-metrics-kafka-sink/src/main/java/org/apache/hadoop/metrics2/sink/kafka/KafkaTimelineMetricsReporter.java",
          "ambari-metrics/ambari-metrics-kafka-sink/src/main/java/org/apache/hadoop/metrics2/sink/kafka/MetricNameBuilder.java",
          "ambari-metrics/ambari-metrics-kafka-sink/src/test/java/org/apache/hadoop/metrics2/sink/kafka/JvmMetricSetTest.java",
          "ambari-server/src/main/resources/common-services/KAFKA/1.0.1/metainfo.xml",
          "ambari-server/src/main/resources/common-services/KAFKA/1.0.1/metrics.json"
        ],
        "message": "AMBARI-25402 Please provide jvm metrics for kafka components in Ambari (santal) (#3110)\n\nAMBARI-25402 Please provide jvm metrics for kafka components in Ambari (santal via dgrinenko)\n\n- renamed mxbean variables, removed unused constant\n- simplified the getThreadMetricNameByState method, created unit test\n- added license",
        "before_after_code_files": [
          "ambari-metrics/ambari-metrics-kafka-sink/src/main/java/org/apache/hadoop/metrics2/sink/kafka/JvmMetricSet.java||ambari-metrics/ambari-metrics-kafka-sink/src/main/java/org/apache/hadoop/metrics2/sink/kafka/JvmMetricSet.java",
          "ambari-metrics/ambari-metrics-kafka-sink/src/main/java/org/apache/hadoop/metrics2/sink/kafka/KafkaTimelineMetricsReporter.java||ambari-metrics/ambari-metrics-kafka-sink/src/main/java/org/apache/hadoop/metrics2/sink/kafka/KafkaTimelineMetricsReporter.java",
          "ambari-metrics/ambari-metrics-kafka-sink/src/main/java/org/apache/hadoop/metrics2/sink/kafka/MetricNameBuilder.java||ambari-metrics/ambari-metrics-kafka-sink/src/main/java/org/apache/hadoop/metrics2/sink/kafka/MetricNameBuilder.java",
          "ambari-metrics/ambari-metrics-kafka-sink/src/test/java/org/apache/hadoop/metrics2/sink/kafka/JvmMetricSetTest.java||ambari-metrics/ambari-metrics-kafka-sink/src/test/java/org/apache/hadoop/metrics2/sink/kafka/JvmMetricSetTest.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/ambari/pull/3633",
          "https://github.com/apache/ambari/pull/3631",
          "https://github.com/apache/ambari/pull/3637",
          "https://github.com/apache/ambari/pull/3632",
          "https://github.com/apache/ambari/pull/3634",
          "https://github.com/apache/ambari/pull/3635"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "ambari-metrics/ambari-metrics-kafka-sink/src/main/java/org/apache/hadoop/metrics2/sink/kafka/JvmMetricSet.java||ambari-metrics/ambari-metrics-kafka-sink/src/main/java/org/apache/hadoop/metrics2/sink/kafka/JvmMetricSet.java": [
          "File: ambari-metrics/ambari-metrics-kafka-sink/src/main/java/org/apache/hadoop/metrics2/sink/kafka/JvmMetricSet.java -> ambari-metrics/ambari-metrics-kafka-sink/src/main/java/org/apache/hadoop/metrics2/sink/kafka/JvmMetricSet.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19: package org.apache.hadoop.metrics2.sink.kafka;",
          "21: import java.lang.management.ManagementFactory;",
          "22: import java.lang.management.MemoryMXBean;",
          "23: import java.lang.management.RuntimeMXBean;",
          "24: import java.lang.management.ThreadMXBean;",
          "25: import java.util.AbstractMap;",
          "26: import java.util.Arrays;",
          "27: import java.util.List;",
          "28: import java.util.Map;",
          "29: import java.util.stream.Collectors;",
          "30: import java.util.stream.Stream;",
          "31: import javax.annotation.Nonnull;",
          "32: import com.yammer.metrics.core.Gauge;",
          "33: import com.yammer.metrics.core.MetricName;",
          "34: import com.yammer.metrics.util.RatioGauge;",
          "36: public class JvmMetricSet {",
          "38:   private static final String MEMORY = \"memory\";",
          "39:   private static final String THREADS = \"threads\";",
          "40:   private static final String RUNTIME = \"runtime\";",
          "42:   private static final JvmMetricSet INSTANCE = new JvmMetricSet();",
          "45:   public static JvmMetricSet getInstance() {",
          "46:     return INSTANCE;",
          "47:   }",
          "49:   private final MemoryMXBean memoryMXBean;",
          "50:   private final ThreadMXBean threadMXBean;",
          "51:   private final RuntimeMXBean runtimeMXBean;",
          "53:   private static class JvmMetric {",
          "54:     private final MetricName metricName;",
          "55:     private final Gauge<?> metric;",
          "57:     JvmMetric(MetricName metricName, Gauge<?> metric) {",
          "58:       this.metricName = metricName;",
          "59:       this.metric = metric;",
          "60:     }",
          "62:     MetricName getMetricName() {",
          "63:       return metricName;",
          "64:     }",
          "66:     Gauge<?> getMetric() {",
          "67:       return metric;",
          "68:     }",
          "69:   }",
          "72:   private JvmMetricSet() {",
          "73:     this(ManagementFactory.getMemoryMXBean(), ManagementFactory.getThreadMXBean(),",
          "74:       ManagementFactory.getRuntimeMXBean());",
          "76:   }",
          "78:   private JvmMetricSet(MemoryMXBean memoryMXBean, ThreadMXBean threadMXBean, RuntimeMXBean runtimeMXBean) {",
          "79:     this.memoryMXBean = memoryMXBean;",
          "80:     this.threadMXBean = threadMXBean;",
          "81:     this.runtimeMXBean = runtimeMXBean;",
          "82:   }",
          "84:   public Map<MetricName, Gauge<?>> getJvmMetrics() {",
          "85:     return Stream.concat(",
          "86:       getMemoryUsageMetrics().stream(),",
          "87:       Stream.concat(",
          "88:         getThreadMetrics().stream(),",
          "89:         Stream.of(getRuntimeMetrics())",
          "90:       ))",
          "91:       .collect(Collectors.toMap(JvmMetric::getMetricName, JvmMetric::getMetric));",
          "92:   }",
          "94:   private List<JvmMetric> getMemoryUsageMetrics() {",
          "96:     return Stream.of(",
          "97:       new AbstractMap.SimpleEntry<>(\"heap_usage\", memoryMXBean.getHeapMemoryUsage()),",
          "98:       new AbstractMap.SimpleEntry<>(\"non_heap_usage\", memoryMXBean.getNonHeapMemoryUsage()))",
          "99:       .map(entry ->",
          "100:         new JvmMetric(",
          "101:           MetricNameBuilder.builder().type(MEMORY).name(entry.getKey()).build(),",
          "102:           new RatioGauge() {",
          "104:             @Override",
          "105:             protected double getNumerator() {",
          "106:               return entry.getValue().getUsed();",
          "107:             }",
          "109:             @Override",
          "110:             protected double getDenominator() {",
          "111:               return entry.getValue().getMax();",
          "112:             }",
          "113:           }",
          "114:         ))",
          "115:       .collect(Collectors.toList());",
          "117:   }",
          "119:   private List<JvmMetric> getThreadMetrics() {",
          "121:     return",
          "122:       Stream.concat(",
          "123:         Stream.of(",
          "124:           new JvmMetric(",
          "125:             MetricNameBuilder.builder().type(THREADS).name(\"thread_count\").build(),",
          "126:             new Gauge<Integer>() {",
          "127:               @Override",
          "128:               public Integer value() {",
          "129:                 return threadMXBean.getThreadCount();",
          "130:               }",
          "131:             }",
          "132:           ),",
          "133:           new JvmMetric(",
          "134:             MetricNameBuilder.builder().type(THREADS).name(\"daemon_thread_count\").build(),",
          "135:             new Gauge<Integer>() {",
          "136:               @Override",
          "137:               public Integer value() {",
          "138:                 return threadMXBean.getDaemonThreadCount();",
          "139:               }",
          "140:             }",
          "141:           )),",
          "142:         Stream",
          "143:           .of(Thread.State.RUNNABLE, Thread.State.BLOCKED, Thread.State.TIMED_WAITING, Thread.State.TERMINATED)",
          "144:           .map(state -> new JvmMetric(",
          "145:             MetricNameBuilder.builder().type(THREADS).name(getThreadMetricNameByState(state)).build(),",
          "146:             new Gauge<Long>() {",
          "147:               @Override",
          "148:               public Long value() {",
          "149:                 return getThreadCountByState(state);",
          "150:               }",
          "151:             }",
          "152:           )))",
          "153:         .collect(Collectors.toList());",
          "154:   }",
          "156:   private String getThreadMetricNameByState(@Nonnull Thread.State state) {",
          "157:     return String.format(\"thread-states.%s\", state.name().toLowerCase());",
          "158:   }",
          "160:   private long getThreadCountByState(@Nonnull Thread.State state) {",
          "161:     return Arrays.stream(threadMXBean.getThreadInfo(threadMXBean.getAllThreadIds(), 0))",
          "162:       .filter(threadInfo -> threadInfo.getThreadState().equals(state))",
          "163:       .count();",
          "164:   }",
          "166:   private JvmMetric getRuntimeMetrics() {",
          "167:     return new JvmMetric(",
          "168:       MetricNameBuilder.builder().type(RUNTIME).name(\"uptime\").build(),",
          "169:       new Gauge<Long>() {",
          "170:         @Override",
          "171:         public Long value() {",
          "172:           return runtimeMXBean.getUptime();",
          "173:         }",
          "174:       }",
          "175:     );",
          "176:   }",
          "178: }",
          "",
          "---------------"
        ],
        "ambari-metrics/ambari-metrics-kafka-sink/src/main/java/org/apache/hadoop/metrics2/sink/kafka/KafkaTimelineMetricsReporter.java||ambari-metrics/ambari-metrics-kafka-sink/src/main/java/org/apache/hadoop/metrics2/sink/kafka/KafkaTimelineMetricsReporter.java": [
          "File: ambari-metrics/ambari-metrics-kafka-sink/src/main/java/org/apache/hadoop/metrics2/sink/kafka/KafkaTimelineMetricsReporter.java -> ambari-metrics/ambari-metrics-kafka-sink/src/main/java/org/apache/hadoop/metrics2/sink/kafka/KafkaTimelineMetricsReporter.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: package org.apache.hadoop.metrics2.sink.kafka;",
          "21: import com.yammer.metrics.Metrics;",
          "22: import com.yammer.metrics.core.Counter;",
          "23: import com.yammer.metrics.core.Gauge;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "21: import java.net.InetAddress;",
          "22: import java.net.UnknownHostException;",
          "23: import java.util.ArrayList;",
          "24: import java.util.Collection;",
          "25: import java.util.HashSet;",
          "26: import java.util.List;",
          "27: import java.util.Map.Entry;",
          "28: import java.util.Set;",
          "29: import java.util.concurrent.TimeUnit;",
          "30: import org.apache.commons.lang.ArrayUtils;",
          "31: import org.apache.commons.lang.ClassUtils;",
          "32: import org.apache.commons.lang.StringUtils;",
          "33: import org.apache.commons.logging.Log;",
          "34: import org.apache.commons.logging.LogFactory;",
          "35: import org.apache.hadoop.metrics2.sink.timeline.AbstractTimelineMetricsSink;",
          "36: import org.apache.hadoop.metrics2.sink.timeline.TimelineMetric;",
          "37: import org.apache.hadoop.metrics2.sink.timeline.TimelineMetrics;",
          "38: import org.apache.hadoop.metrics2.sink.timeline.cache.TimelineMetricsCache;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "33: import kafka.metrics.KafkaMetricsConfig;",
          "34: import kafka.metrics.KafkaMetricsReporter;",
          "35: import kafka.utils.VerifiableProperties;",
          "54: import static org.apache.hadoop.metrics2.sink.timeline.TimelineMetricMetadata.MetricType;",
          "55: import static org.apache.hadoop.metrics2.sink.timeline.cache.TimelineMetricsCache.MAX_EVICTION_TIME_MILLIS;",
          "56: import static org.apache.hadoop.metrics2.sink.timeline.cache.TimelineMetricsCache.MAX_RECS_PER_NAME_DEFAULT;",
          "",
          "[Removed Lines]",
          "36: import org.apache.commons.lang.ArrayUtils;",
          "37: import org.apache.commons.lang.ClassUtils;",
          "38: import org.apache.commons.lang.StringUtils;",
          "39: import org.apache.commons.logging.Log;",
          "40: import org.apache.commons.logging.LogFactory;",
          "41: import org.apache.hadoop.metrics2.sink.timeline.AbstractTimelineMetricsSink;",
          "42: import org.apache.hadoop.metrics2.sink.timeline.TimelineMetric;",
          "43: import org.apache.hadoop.metrics2.sink.timeline.TimelineMetrics;",
          "44: import org.apache.hadoop.metrics2.sink.timeline.cache.TimelineMetricsCache;",
          "45: import java.net.InetAddress;",
          "46: import java.net.UnknownHostException;",
          "47: import java.util.ArrayList;",
          "48: import java.util.Collection;",
          "49: import java.util.HashSet;",
          "50: import java.util.List;",
          "51: import java.util.Map.Entry;",
          "52: import java.util.Set;",
          "53: import java.util.concurrent.TimeUnit;",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "303:     protected TimelineScheduledReporter(MetricsRegistry registry, String name, TimeUnit rateUnit, TimeUnit durationUnit) {",
          "304:       super(registry, name, rateUnit, durationUnit);",
          "305:     }",
          "307:     @Override",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "306:       JvmMetricSet.getInstance()",
          "307:         .getJvmMetrics()",
          "308:         .forEach(registry::newGauge);",
          "",
          "---------------"
        ],
        "ambari-metrics/ambari-metrics-kafka-sink/src/main/java/org/apache/hadoop/metrics2/sink/kafka/MetricNameBuilder.java||ambari-metrics/ambari-metrics-kafka-sink/src/main/java/org/apache/hadoop/metrics2/sink/kafka/MetricNameBuilder.java": [
          "File: ambari-metrics/ambari-metrics-kafka-sink/src/main/java/org/apache/hadoop/metrics2/sink/kafka/MetricNameBuilder.java -> ambari-metrics/ambari-metrics-kafka-sink/src/main/java/org/apache/hadoop/metrics2/sink/kafka/MetricNameBuilder.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19: package org.apache.hadoop.metrics2.sink.kafka;",
          "21: import java.util.regex.Pattern;",
          "23: import com.yammer.metrics.core.MetricName;",
          "25: import static java.util.Optional.ofNullable;",
          "27: public class MetricNameBuilder {",
          "28:   private static final Pattern WHITESPACE = Pattern.compile(\"[\\\\s]+\");",
          "30:   private String group = \"jvm\";",
          "31:   private String type;",
          "32:   private String name;",
          "34:   private final String replacement;",
          "36:   static MetricNameBuilder builder() {",
          "37:     return new MetricNameBuilder();",
          "38:   }",
          "40:   MetricNameBuilder() {",
          "41:     this(null);",
          "42:   }",
          "44:   MetricNameBuilder(String replacement) {",
          "45:     this.replacement = ofNullable(replacement).orElse(\"_\");",
          "46:   }",
          "48:   public MetricNameBuilder group(String group) {",
          "49:     this.group = group;",
          "50:     return this;",
          "51:   }",
          "53:   public MetricNameBuilder type(String type) {",
          "54:     this.type = replaceWhiteSpaces(type);",
          "55:     return this;",
          "56:   }",
          "58:   public MetricNameBuilder name(String name) {",
          "59:     this.name = ofNullable(this.name).orElse(\"\") + replaceWhiteSpaces(name);",
          "60:     return this;",
          "61:   }",
          "63:   private String replaceWhiteSpaces(String value) {",
          "64:     return ofNullable(value)",
          "65:       .map(val -> WHITESPACE.matcher(val).replaceAll(replacement))",
          "66:       .orElse(\"\");",
          "67:   }",
          "69:   public MetricName build() {",
          "70:     return new MetricName(this.group, type, name, null, createMBeanName());",
          "71:   }",
          "73:   private String createMBeanName() {",
          "74:     final StringBuilder builder = new StringBuilder();",
          "75:     builder.append(group);",
          "76:     builder.append(\":type=\");",
          "77:     builder.append(type);",
          "78:     if (name.length() > 0) {",
          "79:       builder.append(\",name=\");",
          "80:       builder.append(name);",
          "81:     }",
          "82:     return builder.toString();",
          "83:   }",
          "85: }",
          "",
          "---------------"
        ],
        "ambari-metrics/ambari-metrics-kafka-sink/src/test/java/org/apache/hadoop/metrics2/sink/kafka/JvmMetricSetTest.java||ambari-metrics/ambari-metrics-kafka-sink/src/test/java/org/apache/hadoop/metrics2/sink/kafka/JvmMetricSetTest.java": [
          "File: ambari-metrics/ambari-metrics-kafka-sink/src/test/java/org/apache/hadoop/metrics2/sink/kafka/JvmMetricSetTest.java -> ambari-metrics/ambari-metrics-kafka-sink/src/test/java/org/apache/hadoop/metrics2/sink/kafka/JvmMetricSetTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19: package org.apache.hadoop.metrics2.sink.kafka;",
          "21: import java.util.Map;",
          "22: import org.junit.Test;",
          "23: import com.yammer.metrics.core.Gauge;",
          "24: import com.yammer.metrics.core.MetricName;",
          "25: import static java.util.stream.Collectors.toList;",
          "26: import static org.junit.Assert.assertFalse;",
          "27: import static org.junit.Assert.assertNotNull;",
          "28: import static org.junit.Assert.assertThat;",
          "29: import static org.junit.matchers.JUnitMatchers.hasItems;",
          "31: public class JvmMetricSetTest {",
          "33:   @Test",
          "34:   public void testGetJvmMetrics() {",
          "36:     Map<MetricName, Gauge<?>> result = JvmMetricSet.getInstance().getJvmMetrics();",
          "38:     assertNotNull(result);",
          "39:     assertFalse(result.isEmpty());",
          "40:     assertThat(",
          "41:       result.keySet()",
          "42:         .stream()",
          "43:         .map(MetricName::getName)",
          "44:         .collect(toList()),",
          "45:       hasItems(\"heap_usage\", \"thread-states.blocked\", \"thread-states.timed_waiting\", \"uptime\"));",
          "46:   }",
          "48: }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "d9684007c03f223ff189e4a5d68365c467936607",
      "candidate_info": {
        "commit_hash": "d9684007c03f223ff189e4a5d68365c467936607",
        "repo": "apache/ambari",
        "commit_url": "https://github.com/apache/ambari/commit/d9684007c03f223ff189e4a5d68365c467936607",
        "files": [
          "ambari-server/src/main/python/ambari_server/dbConfiguration_linux.py"
        ],
        "message": "[AMBARI-24573] Clarify the warning message during ambari server setup (dsen) (#2211)",
        "before_after_code_files": [
          "ambari-server/src/main/python/ambari_server/dbConfiguration_linux.py||ambari-server/src/main/python/ambari_server/dbConfiguration_linux.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/ambari/pull/3633",
          "https://github.com/apache/ambari/pull/3631",
          "https://github.com/apache/ambari/pull/3637",
          "https://github.com/apache/ambari/pull/3632",
          "https://github.com/apache/ambari/pull/3634",
          "https://github.com/apache/ambari/pull/3635"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "ambari-server/src/main/python/ambari_server/dbConfiguration_linux.py||ambari-server/src/main/python/ambari_server/dbConfiguration_linux.py": [
          "File: ambari-server/src/main/python/ambari_server/dbConfiguration_linux.py -> ambari-server/src/main/python/ambari_server/dbConfiguration_linux.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "177:     client_usage_cmd_init = self._get_remote_script_line(self.init_script_file)",
          "179:     print_warning_msg('To reset Ambari Server schema ' +",
          "181:                       + 'drop the schema:' + os.linesep + client_usage_cmd_drop",
          "182:                       + os.linesep + 'Then you must run the following DDL ' +",
          "184:                       client_usage_cmd_init + os.linesep)",
          "186:   def _get_default_driver_path(self, properties):",
          "",
          "[Removed Lines]",
          "180:                       'you must run the following DDL against the database to '",
          "183:                       'against the database to create the schema: ' + os.linesep +",
          "",
          "[Added Lines]",
          "180:                       'you must run the following DDL directly from the database shell to '",
          "183:                       'directly from the database shell to create the schema: ' + os.linesep +",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "272:   # Let the console user initialize the remote database schema",
          "273:   def _setup_remote_db(self):",
          "274:     setup_msg = \"Before starting Ambari Server, you must run the following DDL \" \\",
          "277:     print_warning_msg(setup_msg)",
          "",
          "[Removed Lines]",
          "275:                 \"against the database to create the schema: {0}\".format(self.init_script_file)",
          "",
          "[Added Lines]",
          "275:                 \"directly from the database shell to create the schema: {0}\".format(self.init_script_file)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "3bdfc847e550a29723bd4c0fd97fbb74cec9fb01",
      "candidate_info": {
        "commit_hash": "3bdfc847e550a29723bd4c0fd97fbb74cec9fb01",
        "repo": "apache/ambari",
        "commit_url": "https://github.com/apache/ambari/commit/3bdfc847e550a29723bd4c0fd97fbb74cec9fb01",
        "files": [
          "ambari-web/app/templates/wizard/step8.hbs",
          "ambari-web/app/views/wizard/step8_view.js"
        ],
        "message": "AMBARI-25448. Mask credentials during install step",
        "before_after_code_files": [
          "ambari-web/app/templates/wizard/step8.hbs||ambari-web/app/templates/wizard/step8.hbs",
          "ambari-web/app/views/wizard/step8_view.js||ambari-web/app/views/wizard/step8_view.js"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/ambari/pull/3633",
          "https://github.com/apache/ambari/pull/3631",
          "https://github.com/apache/ambari/pull/3637",
          "https://github.com/apache/ambari/pull/3632",
          "https://github.com/apache/ambari/pull/3634",
          "https://github.com/apache/ambari/pull/3635"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "ambari-web/app/templates/wizard/step8.hbs||ambari-web/app/templates/wizard/step8.hbs": [
          "File: ambari-web/app/templates/wizard/step8.hbs -> ambari-web/app/templates/wizard/step8.hbs",
          "--- Hunk 1 ---",
          "[Context before]",
          "48:           {{else}}",
          "49:             <div>",
          "50:               <ul>",
          "52:                   <li>",
          "53:                     <p><span class=\"text text-info\">{{item.os_type}} ({{item.repo_id}}): <br/></span>{{item.base_url}}</p>",
          "54:                   </li>",
          "",
          "[Removed Lines]",
          "51:                 {{#each item in controller.clusterInfo.repoInfo}}",
          "",
          "[Added Lines]",
          "51:                 {{#each item in view.repoInfo}}",
          "",
          "---------------"
        ],
        "ambari-web/app/views/wizard/step8_view.js||ambari-web/app/views/wizard/step8_view.js": [
          "File: ambari-web/app/views/wizard/step8_view.js -> ambari-web/app/views/wizard/step8_view.js",
          "--- Hunk 1 ---",
          "[Context before]",
          "34:   printReview: function () {",
          "35:     var o = $(\"#step8-info\");",
          "36:     o.jqprint();",
          "38: });",
          "",
          "[Removed Lines]",
          "37:   }",
          "",
          "[Added Lines]",
          "37:   },",
          "39:   repoInfo: function() {",
          "40:     var repoInfo = this.get('controller.clusterInfo.repoInfo');",
          "41:     if (!repoInfo) {",
          "42:       return [];",
          "43:     }",
          "44:     return repoInfo.map(function (item) {",
          "45:       var link = item.get('base_url');",
          "46:       try {",
          "47:         var urlObject = new URL(link);",
          "48:         if (urlObject.username && urlObject.password) {",
          "49:           urlObject.username = urlObject.username.replace(/./g, \"*\");",
          "50:           urlObject.password = urlObject.password.replace(/./g, \"*\");",
          "51:           link = urlObject.toString();",
          "52:         }",
          "53:       } catch (e) {",
          "54:       }",
          "56:       return {",
          "57:         os_type: item.get('os_type'),",
          "58:         repo_id: item.get('repo_id'),",
          "59:         base_url: link",
          "60:       };",
          "61:     });",
          "62:   }.property('controller.clusterInfo.repoInfo')",
          "",
          "---------------"
        ]
      }
    }
  ]
}