{
  "cve_id": "CVE-2021-45229",
  "cve_desc": "It was discovered that the \"Trigger DAG with config\" screen was susceptible to XSS attacks via the `origin` query argument. This issue affects Apache Airflow versions 2.2.3 and below.",
  "repo": "apache/airflow",
  "patch_hash": "628aa1f99c865d97d0b1c7c76e630e43a7b8d319",
  "patch_info": {
    "commit_hash": "628aa1f99c865d97d0b1c7c76e630e43a7b8d319",
    "repo": "apache/airflow",
    "commit_url": "https://github.com/apache/airflow/commit/628aa1f99c865d97d0b1c7c76e630e43a7b8d319",
    "files": [
      "airflow/www/templates/airflow/trigger.html",
      "tests/www/views/test_views_trigger_dag.py"
    ],
    "message": "Simplify trigger cancel button (#21591)\n\nCo-authored-by: Jed Cunningham <jedcunningham@apache.org>\n(cherry picked from commit 65297673a318660fba76797e50d0c06804dfcafc)",
    "before_after_code_files": [
      "airflow/www/templates/airflow/trigger.html||airflow/www/templates/airflow/trigger.html",
      "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py"
    ]
  },
  "patch_diff": {
    "airflow/www/templates/airflow/trigger.html||airflow/www/templates/airflow/trigger.html": [
      "File: airflow/www/templates/airflow/trigger.html -> airflow/www/templates/airflow/trigger.html",
      "--- Hunk 1 ---",
      "[Context before]",
      "63:       </label>",
      "64:     </div>",
      "65:     <button type=\"submit\" class=\"btn btn-primary\">Trigger</button>",
      "67:   </form>",
      "68: {% endblock %}",
      "",
      "[Removed Lines]",
      "66:     <button type=\"button\" class=\"btn\" onclick=\"location.href = '{{ origin }}'; return false\">Cancel</button>",
      "",
      "[Added Lines]",
      "66:     <a class=\"btn\" href=\"{{ origin }}\">Cancel</a>",
      "",
      "---------------"
    ],
    "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py": [
      "File: tests/www/views/test_views_trigger_dag.py -> tests/www/views/test_views_trigger_dag.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "133:         (\"javascript:alert(1)\", \"/home\"),",
      "134:         (\"http://google.com\", \"/home\"),",
      "135:         (\"36539'%3balert(1)%2f%2f166\", \"/home\"),",
      "136:         (",
      "137:             \"%2Ftree%3Fdag_id%3Dexample_bash_operator';alert(33)//\",",
      "138:             \"/home\",",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "136:         (",
      "137:             '\"><script>alert(99)</script><a href=\"',",
      "138:             \"&#34;&gt;&lt;script&gt;alert(99)&lt;/script&gt;&lt;a href=&#34;\",",
      "139:         ),",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "145:     test_dag_id = \"example_bash_operator\"",
      "147:     resp = admin_client.get(f'trigger?dag_id={test_dag_id}&origin={test_origin}')",
      "156: @pytest.mark.parametrize(",
      "",
      "[Removed Lines]",
      "148:     check_content_in_response(",
      "149:         '<button type=\"button\" class=\"btn\" onclick=\"location.href = \\'{}\\'; return false\">'.format(",
      "150:             expected_origin",
      "151:         ),",
      "152:         resp,",
      "153:     )",
      "",
      "[Added Lines]",
      "152:     check_content_in_response(f'<a class=\"btn\" href=\"{expected_origin}\">Cancel</a>', resp)",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "85cdc4da1a1f041a17f9cb9526ce57dd145c6eba",
      "candidate_info": {
        "commit_hash": "85cdc4da1a1f041a17f9cb9526ce57dd145c6eba",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/85cdc4da1a1f041a17f9cb9526ce57dd145c6eba",
        "files": [
          "scripts/ci/testing/ci_run_airflow_testing.sh"
        ],
        "message": "Bring back Core and Other tests to be run in parallel (#19812)\n\nAfter merging #19809 we can very likely come back to parallel\nrunning of Core and Other tests as we separated them out\nthinking that the parallel runs were the cause of the problems.\n\nThose tests should be perfectly fine to run in parallel now.\n\n(cherry picked from commit 6c80149d0abf84caec8f4c1b4e8795ea5923f89a)",
        "before_after_code_files": [
          "scripts/ci/testing/ci_run_airflow_testing.sh||scripts/ci/testing/ci_run_airflow_testing.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "scripts/ci/testing/ci_run_airflow_testing.sh||scripts/ci/testing/ci_run_airflow_testing.sh": [
          "File: scripts/ci/testing/ci_run_airflow_testing.sh -> scripts/ci/testing/ci_run_airflow_testing.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "92:             test_types_to_run=\"${test_types_to_run//Integration/}\"",
          "93:             sequential_tests+=(\"Integration\")",
          "94:         fi",
          "105:         if [[ ${BACKEND} == \"mssql\" || ${BACKEND} == \"mysql\" ]]; then",
          "106:             # For mssql/mysql - they take far more memory than postgres (or sqlite) - we skip the Provider",
          "107:             # tests altogether as they take too much memory even if run sequentially.",
          "",
          "[Removed Lines]",
          "95:         if [[ ${test_types_to_run} == *\"Core\"* ]]; then",
          "96:             echo \"${COLOR_YELLOW}Remove Core from tests_types_to_run and add them to sequential tests due to low memory.${COLOR_RESET}\"",
          "97:             test_types_to_run=\"${test_types_to_run//Core/}\"",
          "98:             sequential_tests+=(\"Core\")",
          "99:         fi",
          "100:         if [[ ${test_types_to_run} == *\"Other\"* ]]; then",
          "101:             echo \"${COLOR_YELLOW}Remove Other from tests_types_to_run and add them to sequential tests due to low memory.${COLOR_RESET}\"",
          "102:             test_types_to_run=\"${test_types_to_run//Other/}\"",
          "103:             sequential_tests+=(\"Other\")",
          "104:         fi",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "92ef164624fd4068aa4becf2052f14d8d0dffd1b",
      "candidate_info": {
        "commit_hash": "92ef164624fd4068aa4becf2052f14d8d0dffd1b",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/92ef164624fd4068aa4becf2052f14d8d0dffd1b",
        "files": [
          "dev/prepare_prod_docker_images.sh"
        ],
        "message": "Add exiting on error in prod image script (#20447)\n\nThe script did not fail but continued on error which might have\nresulted in one or more images missing.\n\nAdding `set -e` fixes it.\n\n(cherry picked from commit 52f3c7ca679350ccc60dfb5b0c5cd9c98e2d7e23)",
        "before_after_code_files": [
          "dev/prepare_prod_docker_images.sh||dev/prepare_prod_docker_images.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "dev/prepare_prod_docker_images.sh||dev/prepare_prod_docker_images.sh": [
          "File: dev/prepare_prod_docker_images.sh -> dev/prepare_prod_docker_images.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: AIRFLOW_SOURCES_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\"/.. && pwd)\"",
          "19: export AIRFLOW_SOURCES_DIR",
          "21: CURRENT_PYTHON_MAJOR_MINOR_VERSIONS=(\"3.7\" \"3.8\" \"3.9\" \"3.6\")",
          "23: usage() {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "21: set -e",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "d2ae684a09c85fc557b24e2fb4421df7da79a9b0",
      "candidate_info": {
        "commit_hash": "d2ae684a09c85fc557b24e2fb4421df7da79a9b0",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/d2ae684a09c85fc557b24e2fb4421df7da79a9b0",
        "files": [
          ".pre-commit-config.yaml",
          "airflow/decorators/base.py",
          "airflow/decorators/python.py",
          "airflow/decorators/python_virtualenv.py",
          "tests/decorators/test_python.py"
        ],
        "message": "Enhance `multiple_outputs` inference of dict typing (#19608)\n\n(cherry picked from commit 4198550bba474e7942705a4c6df2ad916fb76561)",
        "before_after_code_files": [
          "airflow/decorators/base.py||airflow/decorators/base.py",
          "airflow/decorators/python.py||airflow/decorators/python.py",
          "airflow/decorators/python_virtualenv.py||airflow/decorators/python_virtualenv.py",
          "tests/decorators/test_python.py||tests/decorators/test_python.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/decorators/base.py||airflow/decorators/base.py": [
          "File: airflow/decorators/base.py -> airflow/decorators/base.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: import functools",
          "19: import inspect",
          "20: import re",
          "21: from inspect import signature",
          "22: from typing import Any, Callable, Dict, Optional, Tuple, TypeVar, cast",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "21: import sys",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "91:     :param op_args: a list of positional arguments that will get unpacked when",
          "92:         calling your callable (templated)",
          "93:     :type op_args: list",
          "97:     :type multiple_outputs: bool",
          "98:     :param kwargs_to_upstream: For certain operators, we might need to upstream certain arguments",
          "99:         that would otherwise be absorbed by the DecoratedOperator (for example python_callable for the",
          "",
          "[Removed Lines]",
          "94:     :param multiple_outputs: if set, function return value will be",
          "95:         unrolled to multiple XCom values. Dict will unroll to xcom values with keys as keys.",
          "96:         Defaults to False.",
          "",
          "[Added Lines]",
          "95:     :param multiple_outputs: If set to True, the decorated function's return value will be unrolled to",
          "96:         multiple XCom values. Dict will unroll to XCom values with its keys as XCom keys. Defaults to False.",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "190:     :param python_callable: Function to decorate",
          "191:     :type python_callable: Optional[Callable]",
          "196:     :type multiple_outputs: bool",
          "197:     :param decorated_operator_class: The operator that executes the logic needed to run the python function in",
          "198:         the correct environment",
          "",
          "[Removed Lines]",
          "192:     :param multiple_outputs: if set, function return value will be",
          "193:         unrolled to multiple XCom values. List/Tuples will unroll to xcom values",
          "194:         with index as key. Dict will unroll to xcom values with keys as XCom keys.",
          "195:         Defaults to False.",
          "",
          "[Added Lines]",
          "192:     :param multiple_outputs: If set to True, the decorated function's return value will be unrolled to",
          "193:         multiple XCom values. Dict will unroll to XCom values with its keys as XCom keys. Defaults to False.",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "201:     \"\"\"",
          "202:     # try to infer from  type annotation",
          "203:     if python_callable and multiple_outputs is None:",
          "209:     def wrapper(f: T):",
          "210:         \"\"\"",
          "",
          "[Removed Lines]",
          "204:         sig = signature(python_callable).return_annotation",
          "205:         ttype = getattr(sig, \"__origin__\", None)",
          "207:         multiple_outputs = sig != inspect.Signature.empty and ttype in (dict, Dict)",
          "",
          "[Added Lines]",
          "202:         return_type = signature(python_callable).return_annotation",
          "204:         # If the return type annotation is already the builtins ``dict`` type, use it for the inference.",
          "205:         if return_type == dict:",
          "206:             ttype = return_type",
          "207:         # Checking if Python 3.6, ``__origin__`` attribute does not exist until 3.7; need to use ``__extra__``",
          "208:         # TODO: Remove check when support for Python 3.6 is dropped in Airflow 2.3.",
          "209:         elif sys.version_info < (3, 7):",
          "210:             ttype = getattr(return_type, \"__extra__\", None)",
          "211:         else:",
          "212:             ttype = getattr(return_type, \"__origin__\", None)",
          "214:         multiple_outputs = return_type != inspect.Signature.empty and ttype in (dict, Dict)",
          "",
          "---------------"
        ],
        "airflow/decorators/python.py||airflow/decorators/python.py": [
          "File: airflow/decorators/python.py -> airflow/decorators/python.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "33:     :param op_args: a list of positional arguments that will get unpacked when",
          "34:         calling your callable (templated)",
          "35:     :type op_args: list",
          "39:     :type multiple_outputs: bool",
          "40:     \"\"\"",
          "",
          "[Removed Lines]",
          "36:     :param multiple_outputs: if set, function return value will be",
          "37:         unrolled to multiple XCom values. Dict will unroll to xcom values with keys as keys.",
          "38:         Defaults to False.",
          "",
          "[Added Lines]",
          "36:     :param multiple_outputs: If set to True, the decorated function's return value will be unrolled to",
          "37:         multiple XCom values. Dict will unroll to XCom values with its keys as XCom keys. Defaults to False.",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "86:         :param python_callable: Function to decorate",
          "87:         :type python_callable: Optional[Callable]",
          "91:             Defaults to False.",
          "92:         :type multiple_outputs: bool",
          "93:         \"\"\"",
          "",
          "[Removed Lines]",
          "88:         :param multiple_outputs: if set, function return value will be",
          "89:             unrolled to multiple XCom values. List/Tuples will unroll to xcom values",
          "90:             with index as key. Dict will unroll to xcom values with keys as XCom keys.",
          "",
          "[Added Lines]",
          "87:         :param multiple_outputs: If set to True, the decorated function's return value will be unrolled to",
          "88:             multiple XCom values. Dict will unroll to XCom values with its keys as XCom keys.",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "110:     :param python_callable: Function to decorate",
          "111:     :type python_callable: Optional[Callable]",
          "116:     :type multiple_outputs: bool",
          "117:     \"\"\"",
          "118:     return task_decorator_factory(",
          "",
          "[Removed Lines]",
          "112:     :param multiple_outputs: if set, function return value will be",
          "113:         unrolled to multiple XCom values. List/Tuples will unroll to xcom values",
          "114:         with index as key. Dict will unroll to xcom values with keys as XCom keys.",
          "115:         Defaults to False.",
          "",
          "[Added Lines]",
          "110:     :param multiple_outputs: If set to True, the decorated function's return value will be unrolled to",
          "111:         multiple XCom values. Dict will unroll to XCom values with its keys as XCom keys. Defaults to False.",
          "",
          "---------------"
        ],
        "airflow/decorators/python_virtualenv.py||airflow/decorators/python_virtualenv.py": [
          "File: airflow/decorators/python_virtualenv.py -> airflow/decorators/python_virtualenv.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "36:     :param op_args: a list of positional arguments that will get unpacked when",
          "37:         calling your callable (templated)",
          "38:     :type op_args: list",
          "42:     :type multiple_outputs: bool",
          "43:     \"\"\"",
          "",
          "[Removed Lines]",
          "39:     :param multiple_outputs: if set, function return value will be",
          "40:         unrolled to multiple XCom values. Dict will unroll to xcom values with keys as keys.",
          "41:         Defaults to False.",
          "",
          "[Added Lines]",
          "39:     :param multiple_outputs: If set to True, the decorated function's return value will be unrolled to",
          "40:         multiple XCom values. Dict will unroll to XCom values with its keys as XCom keys. Defaults to False.",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "89:         :param python_callable: Function to decorate",
          "90:         :type python_callable: Optional[Callable]",
          "94:             Defaults to False.",
          "95:         :type multiple_outputs: bool",
          "96:         \"\"\"",
          "",
          "[Removed Lines]",
          "91:         :param multiple_outputs: if set, function return value will be",
          "92:             unrolled to multiple XCom values. List/Tuples will unroll to xcom values",
          "93:             with index as key. Dict will unroll to xcom values with keys as XCom keys.",
          "",
          "[Added Lines]",
          "90:         :param multiple_outputs: If set to True, the decorated function's return value will be unrolled to",
          "91:             multiple XCom values. Dict will unroll to XCom values with its keys as XCom keys.",
          "",
          "---------------"
        ],
        "tests/decorators/test_python.py||tests/decorators/test_python.py": [
          "File: tests/decorators/test_python.py -> tests/decorators/test_python.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "15: # KIND, either express or implied.  See the License for the",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "18: import unittest.mock",
          "19: from collections import namedtuple",
          "20: from datetime import date, timedelta",
          "21: from typing import Dict, Tuple",
          "23: import pytest",
          "25: from airflow.decorators import task as task_decorator",
          "26: from airflow.exceptions import AirflowException",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: import sys",
          "25: from parameterized import parameterized",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "112:         with pytest.raises(AirflowException):",
          "113:             task_decorator(not_callable, dag=self.dag)",
          "122:         @task_decorator",
          "123:         def identity_tuple(x: int, y: int) -> Tuple[int, int]:",
          "124:             return x, y",
          "",
          "[Removed Lines]",
          "115:     def test_infer_multiple_outputs_using_typing(self):",
          "116:         @task_decorator",
          "117:         def identity_dict(x: int, y: int) -> Dict[str, int]:",
          "118:             return {\"x\": x, \"y\": y}",
          "120:         assert identity_dict(5, 5).operator.multiple_outputs is True",
          "",
          "[Added Lines]",
          "117:     @parameterized.expand([[\"dict\"], [\"dict[str, int]\"], [\"Dict\"], [\"Dict[str, int]\"]])",
          "118:     def test_infer_multiple_outputs_using_dict_typing(self, test_return_annotation):",
          "119:         if sys.version_info < (3, 9) and test_return_annotation == \"dict[str, int]\":",
          "120:             self.skipTest(\"dict[...] not a supported typing prior to Python 3.9\")",
          "122:             @task_decorator",
          "123:             def identity_dict(x: int, y: int) -> eval(test_return_annotation):",
          "124:                 return {\"x\": x, \"y\": y}",
          "126:             assert identity_dict(5, 5).operator.multiple_outputs is True",
          "128:             @task_decorator",
          "129:             def identity_dict_stringified(x: int, y: int) -> test_return_annotation:",
          "130:                 return {\"x\": x, \"y\": y}",
          "132:             assert identity_dict_stringified(5, 5).operator.multiple_outputs is True",
          "134:     def test_infer_multiple_outputs_using_other_typing(self):",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "969a275df02a81d1f3176ca010e565fb950e6d35",
      "candidate_info": {
        "commit_hash": "969a275df02a81d1f3176ca010e565fb950e6d35",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/969a275df02a81d1f3176ca010e565fb950e6d35",
        "files": [
          "CONTRIBUTING.rst",
          "UPDATING.md",
          "airflow/example_dags/example_bash_operator.py",
          "airflow/example_dags/example_branch_datetime_operator.py",
          "airflow/example_dags/example_branch_day_of_week_operator.py",
          "airflow/example_dags/example_branch_labels.py",
          "airflow/example_dags/example_branch_operator.py",
          "airflow/example_dags/example_branch_python_dop_operator_3.py",
          "airflow/example_dags/example_complex.py",
          "airflow/example_dags/example_dag_decorator.py",
          "airflow/example_dags/example_external_task_marker_dag.py",
          "airflow/example_dags/example_kubernetes_executor.py",
          "airflow/example_dags/example_latest_only_with_trigger.py",
          "airflow/example_dags/example_nested_branch_dag.py",
          "airflow/example_dags/example_passing_params_via_test_command.py",
          "airflow/example_dags/example_python_operator.py",
          "airflow/example_dags/example_short_circuit_operator.py",
          "airflow/example_dags/example_skip_dag.py",
          "airflow/example_dags/example_sla_dag.py",
          "airflow/example_dags/example_task_group.py",
          "airflow/example_dags/example_task_group_decorator.py",
          "airflow/example_dags/example_time_delta_sensor_async.py",
          "airflow/example_dags/example_trigger_controller_dag.py",
          "airflow/example_dags/example_trigger_target_dag.py",
          "airflow/example_dags/example_xcom.py",
          "airflow/example_dags/example_xcomargs.py",
          "airflow/example_dags/subdags/subdag.py",
          "airflow/example_dags/tutorial_etl_dag.py",
          "airflow/example_dags/tutorial_taskflow_api_etl.py",
          "airflow/models/dag.py",
          "airflow/serialization/serialized_objects.py",
          "docs/apache-airflow/best-practices.rst",
          "docs/apache-airflow/concepts/dags.rst",
          "docs/apache-airflow/concepts/operators.rst",
          "docs/apache-airflow/dag-run.rst",
          "docs/apache-airflow/executor/kubernetes.rst",
          "docs/apache-airflow/faq.rst",
          "docs/apache-airflow/howto/timetable.rst",
          "docs/apache-airflow/lineage.rst",
          "docs/apache-airflow/logging-monitoring/callbacks.rst",
          "docs/apache-airflow/timezone.rst",
          "docs/apache-airflow/tutorial.rst",
          "docs/docker-stack/docker-examples/extending/embedding-dags/test_dag.py"
        ],
        "message": "Clarify pendulum use in timezone cases (#21646)\n\nIt is important to use Pendulum in case timezone is used - because\nthere are a number of limitations coming from using stdlib\ntimezone implementation.\n\nHowever our documentation was not very clear about it, especially\nsome examples shown using standard datetime in DAGs which could\nmislead our users to continue using datetime if they use timezone.\n\nThis PR clarifies and stresses the use of pendulum is necessary\nwhen timezone is used. Also it points to the documentation\nin case serialization throws error about not using Pendulum\nso that the users can learn about the reasoning.\n\nThis is the first part of the change - the follow up will be\nchanging all provider examples to also use timezone and\npendulum explicitly.\n\nSee also #20070\n\n(cherry picked from commit f011da235f705411239d992bc3c92f1c072f89a9)",
        "before_after_code_files": [
          "airflow/example_dags/example_bash_operator.py||airflow/example_dags/example_bash_operator.py",
          "airflow/example_dags/example_branch_datetime_operator.py||airflow/example_dags/example_branch_datetime_operator.py",
          "airflow/example_dags/example_branch_day_of_week_operator.py||airflow/example_dags/example_branch_day_of_week_operator.py",
          "airflow/example_dags/example_branch_labels.py||airflow/example_dags/example_branch_labels.py",
          "airflow/example_dags/example_branch_operator.py||airflow/example_dags/example_branch_operator.py",
          "airflow/example_dags/example_branch_python_dop_operator_3.py||airflow/example_dags/example_branch_python_dop_operator_3.py",
          "airflow/example_dags/example_complex.py||airflow/example_dags/example_complex.py",
          "airflow/example_dags/example_dag_decorator.py||airflow/example_dags/example_dag_decorator.py",
          "airflow/example_dags/example_external_task_marker_dag.py||airflow/example_dags/example_external_task_marker_dag.py",
          "airflow/example_dags/example_kubernetes_executor.py||airflow/example_dags/example_kubernetes_executor.py",
          "airflow/example_dags/example_latest_only_with_trigger.py||airflow/example_dags/example_latest_only_with_trigger.py",
          "airflow/example_dags/example_nested_branch_dag.py||airflow/example_dags/example_nested_branch_dag.py",
          "airflow/example_dags/example_passing_params_via_test_command.py||airflow/example_dags/example_passing_params_via_test_command.py",
          "airflow/example_dags/example_python_operator.py||airflow/example_dags/example_python_operator.py",
          "airflow/example_dags/example_short_circuit_operator.py||airflow/example_dags/example_short_circuit_operator.py",
          "airflow/example_dags/example_skip_dag.py||airflow/example_dags/example_skip_dag.py",
          "airflow/example_dags/example_sla_dag.py||airflow/example_dags/example_sla_dag.py",
          "airflow/example_dags/example_task_group.py||airflow/example_dags/example_task_group.py",
          "airflow/example_dags/example_task_group_decorator.py||airflow/example_dags/example_task_group_decorator.py",
          "airflow/example_dags/example_time_delta_sensor_async.py||airflow/example_dags/example_time_delta_sensor_async.py",
          "airflow/example_dags/example_trigger_controller_dag.py||airflow/example_dags/example_trigger_controller_dag.py",
          "airflow/example_dags/example_trigger_target_dag.py||airflow/example_dags/example_trigger_target_dag.py",
          "airflow/example_dags/example_xcom.py||airflow/example_dags/example_xcom.py",
          "airflow/example_dags/example_xcomargs.py||airflow/example_dags/example_xcomargs.py",
          "airflow/example_dags/subdags/subdag.py||airflow/example_dags/subdags/subdag.py",
          "airflow/example_dags/tutorial_etl_dag.py||airflow/example_dags/tutorial_etl_dag.py",
          "airflow/example_dags/tutorial_taskflow_api_etl.py||airflow/example_dags/tutorial_taskflow_api_etl.py",
          "airflow/models/dag.py||airflow/models/dag.py",
          "airflow/serialization/serialized_objects.py||airflow/serialization/serialized_objects.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/example_dags/example_bash_operator.py||airflow/example_dags/example_bash_operator.py": [
          "File: airflow/example_dags/example_bash_operator.py -> airflow/example_dags/example_bash_operator.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: \"\"\"Example DAG demonstrating the usage of the BashOperator.\"\"\"",
          "23: from airflow import DAG",
          "24: from airflow.operators.bash import BashOperator",
          "",
          "[Removed Lines]",
          "21: from datetime import datetime, timedelta",
          "",
          "[Added Lines]",
          "21: import datetime",
          "23: import pendulum",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "27: with DAG(",
          "28:     dag_id='example_bash_operator',",
          "29:     schedule_interval='0 0 * * *',",
          "31:     catchup=False,",
          "33:     tags=['example', 'example2'],",
          "34:     params={\"example_key\": \"example_value\"},",
          "35: ) as dag:",
          "",
          "[Removed Lines]",
          "30:     start_date=datetime(2021, 1, 1),",
          "32:     dagrun_timeout=timedelta(minutes=60),",
          "",
          "[Added Lines]",
          "32:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "34:     dagrun_timeout=datetime.timedelta(minutes=60),",
          "",
          "---------------"
        ],
        "airflow/example_dags/example_branch_datetime_operator.py||airflow/example_dags/example_branch_datetime_operator.py": [
          "File: airflow/example_dags/example_branch_datetime_operator.py -> airflow/example_dags/example_branch_datetime_operator.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: Example DAG demonstrating the usage of DateTimeBranchOperator with datetime as well as time objects as",
          "21: targets.",
          "22: \"\"\"",
          "25: from airflow import DAG",
          "26: from airflow.operators.datetime import BranchDateTimeOperator",
          "",
          "[Removed Lines]",
          "23: import datetime",
          "",
          "[Added Lines]",
          "23: import pendulum",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "29: dag = DAG(",
          "30:     dag_id=\"example_branch_datetime_operator\",",
          "32:     catchup=False,",
          "33:     tags=[\"example\"],",
          "34:     schedule_interval=\"@daily\",",
          "",
          "[Removed Lines]",
          "31:     start_date=datetime.datetime(2021, 1, 1),",
          "",
          "[Added Lines]",
          "31:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "42:     task_id='datetime_branch',",
          "43:     follow_task_ids_if_true=['date_in_range'],",
          "44:     follow_task_ids_if_false=['date_outside_range'],",
          "47:     dag=dag,",
          "48: )",
          "",
          "[Removed Lines]",
          "45:     target_upper=datetime.datetime(2020, 10, 10, 15, 0, 0),",
          "46:     target_lower=datetime.datetime(2020, 10, 10, 14, 0, 0),",
          "",
          "[Added Lines]",
          "45:     target_upper=pendulum.datetime(2020, 10, 10, 15, 0, 0),",
          "46:     target_lower=pendulum.datetime(2020, 10, 10, 14, 0, 0),",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "55: dag = DAG(",
          "56:     dag_id=\"example_branch_datetime_operator_2\",",
          "58:     catchup=False,",
          "59:     tags=[\"example\"],",
          "60:     schedule_interval=\"@daily\",",
          "",
          "[Removed Lines]",
          "57:     start_date=datetime.datetime(2021, 1, 1),",
          "",
          "[Added Lines]",
          "57:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "67:     task_id='datetime_branch',",
          "68:     follow_task_ids_if_true=['date_in_range'],",
          "69:     follow_task_ids_if_false=['date_outside_range'],",
          "72:     dag=dag,",
          "73: )",
          "",
          "[Removed Lines]",
          "70:     target_upper=datetime.time(0, 0, 0),",
          "71:     target_lower=datetime.time(15, 0, 0),",
          "",
          "[Added Lines]",
          "70:     target_upper=pendulum.time(0, 0, 0),",
          "71:     target_lower=pendulum.time(15, 0, 0),",
          "",
          "---------------"
        ],
        "airflow/example_dags/example_branch_day_of_week_operator.py||airflow/example_dags/example_branch_day_of_week_operator.py": [
          "File: airflow/example_dags/example_branch_day_of_week_operator.py -> airflow/example_dags/example_branch_day_of_week_operator.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: \"\"\"",
          "20: Example DAG demonstrating the usage of BranchDayOfWeekOperator.",
          "21: \"\"\"",
          "24: from airflow import DAG",
          "25: from airflow.operators.dummy import DummyOperator",
          "",
          "[Removed Lines]",
          "22: from datetime import datetime",
          "",
          "[Added Lines]",
          "22: import pendulum",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "28: with DAG(",
          "29:     dag_id=\"example_weekday_branch_operator\",",
          "31:     catchup=False,",
          "32:     tags=[\"example\"],",
          "33:     schedule_interval=\"@daily\",",
          "",
          "[Removed Lines]",
          "30:     start_date=datetime(2021, 1, 1),",
          "",
          "[Added Lines]",
          "30:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "",
          "---------------"
        ],
        "airflow/example_dags/example_branch_labels.py||airflow/example_dags/example_branch_labels.py": [
          "File: airflow/example_dags/example_branch_labels.py -> airflow/example_dags/example_branch_labels.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: \"\"\"",
          "20: Example DAG demonstrating the usage of labels with different branches.",
          "21: \"\"\"",
          "24: from airflow import DAG",
          "25: from airflow.operators.dummy import DummyOperator",
          "26: from airflow.utils.edgemodifier import Label",
          "28: with DAG(",
          "30: ) as dag:",
          "31:     ingest = DummyOperator(task_id=\"ingest\")",
          "32:     analyse = DummyOperator(task_id=\"analyze\")",
          "",
          "[Removed Lines]",
          "22: from datetime import datetime",
          "29:     \"example_branch_labels\", schedule_interval=\"@daily\", start_date=datetime(2021, 1, 1), catchup=False",
          "",
          "[Added Lines]",
          "22: import pendulum",
          "29:     \"example_branch_labels\",",
          "30:     schedule_interval=\"@daily\",",
          "31:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "32:     catchup=False,",
          "",
          "---------------"
        ],
        "airflow/example_dags/example_branch_operator.py||airflow/example_dags/example_branch_operator.py": [
          "File: airflow/example_dags/example_branch_operator.py -> airflow/example_dags/example_branch_operator.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: \"\"\"Example DAG demonstrating the usage of the BranchPythonOperator.\"\"\"",
          "21: import random",
          "24: from airflow import DAG",
          "25: from airflow.operators.dummy import DummyOperator",
          "",
          "[Removed Lines]",
          "22: from datetime import datetime",
          "",
          "[Added Lines]",
          "23: import pendulum",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "30: with DAG(",
          "31:     dag_id='example_branch_operator',",
          "33:     catchup=False,",
          "34:     schedule_interval=\"@daily\",",
          "35:     tags=['example', 'example2'],",
          "",
          "[Removed Lines]",
          "32:     start_date=datetime(2021, 1, 1),",
          "",
          "[Added Lines]",
          "33:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "",
          "---------------"
        ],
        "airflow/example_dags/example_branch_python_dop_operator_3.py||airflow/example_dags/example_branch_python_dop_operator_3.py": [
          "File: airflow/example_dags/example_branch_python_dop_operator_3.py -> airflow/example_dags/example_branch_python_dop_operator_3.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: Example DAG demonstrating the usage of BranchPythonOperator with depends_on_past=True, where tasks may be run",
          "21: or skipped on alternating runs.",
          "22: \"\"\"",
          "25: from airflow import DAG",
          "26: from airflow.operators.dummy import DummyOperator",
          "",
          "[Removed Lines]",
          "23: from datetime import datetime",
          "",
          "[Added Lines]",
          "23: import pendulum",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "49: with DAG(",
          "50:     dag_id='example_branch_dop_operator_v3',",
          "51:     schedule_interval='*/1 * * * *',",
          "53:     catchup=False,",
          "54:     default_args={'depends_on_past': True},",
          "55:     tags=['example'],",
          "",
          "[Removed Lines]",
          "52:     start_date=datetime(2021, 1, 1),",
          "",
          "[Added Lines]",
          "52:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "",
          "---------------"
        ],
        "airflow/example_dags/example_complex.py||airflow/example_dags/example_complex.py": [
          "File: airflow/example_dags/example_complex.py -> airflow/example_dags/example_complex.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: \"\"\"",
          "20: Example Airflow DAG that shows the complex DAG structure.",
          "21: \"\"\"",
          "24: from airflow import models",
          "25: from airflow.models.baseoperator import chain",
          "",
          "[Removed Lines]",
          "22: from datetime import datetime",
          "",
          "[Added Lines]",
          "22: import pendulum",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "28: with models.DAG(",
          "29:     dag_id=\"example_complex\",",
          "30:     schedule_interval=None,",
          "32:     catchup=False,",
          "33:     tags=['example', 'example2', 'example3'],",
          "34: ) as dag:",
          "",
          "[Removed Lines]",
          "31:     start_date=datetime(2021, 1, 1),",
          "",
          "[Added Lines]",
          "31:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "",
          "---------------"
        ],
        "airflow/example_dags/example_dag_decorator.py||airflow/example_dags/example_dag_decorator.py": [
          "File: airflow/example_dags/example_dag_decorator.py -> airflow/example_dags/example_dag_decorator.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "15: # KIND, either express or implied.  See the License for the",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "19: from typing import Any, Dict",
          "21: import httpx",
          "23: from airflow.decorators import dag, task",
          "24: from airflow.models.baseoperator import BaseOperator",
          "",
          "[Removed Lines]",
          "18: from datetime import datetime",
          "",
          "[Added Lines]",
          "21: import pendulum",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "39: # [START dag_decorator_usage]",
          "41: def example_dag_decorator(email: str = 'example@example.com'):",
          "42:     \"\"\"",
          "43:     DAG to send server IP to email.",
          "",
          "[Removed Lines]",
          "40: @dag(schedule_interval=None, start_date=datetime(2021, 1, 1), catchup=False, tags=['example'])",
          "",
          "[Added Lines]",
          "40: @dag(",
          "41:     schedule_interval=None,",
          "42:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "43:     catchup=False,",
          "44:     tags=['example'],",
          "45: )",
          "",
          "---------------"
        ],
        "airflow/example_dags/example_external_task_marker_dag.py||airflow/example_dags/example_external_task_marker_dag.py": [
          "File: airflow/example_dags/example_external_task_marker_dag.py -> airflow/example_dags/example_external_task_marker_dag.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "37:     exception",
          "38: \"\"\"",
          "42: from airflow import DAG",
          "43: from airflow.operators.dummy import DummyOperator",
          "44: from airflow.sensors.external_task import ExternalTaskMarker, ExternalTaskSensor",
          "48: with DAG(",
          "49:     dag_id=\"example_external_task_marker_parent\",",
          "",
          "[Removed Lines]",
          "40: import datetime",
          "46: start_date = datetime.datetime(2015, 1, 1)",
          "",
          "[Added Lines]",
          "40: import pendulum",
          "46: start_date = pendulum.datetime(2021, 1, 1, tz=\"UTC\")",
          "",
          "---------------"
        ],
        "airflow/example_dags/example_kubernetes_executor.py||airflow/example_dags/example_kubernetes_executor.py": [
          "File: airflow/example_dags/example_kubernetes_executor.py -> airflow/example_dags/example_kubernetes_executor.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: \"\"\"",
          "21: import logging",
          "22: import os",
          "25: from airflow import DAG",
          "26: from airflow.configuration import conf",
          "",
          "[Removed Lines]",
          "23: from datetime import datetime",
          "",
          "[Added Lines]",
          "24: import pendulum",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "45:     with DAG(",
          "46:         dag_id='example_kubernetes_executor',",
          "47:         schedule_interval=None,",
          "49:         catchup=False,",
          "50:         tags=['example3'],",
          "51:     ) as dag:",
          "",
          "[Removed Lines]",
          "48:         start_date=datetime(2021, 1, 1),",
          "",
          "[Added Lines]",
          "49:         start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "",
          "---------------"
        ],
        "airflow/example_dags/example_latest_only_with_trigger.py||airflow/example_dags/example_latest_only_with_trigger.py": [
          "File: airflow/example_dags/example_latest_only_with_trigger.py -> airflow/example_dags/example_latest_only_with_trigger.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: \"\"\"",
          "22: # [START example]",
          "25: from airflow import DAG",
          "26: from airflow.operators.dummy import DummyOperator",
          "",
          "[Removed Lines]",
          "23: import datetime as dt",
          "",
          "[Added Lines]",
          "23: import datetime",
          "25: import pendulum",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "30: with DAG(",
          "31:     dag_id='latest_only_with_trigger',",
          "34:     catchup=False,",
          "35:     tags=['example3'],",
          "36: ) as dag:",
          "",
          "[Removed Lines]",
          "32:     schedule_interval=dt.timedelta(hours=4),",
          "33:     start_date=dt.datetime(2021, 1, 1),",
          "",
          "[Added Lines]",
          "34:     schedule_interval=datetime.timedelta(hours=4),",
          "35:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "",
          "---------------"
        ],
        "airflow/example_dags/example_nested_branch_dag.py||airflow/example_dags/example_nested_branch_dag.py": [
          "File: airflow/example_dags/example_nested_branch_dag.py -> airflow/example_dags/example_nested_branch_dag.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: ``none_failed_min_one_success`` trigger rule such that they are skipped whenever their corresponding",
          "22: ``BranchPythonOperator`` are skipped.",
          "23: \"\"\"",
          "26: from airflow.models import DAG",
          "27: from airflow.operators.dummy import DummyOperator",
          "",
          "[Removed Lines]",
          "24: from datetime import datetime",
          "",
          "[Added Lines]",
          "24: import pendulum",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "31: with DAG(",
          "32:     dag_id=\"example_nested_branch_dag\",",
          "34:     catchup=False,",
          "35:     schedule_interval=\"@daily\",",
          "36:     tags=[\"example\"],",
          "",
          "[Removed Lines]",
          "33:     start_date=datetime(2021, 1, 1),",
          "",
          "[Added Lines]",
          "33:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "",
          "---------------"
        ],
        "airflow/example_dags/example_passing_params_via_test_command.py||airflow/example_dags/example_passing_params_via_test_command.py": [
          "File: airflow/example_dags/example_passing_params_via_test_command.py -> airflow/example_dags/example_passing_params_via_test_command.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: \"\"\"Example DAG demonstrating the usage of the params arguments in templated arguments.\"\"\"",
          "21: import os",
          "23: from textwrap import dedent",
          "25: from airflow import DAG",
          "26: from airflow.decorators import task",
          "27: from airflow.operators.bash import BashOperator",
          "",
          "[Removed Lines]",
          "22: from datetime import datetime, timedelta",
          "",
          "[Added Lines]",
          "21: import datetime",
          "25: import pendulum",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "61: with DAG(",
          "62:     \"example_passing_params_via_test_command\",",
          "63:     schedule_interval='*/1 * * * *',",
          "65:     catchup=False,",
          "67:     tags=['example'],",
          "68: ) as dag:",
          "69:     run_this = my_py_command(params={\"miff\": \"agg\"})",
          "",
          "[Removed Lines]",
          "64:     start_date=datetime(2021, 1, 1),",
          "66:     dagrun_timeout=timedelta(minutes=4),",
          "",
          "[Added Lines]",
          "66:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "68:     dagrun_timeout=datetime.timedelta(minutes=4),",
          "",
          "---------------"
        ],
        "airflow/example_dags/example_python_operator.py||airflow/example_dags/example_python_operator.py": [
          "File: airflow/example_dags/example_python_operator.py -> airflow/example_dags/example_python_operator.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "23: import logging",
          "24: import shutil",
          "25: import time",
          "27: from pprint import pprint",
          "29: from airflow import DAG",
          "30: from airflow.decorators import task",
          "",
          "[Removed Lines]",
          "26: from datetime import datetime",
          "",
          "[Added Lines]",
          "28: import pendulum",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "34: with DAG(",
          "35:     dag_id='example_python_operator',",
          "36:     schedule_interval=None,",
          "38:     catchup=False,",
          "39:     tags=['example'],",
          "40: ) as dag:",
          "",
          "[Removed Lines]",
          "37:     start_date=datetime(2021, 1, 1),",
          "",
          "[Added Lines]",
          "38:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "",
          "---------------"
        ],
        "airflow/example_dags/example_short_circuit_operator.py||airflow/example_dags/example_short_circuit_operator.py": [
          "File: airflow/example_dags/example_short_circuit_operator.py -> airflow/example_dags/example_short_circuit_operator.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: # under the License.",
          "19: \"\"\"Example DAG demonstrating the usage of the ShortCircuitOperator.\"\"\"",
          "22: from airflow import DAG",
          "23: from airflow.models.baseoperator import chain",
          "",
          "[Removed Lines]",
          "20: from datetime import datetime",
          "",
          "[Added Lines]",
          "20: import pendulum",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "27: with DAG(",
          "28:     dag_id='example_short_circuit_operator',",
          "30:     catchup=False,",
          "31:     tags=['example'],",
          "32: ) as dag:",
          "",
          "[Removed Lines]",
          "29:     start_date=datetime(2021, 1, 1),",
          "",
          "[Added Lines]",
          "29:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "",
          "---------------"
        ],
        "airflow/example_dags/example_skip_dag.py||airflow/example_dags/example_skip_dag.py": [
          "File: airflow/example_dags/example_skip_dag.py -> airflow/example_dags/example_skip_dag.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: \"\"\"Example DAG demonstrating the DummyOperator and a custom DummySkipOperator which skips by default.\"\"\"",
          "23: from airflow import DAG",
          "24: from airflow.exceptions import AirflowSkipException",
          "",
          "[Removed Lines]",
          "21: from datetime import datetime",
          "",
          "[Added Lines]",
          "21: import pendulum",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "54:     join >> final",
          "58:     create_test_pipeline('1', TriggerRule.ALL_SUCCESS)",
          "59:     create_test_pipeline('2', TriggerRule.ONE_SUCCESS)",
          "",
          "[Removed Lines]",
          "57: with DAG(dag_id='example_skip_dag', start_date=datetime(2021, 1, 1), catchup=False, tags=['example']) as dag:",
          "",
          "[Added Lines]",
          "57: with DAG(",
          "58:     dag_id='example_skip_dag',",
          "59:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "60:     catchup=False,",
          "61:     tags=['example'],",
          "62: ) as dag:",
          "",
          "---------------"
        ],
        "airflow/example_dags/example_sla_dag.py||airflow/example_dags/example_sla_dag.py": [
          "File: airflow/example_dags/example_sla_dag.py -> airflow/example_dags/example_sla_dag.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "15: # specific language governing permissions and limitations",
          "16: # under the License.",
          "18: import time",
          "21: from airflow.decorators import dag, task",
          "",
          "[Removed Lines]",
          "19: from datetime import datetime, timedelta",
          "",
          "[Added Lines]",
          "18: import datetime",
          "21: import pendulum",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "40: @dag(",
          "41:     schedule_interval=\"*/2 * * * *\",",
          "43:     catchup=False,",
          "44:     sla_miss_callback=sla_callback,",
          "45:     default_args={'email': \"email@example.com\"},",
          "46: )",
          "47: def example_sla_dag():",
          "49:     def sleep_20():",
          "50:         \"\"\"Sleep for 20 seconds\"\"\"",
          "51:         time.sleep(20)",
          "",
          "[Removed Lines]",
          "42:     start_date=datetime(2021, 1, 1),",
          "48:     @task(sla=timedelta(seconds=10))",
          "",
          "[Added Lines]",
          "44:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "50:     @task(sla=datetime.timedelta(seconds=10))",
          "",
          "---------------"
        ],
        "airflow/example_dags/example_task_group.py||airflow/example_dags/example_task_group.py": [
          "File: airflow/example_dags/example_task_group.py -> airflow/example_dags/example_task_group.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: # under the License.",
          "19: \"\"\"Example DAG demonstrating the usage of the TaskGroup.\"\"\"",
          "22: from airflow.models.dag import DAG",
          "23: from airflow.operators.bash import BashOperator",
          "",
          "[Removed Lines]",
          "20: from datetime import datetime",
          "",
          "[Added Lines]",
          "20: import pendulum",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "27: # [START howto_task_group]",
          "28: with DAG(",
          "30: ) as dag:",
          "31:     start = DummyOperator(task_id=\"start\")",
          "",
          "[Removed Lines]",
          "29:     dag_id=\"example_task_group\", start_date=datetime(2021, 1, 1), catchup=False, tags=[\"example\"]",
          "",
          "[Added Lines]",
          "29:     dag_id=\"example_task_group\",",
          "30:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "31:     catchup=False,",
          "32:     tags=[\"example\"],",
          "",
          "---------------"
        ],
        "airflow/example_dags/example_task_group_decorator.py||airflow/example_dags/example_task_group_decorator.py": [
          "File: airflow/example_dags/example_task_group_decorator.py -> airflow/example_dags/example_task_group_decorator.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: \"\"\"Example DAG demonstrating the usage of the @taskgroup decorator.\"\"\"",
          "23: from airflow.decorators import task, task_group",
          "24: from airflow.models.dag import DAG",
          "",
          "[Removed Lines]",
          "21: from datetime import datetime",
          "",
          "[Added Lines]",
          "21: import pendulum",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "66: # Executing Tasks and TaskGroups",
          "67: with DAG(",
          "69: ) as dag:",
          "70:     start_task = task_start()",
          "71:     end_task = task_end()",
          "",
          "[Removed Lines]",
          "68:     dag_id=\"example_task_group_decorator\", start_date=datetime(2021, 1, 1), catchup=False, tags=[\"example\"]",
          "",
          "[Added Lines]",
          "68:     dag_id=\"example_task_group_decorator\",",
          "69:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "70:     catchup=False,",
          "71:     tags=[\"example\"],",
          "",
          "---------------"
        ],
        "airflow/example_dags/example_time_delta_sensor_async.py||airflow/example_dags/example_time_delta_sensor_async.py": [
          "File: airflow/example_dags/example_time_delta_sensor_async.py -> airflow/example_dags/example_time_delta_sensor_async.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: defers and doesn't occupy a worker slot while it waits",
          "22: \"\"\"",
          "26: from airflow import DAG",
          "27: from airflow.operators.dummy import DummyOperator",
          "",
          "[Removed Lines]",
          "24: from datetime import datetime, timedelta",
          "",
          "[Added Lines]",
          "24: import datetime",
          "26: import pendulum",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "30: with DAG(",
          "31:     dag_id=\"example_time_delta_sensor_async\",",
          "32:     schedule_interval=None,",
          "34:     catchup=False,",
          "35:     tags=[\"example\"],",
          "36: ) as dag:",
          "38:     finish = DummyOperator(task_id=\"finish\")",
          "39:     wait >> finish",
          "",
          "[Removed Lines]",
          "33:     start_date=datetime(2021, 1, 1),",
          "37:     wait = TimeDeltaSensorAsync(task_id=\"wait\", delta=timedelta(seconds=10))",
          "",
          "[Added Lines]",
          "35:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "39:     wait = TimeDeltaSensorAsync(task_id=\"wait\", delta=datetime.timedelta(seconds=10))",
          "",
          "---------------"
        ],
        "airflow/example_dags/example_trigger_controller_dag.py||airflow/example_dags/example_trigger_controller_dag.py": [
          "File: airflow/example_dags/example_trigger_controller_dag.py -> airflow/example_dags/example_trigger_controller_dag.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: 1. 1st DAG (example_trigger_controller_dag) holds a TriggerDagRunOperator, which will trigger the 2nd DAG",
          "22: 2. 2nd DAG (example_trigger_target_dag) which will be triggered by the TriggerDagRunOperator in the 1st DAG",
          "23: \"\"\"",
          "26: from airflow import DAG",
          "27: from airflow.operators.trigger_dagrun import TriggerDagRunOperator",
          "29: with DAG(",
          "30:     dag_id=\"example_trigger_controller_dag\",",
          "32:     catchup=False,",
          "33:     schedule_interval=\"@once\",",
          "34:     tags=['example'],",
          "",
          "[Removed Lines]",
          "24: from datetime import datetime",
          "31:     start_date=datetime(2021, 1, 1),",
          "",
          "[Added Lines]",
          "24: import pendulum",
          "31:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "",
          "---------------"
        ],
        "airflow/example_dags/example_trigger_target_dag.py||airflow/example_dags/example_trigger_target_dag.py": [
          "File: airflow/example_dags/example_trigger_target_dag.py -> airflow/example_dags/example_trigger_target_dag.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: 1. 1st DAG (example_trigger_controller_dag) holds a TriggerDagRunOperator, which will trigger the 2nd DAG",
          "22: 2. 2nd DAG (example_trigger_target_dag) which will be triggered by the TriggerDagRunOperator in the 1st DAG",
          "23: \"\"\"",
          "26: from airflow import DAG",
          "27: from airflow.decorators import task",
          "",
          "[Removed Lines]",
          "24: from datetime import datetime",
          "",
          "[Added Lines]",
          "24: import pendulum",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "42: with DAG(",
          "43:     dag_id=\"example_trigger_target_dag\",",
          "45:     catchup=False,",
          "46:     schedule_interval=None,",
          "47:     tags=['example'],",
          "",
          "[Removed Lines]",
          "44:     start_date=datetime(2021, 1, 1),",
          "",
          "[Added Lines]",
          "44:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "",
          "---------------"
        ],
        "airflow/example_dags/example_xcom.py||airflow/example_dags/example_xcom.py": [
          "File: airflow/example_dags/example_xcom.py -> airflow/example_dags/example_xcom.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: # under the License.",
          "19: \"\"\"Example DAG demonstrating the usage of XComs.\"\"\"",
          "22: from airflow import DAG",
          "23: from airflow.decorators import task",
          "",
          "[Removed Lines]",
          "20: from datetime import datetime",
          "",
          "[Added Lines]",
          "20: import pendulum",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "64: with DAG(",
          "65:     'example_xcom',",
          "66:     schedule_interval=\"@once\",",
          "68:     catchup=False,",
          "69:     tags=['example'],",
          "70: ) as dag:",
          "",
          "[Removed Lines]",
          "67:     start_date=datetime(2021, 1, 1),",
          "",
          "[Added Lines]",
          "67:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "",
          "---------------"
        ],
        "airflow/example_dags/example_xcomargs.py||airflow/example_dags/example_xcomargs.py": [
          "File: airflow/example_dags/example_xcomargs.py -> airflow/example_dags/example_xcomargs.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: \"\"\"Example DAG demonstrating the usage of the XComArgs.\"\"\"",
          "20: import logging",
          "23: from airflow import DAG",
          "24: from airflow.decorators import task",
          "",
          "[Removed Lines]",
          "21: from datetime import datetime",
          "",
          "[Added Lines]",
          "22: import pendulum",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "42: with DAG(",
          "43:     dag_id='example_xcom_args',",
          "45:     catchup=False,",
          "46:     schedule_interval=None,",
          "47:     tags=['example'],",
          "",
          "[Removed Lines]",
          "44:     start_date=datetime(2021, 1, 1),",
          "",
          "[Added Lines]",
          "45:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "51: with DAG(",
          "52:     \"example_xcom_args_with_operators\",",
          "54:     catchup=False,",
          "55:     schedule_interval=None,",
          "56:     tags=['example'],",
          "",
          "[Removed Lines]",
          "53:     start_date=datetime(2021, 1, 1),",
          "",
          "[Added Lines]",
          "54:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "",
          "---------------"
        ],
        "airflow/example_dags/subdags/subdag.py||airflow/example_dags/subdags/subdag.py": [
          "File: airflow/example_dags/subdags/subdag.py -> airflow/example_dags/subdags/subdag.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: \"\"\"Helper function to generate a DAG and operators given some arguments.\"\"\"",
          "21: # [START subdag]",
          "24: from airflow import DAG",
          "25: from airflow.operators.dummy import DummyOperator",
          "",
          "[Removed Lines]",
          "22: from datetime import datetime",
          "",
          "[Added Lines]",
          "22: import pendulum",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "38:     dag_subdag = DAG(",
          "39:         dag_id=f'{parent_dag_name}.{child_dag_name}',",
          "40:         default_args=args,",
          "42:         catchup=False,",
          "43:         schedule_interval=\"@daily\",",
          "44:     )",
          "",
          "[Removed Lines]",
          "41:         start_date=datetime(2021, 1, 1),",
          "",
          "[Added Lines]",
          "41:         start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "",
          "---------------"
        ],
        "airflow/example_dags/tutorial_etl_dag.py||airflow/example_dags/tutorial_etl_dag.py": [
          "File: airflow/example_dags/tutorial_etl_dag.py -> airflow/example_dags/tutorial_etl_dag.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "24: # [START tutorial]",
          "25: # [START import_module]",
          "26: import json",
          "28: from textwrap import dedent",
          "30: # The DAG object; we'll need this to instantiate a DAG",
          "31: from airflow import DAG",
          "",
          "[Removed Lines]",
          "27: from datetime import datetime",
          "",
          "[Added Lines]",
          "29: import pendulum",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "45:     # [END default_args]",
          "46:     description='ETL DAG tutorial',",
          "47:     schedule_interval=None,",
          "49:     catchup=False,",
          "50:     tags=['example'],",
          "51: ) as dag:",
          "",
          "[Removed Lines]",
          "48:     start_date=datetime(2021, 1, 1),",
          "",
          "[Added Lines]",
          "49:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "",
          "---------------"
        ],
        "airflow/example_dags/tutorial_taskflow_api_etl.py||airflow/example_dags/tutorial_taskflow_api_etl.py": [
          "File: airflow/example_dags/tutorial_taskflow_api_etl.py -> airflow/example_dags/tutorial_taskflow_api_etl.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: # [START tutorial]",
          "21: # [START import_module]",
          "22: import json",
          "25: from airflow.decorators import dag, task",
          "",
          "[Removed Lines]",
          "23: from datetime import datetime",
          "",
          "[Added Lines]",
          "24: import pendulum",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "30: # [START instantiate_dag]",
          "32: def tutorial_taskflow_api_etl():",
          "33:     \"\"\"",
          "34:     ### TaskFlow API Tutorial Documentation",
          "",
          "[Removed Lines]",
          "31: @dag(schedule_interval=None, start_date=datetime(2021, 1, 1), catchup=False, tags=['example'])",
          "",
          "[Added Lines]",
          "32: @dag(",
          "33:     schedule_interval=None,",
          "34:     start_date=pendulum.datetime(2021, 1, 1, tz=\"UTC\"),",
          "35:     catchup=False,",
          "36:     tags=['example'],",
          "37: )",
          "",
          "---------------"
        ],
        "airflow/models/dag.py||airflow/models/dag.py": [
          "File: airflow/models/dag.py -> airflow/models/dag.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "187:     DAGs essentially act as namespaces for tasks. A task_id can only be",
          "188:     added once to a DAG.",
          "190:     :param dag_id: The id of the DAG; must consist exclusively of alphanumeric",
          "191:         characters, dashes, dots and underscores (all ASCII)",
          "192:     :type dag_id: str",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "190:     Note that if you plan to use time zones all the dates provided should be pendulum",
          "191:     dates. See :ref:`timezone_aware_dags`.",
          "",
          "---------------"
        ],
        "airflow/serialization/serialized_objects.py||airflow/serialization/serialized_objects.py": [
          "File: airflow/serialization/serialized_objects.py -> airflow/serialization/serialized_objects.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "42: from airflow.settings import json",
          "43: from airflow.timetables.base import Timetable",
          "44: from airflow.utils.code_utils import get_python_source",
          "45: from airflow.utils.module_loading import as_importable_string, import_string",
          "46: from airflow.utils.task_group import TaskGroup",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "45: from airflow.utils.docs import get_docs_url",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "113:         return var.offset",
          "114:     if isinstance(var, Timezone):",
          "115:         return var.name",
          "119: def decode_timezone(var: Union[str, int]) -> Timezone:",
          "",
          "[Removed Lines]",
          "116:     raise ValueError(f\"DAG timezone should be a pendulum.tz.Timezone, not {var!r}\")",
          "",
          "[Added Lines]",
          "117:     raise ValueError(",
          "118:         f\"DAG timezone should be a pendulum.tz.Timezone, not {var!r}. \"",
          "119:         f\"See {get_docs_url('timezone.html#time-zone-aware-dags')}\"",
          "120:     )",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "68f729cb3cab4c1daef8d20a24068030accc0576",
      "candidate_info": {
        "commit_hash": "68f729cb3cab4c1daef8d20a24068030accc0576",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/68f729cb3cab4c1daef8d20a24068030accc0576",
        "files": [
          "scripts/ci/libraries/_kind.sh"
        ],
        "message": "Stop polling when Webserver doesn't start up in Kube tests (#19598)\n\n(cherry picked from commit 6c20444cc688621795dc46a640b3885a9e735e47)",
        "before_after_code_files": [
          "scripts/ci/libraries/_kind.sh||scripts/ci/libraries/_kind.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "scripts/ci/libraries/_kind.sh||scripts/ci/libraries/_kind.sh": [
          "File: scripts/ci/libraries/_kind.sh -> scripts/ci/libraries/_kind.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "298:             echo",
          "299:             echo  \"${COLOR_RED}ERROR: Timeout while waiting for the webserver health check  ${COLOR_RESET}\"",
          "300:             echo",
          "301:         fi",
          "302:     done",
          "303:     echo",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "301:             return 1",
          "",
          "---------------"
        ]
      }
    }
  ]
}