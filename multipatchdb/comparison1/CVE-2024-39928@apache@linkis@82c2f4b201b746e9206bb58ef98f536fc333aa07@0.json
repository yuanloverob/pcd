{
  "cve_id": "CVE-2024-39928",
  "cve_desc": "In Apache Linkis <= 1.5.0, a Random string security vulnerability in Spark EngineConn,\u00a0random string generated by the Token when starting Py4j uses the Commons Lang's RandomStringUtils.\nUsers are recommended to upgrade to version 1.6.0, which fixes this issue.",
  "repo": "apache/linkis",
  "patch_hash": "82c2f4b201b746e9206bb58ef98f536fc333aa07",
  "patch_info": {
    "commit_hash": "82c2f4b201b746e9206bb58ef98f536fc333aa07",
    "repo": "apache/linkis",
    "commit_url": "https://github.com/apache/linkis/commit/82c2f4b201b746e9206bb58ef98f536fc333aa07",
    "files": [
      "LICENSE",
      "linkis-engineconn-plugins/spark/src/main/java/org/apache/linkis/engineplugin/spark/executor/SecureRandomStringUtils.java",
      "linkis-engineconn-plugins/spark/src/main/scala/org/apache/linkis/engineplugin/spark/executor/SparkPythonExecutor.scala"
    ],
    "message": "[MINOR] add util for generating random strings (#5143)",
    "before_after_code_files": [
      "linkis-engineconn-plugins/spark/src/main/java/org/apache/linkis/engineplugin/spark/executor/SecureRandomStringUtils.java||linkis-engineconn-plugins/spark/src/main/java/org/apache/linkis/engineplugin/spark/executor/SecureRandomStringUtils.java",
      "linkis-engineconn-plugins/spark/src/main/scala/org/apache/linkis/engineplugin/spark/executor/SparkPythonExecutor.scala||linkis-engineconn-plugins/spark/src/main/scala/org/apache/linkis/engineplugin/spark/executor/SparkPythonExecutor.scala"
    ]
  },
  "patch_diff": {
    "linkis-engineconn-plugins/spark/src/main/java/org/apache/linkis/engineplugin/spark/executor/SecureRandomStringUtils.java||linkis-engineconn-plugins/spark/src/main/java/org/apache/linkis/engineplugin/spark/executor/SecureRandomStringUtils.java": [
      "File: linkis-engineconn-plugins/spark/src/main/java/org/apache/linkis/engineplugin/spark/executor/SecureRandomStringUtils.java -> linkis-engineconn-plugins/spark/src/main/java/org/apache/linkis/engineplugin/spark/executor/SecureRandomStringUtils.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "[No context available]",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "18: package org.apache.linkis.engineplugin.spark.executor;",
      "20: import org.apache.commons.lang3.StringUtils;",
      "22: import java.security.NoSuchAlgorithmException;",
      "23: import java.security.SecureRandom;",
      "30: final class SecureRandomStringUtils {",
      "34:   private static SecureRandom RANDOM_INSTANCE;",
      "36:   private static SecureRandom random() {",
      "37:     if (RANDOM_INSTANCE != null) {",
      "38:       return RANDOM_INSTANCE;",
      "39:     }",
      "40:     try {",
      "41:       RANDOM_INSTANCE = SecureRandom.getInstanceStrong();",
      "42:       return RANDOM_INSTANCE;",
      "43:     } catch (NoSuchAlgorithmException e) {",
      "44:       throw new IllegalStateException(\"Cannot create SecureRandom.getInstanceStrong()\", e);",
      "45:     }",
      "46:   }",
      "59:   public static String randomAlphanumeric(final int count) {",
      "60:     return random(count, true, true);",
      "61:   }",
      "75:   private static String random(final int count, final boolean letters, final boolean numbers) {",
      "76:     return random(count, 0, 0, letters, numbers);",
      "77:   }",
      "93:   private static String random(",
      "94:       final int count,",
      "95:       final int start,",
      "96:       final int end,",
      "97:       final boolean letters,",
      "98:       final boolean numbers) {",
      "99:     return random(count, start, end, letters, numbers, null, random());",
      "100:   }",
      "128:   private static String random(",
      "129:       int count,",
      "130:       int start,",
      "131:       int end,",
      "132:       final boolean letters,",
      "133:       final boolean numbers,",
      "134:       final char[] chars,",
      "135:       final SecureRandom random) {",
      "136:     if (count == 0) {",
      "137:       return StringUtils.EMPTY;",
      "138:     }",
      "139:     if (count < 0) {",
      "140:       throw new IllegalArgumentException(",
      "141:           \"Requested random string length \" + count + \" is less than 0.\");",
      "142:     }",
      "143:     if (chars != null && chars.length == 0) {",
      "144:       throw new IllegalArgumentException(\"The chars array must not be empty\");",
      "145:     }",
      "147:     if (start == 0 && end == 0) {",
      "148:       if (chars != null) {",
      "149:         end = chars.length;",
      "150:       } else if (!letters && !numbers) {",
      "151:         end = Character.MAX_CODE_POINT;",
      "152:       } else {",
      "153:         end = 'z' + 1;",
      "154:         start = ' ';",
      "155:       }",
      "156:     } else if (end <= start) {",
      "157:       throw new IllegalArgumentException(",
      "158:           \"Parameter end (\" + end + \") must be greater than start (\" + start + \")\");",
      "159:     }",
      "161:     final int zeroDigitAscii = 48;",
      "162:     final int firstLetterAscii = 65;",
      "164:     if (chars == null && (numbers && end <= zeroDigitAscii || letters && end <= firstLetterAscii)) {",
      "165:       throw new IllegalArgumentException(",
      "166:           \"Parameter end (\"",
      "167:               + end",
      "168:               + \") must be greater then (\"",
      "169:               + zeroDigitAscii",
      "170:               + \") for generating digits \"",
      "171:               + \"or greater then (\"",
      "172:               + firstLetterAscii",
      "173:               + \") for generating letters.\");",
      "174:     }",
      "176:     final StringBuilder builder = new StringBuilder(count);",
      "177:     final int gap = end - start;",
      "179:     while (count-- != 0) {",
      "180:       final int codePoint;",
      "181:       if (chars == null) {",
      "182:         codePoint = random.nextInt(gap) + start;",
      "184:         switch (Character.getType(codePoint)) {",
      "185:           case Character.UNASSIGNED:",
      "186:           case Character.PRIVATE_USE:",
      "187:           case Character.SURROGATE:",
      "188:             count++;",
      "189:             continue;",
      "190:         }",
      "192:       } else {",
      "193:         codePoint = chars[random.nextInt(gap) + start];",
      "194:       }",
      "196:       final int numberOfChars = Character.charCount(codePoint);",
      "197:       if (count == 0 && numberOfChars > 1) {",
      "198:         count++;",
      "199:         continue;",
      "200:       }",
      "202:       if (letters && Character.isLetter(codePoint)",
      "203:           || numbers && Character.isDigit(codePoint)",
      "204:           || !letters && !numbers) {",
      "205:         builder.appendCodePoint(codePoint);",
      "207:         if (numberOfChars == 2) {",
      "208:           count--;",
      "209:         }",
      "211:       } else {",
      "212:         count++;",
      "213:       }",
      "214:     }",
      "215:     return builder.toString();",
      "216:   }",
      "218:   private SecureRandomStringUtils() {",
      "220:   }",
      "221: }",
      "",
      "---------------"
    ],
    "linkis-engineconn-plugins/spark/src/main/scala/org/apache/linkis/engineplugin/spark/executor/SparkPythonExecutor.scala||linkis-engineconn-plugins/spark/src/main/scala/org/apache/linkis/engineplugin/spark/executor/SparkPythonExecutor.scala": [
      "File: linkis-engineconn-plugins/spark/src/main/scala/org/apache/linkis/engineplugin/spark/executor/SparkPythonExecutor.scala -> linkis-engineconn-plugins/spark/src/main/scala/org/apache/linkis/engineplugin/spark/executor/SparkPythonExecutor.scala",
      "--- Hunk 1 ---",
      "[Context before]",
      "39: import org.apache.commons.exec.CommandLine",
      "40: import org.apache.commons.io.IOUtils",
      "42: import org.apache.spark.SparkConf",
      "43: import org.apache.spark.api.java.JavaSparkContext",
      "44: import org.apache.spark.sql.{DataFrame, SparkSession}",
      "",
      "[Removed Lines]",
      "41: import org.apache.commons.lang3.{RandomStringUtils, StringUtils}",
      "",
      "[Added Lines]",
      "41: import org.apache.commons.lang3.StringUtils",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "47: import java.io._",
      "48: import java.net.InetAddress",
      "50: import java.util",
      "52: import scala.collection.JavaConverters._",
      "",
      "[Removed Lines]",
      "49: import java.security.SecureRandom",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "77:   private val lineOutputStream = new RsOutputStream",
      "78:   val sqlContext = sparkEngineSession.sqlContext",
      "79:   val SUCCESS = \"success\"",
      "82:   private lazy val gwBuilder: GatewayServerBuilder = {",
      "83:     val builder = new GatewayServerBuilder()",
      "",
      "[Removed Lines]",
      "80:   private lazy val py4jToken: String = SecureRandom.getInstance(\"SHA1PRNG\").nextInt(100000).toString",
      "",
      "[Added Lines]",
      "79:   private lazy val py4jToken: String = SecureRandomStringUtils.randomAlphanumeric(256)",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "2fdf9d3e2ed2ed29a4c6a2382249286883818acb",
      "candidate_info": {
        "commit_hash": "2fdf9d3e2ed2ed29a4c6a2382249286883818acb",
        "repo": "apache/linkis",
        "commit_url": "https://github.com/apache/linkis/commit/2fdf9d3e2ed2ed29a4c6a2382249286883818acb",
        "files": [
          ".asf.yaml",
          "linkis-engineconn-plugins/spark/src/main/scala/org/apache/linkis/engineplugin/spark/config/SparkConfiguration.scala",
          "linkis-engineconn-plugins/spark/src/main/scala/org/apache/linkis/engineplugin/spark/executor/SparkPythonExecutor.scala",
          "linkis-public-enhancements/distribution.xml",
          "linkis-public-enhancements/linkis-datasource/linkis-datasource-manager/server/src/main/assembly/distribution.xml"
        ],
        "message": "[EnginePlugin][Spark]Turn off use secure random by default (#5197)\n\n* Turn off use secure random by default close #5196\n\n* Update Notification Mailing List\n\n* Fix ds meta service build",
        "before_after_code_files": [
          "linkis-engineconn-plugins/spark/src/main/scala/org/apache/linkis/engineplugin/spark/config/SparkConfiguration.scala||linkis-engineconn-plugins/spark/src/main/scala/org/apache/linkis/engineplugin/spark/config/SparkConfiguration.scala",
          "linkis-engineconn-plugins/spark/src/main/scala/org/apache/linkis/engineplugin/spark/executor/SparkPythonExecutor.scala||linkis-engineconn-plugins/spark/src/main/scala/org/apache/linkis/engineplugin/spark/executor/SparkPythonExecutor.scala"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "linkis-engineconn-plugins/spark/src/main/scala/org/apache/linkis/engineplugin/spark/executor/SparkPythonExecutor.scala||linkis-engineconn-plugins/spark/src/main/scala/org/apache/linkis/engineplugin/spark/executor/SparkPythonExecutor.scala"
          ],
          "candidate": [
            "linkis-engineconn-plugins/spark/src/main/scala/org/apache/linkis/engineplugin/spark/executor/SparkPythonExecutor.scala||linkis-engineconn-plugins/spark/src/main/scala/org/apache/linkis/engineplugin/spark/executor/SparkPythonExecutor.scala"
          ]
        }
      },
      "candidate_diff": {
        "linkis-engineconn-plugins/spark/src/main/scala/org/apache/linkis/engineplugin/spark/config/SparkConfiguration.scala||linkis-engineconn-plugins/spark/src/main/scala/org/apache/linkis/engineplugin/spark/config/SparkConfiguration.scala": [
          "File: linkis-engineconn-plugins/spark/src/main/scala/org/apache/linkis/engineplugin/spark/config/SparkConfiguration.scala -> linkis-engineconn-plugins/spark/src/main/scala/org/apache/linkis/engineplugin/spark/config/SparkConfiguration.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "156:     CommonVars(\"wds.linkis.spark.engineconn.fatal.log\", \"error writing class;OutOfMemoryError\")",
          "158:   val PYSPARK_PYTHON3_PATH =",
          "161:   val ENABLE_REPLACE_PACKAGE_NAME =",
          "162:     CommonVars(\"wds.linkis.spark.engine.scala.replace_package_header.enable\", true)",
          "",
          "[Removed Lines]",
          "159:     CommonVars[String](\"pyspark.python3.path\", \"/appcom/Install/anaconda3/bin/python\")",
          "",
          "[Added Lines]",
          "159:     CommonVars[String](\"pyspark.python3.path\", \"python3\")",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "183:   val LINKIS_SPARK_ETL_SUPPORT_HUDI = CommonVars[Boolean](\"linkis.spark.etl.support.hudi\", false)",
          "185:   val SCALA_PARSE_APPEND_CODE =",
          "186:     CommonVars(\"linkis.scala.parse.append.code\", \"val linkisVar=1\").getValue",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "185:   val LINKIS_PYSPARK_USE_SECURE_RANDOM =",
          "186:     CommonVars[Boolean](\"linkis.pyspark.use.secure.random\", false).getValue",
          "",
          "---------------"
        ],
        "linkis-engineconn-plugins/spark/src/main/scala/org/apache/linkis/engineplugin/spark/executor/SparkPythonExecutor.scala||linkis-engineconn-plugins/spark/src/main/scala/org/apache/linkis/engineplugin/spark/executor/SparkPythonExecutor.scala": [
          "File: linkis-engineconn-plugins/spark/src/main/scala/org/apache/linkis/engineplugin/spark/executor/SparkPythonExecutor.scala -> linkis-engineconn-plugins/spark/src/main/scala/org/apache/linkis/engineplugin/spark/executor/SparkPythonExecutor.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "47: import java.io._",
          "48: import java.net.InetAddress",
          "49: import java.util",
          "51: import scala.collection.JavaConverters._",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "49: import java.security.SecureRandom",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "76:   private val lineOutputStream = new RsOutputStream",
          "77:   val sqlContext = sparkEngineSession.sqlContext",
          "78:   val SUCCESS = \"success\"",
          "81:   private lazy val gwBuilder: GatewayServerBuilder = {",
          "82:     val builder = new GatewayServerBuilder()",
          "",
          "[Removed Lines]",
          "79:   private lazy val py4jToken: String = SecureRandomStringUtils.randomAlphanumeric(256)",
          "",
          "[Added Lines]",
          "81:   private lazy val py4jToken: String = if (SparkConfiguration.LINKIS_PYSPARK_USE_SECURE_RANDOM) {",
          "82:     SecureRandomStringUtils.randomAlphanumeric(256)",
          "83:   } else {",
          "84:     SecureRandom.getInstance(\"SHA1PRNG\").nextInt(100000).toString",
          "85:   }",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "152:     )",
          "153:     val userDefinePythonVersion = engineCreationContext.getOptions",
          "154:       .getOrDefault(\"spark.python.version\", \"python\")",
          "156:       .toLowerCase()",
          "157:     val sparkPythonVersion =",
          "158:       if (",
          "",
          "[Removed Lines]",
          "155:       .toString",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ]
      }
    }
  ]
}