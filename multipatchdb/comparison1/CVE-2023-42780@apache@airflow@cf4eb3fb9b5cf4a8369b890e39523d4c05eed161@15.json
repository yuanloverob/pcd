{
  "cve_id": "CVE-2023-42780",
  "cve_desc": "Apache Airflow, versions prior to 2.7.2, contains a security vulnerability that allows authenticated users of Airflow to list warnings for all DAGs, even if the user had no permission to see those DAGs. It would reveal the dag_ids and the stack-traces of import errors for those DAGs with import errors.\nUsers of Apache Airflow are advised to upgrade to version 2.7.2 or newer to mitigate the risk associated with this vulnerability.\n\n",
  "repo": "apache/airflow",
  "patch_hash": "cf4eb3fb9b5cf4a8369b890e39523d4c05eed161",
  "patch_info": {
    "commit_hash": "cf4eb3fb9b5cf4a8369b890e39523d4c05eed161",
    "repo": "apache/airflow",
    "commit_url": "https://github.com/apache/airflow/commit/cf4eb3fb9b5cf4a8369b890e39523d4c05eed161",
    "files": [
      "airflow/api_connexion/endpoints/dag_warning_endpoint.py",
      "tests/api_connexion/endpoints/test_dag_warning_endpoint.py"
    ],
    "message": "Fix dag warning endpoint permissions (#34355)\n\n* Fix dag warning endpoint permissions\n\n* update the query to have an accurate result for total entries and pagination\n\n* add unit tests\n\n* Update test_dag_warning_endpoint.py\n\nCo-authored-by: Tzu-ping Chung <uranusjr@gmail.com>\n\n---------\n\nCo-authored-by: Tzu-ping Chung <uranusjr@gmail.com>\n(cherry picked from commit 3570bbfbea69e2965f91b9964ce28bc268c68129)",
    "before_after_code_files": [
      "airflow/api_connexion/endpoints/dag_warning_endpoint.py||airflow/api_connexion/endpoints/dag_warning_endpoint.py",
      "tests/api_connexion/endpoints/test_dag_warning_endpoint.py||tests/api_connexion/endpoints/test_dag_warning_endpoint.py"
    ]
  },
  "patch_diff": {
    "airflow/api_connexion/endpoints/dag_warning_endpoint.py||airflow/api_connexion/endpoints/dag_warning_endpoint.py": [
      "File: airflow/api_connexion/endpoints/dag_warning_endpoint.py -> airflow/api_connexion/endpoints/dag_warning_endpoint.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "16: # under the License.",
      "17: from __future__ import annotations",
      "19: from sqlalchemy import select",
      "20: from sqlalchemy.orm import Session",
      "22: from airflow.api_connexion import security",
      "23: from airflow.api_connexion.parameters import apply_sorting, check_limit, format_parameters",
      "24: from airflow.api_connexion.schemas.dag_warning_schema import (",
      "25:     DagWarningCollection,",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "19: from flask import g",
      "24: from airflow.api_connexion.exceptions import PermissionDenied",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "28: from airflow.api_connexion.types import APIResponse",
      "29: from airflow.models.dagwarning import DagWarning as DagWarningModel",
      "30: from airflow.security import permissions",
      "31: from airflow.utils.db import get_query_count",
      "32: from airflow.utils.session import NEW_SESSION, provide_session",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "33: from airflow.utils.airflow_flask_app import get_airflow_app",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "52:     allowed_filter_attrs = [\"dag_id\", \"warning_type\", \"message\", \"timestamp\"]",
      "53:     query = select(DagWarningModel)",
      "54:     if dag_id:",
      "55:         query = query.where(DagWarningModel.dag_id == dag_id)",
      "56:     if warning_type:",
      "57:         query = query.where(DagWarningModel.warning_type == warning_type)",
      "58:     total_entries = get_query_count(query, session=session)",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "58:         if not get_airflow_app().appbuilder.sm.can_read_dag(dag_id, g.user):",
      "59:             raise PermissionDenied(detail=f\"User not allowed to access this DAG: {dag_id}\")",
      "61:     else:",
      "62:         readable_dags = get_airflow_app().appbuilder.sm.get_accessible_dag_ids(g.user)",
      "63:         query = query.where(DagWarningModel.dag_id.in_(readable_dags))",
      "",
      "---------------"
    ],
    "tests/api_connexion/endpoints/test_dag_warning_endpoint.py||tests/api_connexion/endpoints/test_dag_warning_endpoint.py": [
      "File: tests/api_connexion/endpoints/test_dag_warning_endpoint.py -> tests/api_connexion/endpoints/test_dag_warning_endpoint.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "35:         app,  # type:ignore",
      "36:         username=\"test\",",
      "37:         role_name=\"Test\",",
      "39:     )",
      "40:     create_user(app, username=\"test_no_permissions\", role_name=\"TestNoPermissions\")  # type: ignore",
      "42:     yield minimal_app_for_api",
      "44:     delete_user(app, username=\"test\")  # type: ignore",
      "45:     delete_user(app, username=\"test_no_permissions\")  # type: ignore",
      "48: class TestBaseDagWarning:",
      "",
      "[Removed Lines]",
      "38:         permissions=[(permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG_WARNING)],  # type: ignore",
      "",
      "[Added Lines]",
      "38:         permissions=[",
      "39:             (permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG_WARNING),",
      "40:             (permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG),",
      "41:         ],  # type: ignore",
      "44:     create_user(",
      "45:         app,  # type:ignore",
      "46:         username=\"test_with_dag2_read\",",
      "47:         role_name=\"TestWithDag2Read\",",
      "48:         permissions=[",
      "49:             (permissions.ACTION_CAN_READ, permissions.RESOURCE_DAG_WARNING),",
      "50:             (permissions.ACTION_CAN_READ, f\"{permissions.RESOURCE_DAG_PREFIX}dag2\"),",
      "51:         ],  # type: ignore",
      "52:     )",
      "58:     delete_user(app, username=\"test_with_dag2_read\")  # type: ignore",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "147:             \"/api/v1/dagWarnings\", environ_overrides={\"REMOTE_USER\": \"test_no_permissions\"}",
      "148:         )",
      "149:         assert response.status_code == 403",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "164:     def test_should_raise_403_forbidden_when_user_has_no_dag_read_permission(self):",
      "165:         response = self.client.get(",
      "166:             \"/api/v1/dagWarnings\",",
      "167:             environ_overrides={\"REMOTE_USER\": \"test_with_dag2_read\"},",
      "168:             query_string={\"dag_id\": \"dag1\"},",
      "169:         )",
      "170:         assert response.status_code == 403",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "b3e2e4cb91784456ce3df45ffcffbc8d38bd0d1c",
      "candidate_info": {
        "commit_hash": "b3e2e4cb91784456ce3df45ffcffbc8d38bd0d1c",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/b3e2e4cb91784456ce3df45ffcffbc8d38bd0d1c",
        "files": [
          "airflow/www/jest-setup.js",
          "airflow/www/static/js/cluster-activity/live-metrics/Health.tsx",
          "airflow/www/static/js/index.d.ts",
          "airflow/www/templates/airflow/cluster_activity.html",
          "airflow/www/views.py"
        ],
        "message": "Hide Irrelevant Dag Processor from Cluster Activity Page (#33611)\n\n* first commit\n\n* refactoring\n\n* adding undefined default\n\n* added logic to check if defined\n\n* refactored component\n\n* refactored not equal sign\n\n* refactored code for boolean type instead of string\n\n* refactored global variable. refactored conditional\n\n* pre-commit and linting fixes\n\n* updated jest-setup\n\n* updated jest-setup\n\n* precommit fix\n\n* Update Health.tsx\n\nreplacing bottom margin with a top margin\n\n* Update Health.tsx\n\nremoved bottom margin from triggerer\n\n(cherry picked from commit c055e1da0b50e98820ffff8f8d10d0882f753384)",
        "before_after_code_files": [
          "airflow/www/jest-setup.js||airflow/www/jest-setup.js",
          "airflow/www/static/js/cluster-activity/live-metrics/Health.tsx||airflow/www/static/js/cluster-activity/live-metrics/Health.tsx",
          "airflow/www/static/js/index.d.ts||airflow/www/static/js/index.d.ts",
          "airflow/www/templates/airflow/cluster_activity.html||airflow/www/templates/airflow/cluster_activity.html",
          "airflow/www/views.py||airflow/www/views.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/34775"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/www/jest-setup.js||airflow/www/jest-setup.js": [
          "File: airflow/www/jest-setup.js -> airflow/www/jest-setup.js",
          "--- Hunk 1 ---",
          "[Context before]",
          "59: global.defaultDagRunDisplayNumber = 245;",
          "61: global.moment = moment;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "63: global.standaloneDagProcessor = true;",
          "",
          "---------------"
        ],
        "airflow/www/static/js/cluster-activity/live-metrics/Health.tsx||airflow/www/static/js/cluster-activity/live-metrics/Health.tsx": [
          "File: airflow/www/static/js/cluster-activity/live-metrics/Health.tsx -> airflow/www/static/js/cluster-activity/live-metrics/Health.tsx",
          "--- Hunk 1 ---",
          "[Context before]",
          "105:               title=\"Triggerer\"",
          "106:               status={data?.triggerer?.status}",
          "107:               latestHeartbeat={data?.triggerer?.latestTriggererHeartbeat}",
          "114:             />",
          "115:           </CardBody>",
          "116:         </Card>",
          "117:       </LoadingWrapper>",
          "",
          "[Removed Lines]",
          "108:               mb={3}",
          "109:             />",
          "110:             <HealthSection",
          "111:               title=\"Dag Processor\"",
          "112:               status={data?.dagProcessor?.status}",
          "113:               latestHeartbeat={data?.dagProcessor?.latestDagProcessorHeartbeat}",
          "",
          "[Added Lines]",
          "108:             {!!standaloneDagProcessor && (",
          "109:               <HealthSection",
          "110:                 title=\"Dag Processor\"",
          "111:                 status={data?.dagProcessor?.status}",
          "112:                 latestHeartbeat={",
          "113:                   data?.dagProcessor?.latestDagProcessorHeartbeat",
          "114:                 }",
          "115:                 mt={3}",
          "116:               />",
          "117:             )}",
          "",
          "---------------"
        ],
        "airflow/www/static/js/index.d.ts||airflow/www/static/js/index.d.ts": [
          "File: airflow/www/static/js/index.d.ts -> airflow/www/static/js/index.d.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "23: declare global {",
          "24:   const autoRefreshInterval: number | undefined;",
          "25:   const stateColors: {",
          "26:     [key: string]: string;",
          "27:   };",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "25:   const standaloneDagProcessor: boolean | undefined;",
          "",
          "---------------"
        ],
        "airflow/www/templates/airflow/cluster_activity.html||airflow/www/templates/airflow/cluster_activity.html": [
          "File: airflow/www/templates/airflow/cluster_activity.html -> airflow/www/templates/airflow/cluster_activity.html",
          "--- Hunk 1 ---",
          "[Context before]",
          "43:   <script>",
          "44:     const stateColors = {{ state_color_mapping|tojson }};",
          "45:     const autoRefreshInterval = {{ auto_refresh_interval }};",
          "46:   </script>",
          "47:   <script src=\"{{ url_for_asset('clusterActivity.js') }}\"></script>",
          "48: {% endblock %}",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "46:     const standaloneDagProcessor = {{ standalone_dag_processor }} === 'True' ;",
          "",
          "---------------"
        ],
        "airflow/www/views.py||airflow/www/views.py": [
          "File: airflow/www/views.py -> airflow/www/views.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1062:         \"\"\"Cluster Activity view.\"\"\"",
          "1063:         state_color_mapping = State.state_color.copy()",
          "1064:         state_color_mapping[\"no_status\"] = state_color_mapping.pop(None)",
          "1065:         return self.render_template(",
          "1066:             \"airflow/cluster_activity.html\",",
          "1067:             auto_refresh_interval=conf.getint(\"webserver\", \"auto_refresh_interval\"),",
          "1068:             state_color_mapping=state_color_mapping,",
          "1069:         )",
          "1071:     @expose(\"/next_run_datasets_summary\", methods=[\"POST\"])",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1065:         standalone_dag_processor = conf.getboolean(\"scheduler\", \"standalone_dag_processor\")",
          "1070:             standalone_dag_processor=standalone_dag_processor,",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "1fd5491636ea03af68fe212a5a9c022795f49c54",
      "candidate_info": {
        "commit_hash": "1fd5491636ea03af68fe212a5a9c022795f49c54",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/1fd5491636ea03af68fe212a5a9c022795f49c54",
        "files": [
          "dev/breeze/src/airflow_breeze/commands/release_management_commands.py"
        ],
        "message": "Only tag :latest image when default python version is used (#34182)\n\nWe should only tag :latest image when default image is used because\nthis step always tags `apache/airflow:X.Y.Z` (defaulti Python) to become\nthe `apache/airflow:latest`. This step was previously run for all Python\nversions which could have two effects:\n\n* if non-default image completed before the default such tagging\n  would fail as the `apache/airflow:X.Y.Z` was not ready yet to\n  be used as target of `apache/airflow:latesti` tag\n\n* if non-default image completed later, it would be no-op because\n  the `apache/airflow:latest` already pointed to `apache/airflow:X.Y.Z`\n\n(cherry picked from commit 51d8b1079b05575c1cf0ca35fcf97ec3c9e1a75b)",
        "before_after_code_files": [
          "dev/breeze/src/airflow_breeze/commands/release_management_commands.py||dev/breeze/src/airflow_breeze/commands/release_management_commands.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/34775"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "dev/breeze/src/airflow_breeze/commands/release_management_commands.py||dev/breeze/src/airflow_breeze/commands/release_management_commands.py": [
          "File: dev/breeze/src/airflow_breeze/commands/release_management_commands.py -> dev/breeze/src/airflow_breeze/commands/release_management_commands.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1032:                     f\"{dockerhub_repo}:{airflow_version}-python{python}\",",
          "1033:                     f\"{dockerhub_repo}:latest-python{python}\",",
          "1034:                 )",
          "1047: def is_package_in_dist(dist_files: list[str], package: str) -> bool:",
          "",
          "[Removed Lines]",
          "1035:         if slim_images:",
          "1036:             alias_image(",
          "1037:                 f\"{dockerhub_repo}:slim-{airflow_version}\",",
          "1038:                 f\"{dockerhub_repo}:slim-latest\",",
          "1039:             )",
          "1040:         else:",
          "1041:             alias_image(",
          "1042:                 f\"{dockerhub_repo}:{airflow_version}\",",
          "1043:                 f\"{dockerhub_repo}:latest\",",
          "1044:             )",
          "",
          "[Added Lines]",
          "1035:         if python == DEFAULT_PYTHON_MAJOR_MINOR_VERSION:",
          "1036:             # only tag latest  \"default\" image when we build default python version",
          "1037:             # otherwise if the non-default images complete before the default one, their jobs will fail",
          "1038:             if slim_images:",
          "1039:                 alias_image(",
          "1040:                     f\"{dockerhub_repo}:slim-{airflow_version}\",",
          "1041:                     f\"{dockerhub_repo}:slim-latest\",",
          "1042:                 )",
          "1043:             else:",
          "1044:                 alias_image(",
          "1045:                     f\"{dockerhub_repo}:{airflow_version}\",",
          "1046:                     f\"{dockerhub_repo}:latest\",",
          "1047:                 )",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "beb33e651097c7f91e7e22ed4079c5671d243f4c",
      "candidate_info": {
        "commit_hash": "beb33e651097c7f91e7e22ed4079c5671d243f4c",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/beb33e651097c7f91e7e22ed4079c5671d243f4c",
        "files": [
          "airflow/www/extensions/init_appbuilder.py",
          "airflow/www/fab_security/manager.py"
        ],
        "message": "Fix FAB-related logging format interpolation (#34139)\n\n(cherry picked from commit fb99f6c9f89f619c69da93a030629ccab4dc52c4)",
        "before_after_code_files": [
          "airflow/www/extensions/init_appbuilder.py||airflow/www/extensions/init_appbuilder.py",
          "airflow/www/fab_security/manager.py||airflow/www/fab_security/manager.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/34775"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/www/extensions/init_appbuilder.py||airflow/www/extensions/init_appbuilder.py": [
          "File: airflow/www/extensions/init_appbuilder.py -> airflow/www/extensions/init_appbuilder.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "69:         return reduce(getattr, tmp[1:], package)",
          "70:     except Exception as e:",
          "71:         log.exception(e)",
          "75: class AirflowAppBuilder:",
          "",
          "[Removed Lines]",
          "72:         log.error(LOGMSG_ERR_FAB_ADDON_IMPORT.format(class_path, e))",
          "",
          "[Added Lines]",
          "72:         log.error(LOGMSG_ERR_FAB_ADDON_IMPORT, class_path, e)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "352:                     addon_class.register_views()",
          "353:                     addon_class.post_process()",
          "354:                     self.addon_managers[addon] = addon_class",
          "356:                 except Exception as e:",
          "357:                     log.exception(e)",
          "360:     def _check_and_init(self, baseview):",
          "361:         if hasattr(baseview, \"datamodel\"):",
          "",
          "[Removed Lines]",
          "355:                     log.info(LOGMSG_INF_FAB_ADDON_ADDED.format(str(addon)))",
          "358:                     log.error(LOGMSG_ERR_FAB_ADDON_PROCESS.format(addon, e))",
          "",
          "[Added Lines]",
          "355:                     log.info(LOGMSG_INF_FAB_ADDON_ADDED, addon)",
          "358:                     log.error(LOGMSG_ERR_FAB_ADDON_PROCESS, addon, e)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "443:             appbuilder.add_link(\"google\", href=\"www.google.com\", icon = \"fa-google-plus\")",
          "444:         \"\"\"",
          "445:         baseview = self._check_and_init(baseview)",
          "448:         if not self._view_exists(baseview):",
          "449:             baseview.appbuilder = self",
          "",
          "[Removed Lines]",
          "446:         log.info(LOGMSG_INF_FAB_ADD_VIEW.format(baseview.__class__.__name__, name))",
          "",
          "[Added Lines]",
          "446:         log.info(LOGMSG_INF_FAB_ADD_VIEW, baseview.__class__.__name__, name)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "544:         :param baseview: A BaseView type class instantiated.",
          "545:         \"\"\"",
          "546:         baseview = self._check_and_init(baseview)",
          "549:         if not self._view_exists(baseview):",
          "550:             baseview.appbuilder = self",
          "",
          "[Removed Lines]",
          "547:         log.info(LOGMSG_INF_FAB_ADD_VIEW.format(baseview.__class__.__name__, \"\"))",
          "",
          "[Added Lines]",
          "547:         log.info(LOGMSG_INF_FAB_ADD_VIEW, baseview.__class__.__name__, \"\")",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "554:                 self.register_blueprint(baseview, endpoint=endpoint, static_folder=static_folder)",
          "555:                 self._add_permission(baseview)",
          "556:         else:",
          "558:         return baseview",
          "560:     def security_cleanup(self):",
          "",
          "[Removed Lines]",
          "557:             log.warning(LOGMSG_WAR_FAB_VIEW_EXISTS.format(baseview.__class__.__name__))",
          "",
          "[Added Lines]",
          "557:             log.warning(LOGMSG_WAR_FAB_VIEW_EXISTS, baseview.__class__.__name__)",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "620:                 self.sm.add_permissions_view(baseview.base_permissions, baseview.class_permission_name)",
          "621:             except Exception as e:",
          "622:                 log.exception(e)",
          "625:     def _add_permissions_menu(self, name, update_perms=False):",
          "626:         if self.update_perms or update_perms:",
          "",
          "[Removed Lines]",
          "623:                 log.error(LOGMSG_ERR_FAB_ADD_PERMISSION_VIEW.format(str(e)))",
          "",
          "[Added Lines]",
          "623:                 log.error(LOGMSG_ERR_FAB_ADD_PERMISSION_VIEW, e)",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "628:                 self.sm.add_permissions_menu(name)",
          "629:             except Exception as e:",
          "630:                 log.exception(e)",
          "633:     def _add_menu_permissions(self, update_perms=False):",
          "634:         if self.update_perms or update_perms:",
          "",
          "[Removed Lines]",
          "631:                 log.error(LOGMSG_ERR_FAB_ADD_PERMISSION_MENU.format(str(e)))",
          "",
          "[Added Lines]",
          "631:                 log.error(LOGMSG_ERR_FAB_ADD_PERMISSION_MENU, e)",
          "",
          "---------------"
        ],
        "airflow/www/fab_security/manager.py||airflow/www/fab_security/manager.py": [
          "File: airflow/www/fab_security/manager.py -> airflow/www/fab_security/manager.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "724:                 \"c0976a03d2f18f680bfff877c9a965db9eedc51bc0be87c\",",
          "725:                 \"password\",",
          "726:             )",
          "728:             return None",
          "729:         elif check_password_hash(user.password, password):",
          "730:             self._rotate_session_id()",
          "",
          "[Removed Lines]",
          "727:             log.info(LOGMSG_WAR_SEC_LOGIN_FAILED.format(username))",
          "",
          "[Added Lines]",
          "727:             log.info(LOGMSG_WAR_SEC_LOGIN_FAILED, username)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "732:             return user",
          "733:         else:",
          "734:             self.update_user_auth_stat(user, False)",
          "736:             return None",
          "738:     def _search_ldap(self, ldap, con, username):",
          "",
          "[Removed Lines]",
          "735:             log.info(LOGMSG_WAR_SEC_LOGIN_FAILED.format(username))",
          "",
          "[Added Lines]",
          "735:             log.info(LOGMSG_WAR_SEC_LOGIN_FAILED, username)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "912:                 try:",
          "913:                     con.start_tls_s()",
          "914:                 except Exception:",
          "916:                     return None",
          "918:             # Define variables, so we can check if they are set in later steps",
          "",
          "[Removed Lines]",
          "915:                     log.error(LOGMSG_ERR_SEC_AUTH_LDAP_TLS.format(self.auth_ldap_server))",
          "",
          "[Added Lines]",
          "915:                     log.error(LOGMSG_ERR_SEC_AUTH_LDAP_TLS, self.auth_ldap_server)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "941:                 # If search failed, go away",
          "942:                 if user_dn is None:",
          "944:                     return None",
          "946:                 # Bind with user_dn/password (validates credentials)",
          "",
          "[Removed Lines]",
          "943:                     log.info(LOGMSG_WAR_SEC_NOLDAP_OBJ.format(username))",
          "",
          "[Added Lines]",
          "943:                     log.info(LOGMSG_WAR_SEC_NOLDAP_OBJ, username)",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "949:                         self.update_user_auth_stat(user, False)",
          "951:                     # Invalid credentials, go away",
          "953:                     return None",
          "955:             # Flow 2 - (Direct Search Bind):",
          "",
          "[Removed Lines]",
          "952:                     log.info(LOGMSG_WAR_SEC_LOGIN_FAILED.format(username))",
          "",
          "[Added Lines]",
          "952:                     log.info(LOGMSG_WAR_SEC_LOGIN_FAILED, username)",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "980:                         self.update_user_auth_stat(user, False)",
          "982:                     # Invalid credentials, go away",
          "984:                     return None",
          "986:                 # Search for `username` (if AUTH_LDAP_SEARCH is set)",
          "",
          "[Removed Lines]",
          "983:                     log.info(LOGMSG_WAR_SEC_LOGIN_FAILED.format(bind_username))",
          "",
          "[Added Lines]",
          "983:                     log.info(LOGMSG_WAR_SEC_LOGIN_FAILED, bind_username)",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "995:                     # If search failed, go away",
          "996:                     if user_dn is None:",
          "998:                         return None",
          "1000:             # Sync the user's roles",
          "",
          "[Removed Lines]",
          "997:                         log.info(LOGMSG_WAR_SEC_NOLDAP_OBJ.format(username))",
          "",
          "[Added Lines]",
          "997:                         log.info(LOGMSG_WAR_SEC_NOLDAP_OBJ, username)",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "1020:                 # If user registration failed, go away",
          "1021:                 if not user:",
          "1023:                     return None",
          "1025:             # LOGIN SUCCESS (only if user is now registered)",
          "",
          "[Removed Lines]",
          "1022:                     log.info(LOGMSG_ERR_SEC_ADD_REGISTER_USER.format(username))",
          "",
          "[Added Lines]",
          "1022:                     log.info(LOGMSG_ERR_SEC_ADD_REGISTER_USER, username)",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "1035:             if isinstance(e, dict):",
          "1036:                 msg = getattr(e, \"message\", None)",
          "1037:             if (msg is not None) and (\"desc\" in msg):",
          "1039:                 return None",
          "1040:             else:",
          "1041:                 log.error(e)",
          "",
          "[Removed Lines]",
          "1038:                 log.error(LOGMSG_ERR_SEC_AUTH_LDAP.format(e.message[\"desc\"]))",
          "",
          "[Added Lines]",
          "1038:                 log.error(LOGMSG_ERR_SEC_AUTH_LDAP, e.message[\"desc\"])",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "1049:         \"\"\"",
          "1050:         user = self.find_user(email=email)",
          "1051:         if user is None or (not user.is_active):",
          "1053:             return None",
          "1054:         else:",
          "1055:             self._rotate_session_id()",
          "",
          "[Removed Lines]",
          "1052:             log.info(LOGMSG_WAR_SEC_LOGIN_FAILED.format(email))",
          "",
          "[Added Lines]",
          "1052:             log.info(LOGMSG_WAR_SEC_LOGIN_FAILED, email)",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "1079:         # If user does not exist on the DB and not auto user registration,",
          "1080:         # or user is inactive, go away.",
          "1081:         elif user is None or (not user.is_active):",
          "1083:             return None",
          "1085:         self._rotate_session_id()",
          "",
          "[Removed Lines]",
          "1082:             log.info(LOGMSG_WAR_SEC_LOGIN_FAILED.format(username))",
          "",
          "[Added Lines]",
          "1082:             log.info(LOGMSG_WAR_SEC_LOGIN_FAILED, username)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "b1354e3cf37d0f1779e27d1bb18b56e040434547",
      "candidate_info": {
        "commit_hash": "b1354e3cf37d0f1779e27d1bb18b56e040434547",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/b1354e3cf37d0f1779e27d1bb18b56e040434547",
        "files": [
          "airflow/models/dag.py",
          "tests/cli/commands/test_dag_command.py"
        ],
        "message": "Fail dag test if defer without triggerer (#34619)\n\nIf user runs dag.test and task defers and no triggerer is running, we should fail so user does not sit there waiting forever.\n\n---------\n\nCo-authored-by: Tzu-ping Chung <uranusjr@gmail.com>\n(cherry picked from commit e81bb487796780705f6df984fbfed04f555943d7)",
        "before_after_code_files": [
          "airflow/models/dag.py||airflow/models/dag.py",
          "tests/cli/commands/test_dag_command.py||tests/cli/commands/test_dag_command.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/34775"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/models/dag.py||airflow/models/dag.py": [
          "File: airflow/models/dag.py -> airflow/models/dag.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "100: from airflow.models.dagrun import RUN_ID_REGEX, DagRun",
          "101: from airflow.models.operator import Operator",
          "102: from airflow.models.param import DagParam, ParamsDict",
          "104: from airflow.secrets.local_filesystem import LocalFilesystemBackend",
          "105: from airflow.security import permissions",
          "106: from airflow.stats import Stats",
          "",
          "[Removed Lines]",
          "103: from airflow.models.taskinstance import Context, TaskInstance, TaskInstanceKey, clear_task_instances",
          "",
          "[Added Lines]",
          "103: from airflow.models.taskinstance import (",
          "104:     Context,",
          "105:     TaskInstance,",
          "106:     TaskInstanceKey,",
          "107:     TaskReturnCode,",
          "108:     clear_task_instances,",
          "109: )",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "275:     }",
          "278: @functools.total_ordering",
          "279: class DAG(LoggingMixin):",
          "280:     \"\"\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "284: class _StopDagTest(Exception):",
          "285:     \"\"\"",
          "286:     Raise when DAG.test should stop immediately.",
          "288:     :meta private:",
          "289:     \"\"\"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "2757:                 try:",
          "2758:                     add_logger_if_needed(ti)",
          "2759:                     ti.task = tasks[ti.task_id]",
          "2761:                 except Exception:",
          "2762:                     self.log.exception(\"Task failed; ti=%s\", ti)",
          "2763:         if conn_file_path or variable_file_path:",
          "",
          "[Removed Lines]",
          "2760:                     _run_task(ti, session=session)",
          "",
          "[Added Lines]",
          "2774:                     ret = _run_task(ti, session=session)",
          "2775:                     if ret is TaskReturnCode.DEFERRED:",
          "2776:                         if not _triggerer_is_healthy():",
          "2777:                             raise _StopDagTest(",
          "2778:                                 \"Task has deferred but triggerer component is not running. \"",
          "2779:                                 \"You can start the triggerer by running `airflow triggerer` in a terminal.\"",
          "2780:                             )",
          "2781:                 except _StopDagTest:",
          "2782:                     # Let this exception bubble out and not be swallowed by the",
          "2783:                     # except block below.",
          "2784:                     raise",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "3885:             return None",
          "3889:     \"\"\"",
          "3890:     Run a single task instance, and push result to Xcom for downstream tasks.",
          "",
          "[Removed Lines]",
          "3888: def _run_task(ti: TaskInstance, session):",
          "",
          "[Added Lines]",
          "3912: def _triggerer_is_healthy():",
          "3913:     from airflow.jobs.triggerer_job_runner import TriggererJobRunner",
          "3915:     job = TriggererJobRunner.most_recent_job()",
          "3916:     return job and job.is_alive()",
          "3919: def _run_task(ti: TaskInstance, session) -> TaskReturnCode | None:",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "3895:     Args:",
          "3896:         ti: TaskInstance to run",
          "3897:     \"\"\"",
          "3898:     log.info(\"*****************************************************\")",
          "3899:     if ti.map_index > 0:",
          "3900:         log.info(\"Running task %s index %d\", ti.task_id, ti.map_index)",
          "3901:     else:",
          "3902:         log.info(\"Running task %s\", ti.task_id)",
          "3903:     try:",
          "3905:         session.flush()",
          "3906:         log.info(\"%s ran successfully!\", ti.task_id)",
          "3907:     except AirflowSkipException:",
          "3908:         log.info(\"Task Skipped, continuing\")",
          "3909:     log.info(\"*****************************************************\")",
          "3912: def _get_or_create_dagrun(",
          "",
          "[Removed Lines]",
          "3904:         ti._run_raw_task(session=session)",
          "",
          "[Added Lines]",
          "3929:     ret = None",
          "3936:         ret = ti._run_raw_task(session=session)",
          "3942:     return ret",
          "",
          "---------------"
        ],
        "tests/cli/commands/test_dag_command.py||tests/cli/commands/test_dag_command.py": [
          "File: tests/cli/commands/test_dag_command.py -> tests/cli/commands/test_dag_command.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "34: from airflow.api_connexion.schemas.dag_schema import DAGSchema",
          "35: from airflow.cli import cli_parser",
          "36: from airflow.cli.commands import dag_command",
          "37: from airflow.exceptions import AirflowException",
          "38: from airflow.models import DagBag, DagModel, DagRun",
          "39: from airflow.models.serialized_dag import SerializedDagModel",
          "40: from airflow.utils import timezone",
          "41: from airflow.utils.session import create_session",
          "42: from airflow.utils.types import DagRunType",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "37: from airflow.decorators import task",
          "40: from airflow.models.baseoperator import BaseOperator",
          "41: from airflow.models.dag import _StopDagTest",
          "43: from airflow.triggers.temporal import TimeDeltaTrigger",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "816:         )",
          "817:         dag_command.dag_test(cli_args)",
          "818:         assert \"data_interval\" in mock__get_or_create_dagrun.call_args.kwargs",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "824:     def test_dag_test_no_triggerer(self, dag_maker):",
          "825:         with dag_maker() as dag:",
          "827:             @task",
          "828:             def one():",
          "829:                 return 1",
          "831:             @task",
          "832:             def two(val):",
          "833:                 return val + 1",
          "835:             class MyOp(BaseOperator):",
          "836:                 template_fields = (\"tfield\",)",
          "838:                 def __init__(self, tfield, **kwargs):",
          "839:                     self.tfield = tfield",
          "840:                     super().__init__(**kwargs)",
          "842:                 def execute(self, context, event=None):",
          "843:                     if event is None:",
          "844:                         print(\"I AM DEFERRING\")",
          "845:                         self.defer(trigger=TimeDeltaTrigger(timedelta(seconds=20)), method_name=\"execute\")",
          "846:                         return",
          "847:                     print(\"RESUMING\")",
          "848:                     return self.tfield + 1",
          "850:             task_one = one()",
          "851:             task_two = two(task_one)",
          "852:             op = MyOp(task_id=\"abc\", tfield=str(task_two))",
          "853:             task_two >> op",
          "854:         with pytest.raises(_StopDagTest, match=\"Task has deferred but triggerer component is not running\"):",
          "855:             dag.test()",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "084839db3c80d959fb37cdd2868fdaaecb1b2631",
      "candidate_info": {
        "commit_hash": "084839db3c80d959fb37cdd2868fdaaecb1b2631",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/084839db3c80d959fb37cdd2868fdaaecb1b2631",
        "files": [
          "airflow/cli/cli_config.py",
          "airflow/cli/commands/connection_command.py",
          "airflow/www/views.py"
        ],
        "message": "E731: replace lambda by a def method in Airflow core (#33758)\n\n(cherry picked from commit a1d4a20548b18721aa7564a1e415ff866db2bebd)",
        "before_after_code_files": [
          "airflow/cli/cli_config.py||airflow/cli/cli_config.py",
          "airflow/cli/commands/connection_command.py||airflow/cli/commands/connection_command.py",
          "airflow/www/views.py||airflow/www/views.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/34775"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/cli/cli_config.py||airflow/cli/cli_config.py": [
          "File: airflow/cli/cli_config.py -> airflow/cli/cli_config.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "103:         \"\"\"Add this argument to an ArgumentParser.\"\"\"",
          "104:         if \"metavar\" in self.kwargs and \"type\" not in self.kwargs:",
          "105:             if self.kwargs[\"metavar\"] == \"DIRPATH\":",
          "107:                 self.kwargs[\"type\"] = type",
          "108:         parser.add_argument(*self.flags, **self.kwargs)",
          "",
          "[Removed Lines]",
          "106:                 type = lambda x: self._is_valid_directory(parser, x)",
          "",
          "[Added Lines]",
          "107:                 def type(x):",
          "108:                     return self._is_valid_directory(parser, x)",
          "",
          "---------------"
        ],
        "airflow/cli/commands/connection_command.py||airflow/cli/commands/connection_command.py": [
          "File: airflow/cli/commands/connection_command.py -> airflow/cli/commands/connection_command.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "115: def _format_connections(conns: list[Connection], file_format: str, serialization_format: str) -> str:",
          "116:     if serialization_format == \"json\":",
          "118:     elif serialization_format == \"uri\":",
          "119:         serializer_func = Connection.get_uri",
          "120:     else:",
          "",
          "[Removed Lines]",
          "117:         serializer_func = lambda x: json.dumps(_connection_to_dict(x))",
          "",
          "[Added Lines]",
          "118:         def serializer_func(x):",
          "119:             return json.dumps(_connection_to_dict(x))",
          "",
          "---------------"
        ],
        "airflow/www/views.py||airflow/www/views.py": [
          "File: airflow/www/views.py -> airflow/www/views.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "320:     sort_order = conf.get(\"webserver\", \"grid_view_sorting_order\", fallback=\"topological\")",
          "321:     if sort_order == \"topological\":",
          "323:     elif sort_order == \"hierarchical_alphabetical\":",
          "325:     else:",
          "326:         raise AirflowConfigException(f\"Unsupported grid_view_sorting_order: {sort_order}\")",
          "",
          "[Removed Lines]",
          "322:         sort_children_fn = lambda task_group: task_group.topological_sort()",
          "324:         sort_children_fn = lambda task_group: task_group.hierarchical_alphabetical_sort()",
          "",
          "[Added Lines]",
          "323:         def sort_children_fn(task_group):",
          "324:             return task_group.topological_sort()",
          "328:         def sort_children_fn(task_group):",
          "329:             return task_group.hierarchical_alphabetical_sort()",
          "",
          "---------------"
        ]
      }
    }
  ]
}