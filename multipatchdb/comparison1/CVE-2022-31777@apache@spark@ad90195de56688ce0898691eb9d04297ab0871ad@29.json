{
  "cve_id": "CVE-2022-31777",
  "cve_desc": "A stored cross-site scripting (XSS) vulnerability in Apache Spark 3.2.1 and earlier, and 3.3.0, allows remote attackers to execute arbitrary JavaScript in the web browser of a user, by including a malicious payload into the logs which would be returned in logs rendered in the UI.",
  "repo": "apache/spark",
  "patch_hash": "ad90195de56688ce0898691eb9d04297ab0871ad",
  "patch_info": {
    "commit_hash": "ad90195de56688ce0898691eb9d04297ab0871ad",
    "repo": "apache/spark",
    "commit_url": "https://github.com/apache/spark/commit/ad90195de56688ce0898691eb9d04297ab0871ad",
    "files": [
      "core/src/main/resources/org/apache/spark/ui/static/log-view.js"
    ],
    "message": "[SPARK-39505][UI] Escape log content rendered in UI\n\n### What changes were proposed in this pull request?\n\nEscape log content rendered to the UI.\n\n### Why are the changes needed?\n\nLog content may contain reserved characters or other code in the log and be misinterpreted in the UI as HTML.\n\n### Does this PR introduce _any_ user-facing change?\n\nNo\n\n### How was this patch tested?\n\nExisting tests\n\nCloses #36902 from srowen/LogViewEscape.\n\nAuthored-by: Sean Owen <srowen@gmail.com>\nSigned-off-by: Dongjoon Hyun <dongjoon@apache.org>",
    "before_after_code_files": [
      "core/src/main/resources/org/apache/spark/ui/static/log-view.js||core/src/main/resources/org/apache/spark/ui/static/log-view.js"
    ]
  },
  "patch_diff": {
    "core/src/main/resources/org/apache/spark/ui/static/log-view.js||core/src/main/resources/org/apache/spark/ui/static/log-view.js": [
      "File: core/src/main/resources/org/apache/spark/ui/static/log-view.js -> core/src/main/resources/org/apache/spark/ui/static/log-view.js",
      "--- Hunk 1 ---",
      "[Context before]",
      "85:       if (retStartByte == 0) {",
      "86:         disableMoreButton();",
      "87:       }",
      "90:       curLogLength = curLogLength + (startByte - retStartByte);",
      "91:       startByte = retStartByte;",
      "",
      "[Removed Lines]",
      "88:       $(\"pre\", \".log-content\").prepend(cleanData);",
      "",
      "[Added Lines]",
      "88:       $(\"pre\", \".log-content\").prepend(document.createTextNode(cleanData));",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "115:             var retLogLength = dataInfo[2];",
      "117:             var cleanData = data.substring(newlineIndex + 1);",
      "120:             curLogLength = curLogLength + (retEndByte - retStartByte);",
      "121:             endByte = retEndByte;",
      "",
      "[Removed Lines]",
      "118:             $(\"pre\", \".log-content\").append(cleanData);",
      "",
      "[Added Lines]",
      "118:             $(\"pre\", \".log-content\").append(document.createTextNode(cleanData));",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "dc2212ed05bb9c9dc340d7290458da77813222d5",
      "candidate_info": {
        "commit_hash": "dc2212ed05bb9c9dc340d7290458da77813222d5",
        "repo": "apache/spark",
        "commit_url": "https://github.com/apache/spark/commit/dc2212ed05bb9c9dc340d7290458da77813222d5",
        "files": [
          "python/pyspark/ml/feature.py",
          "python/pyspark/ml/feature.pyi"
        ],
        "message": "[SPARK-37405][PYTHON] Inline type hints for python/pyspark/ml/feature.py\n\n### What changes were proposed in this pull request?\nInline type hints for python/pyspark/ml/feature.py\n\n### Why are the changes needed?\nWe can take advantage of static type checking within the functions by inlining the type hints.\n\n### Does this PR introduce _any_ user-facing change?\nNo\n\n### How was this patch tested?\nExisting tests\n\nCloses #35530 from dchvn/SPARK-37405.\n\nLead-authored-by: dch nguyen <dchvn.dgd@gmail.com>\nCo-authored-by: dch nguyen <dgd_contributor@viettel.com.vn>\nSigned-off-by: zero323 <mszymkiewicz@gmail.com>\n(cherry picked from commit 8ce8a70e2f8a04c92a2b0d2f45fcdc8c7c8014be)\nSigned-off-by: zero323 <mszymkiewicz@gmail.com>",
        "before_after_code_files": [
          "python/pyspark/ml/feature.py||python/pyspark/ml/feature.py",
          "python/pyspark/ml/feature.pyi||python/pyspark/ml/feature.pyi"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/jack-steven-root/spark/pull/1"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "python/pyspark/ml/feature.py||python/pyspark/ml/feature.py": [
          "File: python/pyspark/ml/feature.py -> python/pyspark/ml/feature.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "14: # See the License for the specific language governing permissions and",
          "15: # limitations under the License.",
          "16: #",
          "20: from pyspark.ml.param.shared import (",
          "21:     HasThreshold,",
          "22:     HasThresholds,",
          "",
          "[Removed Lines]",
          "18: from pyspark import since, keyword_only, SparkContext",
          "19: from pyspark.ml.linalg import _convert_to_vector",
          "",
          "[Added Lines]",
          "17: from typing import (",
          "18:     cast,",
          "19:     overload,",
          "20:     Any,",
          "21:     Dict,",
          "22:     Generic,",
          "23:     List,",
          "24:     Optional,",
          "25:     Tuple,",
          "26:     TypeVar,",
          "27:     Union,",
          "28:     TYPE_CHECKING,",
          "29: )",
          "31: from pyspark import keyword_only, since, SparkContext",
          "32: from pyspark.ml.linalg import _convert_to_vector, DenseMatrix, DenseVector, Vector",
          "33: from pyspark.sql.dataframe import DataFrame",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "40: from pyspark.ml.wrapper import JavaEstimator, JavaModel, JavaParams, JavaTransformer, _jvm",
          "41: from pyspark.ml.common import inherit_doc",
          "43: __all__ = [",
          "44:     \"Binarizer\",",
          "45:     \"BucketedRandomProjectionLSH\",",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "57: if TYPE_CHECKING:",
          "58:     from py4j.java_gateway import JavaObject",
          "60: JM = TypeVar(\"JM\", bound=JavaTransformer)",
          "61: P = TypeVar(\"P\", bound=Params)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "108:     HasOutputCol,",
          "109:     HasInputCols,",
          "110:     HasOutputCols,",
          "112:     JavaMLWritable,",
          "113: ):",
          "114:     \"\"\"",
          "",
          "[Removed Lines]",
          "111:     JavaMLReadable,",
          "",
          "[Added Lines]",
          "131:     JavaMLReadable[\"Binarizer\"],",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "157:     ...",
          "158:     \"\"\"",
          "161:         Params._dummy(),",
          "162:         \"threshold\",",
          "163:         \"Param for threshold used to binarize continuous features. \"",
          "",
          "[Removed Lines]",
          "160:     threshold = Param(",
          "",
          "[Added Lines]",
          "180:     threshold: Param[float] = Param(",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "165:         + \"The features equal to or less than the threshold will be binarized to 0.0\",",
          "166:         typeConverter=TypeConverters.toFloat,",
          "167:     )",
          "169:         Params._dummy(),",
          "170:         \"thresholds\",",
          "171:         \"Param for array of threshold used to binarize continuous features. \"",
          "",
          "[Removed Lines]",
          "168:     thresholds = Param(",
          "",
          "[Added Lines]",
          "188:     thresholds: Param[List[float]] = Param(",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "175:         typeConverter=TypeConverters.toListFloat,",
          "176:     )",
          "178:     @keyword_only",
          "179:     def __init__(",
          "180:         self,",
          "188:     ):",
          "189:         \"\"\"",
          "190:         __init__(self, \\\\*, threshold=0.0, inputCol=None, outputCol=None, thresholds=None, \\",
          "",
          "[Removed Lines]",
          "182:         threshold=0.0,",
          "183:         inputCol=None,",
          "184:         outputCol=None,",
          "185:         thresholds=None,",
          "186:         inputCols=None,",
          "187:         outputCols=None,",
          "",
          "[Added Lines]",
          "198:     _input_kwargs: Dict[str, Any]",
          "200:     @overload",
          "201:     def __init__(",
          "202:         self,",
          "204:         threshold: float = ...,",
          "205:         inputCol: Optional[str] = ...,",
          "206:         outputCol: Optional[str] = ...,",
          "207:     ):",
          "208:         ...",
          "210:     @overload",
          "211:     def __init__(",
          "212:         self,",
          "214:         thresholds: Optional[List[float]] = ...,",
          "215:         inputCols: Optional[List[str]] = ...,",
          "216:         outputCols: Optional[List[str]] = ...,",
          "217:     ):",
          "218:         ...",
          "224:         threshold: float = 0.0,",
          "225:         inputCol: Optional[str] = None,",
          "226:         outputCol: Optional[str] = None,",
          "227:         thresholds: Optional[List[float]] = None,",
          "228:         inputCols: Optional[List[str]] = None,",
          "229:         outputCols: Optional[List[str]] = None,",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "196:         kwargs = self._input_kwargs",
          "197:         self.setParams(**kwargs)",
          "199:     @keyword_only",
          "200:     @since(\"1.4.0\")",
          "201:     def setParams(",
          "202:         self,",
          "211:         \"\"\"",
          "212:         setParams(self, \\\\*, threshold=0.0, inputCol=None, outputCol=None, thresholds=None, \\",
          "213:                   inputCols=None, outputCols=None)",
          "",
          "[Removed Lines]",
          "204:         threshold=0.0,",
          "205:         inputCol=None,",
          "206:         outputCol=None,",
          "207:         thresholds=None,",
          "208:         inputCols=None,",
          "209:         outputCols=None,",
          "210:     ):",
          "",
          "[Added Lines]",
          "241:     @overload",
          "242:     def setParams(",
          "243:         self,",
          "245:         threshold: float = ...,",
          "246:         inputCol: Optional[str] = ...,",
          "247:         outputCol: Optional[str] = ...,",
          "248:     ) -> \"Binarizer\":",
          "249:         ...",
          "251:     @overload",
          "252:     def setParams(",
          "253:         self,",
          "255:         thresholds: Optional[List[float]] = ...,",
          "256:         inputCols: Optional[List[str]] = ...,",
          "257:         outputCols: Optional[List[str]] = ...,",
          "258:     ) -> \"Binarizer\":",
          "259:         ...",
          "266:         threshold: float = 0.0,",
          "267:         inputCol: Optional[str] = None,",
          "268:         outputCol: Optional[str] = None,",
          "269:         thresholds: Optional[List[float]] = None,",
          "270:         inputCols: Optional[List[str]] = None,",
          "271:         outputCols: Optional[List[str]] = None,",
          "272:     ) -> \"Binarizer\":",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "217:         return self._set(**kwargs)",
          "219:     @since(\"1.4.0\")",
          "221:         \"\"\"",
          "222:         Sets the value of :py:attr:`threshold`.",
          "223:         \"\"\"",
          "224:         return self._set(threshold=value)",
          "226:     @since(\"3.0.0\")",
          "228:         \"\"\"",
          "229:         Sets the value of :py:attr:`thresholds`.",
          "230:         \"\"\"",
          "231:         return self._set(thresholds=value)",
          "234:         \"\"\"",
          "235:         Sets the value of :py:attr:`inputCol`.",
          "236:         \"\"\"",
          "237:         return self._set(inputCol=value)",
          "239:     @since(\"3.0.0\")",
          "241:         \"\"\"",
          "242:         Sets the value of :py:attr:`inputCols`.",
          "243:         \"\"\"",
          "244:         return self._set(inputCols=value)",
          "247:         \"\"\"",
          "248:         Sets the value of :py:attr:`outputCol`.",
          "249:         \"\"\"",
          "250:         return self._set(outputCol=value)",
          "252:     @since(\"3.0.0\")",
          "254:         \"\"\"",
          "255:         Sets the value of :py:attr:`outputCols`.",
          "256:         \"\"\"",
          "",
          "[Removed Lines]",
          "220:     def setThreshold(self, value):",
          "227:     def setThresholds(self, value):",
          "233:     def setInputCol(self, value):",
          "240:     def setInputCols(self, value):",
          "246:     def setOutputCol(self, value):",
          "253:     def setOutputCols(self, value):",
          "",
          "[Added Lines]",
          "282:     def setThreshold(self, value: float) -> \"Binarizer\":",
          "289:     def setThresholds(self, value: List[float]) -> \"Binarizer\":",
          "295:     def setInputCol(self, value: str) -> \"Binarizer\":",
          "302:     def setInputCols(self, value: List[str]) -> \"Binarizer\":",
          "308:     def setOutputCol(self, value: str) -> \"Binarizer\":",
          "315:     def setOutputCols(self, value: List[str]) -> \"Binarizer\":",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "262:     Mixin for Locality Sensitive Hashing (LSH) algorithm parameters.",
          "263:     \"\"\"",
          "266:         Params._dummy(),",
          "267:         \"numHashTables\",",
          "268:         \"number of hash tables, where \"",
          "",
          "[Removed Lines]",
          "265:     numHashTables = Param(",
          "",
          "[Added Lines]",
          "327:     numHashTables: Param[int] = Param(",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "271:         typeConverter=TypeConverters.toInt,",
          "272:     )",
          "275:         super(_LSHParams, self).__init__(*args)",
          "276:         self._setDefault(numHashTables=1)",
          "279:         \"\"\"",
          "280:         Gets the value of numHashTables or its default value.",
          "281:         \"\"\"",
          "282:         return self.getOrDefault(self.numHashTables)",
          "286:     \"\"\"",
          "287:     Mixin for Locality Sensitive Hashing (LSH).",
          "288:     \"\"\"",
          "291:         \"\"\"",
          "292:         Sets the value of :py:attr:`numHashTables`.",
          "293:         \"\"\"",
          "294:         return self._set(numHashTables=value)",
          "297:         \"\"\"",
          "298:         Sets the value of :py:attr:`inputCol`.",
          "299:         \"\"\"",
          "300:         return self._set(inputCol=value)",
          "303:         \"\"\"",
          "304:         Sets the value of :py:attr:`outputCol`.",
          "305:         \"\"\"",
          "",
          "[Removed Lines]",
          "274:     def __init__(self, *args):",
          "278:     def getNumHashTables(self):",
          "285: class _LSH(JavaEstimator, _LSHParams, JavaMLReadable, JavaMLWritable):",
          "290:     def setNumHashTables(self, value):",
          "296:     def setInputCol(self, value):",
          "302:     def setOutputCol(self, value):",
          "",
          "[Added Lines]",
          "336:     def __init__(self, *args: Any):",
          "340:     def getNumHashTables(self) -> int:",
          "347: class _LSH(JavaEstimator[JM], _LSHParams, JavaMLReadable, JavaMLWritable, Generic[JM]):",
          "352:     def setNumHashTables(self: P, value: int) -> P:",
          "358:     def setInputCol(self: P, value: str) -> P:",
          "364:     def setOutputCol(self: P, value: str) -> P:",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "311:     Mixin for Locality Sensitive Hashing (LSH) models.",
          "312:     \"\"\"",
          "315:         \"\"\"",
          "316:         Sets the value of :py:attr:`inputCol`.",
          "317:         \"\"\"",
          "318:         return self._set(inputCol=value)",
          "321:         \"\"\"",
          "322:         Sets the value of :py:attr:`outputCol`.",
          "323:         \"\"\"",
          "324:         return self._set(outputCol=value)",
          "327:         \"\"\"",
          "328:         Given a large dataset and an item, approximately find at most k items which have the",
          "329:         closest distance to the item. If the :py:attr:`outputCol` is missing, the method will",
          "",
          "[Removed Lines]",
          "314:     def setInputCol(self, value):",
          "320:     def setOutputCol(self, value):",
          "326:     def approxNearestNeighbors(self, dataset, key, numNearestNeighbors, distCol=\"distCol\"):",
          "",
          "[Added Lines]",
          "376:     def setInputCol(self: P, value: str) -> P:",
          "382:     def setOutputCol(self: P, value: str) -> P:",
          "388:     def approxNearestNeighbors(",
          "389:         self,",
          "390:         dataset: DataFrame,",
          "391:         key: Vector,",
          "392:         numNearestNeighbors: int,",
          "393:         distCol: str = \"distCol\",",
          "394:     ) -> DataFrame:",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "354:         \"\"\"",
          "355:         return self._call_java(\"approxNearestNeighbors\", dataset, key, numNearestNeighbors, distCol)",
          "358:         \"\"\"",
          "359:         Join two datasets to approximately find all pairs of rows whose distance are smaller than",
          "360:         the threshold. If the :py:attr:`outputCol` is missing, the method will transform the data;",
          "",
          "[Removed Lines]",
          "357:     def approxSimilarityJoin(self, datasetA, datasetB, threshold, distCol=\"distCol\"):",
          "",
          "[Added Lines]",
          "425:     def approxSimilarityJoin(",
          "426:         self,",
          "427:         datasetA: DataFrame,",
          "428:         datasetB: DataFrame,",
          "429:         threshold: float,",
          "430:         distCol: str = \"distCol\",",
          "431:     ) -> DataFrame:",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "392:     .. versionadded:: 3.0.0",
          "393:     \"\"\"",
          "396:         Params._dummy(),",
          "397:         \"bucketLength\",",
          "398:         \"the length of each hash bucket, \" + \"a larger bucket lowers the false negative rate.\",",
          "",
          "[Removed Lines]",
          "395:     bucketLength = Param(",
          "",
          "[Added Lines]",
          "469:     bucketLength: Param[float] = Param(",
          "",
          "---------------",
          "--- Hunk 14 ---",
          "[Context before]",
          "400:     )",
          "402:     @since(\"2.2.0\")",
          "404:         \"\"\"",
          "405:         Gets the value of bucketLength or its default value.",
          "406:         \"\"\"",
          "410: @inherit_doc",
          "411: class BucketedRandomProjectionLSH(",
          "413: ):",
          "414:     \"\"\"",
          "415:     LSH class for Euclidean distance metrics.",
          "",
          "[Removed Lines]",
          "403:     def getBucketLength(self):",
          "407:         return self.getOrDefault(self.bucketLength)",
          "412:     _LSH, _BucketedRandomProjectionLSHParams, HasSeed, JavaMLReadable, JavaMLWritable",
          "",
          "[Added Lines]",
          "477:     def getBucketLength(self) -> float:",
          "481:         return (cast(Params, self)).getOrDefault(self.bucketLength)",
          "486:     _LSH[\"BucketedRandomProjectionLSHModel\"],",
          "487:     _LSHParams,",
          "488:     _BucketedRandomProjectionLSHParams,",
          "489:     HasSeed,",
          "490:     JavaMLReadable[\"BucketedRandomProjectionLSH\"],",
          "491:     JavaMLWritable,",
          "",
          "---------------",
          "--- Hunk 15 ---",
          "[Context before]",
          "490:     True",
          "491:     \"\"\"",
          "493:     @keyword_only",
          "494:     def __init__(",
          "496:     ):",
          "497:         \"\"\"",
          "498:         __init__(self, \\\\*, inputCol=None, outputCol=None, seed=None, numHashTables=1, \\",
          "",
          "[Removed Lines]",
          "495:         self, *, inputCol=None, outputCol=None, seed=None, numHashTables=1, bucketLength=None",
          "",
          "[Added Lines]",
          "572:     _input_kwargs: Dict[str, Any]",
          "576:         self,",
          "578:         inputCol: Optional[str] = None,",
          "579:         outputCol: Optional[str] = None,",
          "580:         seed: Optional[int] = None,",
          "581:         numHashTables: int = 1,",
          "582:         bucketLength: Optional[float] = None,",
          "",
          "---------------",
          "--- Hunk 16 ---",
          "[Context before]",
          "508:     @keyword_only",
          "509:     @since(\"2.2.0\")",
          "510:     def setParams(",
          "513:         \"\"\"",
          "514:         setParams(self, \\\\*, inputCol=None, outputCol=None, seed=None, numHashTables=1, \\",
          "515:                   bucketLength=None)",
          "",
          "[Removed Lines]",
          "511:         self, *, inputCol=None, outputCol=None, seed=None, numHashTables=1, bucketLength=None",
          "512:     ):",
          "",
          "[Added Lines]",
          "598:         self,",
          "600:         inputCol: Optional[str] = None,",
          "601:         outputCol: Optional[str] = None,",
          "602:         seed: Optional[int] = None,",
          "603:         numHashTables: int = 1,",
          "604:         bucketLength: Optional[float] = None,",
          "605:     ) -> \"BucketedRandomProjectionLSH\":",
          "",
          "---------------",
          "--- Hunk 17 ---",
          "[Context before]",
          "519:         return self._set(**kwargs)",
          "521:     @since(\"2.2.0\")",
          "523:         \"\"\"",
          "524:         Sets the value of :py:attr:`bucketLength`.",
          "525:         \"\"\"",
          "526:         return self._set(bucketLength=value)",
          "529:         \"\"\"",
          "530:         Sets the value of :py:attr:`seed`.",
          "531:         \"\"\"",
          "532:         return self._set(seed=value)",
          "535:         return BucketedRandomProjectionLSHModel(java_model)",
          "538: class BucketedRandomProjectionLSHModel(",
          "540: ):",
          "541:     r\"\"\"",
          "542:     Model fitted by :py:class:`BucketedRandomProjectionLSH`, where multiple random vectors are",
          "",
          "[Removed Lines]",
          "522:     def setBucketLength(self, value):",
          "528:     def setSeed(self, value):",
          "534:     def _create_model(self, java_model):",
          "539:     _LSHModel, _BucketedRandomProjectionLSHParams, JavaMLReadable, JavaMLWritable",
          "",
          "[Added Lines]",
          "615:     def setBucketLength(self, value: float) -> \"BucketedRandomProjectionLSH\":",
          "621:     def setSeed(self, value: int) -> \"BucketedRandomProjectionLSH\":",
          "627:     def _create_model(self, java_model: \"JavaObject\") -> \"BucketedRandomProjectionLSHModel\":",
          "632:     _LSHModel,",
          "633:     _BucketedRandomProjectionLSHParams,",
          "634:     JavaMLReadable[\"BucketedRandomProjectionLSHModel\"],",
          "635:     JavaMLWritable,",
          "",
          "---------------",
          "--- Hunk 18 ---",
          "[Context before]",
          "557:     HasInputCols,",
          "558:     HasOutputCols,",
          "559:     HasHandleInvalid,",
          "561:     JavaMLWritable,",
          "562: ):",
          "563:     \"\"\"",
          "",
          "[Removed Lines]",
          "560:     JavaMLReadable,",
          "",
          "[Added Lines]",
          "656:     JavaMLReadable[\"Bucketizer\"],",
          "",
          "---------------",
          "--- Hunk 19 ---",
          "[Context before]",
          "625:     ...",
          "626:     \"\"\"",
          "629:         Params._dummy(),",
          "630:         \"splits\",",
          "631:         \"Split points for mapping continuous features into buckets. With n+1 splits, \"",
          "",
          "[Removed Lines]",
          "628:     splits = Param(",
          "",
          "[Added Lines]",
          "724:     splits: Param[List[float]] = Param(",
          "",
          "---------------",
          "--- Hunk 20 ---",
          "[Context before]",
          "637:         typeConverter=TypeConverters.toListFloat,",
          "638:     )",
          "641:         Params._dummy(),",
          "642:         \"handleInvalid\",",
          "643:         \"how to handle invalid entries \"",
          "",
          "[Removed Lines]",
          "640:     handleInvalid = Param(",
          "",
          "[Added Lines]",
          "736:     handleInvalid: Param[str] = Param(",
          "",
          "---------------",
          "--- Hunk 21 ---",
          "[Context before]",
          "652:         typeConverter=TypeConverters.toString,",
          "653:     )",
          "656:         Params._dummy(),",
          "657:         \"splitsArray\",",
          "658:         \"The array of split points for mapping \"",
          "",
          "[Removed Lines]",
          "655:     splitsArray = Param(",
          "",
          "[Added Lines]",
          "751:     splitsArray: Param[List[List[float]]] = Param(",
          "",
          "---------------",
          "--- Hunk 22 ---",
          "[Context before]",
          "666:         typeConverter=TypeConverters.toListListFloat,",
          "667:     )",
          "669:     @keyword_only",
          "670:     def __init__(",
          "671:         self,",
          "680:     ):",
          "681:         \"\"\"",
          "682:         __init__(self, \\\\*, splits=None, inputCol=None, outputCol=None, handleInvalid=\"error\", \\",
          "",
          "[Removed Lines]",
          "673:         splits=None,",
          "674:         inputCol=None,",
          "675:         outputCol=None,",
          "676:         handleInvalid=\"error\",",
          "677:         splitsArray=None,",
          "678:         inputCols=None,",
          "679:         outputCols=None,",
          "",
          "[Added Lines]",
          "765:     _input_kwargs: Dict[str, Any]",
          "767:     @overload",
          "768:     def __init__(",
          "769:         self,",
          "771:         splits: Optional[List[float]] = ...,",
          "772:         inputCol: Optional[str] = ...,",
          "773:         outputCol: Optional[str] = ...,",
          "774:         handleInvalid: str = ...,",
          "775:     ):",
          "776:         ...",
          "778:     @overload",
          "779:     def __init__(",
          "780:         self,",
          "782:         handleInvalid: str = ...,",
          "783:         splitsArray: Optional[List[List[float]]] = ...,",
          "784:         inputCols: Optional[List[str]] = ...,",
          "785:         outputCols: Optional[List[str]] = ...,",
          "786:     ):",
          "787:         ...",
          "793:         splits: Optional[List[float]] = None,",
          "794:         inputCol: Optional[str] = None,",
          "795:         outputCol: Optional[str] = None,",
          "796:         handleInvalid: str = \"error\",",
          "797:         splitsArray: Optional[List[List[float]]] = None,",
          "798:         inputCols: Optional[List[str]] = None,",
          "799:         outputCols: Optional[List[str]] = None,",
          "",
          "---------------",
          "--- Hunk 23 ---",
          "[Context before]",
          "688:         kwargs = self._input_kwargs",
          "689:         self.setParams(**kwargs)",
          "691:     @keyword_only",
          "692:     @since(\"1.4.0\")",
          "693:     def setParams(",
          "694:         self,",
          "704:         \"\"\"",
          "705:         setParams(self, \\\\*, splits=None, inputCol=None, outputCol=None, handleInvalid=\"error\", \\",
          "706:                   splitsArray=None, inputCols=None, outputCols=None)",
          "",
          "[Removed Lines]",
          "696:         splits=None,",
          "697:         inputCol=None,",
          "698:         outputCol=None,",
          "699:         handleInvalid=\"error\",",
          "700:         splitsArray=None,",
          "701:         inputCols=None,",
          "702:         outputCols=None,",
          "703:     ):",
          "",
          "[Added Lines]",
          "811:     @overload",
          "812:     def setParams(",
          "813:         self,",
          "815:         splits: Optional[List[float]] = ...,",
          "816:         inputCol: Optional[str] = ...,",
          "817:         outputCol: Optional[str] = ...,",
          "818:         handleInvalid: str = ...,",
          "819:     ) -> \"Bucketizer\":",
          "820:         ...",
          "822:     @overload",
          "823:     def setParams(",
          "824:         self,",
          "826:         handleInvalid: str = ...,",
          "827:         splitsArray: Optional[List[List[float]]] = ...,",
          "828:         inputCols: Optional[List[str]] = ...,",
          "829:         outputCols: Optional[List[str]] = ...,",
          "830:     ) -> \"Bucketizer\":",
          "831:         ...",
          "838:         splits: Optional[List[float]] = None,",
          "839:         inputCol: Optional[str] = None,",
          "840:         outputCol: Optional[str] = None,",
          "841:         handleInvalid: str = \"error\",",
          "842:         splitsArray: Optional[List[List[float]]] = None,",
          "843:         inputCols: Optional[List[str]] = None,",
          "844:         outputCols: Optional[List[str]] = None,",
          "845:     ) -> \"Bucketizer\":",
          "",
          "---------------",
          "--- Hunk 24 ---",
          "[Context before]",
          "710:         return self._set(**kwargs)",
          "712:     @since(\"1.4.0\")",
          "714:         \"\"\"",
          "715:         Sets the value of :py:attr:`splits`.",
          "716:         \"\"\"",
          "717:         return self._set(splits=value)",
          "719:     @since(\"1.4.0\")",
          "721:         \"\"\"",
          "722:         Gets the value of threshold or its default value.",
          "723:         \"\"\"",
          "724:         return self.getOrDefault(self.splits)",
          "726:     @since(\"3.0.0\")",
          "728:         \"\"\"",
          "729:         Sets the value of :py:attr:`splitsArray`.",
          "730:         \"\"\"",
          "731:         return self._set(splitsArray=value)",
          "733:     @since(\"3.0.0\")",
          "735:         \"\"\"",
          "736:         Gets the array of split points or its default value.",
          "737:         \"\"\"",
          "738:         return self.getOrDefault(self.splitsArray)",
          "741:         \"\"\"",
          "742:         Sets the value of :py:attr:`inputCol`.",
          "743:         \"\"\"",
          "744:         return self._set(inputCol=value)",
          "746:     @since(\"3.0.0\")",
          "748:         \"\"\"",
          "749:         Sets the value of :py:attr:`inputCols`.",
          "750:         \"\"\"",
          "751:         return self._set(inputCols=value)",
          "754:         \"\"\"",
          "755:         Sets the value of :py:attr:`outputCol`.",
          "756:         \"\"\"",
          "757:         return self._set(outputCol=value)",
          "759:     @since(\"3.0.0\")",
          "761:         \"\"\"",
          "762:         Sets the value of :py:attr:`outputCols`.",
          "763:         \"\"\"",
          "764:         return self._set(outputCols=value)",
          "767:         \"\"\"",
          "768:         Sets the value of :py:attr:`handleInvalid`.",
          "769:         \"\"\"",
          "",
          "[Removed Lines]",
          "713:     def setSplits(self, value):",
          "720:     def getSplits(self):",
          "727:     def setSplitsArray(self, value):",
          "734:     def getSplitsArray(self):",
          "740:     def setInputCol(self, value):",
          "747:     def setInputCols(self, value):",
          "753:     def setOutputCol(self, value):",
          "760:     def setOutputCols(self, value):",
          "766:     def setHandleInvalid(self, value):",
          "",
          "[Added Lines]",
          "855:     def setSplits(self, value: List[float]) -> \"Bucketizer\":",
          "862:     def getSplits(self) -> List[float]:",
          "869:     def setSplitsArray(self, value: List[List[float]]) -> \"Bucketizer\":",
          "876:     def getSplitsArray(self) -> List[List[float]]:",
          "882:     def setInputCol(self, value: str) -> \"Bucketizer\":",
          "889:     def setInputCols(self, value: List[str]) -> \"Bucketizer\":",
          "895:     def setOutputCol(self, value: str) -> \"Bucketizer\":",
          "902:     def setOutputCols(self, value: List[str]) -> \"Bucketizer\":",
          "908:     def setHandleInvalid(self, value: str) -> \"Bucketizer\":",
          "",
          "---------------",
          "--- Hunk 25 ---",
          "[Context before]",
          "775:     Params for :py:class:`CountVectorizer` and :py:class:`CountVectorizerModel`.",
          "776:     \"\"\"",
          "779:         Params._dummy(),",
          "780:         \"minTF\",",
          "781:         \"Filter to ignore rare words in\"",
          "",
          "[Removed Lines]",
          "778:     minTF = Param(",
          "",
          "[Added Lines]",
          "920:     minTF: Param[float] = Param(",
          "",
          "---------------",
          "--- Hunk 26 ---",
          "[Context before]",
          "786:         + \"only used in transform of CountVectorizerModel and does not affect fitting. Default 1.0\",",
          "787:         typeConverter=TypeConverters.toFloat,",
          "788:     )",
          "790:         Params._dummy(),",
          "791:         \"minDF\",",
          "792:         \"Specifies the minimum number of\"",
          "",
          "[Removed Lines]",
          "789:     minDF = Param(",
          "",
          "[Added Lines]",
          "931:     minDF: Param[float] = Param(",
          "",
          "---------------",
          "--- Hunk 27 ---",
          "[Context before]",
          "796:         + \" Default 1.0\",",
          "797:         typeConverter=TypeConverters.toFloat,",
          "798:     )",
          "800:         Params._dummy(),",
          "801:         \"maxDF\",",
          "802:         \"Specifies the maximum number of\"",
          "",
          "[Removed Lines]",
          "799:     maxDF = Param(",
          "",
          "[Added Lines]",
          "941:     maxDF: Param[float] = Param(",
          "",
          "---------------",
          "--- Hunk 28 ---",
          "[Context before]",
          "808:         + \" Default (2^63) - 1\",",
          "809:         typeConverter=TypeConverters.toFloat,",
          "810:     )",
          "812:         Params._dummy(),",
          "813:         \"vocabSize\",",
          "814:         \"max size of the vocabulary. Default 1 << 18.\",",
          "815:         typeConverter=TypeConverters.toInt,",
          "816:     )",
          "818:         Params._dummy(),",
          "819:         \"binary\",",
          "820:         \"Binary toggle to control the output vector values.\"",
          "",
          "[Removed Lines]",
          "811:     vocabSize = Param(",
          "817:     binary = Param(",
          "",
          "[Added Lines]",
          "953:     vocabSize: Param[int] = Param(",
          "959:     binary: Param[bool] = Param(",
          "",
          "---------------",
          "--- Hunk 29 ---",
          "[Context before]",
          "824:         typeConverter=TypeConverters.toBoolean,",
          "825:     )",
          "828:         super(_CountVectorizerParams, self).__init__(*args)",
          "829:         self._setDefault(minTF=1.0, minDF=1.0, maxDF=2 ** 63 - 1, vocabSize=1 << 18, binary=False)",
          "831:     @since(\"1.6.0\")",
          "833:         \"\"\"",
          "834:         Gets the value of minTF or its default value.",
          "835:         \"\"\"",
          "836:         return self.getOrDefault(self.minTF)",
          "838:     @since(\"1.6.0\")",
          "840:         \"\"\"",
          "841:         Gets the value of minDF or its default value.",
          "842:         \"\"\"",
          "843:         return self.getOrDefault(self.minDF)",
          "845:     @since(\"2.4.0\")",
          "847:         \"\"\"",
          "848:         Gets the value of maxDF or its default value.",
          "849:         \"\"\"",
          "850:         return self.getOrDefault(self.maxDF)",
          "852:     @since(\"1.6.0\")",
          "854:         \"\"\"",
          "855:         Gets the value of vocabSize or its default value.",
          "856:         \"\"\"",
          "857:         return self.getOrDefault(self.vocabSize)",
          "859:     @since(\"2.0.0\")",
          "861:         \"\"\"",
          "862:         Gets the value of binary or its default value.",
          "863:         \"\"\"",
          "",
          "[Removed Lines]",
          "827:     def __init__(self, *args):",
          "832:     def getMinTF(self):",
          "839:     def getMinDF(self):",
          "846:     def getMaxDF(self):",
          "853:     def getVocabSize(self):",
          "860:     def getBinary(self):",
          "",
          "[Added Lines]",
          "969:     def __init__(self, *args: Any):",
          "974:     def getMinTF(self) -> float:",
          "981:     def getMinDF(self) -> float:",
          "988:     def getMaxDF(self) -> float:",
          "995:     def getVocabSize(self) -> int:",
          "1002:     def getBinary(self) -> bool:",
          "",
          "---------------",
          "--- Hunk 30 ---",
          "[Context before]",
          "867: @inherit_doc",
          "869:     \"\"\"",
          "870:     Extracts a vocabulary from document collections and generates a :py:attr:`CountVectorizerModel`.",
          "",
          "[Removed Lines]",
          "868: class CountVectorizer(JavaEstimator, _CountVectorizerParams, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "1010: class CountVectorizer(",
          "1011:     JavaEstimator[\"CountVectorizerModel\"],",
          "1012:     _CountVectorizerParams,",
          "1013:     JavaMLReadable[\"CountVectorizer\"],",
          "1014:     JavaMLWritable,",
          "1015: ):",
          "",
          "---------------",
          "--- Hunk 31 ---",
          "[Context before]",
          "922:     ...",
          "923:     \"\"\"",
          "925:     @keyword_only",
          "926:     def __init__(",
          "927:         self,",
          "936:     ):",
          "937:         \"\"\"",
          "938:         __init__(self, \\\\*, minTF=1.0, minDF=1.0, maxDF=2 ** 63 - 1, vocabSize=1 << 18,\\",
          "",
          "[Removed Lines]",
          "929:         minTF=1.0,",
          "930:         minDF=1.0,",
          "931:         maxDF=2 ** 63 - 1,",
          "932:         vocabSize=1 << 18,",
          "933:         binary=False,",
          "934:         inputCol=None,",
          "935:         outputCol=None,",
          "",
          "[Added Lines]",
          "1072:     _input_kwargs: Dict[str, Any]",
          "1078:         minTF: float = 1.0,",
          "1079:         minDF: float = 1.0,",
          "1080:         maxDF: float = 2 ** 63 - 1,",
          "1081:         vocabSize: int = 1 << 18,",
          "1082:         binary: bool = False,",
          "1083:         inputCol: Optional[str] = None,",
          "1084:         outputCol: Optional[str] = None,",
          "",
          "---------------",
          "--- Hunk 32 ---",
          "[Context before]",
          "948:     def setParams(",
          "949:         self,",
          "959:         \"\"\"",
          "960:         setParams(self, \\\\*, minTF=1.0, minDF=1.0, maxDF=2 ** 63 - 1, vocabSize=1 << 18,\\",
          "961:                   binary=False, inputCol=None, outputCol=None)",
          "",
          "[Removed Lines]",
          "951:         minTF=1.0,",
          "952:         minDF=1.0,",
          "953:         maxDF=2 ** 63 - 1,",
          "954:         vocabSize=1 << 18,",
          "955:         binary=False,",
          "956:         inputCol=None,",
          "957:         outputCol=None,",
          "958:     ):",
          "",
          "[Added Lines]",
          "1100:         minTF: float = 1.0,",
          "1101:         minDF: float = 1.0,",
          "1102:         maxDF: float = 2 ** 63 - 1,",
          "1103:         vocabSize: int = 1 << 18,",
          "1104:         binary: bool = False,",
          "1105:         inputCol: Optional[str] = None,",
          "1106:         outputCol: Optional[str] = None,",
          "1107:     ) -> \"CountVectorizer\":",
          "",
          "---------------",
          "--- Hunk 33 ---",
          "[Context before]",
          "965:         return self._set(**kwargs)",
          "967:     @since(\"1.6.0\")",
          "969:         \"\"\"",
          "970:         Sets the value of :py:attr:`minTF`.",
          "971:         \"\"\"",
          "972:         return self._set(minTF=value)",
          "974:     @since(\"1.6.0\")",
          "976:         \"\"\"",
          "977:         Sets the value of :py:attr:`minDF`.",
          "978:         \"\"\"",
          "979:         return self._set(minDF=value)",
          "981:     @since(\"2.4.0\")",
          "983:         \"\"\"",
          "984:         Sets the value of :py:attr:`maxDF`.",
          "985:         \"\"\"",
          "986:         return self._set(maxDF=value)",
          "988:     @since(\"1.6.0\")",
          "990:         \"\"\"",
          "991:         Sets the value of :py:attr:`vocabSize`.",
          "992:         \"\"\"",
          "993:         return self._set(vocabSize=value)",
          "995:     @since(\"2.0.0\")",
          "997:         \"\"\"",
          "998:         Sets the value of :py:attr:`binary`.",
          "999:         \"\"\"",
          "1000:         return self._set(binary=value)",
          "1003:         \"\"\"",
          "1004:         Sets the value of :py:attr:`inputCol`.",
          "1005:         \"\"\"",
          "1006:         return self._set(inputCol=value)",
          "1009:         \"\"\"",
          "1010:         Sets the value of :py:attr:`outputCol`.",
          "1011:         \"\"\"",
          "1012:         return self._set(outputCol=value)",
          "1015:         return CountVectorizerModel(java_model)",
          "1018: @inherit_doc",
          "1020:     \"\"\"",
          "1021:     Model fitted by :py:class:`CountVectorizer`.",
          "",
          "[Removed Lines]",
          "968:     def setMinTF(self, value):",
          "975:     def setMinDF(self, value):",
          "982:     def setMaxDF(self, value):",
          "989:     def setVocabSize(self, value):",
          "996:     def setBinary(self, value):",
          "1002:     def setInputCol(self, value):",
          "1008:     def setOutputCol(self, value):",
          "1014:     def _create_model(self, java_model):",
          "1019: class CountVectorizerModel(JavaModel, _CountVectorizerParams, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "1117:     def setMinTF(self, value: float) -> \"CountVectorizer\":",
          "1124:     def setMinDF(self, value: float) -> \"CountVectorizer\":",
          "1131:     def setMaxDF(self, value: float) -> \"CountVectorizer\":",
          "1138:     def setVocabSize(self, value: int) -> \"CountVectorizer\":",
          "1145:     def setBinary(self, value: bool) -> \"CountVectorizer\":",
          "1151:     def setInputCol(self, value: str) -> \"CountVectorizer\":",
          "1157:     def setOutputCol(self, value: str) -> \"CountVectorizer\":",
          "1163:     def _create_model(self, java_model: \"JavaObject\") -> \"CountVectorizerModel\":",
          "1168: class CountVectorizerModel(",
          "1169:     JavaModel, _CountVectorizerParams, JavaMLReadable[\"CountVectorizerModel\"], JavaMLWritable",
          "1170: ):",
          "",
          "---------------",
          "--- Hunk 34 ---",
          "[Context before]",
          "1024:     \"\"\"",
          "1026:     @since(\"3.0.0\")",
          "1028:         \"\"\"",
          "1029:         Sets the value of :py:attr:`inputCol`.",
          "1030:         \"\"\"",
          "1031:         return self._set(inputCol=value)",
          "1033:     @since(\"3.0.0\")",
          "1035:         \"\"\"",
          "1036:         Sets the value of :py:attr:`outputCol`.",
          "1037:         \"\"\"",
          "",
          "[Removed Lines]",
          "1027:     def setInputCol(self, value):",
          "1034:     def setOutputCol(self, value):",
          "",
          "[Added Lines]",
          "1178:     def setInputCol(self, value: str) -> \"CountVectorizerModel\":",
          "1185:     def setOutputCol(self, value: str) -> \"CountVectorizerModel\":",
          "",
          "---------------",
          "--- Hunk 35 ---",
          "[Context before]",
          "1040:     @classmethod",
          "1041:     @since(\"2.4.0\")",
          "1043:         \"\"\"",
          "1044:         Construct the model directly from a vocabulary list of strings,",
          "1045:         requires an active SparkContext.",
          "1046:         \"\"\"",
          "1047:         sc = SparkContext._active_spark_context",
          "1048:         java_class = sc._gateway.jvm.java.lang.String",
          "1049:         jvocab = CountVectorizerModel._new_java_array(vocabulary, java_class)",
          "1050:         model = CountVectorizerModel._create_from_java_class(",
          "",
          "[Removed Lines]",
          "1042:     def from_vocabulary(cls, vocabulary, inputCol, outputCol=None, minTF=None, binary=None):",
          "",
          "[Added Lines]",
          "1193:     def from_vocabulary(",
          "1194:         cls,",
          "1195:         vocabulary: List[str],",
          "1196:         inputCol: str,",
          "1197:         outputCol: Optional[str] = None,",
          "1198:         minTF: Optional[float] = None,",
          "1199:         binary: Optional[bool] = None,",
          "1200:     ) -> \"CountVectorizerModel\":",
          "1206:         assert sc is not None and sc._gateway is not None",
          "",
          "---------------",
          "--- Hunk 36 ---",
          "[Context before]",
          "1060:         model._set(vocabSize=len(vocabulary))",
          "1061:         return model",
          "1064:     @since(\"1.6.0\")",
          "1066:         \"\"\"",
          "1067:         An array of terms in the vocabulary.",
          "1068:         \"\"\"",
          "1069:         return self._call_java(\"vocabulary\")",
          "1071:     @since(\"2.4.0\")",
          "1073:         \"\"\"",
          "1074:         Sets the value of :py:attr:`minTF`.",
          "1075:         \"\"\"",
          "1076:         return self._set(minTF=value)",
          "1078:     @since(\"2.4.0\")",
          "1080:         \"\"\"",
          "1081:         Sets the value of :py:attr:`binary`.",
          "1082:         \"\"\"",
          "",
          "[Removed Lines]",
          "1063:     @property",
          "1065:     def vocabulary(self):",
          "1072:     def setMinTF(self, value):",
          "1079:     def setBinary(self, value):",
          "",
          "[Added Lines]",
          "1222:     @property  # type: ignore[misc]",
          "1224:     def vocabulary(self) -> List[str]:",
          "1231:     def setMinTF(self, value: float) -> \"CountVectorizerModel\":",
          "1238:     def setBinary(self, value: bool) -> \"CountVectorizerModel\":",
          "",
          "---------------",
          "--- Hunk 37 ---",
          "[Context before]",
          "1086: @inherit_doc",
          "1088:     \"\"\"",
          "1089:     A feature transformer that takes the 1D discrete cosine transform",
          "1090:     of a real vector. No zero padding is performed on the input vector.",
          "",
          "[Removed Lines]",
          "1087: class DCT(JavaTransformer, HasInputCol, HasOutputCol, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "1246: class DCT(JavaTransformer, HasInputCol, HasOutputCol, JavaMLReadable[\"DCT\"], JavaMLWritable):",
          "",
          "---------------",
          "--- Hunk 38 ---",
          "[Context before]",
          "1125:     False",
          "1126:     \"\"\"",
          "1129:         Params._dummy(),",
          "1130:         \"inverse\",",
          "1131:         \"Set transformer to perform inverse DCT, \" + \"default False.\",",
          "1132:         typeConverter=TypeConverters.toBoolean,",
          "1133:     )",
          "1135:     @keyword_only",
          "1137:         \"\"\"",
          "1138:         __init__(self, \\\\*, inverse=False, inputCol=None, outputCol=None)",
          "1139:         \"\"\"",
          "",
          "[Removed Lines]",
          "1128:     inverse = Param(",
          "1136:     def __init__(self, *, inverse=False, inputCol=None, outputCol=None):",
          "",
          "[Added Lines]",
          "1287:     inverse: Param[bool] = Param(",
          "1294:     _input_kwargs: Dict[str, Any]",
          "1297:     def __init__(",
          "1298:         self,",
          "1300:         inverse: bool = False,",
          "1301:         inputCol: Optional[str] = None,",
          "1302:         outputCol: Optional[str] = None,",
          "1303:     ):",
          "",
          "---------------",
          "--- Hunk 39 ---",
          "[Context before]",
          "1146:     @keyword_only",
          "1147:     @since(\"1.6.0\")",
          "1149:         \"\"\"",
          "1150:         setParams(self, \\\\*, inverse=False, inputCol=None, outputCol=None)",
          "1151:         Sets params for this DCT.",
          "",
          "[Removed Lines]",
          "1148:     def setParams(self, *, inverse=False, inputCol=None, outputCol=None):",
          "",
          "[Added Lines]",
          "1315:     def setParams(",
          "1316:         self,",
          "1318:         inverse: bool = False,",
          "1319:         inputCol: Optional[str] = None,",
          "1320:         outputCol: Optional[str] = None,",
          "1321:     ) -> \"DCT\":",
          "",
          "---------------",
          "--- Hunk 40 ---",
          "[Context before]",
          "1154:         return self._set(**kwargs)",
          "1156:     @since(\"1.6.0\")",
          "1158:         \"\"\"",
          "1159:         Sets the value of :py:attr:`inverse`.",
          "1160:         \"\"\"",
          "1161:         return self._set(inverse=value)",
          "1163:     @since(\"1.6.0\")",
          "1165:         \"\"\"",
          "1166:         Gets the value of inverse or its default value.",
          "1167:         \"\"\"",
          "1168:         return self.getOrDefault(self.inverse)",
          "1171:         \"\"\"",
          "1172:         Sets the value of :py:attr:`inputCol`.",
          "1173:         \"\"\"",
          "1174:         return self._set(inputCol=value)",
          "1177:         \"\"\"",
          "1178:         Sets the value of :py:attr:`outputCol`.",
          "1179:         \"\"\"",
          "",
          "[Removed Lines]",
          "1157:     def setInverse(self, value):",
          "1164:     def getInverse(self):",
          "1170:     def setInputCol(self, value):",
          "1176:     def setOutputCol(self, value):",
          "",
          "[Added Lines]",
          "1330:     def setInverse(self, value: bool) -> \"DCT\":",
          "1337:     def getInverse(self) -> bool:",
          "1343:     def setInputCol(self, value: str) -> \"DCT\":",
          "1349:     def setOutputCol(self, value: str) -> \"DCT\":",
          "",
          "---------------",
          "--- Hunk 41 ---",
          "[Context before]",
          "1183: @inherit_doc",
          "1184: class ElementwiseProduct(",
          "1186: ):",
          "1187:     \"\"\"",
          "1188:     Outputs the Hadamard product (i.e., the element-wise product) of each input vector",
          "",
          "[Removed Lines]",
          "1185:     JavaTransformer, HasInputCol, HasOutputCol, JavaMLReadable, JavaMLWritable",
          "",
          "[Added Lines]",
          "1358:     JavaTransformer,",
          "1359:     HasInputCol,",
          "1360:     HasOutputCol,",
          "1361:     JavaMLReadable[\"ElementwiseProduct\"],",
          "1362:     JavaMLWritable,",
          "",
          "---------------",
          "--- Hunk 42 ---",
          "[Context before]",
          "1215:     True",
          "1216:     \"\"\"",
          "1219:         Params._dummy(),",
          "1220:         \"scalingVec\",",
          "1221:         \"Vector for hadamard product.\",",
          "1222:         typeConverter=TypeConverters.toVector,",
          "1223:     )",
          "1225:     @keyword_only",
          "1227:         \"\"\"",
          "1228:         __init__(self, \\\\*, scalingVec=None, inputCol=None, outputCol=None)",
          "1229:         \"\"\"",
          "",
          "[Removed Lines]",
          "1218:     scalingVec = Param(",
          "1226:     def __init__(self, *, scalingVec=None, inputCol=None, outputCol=None):",
          "",
          "[Added Lines]",
          "1395:     scalingVec: Param[Vector] = Param(",
          "1402:     _input_kwargs: Dict[str, Any]",
          "1405:     def __init__(",
          "1406:         self,",
          "1408:         scalingVec: Optional[Vector] = None,",
          "1409:         inputCol: Optional[str] = None,",
          "1410:         outputCol: Optional[str] = None,",
          "1411:     ):",
          "",
          "---------------",
          "--- Hunk 43 ---",
          "[Context before]",
          "1237:     @keyword_only",
          "1238:     @since(\"1.5.0\")",
          "1240:         \"\"\"",
          "1241:         setParams(self, \\\\*, scalingVec=None, inputCol=None, outputCol=None)",
          "1242:         Sets params for this ElementwiseProduct.",
          "",
          "[Removed Lines]",
          "1239:     def setParams(self, *, scalingVec=None, inputCol=None, outputCol=None):",
          "",
          "[Added Lines]",
          "1424:     def setParams(",
          "1425:         self,",
          "1427:         scalingVec: Optional[Vector] = None,",
          "1428:         inputCol: Optional[str] = None,",
          "1429:         outputCol: Optional[str] = None,",
          "1430:     ) -> \"ElementwiseProduct\":",
          "",
          "---------------",
          "--- Hunk 44 ---",
          "[Context before]",
          "1245:         return self._set(**kwargs)",
          "1247:     @since(\"2.0.0\")",
          "1249:         \"\"\"",
          "1250:         Sets the value of :py:attr:`scalingVec`.",
          "1251:         \"\"\"",
          "1252:         return self._set(scalingVec=value)",
          "1254:     @since(\"2.0.0\")",
          "1256:         \"\"\"",
          "1257:         Gets the value of scalingVec or its default value.",
          "1258:         \"\"\"",
          "1259:         return self.getOrDefault(self.scalingVec)",
          "1262:         \"\"\"",
          "1263:         Sets the value of :py:attr:`inputCol`.",
          "1264:         \"\"\"",
          "1265:         return self._set(inputCol=value)",
          "1268:         \"\"\"",
          "1269:         Sets the value of :py:attr:`outputCol`.",
          "1270:         \"\"\"",
          "",
          "[Removed Lines]",
          "1248:     def setScalingVec(self, value):",
          "1255:     def getScalingVec(self):",
          "1261:     def setInputCol(self, value):",
          "1267:     def setOutputCol(self, value):",
          "",
          "[Added Lines]",
          "1439:     def setScalingVec(self, value: Vector) -> \"ElementwiseProduct\":",
          "1446:     def getScalingVec(self) -> Vector:",
          "1452:     def setInputCol(self, value: str) -> \"ElementwiseProduct\":",
          "1458:     def setOutputCol(self, value: str) -> \"ElementwiseProduct\":",
          "",
          "---------------",
          "--- Hunk 45 ---",
          "[Context before]",
          "1274: @inherit_doc",
          "1275: class FeatureHasher(",
          "1277: ):",
          "1278:     \"\"\"",
          "1279:     Feature hashing projects a set of categorical or numerical features into a feature vector of",
          "",
          "[Removed Lines]",
          "1276:     JavaTransformer, HasInputCols, HasOutputCol, HasNumFeatures, JavaMLReadable, JavaMLWritable",
          "",
          "[Added Lines]",
          "1467:     JavaTransformer,",
          "1468:     HasInputCols,",
          "1469:     HasOutputCol,",
          "1470:     HasNumFeatures,",
          "1471:     JavaMLReadable[\"FeatureHasher\"],",
          "1472:     JavaMLWritable,",
          "",
          "---------------",
          "--- Hunk 46 ---",
          "[Context before]",
          "1332:     True",
          "1333:     \"\"\"",
          "1336:         Params._dummy(),",
          "1337:         \"categoricalCols\",",
          "1338:         \"numeric columns to treat as categorical\",",
          "1339:         typeConverter=TypeConverters.toListString,",
          "1340:     )",
          "1342:     @keyword_only",
          "1343:     def __init__(",
          "1345:     ):",
          "1346:         \"\"\"",
          "1347:         __init__(self, \\\\*, numFeatures=1 << 18, inputCols=None, outputCol=None, \\",
          "",
          "[Removed Lines]",
          "1335:     categoricalCols = Param(",
          "1344:         self, *, numFeatures=1 << 18, inputCols=None, outputCol=None, categoricalCols=None",
          "",
          "[Added Lines]",
          "1531:     categoricalCols: Param[List[str]] = Param(",
          "1538:     _input_kwargs: Dict[str, Any]",
          "1542:         self,",
          "1544:         numFeatures: int = 1 << 18,",
          "1545:         inputCols: Optional[List[str]] = None,",
          "1546:         outputCol: Optional[str] = None,",
          "1547:         categoricalCols: Optional[List[str]] = None,",
          "",
          "---------------",
          "--- Hunk 47 ---",
          "[Context before]",
          "1356:     @keyword_only",
          "1357:     @since(\"2.3.0\")",
          "1358:     def setParams(",
          "1361:         \"\"\"",
          "1362:         setParams(self, \\\\*, numFeatures=1 << 18, inputCols=None, outputCol=None, \\",
          "1363:                   categoricalCols=None)",
          "",
          "[Removed Lines]",
          "1359:         self, *, numFeatures=1 << 18, inputCols=None, outputCol=None, categoricalCols=None",
          "1360:     ):",
          "",
          "[Added Lines]",
          "1562:         self,",
          "1564:         numFeatures: int = 1 << 18,",
          "1565:         inputCols: Optional[List[str]] = None,",
          "1566:         outputCol: Optional[str] = None,",
          "1567:         categoricalCols: Optional[List[str]] = None,",
          "1568:     ) -> \"FeatureHasher\":",
          "",
          "---------------",
          "--- Hunk 48 ---",
          "[Context before]",
          "1367:         return self._set(**kwargs)",
          "1369:     @since(\"2.3.0\")",
          "1371:         \"\"\"",
          "1372:         Sets the value of :py:attr:`categoricalCols`.",
          "1373:         \"\"\"",
          "1374:         return self._set(categoricalCols=value)",
          "1376:     @since(\"2.3.0\")",
          "1378:         \"\"\"",
          "1379:         Gets the value of binary or its default value.",
          "1380:         \"\"\"",
          "1381:         return self.getOrDefault(self.categoricalCols)",
          "1384:         \"\"\"",
          "1385:         Sets the value of :py:attr:`inputCols`.",
          "1386:         \"\"\"",
          "1387:         return self._set(inputCols=value)",
          "1390:         \"\"\"",
          "1391:         Sets the value of :py:attr:`outputCol`.",
          "1392:         \"\"\"",
          "1393:         return self._set(outputCol=value)",
          "1396:         \"\"\"",
          "1397:         Sets the value of :py:attr:`numFeatures`.",
          "1398:         \"\"\"",
          "",
          "[Removed Lines]",
          "1370:     def setCategoricalCols(self, value):",
          "1377:     def getCategoricalCols(self):",
          "1383:     def setInputCols(self, value):",
          "1389:     def setOutputCol(self, value):",
          "1395:     def setNumFeatures(self, value):",
          "",
          "[Added Lines]",
          "1578:     def setCategoricalCols(self, value: List[str]) -> \"FeatureHasher\":",
          "1585:     def getCategoricalCols(self) -> List[str]:",
          "1591:     def setInputCols(self, value: List[str]) -> \"FeatureHasher\":",
          "1597:     def setOutputCol(self, value: str) -> \"FeatureHasher\":",
          "1603:     def setNumFeatures(self, value: int) -> \"FeatureHasher\":",
          "",
          "---------------",
          "--- Hunk 49 ---",
          "[Context before]",
          "1402: @inherit_doc",
          "1403: class HashingTF(",
          "1405: ):",
          "1406:     \"\"\"",
          "1407:     Maps a sequence of terms to their term frequencies using the hashing trick.",
          "",
          "[Removed Lines]",
          "1404:     JavaTransformer, HasInputCol, HasOutputCol, HasNumFeatures, JavaMLReadable, JavaMLWritable",
          "",
          "[Added Lines]",
          "1612:     JavaTransformer,",
          "1613:     HasInputCol,",
          "1614:     HasOutputCol,",
          "1615:     HasNumFeatures,",
          "1616:     JavaMLReadable[\"HashingTF\"],",
          "1617:     JavaMLWritable,",
          "",
          "---------------",
          "--- Hunk 50 ---",
          "[Context before]",
          "1437:     5",
          "1438:     \"\"\"",
          "1441:         Params._dummy(),",
          "1442:         \"binary\",",
          "1443:         \"If True, all non zero counts are set to 1. \"",
          "",
          "[Removed Lines]",
          "1440:     binary = Param(",
          "",
          "[Added Lines]",
          "1653:     binary: Param[bool] = Param(",
          "",
          "---------------",
          "--- Hunk 51 ---",
          "[Context before]",
          "1446:         typeConverter=TypeConverters.toBoolean,",
          "1447:     )",
          "1449:     @keyword_only",
          "1451:         \"\"\"",
          "1452:         __init__(self, \\\\*, numFeatures=1 << 18, binary=False, inputCol=None, outputCol=None)",
          "1453:         \"\"\"",
          "",
          "[Removed Lines]",
          "1450:     def __init__(self, *, numFeatures=1 << 18, binary=False, inputCol=None, outputCol=None):",
          "",
          "[Added Lines]",
          "1662:     _input_kwargs: Dict[str, Any]",
          "1665:     def __init__(",
          "1666:         self,",
          "1668:         numFeatures: int = 1 << 18,",
          "1669:         binary: bool = False,",
          "1670:         inputCol: Optional[str] = None,",
          "1671:         outputCol: Optional[str] = None,",
          "1672:     ):",
          "",
          "---------------",
          "--- Hunk 52 ---",
          "[Context before]",
          "1460:     @keyword_only",
          "1461:     @since(\"1.3.0\")",
          "1463:         \"\"\"",
          "1464:         setParams(self, \\\\*, numFeatures=1 << 18, binary=False, inputCol=None, outputCol=None)",
          "1465:         Sets params for this HashingTF.",
          "",
          "[Removed Lines]",
          "1462:     def setParams(self, *, numFeatures=1 << 18, binary=False, inputCol=None, outputCol=None):",
          "",
          "[Added Lines]",
          "1684:     def setParams(",
          "1685:         self,",
          "1687:         numFeatures: int = 1 << 18,",
          "1688:         binary: bool = False,",
          "1689:         inputCol: Optional[str] = None,",
          "1690:         outputCol: Optional[str] = None,",
          "1691:     ) -> \"HashingTF\":",
          "",
          "---------------",
          "--- Hunk 53 ---",
          "[Context before]",
          "1468:         return self._set(**kwargs)",
          "1470:     @since(\"2.0.0\")",
          "1472:         \"\"\"",
          "1473:         Sets the value of :py:attr:`binary`.",
          "1474:         \"\"\"",
          "1475:         return self._set(binary=value)",
          "1477:     @since(\"2.0.0\")",
          "1479:         \"\"\"",
          "1480:         Gets the value of binary or its default value.",
          "1481:         \"\"\"",
          "1482:         return self.getOrDefault(self.binary)",
          "1485:         \"\"\"",
          "1486:         Sets the value of :py:attr:`inputCol`.",
          "1487:         \"\"\"",
          "1488:         return self._set(inputCol=value)",
          "1491:         \"\"\"",
          "1492:         Sets the value of :py:attr:`outputCol`.",
          "1493:         \"\"\"",
          "1494:         return self._set(outputCol=value)",
          "1497:         \"\"\"",
          "1498:         Sets the value of :py:attr:`numFeatures`.",
          "1499:         \"\"\"",
          "1500:         return self._set(numFeatures=value)",
          "1502:     @since(\"3.0.0\")",
          "1504:         \"\"\"",
          "1505:         Returns the index of the input term.",
          "1506:         \"\"\"",
          "1507:         self._transfer_params_to_java()",
          "1508:         return self._java_obj.indexOf(term)",
          "",
          "[Removed Lines]",
          "1471:     def setBinary(self, value):",
          "1478:     def getBinary(self):",
          "1484:     def setInputCol(self, value):",
          "1490:     def setOutputCol(self, value):",
          "1496:     def setNumFeatures(self, value):",
          "1503:     def indexOf(self, term):",
          "",
          "[Added Lines]",
          "1700:     def setBinary(self, value: bool) -> \"HashingTF\":",
          "1707:     def getBinary(self) -> bool:",
          "1713:     def setInputCol(self, value: str) -> \"HashingTF\":",
          "1719:     def setOutputCol(self, value: str) -> \"HashingTF\":",
          "1725:     def setNumFeatures(self, value: int) -> \"HashingTF\":",
          "1732:     def indexOf(self, term: Any) -> int:",
          "1737:         assert self._java_obj is not None",
          "",
          "---------------",
          "--- Hunk 54 ---",
          "[Context before]",
          "1515:     .. versionadded:: 3.0.0",
          "1516:     \"\"\"",
          "1519:         Params._dummy(),",
          "1520:         \"minDocFreq\",",
          "1521:         \"minimum number of documents in which a term should appear for filtering\",",
          "",
          "[Removed Lines]",
          "1518:     minDocFreq = Param(",
          "",
          "[Added Lines]",
          "1748:     minDocFreq: Param[int] = Param(",
          "",
          "---------------",
          "--- Hunk 55 ---",
          "[Context before]",
          "1523:     )",
          "1525:     @since(\"1.4.0\")",
          "1527:         \"\"\"",
          "1528:         Gets the value of minDocFreq or its default value.",
          "1529:         \"\"\"",
          "1530:         return self.getOrDefault(self.minDocFreq)",
          "1533:         super(_IDFParams, self).__init__(*args)",
          "1534:         self._setDefault(minDocFreq=0)",
          "1537: @inherit_doc",
          "1539:     \"\"\"",
          "1540:     Compute the Inverse Document Frequency (IDF) given a collection of documents.",
          "",
          "[Removed Lines]",
          "1526:     def getMinDocFreq(self):",
          "1532:     def __init__(self, *args):",
          "1538: class IDF(JavaEstimator, _IDFParams, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "1756:     def getMinDocFreq(self) -> int:",
          "1762:     def __init__(self, *args: Any):",
          "1768: class IDF(JavaEstimator[\"IDFModel\"], _IDFParams, JavaMLReadable[\"IDF\"], JavaMLWritable):",
          "",
          "---------------",
          "--- Hunk 56 ---",
          "[Context before]",
          "1581:     True",
          "1582:     \"\"\"",
          "1584:     @keyword_only",
          "1586:         \"\"\"",
          "1587:         __init__(self, \\\\*, minDocFreq=0, inputCol=None, outputCol=None)",
          "1588:         \"\"\"",
          "",
          "[Removed Lines]",
          "1585:     def __init__(self, *, minDocFreq=0, inputCol=None, outputCol=None):",
          "",
          "[Added Lines]",
          "1814:     _input_kwargs: Dict[str, Any]",
          "1817:     def __init__(",
          "1818:         self,",
          "1820:         minDocFreq: int = 0,",
          "1821:         inputCol: Optional[str] = None,",
          "1822:         outputCol: Optional[str] = None,",
          "1823:     ):",
          "",
          "---------------",
          "--- Hunk 57 ---",
          "[Context before]",
          "1594:     @keyword_only",
          "1595:     @since(\"1.4.0\")",
          "1597:         \"\"\"",
          "1598:         setParams(self, \\\\*, minDocFreq=0, inputCol=None, outputCol=None)",
          "1599:         Sets params for this IDF.",
          "",
          "[Removed Lines]",
          "1596:     def setParams(self, *, minDocFreq=0, inputCol=None, outputCol=None):",
          "",
          "[Added Lines]",
          "1834:     def setParams(",
          "1835:         self,",
          "1837:         minDocFreq: int = 0,",
          "1838:         inputCol: Optional[str] = None,",
          "1839:         outputCol: Optional[str] = None,",
          "1840:     ) -> \"IDF\":",
          "",
          "---------------",
          "--- Hunk 58 ---",
          "[Context before]",
          "1602:         return self._set(**kwargs)",
          "1604:     @since(\"1.4.0\")",
          "1606:         \"\"\"",
          "1607:         Sets the value of :py:attr:`minDocFreq`.",
          "1608:         \"\"\"",
          "1609:         return self._set(minDocFreq=value)",
          "1612:         \"\"\"",
          "1613:         Sets the value of :py:attr:`inputCol`.",
          "1614:         \"\"\"",
          "1615:         return self._set(inputCol=value)",
          "1618:         \"\"\"",
          "1619:         Sets the value of :py:attr:`outputCol`.",
          "1620:         \"\"\"",
          "1621:         return self._set(outputCol=value)",
          "1624:         return IDFModel(java_model)",
          "1628:     \"\"\"",
          "1629:     Model fitted by :py:class:`IDF`.",
          "",
          "[Removed Lines]",
          "1605:     def setMinDocFreq(self, value):",
          "1611:     def setInputCol(self, value):",
          "1617:     def setOutputCol(self, value):",
          "1623:     def _create_model(self, java_model):",
          "1627: class IDFModel(JavaModel, _IDFParams, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "1849:     def setMinDocFreq(self, value: int) -> \"IDF\":",
          "1855:     def setInputCol(self, value: str) -> \"IDF\":",
          "1861:     def setOutputCol(self, value: str) -> \"IDF\":",
          "1867:     def _create_model(self, java_model: \"JavaObject\") -> \"IDFModel\":",
          "1871: class IDFModel(JavaModel, _IDFParams, JavaMLReadable[\"IDFModel\"], JavaMLWritable):",
          "",
          "---------------",
          "--- Hunk 59 ---",
          "[Context before]",
          "1632:     \"\"\"",
          "1634:     @since(\"3.0.0\")",
          "1636:         \"\"\"",
          "1637:         Sets the value of :py:attr:`inputCol`.",
          "1638:         \"\"\"",
          "1639:         return self._set(inputCol=value)",
          "1641:     @since(\"3.0.0\")",
          "1643:         \"\"\"",
          "1644:         Sets the value of :py:attr:`outputCol`.",
          "1645:         \"\"\"",
          "1646:         return self._set(outputCol=value)",
          "1649:     @since(\"2.0.0\")",
          "1651:         \"\"\"",
          "1652:         Returns the IDF vector.",
          "1653:         \"\"\"",
          "1654:         return self._call_java(\"idf\")",
          "1657:     @since(\"3.0.0\")",
          "1659:         \"\"\"",
          "1660:         Returns the document frequency.",
          "1661:         \"\"\"",
          "1662:         return self._call_java(\"docFreq\")",
          "1665:     @since(\"3.0.0\")",
          "1667:         \"\"\"",
          "1668:         Returns number of documents evaluated to compute idf",
          "1669:         \"\"\"",
          "",
          "[Removed Lines]",
          "1635:     def setInputCol(self, value):",
          "1642:     def setOutputCol(self, value):",
          "1648:     @property",
          "1650:     def idf(self):",
          "1656:     @property",
          "1658:     def docFreq(self):",
          "1664:     @property",
          "1666:     def numDocs(self):",
          "",
          "[Added Lines]",
          "1879:     def setInputCol(self, value: str) -> \"IDFModel\":",
          "1886:     def setOutputCol(self, value: str) -> \"IDFModel\":",
          "1892:     @property  # type: ignore[misc]",
          "1894:     def idf(self) -> Vector:",
          "1900:     @property  # type: ignore[misc]",
          "1902:     def docFreq(self) -> List[int]:",
          "1908:     @property  # type: ignore[misc]",
          "1910:     def numDocs(self) -> int:",
          "",
          "---------------",
          "--- Hunk 60 ---",
          "[Context before]",
          "1677:     .. versionadded:: 3.0.0",
          "1678:     \"\"\"",
          "1681:         Params._dummy(),",
          "1682:         \"strategy\",",
          "1683:         \"strategy for imputation. If mean, then replace missing values using the mean \"",
          "",
          "[Removed Lines]",
          "1680:     strategy = Param(",
          "",
          "[Added Lines]",
          "1924:     strategy: Param[str] = Param(",
          "",
          "---------------",
          "--- Hunk 61 ---",
          "[Context before]",
          "1687:         typeConverter=TypeConverters.toString,",
          "1688:     )",
          "1691:         Params._dummy(),",
          "1692:         \"missingValue\",",
          "1693:         \"The placeholder for the missing values. All occurrences of missingValue \"",
          "",
          "[Removed Lines]",
          "1690:     missingValue = Param(",
          "",
          "[Added Lines]",
          "1934:     missingValue: Param[float] = Param(",
          "",
          "---------------",
          "--- Hunk 62 ---",
          "[Context before]",
          "1695:         typeConverter=TypeConverters.toFloat,",
          "1696:     )",
          "1699:         super(_ImputerParams, self).__init__(*args)",
          "1700:         self._setDefault(strategy=\"mean\", missingValue=float(\"nan\"), relativeError=0.001)",
          "1702:     @since(\"2.2.0\")",
          "1704:         \"\"\"",
          "1705:         Gets the value of :py:attr:`strategy` or its default value.",
          "1706:         \"\"\"",
          "1707:         return self.getOrDefault(self.strategy)",
          "1709:     @since(\"2.2.0\")",
          "1711:         \"\"\"",
          "1712:         Gets the value of :py:attr:`missingValue` or its default value.",
          "1713:         \"\"\"",
          "",
          "[Removed Lines]",
          "1698:     def __init__(self, *args):",
          "1703:     def getStrategy(self):",
          "1710:     def getMissingValue(self):",
          "",
          "[Added Lines]",
          "1942:     def __init__(self, *args: Any):",
          "1947:     def getStrategy(self) -> str:",
          "1954:     def getMissingValue(self) -> float:",
          "",
          "---------------",
          "--- Hunk 63 ---",
          "[Context before]",
          "1717: @inherit_doc",
          "1719:     \"\"\"",
          "1720:     Imputation estimator for completing missing values, using the mean, median or mode",
          "1721:     of the columns in which the missing values are located. The input columns should be of",
          "",
          "[Removed Lines]",
          "1718: class Imputer(JavaEstimator, _ImputerParams, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "1962: class Imputer(",
          "1963:     JavaEstimator[\"ImputerModel\"], _ImputerParams, JavaMLReadable[\"Imputer\"], JavaMLWritable",
          "1964: ):",
          "",
          "---------------",
          "--- Hunk 64 ---",
          "[Context before]",
          "1829:     True",
          "1830:     \"\"\"",
          "1832:     @keyword_only",
          "1833:     def __init__(",
          "1834:         self,",
          "1843:     ):",
          "1844:         \"\"\"",
          "1845:         __init__(self, \\\\*, strategy=\"mean\", missingValue=float(\"nan\"), inputCols=None, \\",
          "",
          "[Removed Lines]",
          "1836:         strategy=\"mean\",",
          "1837:         missingValue=float(\"nan\"),",
          "1838:         inputCols=None,",
          "1839:         outputCols=None,",
          "1840:         inputCol=None,",
          "1841:         outputCol=None,",
          "1842:         relativeError=0.001,",
          "",
          "[Added Lines]",
          "2078:     _input_kwargs: Dict[str, Any]",
          "2080:     @overload",
          "2081:     def __init__(",
          "2082:         self,",
          "2084:         strategy: str = ...,",
          "2085:         missingValue: float = ...,",
          "2086:         inputCols: Optional[List[str]] = ...,",
          "2087:         outputCols: Optional[List[str]] = ...,",
          "2088:         relativeError: float = ...,",
          "2089:     ):",
          "2090:         ...",
          "2092:     @overload",
          "2093:     def __init__(",
          "2094:         self,",
          "2096:         strategy: str = ...,",
          "2097:         missingValue: float = ...,",
          "2098:         inputCol: Optional[str] = ...,",
          "2099:         outputCol: Optional[str] = ...,",
          "2100:         relativeError: float = ...,",
          "2101:     ):",
          "2102:         ...",
          "2108:         strategy: str = \"mean\",",
          "2109:         missingValue: float = float(\"nan\"),",
          "2110:         inputCols: Optional[List[str]] = None,",
          "2111:         outputCols: Optional[List[str]] = None,",
          "2112:         inputCol: Optional[str] = None,",
          "2113:         outputCol: Optional[str] = None,",
          "2114:         relativeError: float = 0.001,",
          "",
          "---------------",
          "--- Hunk 65 ---",
          "[Context before]",
          "1850:         kwargs = self._input_kwargs",
          "1851:         self.setParams(**kwargs)",
          "1853:     @keyword_only",
          "1854:     @since(\"2.2.0\")",
          "1855:     def setParams(",
          "1856:         self,",
          "1866:         \"\"\"",
          "1867:         setParams(self, \\\\*, strategy=\"mean\", missingValue=float(\"nan\"), inputCols=None, \\",
          "1868:                   outputCols=None, inputCol=None, outputCol=None, relativeError=0.001)",
          "",
          "[Removed Lines]",
          "1858:         strategy=\"mean\",",
          "1859:         missingValue=float(\"nan\"),",
          "1860:         inputCols=None,",
          "1861:         outputCols=None,",
          "1862:         inputCol=None,",
          "1863:         outputCol=None,",
          "1864:         relativeError=0.001,",
          "1865:     ):",
          "",
          "[Added Lines]",
          "2125:     @overload",
          "2126:     def setParams(",
          "2127:         self,",
          "2129:         strategy: str = ...,",
          "2130:         missingValue: float = ...,",
          "2131:         inputCols: Optional[List[str]] = ...,",
          "2132:         outputCols: Optional[List[str]] = ...,",
          "2133:         relativeError: float = ...,",
          "2134:     ) -> \"Imputer\":",
          "2135:         ...",
          "2137:     @overload",
          "2138:     def setParams(",
          "2139:         self,",
          "2141:         strategy: str = ...,",
          "2142:         missingValue: float = ...,",
          "2143:         inputCol: Optional[str] = ...,",
          "2144:         outputCol: Optional[str] = ...,",
          "2145:         relativeError: float = ...,",
          "2146:     ) -> \"Imputer\":",
          "2147:         ...",
          "2154:         strategy: str = \"mean\",",
          "2155:         missingValue: float = float(\"nan\"),",
          "2156:         inputCols: Optional[List[str]] = None,",
          "2157:         outputCols: Optional[List[str]] = None,",
          "2158:         inputCol: Optional[str] = None,",
          "2159:         outputCol: Optional[str] = None,",
          "2160:         relativeError: float = 0.001,",
          "2161:     ) -> \"Imputer\":",
          "",
          "---------------",
          "--- Hunk 66 ---",
          "[Context before]",
          "1872:         return self._set(**kwargs)",
          "1874:     @since(\"2.2.0\")",
          "1876:         \"\"\"",
          "1877:         Sets the value of :py:attr:`strategy`.",
          "1878:         \"\"\"",
          "1879:         return self._set(strategy=value)",
          "1881:     @since(\"2.2.0\")",
          "1883:         \"\"\"",
          "1884:         Sets the value of :py:attr:`missingValue`.",
          "1885:         \"\"\"",
          "1886:         return self._set(missingValue=value)",
          "1888:     @since(\"2.2.0\")",
          "1890:         \"\"\"",
          "1891:         Sets the value of :py:attr:`inputCols`.",
          "1892:         \"\"\"",
          "1893:         return self._set(inputCols=value)",
          "1895:     @since(\"2.2.0\")",
          "1897:         \"\"\"",
          "1898:         Sets the value of :py:attr:`outputCols`.",
          "1899:         \"\"\"",
          "1900:         return self._set(outputCols=value)",
          "1902:     @since(\"3.0.0\")",
          "1904:         \"\"\"",
          "1905:         Sets the value of :py:attr:`inputCol`.",
          "1906:         \"\"\"",
          "1907:         return self._set(inputCol=value)",
          "1909:     @since(\"3.0.0\")",
          "1911:         \"\"\"",
          "1912:         Sets the value of :py:attr:`outputCol`.",
          "1913:         \"\"\"",
          "1914:         return self._set(outputCol=value)",
          "1916:     @since(\"3.0.0\")",
          "1918:         \"\"\"",
          "1919:         Sets the value of :py:attr:`relativeError`.",
          "1920:         \"\"\"",
          "1921:         return self._set(relativeError=value)",
          "1924:         return ImputerModel(java_model)",
          "1928:     \"\"\"",
          "1929:     Model fitted by :py:class:`Imputer`.",
          "",
          "[Removed Lines]",
          "1875:     def setStrategy(self, value):",
          "1882:     def setMissingValue(self, value):",
          "1889:     def setInputCols(self, value):",
          "1896:     def setOutputCols(self, value):",
          "1903:     def setInputCol(self, value):",
          "1910:     def setOutputCol(self, value):",
          "1917:     def setRelativeError(self, value):",
          "1923:     def _create_model(self, java_model):",
          "1927: class ImputerModel(JavaModel, _ImputerParams, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "2171:     def setStrategy(self, value: str) -> \"Imputer\":",
          "2178:     def setMissingValue(self, value: float) -> \"Imputer\":",
          "2185:     def setInputCols(self, value: List[str]) -> \"Imputer\":",
          "2192:     def setOutputCols(self, value: List[str]) -> \"Imputer\":",
          "2199:     def setInputCol(self, value: str) -> \"Imputer\":",
          "2206:     def setOutputCol(self, value: str) -> \"Imputer\":",
          "2213:     def setRelativeError(self, value: float) -> \"Imputer\":",
          "2219:     def _create_model(self, java_model: \"JavaObject\") -> \"ImputerModel\":",
          "2223: class ImputerModel(JavaModel, _ImputerParams, JavaMLReadable[\"ImputerModel\"], JavaMLWritable):",
          "",
          "---------------",
          "--- Hunk 67 ---",
          "[Context before]",
          "1932:     \"\"\"",
          "1934:     @since(\"3.0.0\")",
          "1936:         \"\"\"",
          "1937:         Sets the value of :py:attr:`inputCols`.",
          "1938:         \"\"\"",
          "1939:         return self._set(inputCols=value)",
          "1941:     @since(\"3.0.0\")",
          "1943:         \"\"\"",
          "1944:         Sets the value of :py:attr:`outputCols`.",
          "1945:         \"\"\"",
          "1946:         return self._set(outputCols=value)",
          "1948:     @since(\"3.0.0\")",
          "1950:         \"\"\"",
          "1951:         Sets the value of :py:attr:`inputCol`.",
          "1952:         \"\"\"",
          "1953:         return self._set(inputCol=value)",
          "1955:     @since(\"3.0.0\")",
          "1957:         \"\"\"",
          "1958:         Sets the value of :py:attr:`outputCol`.",
          "1959:         \"\"\"",
          "1960:         return self._set(outputCol=value)",
          "1963:     @since(\"2.2.0\")",
          "1965:         \"\"\"",
          "1966:         Returns a DataFrame containing inputCols and their corresponding surrogates,",
          "1967:         which are used to replace the missing values in the input DataFrame.",
          "",
          "[Removed Lines]",
          "1935:     def setInputCols(self, value):",
          "1942:     def setOutputCols(self, value):",
          "1949:     def setInputCol(self, value):",
          "1956:     def setOutputCol(self, value):",
          "1962:     @property",
          "1964:     def surrogateDF(self):",
          "",
          "[Added Lines]",
          "2231:     def setInputCols(self, value: List[str]) -> \"ImputerModel\":",
          "2238:     def setOutputCols(self, value: List[str]) -> \"ImputerModel\":",
          "2245:     def setInputCol(self, value: str) -> \"ImputerModel\":",
          "2252:     def setOutputCol(self, value: str) -> \"ImputerModel\":",
          "2258:     @property  # type: ignore[misc]",
          "2260:     def surrogateDF(self) -> DataFrame:",
          "",
          "---------------",
          "--- Hunk 68 ---",
          "[Context before]",
          "1972: @inherit_doc",
          "1974:     \"\"\"",
          "1975:     Implements the feature interaction transform. This transformer takes in Double and Vector type",
          "1976:     columns and outputs a flattened vector of their feature interactions. To handle interaction,",
          "",
          "[Removed Lines]",
          "1973: class Interaction(JavaTransformer, HasInputCols, HasOutputCol, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "2269: class Interaction(",
          "2270:     JavaTransformer,",
          "2271:     HasInputCols,",
          "2272:     HasOutputCol,",
          "2273:     JavaMLReadable[\"Interaction\"],",
          "2274:     JavaMLWritable,",
          "2275: ):",
          "",
          "---------------",
          "--- Hunk 69 ---",
          "[Context before]",
          "2006:     True",
          "2007:     \"\"\"",
          "2009:     @keyword_only",
          "2011:         \"\"\"",
          "2012:         __init__(self, \\\\*, inputCols=None, outputCol=None):",
          "2013:         \"\"\"",
          "",
          "[Removed Lines]",
          "2010:     def __init__(self, *, inputCols=None, outputCol=None):",
          "",
          "[Added Lines]",
          "2311:     _input_kwargs: Dict[str, Any]",
          "2314:     def __init__(self, *, inputCols: Optional[List[str]] = None, outputCol: Optional[str] = None):",
          "",
          "---------------",
          "--- Hunk 70 ---",
          "[Context before]",
          "2020:     @keyword_only",
          "2021:     @since(\"3.0.0\")",
          "2023:         \"\"\"",
          "2024:         setParams(self, \\\\*, inputCols=None, outputCol=None)",
          "2025:         Sets params for this Interaction.",
          "",
          "[Removed Lines]",
          "2022:     def setParams(self, *, inputCols=None, outputCol=None):",
          "",
          "[Added Lines]",
          "2326:     def setParams(",
          "2327:         self, *, inputCols: Optional[List[str]] = None, outputCol: Optional[str] = None",
          "2328:     ) -> \"Interaction\":",
          "",
          "---------------",
          "--- Hunk 71 ---",
          "[Context before]",
          "2028:         return self._set(**kwargs)",
          "2030:     @since(\"3.0.0\")",
          "2032:         \"\"\"",
          "2033:         Sets the value of :py:attr:`inputCols`.",
          "2034:         \"\"\"",
          "2035:         return self._set(inputCols=value)",
          "2037:     @since(\"3.0.0\")",
          "2039:         \"\"\"",
          "2040:         Sets the value of :py:attr:`outputCol`.",
          "2041:         \"\"\"",
          "",
          "[Removed Lines]",
          "2031:     def setInputCols(self, value):",
          "2038:     def setOutputCol(self, value):",
          "",
          "[Added Lines]",
          "2337:     def setInputCols(self, value: List[str]) -> \"Interaction\":",
          "2344:     def setOutputCol(self, value: str) -> \"Interaction\":",
          "",
          "---------------",
          "--- Hunk 72 ---",
          "[Context before]",
          "2055: @inherit_doc",
          "2057:     \"\"\"",
          "2058:     Rescale each feature individually to range [-1, 1] by dividing through the largest maximum",
          "2059:     absolute value in each feature. It does not shift/center the data, and thus does not destroy",
          "",
          "[Removed Lines]",
          "2056: class MaxAbsScaler(JavaEstimator, _MaxAbsScalerParams, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "2362: class MaxAbsScaler(",
          "2363:     JavaEstimator[\"MaxAbsScalerModel\"],",
          "2364:     _MaxAbsScalerParams,",
          "2365:     JavaMLReadable[\"MaxAbsScaler\"],",
          "2366:     JavaMLWritable,",
          "2367: ):",
          "",
          "---------------",
          "--- Hunk 73 ---",
          "[Context before]",
          "2095:     True",
          "2096:     \"\"\"",
          "2098:     @keyword_only",
          "2100:         \"\"\"",
          "2101:         __init__(self, \\\\*, inputCol=None, outputCol=None)",
          "2102:         \"\"\"",
          "",
          "[Removed Lines]",
          "2099:     def __init__(self, *, inputCol=None, outputCol=None):",
          "",
          "[Added Lines]",
          "2409:     _input_kwargs: Dict[str, Any]",
          "2412:     def __init__(self, *, inputCol: Optional[str] = None, outputCol: Optional[str] = None):",
          "",
          "---------------",
          "--- Hunk 74 ---",
          "[Context before]",
          "2109:     @keyword_only",
          "2110:     @since(\"2.0.0\")",
          "2112:         \"\"\"",
          "2113:         setParams(self, \\\\*, inputCol=None, outputCol=None)",
          "2114:         Sets params for this MaxAbsScaler.",
          "",
          "[Removed Lines]",
          "2111:     def setParams(self, *, inputCol=None, outputCol=None):",
          "",
          "[Added Lines]",
          "2424:     def setParams(",
          "2425:         self, *, inputCol: Optional[str] = None, outputCol: Optional[str] = None",
          "2426:     ) -> \"MaxAbsScaler\":",
          "",
          "---------------",
          "--- Hunk 75 ---",
          "[Context before]",
          "2116:         kwargs = self._input_kwargs",
          "2117:         return self._set(**kwargs)",
          "2120:         \"\"\"",
          "2121:         Sets the value of :py:attr:`inputCol`.",
          "2122:         \"\"\"",
          "2123:         return self._set(inputCol=value)",
          "2126:         \"\"\"",
          "2127:         Sets the value of :py:attr:`outputCol`.",
          "2128:         \"\"\"",
          "2129:         return self._set(outputCol=value)",
          "2132:         return MaxAbsScalerModel(java_model)",
          "2136:     \"\"\"",
          "2137:     Model fitted by :py:class:`MaxAbsScaler`.",
          "",
          "[Removed Lines]",
          "2119:     def setInputCol(self, value):",
          "2125:     def setOutputCol(self, value):",
          "2131:     def _create_model(self, java_model):",
          "2135: class MaxAbsScalerModel(JavaModel, _MaxAbsScalerParams, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "2434:     def setInputCol(self, value: str) -> \"MaxAbsScaler\":",
          "2440:     def setOutputCol(self, value: str) -> \"MaxAbsScaler\":",
          "2446:     def _create_model(self, java_model: \"JavaObject\") -> \"MaxAbsScalerModel\":",
          "2450: class MaxAbsScalerModel(",
          "2451:     JavaModel, _MaxAbsScalerParams, JavaMLReadable[\"MaxAbsScalerModel\"], JavaMLWritable",
          "2452: ):",
          "",
          "---------------",
          "--- Hunk 76 ---",
          "[Context before]",
          "2140:     \"\"\"",
          "2142:     @since(\"3.0.0\")",
          "2144:         \"\"\"",
          "2145:         Sets the value of :py:attr:`inputCol`.",
          "2146:         \"\"\"",
          "2147:         return self._set(inputCol=value)",
          "2149:     @since(\"3.0.0\")",
          "2151:         \"\"\"",
          "2152:         Sets the value of :py:attr:`outputCol`.",
          "2153:         \"\"\"",
          "2154:         return self._set(outputCol=value)",
          "2157:     @since(\"2.0.0\")",
          "2159:         \"\"\"",
          "2160:         Max Abs vector.",
          "2161:         \"\"\"",
          "",
          "[Removed Lines]",
          "2143:     def setInputCol(self, value):",
          "2150:     def setOutputCol(self, value):",
          "2156:     @property",
          "2158:     def maxAbs(self):",
          "",
          "[Added Lines]",
          "2460:     def setInputCol(self, value: str) -> \"MaxAbsScalerModel\":",
          "2467:     def setOutputCol(self, value: str) -> \"MaxAbsScalerModel\":",
          "2473:     @property  # type: ignore[misc]",
          "2475:     def maxAbs(self) -> Vector:",
          "",
          "---------------",
          "--- Hunk 77 ---",
          "[Context before]",
          "2165: @inherit_doc",
          "2168:     \"\"\"",
          "2169:     LSH class for Jaccard distance.",
          "",
          "[Removed Lines]",
          "2166: class MinHashLSH(_LSH, HasInputCol, HasOutputCol, HasSeed, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "2483: class MinHashLSH(",
          "2484:     _LSH[\"MinHashLSHModel\"],",
          "2485:     HasInputCol,",
          "2486:     HasOutputCol,",
          "2487:     HasSeed,",
          "2488:     JavaMLReadable[\"MinHashLSH\"],",
          "2489:     JavaMLWritable,",
          "2490: ):",
          "",
          "---------------",
          "--- Hunk 78 ---",
          "[Context before]",
          "2228:     True",
          "2229:     \"\"\"",
          "2231:     @keyword_only",
          "2233:         \"\"\"",
          "2234:         __init__(self, \\\\*, inputCol=None, outputCol=None, seed=None, numHashTables=1)",
          "2235:         \"\"\"",
          "",
          "[Removed Lines]",
          "2232:     def __init__(self, *, inputCol=None, outputCol=None, seed=None, numHashTables=1):",
          "",
          "[Added Lines]",
          "2555:     _input_kwargs: Dict[str, Any]",
          "2558:     def __init__(",
          "2559:         self,",
          "2561:         inputCol: Optional[str] = None,",
          "2562:         outputCol: Optional[str] = None,",
          "2563:         seed: Optional[int] = None,",
          "2564:         numHashTables: int = 1,",
          "2565:     ):",
          "",
          "---------------",
          "--- Hunk 79 ---",
          "[Context before]",
          "2241:     @keyword_only",
          "2242:     @since(\"2.2.0\")",
          "2244:         \"\"\"",
          "2245:         setParams(self, \\\\*, inputCol=None, outputCol=None, seed=None, numHashTables=1)",
          "2246:         Sets params for this MinHashLSH.",
          "",
          "[Removed Lines]",
          "2243:     def setParams(self, *, inputCol=None, outputCol=None, seed=None, numHashTables=1):",
          "",
          "[Added Lines]",
          "2576:     def setParams(",
          "2577:         self,",
          "2579:         inputCol: Optional[str] = None,",
          "2580:         outputCol: Optional[str] = None,",
          "2581:         seed: Optional[int] = None,",
          "2582:         numHashTables: int = 1,",
          "2583:     ) -> \"MinHashLSH\":",
          "",
          "---------------",
          "--- Hunk 80 ---",
          "[Context before]",
          "2248:         kwargs = self._input_kwargs",
          "2249:         return self._set(**kwargs)",
          "2252:         \"\"\"",
          "2253:         Sets the value of :py:attr:`seed`.",
          "2254:         \"\"\"",
          "2255:         return self._set(seed=value)",
          "2258:         return MinHashLSHModel(java_model)",
          "",
          "[Removed Lines]",
          "2251:     def setSeed(self, value):",
          "2257:     def _create_model(self, java_model):",
          "",
          "[Added Lines]",
          "2591:     def setSeed(self, value: int) -> \"MinHashLSH\":",
          "2597:     def _create_model(self, java_model: \"JavaObject\") -> \"MinHashLSHModel\":",
          "",
          "---------------",
          "--- Hunk 81 ---",
          "[Context before]",
          "2282:     .. versionadded:: 3.0.0",
          "2283:     \"\"\"",
          "2286:         Params._dummy(),",
          "2287:         \"min\",",
          "2288:         \"Lower bound of the output feature range\",",
          "2289:         typeConverter=TypeConverters.toFloat,",
          "2290:     )",
          "2292:         Params._dummy(),",
          "2293:         \"max\",",
          "2294:         \"Upper bound of the output feature range\",",
          "2295:         typeConverter=TypeConverters.toFloat,",
          "2296:     )",
          "2299:         super(_MinMaxScalerParams, self).__init__(*args)",
          "2300:         self._setDefault(min=0.0, max=1.0)",
          "2302:     @since(\"1.6.0\")",
          "2304:         \"\"\"",
          "2305:         Gets the value of min or its default value.",
          "2306:         \"\"\"",
          "2307:         return self.getOrDefault(self.min)",
          "2309:     @since(\"1.6.0\")",
          "2311:         \"\"\"",
          "2312:         Gets the value of max or its default value.",
          "2313:         \"\"\"",
          "",
          "[Removed Lines]",
          "2285:     min = Param(",
          "2291:     max = Param(",
          "2298:     def __init__(self, *args):",
          "2303:     def getMin(self):",
          "2310:     def getMax(self):",
          "",
          "[Added Lines]",
          "2625:     min: Param[float] = Param(",
          "2631:     max: Param[float] = Param(",
          "2638:     def __init__(self, *args: Any):",
          "2643:     def getMin(self) -> float:",
          "2650:     def getMax(self) -> float:",
          "",
          "---------------",
          "--- Hunk 82 ---",
          "[Context before]",
          "2317: @inherit_doc",
          "2319:     \"\"\"",
          "2320:     Rescale each feature individually to a common range [min, max] linearly using column summary",
          "2321:     statistics, which is also known as min-max normalization or Rescaling. The rescaled value for",
          "",
          "[Removed Lines]",
          "2318: class MinMaxScaler(JavaEstimator, _MinMaxScalerParams, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "2658: class MinMaxScaler(",
          "2659:     JavaEstimator[\"MinMaxScalerModel\"],",
          "2660:     _MinMaxScalerParams,",
          "2661:     JavaMLReadable[\"MinMaxScaler\"],",
          "2662:     JavaMLWritable,",
          "2663: ):",
          "",
          "---------------",
          "--- Hunk 83 ---",
          "[Context before]",
          "2372:     True",
          "2373:     \"\"\"",
          "2375:     @keyword_only",
          "2377:         \"\"\"",
          "2378:         __init__(self, \\\\*, min=0.0, max=1.0, inputCol=None, outputCol=None)",
          "2379:         \"\"\"",
          "",
          "[Removed Lines]",
          "2376:     def __init__(self, *, min=0.0, max=1.0, inputCol=None, outputCol=None):",
          "",
          "[Added Lines]",
          "2720:     _input_kwargs: Dict[str, Any]",
          "2723:     def __init__(",
          "2724:         self,",
          "2726:         min: float = 0.0,",
          "2727:         max: float = 1.0,",
          "2728:         inputCol: Optional[str] = None,",
          "2729:         outputCol: Optional[str] = None,",
          "2730:     ):",
          "",
          "---------------",
          "--- Hunk 84 ---",
          "[Context before]",
          "2385:     @keyword_only",
          "2386:     @since(\"1.6.0\")",
          "2388:         \"\"\"",
          "2389:         setParams(self, \\\\*, min=0.0, max=1.0, inputCol=None, outputCol=None)",
          "2390:         Sets params for this MinMaxScaler.",
          "",
          "[Removed Lines]",
          "2387:     def setParams(self, *, min=0.0, max=1.0, inputCol=None, outputCol=None):",
          "",
          "[Added Lines]",
          "2741:     def setParams(",
          "2742:         self,",
          "2744:         min: float = 0.0,",
          "2745:         max: float = 1.0,",
          "2746:         inputCol: Optional[str] = None,",
          "2747:         outputCol: Optional[str] = None,",
          "2748:     ) -> \"MinMaxScaler\":",
          "",
          "---------------",
          "--- Hunk 85 ---",
          "[Context before]",
          "2393:         return self._set(**kwargs)",
          "2395:     @since(\"1.6.0\")",
          "2397:         \"\"\"",
          "2398:         Sets the value of :py:attr:`min`.",
          "2399:         \"\"\"",
          "2400:         return self._set(min=value)",
          "2402:     @since(\"1.6.0\")",
          "2404:         \"\"\"",
          "2405:         Sets the value of :py:attr:`max`.",
          "2406:         \"\"\"",
          "2407:         return self._set(max=value)",
          "2410:         \"\"\"",
          "2411:         Sets the value of :py:attr:`inputCol`.",
          "2412:         \"\"\"",
          "2413:         return self._set(inputCol=value)",
          "2416:         \"\"\"",
          "2417:         Sets the value of :py:attr:`outputCol`.",
          "2418:         \"\"\"",
          "2419:         return self._set(outputCol=value)",
          "2422:         return MinMaxScalerModel(java_model)",
          "2426:     \"\"\"",
          "2427:     Model fitted by :py:class:`MinMaxScaler`.",
          "",
          "[Removed Lines]",
          "2396:     def setMin(self, value):",
          "2403:     def setMax(self, value):",
          "2409:     def setInputCol(self, value):",
          "2415:     def setOutputCol(self, value):",
          "2421:     def _create_model(self, java_model):",
          "2425: class MinMaxScalerModel(JavaModel, _MinMaxScalerParams, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "2757:     def setMin(self, value: float) -> \"MinMaxScaler\":",
          "2764:     def setMax(self, value: float) -> \"MinMaxScaler\":",
          "2770:     def setInputCol(self, value: str) -> \"MinMaxScaler\":",
          "2776:     def setOutputCol(self, value: str) -> \"MinMaxScaler\":",
          "2782:     def _create_model(self, java_model: \"JavaObject\") -> \"MinMaxScalerModel\":",
          "2786: class MinMaxScalerModel(",
          "2787:     JavaModel, _MinMaxScalerParams, JavaMLReadable[\"MinMaxScalerModel\"], JavaMLWritable",
          "2788: ):",
          "",
          "---------------",
          "--- Hunk 86 ---",
          "[Context before]",
          "2430:     \"\"\"",
          "2432:     @since(\"3.0.0\")",
          "2434:         \"\"\"",
          "2435:         Sets the value of :py:attr:`inputCol`.",
          "2436:         \"\"\"",
          "2437:         return self._set(inputCol=value)",
          "2439:     @since(\"3.0.0\")",
          "2441:         \"\"\"",
          "2442:         Sets the value of :py:attr:`outputCol`.",
          "2443:         \"\"\"",
          "2444:         return self._set(outputCol=value)",
          "2446:     @since(\"3.0.0\")",
          "2448:         \"\"\"",
          "2449:         Sets the value of :py:attr:`min`.",
          "2450:         \"\"\"",
          "2451:         return self._set(min=value)",
          "2453:     @since(\"3.0.0\")",
          "2455:         \"\"\"",
          "2456:         Sets the value of :py:attr:`max`.",
          "2457:         \"\"\"",
          "2458:         return self._set(max=value)",
          "2461:     @since(\"2.0.0\")",
          "2463:         \"\"\"",
          "2464:         Min value for each original column during fitting.",
          "2465:         \"\"\"",
          "2466:         return self._call_java(\"originalMin\")",
          "2469:     @since(\"2.0.0\")",
          "2471:         \"\"\"",
          "2472:         Max value for each original column during fitting.",
          "2473:         \"\"\"",
          "",
          "[Removed Lines]",
          "2433:     def setInputCol(self, value):",
          "2440:     def setOutputCol(self, value):",
          "2447:     def setMin(self, value):",
          "2454:     def setMax(self, value):",
          "2460:     @property",
          "2462:     def originalMin(self):",
          "2468:     @property",
          "2470:     def originalMax(self):",
          "",
          "[Added Lines]",
          "2796:     def setInputCol(self, value: str) -> \"MinMaxScalerModel\":",
          "2803:     def setOutputCol(self, value: str) -> \"MinMaxScalerModel\":",
          "2810:     def setMin(self, value: float) -> \"MinMaxScalerModel\":",
          "2817:     def setMax(self, value: float) -> \"MinMaxScalerModel\":",
          "2823:     @property  # type: ignore[misc]",
          "2825:     def originalMin(self) -> Vector:",
          "2831:     @property  # type: ignore[misc]",
          "2833:     def originalMax(self) -> Vector:",
          "",
          "---------------",
          "--- Hunk 87 ---",
          "[Context before]",
          "2477: @inherit_doc",
          "2479:     \"\"\"",
          "2480:     A feature transformer that converts the input array of strings into an array of n-grams. Null",
          "2481:     values in the input array are ignored.",
          "",
          "[Removed Lines]",
          "2478: class NGram(JavaTransformer, HasInputCol, HasOutputCol, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "2841: class NGram(JavaTransformer, HasInputCol, HasOutputCol, JavaMLReadable[\"NGram\"], JavaMLWritable):",
          "",
          "---------------",
          "--- Hunk 88 ---",
          "[Context before]",
          "2519:     True",
          "2520:     \"\"\"",
          "2523:         Params._dummy(),",
          "2524:         \"n\",",
          "2525:         \"number of elements per n-gram (>=1)\",",
          "2526:         typeConverter=TypeConverters.toInt,",
          "2527:     )",
          "2529:     @keyword_only",
          "2531:         \"\"\"",
          "2532:         __init__(self, \\\\*, n=2, inputCol=None, outputCol=None)",
          "2533:         \"\"\"",
          "",
          "[Removed Lines]",
          "2522:     n = Param(",
          "2530:     def __init__(self, *, n=2, inputCol=None, outputCol=None):",
          "",
          "[Added Lines]",
          "2885:     n: Param[int] = Param(",
          "2892:     _input_kwargs: Dict[str, Any]",
          "2895:     def __init__(",
          "2896:         self, *, n: int = 2, inputCol: Optional[str] = None, outputCol: Optional[str] = None",
          "2897:     ):",
          "",
          "---------------",
          "--- Hunk 89 ---",
          "[Context before]",
          "2540:     @keyword_only",
          "2541:     @since(\"1.5.0\")",
          "2543:         \"\"\"",
          "2544:         setParams(self, \\\\*, n=2, inputCol=None, outputCol=None)",
          "2545:         Sets params for this NGram.",
          "",
          "[Removed Lines]",
          "2542:     def setParams(self, *, n=2, inputCol=None, outputCol=None):",
          "",
          "[Added Lines]",
          "2909:     def setParams(",
          "2910:         self, *, n: int = 2, inputCol: Optional[str] = None, outputCol: Optional[str] = None",
          "2911:     ) -> \"NGram\":",
          "",
          "---------------",
          "--- Hunk 90 ---",
          "[Context before]",
          "2548:         return self._set(**kwargs)",
          "2550:     @since(\"1.5.0\")",
          "2552:         \"\"\"",
          "2553:         Sets the value of :py:attr:`n`.",
          "2554:         \"\"\"",
          "2555:         return self._set(n=value)",
          "2557:     @since(\"1.5.0\")",
          "2559:         \"\"\"",
          "2560:         Gets the value of n or its default value.",
          "2561:         \"\"\"",
          "2562:         return self.getOrDefault(self.n)",
          "2565:         \"\"\"",
          "2566:         Sets the value of :py:attr:`inputCol`.",
          "2567:         \"\"\"",
          "2568:         return self._set(inputCol=value)",
          "2571:         \"\"\"",
          "2572:         Sets the value of :py:attr:`outputCol`.",
          "2573:         \"\"\"",
          "",
          "[Removed Lines]",
          "2551:     def setN(self, value):",
          "2558:     def getN(self):",
          "2564:     def setInputCol(self, value):",
          "2570:     def setOutputCol(self, value):",
          "",
          "[Added Lines]",
          "2920:     def setN(self, value: int) -> \"NGram\":",
          "2927:     def getN(self) -> int:",
          "2933:     def setInputCol(self, value: str) -> \"NGram\":",
          "2939:     def setOutputCol(self, value: str) -> \"NGram\":",
          "",
          "---------------",
          "--- Hunk 91 ---",
          "[Context before]",
          "2577: @inherit_doc",
          "2579:     \"\"\"",
          "2580:      Normalize a vector to have unit norm using the given p-norm.",
          "",
          "[Removed Lines]",
          "2578: class Normalizer(JavaTransformer, HasInputCol, HasOutputCol, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "2947: class Normalizer(",
          "2948:     JavaTransformer,",
          "2949:     HasInputCol,",
          "2950:     HasOutputCol,",
          "2951:     JavaMLReadable[\"Normalizer\"],",
          "2952:     JavaMLWritable,",
          "2953: ):",
          "",
          "---------------",
          "--- Hunk 92 ---",
          "[Context before]",
          "2610:     p = Param(Params._dummy(), \"p\", \"the p norm value.\", typeConverter=TypeConverters.toFloat)",
          "2612:     @keyword_only",
          "2614:         \"\"\"",
          "2615:         __init__(self, \\\\*, p=2.0, inputCol=None, outputCol=None)",
          "2616:         \"\"\"",
          "",
          "[Removed Lines]",
          "2613:     def __init__(self, *, p=2.0, inputCol=None, outputCol=None):",
          "",
          "[Added Lines]",
          "2987:     _input_kwargs: Dict[str, Any]",
          "2990:     def __init__(",
          "2991:         self, *, p: float = 2.0, inputCol: Optional[str] = None, outputCol: Optional[str] = None",
          "2992:     ):",
          "",
          "---------------",
          "--- Hunk 93 ---",
          "[Context before]",
          "2623:     @keyword_only",
          "2624:     @since(\"1.4.0\")",
          "2626:         \"\"\"",
          "2627:         setParams(self, \\\\*, p=2.0, inputCol=None, outputCol=None)",
          "2628:         Sets params for this Normalizer.",
          "",
          "[Removed Lines]",
          "2625:     def setParams(self, *, p=2.0, inputCol=None, outputCol=None):",
          "",
          "[Added Lines]",
          "3004:     def setParams(",
          "3005:         self, *, p: float = 2.0, inputCol: Optional[str] = None, outputCol: Optional[str] = None",
          "3006:     ) -> \"Normalizer\":",
          "",
          "---------------",
          "--- Hunk 94 ---",
          "[Context before]",
          "2631:         return self._set(**kwargs)",
          "2633:     @since(\"1.4.0\")",
          "2635:         \"\"\"",
          "2636:         Sets the value of :py:attr:`p`.",
          "2637:         \"\"\"",
          "2638:         return self._set(p=value)",
          "2640:     @since(\"1.4.0\")",
          "2642:         \"\"\"",
          "2643:         Gets the value of p or its default value.",
          "2644:         \"\"\"",
          "2645:         return self.getOrDefault(self.p)",
          "2648:         \"\"\"",
          "2649:         Sets the value of :py:attr:`inputCol`.",
          "2650:         \"\"\"",
          "2651:         return self._set(inputCol=value)",
          "2654:         \"\"\"",
          "2655:         Sets the value of :py:attr:`outputCol`.",
          "2656:         \"\"\"",
          "",
          "[Removed Lines]",
          "2634:     def setP(self, value):",
          "2641:     def getP(self):",
          "2647:     def setInputCol(self, value):",
          "2653:     def setOutputCol(self, value):",
          "",
          "[Added Lines]",
          "3015:     def setP(self, value: float) -> \"Normalizer\":",
          "3022:     def getP(self) -> float:",
          "3028:     def setInputCol(self, value: str) -> \"Normalizer\":",
          "3034:     def setOutputCol(self, value: str) -> \"Normalizer\":",
          "",
          "---------------",
          "--- Hunk 95 ---",
          "[Context before]",
          "2666:     .. versionadded:: 3.0.0",
          "2667:     \"\"\"",
          "2670:         Params._dummy(),",
          "2671:         \"handleInvalid\",",
          "2672:         \"How to handle invalid data during \"",
          "",
          "[Removed Lines]",
          "2669:     handleInvalid = Param(",
          "",
          "[Added Lines]",
          "3050:     handleInvalid: Param[str] = Param(",
          "",
          "---------------",
          "--- Hunk 96 ---",
          "[Context before]",
          "2677:         typeConverter=TypeConverters.toString,",
          "2678:     )",
          "2681:         Params._dummy(),",
          "2682:         \"dropLast\",",
          "2683:         \"whether to drop the last category\",",
          "2684:         typeConverter=TypeConverters.toBoolean,",
          "2685:     )",
          "2688:         super(_OneHotEncoderParams, self).__init__(*args)",
          "2689:         self._setDefault(handleInvalid=\"error\", dropLast=True)",
          "2691:     @since(\"2.3.0\")",
          "2693:         \"\"\"",
          "2694:         Gets the value of dropLast or its default value.",
          "2695:         \"\"\"",
          "",
          "[Removed Lines]",
          "2680:     dropLast = Param(",
          "2687:     def __init__(self, *args):",
          "2692:     def getDropLast(self):",
          "",
          "[Added Lines]",
          "3061:     dropLast: Param[bool] = Param(",
          "3068:     def __init__(self, *args: Any):",
          "3073:     def getDropLast(self) -> bool:",
          "",
          "---------------",
          "--- Hunk 97 ---",
          "[Context before]",
          "2699: @inherit_doc",
          "2701:     \"\"\"",
          "2702:     A one-hot encoder that maps a column of category indices to a column of binary vectors, with",
          "2703:     at most a single one-value per row that indicates the input category index.",
          "",
          "[Removed Lines]",
          "2700: class OneHotEncoder(JavaEstimator, _OneHotEncoderParams, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "3081: class OneHotEncoder(",
          "3082:     JavaEstimator[\"OneHotEncoderModel\"],",
          "3083:     _OneHotEncoderParams,",
          "3084:     JavaMLReadable[\"OneHotEncoder\"],",
          "3085:     JavaMLWritable,",
          "3086: ):",
          "",
          "---------------",
          "--- Hunk 98 ---",
          "[Context before]",
          "2760:     True",
          "2761:     \"\"\"",
          "2763:     @keyword_only",
          "2764:     def __init__(",
          "2765:         self,",
          "2773:     ):",
          "2774:         \"\"\"",
          "2775:         __init__(self, \\\\*, inputCols=None, outputCols=None, handleInvalid=\"error\", dropLast=True, \\",
          "",
          "[Removed Lines]",
          "2767:         inputCols=None,",
          "2768:         outputCols=None,",
          "2769:         handleInvalid=\"error\",",
          "2770:         dropLast=True,",
          "2771:         inputCol=None,",
          "2772:         outputCol=None,",
          "",
          "[Added Lines]",
          "3149:     _input_kwargs: Dict[str, Any]",
          "3151:     @overload",
          "3152:     def __init__(",
          "3153:         self,",
          "3155:         inputCols: Optional[List[str]] = ...,",
          "3156:         outputCols: Optional[List[str]] = ...,",
          "3157:         handleInvalid: str = ...,",
          "3158:         dropLast: bool = ...,",
          "3159:     ):",
          "3160:         ...",
          "3162:     @overload",
          "3163:     def __init__(",
          "3164:         self,",
          "3166:         handleInvalid: str = ...,",
          "3167:         dropLast: bool = ...,",
          "3168:         inputCol: Optional[str] = ...,",
          "3169:         outputCol: Optional[str] = ...,",
          "3170:     ):",
          "3171:         ...",
          "3177:         inputCols: Optional[List[str]] = None,",
          "3178:         outputCols: Optional[List[str]] = None,",
          "3179:         handleInvalid: str = \"error\",",
          "3180:         dropLast: bool = True,",
          "3181:         inputCol: Optional[str] = None,",
          "3182:         outputCol: Optional[str] = None,",
          "",
          "---------------",
          "--- Hunk 99 ---",
          "[Context before]",
          "2780:         kwargs = self._input_kwargs",
          "2781:         self.setParams(**kwargs)",
          "2783:     @keyword_only",
          "2784:     @since(\"2.3.0\")",
          "2785:     def setParams(",
          "2786:         self,",
          "2795:         \"\"\"",
          "2796:         setParams(self, \\\\*, inputCols=None, outputCols=None, handleInvalid=\"error\", \\",
          "2797:                   dropLast=True, inputCol=None, outputCol=None)",
          "",
          "[Removed Lines]",
          "2788:         inputCols=None,",
          "2789:         outputCols=None,",
          "2790:         handleInvalid=\"error\",",
          "2791:         dropLast=True,",
          "2792:         inputCol=None,",
          "2793:         outputCol=None,",
          "2794:     ):",
          "",
          "[Added Lines]",
          "3193:     @overload",
          "3194:     def setParams(",
          "3195:         self,",
          "3197:         inputCols: Optional[List[str]] = ...,",
          "3198:         outputCols: Optional[List[str]] = ...,",
          "3199:         handleInvalid: str = ...,",
          "3200:         dropLast: bool = ...,",
          "3201:     ) -> \"OneHotEncoder\":",
          "3202:         ...",
          "3204:     @overload",
          "3205:     def setParams(",
          "3206:         self,",
          "3208:         handleInvalid: str = ...,",
          "3209:         dropLast: bool = ...,",
          "3210:         inputCol: Optional[str] = ...,",
          "3211:         outputCol: Optional[str] = ...,",
          "3212:     ) -> \"OneHotEncoder\":",
          "3213:         ...",
          "3220:         inputCols: Optional[List[str]] = None,",
          "3221:         outputCols: Optional[List[str]] = None,",
          "3222:         handleInvalid: str = \"error\",",
          "3223:         dropLast: bool = True,",
          "3224:         inputCol: Optional[str] = None,",
          "3225:         outputCol: Optional[str] = None,",
          "3226:     ) -> \"OneHotEncoder\":",
          "",
          "---------------",
          "--- Hunk 100 ---",
          "[Context before]",
          "2801:         return self._set(**kwargs)",
          "2803:     @since(\"2.3.0\")",
          "2805:         \"\"\"",
          "2806:         Sets the value of :py:attr:`dropLast`.",
          "2807:         \"\"\"",
          "2808:         return self._set(dropLast=value)",
          "2810:     @since(\"3.0.0\")",
          "2812:         \"\"\"",
          "2813:         Sets the value of :py:attr:`inputCols`.",
          "2814:         \"\"\"",
          "2815:         return self._set(inputCols=value)",
          "2817:     @since(\"3.0.0\")",
          "2819:         \"\"\"",
          "2820:         Sets the value of :py:attr:`outputCols`.",
          "2821:         \"\"\"",
          "2822:         return self._set(outputCols=value)",
          "2824:     @since(\"3.0.0\")",
          "2826:         \"\"\"",
          "2827:         Sets the value of :py:attr:`handleInvalid`.",
          "2828:         \"\"\"",
          "2829:         return self._set(handleInvalid=value)",
          "2831:     @since(\"3.0.0\")",
          "2833:         \"\"\"",
          "2834:         Sets the value of :py:attr:`inputCol`.",
          "2835:         \"\"\"",
          "2836:         return self._set(inputCol=value)",
          "2838:     @since(\"3.0.0\")",
          "2840:         \"\"\"",
          "2841:         Sets the value of :py:attr:`outputCol`.",
          "2842:         \"\"\"",
          "2843:         return self._set(outputCol=value)",
          "2846:         return OneHotEncoderModel(java_model)",
          "2850:     \"\"\"",
          "2851:     Model fitted by :py:class:`OneHotEncoder`.",
          "",
          "[Removed Lines]",
          "2804:     def setDropLast(self, value):",
          "2811:     def setInputCols(self, value):",
          "2818:     def setOutputCols(self, value):",
          "2825:     def setHandleInvalid(self, value):",
          "2832:     def setInputCol(self, value):",
          "2839:     def setOutputCol(self, value):",
          "2845:     def _create_model(self, java_model):",
          "2849: class OneHotEncoderModel(JavaModel, _OneHotEncoderParams, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "3236:     def setDropLast(self, value: bool) -> \"OneHotEncoder\":",
          "3243:     def setInputCols(self, value: List[str]) -> \"OneHotEncoder\":",
          "3250:     def setOutputCols(self, value: List[str]) -> \"OneHotEncoder\":",
          "3257:     def setHandleInvalid(self, value: str) -> \"OneHotEncoder\":",
          "3264:     def setInputCol(self, value: str) -> \"OneHotEncoder\":",
          "3271:     def setOutputCol(self, value: str) -> \"OneHotEncoder\":",
          "3277:     def _create_model(self, java_model: \"JavaObject\") -> \"OneHotEncoderModel\":",
          "3281: class OneHotEncoderModel(",
          "3282:     JavaModel, _OneHotEncoderParams, JavaMLReadable[\"OneHotEncoderModel\"], JavaMLWritable",
          "3283: ):",
          "",
          "---------------",
          "--- Hunk 101 ---",
          "[Context before]",
          "2854:     \"\"\"",
          "2856:     @since(\"3.0.0\")",
          "2858:         \"\"\"",
          "2859:         Sets the value of :py:attr:`dropLast`.",
          "2860:         \"\"\"",
          "2861:         return self._set(dropLast=value)",
          "2863:     @since(\"3.0.0\")",
          "2865:         \"\"\"",
          "2866:         Sets the value of :py:attr:`inputCols`.",
          "2867:         \"\"\"",
          "2868:         return self._set(inputCols=value)",
          "2870:     @since(\"3.0.0\")",
          "2872:         \"\"\"",
          "2873:         Sets the value of :py:attr:`outputCols`.",
          "2874:         \"\"\"",
          "2875:         return self._set(outputCols=value)",
          "2877:     @since(\"3.0.0\")",
          "2879:         \"\"\"",
          "2880:         Sets the value of :py:attr:`inputCol`.",
          "2881:         \"\"\"",
          "2882:         return self._set(inputCol=value)",
          "2884:     @since(\"3.0.0\")",
          "2886:         \"\"\"",
          "2887:         Sets the value of :py:attr:`outputCol`.",
          "2888:         \"\"\"",
          "2889:         return self._set(outputCol=value)",
          "2891:     @since(\"3.0.0\")",
          "2893:         \"\"\"",
          "2894:         Sets the value of :py:attr:`handleInvalid`.",
          "2895:         \"\"\"",
          "2896:         return self._set(handleInvalid=value)",
          "2899:     @since(\"2.3.0\")",
          "2901:         \"\"\"",
          "2902:         Original number of categories for each feature being encoded.",
          "2903:         The array contains one value for each input column, in order.",
          "",
          "[Removed Lines]",
          "2857:     def setDropLast(self, value):",
          "2864:     def setInputCols(self, value):",
          "2871:     def setOutputCols(self, value):",
          "2878:     def setInputCol(self, value):",
          "2885:     def setOutputCol(self, value):",
          "2892:     def setHandleInvalid(self, value):",
          "2898:     @property",
          "2900:     def categorySizes(self):",
          "",
          "[Added Lines]",
          "3291:     def setDropLast(self, value: bool) -> \"OneHotEncoderModel\":",
          "3298:     def setInputCols(self, value: List[str]) -> \"OneHotEncoderModel\":",
          "3305:     def setOutputCols(self, value: List[str]) -> \"OneHotEncoderModel\":",
          "3312:     def setInputCol(self, value: str) -> \"OneHotEncoderModel\":",
          "3319:     def setOutputCol(self, value: str) -> \"OneHotEncoderModel\":",
          "3326:     def setHandleInvalid(self, value: str) -> \"OneHotEncoderModel\":",
          "3332:     @property  # type: ignore[misc]",
          "3334:     def categorySizes(self) -> List[int]:",
          "",
          "---------------",
          "--- Hunk 102 ---",
          "[Context before]",
          "2908: @inherit_doc",
          "2909: class PolynomialExpansion(",
          "2911: ):",
          "2912:     \"\"\"",
          "2913:     Perform feature expansion in a polynomial space. As said in `wikipedia of Polynomial Expansion",
          "",
          "[Removed Lines]",
          "2910:     JavaTransformer, HasInputCol, HasOutputCol, JavaMLReadable, JavaMLWritable",
          "",
          "[Added Lines]",
          "3344:     JavaTransformer,",
          "3345:     HasInputCol,",
          "3346:     HasOutputCol,",
          "3347:     JavaMLReadable[\"PolynomialExpansion\"],",
          "3348:     JavaMLWritable,",
          "",
          "---------------",
          "--- Hunk 103 ---",
          "[Context before]",
          "2940:     True",
          "2941:     \"\"\"",
          "2944:         Params._dummy(),",
          "2945:         \"degree\",",
          "2946:         \"the polynomial degree to expand (>= 1)\",",
          "2947:         typeConverter=TypeConverters.toInt,",
          "2948:     )",
          "2950:     @keyword_only",
          "2952:         \"\"\"",
          "2953:         __init__(self, \\\\*, degree=2, inputCol=None, outputCol=None)",
          "2954:         \"\"\"",
          "",
          "[Removed Lines]",
          "2943:     degree = Param(",
          "2951:     def __init__(self, *, degree=2, inputCol=None, outputCol=None):",
          "",
          "[Added Lines]",
          "3381:     degree: Param[int] = Param(",
          "3388:     _input_kwargs: Dict[str, Any]",
          "3391:     def __init__(",
          "3392:         self, *, degree: int = 2, inputCol: Optional[str] = None, outputCol: Optional[str] = None",
          "3393:     ):",
          "",
          "---------------",
          "--- Hunk 104 ---",
          "[Context before]",
          "2963:     @keyword_only",
          "2964:     @since(\"1.4.0\")",
          "2966:         \"\"\"",
          "2967:         setParams(self, \\\\*, degree=2, inputCol=None, outputCol=None)",
          "2968:         Sets params for this PolynomialExpansion.",
          "",
          "[Removed Lines]",
          "2965:     def setParams(self, *, degree=2, inputCol=None, outputCol=None):",
          "",
          "[Added Lines]",
          "3407:     def setParams(",
          "3408:         self, *, degree: int = 2, inputCol: Optional[str] = None, outputCol: Optional[str] = None",
          "3409:     ) -> \"PolynomialExpansion\":",
          "",
          "---------------",
          "--- Hunk 105 ---",
          "[Context before]",
          "2971:         return self._set(**kwargs)",
          "2973:     @since(\"1.4.0\")",
          "2975:         \"\"\"",
          "2976:         Sets the value of :py:attr:`degree`.",
          "2977:         \"\"\"",
          "2978:         return self._set(degree=value)",
          "2980:     @since(\"1.4.0\")",
          "2982:         \"\"\"",
          "2983:         Gets the value of degree or its default value.",
          "2984:         \"\"\"",
          "2985:         return self.getOrDefault(self.degree)",
          "2988:         \"\"\"",
          "2989:         Sets the value of :py:attr:`inputCol`.",
          "2990:         \"\"\"",
          "2991:         return self._set(inputCol=value)",
          "2994:         \"\"\"",
          "2995:         Sets the value of :py:attr:`outputCol`.",
          "2996:         \"\"\"",
          "",
          "[Removed Lines]",
          "2974:     def setDegree(self, value):",
          "2981:     def getDegree(self):",
          "2987:     def setInputCol(self, value):",
          "2993:     def setOutputCol(self, value):",
          "",
          "[Added Lines]",
          "3418:     def setDegree(self, value: int) -> \"PolynomialExpansion\":",
          "3425:     def getDegree(self) -> int:",
          "3431:     def setInputCol(self, value: str) -> \"PolynomialExpansion\":",
          "3437:     def setOutputCol(self, value: str) -> \"PolynomialExpansion\":",
          "",
          "---------------",
          "--- Hunk 106 ---",
          "[Context before]",
          "3006:     HasOutputCols,",
          "3007:     HasHandleInvalid,",
          "3008:     HasRelativeError,",
          "3010:     JavaMLWritable,",
          "3011: ):",
          "3012:     \"\"\"",
          "",
          "[Removed Lines]",
          "3009:     JavaMLReadable,",
          "",
          "[Added Lines]",
          "3453:     JavaMLReadable[\"QuantileDiscretizer\"],",
          "",
          "---------------",
          "--- Hunk 107 ---",
          "[Context before]",
          "3102:     ...",
          "3103:     \"\"\"",
          "3106:         Params._dummy(),",
          "3107:         \"numBuckets\",",
          "3108:         \"Maximum number of buckets (quantiles, or \"",
          "",
          "[Removed Lines]",
          "3105:     numBuckets = Param(",
          "",
          "[Added Lines]",
          "3549:     numBuckets: Param[int] = Param(",
          "",
          "---------------",
          "--- Hunk 108 ---",
          "[Context before]",
          "3110:         typeConverter=TypeConverters.toInt,",
          "3111:     )",
          "3114:         Params._dummy(),",
          "3115:         \"handleInvalid\",",
          "3116:         \"how to handle invalid entries. \"",
          "",
          "[Removed Lines]",
          "3113:     handleInvalid = Param(",
          "",
          "[Added Lines]",
          "3557:     handleInvalid: Param[str] = Param(",
          "",
          "---------------",
          "--- Hunk 109 ---",
          "[Context before]",
          "3124:         typeConverter=TypeConverters.toString,",
          "3125:     )",
          "3128:         Params._dummy(),",
          "3129:         \"numBucketsArray\",",
          "3130:         \"Array of number of buckets \"",
          "",
          "[Removed Lines]",
          "3127:     numBucketsArray = Param(",
          "",
          "[Added Lines]",
          "3571:     numBucketsArray: Param[List[int]] = Param(",
          "",
          "---------------",
          "--- Hunk 110 ---",
          "[Context before]",
          "3135:         typeConverter=TypeConverters.toListInt,",
          "3136:     )",
          "3138:     @keyword_only",
          "3139:     def __init__(",
          "3140:         self,",
          "3150:     ):",
          "3151:         \"\"\"",
          "3152:         __init__(self, \\\\*, numBuckets=2, inputCol=None, outputCol=None, relativeError=0.001, \\",
          "",
          "[Removed Lines]",
          "3142:         numBuckets=2,",
          "3143:         inputCol=None,",
          "3144:         outputCol=None,",
          "3145:         relativeError=0.001,",
          "3146:         handleInvalid=\"error\",",
          "3147:         numBucketsArray=None,",
          "3148:         inputCols=None,",
          "3149:         outputCols=None,",
          "",
          "[Added Lines]",
          "3582:     _input_kwargs: Dict[str, Any]",
          "3584:     @overload",
          "3585:     def __init__(",
          "3586:         self,",
          "3588:         numBuckets: int = ...,",
          "3589:         inputCol: Optional[str] = ...,",
          "3590:         outputCol: Optional[str] = ...,",
          "3591:         relativeError: float = ...,",
          "3592:         handleInvalid: str = ...,",
          "3593:     ):",
          "3594:         ...",
          "3596:     @overload",
          "3597:     def __init__(",
          "3598:         self,",
          "3600:         relativeError: float = ...,",
          "3601:         handleInvalid: str = ...,",
          "3602:         numBucketsArray: Optional[List[int]] = ...,",
          "3603:         inputCols: Optional[List[str]] = ...,",
          "3604:         outputCols: Optional[List[str]] = ...,",
          "3605:     ):",
          "3606:         ...",
          "3612:         numBuckets: int = 2,",
          "3613:         inputCol: Optional[str] = None,",
          "3614:         outputCol: Optional[str] = None,",
          "3615:         relativeError: float = 0.001,",
          "3616:         handleInvalid: str = \"error\",",
          "3617:         numBucketsArray: Optional[List[int]] = None,",
          "3618:         inputCols: Optional[List[str]] = None,",
          "3619:         outputCols: Optional[List[str]] = None,",
          "",
          "---------------",
          "--- Hunk 111 ---",
          "[Context before]",
          "3160:         kwargs = self._input_kwargs",
          "3161:         self.setParams(**kwargs)",
          "3163:     @keyword_only",
          "3164:     @since(\"2.0.0\")",
          "3165:     def setParams(",
          "3166:         self,",
          "3177:         \"\"\"",
          "3178:         setParams(self, \\\\*, numBuckets=2, inputCol=None, outputCol=None, relativeError=0.001, \\",
          "3179:                   handleInvalid=\"error\", numBucketsArray=None, inputCols=None, outputCols=None)",
          "",
          "[Removed Lines]",
          "3168:         numBuckets=2,",
          "3169:         inputCol=None,",
          "3170:         outputCol=None,",
          "3171:         relativeError=0.001,",
          "3172:         handleInvalid=\"error\",",
          "3173:         numBucketsArray=None,",
          "3174:         inputCols=None,",
          "3175:         outputCols=None,",
          "3176:     ):",
          "",
          "[Added Lines]",
          "3633:     @overload",
          "3634:     def setParams(",
          "3635:         self,",
          "3637:         numBuckets: int = ...,",
          "3638:         inputCol: Optional[str] = ...,",
          "3639:         outputCol: Optional[str] = ...,",
          "3640:         relativeError: float = ...,",
          "3641:         handleInvalid: str = ...,",
          "3642:     ) -> \"QuantileDiscretizer\":",
          "3643:         ...",
          "3645:     @overload",
          "3646:     def setParams(",
          "3647:         self,",
          "3649:         relativeError: float = ...,",
          "3650:         handleInvalid: str = ...,",
          "3651:         numBucketsArray: Optional[List[int]] = ...,",
          "3652:         inputCols: Optional[List[str]] = ...,",
          "3653:         outputCols: Optional[List[str]] = ...,",
          "3654:     ) -> \"QuantileDiscretizer\":",
          "3655:         ...",
          "3662:         numBuckets: int = 2,",
          "3663:         inputCol: Optional[str] = None,",
          "3664:         outputCol: Optional[str] = None,",
          "3665:         relativeError: float = 0.001,",
          "3666:         handleInvalid: str = \"error\",",
          "3667:         numBucketsArray: Optional[List[int]] = None,",
          "3668:         inputCols: Optional[List[str]] = None,",
          "3669:         outputCols: Optional[List[str]] = None,",
          "3670:     ) -> \"QuantileDiscretizer\":",
          "",
          "---------------",
          "--- Hunk 112 ---",
          "[Context before]",
          "3183:         return self._set(**kwargs)",
          "3185:     @since(\"2.0.0\")",
          "3187:         \"\"\"",
          "3188:         Sets the value of :py:attr:`numBuckets`.",
          "3189:         \"\"\"",
          "3190:         return self._set(numBuckets=value)",
          "3192:     @since(\"2.0.0\")",
          "3194:         \"\"\"",
          "3195:         Gets the value of numBuckets or its default value.",
          "3196:         \"\"\"",
          "3197:         return self.getOrDefault(self.numBuckets)",
          "3199:     @since(\"3.0.0\")",
          "3201:         \"\"\"",
          "3202:         Sets the value of :py:attr:`numBucketsArray`.",
          "3203:         \"\"\"",
          "3204:         return self._set(numBucketsArray=value)",
          "3206:     @since(\"3.0.0\")",
          "3208:         \"\"\"",
          "3209:         Gets the value of numBucketsArray or its default value.",
          "3210:         \"\"\"",
          "3211:         return self.getOrDefault(self.numBucketsArray)",
          "3213:     @since(\"2.0.0\")",
          "3215:         \"\"\"",
          "3216:         Sets the value of :py:attr:`relativeError`.",
          "3217:         \"\"\"",
          "3218:         return self._set(relativeError=value)",
          "3221:         \"\"\"",
          "3222:         Sets the value of :py:attr:`inputCol`.",
          "3223:         \"\"\"",
          "3224:         return self._set(inputCol=value)",
          "3226:     @since(\"3.0.0\")",
          "3228:         \"\"\"",
          "3229:         Sets the value of :py:attr:`inputCols`.",
          "3230:         \"\"\"",
          "3231:         return self._set(inputCols=value)",
          "3234:         \"\"\"",
          "3235:         Sets the value of :py:attr:`outputCol`.",
          "3236:         \"\"\"",
          "3237:         return self._set(outputCol=value)",
          "3239:     @since(\"3.0.0\")",
          "3241:         \"\"\"",
          "3242:         Sets the value of :py:attr:`outputCols`.",
          "3243:         \"\"\"",
          "3244:         return self._set(outputCols=value)",
          "3247:         \"\"\"",
          "3248:         Sets the value of :py:attr:`handleInvalid`.",
          "3249:         \"\"\"",
          "3250:         return self._set(handleInvalid=value)",
          "3253:         \"\"\"",
          "3254:         Private method to convert the java_model to a Python model.",
          "3255:         \"\"\"",
          "",
          "[Removed Lines]",
          "3186:     def setNumBuckets(self, value):",
          "3193:     def getNumBuckets(self):",
          "3200:     def setNumBucketsArray(self, value):",
          "3207:     def getNumBucketsArray(self):",
          "3214:     def setRelativeError(self, value):",
          "3220:     def setInputCol(self, value):",
          "3227:     def setInputCols(self, value):",
          "3233:     def setOutputCol(self, value):",
          "3240:     def setOutputCols(self, value):",
          "3246:     def setHandleInvalid(self, value):",
          "3252:     def _create_model(self, java_model):",
          "",
          "[Added Lines]",
          "3680:     def setNumBuckets(self, value: int) -> \"QuantileDiscretizer\":",
          "3687:     def getNumBuckets(self) -> int:",
          "3694:     def setNumBucketsArray(self, value: List[int]) -> \"QuantileDiscretizer\":",
          "3701:     def getNumBucketsArray(self) -> List[int]:",
          "3708:     def setRelativeError(self, value: float) -> \"QuantileDiscretizer\":",
          "3714:     def setInputCol(self, value: str) -> \"QuantileDiscretizer\":",
          "3721:     def setInputCols(self, value: List[str]) -> \"QuantileDiscretizer\":",
          "3727:     def setOutputCol(self, value: str) -> \"QuantileDiscretizer\":",
          "3734:     def setOutputCols(self, value: List[str]) -> \"QuantileDiscretizer\":",
          "3740:     def setHandleInvalid(self, value: str) -> \"QuantileDiscretizer\":",
          "3746:     def _create_model(self, java_model: \"JavaObject\") -> Bucketizer:",
          "",
          "---------------",
          "--- Hunk 113 ---",
          "[Context before]",
          "3277:     .. versionadded:: 3.0.0",
          "3278:     \"\"\"",
          "3281:         Params._dummy(),",
          "3282:         \"lower\",",
          "3283:         \"Lower quantile to calculate quantile range\",",
          "3284:         typeConverter=TypeConverters.toFloat,",
          "3285:     )",
          "3287:         Params._dummy(),",
          "3288:         \"upper\",",
          "3289:         \"Upper quantile to calculate quantile range\",",
          "3290:         typeConverter=TypeConverters.toFloat,",
          "3291:     )",
          "3293:         Params._dummy(),",
          "3294:         \"withCentering\",",
          "3295:         \"Whether to center data with median\",",
          "3296:         typeConverter=TypeConverters.toBoolean,",
          "3297:     )",
          "3299:         Params._dummy(),",
          "3300:         \"withScaling\",",
          "3301:         \"Whether to scale the data to \" \"quantile range\",",
          "3302:         typeConverter=TypeConverters.toBoolean,",
          "3303:     )",
          "3306:         super(_RobustScalerParams, self).__init__(*args)",
          "3307:         self._setDefault(",
          "3308:             lower=0.25, upper=0.75, withCentering=False, withScaling=True, relativeError=0.001",
          "3309:         )",
          "3311:     @since(\"3.0.0\")",
          "3313:         \"\"\"",
          "3314:         Gets the value of lower or its default value.",
          "3315:         \"\"\"",
          "3316:         return self.getOrDefault(self.lower)",
          "3318:     @since(\"3.0.0\")",
          "3320:         \"\"\"",
          "3321:         Gets the value of upper or its default value.",
          "3322:         \"\"\"",
          "3323:         return self.getOrDefault(self.upper)",
          "3325:     @since(\"3.0.0\")",
          "3327:         \"\"\"",
          "3328:         Gets the value of withCentering or its default value.",
          "3329:         \"\"\"",
          "3330:         return self.getOrDefault(self.withCentering)",
          "3332:     @since(\"3.0.0\")",
          "3334:         \"\"\"",
          "3335:         Gets the value of withScaling or its default value.",
          "3336:         \"\"\"",
          "",
          "[Removed Lines]",
          "3280:     lower = Param(",
          "3286:     upper = Param(",
          "3292:     withCentering = Param(",
          "3298:     withScaling = Param(",
          "3305:     def __init__(self, *args):",
          "3312:     def getLower(self):",
          "3319:     def getUpper(self):",
          "3326:     def getWithCentering(self):",
          "3333:     def getWithScaling(self):",
          "",
          "[Added Lines]",
          "3774:     lower: Param[float] = Param(",
          "3780:     upper: Param[float] = Param(",
          "3786:     withCentering: Param[bool] = Param(",
          "3792:     withScaling: Param[bool] = Param(",
          "3799:     def __init__(self, *args: Any):",
          "3806:     def getLower(self) -> float:",
          "3813:     def getUpper(self) -> float:",
          "3820:     def getWithCentering(self) -> bool:",
          "3827:     def getWithScaling(self) -> bool:",
          "",
          "---------------",
          "--- Hunk 114 ---",
          "[Context before]",
          "3340: @inherit_doc",
          "3342:     \"\"\"",
          "3343:     RobustScaler removes the median and scales the data according to the quantile range.",
          "3344:     The quantile range is by default IQR (Interquartile Range, quantile range between the",
          "",
          "[Removed Lines]",
          "3341: class RobustScaler(JavaEstimator, _RobustScalerParams, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "3835: class RobustScaler(",
          "3836:     JavaEstimator, _RobustScalerParams, JavaMLReadable[\"RobustScaler\"], JavaMLWritable",
          "3837: ):",
          "",
          "---------------",
          "--- Hunk 115 ---",
          "[Context before]",
          "3391:     True",
          "3392:     \"\"\"",
          "3394:     @keyword_only",
          "3395:     def __init__(",
          "3396:         self,",
          "3405:     ):",
          "3406:         \"\"\"",
          "3407:         __init__(self, \\\\*, lower=0.25, upper=0.75, withCentering=False, withScaling=True, \\",
          "",
          "[Removed Lines]",
          "3398:         lower=0.25,",
          "3399:         upper=0.75,",
          "3400:         withCentering=False,",
          "3401:         withScaling=True,",
          "3402:         inputCol=None,",
          "3403:         outputCol=None,",
          "3404:         relativeError=0.001,",
          "",
          "[Added Lines]",
          "3890:     _input_kwargs: Dict[str, Any]",
          "3896:         lower: float = 0.25,",
          "3897:         upper: float = 0.75,",
          "3898:         withCentering: bool = False,",
          "3899:         withScaling: bool = True,",
          "3900:         inputCol: Optional[str] = None,",
          "3901:         outputCol: Optional[str] = None,",
          "3902:         relativeError: float = 0.001,",
          "",
          "---------------",
          "--- Hunk 116 ---",
          "[Context before]",
          "3417:     def setParams(",
          "3418:         self,",
          "3428:         \"\"\"",
          "3429:         setParams(self, \\\\*, lower=0.25, upper=0.75, withCentering=False, withScaling=True, \\",
          "3430:                   inputCol=None, outputCol=None, relativeError=0.001)",
          "",
          "[Removed Lines]",
          "3420:         lower=0.25,",
          "3421:         upper=0.75,",
          "3422:         withCentering=False,",
          "3423:         withScaling=True,",
          "3424:         inputCol=None,",
          "3425:         outputCol=None,",
          "3426:         relativeError=0.001,",
          "3427:     ):",
          "",
          "[Added Lines]",
          "3918:         lower: float = 0.25,",
          "3919:         upper: float = 0.75,",
          "3920:         withCentering: bool = False,",
          "3921:         withScaling: bool = True,",
          "3922:         inputCol: Optional[str] = None,",
          "3923:         outputCol: Optional[str] = None,",
          "3924:         relativeError: float = 0.001,",
          "3925:     ) -> \"RobustScaler\":",
          "",
          "---------------",
          "--- Hunk 117 ---",
          "[Context before]",
          "3434:         return self._set(**kwargs)",
          "3436:     @since(\"3.0.0\")",
          "3438:         \"\"\"",
          "3439:         Sets the value of :py:attr:`lower`.",
          "3440:         \"\"\"",
          "3441:         return self._set(lower=value)",
          "3443:     @since(\"3.0.0\")",
          "3445:         \"\"\"",
          "3446:         Sets the value of :py:attr:`upper`.",
          "3447:         \"\"\"",
          "3448:         return self._set(upper=value)",
          "3450:     @since(\"3.0.0\")",
          "3452:         \"\"\"",
          "3453:         Sets the value of :py:attr:`withCentering`.",
          "3454:         \"\"\"",
          "3455:         return self._set(withCentering=value)",
          "3457:     @since(\"3.0.0\")",
          "3459:         \"\"\"",
          "3460:         Sets the value of :py:attr:`withScaling`.",
          "3461:         \"\"\"",
          "3462:         return self._set(withScaling=value)",
          "3464:     @since(\"3.0.0\")",
          "3466:         \"\"\"",
          "3467:         Sets the value of :py:attr:`inputCol`.",
          "3468:         \"\"\"",
          "3469:         return self._set(inputCol=value)",
          "3471:     @since(\"3.0.0\")",
          "3473:         \"\"\"",
          "3474:         Sets the value of :py:attr:`outputCol`.",
          "3475:         \"\"\"",
          "3476:         return self._set(outputCol=value)",
          "3478:     @since(\"3.0.0\")",
          "3480:         \"\"\"",
          "3481:         Sets the value of :py:attr:`relativeError`.",
          "3482:         \"\"\"",
          "3483:         return self._set(relativeError=value)",
          "3486:         return RobustScalerModel(java_model)",
          "3490:     \"\"\"",
          "3491:     Model fitted by :py:class:`RobustScaler`.",
          "",
          "[Removed Lines]",
          "3437:     def setLower(self, value):",
          "3444:     def setUpper(self, value):",
          "3451:     def setWithCentering(self, value):",
          "3458:     def setWithScaling(self, value):",
          "3465:     def setInputCol(self, value):",
          "3472:     def setOutputCol(self, value):",
          "3479:     def setRelativeError(self, value):",
          "3485:     def _create_model(self, java_model):",
          "3489: class RobustScalerModel(JavaModel, _RobustScalerParams, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "3935:     def setLower(self, value: float) -> \"RobustScaler\":",
          "3942:     def setUpper(self, value: float) -> \"RobustScaler\":",
          "3949:     def setWithCentering(self, value: bool) -> \"RobustScaler\":",
          "3956:     def setWithScaling(self, value: bool) -> \"RobustScaler\":",
          "3963:     def setInputCol(self, value: str) -> \"RobustScaler\":",
          "3970:     def setOutputCol(self, value: str) -> \"RobustScaler\":",
          "3977:     def setRelativeError(self, value: float) -> \"RobustScaler\":",
          "3983:     def _create_model(self, java_model: \"JavaObject\") -> \"RobustScalerModel\":",
          "3987: class RobustScalerModel(",
          "3988:     JavaModel, _RobustScalerParams, JavaMLReadable[\"RobustScalerModel\"], JavaMLWritable",
          "3989: ):",
          "",
          "---------------",
          "--- Hunk 118 ---",
          "[Context before]",
          "3494:     \"\"\"",
          "3496:     @since(\"3.0.0\")",
          "3498:         \"\"\"",
          "3499:         Sets the value of :py:attr:`inputCol`.",
          "3500:         \"\"\"",
          "3501:         return self._set(inputCol=value)",
          "3503:     @since(\"3.0.0\")",
          "3505:         \"\"\"",
          "3506:         Sets the value of :py:attr:`outputCol`.",
          "3507:         \"\"\"",
          "3508:         return self._set(outputCol=value)",
          "3511:     @since(\"3.0.0\")",
          "3513:         \"\"\"",
          "3514:         Median of the RobustScalerModel.",
          "3515:         \"\"\"",
          "3516:         return self._call_java(\"median\")",
          "3519:     @since(\"3.0.0\")",
          "3521:         \"\"\"",
          "3522:         Quantile range of the RobustScalerModel.",
          "3523:         \"\"\"",
          "",
          "[Removed Lines]",
          "3497:     def setInputCol(self, value):",
          "3504:     def setOutputCol(self, value):",
          "3510:     @property",
          "3512:     def median(self):",
          "3518:     @property",
          "3520:     def range(self):",
          "",
          "[Added Lines]",
          "3997:     def setInputCol(self, value: str) -> \"RobustScalerModel\":",
          "4004:     def setOutputCol(self, value: str) -> \"RobustScalerModel\":",
          "4010:     @property  # type: ignore[misc]",
          "4012:     def median(self) -> Vector:",
          "4018:     @property  # type: ignore[misc]",
          "4020:     def range(self) -> Vector:",
          "",
          "---------------",
          "--- Hunk 119 ---",
          "[Context before]",
          "3527: @inherit_doc",
          "3529:     \"\"\"",
          "3530:     A regex based tokenizer that extracts tokens either by using the",
          "3531:     provided regex pattern (in Java dialect) to split the text",
          "",
          "[Removed Lines]",
          "3528: class RegexTokenizer(JavaTransformer, HasInputCol, HasOutputCol, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "4028: class RegexTokenizer(",
          "4029:     JavaTransformer,",
          "4030:     HasInputCol,",
          "4031:     HasOutputCol,",
          "4032:     JavaMLReadable[\"RegexTokenizer\"],",
          "4033:     JavaMLWritable,",
          "4034: ):",
          "",
          "---------------",
          "--- Hunk 120 ---",
          "[Context before]",
          "3570:     True",
          "3571:     \"\"\"",
          "3574:         Params._dummy(),",
          "3575:         \"minTokenLength\",",
          "3576:         \"minimum token length (>= 0)\",",
          "3577:         typeConverter=TypeConverters.toInt,",
          "3578:     )",
          "3580:         Params._dummy(),",
          "3581:         \"gaps\",",
          "3582:         \"whether regex splits on gaps (True) or matches tokens \" + \"(False)\",",
          "3583:     )",
          "3585:         Params._dummy(),",
          "3586:         \"pattern\",",
          "3587:         \"regex pattern (Java dialect) used for tokenizing\",",
          "3588:         typeConverter=TypeConverters.toString,",
          "3589:     )",
          "3591:         Params._dummy(),",
          "3592:         \"toLowercase\",",
          "3593:         \"whether to convert all characters to \" + \"lowercase before tokenizing\",",
          "3594:         typeConverter=TypeConverters.toBoolean,",
          "3595:     )",
          "3597:     @keyword_only",
          "3598:     def __init__(",
          "3599:         self,",
          "3607:     ):",
          "3608:         \"\"\"",
          "3609:         __init__(self, \\\\*, minTokenLength=1, gaps=True, pattern=\"\\\\s+\", inputCol=None, \\",
          "",
          "[Removed Lines]",
          "3573:     minTokenLength = Param(",
          "3579:     gaps = Param(",
          "3584:     pattern = Param(",
          "3590:     toLowercase = Param(",
          "3601:         minTokenLength=1,",
          "3602:         gaps=True,",
          "3603:         pattern=\"\\\\s+\",",
          "3604:         inputCol=None,",
          "3605:         outputCol=None,",
          "3606:         toLowercase=True,",
          "",
          "[Added Lines]",
          "4079:     minTokenLength: Param[int] = Param(",
          "4085:     gaps: Param[bool] = Param(",
          "4090:     pattern: Param[str] = Param(",
          "4096:     toLowercase: Param[bool] = Param(",
          "4103:     _input_kwargs: Dict[str, Any]",
          "4109:         minTokenLength: int = 1,",
          "4110:         gaps: bool = True,",
          "4111:         pattern: str = \"\\\\s+\",",
          "4112:         inputCol: Optional[str] = None,",
          "4113:         outputCol: Optional[str] = None,",
          "4114:         toLowercase: bool = True,",
          "",
          "---------------",
          "--- Hunk 121 ---",
          "[Context before]",
          "3620:     def setParams(",
          "3621:         self,",
          "3630:         \"\"\"",
          "3631:         setParams(self, \\\\*, minTokenLength=1, gaps=True, pattern=\"\\\\s+\", inputCol=None, \\",
          "3632:                   outputCol=None, toLowercase=True)",
          "",
          "[Removed Lines]",
          "3623:         minTokenLength=1,",
          "3624:         gaps=True,",
          "3625:         pattern=\"\\\\s+\",",
          "3626:         inputCol=None,",
          "3627:         outputCol=None,",
          "3628:         toLowercase=True,",
          "3629:     ):",
          "",
          "[Added Lines]",
          "4131:         minTokenLength: int = 1,",
          "4132:         gaps: bool = True,",
          "4133:         pattern: str = \"\\\\s+\",",
          "4134:         inputCol: Optional[str] = None,",
          "4135:         outputCol: Optional[str] = None,",
          "4136:         toLowercase: bool = True,",
          "4137:     ) -> \"RegexTokenizer\":",
          "",
          "---------------",
          "--- Hunk 122 ---",
          "[Context before]",
          "3636:         return self._set(**kwargs)",
          "3638:     @since(\"1.4.0\")",
          "3640:         \"\"\"",
          "3641:         Sets the value of :py:attr:`minTokenLength`.",
          "3642:         \"\"\"",
          "3643:         return self._set(minTokenLength=value)",
          "3645:     @since(\"1.4.0\")",
          "3647:         \"\"\"",
          "3648:         Gets the value of minTokenLength or its default value.",
          "3649:         \"\"\"",
          "3650:         return self.getOrDefault(self.minTokenLength)",
          "3652:     @since(\"1.4.0\")",
          "3654:         \"\"\"",
          "3655:         Sets the value of :py:attr:`gaps`.",
          "3656:         \"\"\"",
          "3657:         return self._set(gaps=value)",
          "3659:     @since(\"1.4.0\")",
          "3661:         \"\"\"",
          "3662:         Gets the value of gaps or its default value.",
          "3663:         \"\"\"",
          "3664:         return self.getOrDefault(self.gaps)",
          "3666:     @since(\"1.4.0\")",
          "3668:         \"\"\"",
          "3669:         Sets the value of :py:attr:`pattern`.",
          "3670:         \"\"\"",
          "3671:         return self._set(pattern=value)",
          "3673:     @since(\"1.4.0\")",
          "3675:         \"\"\"",
          "3676:         Gets the value of pattern or its default value.",
          "3677:         \"\"\"",
          "3678:         return self.getOrDefault(self.pattern)",
          "3680:     @since(\"2.0.0\")",
          "3682:         \"\"\"",
          "3683:         Sets the value of :py:attr:`toLowercase`.",
          "3684:         \"\"\"",
          "3685:         return self._set(toLowercase=value)",
          "3687:     @since(\"2.0.0\")",
          "3689:         \"\"\"",
          "3690:         Gets the value of toLowercase or its default value.",
          "3691:         \"\"\"",
          "3692:         return self.getOrDefault(self.toLowercase)",
          "3695:         \"\"\"",
          "3696:         Sets the value of :py:attr:`inputCol`.",
          "3697:         \"\"\"",
          "3698:         return self._set(inputCol=value)",
          "3701:         \"\"\"",
          "3702:         Sets the value of :py:attr:`outputCol`.",
          "3703:         \"\"\"",
          "",
          "[Removed Lines]",
          "3639:     def setMinTokenLength(self, value):",
          "3646:     def getMinTokenLength(self):",
          "3653:     def setGaps(self, value):",
          "3660:     def getGaps(self):",
          "3667:     def setPattern(self, value):",
          "3674:     def getPattern(self):",
          "3681:     def setToLowercase(self, value):",
          "3688:     def getToLowercase(self):",
          "3694:     def setInputCol(self, value):",
          "3700:     def setOutputCol(self, value):",
          "",
          "[Added Lines]",
          "4147:     def setMinTokenLength(self, value: int) -> \"RegexTokenizer\":",
          "4154:     def getMinTokenLength(self) -> int:",
          "4161:     def setGaps(self, value: bool) -> \"RegexTokenizer\":",
          "4168:     def getGaps(self) -> bool:",
          "4175:     def setPattern(self, value: str) -> \"RegexTokenizer\":",
          "4182:     def getPattern(self) -> str:",
          "4189:     def setToLowercase(self, value: bool) -> \"RegexTokenizer\":",
          "4196:     def getToLowercase(self) -> bool:",
          "4202:     def setInputCol(self, value: str) -> \"RegexTokenizer\":",
          "4208:     def setOutputCol(self, value: str) -> \"RegexTokenizer\":",
          "",
          "---------------",
          "--- Hunk 123 ---",
          "[Context before]",
          "3707: @inherit_doc",
          "3709:     \"\"\"",
          "3710:     Implements the transforms which are defined by SQL statement.",
          "3711:     Currently we only support SQL syntax like `SELECT ... FROM __THIS__`",
          "",
          "[Removed Lines]",
          "3708: class SQLTransformer(JavaTransformer, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "4216: class SQLTransformer(JavaTransformer, JavaMLReadable[\"SQLTransformer\"], JavaMLWritable):",
          "",
          "---------------",
          "--- Hunk 124 ---",
          "[Context before]",
          "3733:         Params._dummy(), \"statement\", \"SQL statement\", typeConverter=TypeConverters.toString",
          "3734:     )",
          "3736:     @keyword_only",
          "3738:         \"\"\"",
          "3739:         __init__(self, \\\\*, statement=None)",
          "3740:         \"\"\"",
          "",
          "[Removed Lines]",
          "3737:     def __init__(self, *, statement=None):",
          "",
          "[Added Lines]",
          "4244:     _input_kwargs: Dict[str, Any]",
          "4247:     def __init__(self, *, statement: Optional[str] = None):",
          "",
          "---------------",
          "--- Hunk 125 ---",
          "[Context before]",
          "3746:     @keyword_only",
          "3747:     @since(\"1.6.0\")",
          "3749:         \"\"\"",
          "3750:         setParams(self, \\\\*, statement=None)",
          "3751:         Sets params for this SQLTransformer.",
          "",
          "[Removed Lines]",
          "3748:     def setParams(self, *, statement=None):",
          "",
          "[Added Lines]",
          "4258:     def setParams(self, *, statement: Optional[str] = None) -> \"SQLTransformer\":",
          "",
          "---------------",
          "--- Hunk 126 ---",
          "[Context before]",
          "3754:         return self._set(**kwargs)",
          "3756:     @since(\"1.6.0\")",
          "3758:         \"\"\"",
          "3759:         Sets the value of :py:attr:`statement`.",
          "3760:         \"\"\"",
          "3761:         return self._set(statement=value)",
          "3763:     @since(\"1.6.0\")",
          "3765:         \"\"\"",
          "3766:         Gets the value of statement or its default value.",
          "3767:         \"\"\"",
          "",
          "[Removed Lines]",
          "3757:     def setStatement(self, value):",
          "3764:     def getStatement(self):",
          "",
          "[Added Lines]",
          "4267:     def setStatement(self, value: str) -> \"SQLTransformer\":",
          "4274:     def getStatement(self) -> str:",
          "",
          "---------------",
          "--- Hunk 127 ---",
          "[Context before]",
          "3775:     .. versionadded:: 3.0.0",
          "3776:     \"\"\"",
          "3779:         Params._dummy(), \"withMean\", \"Center data with mean\", typeConverter=TypeConverters.toBoolean",
          "3780:     )",
          "3782:         Params._dummy(),",
          "3783:         \"withStd\",",
          "3784:         \"Scale to unit standard deviation\",",
          "3785:         typeConverter=TypeConverters.toBoolean,",
          "3786:     )",
          "3789:         super(_StandardScalerParams, self).__init__(*args)",
          "3790:         self._setDefault(withMean=False, withStd=True)",
          "3792:     @since(\"1.4.0\")",
          "3794:         \"\"\"",
          "3795:         Gets the value of withMean or its default value.",
          "3796:         \"\"\"",
          "3797:         return self.getOrDefault(self.withMean)",
          "3799:     @since(\"1.4.0\")",
          "3801:         \"\"\"",
          "3802:         Gets the value of withStd or its default value.",
          "3803:         \"\"\"",
          "",
          "[Removed Lines]",
          "3778:     withMean = Param(",
          "3781:     withStd = Param(",
          "3788:     def __init__(self, *args):",
          "3793:     def getWithMean(self):",
          "3800:     def getWithStd(self):",
          "",
          "[Added Lines]",
          "4288:     withMean: Param[bool] = Param(",
          "4291:     withStd: Param[bool] = Param(",
          "4298:     def __init__(self, *args: Any):",
          "4303:     def getWithMean(self) -> bool:",
          "4310:     def getWithStd(self) -> bool:",
          "",
          "---------------",
          "--- Hunk 128 ---",
          "[Context before]",
          "3807: @inherit_doc",
          "3809:     \"\"\"",
          "3810:     Standardizes features by removing the mean and scaling to unit variance using column summary",
          "3811:     statistics on the samples in the training set.",
          "",
          "[Removed Lines]",
          "3808: class StandardScaler(JavaEstimator, _StandardScalerParams, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "4318: class StandardScaler(",
          "4319:     JavaEstimator[\"StandardScalerModel\"],",
          "4320:     _StandardScalerParams,",
          "4321:     JavaMLReadable[\"StandardScaler\"],",
          "4322:     JavaMLWritable,",
          "4323: ):",
          "",
          "---------------",
          "--- Hunk 129 ---",
          "[Context before]",
          "3854:     True",
          "3855:     \"\"\"",
          "3857:     @keyword_only",
          "3859:         \"\"\"",
          "3860:         __init__(self, \\\\*, withMean=False, withStd=True, inputCol=None, outputCol=None)",
          "3861:         \"\"\"",
          "",
          "[Removed Lines]",
          "3858:     def __init__(self, *, withMean=False, withStd=True, inputCol=None, outputCol=None):",
          "",
          "[Added Lines]",
          "4372:     _input_kwargs: Dict[str, Any]",
          "4375:     def __init__(",
          "4376:         self,",
          "4378:         withMean: bool = False,",
          "4379:         withStd: bool = True,",
          "4380:         inputCol: Optional[str] = None,",
          "4381:         outputCol: Optional[str] = None,",
          "4382:     ):",
          "",
          "---------------",
          "--- Hunk 130 ---",
          "[Context before]",
          "3867:     @keyword_only",
          "3868:     @since(\"1.4.0\")",
          "3870:         \"\"\"",
          "3871:         setParams(self, \\\\*, withMean=False, withStd=True, inputCol=None, outputCol=None)",
          "3872:         Sets params for this StandardScaler.",
          "",
          "[Removed Lines]",
          "3869:     def setParams(self, *, withMean=False, withStd=True, inputCol=None, outputCol=None):",
          "",
          "[Added Lines]",
          "4393:     def setParams(",
          "4394:         self,",
          "4396:         withMean: bool = False,",
          "4397:         withStd: bool = True,",
          "4398:         inputCol: Optional[str] = None,",
          "4399:         outputCol: Optional[str] = None,",
          "4400:     ) -> \"StandardScaler\":",
          "",
          "---------------",
          "--- Hunk 131 ---",
          "[Context before]",
          "3875:         return self._set(**kwargs)",
          "3877:     @since(\"1.4.0\")",
          "3879:         \"\"\"",
          "3880:         Sets the value of :py:attr:`withMean`.",
          "3881:         \"\"\"",
          "3882:         return self._set(withMean=value)",
          "3884:     @since(\"1.4.0\")",
          "3886:         \"\"\"",
          "3887:         Sets the value of :py:attr:`withStd`.",
          "3888:         \"\"\"",
          "3889:         return self._set(withStd=value)",
          "3892:         \"\"\"",
          "3893:         Sets the value of :py:attr:`inputCol`.",
          "3894:         \"\"\"",
          "3895:         return self._set(inputCol=value)",
          "3898:         \"\"\"",
          "3899:         Sets the value of :py:attr:`outputCol`.",
          "3900:         \"\"\"",
          "3901:         return self._set(outputCol=value)",
          "3904:         return StandardScalerModel(java_model)",
          "3908:     \"\"\"",
          "3909:     Model fitted by :py:class:`StandardScaler`.",
          "3911:     .. versionadded:: 1.4.0",
          "3912:     \"\"\"",
          "3915:         \"\"\"",
          "3916:         Sets the value of :py:attr:`inputCol`.",
          "3917:         \"\"\"",
          "3918:         return self._set(inputCol=value)",
          "3921:         \"\"\"",
          "3922:         Sets the value of :py:attr:`outputCol`.",
          "3923:         \"\"\"",
          "3924:         return self._set(outputCol=value)",
          "3927:     @since(\"2.0.0\")",
          "3929:         \"\"\"",
          "3930:         Standard deviation of the StandardScalerModel.",
          "3931:         \"\"\"",
          "3932:         return self._call_java(\"std\")",
          "3935:     @since(\"2.0.0\")",
          "3937:         \"\"\"",
          "3938:         Mean of the StandardScalerModel.",
          "3939:         \"\"\"",
          "",
          "[Removed Lines]",
          "3878:     def setWithMean(self, value):",
          "3885:     def setWithStd(self, value):",
          "3891:     def setInputCol(self, value):",
          "3897:     def setOutputCol(self, value):",
          "3903:     def _create_model(self, java_model):",
          "3907: class StandardScalerModel(JavaModel, _StandardScalerParams, JavaMLReadable, JavaMLWritable):",
          "3914:     def setInputCol(self, value):",
          "3920:     def setOutputCol(self, value):",
          "3926:     @property",
          "3928:     def std(self):",
          "3934:     @property",
          "3936:     def mean(self):",
          "",
          "[Added Lines]",
          "4409:     def setWithMean(self, value: bool) -> \"StandardScaler\":",
          "4416:     def setWithStd(self, value: bool) -> \"StandardScaler\":",
          "4422:     def setInputCol(self, value: str) -> \"StandardScaler\":",
          "4428:     def setOutputCol(self, value: str) -> \"StandardScaler\":",
          "4434:     def _create_model(self, java_model: \"JavaObject\") -> \"StandardScalerModel\":",
          "4438: class StandardScalerModel(",
          "4439:     JavaModel,",
          "4440:     _StandardScalerParams,",
          "4441:     JavaMLReadable[\"StandardScalerModel\"],",
          "4442:     JavaMLWritable,",
          "4443: ):",
          "4450:     def setInputCol(self, value: str) -> \"StandardScalerModel\":",
          "4456:     def setOutputCol(self, value: str) -> \"StandardScalerModel\":",
          "4462:     @property  # type: ignore[misc]",
          "4464:     def std(self) -> Vector:",
          "4470:     @property  # type: ignore[misc]",
          "4472:     def mean(self) -> Vector:",
          "",
          "---------------",
          "--- Hunk 132 ---",
          "[Context before]",
          "3947:     Params for :py:class:`StringIndexer` and :py:class:`StringIndexerModel`.",
          "3948:     \"\"\"",
          "3951:         Params._dummy(),",
          "3952:         \"stringOrderType\",",
          "3953:         \"How to order labels of string column. The first label after \"",
          "",
          "[Removed Lines]",
          "3950:     stringOrderType = Param(",
          "",
          "[Added Lines]",
          "4486:     stringOrderType: Param[str] = Param(",
          "",
          "---------------",
          "--- Hunk 133 ---",
          "[Context before]",
          "3959:         typeConverter=TypeConverters.toString,",
          "3960:     )",
          "3963:         Params._dummy(),",
          "3964:         \"handleInvalid\",",
          "3965:         \"how to handle invalid data (unseen \"",
          "",
          "[Removed Lines]",
          "3962:     handleInvalid = Param(",
          "",
          "[Added Lines]",
          "4498:     handleInvalid: Param[str] = Param(",
          "",
          "---------------",
          "--- Hunk 134 ---",
          "[Context before]",
          "3970:         typeConverter=TypeConverters.toString,",
          "3971:     )",
          "3974:         super(_StringIndexerParams, self).__init__(*args)",
          "3975:         self._setDefault(handleInvalid=\"error\", stringOrderType=\"frequencyDesc\")",
          "3977:     @since(\"2.3.0\")",
          "3979:         \"\"\"",
          "3980:         Gets the value of :py:attr:`stringOrderType` or its default value 'frequencyDesc'.",
          "3981:         \"\"\"",
          "",
          "[Removed Lines]",
          "3973:     def __init__(self, *args):",
          "3978:     def getStringOrderType(self):",
          "",
          "[Added Lines]",
          "4509:     def __init__(self, *args: Any):",
          "4514:     def getStringOrderType(self) -> str:",
          "",
          "---------------",
          "--- Hunk 135 ---",
          "[Context before]",
          "3985: @inherit_doc",
          "3987:     \"\"\"",
          "3988:     A label indexer that maps a string column of labels to an ML column of label indices.",
          "3989:     If the input column is numeric, we cast it to string and index the string values.",
          "",
          "[Removed Lines]",
          "3986: class StringIndexer(JavaEstimator, _StringIndexerParams, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "4522: class StringIndexer(",
          "4523:     JavaEstimator[\"StringIndexerModel\"],",
          "4524:     _StringIndexerParams,",
          "4525:     JavaMLReadable[\"StringIndexer\"],",
          "4526:     JavaMLWritable,",
          "4527: ):",
          "",
          "---------------",
          "--- Hunk 136 ---",
          "[Context before]",
          "4066:     [(0, 0.0, 0.0), (1, 1.0, 1.0), (2, 2.0, 0.0), (3, 0.0, 1.0), (4, 0.0, 1.0), (5, 2.0, 1.0)]",
          "4067:     \"\"\"",
          "4069:     @keyword_only",
          "4070:     def __init__(",
          "4071:         self,",
          "4079:     ):",
          "4080:         \"\"\"",
          "4081:         __init__(self, \\\\*, inputCol=None, outputCol=None, inputCols=None, outputCols=None, \\",
          "",
          "[Removed Lines]",
          "4073:         inputCol=None,",
          "4074:         outputCol=None,",
          "4075:         inputCols=None,",
          "4076:         outputCols=None,",
          "4077:         handleInvalid=\"error\",",
          "4078:         stringOrderType=\"frequencyDesc\",",
          "",
          "[Added Lines]",
          "4610:     _input_kwargs: Dict[str, Any]",
          "4612:     @overload",
          "4613:     def __init__(",
          "4614:         self,",
          "4616:         inputCol: Optional[str] = ...,",
          "4617:         outputCol: Optional[str] = ...,",
          "4618:         handleInvalid: str = ...,",
          "4619:         stringOrderType: str = ...,",
          "4620:     ):",
          "4621:         ...",
          "4623:     @overload",
          "4624:     def __init__(",
          "4625:         self,",
          "4627:         inputCols: Optional[List[str]] = ...,",
          "4628:         outputCols: Optional[List[str]] = ...,",
          "4629:         handleInvalid: str = ...,",
          "4630:         stringOrderType: str = ...,",
          "4631:     ):",
          "4632:         ...",
          "4638:         inputCol: Optional[str] = None,",
          "4639:         outputCol: Optional[str] = None,",
          "4640:         inputCols: Optional[List[str]] = None,",
          "4641:         outputCols: Optional[List[str]] = None,",
          "4642:         handleInvalid: str = \"error\",",
          "4643:         stringOrderType: str = \"frequencyDesc\",",
          "",
          "---------------",
          "--- Hunk 137 ---",
          "[Context before]",
          "4086:         kwargs = self._input_kwargs",
          "4087:         self.setParams(**kwargs)",
          "4089:     @keyword_only",
          "4090:     @since(\"1.4.0\")",
          "4091:     def setParams(",
          "4092:         self,",
          "4101:         \"\"\"",
          "4102:         setParams(self, \\\\*, inputCol=None, outputCol=None, inputCols=None, outputCols=None, \\",
          "4103:                   handleInvalid=\"error\", stringOrderType=\"frequencyDesc\")",
          "",
          "[Removed Lines]",
          "4094:         inputCol=None,",
          "4095:         outputCol=None,",
          "4096:         inputCols=None,",
          "4097:         outputCols=None,",
          "4098:         handleInvalid=\"error\",",
          "4099:         stringOrderType=\"frequencyDesc\",",
          "4100:     ):",
          "",
          "[Added Lines]",
          "4654:     @overload",
          "4655:     def setParams(",
          "4656:         self,",
          "4658:         inputCol: Optional[str] = ...,",
          "4659:         outputCol: Optional[str] = ...,",
          "4660:         handleInvalid: str = ...,",
          "4661:         stringOrderType: str = ...,",
          "4662:     ) -> \"StringIndexer\":",
          "4663:         ...",
          "4665:     @overload",
          "4666:     def setParams(",
          "4667:         self,",
          "4669:         inputCols: Optional[List[str]] = ...,",
          "4670:         outputCols: Optional[List[str]] = ...,",
          "4671:         handleInvalid: str = ...,",
          "4672:         stringOrderType: str = ...,",
          "4673:     ) -> \"StringIndexer\":",
          "4674:         ...",
          "4681:         inputCol: Optional[str] = None,",
          "4682:         outputCol: Optional[str] = None,",
          "4683:         inputCols: Optional[List[str]] = None,",
          "4684:         outputCols: Optional[List[str]] = None,",
          "4685:         handleInvalid: str = \"error\",",
          "4686:         stringOrderType: str = \"frequencyDesc\",",
          "4687:     ) -> \"StringIndexer\":",
          "",
          "---------------",
          "--- Hunk 138 ---",
          "[Context before]",
          "4106:         kwargs = self._input_kwargs",
          "4107:         return self._set(**kwargs)",
          "4110:         return StringIndexerModel(java_model)",
          "4112:     @since(\"2.3.0\")",
          "4114:         \"\"\"",
          "4115:         Sets the value of :py:attr:`stringOrderType`.",
          "4116:         \"\"\"",
          "4117:         return self._set(stringOrderType=value)",
          "4120:         \"\"\"",
          "4121:         Sets the value of :py:attr:`inputCol`.",
          "4122:         \"\"\"",
          "4123:         return self._set(inputCol=value)",
          "4125:     @since(\"3.0.0\")",
          "4127:         \"\"\"",
          "4128:         Sets the value of :py:attr:`inputCols`.",
          "4129:         \"\"\"",
          "4130:         return self._set(inputCols=value)",
          "4133:         \"\"\"",
          "4134:         Sets the value of :py:attr:`outputCol`.",
          "4135:         \"\"\"",
          "4136:         return self._set(outputCol=value)",
          "4138:     @since(\"3.0.0\")",
          "4140:         \"\"\"",
          "4141:         Sets the value of :py:attr:`outputCols`.",
          "4142:         \"\"\"",
          "4143:         return self._set(outputCols=value)",
          "4146:         \"\"\"",
          "4147:         Sets the value of :py:attr:`handleInvalid`.",
          "4148:         \"\"\"",
          "4149:         return self._set(handleInvalid=value)",
          "4153:     \"\"\"",
          "4154:     Model fitted by :py:class:`StringIndexer`.",
          "4156:     .. versionadded:: 1.4.0",
          "4157:     \"\"\"",
          "4160:         \"\"\"",
          "4161:         Sets the value of :py:attr:`inputCol`.",
          "4162:         \"\"\"",
          "4163:         return self._set(inputCol=value)",
          "4165:     @since(\"3.0.0\")",
          "4167:         \"\"\"",
          "4168:         Sets the value of :py:attr:`inputCols`.",
          "4169:         \"\"\"",
          "4170:         return self._set(inputCols=value)",
          "4173:         \"\"\"",
          "4174:         Sets the value of :py:attr:`outputCol`.",
          "4175:         \"\"\"",
          "4176:         return self._set(outputCol=value)",
          "4178:     @since(\"3.0.0\")",
          "4180:         \"\"\"",
          "4181:         Sets the value of :py:attr:`outputCols`.",
          "4182:         \"\"\"",
          "4183:         return self._set(outputCols=value)",
          "4185:     @since(\"2.4.0\")",
          "4187:         \"\"\"",
          "4188:         Sets the value of :py:attr:`handleInvalid`.",
          "4189:         \"\"\"",
          "",
          "[Removed Lines]",
          "4109:     def _create_model(self, java_model):",
          "4113:     def setStringOrderType(self, value):",
          "4119:     def setInputCol(self, value):",
          "4126:     def setInputCols(self, value):",
          "4132:     def setOutputCol(self, value):",
          "4139:     def setOutputCols(self, value):",
          "4145:     def setHandleInvalid(self, value):",
          "4152: class StringIndexerModel(JavaModel, _StringIndexerParams, JavaMLReadable, JavaMLWritable):",
          "4159:     def setInputCol(self, value):",
          "4166:     def setInputCols(self, value):",
          "4172:     def setOutputCol(self, value):",
          "4179:     def setOutputCols(self, value):",
          "4186:     def setHandleInvalid(self, value):",
          "",
          "[Added Lines]",
          "4696:     def _create_model(self, java_model: \"JavaObject\") -> \"StringIndexerModel\":",
          "4700:     def setStringOrderType(self, value: str) -> \"StringIndexer\":",
          "4706:     def setInputCol(self, value: str) -> \"StringIndexer\":",
          "4713:     def setInputCols(self, value: List[str]) -> \"StringIndexer\":",
          "4719:     def setOutputCol(self, value: str) -> \"StringIndexer\":",
          "4726:     def setOutputCols(self, value: List[str]) -> \"StringIndexer\":",
          "4732:     def setHandleInvalid(self, value: str) -> \"StringIndexer\":",
          "4739: class StringIndexerModel(",
          "4740:     JavaModel, _StringIndexerParams, JavaMLReadable[\"StringIndexerModel\"], JavaMLWritable",
          "4741: ):",
          "4748:     def setInputCol(self, value: str) -> \"StringIndexerModel\":",
          "4755:     def setInputCols(self, value: List[str]) -> \"StringIndexerModel\":",
          "4761:     def setOutputCol(self, value: str) -> \"StringIndexerModel\":",
          "4768:     def setOutputCols(self, value: List[str]) -> \"StringIndexerModel\":",
          "4775:     def setHandleInvalid(self, value: str) -> \"StringIndexerModel\":",
          "",
          "---------------",
          "--- Hunk 139 ---",
          "[Context before]",
          "4192:     @classmethod",
          "4193:     @since(\"2.4.0\")",
          "4195:         \"\"\"",
          "4196:         Construct the model directly from an array of label strings,",
          "4197:         requires an active SparkContext.",
          "4198:         \"\"\"",
          "4199:         sc = SparkContext._active_spark_context",
          "4200:         java_class = sc._gateway.jvm.java.lang.String",
          "4201:         jlabels = StringIndexerModel._new_java_array(labels, java_class)",
          "4202:         model = StringIndexerModel._create_from_java_class(",
          "",
          "[Removed Lines]",
          "4194:     def from_labels(cls, labels, inputCol, outputCol=None, handleInvalid=None):",
          "",
          "[Added Lines]",
          "4783:     def from_labels(",
          "4784:         cls,",
          "4785:         labels: List[str],",
          "4786:         inputCol: str,",
          "4787:         outputCol: Optional[str] = None,",
          "4788:         handleInvalid: Optional[str] = None,",
          "4789:     ) -> \"StringIndexerModel\":",
          "4795:         assert sc is not None and sc._gateway is not None",
          "",
          "---------------",
          "--- Hunk 140 ---",
          "[Context before]",
          "4212:     @classmethod",
          "4213:     @since(\"3.0.0\")",
          "4215:         \"\"\"",
          "4216:         Construct the model directly from an array of array of label strings,",
          "4217:         requires an active SparkContext.",
          "4218:         \"\"\"",
          "4219:         sc = SparkContext._active_spark_context",
          "4220:         java_class = sc._gateway.jvm.java.lang.String",
          "4221:         jlabels = StringIndexerModel._new_java_array(arrayOfLabels, java_class)",
          "4222:         model = StringIndexerModel._create_from_java_class(",
          "",
          "[Removed Lines]",
          "4214:     def from_arrays_of_labels(cls, arrayOfLabels, inputCols, outputCols=None, handleInvalid=None):",
          "",
          "[Added Lines]",
          "4810:     def from_arrays_of_labels(",
          "4811:         cls,",
          "4812:         arrayOfLabels: List[List[str]],",
          "4813:         inputCols: List[str],",
          "4814:         outputCols: Optional[List[str]] = None,",
          "4815:         handleInvalid: Optional[str] = None,",
          "4816:     ) -> \"StringIndexerModel\":",
          "4822:         assert sc is not None and sc._gateway is not None",
          "",
          "---------------",
          "--- Hunk 141 ---",
          "[Context before]",
          "4229:             model.setHandleInvalid(handleInvalid)",
          "4230:         return model",
          "4233:     @since(\"1.5.0\")",
          "4235:         \"\"\"",
          "4236:         Ordered list of labels, corresponding to indices to be assigned.",
          "",
          "[Removed Lines]",
          "4232:     @property",
          "4234:     def labels(self):",
          "",
          "[Added Lines]",
          "4835:     @property  # type: ignore[misc]",
          "4837:     def labels(self) -> List[str]:",
          "",
          "---------------",
          "--- Hunk 142 ---",
          "[Context before]",
          "4240:         \"\"\"",
          "4241:         return self._call_java(\"labels\")",
          "4244:     @since(\"3.0.2\")",
          "4246:         \"\"\"",
          "4247:         Array of ordered list of labels, corresponding to indices to be assigned",
          "4248:         for each input column.",
          "",
          "[Removed Lines]",
          "4243:     @property",
          "4245:     def labelsArray(self):",
          "",
          "[Added Lines]",
          "4846:     @property  # type: ignore[misc]",
          "4848:     def labelsArray(self) -> List[str]:",
          "",
          "---------------",
          "--- Hunk 143 ---",
          "[Context before]",
          "4253: @inherit_doc",
          "4255:     \"\"\"",
          "4256:     A :py:class:`pyspark.ml.base.Transformer` that maps a column of indices back to a new column of",
          "4257:     corresponding string values.",
          "",
          "[Removed Lines]",
          "4254: class IndexToString(JavaTransformer, HasInputCol, HasOutputCol, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "4857: class IndexToString(",
          "4858:     JavaTransformer,",
          "4859:     HasInputCol,",
          "4860:     HasOutputCol,",
          "4861:     JavaMLReadable[\"IndexToString\"],",
          "4862:     JavaMLWritable,",
          "4863: ):",
          "",
          "---------------",
          "--- Hunk 144 ---",
          "[Context before]",
          "4265:     StringIndexer : for converting categorical values into category indices",
          "4266:     \"\"\"",
          "4269:         Params._dummy(),",
          "4270:         \"labels\",",
          "4271:         \"Optional array of labels specifying index-string mapping.\"",
          "",
          "[Removed Lines]",
          "4268:     labels = Param(",
          "",
          "[Added Lines]",
          "4877:     labels: Param[List[str]] = Param(",
          "",
          "---------------",
          "--- Hunk 145 ---",
          "[Context before]",
          "4273:         typeConverter=TypeConverters.toListString,",
          "4274:     )",
          "4276:     @keyword_only",
          "4278:         \"\"\"",
          "4279:         __init__(self, \\\\*, inputCol=None, outputCol=None, labels=None)",
          "4280:         \"\"\"",
          "",
          "[Removed Lines]",
          "4277:     def __init__(self, *, inputCol=None, outputCol=None, labels=None):",
          "",
          "[Added Lines]",
          "4885:     _input_kwargs: Dict[str, Any]",
          "4888:     def __init__(",
          "4889:         self,",
          "4891:         inputCol: Optional[str] = None,",
          "4892:         outputCol: Optional[str] = None,",
          "4893:         labels: Optional[List[str]] = None,",
          "4894:     ):",
          "",
          "---------------",
          "--- Hunk 146 ---",
          "[Context before]",
          "4286:     @keyword_only",
          "4287:     @since(\"1.6.0\")",
          "4289:         \"\"\"",
          "4290:         setParams(self, \\\\*, inputCol=None, outputCol=None, labels=None)",
          "4291:         Sets params for this IndexToString.",
          "",
          "[Removed Lines]",
          "4288:     def setParams(self, *, inputCol=None, outputCol=None, labels=None):",
          "",
          "[Added Lines]",
          "4905:     def setParams(",
          "4906:         self,",
          "4908:         inputCol: Optional[str] = None,",
          "4909:         outputCol: Optional[str] = None,",
          "4910:         labels: Optional[List[str]] = None,",
          "4911:     ) -> \"IndexToString\":",
          "",
          "---------------",
          "--- Hunk 147 ---",
          "[Context before]",
          "4294:         return self._set(**kwargs)",
          "4296:     @since(\"1.6.0\")",
          "4298:         \"\"\"",
          "4299:         Sets the value of :py:attr:`labels`.",
          "4300:         \"\"\"",
          "4301:         return self._set(labels=value)",
          "4303:     @since(\"1.6.0\")",
          "4305:         \"\"\"",
          "4306:         Gets the value of :py:attr:`labels` or its default value.",
          "4307:         \"\"\"",
          "4308:         return self.getOrDefault(self.labels)",
          "4311:         \"\"\"",
          "4312:         Sets the value of :py:attr:`inputCol`.",
          "4313:         \"\"\"",
          "4314:         return self._set(inputCol=value)",
          "4317:         \"\"\"",
          "4318:         Sets the value of :py:attr:`outputCol`.",
          "4319:         \"\"\"",
          "",
          "[Removed Lines]",
          "4297:     def setLabels(self, value):",
          "4304:     def getLabels(self):",
          "4310:     def setInputCol(self, value):",
          "4316:     def setOutputCol(self, value):",
          "",
          "[Added Lines]",
          "4920:     def setLabels(self, value: List[str]) -> \"IndexToString\":",
          "4927:     def getLabels(self) -> List[str]:",
          "4933:     def setInputCol(self, value: str) -> \"IndexToString\":",
          "4939:     def setOutputCol(self, value: str) -> \"IndexToString\":",
          "",
          "---------------",
          "--- Hunk 148 ---",
          "[Context before]",
          "4326:     HasOutputCol,",
          "4327:     HasInputCols,",
          "4328:     HasOutputCols,",
          "4330:     JavaMLWritable,",
          "4331: ):",
          "4332:     \"\"\"",
          "",
          "[Removed Lines]",
          "4329:     JavaMLReadable,",
          "",
          "[Added Lines]",
          "4952:     JavaMLReadable[\"StopWordsRemover\"],",
          "",
          "---------------",
          "--- Hunk 149 ---",
          "[Context before]",
          "4373:     ...",
          "4374:     \"\"\"",
          "4377:         Params._dummy(),",
          "4378:         \"stopWords\",",
          "4379:         \"The words to be filtered out\",",
          "4380:         typeConverter=TypeConverters.toListString,",
          "4381:     )",
          "4383:         Params._dummy(),",
          "4384:         \"caseSensitive\",",
          "4385:         \"whether to do a case sensitive \" + \"comparison over the stop words\",",
          "4386:         typeConverter=TypeConverters.toBoolean,",
          "4387:     )",
          "4389:         Params._dummy(),",
          "4390:         \"locale\",",
          "4391:         \"locale of the input. ignored when case sensitive \" + \"is true\",",
          "4392:         typeConverter=TypeConverters.toString,",
          "4393:     )",
          "4395:     @keyword_only",
          "4396:     def __init__(",
          "4397:         self,",
          "4406:     ):",
          "4407:         \"\"\"",
          "4408:         __init__(self, \\\\*, inputCol=None, outputCol=None, stopWords=None, caseSensitive=false, \\",
          "",
          "[Removed Lines]",
          "4376:     stopWords = Param(",
          "4382:     caseSensitive = Param(",
          "4388:     locale = Param(",
          "4399:         inputCol=None,",
          "4400:         outputCol=None,",
          "4401:         stopWords=None,",
          "4402:         caseSensitive=False,",
          "4403:         locale=None,",
          "4404:         inputCols=None,",
          "4405:         outputCols=None,",
          "",
          "[Added Lines]",
          "4999:     stopWords: Param[List[str]] = Param(",
          "5005:     caseSensitive: Param[bool] = Param(",
          "5011:     locale: Param[str] = Param(",
          "5018:     _input_kwargs: Dict[str, Any]",
          "5020:     @overload",
          "5021:     def __init__(",
          "5022:         self,",
          "5024:         inputCol: Optional[str] = ...,",
          "5025:         outputCol: Optional[str] = ...,",
          "5026:         stopWords: Optional[List[str]] = ...,",
          "5027:         caseSensitive: bool = ...,",
          "5028:         locale: Optional[str] = ...,",
          "5029:     ):",
          "5030:         ...",
          "5032:     @overload",
          "5033:     def __init__(",
          "5034:         self,",
          "5036:         stopWords: Optional[List[str]] = ...,",
          "5037:         caseSensitive: bool = ...,",
          "5038:         locale: Optional[str] = ...,",
          "5039:         inputCols: Optional[List[str]] = ...,",
          "5040:         outputCols: Optional[List[str]] = ...,",
          "5041:     ):",
          "5042:         ...",
          "5048:         inputCol: Optional[str] = None,",
          "5049:         outputCol: Optional[str] = None,",
          "5050:         stopWords: Optional[List[str]] = None,",
          "5051:         caseSensitive: bool = False,",
          "5052:         locale: Optional[str] = None,",
          "5053:         inputCols: Optional[List[str]] = None,",
          "5054:         outputCols: Optional[List[str]] = None,",
          "",
          "---------------",
          "--- Hunk 150 ---",
          "[Context before]",
          "4420:         kwargs = self._input_kwargs",
          "4421:         self.setParams(**kwargs)",
          "4423:     @keyword_only",
          "4424:     @since(\"1.6.0\")",
          "4425:     def setParams(",
          "4426:         self,",
          "4436:         \"\"\"",
          "4437:         setParams(self, \\\\*, inputCol=None, outputCol=None, stopWords=None, caseSensitive=false, \\",
          "4438:                   locale=None, inputCols=None, outputCols=None)",
          "",
          "[Removed Lines]",
          "4428:         inputCol=None,",
          "4429:         outputCol=None,",
          "4430:         stopWords=None,",
          "4431:         caseSensitive=False,",
          "4432:         locale=None,",
          "4433:         inputCols=None,",
          "4434:         outputCols=None,",
          "4435:     ):",
          "",
          "[Added Lines]",
          "5072:     @overload",
          "5073:     def setParams(",
          "5074:         self,",
          "5076:         inputCol: Optional[str] = ...,",
          "5077:         outputCol: Optional[str] = ...,",
          "5078:         stopWords: Optional[List[str]] = ...,",
          "5079:         caseSensitive: bool = ...,",
          "5080:         locale: Optional[str] = ...,",
          "5081:     ) -> \"StopWordsRemover\":",
          "5082:         ...",
          "5084:     @overload",
          "5085:     def setParams(",
          "5086:         self,",
          "5088:         stopWords: Optional[List[str]] = ...,",
          "5089:         caseSensitive: bool = ...,",
          "5090:         locale: Optional[str] = ...,",
          "5091:         inputCols: Optional[List[str]] = ...,",
          "5092:         outputCols: Optional[List[str]] = ...,",
          "5093:     ) -> \"StopWordsRemover\":",
          "5094:         ...",
          "5101:         inputCol: Optional[str] = None,",
          "5102:         outputCol: Optional[str] = None,",
          "5103:         stopWords: Optional[List[str]] = None,",
          "5104:         caseSensitive: bool = False,",
          "5105:         locale: Optional[str] = None,",
          "5106:         inputCols: Optional[List[str]] = None,",
          "5107:         outputCols: Optional[List[str]] = None,",
          "5108:     ) -> \"StopWordsRemover\":",
          "",
          "---------------",
          "--- Hunk 151 ---",
          "[Context before]",
          "4442:         return self._set(**kwargs)",
          "4444:     @since(\"1.6.0\")",
          "4446:         \"\"\"",
          "4447:         Sets the value of :py:attr:`stopWords`.",
          "4448:         \"\"\"",
          "4449:         return self._set(stopWords=value)",
          "4451:     @since(\"1.6.0\")",
          "4453:         \"\"\"",
          "4454:         Gets the value of :py:attr:`stopWords` or its default value.",
          "4455:         \"\"\"",
          "4456:         return self.getOrDefault(self.stopWords)",
          "4458:     @since(\"1.6.0\")",
          "4460:         \"\"\"",
          "4461:         Sets the value of :py:attr:`caseSensitive`.",
          "4462:         \"\"\"",
          "4463:         return self._set(caseSensitive=value)",
          "4465:     @since(\"1.6.0\")",
          "4467:         \"\"\"",
          "4468:         Gets the value of :py:attr:`caseSensitive` or its default value.",
          "4469:         \"\"\"",
          "4470:         return self.getOrDefault(self.caseSensitive)",
          "4472:     @since(\"2.4.0\")",
          "4474:         \"\"\"",
          "4475:         Sets the value of :py:attr:`locale`.",
          "4476:         \"\"\"",
          "4477:         return self._set(locale=value)",
          "4479:     @since(\"2.4.0\")",
          "4481:         \"\"\"",
          "4482:         Gets the value of :py:attr:`locale`.",
          "4483:         \"\"\"",
          "4484:         return self.getOrDefault(self.locale)",
          "4487:         \"\"\"",
          "4488:         Sets the value of :py:attr:`inputCol`.",
          "4489:         \"\"\"",
          "4490:         return self._set(inputCol=value)",
          "4493:         \"\"\"",
          "4494:         Sets the value of :py:attr:`outputCol`.",
          "4495:         \"\"\"",
          "4496:         return self._set(outputCol=value)",
          "4498:     @since(\"3.0.0\")",
          "4500:         \"\"\"",
          "4501:         Sets the value of :py:attr:`inputCols`.",
          "4502:         \"\"\"",
          "4503:         return self._set(inputCols=value)",
          "4505:     @since(\"3.0.0\")",
          "4507:         \"\"\"",
          "4508:         Sets the value of :py:attr:`outputCols`.",
          "4509:         \"\"\"",
          "",
          "[Removed Lines]",
          "4445:     def setStopWords(self, value):",
          "4452:     def getStopWords(self):",
          "4459:     def setCaseSensitive(self, value):",
          "4466:     def getCaseSensitive(self):",
          "4473:     def setLocale(self, value):",
          "4480:     def getLocale(self):",
          "4486:     def setInputCol(self, value):",
          "4492:     def setOutputCol(self, value):",
          "4499:     def setInputCols(self, value):",
          "4506:     def setOutputCols(self, value):",
          "",
          "[Added Lines]",
          "5118:     def setStopWords(self, value: List[str]) -> \"StopWordsRemover\":",
          "5125:     def getStopWords(self) -> List[str]:",
          "5132:     def setCaseSensitive(self, value: bool) -> \"StopWordsRemover\":",
          "5139:     def getCaseSensitive(self) -> bool:",
          "5146:     def setLocale(self, value: str) -> \"StopWordsRemover\":",
          "5153:     def getLocale(self) -> str:",
          "5159:     def setInputCol(self, value: str) -> \"StopWordsRemover\":",
          "5165:     def setOutputCol(self, value: str) -> \"StopWordsRemover\":",
          "5172:     def setInputCols(self, value: List[str]) -> \"StopWordsRemover\":",
          "5179:     def setOutputCols(self, value: List[str]) -> \"StopWordsRemover\":",
          "",
          "---------------",
          "--- Hunk 152 ---",
          "[Context before]",
          "4512:     @staticmethod",
          "4513:     @since(\"2.0.0\")",
          "4515:         \"\"\"",
          "4516:         Loads the default stop words for the given language.",
          "4517:         Supported languages: danish, dutch, english, finnish, french, german, hungarian,",
          "",
          "[Removed Lines]",
          "4514:     def loadDefaultStopWords(language):",
          "",
          "[Added Lines]",
          "5187:     def loadDefaultStopWords(language: str) -> List[str]:",
          "",
          "---------------",
          "--- Hunk 153 ---",
          "[Context before]",
          "4524: @inherit_doc",
          "4526:     \"\"\"",
          "4527:     A tokenizer that converts the input string to lowercase and then",
          "4528:     splits it by white spaces.",
          "",
          "[Removed Lines]",
          "4525: class Tokenizer(JavaTransformer, HasInputCol, HasOutputCol, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "5198: class Tokenizer(",
          "5199:     JavaTransformer,",
          "5200:     HasInputCol,",
          "5201:     HasOutputCol,",
          "5202:     JavaMLReadable[\"Tokenizer\"],",
          "5203:     JavaMLWritable,",
          "5204: ):",
          "",
          "---------------",
          "--- Hunk 154 ---",
          "[Context before]",
          "4557:     True",
          "4558:     \"\"\"",
          "4560:     @keyword_only",
          "4562:         \"\"\"",
          "4563:         __init__(self, \\\\*, inputCol=None, outputCol=None)",
          "4564:         \"\"\"",
          "",
          "[Removed Lines]",
          "4561:     def __init__(self, *, inputCol=None, outputCol=None):",
          "",
          "[Added Lines]",
          "5239:     _input_kwargs: Dict[str, Any]",
          "5242:     def __init__(self, *, inputCol: Optional[str] = None, outputCol: Optional[str] = None):",
          "",
          "---------------",
          "--- Hunk 155 ---",
          "[Context before]",
          "4570:     @keyword_only",
          "4571:     @since(\"1.3.0\")",
          "4573:         \"\"\"",
          "4574:         setParams(self, \\\\*, inputCol=None, outputCol=None)",
          "4575:         Sets params for this Tokenizer.",
          "",
          "[Removed Lines]",
          "4572:     def setParams(self, *, inputCol=None, outputCol=None):",
          "",
          "[Added Lines]",
          "5253:     def setParams(",
          "5254:         self, *, inputCol: Optional[str] = None, outputCol: Optional[str] = None",
          "5255:     ) -> \"Tokenizer\":",
          "",
          "---------------",
          "--- Hunk 156 ---",
          "[Context before]",
          "4577:         kwargs = self._input_kwargs",
          "4578:         return self._set(**kwargs)",
          "4581:         \"\"\"",
          "4582:         Sets the value of :py:attr:`inputCol`.",
          "4583:         \"\"\"",
          "4584:         return self._set(inputCol=value)",
          "4587:         \"\"\"",
          "4588:         Sets the value of :py:attr:`outputCol`.",
          "4589:         \"\"\"",
          "",
          "[Removed Lines]",
          "4580:     def setInputCol(self, value):",
          "4586:     def setOutputCol(self, value):",
          "",
          "[Added Lines]",
          "5263:     def setInputCol(self, value: str) -> \"Tokenizer\":",
          "5269:     def setOutputCol(self, value: str) -> \"Tokenizer\":",
          "",
          "---------------",
          "--- Hunk 157 ---",
          "[Context before]",
          "4593: @inherit_doc",
          "4594: class VectorAssembler(",
          "4596: ):",
          "4597:     \"\"\"",
          "4598:     A feature transformer that merges multiple columns into a vector column.",
          "",
          "[Removed Lines]",
          "4595:     JavaTransformer, HasInputCols, HasOutputCol, HasHandleInvalid, JavaMLReadable, JavaMLWritable",
          "",
          "[Added Lines]",
          "5278:     JavaTransformer,",
          "5279:     HasInputCols,",
          "5280:     HasOutputCol,",
          "5281:     HasHandleInvalid,",
          "5282:     JavaMLReadable[\"VectorAssembler\"],",
          "5283:     JavaMLWritable,",
          "",
          "---------------",
          "--- Hunk 158 ---",
          "[Context before]",
          "4639:     ...",
          "4640:     \"\"\"",
          "4643:         Params._dummy(),",
          "4644:         \"handleInvalid\",",
          "4645:         \"How to handle invalid data (NULL \"",
          "",
          "[Removed Lines]",
          "4642:     handleInvalid = Param(",
          "",
          "[Added Lines]",
          "5330:     handleInvalid: Param[str] = Param(",
          "",
          "---------------",
          "--- Hunk 159 ---",
          "[Context before]",
          "4653:         typeConverter=TypeConverters.toString,",
          "4654:     )",
          "4656:     @keyword_only",
          "4658:         \"\"\"",
          "4659:         __init__(self, \\\\*, inputCols=None, outputCol=None, handleInvalid=\"error\")",
          "4660:         \"\"\"",
          "",
          "[Removed Lines]",
          "4657:     def __init__(self, *, inputCols=None, outputCol=None, handleInvalid=\"error\"):",
          "",
          "[Added Lines]",
          "5344:     _input_kwargs: Dict[str, Any]",
          "5347:     def __init__(",
          "5348:         self,",
          "5350:         inputCols: Optional[List[str]] = None,",
          "5351:         outputCol: Optional[str] = None,",
          "5352:         handleInvalid: str = \"error\",",
          "5353:     ):",
          "",
          "---------------",
          "--- Hunk 160 ---",
          "[Context before]",
          "4667:     @keyword_only",
          "4668:     @since(\"1.4.0\")",
          "4670:         \"\"\"",
          "4671:         setParams(self, \\\\*, inputCols=None, outputCol=None, handleInvalid=\"error\")",
          "4672:         Sets params for this VectorAssembler.",
          "",
          "[Removed Lines]",
          "4669:     def setParams(self, *, inputCols=None, outputCol=None, handleInvalid=\"error\"):",
          "",
          "[Added Lines]",
          "5365:     def setParams(",
          "5366:         self,",
          "5368:         inputCols: Optional[List[str]] = None,",
          "5369:         outputCol: Optional[str] = None,",
          "5370:         handleInvalid: str = \"error\",",
          "5371:     ) -> \"VectorAssembler\":",
          "",
          "---------------",
          "--- Hunk 161 ---",
          "[Context before]",
          "4674:         kwargs = self._input_kwargs",
          "4675:         return self._set(**kwargs)",
          "4678:         \"\"\"",
          "4679:         Sets the value of :py:attr:`inputCols`.",
          "4680:         \"\"\"",
          "4681:         return self._set(inputCols=value)",
          "4684:         \"\"\"",
          "4685:         Sets the value of :py:attr:`outputCol`.",
          "4686:         \"\"\"",
          "4687:         return self._set(outputCol=value)",
          "4690:         \"\"\"",
          "4691:         Sets the value of :py:attr:`handleInvalid`.",
          "4692:         \"\"\"",
          "",
          "[Removed Lines]",
          "4677:     def setInputCols(self, value):",
          "4683:     def setOutputCol(self, value):",
          "4689:     def setHandleInvalid(self, value):",
          "",
          "[Added Lines]",
          "5379:     def setInputCols(self, value: List[str]) -> \"VectorAssembler\":",
          "5385:     def setOutputCol(self, value: str) -> \"VectorAssembler\":",
          "5391:     def setHandleInvalid(self, value: str) -> \"VectorAssembler\":",
          "",
          "---------------",
          "--- Hunk 162 ---",
          "[Context before]",
          "4700:     .. versionadded:: 3.0.0",
          "4701:     \"\"\"",
          "4704:         Params._dummy(),",
          "4705:         \"maxCategories\",",
          "4706:         \"Threshold for the number of values a categorical feature can take \"",
          "",
          "[Removed Lines]",
          "4703:     maxCategories = Param(",
          "",
          "[Added Lines]",
          "5405:     maxCategories: Param[int] = Param(",
          "",
          "---------------",
          "--- Hunk 163 ---",
          "[Context before]",
          "4709:         typeConverter=TypeConverters.toInt,",
          "4710:     )",
          "4713:         Params._dummy(),",
          "4714:         \"handleInvalid\",",
          "4715:         \"How to handle invalid data \"",
          "",
          "[Removed Lines]",
          "4712:     handleInvalid = Param(",
          "",
          "[Added Lines]",
          "5414:     handleInvalid: Param[str] = Param(",
          "",
          "---------------",
          "--- Hunk 164 ---",
          "[Context before]",
          "4720:         typeConverter=TypeConverters.toString,",
          "4721:     )",
          "4724:         super(_VectorIndexerParams, self).__init__(*args)",
          "4725:         self._setDefault(maxCategories=20, handleInvalid=\"error\")",
          "4727:     @since(\"1.4.0\")",
          "4729:         \"\"\"",
          "4730:         Gets the value of maxCategories or its default value.",
          "4731:         \"\"\"",
          "",
          "[Removed Lines]",
          "4723:     def __init__(self, *args):",
          "4728:     def getMaxCategories(self):",
          "",
          "[Added Lines]",
          "5425:     def __init__(self, *args: Any):",
          "5430:     def getMaxCategories(self) -> int:",
          "",
          "---------------",
          "--- Hunk 165 ---",
          "[Context before]",
          "4735: @inherit_doc",
          "4737:     \"\"\"",
          "4738:     Class for indexing categorical feature columns in a dataset of `Vector`.",
          "",
          "[Removed Lines]",
          "4736: class VectorIndexer(JavaEstimator, _VectorIndexerParams, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "5438: class VectorIndexer(",
          "5439:     JavaEstimator[\"VectorIndexerModel\"],",
          "5440:     _VectorIndexerParams,",
          "5441:     HasHandleInvalid,",
          "5442:     JavaMLReadable[\"VectorIndexer\"],",
          "5443:     JavaMLWritable,",
          "5444: ):",
          "",
          "---------------",
          "--- Hunk 166 ---",
          "[Context before]",
          "4821:     DenseVector([2.0, 1.0])",
          "4822:     \"\"\"",
          "4824:     @keyword_only",
          "4826:         \"\"\"",
          "4827:         __init__(self, \\\\*, maxCategories=20, inputCol=None, outputCol=None, handleInvalid=\"error\")",
          "4828:         \"\"\"",
          "",
          "[Removed Lines]",
          "4825:     def __init__(self, *, maxCategories=20, inputCol=None, outputCol=None, handleInvalid=\"error\"):",
          "",
          "[Added Lines]",
          "5532:     _input_kwargs: Dict[str, Any]",
          "5535:     def __init__(",
          "5536:         self,",
          "5538:         maxCategories: int = 20,",
          "5539:         inputCol: Optional[str] = None,",
          "5540:         outputCol: Optional[str] = None,",
          "5541:         handleInvalid: str = \"error\",",
          "5542:     ):",
          "",
          "---------------",
          "--- Hunk 167 ---",
          "[Context before]",
          "4834:     @keyword_only",
          "4835:     @since(\"1.4.0\")",
          "4837:         \"\"\"",
          "4838:         setParams(self, \\\\*, maxCategories=20, inputCol=None, outputCol=None, handleInvalid=\"error\")",
          "4839:         Sets params for this VectorIndexer.",
          "",
          "[Removed Lines]",
          "4836:     def setParams(self, *, maxCategories=20, inputCol=None, outputCol=None, handleInvalid=\"error\"):",
          "",
          "[Added Lines]",
          "5553:     def setParams(",
          "5554:         self,",
          "5556:         maxCategories: int = 20,",
          "5557:         inputCol: Optional[str] = None,",
          "5558:         outputCol: Optional[str] = None,",
          "5559:         handleInvalid: str = \"error\",",
          "5560:     ) -> \"VectorIndexer\":",
          "",
          "---------------",
          "--- Hunk 168 ---",
          "[Context before]",
          "4842:         return self._set(**kwargs)",
          "4844:     @since(\"1.4.0\")",
          "4846:         \"\"\"",
          "4847:         Sets the value of :py:attr:`maxCategories`.",
          "4848:         \"\"\"",
          "4849:         return self._set(maxCategories=value)",
          "4852:         \"\"\"",
          "4853:         Sets the value of :py:attr:`inputCol`.",
          "4854:         \"\"\"",
          "4855:         return self._set(inputCol=value)",
          "4858:         \"\"\"",
          "4859:         Sets the value of :py:attr:`outputCol`.",
          "4860:         \"\"\"",
          "4861:         return self._set(outputCol=value)",
          "4864:         \"\"\"",
          "4865:         Sets the value of :py:attr:`handleInvalid`.",
          "4866:         \"\"\"",
          "4867:         return self._set(handleInvalid=value)",
          "4870:         return VectorIndexerModel(java_model)",
          "4874:     \"\"\"",
          "4875:     Model fitted by :py:class:`VectorIndexer`.",
          "",
          "[Removed Lines]",
          "4845:     def setMaxCategories(self, value):",
          "4851:     def setInputCol(self, value):",
          "4857:     def setOutputCol(self, value):",
          "4863:     def setHandleInvalid(self, value):",
          "4869:     def _create_model(self, java_model):",
          "4873: class VectorIndexerModel(JavaModel, _VectorIndexerParams, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "5569:     def setMaxCategories(self, value: int) -> \"VectorIndexer\":",
          "5575:     def setInputCol(self, value: str) -> \"VectorIndexer\":",
          "5581:     def setOutputCol(self, value: str) -> \"VectorIndexer\":",
          "5587:     def setHandleInvalid(self, value: str) -> \"VectorIndexer\":",
          "5593:     def _create_model(self, java_model: \"JavaObject\") -> \"VectorIndexerModel\":",
          "5597: class VectorIndexerModel(",
          "5598:     JavaModel, _VectorIndexerParams, JavaMLReadable[\"VectorIndexerModel\"], JavaMLWritable",
          "5599: ):",
          "",
          "---------------",
          "--- Hunk 169 ---",
          "[Context before]",
          "4888:     \"\"\"",
          "4890:     @since(\"3.0.0\")",
          "4892:         \"\"\"",
          "4893:         Sets the value of :py:attr:`inputCol`.",
          "4894:         \"\"\"",
          "4895:         return self._set(inputCol=value)",
          "4897:     @since(\"3.0.0\")",
          "4899:         \"\"\"",
          "4900:         Sets the value of :py:attr:`outputCol`.",
          "4901:         \"\"\"",
          "4902:         return self._set(outputCol=value)",
          "4905:     @since(\"1.4.0\")",
          "4907:         \"\"\"",
          "4908:         Number of features, i.e., length of Vectors which this transforms.",
          "4909:         \"\"\"",
          "4910:         return self._call_java(\"numFeatures\")",
          "4913:     @since(\"1.4.0\")",
          "4915:         \"\"\"",
          "4916:         Feature value index.  Keys are categorical feature indices (column indices).",
          "4917:         Values are maps from original features values to 0-based category indices.",
          "",
          "[Removed Lines]",
          "4891:     def setInputCol(self, value):",
          "4898:     def setOutputCol(self, value):",
          "4904:     @property",
          "4906:     def numFeatures(self):",
          "4912:     @property",
          "4914:     def categoryMaps(self):",
          "",
          "[Added Lines]",
          "5617:     def setInputCol(self, value: str) -> \"VectorIndexerModel\":",
          "5624:     def setOutputCol(self, value: str) -> \"VectorIndexerModel\":",
          "5630:     @property  # type: ignore[misc]",
          "5632:     def numFeatures(self) -> int:",
          "5638:     @property  # type: ignore[misc]",
          "5640:     def categoryMaps(self) -> Dict[int, Tuple[float, int]]:",
          "",
          "---------------",
          "--- Hunk 170 ---",
          "[Context before]",
          "4923: @inherit_doc",
          "4925:     \"\"\"",
          "4926:     This class takes a feature vector and outputs a new feature vector with a subarray",
          "4927:     of the original features.",
          "",
          "[Removed Lines]",
          "4924: class VectorSlicer(JavaTransformer, HasInputCol, HasOutputCol, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "5650: class VectorSlicer(",
          "5651:     JavaTransformer,",
          "5652:     HasInputCol,",
          "5653:     HasOutputCol,",
          "5654:     JavaMLReadable[\"VectorSlicer\"],",
          "5655:     JavaMLWritable,",
          "5656: ):",
          "",
          "---------------",
          "--- Hunk 171 ---",
          "[Context before]",
          "4958:     True",
          "4959:     \"\"\"",
          "4962:         Params._dummy(),",
          "4963:         \"indices\",",
          "4964:         \"An array of indices to select features from \"",
          "4965:         + \"a vector column. There can be no overlap with names.\",",
          "4966:         typeConverter=TypeConverters.toListInt,",
          "4967:     )",
          "4969:         Params._dummy(),",
          "4970:         \"names\",",
          "4971:         \"An array of feature names to select features from \"",
          "",
          "[Removed Lines]",
          "4961:     indices = Param(",
          "4968:     names = Param(",
          "",
          "[Added Lines]",
          "5693:     indices: Param[List[int]] = Param(",
          "5700:     names: Param[List[str]] = Param(",
          "",
          "---------------",
          "--- Hunk 172 ---",
          "[Context before]",
          "4975:         typeConverter=TypeConverters.toListString,",
          "4976:     )",
          "4978:     @keyword_only",
          "4980:         \"\"\"",
          "4981:         __init__(self, \\\\*, inputCol=None, outputCol=None, indices=None, names=None)",
          "4982:         \"\"\"",
          "",
          "[Removed Lines]",
          "4979:     def __init__(self, *, inputCol=None, outputCol=None, indices=None, names=None):",
          "",
          "[Added Lines]",
          "5710:     _input_kwargs: Dict[str, Any]",
          "5713:     def __init__(",
          "5714:         self,",
          "5716:         inputCol: Optional[str] = None,",
          "5717:         outputCol: Optional[str] = None,",
          "5718:         indices: Optional[List[int]] = None,",
          "5719:         names: Optional[List[str]] = None,",
          "5720:     ):",
          "",
          "---------------",
          "--- Hunk 173 ---",
          "[Context before]",
          "4989:     @keyword_only",
          "4990:     @since(\"1.6.0\")",
          "4992:         \"\"\"",
          "4993:         setParams(self, \\\\*, inputCol=None, outputCol=None, indices=None, names=None):",
          "4994:         Sets params for this VectorSlicer.",
          "",
          "[Removed Lines]",
          "4991:     def setParams(self, *, inputCol=None, outputCol=None, indices=None, names=None):",
          "",
          "[Added Lines]",
          "5732:     def setParams(",
          "5733:         self,",
          "5735:         inputCol: Optional[str] = None,",
          "5736:         outputCol: Optional[str] = None,",
          "5737:         indices: Optional[List[int]] = None,",
          "5738:         names: Optional[List[str]] = None,",
          "5739:     ) -> \"VectorSlicer\":",
          "",
          "---------------",
          "--- Hunk 174 ---",
          "[Context before]",
          "4997:         return self._set(**kwargs)",
          "4999:     @since(\"1.6.0\")",
          "5001:         \"\"\"",
          "5002:         Sets the value of :py:attr:`indices`.",
          "5003:         \"\"\"",
          "5004:         return self._set(indices=value)",
          "5006:     @since(\"1.6.0\")",
          "5008:         \"\"\"",
          "5009:         Gets the value of indices or its default value.",
          "5010:         \"\"\"",
          "5011:         return self.getOrDefault(self.indices)",
          "5013:     @since(\"1.6.0\")",
          "5015:         \"\"\"",
          "5016:         Sets the value of :py:attr:`names`.",
          "5017:         \"\"\"",
          "5018:         return self._set(names=value)",
          "5020:     @since(\"1.6.0\")",
          "5022:         \"\"\"",
          "5023:         Gets the value of names or its default value.",
          "5024:         \"\"\"",
          "5025:         return self.getOrDefault(self.names)",
          "5028:         \"\"\"",
          "5029:         Sets the value of :py:attr:`inputCol`.",
          "5030:         \"\"\"",
          "5031:         return self._set(inputCol=value)",
          "5034:         \"\"\"",
          "5035:         Sets the value of :py:attr:`outputCol`.",
          "5036:         \"\"\"",
          "",
          "[Removed Lines]",
          "5000:     def setIndices(self, value):",
          "5007:     def getIndices(self):",
          "5014:     def setNames(self, value):",
          "5021:     def getNames(self):",
          "5027:     def setInputCol(self, value):",
          "5033:     def setOutputCol(self, value):",
          "",
          "[Added Lines]",
          "5748:     def setIndices(self, value: List[int]) -> \"VectorSlicer\":",
          "5755:     def getIndices(self) -> List[int]:",
          "5762:     def setNames(self, value: List[str]) -> \"VectorSlicer\":",
          "5769:     def getNames(self) -> List[str]:",
          "5775:     def setInputCol(self, value: str) -> \"VectorSlicer\":",
          "5781:     def setOutputCol(self, value: str) -> \"VectorSlicer\":",
          "",
          "---------------",
          "--- Hunk 175 ---",
          "[Context before]",
          "5044:     .. versionadded:: 3.0.0",
          "5045:     \"\"\"",
          "5048:         Params._dummy(),",
          "5049:         \"vectorSize\",",
          "5050:         \"the dimension of codes after transforming from words\",",
          "5051:         typeConverter=TypeConverters.toInt,",
          "5052:     )",
          "5054:         Params._dummy(),",
          "5055:         \"numPartitions\",",
          "5056:         \"number of partitions for sentences of words\",",
          "5057:         typeConverter=TypeConverters.toInt,",
          "5058:     )",
          "5060:         Params._dummy(),",
          "5061:         \"minCount\",",
          "5062:         \"the minimum number of times a token must appear to be included in the \"",
          "5063:         + \"word2vec model's vocabulary\",",
          "5064:         typeConverter=TypeConverters.toInt,",
          "5065:     )",
          "5067:         Params._dummy(),",
          "5068:         \"windowSize\",",
          "5069:         \"the window size (context words from [-window, window]). Default value is 5\",",
          "5070:         typeConverter=TypeConverters.toInt,",
          "5071:     )",
          "5073:         Params._dummy(),",
          "5074:         \"maxSentenceLength\",",
          "5075:         \"Maximum length (in words) of each sentence in the input data. \"",
          "",
          "[Removed Lines]",
          "5047:     vectorSize = Param(",
          "5053:     numPartitions = Param(",
          "5059:     minCount = Param(",
          "5066:     windowSize = Param(",
          "5072:     maxSentenceLength = Param(",
          "",
          "[Added Lines]",
          "5795:     vectorSize: Param[int] = Param(",
          "5801:     numPartitions: Param[int] = Param(",
          "5807:     minCount: Param[int] = Param(",
          "5814:     windowSize: Param[int] = Param(",
          "5820:     maxSentenceLength: Param[int] = Param(",
          "",
          "---------------",
          "--- Hunk 176 ---",
          "[Context before]",
          "5078:         typeConverter=TypeConverters.toInt,",
          "5079:     )",
          "5082:         super(_Word2VecParams, self).__init__(*args)",
          "5083:         self._setDefault(",
          "5084:             vectorSize=100,",
          "",
          "[Removed Lines]",
          "5081:     def __init__(self, *args):",
          "",
          "[Added Lines]",
          "5829:     def __init__(self, *args: Any):",
          "",
          "---------------",
          "--- Hunk 177 ---",
          "[Context before]",
          "5091:         )",
          "5093:     @since(\"1.4.0\")",
          "5095:         \"\"\"",
          "5096:         Gets the value of vectorSize or its default value.",
          "5097:         \"\"\"",
          "5098:         return self.getOrDefault(self.vectorSize)",
          "5100:     @since(\"1.4.0\")",
          "5102:         \"\"\"",
          "5103:         Gets the value of numPartitions or its default value.",
          "5104:         \"\"\"",
          "5105:         return self.getOrDefault(self.numPartitions)",
          "5107:     @since(\"1.4.0\")",
          "5109:         \"\"\"",
          "5110:         Gets the value of minCount or its default value.",
          "5111:         \"\"\"",
          "5112:         return self.getOrDefault(self.minCount)",
          "5114:     @since(\"2.0.0\")",
          "5116:         \"\"\"",
          "5117:         Gets the value of windowSize or its default value.",
          "5118:         \"\"\"",
          "5119:         return self.getOrDefault(self.windowSize)",
          "5121:     @since(\"2.0.0\")",
          "5123:         \"\"\"",
          "5124:         Gets the value of maxSentenceLength or its default value.",
          "5125:         \"\"\"",
          "",
          "[Removed Lines]",
          "5094:     def getVectorSize(self):",
          "5101:     def getNumPartitions(self):",
          "5108:     def getMinCount(self):",
          "5115:     def getWindowSize(self):",
          "5122:     def getMaxSentenceLength(self):",
          "",
          "[Added Lines]",
          "5842:     def getVectorSize(self) -> int:",
          "5849:     def getNumPartitions(self) -> int:",
          "5856:     def getMinCount(self) -> int:",
          "5863:     def getWindowSize(self) -> int:",
          "5870:     def getMaxSentenceLength(self) -> int:",
          "",
          "---------------",
          "--- Hunk 178 ---",
          "[Context before]",
          "5129: @inherit_doc",
          "5131:     \"\"\"",
          "5132:     Word2Vec trains a model of `Map(String, Vector)`, i.e. transforms a word into a code for further",
          "5133:     natural language processing or machine learning process.",
          "",
          "[Removed Lines]",
          "5130: class Word2Vec(JavaEstimator, _Word2VecParams, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "5878: class Word2Vec(",
          "5879:     JavaEstimator[\"Word2VecModel\"],",
          "5880:     _Word2VecParams,",
          "5881:     JavaMLReadable[\"Word2Vec\"],",
          "5882:     JavaMLWritable,",
          "5883: ):",
          "",
          "---------------",
          "--- Hunk 179 ---",
          "[Context before]",
          "5191:     True",
          "5192:     \"\"\"",
          "5194:     @keyword_only",
          "5195:     def __init__(",
          "5196:         self,",
          "5208:     ):",
          "5209:         \"\"\"",
          "5210:         __init__(self, \\\\*, vectorSize=100, minCount=5, numPartitions=1, stepSize=0.025, \\",
          "",
          "[Removed Lines]",
          "5198:         vectorSize=100,",
          "5199:         minCount=5,",
          "5200:         numPartitions=1,",
          "5201:         stepSize=0.025,",
          "5202:         maxIter=1,",
          "5203:         seed=None,",
          "5204:         inputCol=None,",
          "5205:         outputCol=None,",
          "5206:         windowSize=5,",
          "5207:         maxSentenceLength=1000,",
          "",
          "[Added Lines]",
          "5947:     _input_kwargs: Dict[str, Any]",
          "5953:         vectorSize: int = 100,",
          "5954:         minCount: int = 5,",
          "5955:         numPartitions: int = 1,",
          "5956:         stepSize: float = 0.025,",
          "5957:         maxIter: int = 1,",
          "5958:         seed: Optional[int] = None,",
          "5959:         inputCol: Optional[str] = None,",
          "5960:         outputCol: Optional[str] = None,",
          "5961:         windowSize: int = 5,",
          "5962:         maxSentenceLength: int = 1000,",
          "",
          "---------------",
          "--- Hunk 180 ---",
          "[Context before]",
          "5221:     def setParams(",
          "5222:         self,",
          "5235:         \"\"\"",
          "5236:         setParams(self, \\\\*, minCount=5, numPartitions=1, stepSize=0.025, maxIter=1, \\",
          "5237:                   seed=None, inputCol=None, outputCol=None, windowSize=5, \\",
          "",
          "[Removed Lines]",
          "5224:         vectorSize=100,",
          "5225:         minCount=5,",
          "5226:         numPartitions=1,",
          "5227:         stepSize=0.025,",
          "5228:         maxIter=1,",
          "5229:         seed=None,",
          "5230:         inputCol=None,",
          "5231:         outputCol=None,",
          "5232:         windowSize=5,",
          "5233:         maxSentenceLength=1000,",
          "5234:     ):",
          "",
          "[Added Lines]",
          "5979:         vectorSize: int = 100,",
          "5980:         minCount: int = 5,",
          "5981:         numPartitions: int = 1,",
          "5982:         stepSize: float = 0.025,",
          "5983:         maxIter: int = 1,",
          "5984:         seed: Optional[int] = None,",
          "5985:         inputCol: Optional[str] = None,",
          "5986:         outputCol: Optional[str] = None,",
          "5987:         windowSize: int = 5,",
          "5988:         maxSentenceLength: int = 1000,",
          "5989:     ) -> \"Word2Vec\":",
          "",
          "---------------",
          "--- Hunk 181 ---",
          "[Context before]",
          "5242:         return self._set(**kwargs)",
          "5244:     @since(\"1.4.0\")",
          "5246:         \"\"\"",
          "5247:         Sets the value of :py:attr:`vectorSize`.",
          "5248:         \"\"\"",
          "5249:         return self._set(vectorSize=value)",
          "5251:     @since(\"1.4.0\")",
          "5253:         \"\"\"",
          "5254:         Sets the value of :py:attr:`numPartitions`.",
          "5255:         \"\"\"",
          "5256:         return self._set(numPartitions=value)",
          "5258:     @since(\"1.4.0\")",
          "5260:         \"\"\"",
          "5261:         Sets the value of :py:attr:`minCount`.",
          "5262:         \"\"\"",
          "5263:         return self._set(minCount=value)",
          "5265:     @since(\"2.0.0\")",
          "5267:         \"\"\"",
          "5268:         Sets the value of :py:attr:`windowSize`.",
          "5269:         \"\"\"",
          "5270:         return self._set(windowSize=value)",
          "5272:     @since(\"2.0.0\")",
          "5274:         \"\"\"",
          "5275:         Sets the value of :py:attr:`maxSentenceLength`.",
          "5276:         \"\"\"",
          "5277:         return self._set(maxSentenceLength=value)",
          "5280:         \"\"\"",
          "5281:         Sets the value of :py:attr:`maxIter`.",
          "5282:         \"\"\"",
          "5283:         return self._set(maxIter=value)",
          "5286:         \"\"\"",
          "5287:         Sets the value of :py:attr:`inputCol`.",
          "5288:         \"\"\"",
          "5289:         return self._set(inputCol=value)",
          "5292:         \"\"\"",
          "5293:         Sets the value of :py:attr:`outputCol`.",
          "5294:         \"\"\"",
          "5295:         return self._set(outputCol=value)",
          "5298:         \"\"\"",
          "5299:         Sets the value of :py:attr:`seed`.",
          "5300:         \"\"\"",
          "5301:         return self._set(seed=value)",
          "5303:     @since(\"1.4.0\")",
          "5305:         \"\"\"",
          "5306:         Sets the value of :py:attr:`stepSize`.",
          "5307:         \"\"\"",
          "5308:         return self._set(stepSize=value)",
          "5311:         return Word2VecModel(java_model)",
          "5315:     \"\"\"",
          "5316:     Model fitted by :py:class:`Word2Vec`.",
          "",
          "[Removed Lines]",
          "5245:     def setVectorSize(self, value):",
          "5252:     def setNumPartitions(self, value):",
          "5259:     def setMinCount(self, value):",
          "5266:     def setWindowSize(self, value):",
          "5273:     def setMaxSentenceLength(self, value):",
          "5279:     def setMaxIter(self, value):",
          "5285:     def setInputCol(self, value):",
          "5291:     def setOutputCol(self, value):",
          "5297:     def setSeed(self, value):",
          "5304:     def setStepSize(self, value):",
          "5310:     def _create_model(self, java_model):",
          "5314: class Word2VecModel(JavaModel, _Word2VecParams, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "6000:     def setVectorSize(self, value: int) -> \"Word2Vec\":",
          "6007:     def setNumPartitions(self, value: int) -> \"Word2Vec\":",
          "6014:     def setMinCount(self, value: int) -> \"Word2Vec\":",
          "6021:     def setWindowSize(self, value: int) -> \"Word2Vec\":",
          "6028:     def setMaxSentenceLength(self, value: int) -> \"Word2Vec\":",
          "6034:     def setMaxIter(self, value: int) -> \"Word2Vec\":",
          "6040:     def setInputCol(self, value: str) -> \"Word2Vec\":",
          "6046:     def setOutputCol(self, value: str) -> \"Word2Vec\":",
          "6052:     def setSeed(self, value: int) -> \"Word2Vec\":",
          "6059:     def setStepSize(self, value: float) -> \"Word2Vec\":",
          "6065:     def _create_model(self, java_model: \"JavaObject\") -> \"Word2VecModel\":",
          "6069: class Word2VecModel(JavaModel, _Word2VecParams, JavaMLReadable[\"Word2VecModel\"], JavaMLWritable):",
          "",
          "---------------",
          "--- Hunk 182 ---",
          "[Context before]",
          "5319:     \"\"\"",
          "5321:     @since(\"1.5.0\")",
          "5323:         \"\"\"",
          "5324:         Returns the vector representation of the words as a dataframe",
          "5325:         with two fields, word and vector.",
          "5326:         \"\"\"",
          "5327:         return self._call_java(\"getVectors\")",
          "5330:         \"\"\"",
          "5331:         Sets the value of :py:attr:`inputCol`.",
          "5332:         \"\"\"",
          "5333:         return self._set(inputCol=value)",
          "5336:         \"\"\"",
          "5337:         Sets the value of :py:attr:`outputCol`.",
          "5338:         \"\"\"",
          "5339:         return self._set(outputCol=value)",
          "5341:     @since(\"1.5.0\")",
          "5343:         \"\"\"",
          "5344:         Find \"num\" number of words closest in similarity to \"word\".",
          "5345:         word can be a string or vector representation.",
          "",
          "[Removed Lines]",
          "5322:     def getVectors(self):",
          "5329:     def setInputCol(self, value):",
          "5335:     def setOutputCol(self, value):",
          "5342:     def findSynonyms(self, word, num):",
          "",
          "[Added Lines]",
          "6077:     def getVectors(self) -> DataFrame:",
          "6084:     def setInputCol(self, value: str) -> \"Word2VecModel\":",
          "6090:     def setOutputCol(self, value: str) -> \"Word2VecModel\":",
          "6097:     def findSynonyms(self, word: Union[str, Vector], num: int) -> DataFrame:",
          "",
          "---------------",
          "--- Hunk 183 ---",
          "[Context before]",
          "5351:         return self._call_java(\"findSynonyms\", word, num)",
          "5353:     @since(\"2.3.0\")",
          "5355:         \"\"\"",
          "5356:         Find \"num\" number of words closest in similarity to \"word\".",
          "5357:         word can be a string or vector representation.",
          "",
          "[Removed Lines]",
          "5354:     def findSynonymsArray(self, word, num):",
          "",
          "[Added Lines]",
          "6109:     def findSynonymsArray(self, word: Union[Vector, str], num: int) -> List[Tuple[str, float]]:",
          "",
          "---------------",
          "--- Hunk 184 ---",
          "[Context before]",
          "5360:         \"\"\"",
          "5361:         if not isinstance(word, str):",
          "5362:             word = _convert_to_vector(word)",
          "5363:         tuples = self._java_obj.findSynonymsArray(word, num)",
          "5364:         return list(map(lambda st: (st._1(), st._2()), list(tuples)))",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "6118:         assert self._java_obj is not None",
          "",
          "---------------",
          "--- Hunk 185 ---",
          "[Context before]",
          "5371:     .. versionadded:: 3.0.0",
          "5372:     \"\"\"",
          "5375:         Params._dummy(),",
          "5376:         \"k\",",
          "5377:         \"the number of principal components\",",
          "",
          "[Removed Lines]",
          "5374:     k = Param(",
          "",
          "[Added Lines]",
          "6130:     k: Param[int] = Param(",
          "",
          "---------------",
          "--- Hunk 186 ---",
          "[Context before]",
          "5379:     )",
          "5381:     @since(\"1.5.0\")",
          "5383:         \"\"\"",
          "5384:         Gets the value of k or its default value.",
          "5385:         \"\"\"",
          "",
          "[Removed Lines]",
          "5382:     def getK(self):",
          "",
          "[Added Lines]",
          "6138:     def getK(self) -> int:",
          "",
          "---------------",
          "--- Hunk 187 ---",
          "[Context before]",
          "5389: @inherit_doc",
          "5391:     \"\"\"",
          "5392:     PCA trains a model to project vectors to a lower dimensional space of the",
          "5393:     top :py:attr:`k` principal components.",
          "",
          "[Removed Lines]",
          "5390: class PCA(JavaEstimator, _PCAParams, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "6146: class PCA(JavaEstimator[\"PCAModel\"], _PCAParams, JavaMLReadable[\"PCA\"], JavaMLWritable):",
          "",
          "---------------",
          "--- Hunk 188 ---",
          "[Context before]",
          "5429:     True",
          "5430:     \"\"\"",
          "5432:     @keyword_only",
          "5434:         \"\"\"",
          "5435:         __init__(self, \\\\*, k=None, inputCol=None, outputCol=None)",
          "5436:         \"\"\"",
          "",
          "[Removed Lines]",
          "5433:     def __init__(self, *, k=None, inputCol=None, outputCol=None):",
          "",
          "[Added Lines]",
          "6188:     _input_kwargs: Dict[str, Any]",
          "6191:     def __init__(",
          "6192:         self,",
          "6194:         k: Optional[int] = None,",
          "6195:         inputCol: Optional[str] = None,",
          "6196:         outputCol: Optional[str] = None,",
          "6197:     ):",
          "",
          "---------------",
          "--- Hunk 189 ---",
          "[Context before]",
          "5442:     @keyword_only",
          "5443:     @since(\"1.5.0\")",
          "5445:         \"\"\"",
          "5446:         setParams(self, \\\\*, k=None, inputCol=None, outputCol=None)",
          "5447:         Set params for this PCA.",
          "",
          "[Removed Lines]",
          "5444:     def setParams(self, *, k=None, inputCol=None, outputCol=None):",
          "",
          "[Added Lines]",
          "6208:     def setParams(",
          "6209:         self,",
          "6211:         k: Optional[int] = None,",
          "6212:         inputCol: Optional[str] = None,",
          "6213:         outputCol: Optional[str] = None,",
          "6214:     ) -> \"PCA\":",
          "",
          "---------------",
          "--- Hunk 190 ---",
          "[Context before]",
          "5450:         return self._set(**kwargs)",
          "5452:     @since(\"1.5.0\")",
          "5454:         \"\"\"",
          "5455:         Sets the value of :py:attr:`k`.",
          "5456:         \"\"\"",
          "5457:         return self._set(k=value)",
          "5460:         \"\"\"",
          "5461:         Sets the value of :py:attr:`inputCol`.",
          "5462:         \"\"\"",
          "5463:         return self._set(inputCol=value)",
          "5466:         \"\"\"",
          "5467:         Sets the value of :py:attr:`outputCol`.",
          "5468:         \"\"\"",
          "5469:         return self._set(outputCol=value)",
          "5472:         return PCAModel(java_model)",
          "5476:     \"\"\"",
          "5477:     Model fitted by :py:class:`PCA`. Transforms vectors to a lower dimensional space.",
          "",
          "[Removed Lines]",
          "5453:     def setK(self, value):",
          "5459:     def setInputCol(self, value):",
          "5465:     def setOutputCol(self, value):",
          "5471:     def _create_model(self, java_model):",
          "5475: class PCAModel(JavaModel, _PCAParams, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "6223:     def setK(self, value: int) -> \"PCA\":",
          "6229:     def setInputCol(self, value: str) -> \"PCA\":",
          "6235:     def setOutputCol(self, value: str) -> \"PCA\":",
          "6241:     def _create_model(self, java_model: \"JavaObject\") -> \"PCAModel\":",
          "6245: class PCAModel(JavaModel, _PCAParams, JavaMLReadable[\"PCAModel\"], JavaMLWritable):",
          "",
          "---------------",
          "--- Hunk 191 ---",
          "[Context before]",
          "5480:     \"\"\"",
          "5482:     @since(\"3.0.0\")",
          "5484:         \"\"\"",
          "5485:         Sets the value of :py:attr:`inputCol`.",
          "5486:         \"\"\"",
          "5487:         return self._set(inputCol=value)",
          "5489:     @since(\"3.0.0\")",
          "5491:         \"\"\"",
          "5492:         Sets the value of :py:attr:`outputCol`.",
          "5493:         \"\"\"",
          "5494:         return self._set(outputCol=value)",
          "5497:     @since(\"2.0.0\")",
          "5499:         \"\"\"",
          "5500:         Returns a principal components Matrix.",
          "5501:         Each column is one principal component.",
          "5502:         \"\"\"",
          "5503:         return self._call_java(\"pc\")",
          "5506:     @since(\"2.0.0\")",
          "5508:         \"\"\"",
          "5509:         Returns a vector of proportions of variance",
          "5510:         explained by each principal component.",
          "",
          "[Removed Lines]",
          "5483:     def setInputCol(self, value):",
          "5490:     def setOutputCol(self, value):",
          "5496:     @property",
          "5498:     def pc(self):",
          "5505:     @property",
          "5507:     def explainedVariance(self):",
          "",
          "[Added Lines]",
          "6253:     def setInputCol(self, value: str) -> \"PCAModel\":",
          "6260:     def setOutputCol(self, value: str) -> \"PCAModel\":",
          "6266:     @property  # type: ignore[misc]",
          "6268:     def pc(self) -> DenseMatrix:",
          "6275:     @property  # type: ignore[misc]",
          "6277:     def explainedVariance(self) -> DenseVector:",
          "",
          "---------------",
          "--- Hunk 192 ---",
          "[Context before]",
          "5519:     .. versionadded:: 3.0.0",
          "5520:     \"\"\"",
          "5523:         Params._dummy(), \"formula\", \"R model formula\", typeConverter=TypeConverters.toString",
          "5524:     )",
          "5527:         Params._dummy(),",
          "5528:         \"forceIndexLabel\",",
          "5529:         \"Force to index label whether it is numeric or string\",",
          "5530:         typeConverter=TypeConverters.toBoolean,",
          "5531:     )",
          "5534:         Params._dummy(),",
          "5535:         \"stringIndexerOrderType\",",
          "5536:         \"How to order categories of a string feature column used by \"",
          "",
          "[Removed Lines]",
          "5522:     formula = Param(",
          "5526:     forceIndexLabel = Param(",
          "5533:     stringIndexerOrderType = Param(",
          "",
          "[Added Lines]",
          "6292:     formula: Param[str] = Param(",
          "6296:     forceIndexLabel: Param[bool] = Param(",
          "6303:     stringIndexerOrderType: Param[str] = Param(",
          "",
          "---------------",
          "--- Hunk 193 ---",
          "[Context before]",
          "5542:         typeConverter=TypeConverters.toString,",
          "5543:     )",
          "5546:         Params._dummy(),",
          "5547:         \"handleInvalid\",",
          "5548:         \"how to handle invalid entries. \"",
          "",
          "[Removed Lines]",
          "5545:     handleInvalid = Param(",
          "",
          "[Added Lines]",
          "6315:     handleInvalid: Param[str] = Param(",
          "",
          "---------------",
          "--- Hunk 194 ---",
          "[Context before]",
          "5552:         typeConverter=TypeConverters.toString,",
          "5553:     )",
          "5556:         super(_RFormulaParams, self).__init__(*args)",
          "5557:         self._setDefault(",
          "5558:             forceIndexLabel=False, stringIndexerOrderType=\"frequencyDesc\", handleInvalid=\"error\"",
          "5559:         )",
          "5561:     @since(\"1.5.0\")",
          "5563:         \"\"\"",
          "5564:         Gets the value of :py:attr:`formula`.",
          "5565:         \"\"\"",
          "5566:         return self.getOrDefault(self.formula)",
          "5568:     @since(\"2.1.0\")",
          "5570:         \"\"\"",
          "5571:         Gets the value of :py:attr:`forceIndexLabel`.",
          "5572:         \"\"\"",
          "5573:         return self.getOrDefault(self.forceIndexLabel)",
          "5575:     @since(\"2.3.0\")",
          "5577:         \"\"\"",
          "5578:         Gets the value of :py:attr:`stringIndexerOrderType` or its default value 'frequencyDesc'.",
          "5579:         \"\"\"",
          "",
          "[Removed Lines]",
          "5555:     def __init__(self, *args):",
          "5562:     def getFormula(self):",
          "5569:     def getForceIndexLabel(self):",
          "5576:     def getStringIndexerOrderType(self):",
          "",
          "[Added Lines]",
          "6325:     def __init__(self, *args: Any):",
          "6332:     def getFormula(self) -> str:",
          "6339:     def getForceIndexLabel(self) -> bool:",
          "6346:     def getStringIndexerOrderType(self) -> str:",
          "",
          "---------------",
          "--- Hunk 195 ---",
          "[Context before]",
          "5583: @inherit_doc",
          "5585:     \"\"\"",
          "5586:     Implements the transforms required for fitting a dataset against an",
          "5587:     R model formula. Currently we support a limited subset of the R",
          "",
          "[Removed Lines]",
          "5584: class RFormula(JavaEstimator, _RFormulaParams, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "6354: class RFormula(",
          "6355:     JavaEstimator[\"RFormulaModel\"],",
          "6356:     _RFormulaParams,",
          "6357:     JavaMLReadable[\"RFormula\"],",
          "6358:     JavaMLWritable,",
          "6359: ):",
          "",
          "---------------",
          "--- Hunk 196 ---",
          "[Context before]",
          "5654:     'RFormulaModel(ResolvedRFormula(label=y, terms=[x,s], hasIntercept=true)) (uid=...)'",
          "5655:     \"\"\"",
          "5657:     @keyword_only",
          "5658:     def __init__(",
          "5659:         self,",
          "5667:     ):",
          "5668:         \"\"\"",
          "5669:         __init__(self, \\\\*, formula=None, featuresCol=\"features\", labelCol=\"label\", \\",
          "",
          "[Removed Lines]",
          "5661:         formula=None,",
          "5662:         featuresCol=\"features\",",
          "5663:         labelCol=\"label\",",
          "5664:         forceIndexLabel=False,",
          "5665:         stringIndexerOrderType=\"frequencyDesc\",",
          "5666:         handleInvalid=\"error\",",
          "",
          "[Added Lines]",
          "6432:     _input_kwargs: Dict[str, Any]",
          "6438:         formula: Optional[str] = None,",
          "6439:         featuresCol: str = \"features\",",
          "6440:         labelCol: str = \"label\",",
          "6441:         forceIndexLabel: bool = False,",
          "6442:         stringIndexerOrderType: str = \"frequencyDesc\",",
          "6443:         handleInvalid: str = \"error\",",
          "",
          "---------------",
          "--- Hunk 197 ---",
          "[Context before]",
          "5680:     def setParams(",
          "5681:         self,",
          "5690:         \"\"\"",
          "5691:         setParams(self, \\\\*, formula=None, featuresCol=\"features\", labelCol=\"label\", \\",
          "5692:                   forceIndexLabel=False, stringIndexerOrderType=\"frequencyDesc\", \\",
          "",
          "[Removed Lines]",
          "5683:         formula=None,",
          "5684:         featuresCol=\"features\",",
          "5685:         labelCol=\"label\",",
          "5686:         forceIndexLabel=False,",
          "5687:         stringIndexerOrderType=\"frequencyDesc\",",
          "5688:         handleInvalid=\"error\",",
          "5689:     ):",
          "",
          "[Added Lines]",
          "6460:         formula: Optional[str] = None,",
          "6461:         featuresCol: str = \"features\",",
          "6462:         labelCol: str = \"label\",",
          "6463:         forceIndexLabel: bool = False,",
          "6464:         stringIndexerOrderType: str = \"frequencyDesc\",",
          "6465:         handleInvalid: str = \"error\",",
          "6466:     ) -> \"RFormula\":",
          "",
          "---------------",
          "--- Hunk 198 ---",
          "[Context before]",
          "5697:         return self._set(**kwargs)",
          "5699:     @since(\"1.5.0\")",
          "5701:         \"\"\"",
          "5702:         Sets the value of :py:attr:`formula`.",
          "5703:         \"\"\"",
          "5704:         return self._set(formula=value)",
          "5706:     @since(\"2.1.0\")",
          "5708:         \"\"\"",
          "5709:         Sets the value of :py:attr:`forceIndexLabel`.",
          "5710:         \"\"\"",
          "5711:         return self._set(forceIndexLabel=value)",
          "5713:     @since(\"2.3.0\")",
          "5715:         \"\"\"",
          "5716:         Sets the value of :py:attr:`stringIndexerOrderType`.",
          "5717:         \"\"\"",
          "5718:         return self._set(stringIndexerOrderType=value)",
          "5721:         \"\"\"",
          "5722:         Sets the value of :py:attr:`featuresCol`.",
          "5723:         \"\"\"",
          "5724:         return self._set(featuresCol=value)",
          "5727:         \"\"\"",
          "5728:         Sets the value of :py:attr:`labelCol`.",
          "5729:         \"\"\"",
          "5730:         return self._set(labelCol=value)",
          "5733:         \"\"\"",
          "5734:         Sets the value of :py:attr:`handleInvalid`.",
          "5735:         \"\"\"",
          "5736:         return self._set(handleInvalid=value)",
          "5739:         return RFormulaModel(java_model)",
          "5742:         formulaStr = self.getFormula() if self.isDefined(self.formula) else \"\"",
          "5743:         return \"RFormula(%s) (uid=%s)\" % (formulaStr, self.uid)",
          "5747:     \"\"\"",
          "5748:     Model fitted by :py:class:`RFormula`. Fitting is required to determine the",
          "5749:     factor levels of formula terms.",
          "",
          "[Removed Lines]",
          "5700:     def setFormula(self, value):",
          "5707:     def setForceIndexLabel(self, value):",
          "5714:     def setStringIndexerOrderType(self, value):",
          "5720:     def setFeaturesCol(self, value):",
          "5726:     def setLabelCol(self, value):",
          "5732:     def setHandleInvalid(self, value):",
          "5738:     def _create_model(self, java_model):",
          "5741:     def __str__(self):",
          "5746: class RFormulaModel(JavaModel, _RFormulaParams, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "6477:     def setFormula(self, value: str) -> \"RFormula\":",
          "6484:     def setForceIndexLabel(self, value: bool) -> \"RFormula\":",
          "6491:     def setStringIndexerOrderType(self, value: str) -> \"RFormula\":",
          "6497:     def setFeaturesCol(self, value: str) -> \"RFormula\":",
          "6503:     def setLabelCol(self, value: str) -> \"RFormula\":",
          "6509:     def setHandleInvalid(self, value: str) -> \"RFormula\":",
          "6515:     def _create_model(self, java_model: \"JavaObject\") -> \"RFormulaModel\":",
          "6518:     def __str__(self) -> str:",
          "6523: class RFormulaModel(JavaModel, _RFormulaParams, JavaMLReadable[\"RFormulaModel\"], JavaMLWritable):",
          "",
          "---------------",
          "--- Hunk 199 ---",
          "[Context before]",
          "5751:     .. versionadded:: 1.5.0",
          "5752:     \"\"\"",
          "5755:         resolvedFormula = self._call_java(\"resolvedFormula\")",
          "5756:         return \"RFormulaModel(%s) (uid=%s)\" % (resolvedFormula, self.uid)",
          "",
          "[Removed Lines]",
          "5754:     def __str__(self):",
          "",
          "[Added Lines]",
          "6531:     def __str__(self) -> str:",
          "",
          "---------------",
          "--- Hunk 200 ---",
          "[Context before]",
          "5763:     .. versionadded:: 3.1.0",
          "5764:     \"\"\"",
          "5767:         Params._dummy(),",
          "5768:         \"selectorType\",",
          "5769:         \"The selector type. \"",
          "",
          "[Removed Lines]",
          "5766:     selectorType = Param(",
          "",
          "[Added Lines]",
          "6543:     selectorType: Param[str] = Param(",
          "",
          "---------------",
          "--- Hunk 201 ---",
          "[Context before]",
          "5771:         typeConverter=TypeConverters.toString,",
          "5772:     )",
          "5775:         Params._dummy(),",
          "5776:         \"numTopFeatures\",",
          "5777:         \"Number of features that selector will select, ordered by ascending p-value. \"",
          "",
          "[Removed Lines]",
          "5774:     numTopFeatures = Param(",
          "",
          "[Added Lines]",
          "6551:     numTopFeatures: Param[int] = Param(",
          "",
          "---------------",
          "--- Hunk 202 ---",
          "[Context before]",
          "5780:         typeConverter=TypeConverters.toInt,",
          "5781:     )",
          "5784:         Params._dummy(),",
          "5785:         \"percentile\",",
          "5786:         \"Percentile of features that selector \" + \"will select, ordered by ascending p-value.\",",
          "5787:         typeConverter=TypeConverters.toFloat,",
          "5788:     )",
          "5791:         Params._dummy(),",
          "5792:         \"fpr\",",
          "5793:         \"The highest p-value for features to be kept.\",",
          "5794:         typeConverter=TypeConverters.toFloat,",
          "5795:     )",
          "5798:         Params._dummy(),",
          "5799:         \"fdr\",",
          "5800:         \"The upper bound of the expected false discovery rate.\",",
          "5801:         typeConverter=TypeConverters.toFloat,",
          "5802:     )",
          "5805:         Params._dummy(),",
          "5806:         \"fwe\",",
          "5807:         \"The upper bound of the expected family-wise error rate.\",",
          "5808:         typeConverter=TypeConverters.toFloat,",
          "5809:     )",
          "5812:         super(_SelectorParams, self).__init__(*args)",
          "5813:         self._setDefault(",
          "5814:             numTopFeatures=50,",
          "",
          "[Removed Lines]",
          "5783:     percentile = Param(",
          "5790:     fpr = Param(",
          "5797:     fdr = Param(",
          "5804:     fwe = Param(",
          "5811:     def __init__(self, *args):",
          "",
          "[Added Lines]",
          "6560:     percentile: Param[float] = Param(",
          "6567:     fpr: Param[float] = Param(",
          "6574:     fdr: Param[float] = Param(",
          "6581:     fwe: Param[float] = Param(",
          "6588:     def __init__(self, *args: Any):",
          "",
          "---------------",
          "--- Hunk 203 ---",
          "[Context before]",
          "5820:         )",
          "5822:     @since(\"2.1.0\")",
          "5824:         \"\"\"",
          "5825:         Gets the value of selectorType or its default value.",
          "5826:         \"\"\"",
          "5827:         return self.getOrDefault(self.selectorType)",
          "5829:     @since(\"2.0.0\")",
          "5831:         \"\"\"",
          "5832:         Gets the value of numTopFeatures or its default value.",
          "5833:         \"\"\"",
          "5834:         return self.getOrDefault(self.numTopFeatures)",
          "5836:     @since(\"2.1.0\")",
          "5838:         \"\"\"",
          "5839:         Gets the value of percentile or its default value.",
          "5840:         \"\"\"",
          "5841:         return self.getOrDefault(self.percentile)",
          "5843:     @since(\"2.1.0\")",
          "5845:         \"\"\"",
          "5846:         Gets the value of fpr or its default value.",
          "5847:         \"\"\"",
          "5848:         return self.getOrDefault(self.fpr)",
          "5850:     @since(\"2.2.0\")",
          "5852:         \"\"\"",
          "5853:         Gets the value of fdr or its default value.",
          "5854:         \"\"\"",
          "5855:         return self.getOrDefault(self.fdr)",
          "5857:     @since(\"2.2.0\")",
          "5859:         \"\"\"",
          "5860:         Gets the value of fwe or its default value.",
          "5861:         \"\"\"",
          "5862:         return self.getOrDefault(self.fwe)",
          "5866:     \"\"\"",
          "5867:     Mixin for Selectors.",
          "5868:     \"\"\"",
          "5870:     @since(\"2.1.0\")",
          "5872:         \"\"\"",
          "5873:         Sets the value of :py:attr:`selectorType`.",
          "5874:         \"\"\"",
          "5875:         return self._set(selectorType=value)",
          "5877:     @since(\"2.0.0\")",
          "5879:         \"\"\"",
          "5880:         Sets the value of :py:attr:`numTopFeatures`.",
          "5881:         Only applicable when selectorType = \"numTopFeatures\".",
          "",
          "[Removed Lines]",
          "5823:     def getSelectorType(self):",
          "5830:     def getNumTopFeatures(self):",
          "5837:     def getPercentile(self):",
          "5844:     def getFpr(self):",
          "5851:     def getFdr(self):",
          "5858:     def getFwe(self):",
          "5865: class _Selector(JavaEstimator, _SelectorParams, JavaMLReadable, JavaMLWritable):",
          "5871:     def setSelectorType(self, value):",
          "5878:     def setNumTopFeatures(self, value):",
          "",
          "[Added Lines]",
          "6600:     def getSelectorType(self) -> str:",
          "6607:     def getNumTopFeatures(self) -> int:",
          "6614:     def getPercentile(self) -> float:",
          "6621:     def getFpr(self) -> float:",
          "6628:     def getFdr(self) -> float:",
          "6635:     def getFwe(self) -> float:",
          "6642: class _Selector(JavaEstimator[JM], _SelectorParams, JavaMLReadable, JavaMLWritable, Generic[JM]):",
          "6648:     def setSelectorType(self: P, value: str) -> P:",
          "6655:     def setNumTopFeatures(self: P, value: int) -> P:",
          "",
          "---------------",
          "--- Hunk 204 ---",
          "[Context before]",
          "5883:         return self._set(numTopFeatures=value)",
          "5885:     @since(\"2.1.0\")",
          "5887:         \"\"\"",
          "5888:         Sets the value of :py:attr:`percentile`.",
          "5889:         Only applicable when selectorType = \"percentile\".",
          "",
          "[Removed Lines]",
          "5886:     def setPercentile(self, value):",
          "",
          "[Added Lines]",
          "6663:     def setPercentile(self: P, value: float) -> P:",
          "",
          "---------------",
          "--- Hunk 205 ---",
          "[Context before]",
          "5891:         return self._set(percentile=value)",
          "5893:     @since(\"2.1.0\")",
          "5895:         \"\"\"",
          "5896:         Sets the value of :py:attr:`fpr`.",
          "5897:         Only applicable when selectorType = \"fpr\".",
          "",
          "[Removed Lines]",
          "5894:     def setFpr(self, value):",
          "",
          "[Added Lines]",
          "6671:     def setFpr(self: P, value: float) -> P:",
          "",
          "---------------",
          "--- Hunk 206 ---",
          "[Context before]",
          "5899:         return self._set(fpr=value)",
          "5901:     @since(\"2.2.0\")",
          "5903:         \"\"\"",
          "5904:         Sets the value of :py:attr:`fdr`.",
          "5905:         Only applicable when selectorType = \"fdr\".",
          "",
          "[Removed Lines]",
          "5902:     def setFdr(self, value):",
          "",
          "[Added Lines]",
          "6679:     def setFdr(self: P, value: float) -> P:",
          "",
          "---------------",
          "--- Hunk 207 ---",
          "[Context before]",
          "5907:         return self._set(fdr=value)",
          "5909:     @since(\"2.2.0\")",
          "5911:         \"\"\"",
          "5912:         Sets the value of :py:attr:`fwe`.",
          "5913:         Only applicable when selectorType = \"fwe\".",
          "5914:         \"\"\"",
          "5915:         return self._set(fwe=value)",
          "5918:         \"\"\"",
          "5919:         Sets the value of :py:attr:`featuresCol`.",
          "5920:         \"\"\"",
          "5921:         return self._set(featuresCol=value)",
          "5924:         \"\"\"",
          "5925:         Sets the value of :py:attr:`outputCol`.",
          "5926:         \"\"\"",
          "5927:         return self._set(outputCol=value)",
          "5930:         \"\"\"",
          "5931:         Sets the value of :py:attr:`labelCol`.",
          "5932:         \"\"\"",
          "",
          "[Removed Lines]",
          "5910:     def setFwe(self, value):",
          "5917:     def setFeaturesCol(self, value):",
          "5923:     def setOutputCol(self, value):",
          "5929:     def setLabelCol(self, value):",
          "",
          "[Added Lines]",
          "6687:     def setFwe(self: P, value: float) -> P:",
          "6694:     def setFeaturesCol(self: P, value: str) -> P:",
          "6700:     def setOutputCol(self: P, value: str) -> P:",
          "6706:     def setLabelCol(self: P, value: str) -> P:",
          "",
          "---------------",
          "--- Hunk 208 ---",
          "[Context before]",
          "5939:     \"\"\"",
          "5941:     @since(\"3.0.0\")",
          "5943:         \"\"\"",
          "5944:         Sets the value of :py:attr:`featuresCol`.",
          "5945:         \"\"\"",
          "5946:         return self._set(featuresCol=value)",
          "5948:     @since(\"3.0.0\")",
          "5950:         \"\"\"",
          "5951:         Sets the value of :py:attr:`outputCol`.",
          "5952:         \"\"\"",
          "5953:         return self._set(outputCol=value)",
          "5956:     @since(\"2.0.0\")",
          "5958:         \"\"\"",
          "5959:         List of indices to select (filter).",
          "5960:         \"\"\"",
          "",
          "[Removed Lines]",
          "5942:     def setFeaturesCol(self, value):",
          "5949:     def setOutputCol(self, value):",
          "5955:     @property",
          "5957:     def selectedFeatures(self):",
          "",
          "[Added Lines]",
          "6719:     def setFeaturesCol(self: P, value: str) -> P:",
          "6726:     def setOutputCol(self: P, value: str) -> P:",
          "6732:     @property  # type: ignore[misc]",
          "6734:     def selectedFeatures(self) -> List[int]:",
          "",
          "---------------",
          "--- Hunk 209 ---",
          "[Context before]",
          "5964: @inherit_doc",
          "5966:     \"\"\"",
          "5967:     Chi-Squared feature selection, which selects categorical features to use for predicting a",
          "5968:     categorical label.",
          "",
          "[Removed Lines]",
          "5965: class ChiSqSelector(_Selector, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "6742: class ChiSqSelector(",
          "6743:     _Selector[\"ChiSqSelectorModel\"],",
          "6744:     JavaMLReadable[\"ChiSqSelector\"],",
          "6745:     JavaMLWritable,",
          "6746: ):",
          "",
          "---------------",
          "--- Hunk 210 ---",
          "[Context before]",
          "6024:     True",
          "6025:     \"\"\"",
          "6027:     @keyword_only",
          "6028:     def __init__(",
          "6029:         self,",
          "6040:     ):",
          "6041:         \"\"\"",
          "6042:         __init__(self, \\\\*, numTopFeatures=50, featuresCol=\"features\", outputCol=None, \\",
          "",
          "[Removed Lines]",
          "6031:         numTopFeatures=50,",
          "6032:         featuresCol=\"features\",",
          "6033:         outputCol=None,",
          "6034:         labelCol=\"label\",",
          "6035:         selectorType=\"numTopFeatures\",",
          "6036:         percentile=0.1,",
          "6037:         fpr=0.05,",
          "6038:         fdr=0.05,",
          "6039:         fwe=0.05,",
          "",
          "[Added Lines]",
          "6808:     _input_kwargs: Dict[str, Any]",
          "6814:         numTopFeatures: int = 50,",
          "6815:         featuresCol: str = \"features\",",
          "6816:         outputCol: Optional[str] = None,",
          "6817:         labelCol: str = \"label\",",
          "6818:         selectorType: str = \"numTopFeatures\",",
          "6819:         percentile: float = 0.1,",
          "6820:         fpr: float = 0.05,",
          "6821:         fdr: float = 0.05,",
          "6822:         fwe: float = 0.05,",
          "",
          "---------------",
          "--- Hunk 211 ---",
          "[Context before]",
          "6053:     def setParams(",
          "6054:         self,",
          "6066:         \"\"\"",
          "6067:         setParams(self, \\\\*, numTopFeatures=50, featuresCol=\"features\", outputCol=None, \\",
          "6069:                   fdr=0.05, fwe=0.05)",
          "6070:         Sets params for this ChiSqSelector.",
          "6071:         \"\"\"",
          "6072:         kwargs = self._input_kwargs",
          "6073:         return self._set(**kwargs)",
          "6076:         return ChiSqSelectorModel(java_model)",
          "6080:     \"\"\"",
          "6081:     Model fitted by :py:class:`ChiSqSelector`.",
          "",
          "[Removed Lines]",
          "6056:         numTopFeatures=50,",
          "6057:         featuresCol=\"features\",",
          "6058:         outputCol=None,",
          "6059:         labelCol=\"labels\",",
          "6060:         selectorType=\"numTopFeatures\",",
          "6061:         percentile=0.1,",
          "6062:         fpr=0.05,",
          "6063:         fdr=0.05,",
          "6064:         fwe=0.05,",
          "6065:     ):",
          "6068:                   labelCol=\"labels\", selectorType=\"numTopFeatures\", percentile=0.1, fpr=0.05, \\",
          "6075:     def _create_model(self, java_model):",
          "6079: class ChiSqSelectorModel(_SelectorModel, JavaMLReadable, JavaMLWritable):",
          "",
          "[Added Lines]",
          "6839:         numTopFeatures: int = 50,",
          "6840:         featuresCol: str = \"features\",",
          "6841:         outputCol: Optional[str] = None,",
          "6842:         labelCol: str = \"label\",",
          "6843:         selectorType: str = \"numTopFeatures\",",
          "6844:         percentile: float = 0.1,",
          "6845:         fpr: float = 0.05,",
          "6846:         fdr: float = 0.05,",
          "6847:         fwe: float = 0.05,",
          "6848:     ) -> \"ChiSqSelector\":",
          "6851:                   labelCol=\"label\", selectorType=\"numTopFeatures\", percentile=0.1, fpr=0.05, \\",
          "6858:     def _create_model(self, java_model: \"JavaObject\") -> \"ChiSqSelectorModel\":",
          "6862: class ChiSqSelectorModel(_SelectorModel, JavaMLReadable[\"ChiSqSelectorModel\"], JavaMLWritable):",
          "",
          "---------------",
          "--- Hunk 212 ---",
          "[Context before]",
          "6087: @inherit_doc",
          "6088: class VectorSizeHint(",
          "6090: ):",
          "6091:     \"\"\"",
          "6092:     A feature transformer that adds size information to the metadata of a vector column.",
          "",
          "[Removed Lines]",
          "6089:     JavaTransformer, HasInputCol, HasHandleInvalid, JavaMLReadable, JavaMLWritable",
          "",
          "[Added Lines]",
          "6872:     JavaTransformer,",
          "6873:     HasInputCol,",
          "6874:     HasHandleInvalid,",
          "6875:     JavaMLReadable[\"VectorSizeHint\"],",
          "6876:     JavaMLWritable,",
          "",
          "---------------",
          "--- Hunk 213 ---",
          "[Context before]",
          "6122:     True",
          "6123:     \"\"\"",
          "6126:         Params._dummy(), \"size\", \"Size of vectors in column.\", typeConverter=TypeConverters.toInt",
          "6127:     )",
          "6130:         Params._dummy(),",
          "6131:         \"handleInvalid\",",
          "6132:         \"How to handle invalid vectors in inputCol. Invalid vectors include \"",
          "",
          "[Removed Lines]",
          "6125:     size = Param(",
          "6129:     handleInvalid = Param(",
          "",
          "[Added Lines]",
          "6912:     size: Param[int] = Param(",
          "6916:     handleInvalid: Param[str] = Param(",
          "",
          "---------------",
          "--- Hunk 214 ---",
          "[Context before]",
          "6137:         TypeConverters.toString,",
          "6138:     )",
          "6140:     @keyword_only",
          "6142:         \"\"\"",
          "6143:         __init__(self, \\\\*, inputCol=None, size=None, handleInvalid=\"error\")",
          "6144:         \"\"\"",
          "",
          "[Removed Lines]",
          "6141:     def __init__(self, *, inputCol=None, size=None, handleInvalid=\"error\"):",
          "",
          "[Added Lines]",
          "6927:     _input_kwargs: Dict[str, Any]",
          "6930:     def __init__(",
          "6931:         self,",
          "6933:         inputCol: Optional[str] = None,",
          "6934:         size: Optional[int] = None,",
          "6935:         handleInvalid: str = \"error\",",
          "6936:     ):",
          "",
          "---------------",
          "--- Hunk 215 ---",
          "[Context before]",
          "6150:     @keyword_only",
          "6151:     @since(\"2.3.0\")",
          "6153:         \"\"\"",
          "6154:         setParams(self, \\\\*, inputCol=None, size=None, handleInvalid=\"error\")",
          "6155:         Sets params for this VectorSizeHint.",
          "",
          "[Removed Lines]",
          "6152:     def setParams(self, *, inputCol=None, size=None, handleInvalid=\"error\"):",
          "",
          "[Added Lines]",
          "6947:     def setParams(",
          "6948:         self,",
          "6950:         inputCol: Optional[str] = None,",
          "6951:         size: Optional[str] = None,",
          "6952:         handleInvalid: str = \"error\",",
          "6953:     ) -> \"VectorSizeHint\":",
          "",
          "---------------",
          "--- Hunk 216 ---",
          "[Context before]",
          "6158:         return self._set(**kwargs)",
          "6160:     @since(\"2.3.0\")",
          "6162:         \"\"\"Gets size param, the size of vectors in `inputCol`.\"\"\"",
          "6163:         return self.getOrDefault(self.size)",
          "6165:     @since(\"2.3.0\")",
          "6167:         \"\"\"Sets size param, the size of vectors in `inputCol`.\"\"\"",
          "6168:         return self._set(size=value)",
          "6171:         \"\"\"",
          "6172:         Sets the value of :py:attr:`inputCol`.",
          "6173:         \"\"\"",
          "6174:         return self._set(inputCol=value)",
          "6177:         \"\"\"",
          "6178:         Sets the value of :py:attr:`handleInvalid`.",
          "6179:         \"\"\"",
          "",
          "[Removed Lines]",
          "6161:     def getSize(self):",
          "6166:     def setSize(self, value):",
          "6170:     def setInputCol(self, value):",
          "6176:     def setHandleInvalid(self, value):",
          "",
          "[Added Lines]",
          "6962:     def getSize(self) -> int:",
          "6967:     def setSize(self, value: int) -> \"VectorSizeHint\":",
          "6971:     def setInputCol(self, value: str) -> \"VectorSizeHint\":",
          "6977:     def setHandleInvalid(self, value: str) -> \"VectorSizeHint\":",
          "",
          "---------------",
          "--- Hunk 217 ---",
          "[Context before]",
          "6188:     .. versionadded:: 3.1.0",
          "6189:     \"\"\"",
          "6192:         Params._dummy(),",
          "6193:         \"varianceThreshold\",",
          "6194:         \"Param for variance threshold. Features with a variance not \"",
          "",
          "[Removed Lines]",
          "6191:     varianceThreshold = Param(",
          "",
          "[Added Lines]",
          "6992:     varianceThreshold: Param[float] = Param(",
          "",
          "---------------",
          "--- Hunk 218 ---",
          "[Context before]",
          "6198:     )",
          "6200:     @since(\"3.1.0\")",
          "6202:         \"\"\"",
          "6203:         Gets the value of varianceThreshold or its default value.",
          "6204:         \"\"\"",
          "",
          "[Removed Lines]",
          "6201:     def getVarianceThreshold(self):",
          "",
          "[Added Lines]",
          "7002:     def getVarianceThreshold(self) -> float:",
          "",
          "---------------",
          "--- Hunk 219 ---",
          "[Context before]",
          "6208: @inherit_doc",
          "6209: class VarianceThresholdSelector(",
          "6211: ):",
          "6212:     \"\"\"",
          "6213:     Feature selector that removes all low-variance features. Features with a",
          "",
          "[Removed Lines]",
          "6210:     JavaEstimator, _VarianceThresholdSelectorParams, JavaMLReadable, JavaMLWritable",
          "",
          "[Added Lines]",
          "7011:     JavaEstimator[\"VarianceThresholdSelectorModel\"],",
          "7012:     _VarianceThresholdSelectorParams,",
          "7013:     JavaMLReadable[\"VarianceThresholdSelector\"],",
          "7014:     JavaMLWritable,",
          "",
          "---------------",
          "--- Hunk 220 ---",
          "[Context before]",
          "6252:     True",
          "6253:     \"\"\"",
          "6255:     @keyword_only",
          "6257:         \"\"\"",
          "6258:         __init__(self, \\\\*, featuresCol=\"features\", outputCol=None, varianceThreshold=0.0)",
          "6259:         \"\"\"",
          "",
          "[Removed Lines]",
          "6256:     def __init__(self, *, featuresCol=\"features\", outputCol=None, varianceThreshold=0.0):",
          "",
          "[Added Lines]",
          "7059:     _input_kwargs: Dict[str, Any]",
          "7062:     def __init__(",
          "7063:         self,",
          "7065:         featuresCol: str = \"features\",",
          "7066:         outputCol: Optional[str] = None,",
          "7067:         varianceThreshold: float = 0.0,",
          "7068:     ):",
          "",
          "---------------",
          "--- Hunk 221 ---",
          "[Context before]",
          "6268:     @keyword_only",
          "6269:     @since(\"3.1.0\")",
          "6271:         \"\"\"",
          "6272:         setParams(self, \\\\*, featuresCol=\"features\", outputCol=None, varianceThreshold=0.0)",
          "6273:         Sets params for this VarianceThresholdSelector.",
          "",
          "[Removed Lines]",
          "6270:     def setParams(self, *, featuresCol=\"features\", outputCol=None, varianceThreshold=0.0):",
          "",
          "[Added Lines]",
          "7082:     def setParams(",
          "7083:         self,",
          "7085:         featuresCol: str = \"features\",",
          "7086:         outputCol: Optional[str] = None,",
          "7087:         varianceThreshold: float = 0.0,",
          "7088:     ) -> \"VarianceThresholdSelector\":",
          "",
          "---------------",
          "--- Hunk 222 ---",
          "[Context before]",
          "6276:         return self._set(**kwargs)",
          "6278:     @since(\"3.1.0\")",
          "6280:         \"\"\"",
          "6281:         Sets the value of :py:attr:`varianceThreshold`.",
          "6282:         \"\"\"",
          "6283:         return self._set(varianceThreshold=value)",
          "6285:     @since(\"3.1.0\")",
          "6287:         \"\"\"",
          "6288:         Sets the value of :py:attr:`featuresCol`.",
          "6289:         \"\"\"",
          "6290:         return self._set(featuresCol=value)",
          "6292:     @since(\"3.1.0\")",
          "6294:         \"\"\"",
          "6295:         Sets the value of :py:attr:`outputCol`.",
          "6296:         \"\"\"",
          "6297:         return self._set(outputCol=value)",
          "6300:         return VarianceThresholdSelectorModel(java_model)",
          "6303: class VarianceThresholdSelectorModel(",
          "6305: ):",
          "6306:     \"\"\"",
          "6307:     Model fitted by :py:class:`VarianceThresholdSelector`.",
          "",
          "[Removed Lines]",
          "6279:     def setVarianceThreshold(self, value):",
          "6286:     def setFeaturesCol(self, value):",
          "6293:     def setOutputCol(self, value):",
          "6299:     def _create_model(self, java_model):",
          "6304:     JavaModel, _VarianceThresholdSelectorParams, JavaMLReadable, JavaMLWritable",
          "",
          "[Added Lines]",
          "7097:     def setVarianceThreshold(self, value: float) -> \"VarianceThresholdSelector\":",
          "7104:     def setFeaturesCol(self, value: str) -> \"VarianceThresholdSelector\":",
          "7111:     def setOutputCol(self, value: str) -> \"VarianceThresholdSelector\":",
          "7117:     def _create_model(self, java_model: \"JavaObject\") -> \"VarianceThresholdSelectorModel\":",
          "7122:     JavaModel,",
          "7123:     _VarianceThresholdSelectorParams,",
          "7124:     JavaMLReadable[\"VarianceThresholdSelectorModel\"],",
          "7125:     JavaMLWritable,",
          "",
          "---------------",
          "--- Hunk 223 ---",
          "[Context before]",
          "6310:     \"\"\"",
          "6312:     @since(\"3.1.0\")",
          "6314:         \"\"\"",
          "6315:         Sets the value of :py:attr:`featuresCol`.",
          "6316:         \"\"\"",
          "6317:         return self._set(featuresCol=value)",
          "6319:     @since(\"3.1.0\")",
          "6321:         \"\"\"",
          "6322:         Sets the value of :py:attr:`outputCol`.",
          "6323:         \"\"\"",
          "6324:         return self._set(outputCol=value)",
          "6327:     @since(\"3.1.0\")",
          "6329:         \"\"\"",
          "6330:         List of indices to select (filter).",
          "6331:         \"\"\"",
          "",
          "[Removed Lines]",
          "6313:     def setFeaturesCol(self, value):",
          "6320:     def setOutputCol(self, value):",
          "6326:     @property",
          "6328:     def selectedFeatures(self):",
          "",
          "[Added Lines]",
          "7134:     def setFeaturesCol(self, value: str) -> \"VarianceThresholdSelectorModel\":",
          "7141:     def setOutputCol(self, value: str) -> \"VarianceThresholdSelectorModel\":",
          "7147:     @property  # type: ignore[misc]",
          "7149:     def selectedFeatures(self) -> List[int]:",
          "",
          "---------------",
          "--- Hunk 224 ---",
          "[Context before]",
          "6340:     .. versionadded:: 3.1.0",
          "6341:     \"\"\"",
          "6344:         Params._dummy(),",
          "6345:         \"featureType\",",
          "6346:         \"The feature type. \" + \"Supported options: categorical, continuous.\",",
          "6347:         typeConverter=TypeConverters.toString,",
          "6348:     )",
          "6351:         Params._dummy(),",
          "6352:         \"labelType\",",
          "6353:         \"The label type. \" + \"Supported options: categorical, continuous.\",",
          "6354:         typeConverter=TypeConverters.toString,",
          "6355:     )",
          "6358:         Params._dummy(),",
          "6359:         \"selectionMode\",",
          "6360:         \"The selection mode. \"",
          "",
          "[Removed Lines]",
          "6343:     featureType = Param(",
          "6350:     labelType = Param(",
          "6357:     selectionMode = Param(",
          "",
          "[Added Lines]",
          "7164:     featureType: Param[str] = Param(",
          "7171:     labelType: Param[str] = Param(",
          "7178:     selectionMode: Param[str] = Param(",
          "",
          "---------------",
          "--- Hunk 225 ---",
          "[Context before]",
          "6363:         typeConverter=TypeConverters.toString,",
          "6364:     )",
          "6367:         Params._dummy(),",
          "6368:         \"selectionThreshold\",",
          "6369:         \"The upper bound of the \" + \"features that selector will select.\",",
          "6370:         typeConverter=TypeConverters.toFloat,",
          "6371:     )",
          "6374:         super(_UnivariateFeatureSelectorParams, self).__init__(*args)",
          "6375:         self._setDefault(selectionMode=\"numTopFeatures\")",
          "6377:     @since(\"3.1.1\")",
          "6379:         \"\"\"",
          "6380:         Gets the value of featureType or its default value.",
          "6381:         \"\"\"",
          "6382:         return self.getOrDefault(self.featureType)",
          "6384:     @since(\"3.1.1\")",
          "6386:         \"\"\"",
          "6387:         Gets the value of labelType or its default value.",
          "6388:         \"\"\"",
          "6389:         return self.getOrDefault(self.labelType)",
          "6391:     @since(\"3.1.1\")",
          "6393:         \"\"\"",
          "6394:         Gets the value of selectionMode or its default value.",
          "6395:         \"\"\"",
          "6396:         return self.getOrDefault(self.selectionMode)",
          "6398:     @since(\"3.1.1\")",
          "6400:         \"\"\"",
          "6401:         Gets the value of selectionThreshold or its default value.",
          "6402:         \"\"\"",
          "",
          "[Removed Lines]",
          "6366:     selectionThreshold = Param(",
          "6373:     def __init__(self, *args):",
          "6378:     def getFeatureType(self):",
          "6385:     def getLabelType(self):",
          "6392:     def getSelectionMode(self):",
          "6399:     def getSelectionThreshold(self):",
          "",
          "[Added Lines]",
          "7187:     selectionThreshold: Param[float] = Param(",
          "7194:     def __init__(self, *args: Any):",
          "7199:     def getFeatureType(self) -> str:",
          "7206:     def getLabelType(self) -> str:",
          "7213:     def getSelectionMode(self) -> str:",
          "7220:     def getSelectionThreshold(self) -> float:",
          "",
          "---------------",
          "--- Hunk 226 ---",
          "[Context before]",
          "6406: @inherit_doc",
          "6407: class UnivariateFeatureSelector(",
          "6409: ):",
          "6410:     \"\"\"",
          "6411:     UnivariateFeatureSelector",
          "",
          "[Removed Lines]",
          "6408:     JavaEstimator, _UnivariateFeatureSelectorParams, JavaMLReadable, JavaMLWritable",
          "",
          "[Added Lines]",
          "7229:     JavaEstimator[\"UnivariateFeatureSelectorModel\"],",
          "7230:     _UnivariateFeatureSelectorParams,",
          "7231:     JavaMLReadable[\"UnivariateFeatureSelector\"],",
          "7232:     JavaMLWritable,",
          "",
          "---------------",
          "--- Hunk 227 ---",
          "[Context before]",
          "6479:     True",
          "6480:     \"\"\"",
          "6482:     @keyword_only",
          "6483:     def __init__(",
          "6484:         self,",
          "6490:     ):",
          "6491:         \"\"\"",
          "6492:         __init__(self, \\\\*, featuresCol=\"features\", outputCol=None, \\",
          "",
          "[Removed Lines]",
          "6486:         featuresCol=\"features\",",
          "6487:         outputCol=None,",
          "6488:         labelCol=\"label\",",
          "6489:         selectionMode=\"numTopFeatures\",",
          "",
          "[Added Lines]",
          "7306:     _input_kwargs: Dict[str, Any]",
          "7312:         featuresCol: str = \"features\",",
          "7313:         outputCol: Optional[str] = None,",
          "7314:         labelCol: str = \"label\",",
          "7315:         selectionMode: str = \"numTopFeatures\",",
          "",
          "---------------",
          "--- Hunk 228 ---",
          "[Context before]",
          "6504:     def setParams(",
          "6505:         self,",
          "6512:         \"\"\"",
          "6513:         setParams(self, \\\\*, featuresCol=\"features\", outputCol=None, \\",
          "6515:         Sets params for this UnivariateFeatureSelector.",
          "6516:         \"\"\"",
          "6517:         kwargs = self._input_kwargs",
          "6518:         return self._set(**kwargs)",
          "6520:     @since(\"3.1.1\")",
          "6522:         \"\"\"",
          "6523:         Sets the value of :py:attr:`featureType`.",
          "6524:         \"\"\"",
          "6525:         return self._set(featureType=value)",
          "6527:     @since(\"3.1.1\")",
          "6529:         \"\"\"",
          "6530:         Sets the value of :py:attr:`labelType`.",
          "6531:         \"\"\"",
          "6532:         return self._set(labelType=value)",
          "6534:     @since(\"3.1.1\")",
          "6536:         \"\"\"",
          "6537:         Sets the value of :py:attr:`selectionMode`.",
          "6538:         \"\"\"",
          "6539:         return self._set(selectionMode=value)",
          "6541:     @since(\"3.1.1\")",
          "6543:         \"\"\"",
          "6544:         Sets the value of :py:attr:`selectionThreshold`.",
          "6545:         \"\"\"",
          "6546:         return self._set(selectionThreshold=value)",
          "6549:         \"\"\"",
          "6550:         Sets the value of :py:attr:`featuresCol`.",
          "6551:         \"\"\"",
          "6552:         return self._set(featuresCol=value)",
          "6555:         \"\"\"",
          "6556:         Sets the value of :py:attr:`outputCol`.",
          "6557:         \"\"\"",
          "6558:         return self._set(outputCol=value)",
          "6561:         \"\"\"",
          "6562:         Sets the value of :py:attr:`labelCol`.",
          "6563:         \"\"\"",
          "6564:         return self._set(labelCol=value)",
          "6567:         return UnivariateFeatureSelectorModel(java_model)",
          "6570: class UnivariateFeatureSelectorModel(",
          "6572: ):",
          "6573:     \"\"\"",
          "6574:     Model fitted by :py:class:`UnivariateFeatureSelector`.",
          "",
          "[Removed Lines]",
          "6507:         featuresCol=\"features\",",
          "6508:         outputCol=None,",
          "6509:         labelCol=\"labels\",",
          "6510:         selectionMode=\"numTopFeatures\",",
          "6511:     ):",
          "6514:                   labelCol=\"labels\", selectionMode=\"numTopFeatures\")",
          "6521:     def setFeatureType(self, value):",
          "6528:     def setLabelType(self, value):",
          "6535:     def setSelectionMode(self, value):",
          "6542:     def setSelectionThreshold(self, value):",
          "6548:     def setFeaturesCol(self, value):",
          "6554:     def setOutputCol(self, value):",
          "6560:     def setLabelCol(self, value):",
          "6566:     def _create_model(self, java_model):",
          "6571:     JavaModel, _UnivariateFeatureSelectorParams, JavaMLReadable, JavaMLWritable",
          "",
          "[Added Lines]",
          "7333:         featuresCol: str = \"features\",",
          "7334:         outputCol: Optional[str] = None,",
          "7335:         labelCol: str = \"label\",",
          "7336:         selectionMode: str = \"numTopFeatures\",",
          "7337:     ) -> \"UnivariateFeatureSelector\":",
          "7340:                   labelCol=\"label\", selectionMode=\"numTopFeatures\")",
          "7347:     def setFeatureType(self, value: str) -> \"UnivariateFeatureSelector\":",
          "7354:     def setLabelType(self, value: str) -> \"UnivariateFeatureSelector\":",
          "7361:     def setSelectionMode(self, value: str) -> \"UnivariateFeatureSelector\":",
          "7368:     def setSelectionThreshold(self, value: float) -> \"UnivariateFeatureSelector\":",
          "7374:     def setFeaturesCol(self, value: str) -> \"UnivariateFeatureSelector\":",
          "7380:     def setOutputCol(self, value: str) -> \"UnivariateFeatureSelector\":",
          "7386:     def setLabelCol(self, value: str) -> \"UnivariateFeatureSelector\":",
          "7392:     def _create_model(self, java_model: \"JavaObject\") -> \"UnivariateFeatureSelectorModel\":",
          "7397:     JavaModel,",
          "7398:     _UnivariateFeatureSelectorParams,",
          "7399:     JavaMLReadable[\"UnivariateFeatureSelectorModel\"],",
          "7400:     JavaMLWritable,",
          "",
          "---------------",
          "--- Hunk 229 ---",
          "[Context before]",
          "6577:     \"\"\"",
          "6579:     @since(\"3.1.1\")",
          "6581:         \"\"\"",
          "6582:         Sets the value of :py:attr:`featuresCol`.",
          "6583:         \"\"\"",
          "6584:         return self._set(featuresCol=value)",
          "6586:     @since(\"3.1.1\")",
          "6588:         \"\"\"",
          "6589:         Sets the value of :py:attr:`outputCol`.",
          "6590:         \"\"\"",
          "6591:         return self._set(outputCol=value)",
          "6594:     @since(\"3.1.1\")",
          "6596:         \"\"\"",
          "6597:         List of indices to select (filter).",
          "6598:         \"\"\"",
          "",
          "[Removed Lines]",
          "6580:     def setFeaturesCol(self, value):",
          "6587:     def setOutputCol(self, value):",
          "6593:     @property",
          "6595:     def selectedFeatures(self):",
          "",
          "[Added Lines]",
          "7409:     def setFeaturesCol(self, value: str) -> \"UnivariateFeatureSelectorModel\":",
          "7416:     def setOutputCol(self, value: str) -> \"UnivariateFeatureSelectorModel\":",
          "7422:     @property  # type: ignore[misc]",
          "7424:     def selectedFeatures(self) -> List[int]:",
          "",
          "---------------"
        ],
        "python/pyspark/ml/feature.pyi||python/pyspark/ml/feature.pyi": [
          "File: python/pyspark/ml/feature.pyi -> python/pyspark/ml/feature.pyi",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "5dfa24d154a222f25431040d4434bccb1af8fdb0",
      "candidate_info": {
        "commit_hash": "5dfa24d154a222f25431040d4434bccb1af8fdb0",
        "repo": "apache/spark",
        "commit_url": "https://github.com/apache/spark/commit/5dfa24d154a222f25431040d4434bccb1af8fdb0",
        "files": [
          "sql/catalyst/src/main/scala/org/apache/spark/sql/errors/QueryErrorsBase.scala",
          "sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/encoders/EncoderResolutionSuite.scala",
          "sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/expressions/AnsiCastSuiteBase.scala",
          "sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/expressions/CastSuite.scala",
          "sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/util/DateFormatterSuite.scala",
          "sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/util/TimestampFormatterSuite.scala",
          "sql/catalyst/src/test/scala/org/apache/spark/sql/types/DecimalSuite.scala",
          "sql/core/src/test/resources/sql-tests/results/ansi/cast.sql.out",
          "sql/core/src/test/resources/sql-tests/results/ansi/date.sql.out",
          "sql/core/src/test/resources/sql-tests/results/ansi/datetime-parsing-invalid.sql.out",
          "sql/core/src/test/resources/sql-tests/results/ansi/interval.sql.out",
          "sql/core/src/test/resources/sql-tests/results/ansi/string-functions.sql.out",
          "sql/core/src/test/resources/sql-tests/results/postgreSQL/float4.sql.out",
          "sql/core/src/test/resources/sql-tests/results/postgreSQL/float8.sql.out",
          "sql/core/src/test/resources/sql-tests/results/postgreSQL/int8.sql.out",
          "sql/core/src/test/resources/sql-tests/results/postgreSQL/text.sql.out",
          "sql/core/src/test/resources/sql-tests/results/postgreSQL/window_part2.sql.out",
          "sql/core/src/test/resources/sql-tests/results/postgreSQL/window_part3.sql.out",
          "sql/core/src/test/resources/sql-tests/results/postgreSQL/window_part4.sql.out",
          "sql/core/src/test/resources/sql-tests/results/timestampNTZ/timestamp-ansi.sql.out",
          "sql/core/src/test/scala/org/apache/spark/sql/DatasetSuite.scala",
          "sql/core/src/test/scala/org/apache/spark/sql/SQLInsertTestSuite.scala",
          "sql/core/src/test/scala/org/apache/spark/sql/errors/QueryCompilationErrorsSuite.scala",
          "sql/core/src/test/scala/org/apache/spark/sql/errors/QueryExecutionErrorsSuite.scala",
          "sql/core/src/test/scala/org/apache/spark/sql/sources/InsertSuite.scala"
        ],
        "message": "[SPARK-38996][SQL][3.3] Use double quotes for types in error messages\n\n### What changes were proposed in this pull request?\n\nThis PR is a backport of https://github.com/apache/spark/pull/36324\n\nIn the PR, I propose to modify the method `QueryErrorsBase.toSQLType()` to use double quotes for types in error messages.\n\n### Why are the changes needed?\n1. To highlight types and make them more visible for users.\n2. To be able to easily parse types from error text.\n3. To be consistent to other outputs of identifiers, sql statement and etc. where Spark uses quotes or ticks.\n\n### Does this PR introduce _any_ user-facing change?\nYes, the PR changes user-facing errors.\n\n### How was this patch tested?\nBy running the modified test suites:\n```\n$ build/sbt \"test:testOnly *QueryParsingErrorsSuite\"\n$ build/sbt \"test:testOnly *QueryCompilationErrorsSuite\"\n$ build/sbt \"test:testOnly *QueryExecutionErrorsSuite\"\n$ build/sbt \"testOnly *CastSuite\"\n$ build/sbt \"testOnly *AnsiCastSuiteWithAnsiModeOn\"\n$ build/sbt \"testOnly *EncoderResolutionSuite\"\n$ build/sbt \"test:testOnly *DatasetSuite\"\n$ build/sbt \"test:testOnly *InsertSuite\"\n```\n\nAuthored-by: Max Gekk <max.gekkgmail.com>\nSigned-off-by: Max Gekk <max.gekkgmail.com>\n(cherry picked from commit 5e494d3de70c6e46f33addd751a227e6f9d5703f)\nSigned-off-by: Max Gekk <max.gekkgmail.com>\n\nCloses #36329 from MaxGekk/wrap-types-in-error-classes-3.3.\n\nAuthored-by: Max Gekk <max.gekk@gmail.com>\nSigned-off-by: Hyukjin Kwon <gurwls223@apache.org>",
        "before_after_code_files": [
          "sql/catalyst/src/main/scala/org/apache/spark/sql/errors/QueryErrorsBase.scala||sql/catalyst/src/main/scala/org/apache/spark/sql/errors/QueryErrorsBase.scala",
          "sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/encoders/EncoderResolutionSuite.scala||sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/encoders/EncoderResolutionSuite.scala",
          "sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/expressions/AnsiCastSuiteBase.scala||sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/expressions/AnsiCastSuiteBase.scala",
          "sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/expressions/CastSuite.scala||sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/expressions/CastSuite.scala",
          "sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/util/DateFormatterSuite.scala||sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/util/DateFormatterSuite.scala",
          "sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/util/TimestampFormatterSuite.scala||sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/util/TimestampFormatterSuite.scala",
          "sql/catalyst/src/test/scala/org/apache/spark/sql/types/DecimalSuite.scala||sql/catalyst/src/test/scala/org/apache/spark/sql/types/DecimalSuite.scala",
          "sql/core/src/test/scala/org/apache/spark/sql/DatasetSuite.scala||sql/core/src/test/scala/org/apache/spark/sql/DatasetSuite.scala",
          "sql/core/src/test/scala/org/apache/spark/sql/SQLInsertTestSuite.scala||sql/core/src/test/scala/org/apache/spark/sql/SQLInsertTestSuite.scala",
          "sql/core/src/test/scala/org/apache/spark/sql/errors/QueryCompilationErrorsSuite.scala||sql/core/src/test/scala/org/apache/spark/sql/errors/QueryCompilationErrorsSuite.scala",
          "sql/core/src/test/scala/org/apache/spark/sql/errors/QueryExecutionErrorsSuite.scala||sql/core/src/test/scala/org/apache/spark/sql/errors/QueryExecutionErrorsSuite.scala",
          "sql/core/src/test/scala/org/apache/spark/sql/sources/InsertSuite.scala||sql/core/src/test/scala/org/apache/spark/sql/sources/InsertSuite.scala"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/jack-steven-root/spark/pull/1"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "sql/catalyst/src/main/scala/org/apache/spark/sql/errors/QueryErrorsBase.scala||sql/catalyst/src/main/scala/org/apache/spark/sql/errors/QueryErrorsBase.scala": [
          "File: sql/catalyst/src/main/scala/org/apache/spark/sql/errors/QueryErrorsBase.scala -> sql/catalyst/src/main/scala/org/apache/spark/sql/errors/QueryErrorsBase.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "62:   }",
          "64:   def toSQLType(t: DataType): String = {",
          "66:   }",
          "67: }",
          "",
          "[Removed Lines]",
          "65:     t.sql",
          "",
          "[Added Lines]",
          "65:     \"\\\"\" + t.sql + \"\\\"\"",
          "",
          "---------------"
        ],
        "sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/encoders/EncoderResolutionSuite.scala||sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/encoders/EncoderResolutionSuite.scala": [
          "File: sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/encoders/EncoderResolutionSuite.scala -> sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/encoders/EncoderResolutionSuite.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "88:     val attrs = Seq('arr.array(StringType))",
          "89:     assert(intercept[AnalysisException](encoder.resolveAndBind(attrs)).message ==",
          "90:       s\"\"\"",
          "92:          |The type path of the target object is:",
          "93:          |- array element class: \"scala.Long\"",
          "94:          |- field (class: \"scala.Array\", name: \"arr\")",
          "",
          "[Removed Lines]",
          "91:          |Cannot up cast array element from STRING to BIGINT.",
          "",
          "[Added Lines]",
          "91:          |Cannot up cast array element from \"STRING\" to \"BIGINT\".",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "211:       val attrs = Seq(attr)",
          "212:       assert(intercept[AnalysisException](encoder.resolveAndBind(attrs)).message ==",
          "213:         s\"\"\"",
          "215:            |The type path of the target object is:",
          "216:            |- root class: \"java.lang.String\"",
          "217:            |You can either add an explicit cast to the input data or choose a higher precision type",
          "",
          "[Removed Lines]",
          "214:            |Cannot up cast a from ${attr.dataType.sql} to STRING.",
          "",
          "[Added Lines]",
          "214:            |Cannot up cast a from \"${attr.dataType.sql}\" to \"STRING\".",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "225:     }.message",
          "226:     assert(msg1 ==",
          "227:       s\"\"\"",
          "229:          |The type path of the target object is:",
          "230:          |- field (class: \"scala.Int\", name: \"b\")",
          "231:          |- root class: \"org.apache.spark.sql.catalyst.encoders.StringIntClass\"",
          "",
          "[Removed Lines]",
          "228:          |Cannot up cast b from BIGINT to INT.",
          "",
          "[Added Lines]",
          "228:          |Cannot up cast b from \"BIGINT\" to \"INT\".",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "238:     }.message",
          "239:     assert(msg2 ==",
          "240:       s\"\"\"",
          "242:          |The type path of the target object is:",
          "243:          |- field (class: \"scala.Long\", name: \"b\")",
          "244:          |- field (class: \"org.apache.spark.sql.catalyst.encoders.StringLongClass\", name: \"b\")",
          "",
          "[Removed Lines]",
          "241:          |Cannot up cast b.`b` from DECIMAL(38,18) to BIGINT.",
          "",
          "[Added Lines]",
          "241:          |Cannot up cast b.`b` from \"DECIMAL(38,18)\" to \"BIGINT\".",
          "",
          "---------------"
        ],
        "sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/expressions/AnsiCastSuiteBase.scala||sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/expressions/AnsiCastSuiteBase.scala": [
          "File: sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/expressions/AnsiCastSuiteBase.scala -> sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/expressions/AnsiCastSuiteBase.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "177:     Seq(IntegerType, ShortType, ByteType, LongType).foreach { dataType =>",
          "178:       checkExceptionInExpression[NumberFormatException](cast(\"string\", dataType),",
          "180:       checkExceptionInExpression[NumberFormatException](cast(\"123-string\", dataType),",
          "182:       checkExceptionInExpression[NumberFormatException](cast(\"2020-07-19\", dataType),",
          "184:       checkExceptionInExpression[NumberFormatException](cast(\"1.23\", dataType),",
          "186:     }",
          "188:     Seq(DoubleType, FloatType, DecimalType.USER_DEFAULT).foreach { dataType =>",
          "189:       checkExceptionInExpression[NumberFormatException](cast(\"string\", dataType),",
          "191:       checkExceptionInExpression[NumberFormatException](cast(\"123.000.00\", dataType),",
          "193:       checkExceptionInExpression[NumberFormatException](cast(\"abc.com\", dataType),",
          "195:     }",
          "196:   }",
          "198:   protected def checkCastToNumericError(l: Literal, to: DataType,",
          "199:       expectedDataTypeInErrorMsg: DataType, tryCastResult: Any): Unit = {",
          "200:     checkExceptionInExpression[NumberFormatException](",
          "202:   }",
          "204:   test(\"cast from invalid string array to numeric array should throw NumberFormatException\") {",
          "",
          "[Removed Lines]",
          "179:         s\"Invalid input syntax for type ${dataType.sql}: 'string'\")",
          "181:         s\"Invalid input syntax for type ${dataType.sql}: '123-string'\")",
          "183:         s\"Invalid input syntax for type ${dataType.sql}: '2020-07-19'\")",
          "185:         s\"Invalid input syntax for type ${dataType.sql}: '1.23'\")",
          "190:         s\"Invalid input syntax for type ${dataType.sql}: 'string'\")",
          "192:         s\"Invalid input syntax for type ${dataType.sql}: '123.000.00'\")",
          "194:         s\"Invalid input syntax for type ${dataType.sql}: 'abc.com'\")",
          "201:       cast(l, to), s\"Invalid input syntax for type ${expectedDataTypeInErrorMsg.sql}: 'true'\")",
          "",
          "[Added Lines]",
          "179:         s\"\"\"Invalid input syntax for type \"${dataType.sql}\": 'string'\"\"\")",
          "181:         s\"\"\"Invalid input syntax for type \"${dataType.sql}\": '123-string'\"\"\")",
          "183:         s\"\"\"Invalid input syntax for type \"${dataType.sql}\": '2020-07-19'\"\"\")",
          "185:         s\"\"\"Invalid input syntax for type \"${dataType.sql}\": '1.23'\"\"\")",
          "190:         s\"\"\"Invalid input syntax for type \"${dataType.sql}\": 'string'\"\"\")",
          "192:         s\"\"\"Invalid input syntax for type \"${dataType.sql}\": '123.000.00'\"\"\")",
          "194:         s\"\"\"Invalid input syntax for type \"${dataType.sql}\": 'abc.com'\"\"\")",
          "201:       cast(l, to), s\"\"\"Invalid input syntax for type \"${expectedDataTypeInErrorMsg.sql}\": 'true'\"\"\")",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "246:     checkExceptionInExpression[NumberFormatException](",
          "247:       cast(\"abcd\", DecimalType(38, 1)),",
          "249:   }",
          "251:   protected def checkCastToBooleanError(l: Literal, to: DataType, tryCastResult: Any): Unit = {",
          "",
          "[Removed Lines]",
          "248:       s\"Invalid input syntax for type ${DecimalType(38, 1).sql}: 'abcd'\")",
          "",
          "[Added Lines]",
          "248:       s\"\"\"Invalid input syntax for type \"${DecimalType(38, 1).sql}\": 'abcd'\"\"\")",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "261:   protected def checkCastToTimestampError(l: Literal, to: DataType): Unit = {",
          "262:     checkExceptionInExpression[DateTimeException](",
          "264:   }",
          "266:   test(\"cast from timestamp II\") {",
          "",
          "[Removed Lines]",
          "263:       cast(l, to), s\"Invalid input syntax for type TIMESTAMP: ${toSQLValue(l)}\")",
          "",
          "[Added Lines]",
          "263:       cast(l, to), s\"\"\"Invalid input syntax for type \"TIMESTAMP\": ${toSQLValue(l)}\"\"\")",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "281:       assert(negativeTs.getTime < 0)",
          "282:       Seq(ByteType, ShortType, IntegerType).foreach { dt =>",
          "283:         checkExceptionInExpression[SparkArithmeticException](",
          "285:       }",
          "286:     }",
          "287:   }",
          "",
          "[Removed Lines]",
          "284:           cast(negativeTs, dt), s\"to ${dt.sql} causes overflow\")",
          "",
          "[Added Lines]",
          "284:           cast(negativeTs, dt), s\"\"\"to \"${dt.sql}\" causes overflow\"\"\")",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "292:       assert(negativeTs.getTime < 0)",
          "293:       Seq(ByteType, ShortType, IntegerType).foreach { dt =>",
          "294:         checkExceptionInExpression[SparkArithmeticException](",
          "296:       }",
          "297:       val expectedSecs = Math.floorDiv(negativeTs.getTime, MILLIS_PER_SECOND)",
          "298:       checkEvaluation(cast(negativeTs, LongType), expectedSecs)",
          "",
          "[Removed Lines]",
          "295:           cast(negativeTs, dt), s\"to ${dt.sql} causes overflow\")",
          "",
          "[Added Lines]",
          "295:           cast(negativeTs, dt), s\"\"\"to \"${dt.sql}\" causes overflow\"\"\")",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "371:       assert(ret.resolved == !isTryCast)",
          "372:       if (!isTryCast) {",
          "373:         checkExceptionInExpression[NumberFormatException](",
          "375:       }",
          "376:     }",
          "",
          "[Removed Lines]",
          "374:           ret, s\"Invalid input syntax for type ${IntegerType.sql}\")",
          "",
          "[Added Lines]",
          "374:           ret, s\"\"\"Invalid input syntax for type \"${IntegerType.sql}\"\"\"\")",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "389:       assert(ret.resolved == !isTryCast)",
          "390:       if (!isTryCast) {",
          "391:         checkExceptionInExpression[NumberFormatException](",
          "393:       }",
          "394:     }",
          "395:   }",
          "",
          "[Removed Lines]",
          "392:           ret, s\"Invalid input syntax for type ${IntegerType.sql}\")",
          "",
          "[Added Lines]",
          "392:           ret, s\"\"\"Invalid input syntax for type \"${IntegerType.sql}\"\"\"\")",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "514:     assert(ret.resolved === !isTryCast)",
          "515:     if (!isTryCast) {",
          "516:       checkExceptionInExpression[NumberFormatException](",
          "518:     }",
          "519:   }",
          "",
          "[Removed Lines]",
          "517:         ret, s\"Invalid input syntax for type ${IntegerType.sql}\")",
          "",
          "[Added Lines]",
          "517:         ret, s\"\"\"Invalid input syntax for type \"${IntegerType.sql}\"\"\"\")",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "523:       def checkCastWithParseError(str: String): Unit = {",
          "524:         checkExceptionInExpression[DateTimeException](",
          "525:           cast(Literal(str), TimestampType, Option(zid.getId)),",
          "527:       }",
          "529:       checkCastWithParseError(\"123\")",
          "",
          "[Removed Lines]",
          "526:           s\"Invalid input syntax for type TIMESTAMP: '$str'\")",
          "",
          "[Added Lines]",
          "526:           s\"\"\"Invalid input syntax for type \"TIMESTAMP\": '$str'\"\"\")",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "544:       def checkCastWithParseError(str: String): Unit = {",
          "545:         checkExceptionInExpression[DateTimeException](",
          "546:           cast(Literal(str), DateType, Option(zid.getId)),",
          "548:       }",
          "550:       checkCastWithParseError(\"2015-13-18\")",
          "",
          "[Removed Lines]",
          "547:           s\"Invalid input syntax for type DATE: '$str'\")",
          "",
          "[Added Lines]",
          "547:           s\"\"\"Invalid input syntax for type \"DATE\": '$str'\"\"\")",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "572:       \"2021-06-17 00:00:00ABC\").foreach { invalidInput =>",
          "573:       checkExceptionInExpression[DateTimeException](",
          "574:         cast(invalidInput, TimestampNTZType),",
          "576:     }",
          "577:   }",
          "578: }",
          "",
          "[Removed Lines]",
          "575:         s\"Invalid input syntax for type TIMESTAMP_NTZ: '$invalidInput'\")",
          "",
          "[Added Lines]",
          "575:         s\"\"\"Invalid input syntax for type \"TIMESTAMP_NTZ\": '$invalidInput'\"\"\")",
          "",
          "---------------"
        ],
        "sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/expressions/CastSuite.scala||sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/expressions/CastSuite.scala": [
          "File: sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/expressions/CastSuite.scala -> sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/expressions/CastSuite.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "592:       val e1 = intercept[ArithmeticException] {",
          "593:         Cast(Literal(Byte.MaxValue + 1), ByteType).eval()",
          "594:       }.getMessage",
          "596:       val e2 = intercept[ArithmeticException] {",
          "597:         Cast(Literal(Short.MaxValue + 1), ShortType).eval()",
          "598:       }.getMessage",
          "600:       val e3 = intercept[ArithmeticException] {",
          "601:         Cast(Literal(Int.MaxValue + 1L), IntegerType).eval()",
          "602:       }.getMessage",
          "604:     }",
          "605:   }",
          "",
          "[Removed Lines]",
          "595:       assert(e1.contains(\"Casting 128 to TINYINT causes overflow\"))",
          "599:       assert(e2.contains(\"Casting 32768 to SMALLINT causes overflow\"))",
          "603:       assert(e3.contains(\"Casting 2147483648L to INT causes overflow\"))",
          "",
          "[Added Lines]",
          "595:       assert(e1.contains(\"Casting 128 to \\\"TINYINT\\\" causes overflow\"))",
          "599:       assert(e2.contains(\"Casting 32768 to \\\"SMALLINT\\\" causes overflow\"))",
          "603:       assert(e3.contains(\"Casting 2147483648L to \\\"INT\\\" causes overflow\"))",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "642:           checkEvaluation(cast(v2, LongType), 25L)",
          "643:         case MINUTE =>",
          "644:           checkExceptionInExpression[ArithmeticException](cast(v2, ByteType),",
          "646:           checkEvaluation(cast(v2, ShortType), (MINUTES_PER_HOUR * 25 + 1).toShort)",
          "647:           checkEvaluation(cast(v2, IntegerType), (MINUTES_PER_HOUR * 25 + 1).toInt)",
          "648:           checkEvaluation(cast(v2, LongType), MINUTES_PER_HOUR * 25 + 1)",
          "649:         case SECOND =>",
          "650:           checkExceptionInExpression[ArithmeticException](cast(v2, ByteType),",
          "652:           checkExceptionInExpression[ArithmeticException](cast(v2, ShortType),",
          "654:           checkEvaluation(cast(v2, IntegerType), num.toInt)",
          "655:           checkEvaluation(cast(v2, LongType), num)",
          "656:       }",
          "",
          "[Removed Lines]",
          "645:             s\"Casting $v2 to TINYINT causes overflow\")",
          "651:             s\"Casting $v2 to TINYINT causes overflow\")",
          "653:             s\"Casting $v2 to SMALLINT causes overflow\")",
          "",
          "[Added Lines]",
          "645:             s\"\"\"Casting $v2 to \"TINYINT\" causes overflow\"\"\")",
          "651:             s\"\"\"Casting $v2 to \"TINYINT\" causes overflow\"\"\")",
          "653:             s\"\"\"Casting $v2 to \"SMALLINT\" causes overflow\"\"\")",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "659:       dt.endField match {",
          "660:         case DAY =>",
          "661:           checkExceptionInExpression[ArithmeticException](cast(v3, ByteType),",
          "663:           checkExceptionInExpression[ArithmeticException](cast(v3, ShortType),",
          "665:           checkEvaluation(cast(v3, IntegerType), (Long.MaxValue / MICROS_PER_DAY).toInt)",
          "666:           checkEvaluation(cast(v3, LongType), Long.MaxValue / MICROS_PER_DAY)",
          "667:         case HOUR =>",
          "668:           checkExceptionInExpression[ArithmeticException](cast(v3, ByteType),",
          "670:           checkExceptionInExpression[ArithmeticException](cast(v3, ShortType),",
          "672:           checkExceptionInExpression[ArithmeticException](cast(v3, IntegerType),",
          "674:           checkEvaluation(cast(v3, LongType), Long.MaxValue / MICROS_PER_HOUR)",
          "675:         case MINUTE =>",
          "676:           checkExceptionInExpression[ArithmeticException](cast(v3, ByteType),",
          "678:           checkExceptionInExpression[ArithmeticException](cast(v3, ShortType),",
          "680:           checkExceptionInExpression[ArithmeticException](cast(v3, IntegerType),",
          "682:           checkEvaluation(cast(v3, LongType), Long.MaxValue / MICROS_PER_MINUTE)",
          "683:         case SECOND =>",
          "684:           checkExceptionInExpression[ArithmeticException](cast(v3, ByteType),",
          "686:           checkExceptionInExpression[ArithmeticException](cast(v3, ShortType),",
          "688:           checkExceptionInExpression[ArithmeticException](cast(v3, IntegerType),",
          "690:           checkEvaluation(cast(v3, LongType), Long.MaxValue / MICROS_PER_SECOND)",
          "691:       }",
          "",
          "[Removed Lines]",
          "662:             s\"Casting $v3 to TINYINT causes overflow\")",
          "664:             s\"Casting $v3 to SMALLINT causes overflow\")",
          "669:             s\"Casting $v3 to TINYINT causes overflow\")",
          "671:             s\"Casting $v3 to SMALLINT causes overflow\")",
          "673:             s\"Casting $v3 to INT causes overflow\")",
          "677:             s\"Casting $v3 to TINYINT causes overflow\")",
          "679:             s\"Casting $v3 to SMALLINT causes overflow\")",
          "681:             s\"Casting $v3 to INT causes overflow\")",
          "685:             s\"Casting $v3 to TINYINT causes overflow\")",
          "687:             s\"Casting $v3 to SMALLINT causes overflow\")",
          "689:             s\"Casting $v3 to INT causes overflow\")",
          "",
          "[Added Lines]",
          "662:             s\"\"\"Casting $v3 to \"TINYINT\" causes overflow\"\"\")",
          "664:             s\"\"\"Casting $v3 to \"SMALLINT\" causes overflow\"\"\")",
          "669:             s\"\"\"Casting $v3 to \"TINYINT\" causes overflow\"\"\")",
          "671:             s\"\"\"Casting $v3 to \"SMALLINT\" causes overflow\"\"\")",
          "673:             s\"\"\"Casting $v3 to \"INT\" causes overflow\"\"\")",
          "677:             s\"\"\"Casting $v3 to \"TINYINT\" causes overflow\"\"\")",
          "679:             s\"\"\"Casting $v3 to \"SMALLINT\" causes overflow\"\"\")",
          "681:             s\"\"\"Casting $v3 to \"INT\" causes overflow\"\"\")",
          "685:             s\"\"\"Casting $v3 to \"TINYINT\" causes overflow\"\"\")",
          "687:             s\"\"\"Casting $v3 to \"SMALLINT\" causes overflow\"\"\")",
          "689:             s\"\"\"Casting $v3 to \"INT\" causes overflow\"\"\")",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "694:       dt.endField match {",
          "695:         case DAY =>",
          "696:           checkExceptionInExpression[ArithmeticException](cast(v4, ByteType),",
          "698:           checkExceptionInExpression[ArithmeticException](cast(v4, ShortType),",
          "700:           checkEvaluation(cast(v4, IntegerType), (Long.MinValue / MICROS_PER_DAY).toInt)",
          "701:           checkEvaluation(cast(v4, LongType), Long.MinValue / MICROS_PER_DAY)",
          "702:         case HOUR =>",
          "703:           checkExceptionInExpression[ArithmeticException](cast(v4, ByteType),",
          "705:           checkExceptionInExpression[ArithmeticException](cast(v4, ShortType),",
          "707:           checkExceptionInExpression[ArithmeticException](cast(v4, IntegerType),",
          "709:           checkEvaluation(cast(v4, LongType), Long.MinValue / MICROS_PER_HOUR)",
          "710:         case MINUTE =>",
          "711:           checkExceptionInExpression[ArithmeticException](cast(v4, ByteType),",
          "713:           checkExceptionInExpression[ArithmeticException](cast(v4, ShortType),",
          "715:           checkExceptionInExpression[ArithmeticException](cast(v4, IntegerType),",
          "717:           checkEvaluation(cast(v4, LongType), Long.MinValue / MICROS_PER_MINUTE)",
          "718:         case SECOND =>",
          "719:           checkExceptionInExpression[ArithmeticException](cast(v4, ByteType),",
          "721:           checkExceptionInExpression[ArithmeticException](cast(v4, ShortType),",
          "723:           checkExceptionInExpression[ArithmeticException](cast(v4, IntegerType),",
          "725:           checkEvaluation(cast(v4, LongType), Long.MinValue / MICROS_PER_SECOND)",
          "726:       }",
          "727:     }",
          "",
          "[Removed Lines]",
          "697:             s\"Casting $v4 to TINYINT causes overflow\")",
          "699:             s\"Casting $v4 to SMALLINT causes overflow\")",
          "704:             s\"Casting $v4 to TINYINT causes overflow\")",
          "706:             s\"Casting $v4 to SMALLINT causes overflow\")",
          "708:             s\"Casting $v4 to INT causes overflow\")",
          "712:             s\"Casting $v4 to TINYINT causes overflow\")",
          "714:             s\"Casting $v4 to SMALLINT causes overflow\")",
          "716:             s\"Casting $v4 to INT causes overflow\")",
          "720:             s\"Casting $v4 to TINYINT causes overflow\")",
          "722:             s\"Casting $v4 to SMALLINT causes overflow\")",
          "724:             s\"Casting $v4 to INT causes overflow\")",
          "",
          "[Added Lines]",
          "697:             s\"\"\"Casting $v4 to \"TINYINT\" causes overflow\"\"\")",
          "699:             s\"\"\"Casting $v4 to \"SMALLINT\" causes overflow\"\"\")",
          "704:             s\"\"\"Casting $v4 to \"TINYINT\" causes overflow\"\"\")",
          "706:             s\"\"\"Casting $v4 to \"SMALLINT\" causes overflow\"\"\")",
          "708:             s\"\"\"Casting $v4 to \"INT\" causes overflow\"\"\")",
          "712:             s\"\"\"Casting $v4 to \"TINYINT\" causes overflow\"\"\")",
          "714:             s\"\"\"Casting $v4 to \"SMALLINT\" causes overflow\"\"\")",
          "716:             s\"\"\"Casting $v4 to \"INT\" causes overflow\"\"\")",
          "720:             s\"\"\"Casting $v4 to \"TINYINT\" causes overflow\"\"\")",
          "722:             s\"\"\"Casting $v4 to \"SMALLINT\" causes overflow\"\"\")",
          "724:             s\"\"\"Casting $v4 to \"INT\" causes overflow\"\"\")",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "777:     ).foreach {",
          "778:       case (v, toType) =>",
          "779:         checkExceptionInExpression[ArithmeticException](cast(v, toType),",
          "781:     }",
          "783:     Seq(",
          "",
          "[Removed Lines]",
          "780:           s\"Casting $v to ${toType.sql} causes overflow\")",
          "",
          "[Added Lines]",
          "780:           s\"\"\"Casting $v to \"${toType.sql}\" causes overflow\"\"\")",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "792:     ).foreach {",
          "793:       case (v, toType) =>",
          "794:         checkExceptionInExpression[ArithmeticException](cast(v, toType),",
          "796:     }",
          "797:   }",
          "",
          "[Removed Lines]",
          "795:           s\"Casting ${v}L to ${toType.sql} causes overflow\")",
          "",
          "[Added Lines]",
          "795:           s\"\"\"Casting ${v}L to \"${toType.sql}\" causes overflow\"\"\")",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "829:       case (v, dt, toType) =>",
          "830:         val value = Literal.create(v, dt)",
          "831:         checkExceptionInExpression[ArithmeticException](cast(value, toType),",
          "833:     }",
          "835:     Seq(",
          "",
          "[Removed Lines]",
          "832:           s\"Casting $value to ${toType.sql} causes overflow\")",
          "",
          "[Added Lines]",
          "832:           s\"\"\"Casting $value to \"${toType.sql}\" causes overflow\"\"\")",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "887:     ).foreach {",
          "888:       case (v, toType) =>",
          "889:         checkExceptionInExpression[ArithmeticException](cast(v, toType),",
          "891:     }",
          "893:     Seq(",
          "",
          "[Removed Lines]",
          "890:           s\"Casting $v to ${toType.sql} causes overflow\")",
          "",
          "[Added Lines]",
          "890:           s\"\"\"Casting $v to \"${toType.sql}\" causes overflow\"\"\")",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "898:     ).foreach {",
          "899:       case (v, toType) =>",
          "900:         checkExceptionInExpression[ArithmeticException](cast(v, toType),",
          "902:     }",
          "903:   }",
          "904: }",
          "",
          "[Removed Lines]",
          "901:           s\"Casting ${v}L to ${toType.sql} causes overflow\")",
          "",
          "[Added Lines]",
          "901:           s\"\"\"Casting ${v}L to \"${toType.sql}\" causes overflow\"\"\")",
          "",
          "---------------"
        ],
        "sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/util/DateFormatterSuite.scala||sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/util/DateFormatterSuite.scala": [
          "File: sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/util/DateFormatterSuite.scala -> sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/util/DateFormatterSuite.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "208:     val errMsg = intercept[DateTimeException] {",
          "209:       formatter.parse(\"x123\")",
          "210:     }.getMessage",
          "212:   }",
          "213: }",
          "",
          "[Removed Lines]",
          "211:     assert(errMsg.contains(\"Invalid input syntax for type DATE: 'x123'\"))",
          "",
          "[Added Lines]",
          "211:     assert(errMsg.contains(\"\"\"Invalid input syntax for type \"DATE\": 'x123'\"\"\"))",
          "",
          "---------------"
        ],
        "sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/util/TimestampFormatterSuite.scala||sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/util/TimestampFormatterSuite.scala": [
          "File: sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/util/TimestampFormatterSuite.scala -> sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/util/TimestampFormatterSuite.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "453:       val errMsg = intercept[DateTimeException] {",
          "454:         formatter.parse(\"x123\")",
          "455:       }.getMessage",
          "457:     }",
          "458:   }",
          "459: }",
          "",
          "[Removed Lines]",
          "456:       assert(errMsg.contains(\"Invalid input syntax for type TIMESTAMP: 'x123'\"))",
          "",
          "[Added Lines]",
          "456:       assert(errMsg.contains(\"\"\"Invalid input syntax for type \"TIMESTAMP\": 'x123'\"\"\"))",
          "",
          "---------------"
        ],
        "sql/catalyst/src/test/scala/org/apache/spark/sql/types/DecimalSuite.scala||sql/catalyst/src/test/scala/org/apache/spark/sql/types/DecimalSuite.scala": [
          "File: sql/catalyst/src/test/scala/org/apache/spark/sql/types/DecimalSuite.scala -> sql/catalyst/src/test/scala/org/apache/spark/sql/types/DecimalSuite.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "285:     assert(Decimal.fromString(UTF8String.fromString(\"str\")) === null)",
          "286:     val e = intercept[NumberFormatException](Decimal.fromStringANSI(UTF8String.fromString(\"str\")))",
          "287:     assert(e.getMessage.contains(\"Invalid input syntax for type \" +",
          "289:   }",
          "291:   test(\"SPARK-35841: Casting string to decimal type doesn't work \" +",
          "",
          "[Removed Lines]",
          "288:       s\"${DecimalType.USER_DEFAULT.sql}: 'str'\"))",
          "",
          "[Added Lines]",
          "288:       s\"\"\"\"${DecimalType.USER_DEFAULT.sql}\": 'str'\"\"\"))",
          "",
          "---------------"
        ],
        "sql/core/src/test/scala/org/apache/spark/sql/DatasetSuite.scala||sql/core/src/test/scala/org/apache/spark/sql/DatasetSuite.scala": [
          "File: sql/core/src/test/scala/org/apache/spark/sql/DatasetSuite.scala -> sql/core/src/test/scala/org/apache/spark/sql/DatasetSuite.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "1951:         .map(b => b - 1)",
          "1952:         .collect()",
          "1953:     }",
          "1955:   }",
          "1957:   test(\"SPARK-26690: checkpoints should be executed with an execution id\") {",
          "",
          "[Removed Lines]",
          "1954:     assert(thrownException.message.contains(\"Cannot up cast id from BIGINT to TINYINT\"))",
          "",
          "[Added Lines]",
          "1954:     assert(thrownException.message.contains(\"\"\"Cannot up cast id from \"BIGINT\" to \"TINYINT\"\"\"\"))",
          "",
          "---------------"
        ],
        "sql/core/src/test/scala/org/apache/spark/sql/SQLInsertTestSuite.scala||sql/core/src/test/scala/org/apache/spark/sql/SQLInsertTestSuite.scala": [
          "File: sql/core/src/test/scala/org/apache/spark/sql/SQLInsertTestSuite.scala -> sql/core/src/test/scala/org/apache/spark/sql/SQLInsertTestSuite.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "302:             val errorMsg = intercept[NumberFormatException] {",
          "303:               sql(\"insert into t partition(a='ansi') values('ansi')\")",
          "304:             }.getMessage",
          "306:           } else {",
          "307:             sql(\"insert into t partition(a='ansi') values('ansi')\")",
          "308:             checkAnswer(sql(\"select * from t\"), Row(\"ansi\", null) :: Nil)",
          "",
          "[Removed Lines]",
          "305:             assert(errorMsg.contains(\"Invalid input syntax for type INT: 'ansi'\"))",
          "",
          "[Added Lines]",
          "305:             assert(errorMsg.contains(\"\"\"Invalid input syntax for type \"INT\": 'ansi'\"\"\"))",
          "",
          "---------------"
        ],
        "sql/core/src/test/scala/org/apache/spark/sql/errors/QueryCompilationErrorsSuite.scala||sql/core/src/test/scala/org/apache/spark/sql/errors/QueryCompilationErrorsSuite.scala": [
          "File: sql/core/src/test/scala/org/apache/spark/sql/errors/QueryCompilationErrorsSuite.scala -> sql/core/src/test/scala/org/apache/spark/sql/errors/QueryCompilationErrorsSuite.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "37:     }.message",
          "38:     assert(msg1 ===",
          "39:       s\"\"\"",
          "41:          |The type path of the target object is:",
          "42:          |- field (class: \"scala.Int\", name: \"b\")",
          "43:          |- root class: \"org.apache.spark.sql.errors.StringIntClass\"",
          "",
          "[Removed Lines]",
          "40:          |Cannot up cast b from BIGINT to INT.",
          "",
          "[Added Lines]",
          "40:          |Cannot up cast b from \"BIGINT\" to \"INT\".",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "51:     }.message",
          "52:     assert(msg2 ===",
          "53:       s\"\"\"",
          "55:          |The type path of the target object is:",
          "56:          |- field (class: \"scala.Long\", name: \"b\")",
          "57:          |- field (class: \"org.apache.spark.sql.errors.StringLongClass\", name: \"b\")",
          "",
          "[Removed Lines]",
          "54:          |Cannot up cast b.`b` from DECIMAL(38,18) to BIGINT.",
          "",
          "[Added Lines]",
          "54:          |Cannot up cast b.`b` from \"DECIMAL(38,18)\" to \"BIGINT\".",
          "",
          "---------------"
        ],
        "sql/core/src/test/scala/org/apache/spark/sql/errors/QueryExecutionErrorsSuite.scala||sql/core/src/test/scala/org/apache/spark/sql/errors/QueryExecutionErrorsSuite.scala": [
          "File: sql/core/src/test/scala/org/apache/spark/sql/errors/QueryExecutionErrorsSuite.scala -> sql/core/src/test/scala/org/apache/spark/sql/errors/QueryExecutionErrorsSuite.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "142:         .collect()",
          "143:     }",
          "144:     assert(e2.getMessage === \"The feature is not supported: pivoting by the value\" +",
          "146:   }",
          "148:   test(\"UNSUPPORTED_FEATURE: unsupported pivot operations\") {",
          "",
          "[Removed Lines]",
          "145:       \"\"\" '[dotnet,Dummies]' of the column data type STRUCT<col1: STRING, training: STRING>.\"\"\")",
          "",
          "[Added Lines]",
          "145:       \"\"\" '[dotnet,Dummies]' of the column data type \"STRUCT<col1: STRING, training: STRING>\".\"\"\")",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "237:     assert(e.getErrorClass === \"UNSUPPORTED_OPERATION\")",
          "238:     assert(e.getMessage === \"The operation is not supported: \" +",
          "240:   }",
          "242:   test(\"UNSUPPORTED_OPERATION - SPARK-36346: can't read Timestamp as TimestampNTZ\") {",
          "",
          "[Removed Lines]",
          "239:       \"TIMESTAMP must supply timeZoneId parameter while converting to the arrow timestamp type.\")",
          "",
          "[Added Lines]",
          "239:       \"\\\"TIMESTAMP\\\" must supply timeZoneId parameter \" +",
          "240:       \"while converting to the arrow timestamp type.\")",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "250:         assert(e.getErrorClass === \"UNSUPPORTED_OPERATION\")",
          "251:         assert(e.getMessage === \"The operation is not supported: \" +",
          "253:       }",
          "254:     }",
          "255:   }",
          "",
          "[Removed Lines]",
          "252:           \"Unable to convert TIMESTAMP of Orc to data type TIMESTAMP_NTZ.\")",
          "",
          "[Added Lines]",
          "253:           \"Unable to convert \\\"TIMESTAMP\\\" of Orc to data type \\\"TIMESTAMP_NTZ\\\".\")",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "265:         assert(e.getErrorClass === \"UNSUPPORTED_OPERATION\")",
          "266:         assert(e.getMessage === \"The operation is not supported: \" +",
          "268:       }",
          "269:     }",
          "270:   }",
          "",
          "[Removed Lines]",
          "267:           \"Unable to convert TIMESTAMP_NTZ of Orc to data type TIMESTAMP.\")",
          "",
          "[Added Lines]",
          "268:           \"Unable to convert \\\"TIMESTAMP_NTZ\\\" of Orc to data type \\\"TIMESTAMP\\\".\")",
          "",
          "---------------"
        ],
        "sql/core/src/test/scala/org/apache/spark/sql/sources/InsertSuite.scala||sql/core/src/test/scala/org/apache/spark/sql/sources/InsertSuite.scala": [
          "File: sql/core/src/test/scala/org/apache/spark/sql/sources/InsertSuite.scala -> sql/core/src/test/scala/org/apache/spark/sql/sources/InsertSuite.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "713:         var msg = intercept[SparkException] {",
          "714:           sql(s\"insert into t values($outOfRangeValue1)\")",
          "715:         }.getCause.getMessage",
          "718:         val outOfRangeValue2 = (Int.MinValue - 1L).toString",
          "719:         msg = intercept[SparkException] {",
          "720:           sql(s\"insert into t values($outOfRangeValue2)\")",
          "721:         }.getCause.getMessage",
          "723:       }",
          "724:     }",
          "725:   }",
          "",
          "[Removed Lines]",
          "716:         assert(msg.contains(s\"Casting ${outOfRangeValue1}L to INT causes overflow\"))",
          "722:         assert(msg.contains(s\"Casting ${outOfRangeValue2}L to INT causes overflow\"))",
          "",
          "[Added Lines]",
          "716:         assert(msg.contains(s\"\"\"Casting ${outOfRangeValue1}L to \"INT\" causes overflow\"\"\"))",
          "722:         assert(msg.contains(s\"\"\"Casting ${outOfRangeValue2}L to \"INT\" causes overflow\"\"\"))",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "733:         var msg = intercept[SparkException] {",
          "734:           sql(s\"insert into t values(${outOfRangeValue1}D)\")",
          "735:         }.getCause.getMessage",
          "738:         val outOfRangeValue2 = Math.nextDown(Long.MinValue)",
          "739:         msg = intercept[SparkException] {",
          "740:           sql(s\"insert into t values(${outOfRangeValue2}D)\")",
          "741:         }.getCause.getMessage",
          "743:       }",
          "744:     }",
          "745:   }",
          "",
          "[Removed Lines]",
          "736:         assert(msg.contains(s\"Casting ${outOfRangeValue1}D to BIGINT causes overflow\"))",
          "742:         assert(msg.contains(s\"Casting ${outOfRangeValue2}D to BIGINT causes overflow\"))",
          "",
          "[Added Lines]",
          "736:         assert(msg.contains(s\"\"\"Casting ${outOfRangeValue1}D to \"BIGINT\" causes overflow\"\"\"))",
          "742:         assert(msg.contains(s\"\"\"Casting ${outOfRangeValue2}D to \"BIGINT\" causes overflow\"\"\"))",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "e54dc43e750be23062422ca096d1e8439178a1d1",
      "candidate_info": {
        "commit_hash": "e54dc43e750be23062422ca096d1e8439178a1d1",
        "repo": "apache/spark",
        "commit_url": "https://github.com/apache/spark/commit/e54dc43e750be23062422ca096d1e8439178a1d1",
        "files": [
          "sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/InjectRuntimeFilter.scala",
          "sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/joins.scala",
          "sql/catalyst/src/main/scala/org/apache/spark/sql/internal/SQLConf.scala",
          "sql/core/src/main/scala/org/apache/spark/sql/execution/dynamicpruning/PartitionPruning.scala",
          "sql/core/src/test/scala/org/apache/spark/sql/InjectRuntimeFilterSuite.scala"
        ],
        "message": "[SPARK-38565][SQL] Support Left Semi join in row level runtime filters\n\n### What changes were proposed in this pull request?\n\n1. Support Left Semi join in row level runtime filters.\n2. Rename `spark.sql.optimizer.runtime.bloomFilter.applicationSideScanSizethreshold` to `spark.sql.optimizer.runtime.bloomFilter.applicationSideScanSizeThreshold`.\n\n### Why are the changes needed?\n\nImprove query performance and make the code easier to maintain.\n\n### Does this PR introduce _any_ user-facing change?\n\nNo.\n\n### How was this patch tested?\n\nExisting UT.\n\nCloses #36131 from wangyum/SPARK-38565.\n\nAuthored-by: Yuming Wang <yumwang@ebay.com>\nSigned-off-by: Yuming Wang <yumwang@ebay.com>\n(cherry picked from commit 073fd2ad5c16d193725954e76ce357e4a9d97449)\nSigned-off-by: Yuming Wang <yumwang@ebay.com>",
        "before_after_code_files": [
          "sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/InjectRuntimeFilter.scala||sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/InjectRuntimeFilter.scala",
          "sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/joins.scala||sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/joins.scala",
          "sql/catalyst/src/main/scala/org/apache/spark/sql/internal/SQLConf.scala||sql/catalyst/src/main/scala/org/apache/spark/sql/internal/SQLConf.scala",
          "sql/core/src/main/scala/org/apache/spark/sql/execution/dynamicpruning/PartitionPruning.scala||sql/core/src/main/scala/org/apache/spark/sql/execution/dynamicpruning/PartitionPruning.scala",
          "sql/core/src/test/scala/org/apache/spark/sql/InjectRuntimeFilterSuite.scala||sql/core/src/test/scala/org/apache/spark/sql/InjectRuntimeFilterSuite.scala"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/jack-steven-root/spark/pull/1"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/InjectRuntimeFilter.scala||sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/InjectRuntimeFilter.scala": [
          "File: sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/InjectRuntimeFilter.scala -> sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/InjectRuntimeFilter.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: import org.apache.spark.sql.catalyst.expressions._",
          "21: import org.apache.spark.sql.catalyst.expressions.aggregate.{AggregateExpression, BloomFilterAggregate, Complete}",
          "22: import org.apache.spark.sql.catalyst.planning.{ExtractEquiJoinKeys, PhysicalOperation}",
          "24: import org.apache.spark.sql.catalyst.plans.logical._",
          "25: import org.apache.spark.sql.catalyst.rules.Rule",
          "26: import org.apache.spark.sql.catalyst.trees.TreePattern.{INVOKE, JSON_TO_STRUCT, LIKE_FAMLIY, PYTHON_UDF, REGEXP_EXTRACT_FAMILY, REGEXP_REPLACE, SCALA_UDF}",
          "",
          "[Removed Lines]",
          "23: import org.apache.spark.sql.catalyst.plans._",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "132:       REGEXP_EXTRACT_FAMILY, REGEXP_REPLACE)",
          "133:   }",
          "145:   private def isProbablyShuffleJoin(left: LogicalPlan,",
          "146:       right: LogicalPlan, hint: JoinHint): Boolean = {",
          "147:     !hintToBroadcastLeft(hint) && !hintToBroadcastRight(hint) &&",
          "",
          "[Removed Lines]",
          "135:   private def canFilterLeft(joinType: JoinType): Boolean = joinType match {",
          "136:     case Inner | RightOuter => true",
          "137:     case _ => false",
          "138:   }",
          "140:   private def canFilterRight(joinType: JoinType): Boolean = joinType match {",
          "141:     case Inner | LeftOuter => true",
          "142:     case _ => false",
          "143:   }",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "149:   }",
          "151:   private def probablyHasShuffle(plan: LogicalPlan): Boolean = {",
          "157:   }",
          "",
          "[Removed Lines]",
          "152:     plan.collectFirst {",
          "153:       case j@Join(left, right, _, _, hint)",
          "154:         if isProbablyShuffleJoin(left, right, hint) => j",
          "155:       case a: Aggregate => a",
          "156:     }.nonEmpty",
          "",
          "[Added Lines]",
          "141:     plan.exists {",
          "142:       case Join(left, right, _, _, hint) => isProbablyShuffleJoin(left, right, hint)",
          "143:       case _: Aggregate => true",
          "144:       case _ => false",
          "145:     }",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "235:   }",
          "237:   private def findBloomFilterWithExp(plan: LogicalPlan, key: Expression): Boolean = {",
          "239:       case Filter(condition, _) =>",
          "240:         splitConjunctivePredicates(condition).exists {",
          "241:           case BloomFilterMightContain(_, XxHash64(Seq(valueExpression), _))",
          "",
          "[Removed Lines]",
          "238:     plan.find {",
          "",
          "[Added Lines]",
          "227:     plan.exists {",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "243:           case _ => false",
          "244:         }",
          "245:       case _ => false",
          "247:   }",
          "249:   def hasInSubquery(left: LogicalPlan, right: LogicalPlan, leftKey: Expression,",
          "",
          "[Removed Lines]",
          "246:     }.isDefined",
          "",
          "[Added Lines]",
          "235:     }",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "277:             isSimpleExpression(l) && isSimpleExpression(r)) {",
          "278:             val oldLeft = newLeft",
          "279:             val oldRight = newRight",
          "281:               newLeft = injectFilter(l, newLeft, r, right)",
          "282:             }",
          "285:               filteringHasBenefit(right, left, r, hint)) {",
          "286:               newRight = injectFilter(r, newRight, l, left)",
          "287:             }",
          "",
          "[Removed Lines]",
          "280:             if (canFilterLeft(joinType) && filteringHasBenefit(left, right, l, hint)) {",
          "284:             if (newLeft.fastEquals(oldLeft) && canFilterRight(joinType) &&",
          "",
          "[Added Lines]",
          "269:             if (canPruneLeft(joinType) && filteringHasBenefit(left, right, l, hint)) {",
          "273:             if (newLeft.fastEquals(oldLeft) && canPruneRight(joinType) &&",
          "",
          "---------------"
        ],
        "sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/joins.scala||sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/joins.scala": [
          "File: sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/joins.scala -> sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/joins.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "347:         join.hint, hintOnly = false, conf).isDefined",
          "348:   }",
          "350:   def hintToBroadcastLeft(hint: JoinHint): Boolean = {",
          "351:     hint.leftHint.exists(_.strategy.contains(BROADCAST))",
          "352:   }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "350:   def canPruneLeft(joinType: JoinType): Boolean = joinType match {",
          "351:     case Inner | LeftSemi | RightOuter => true",
          "352:     case _ => false",
          "353:   }",
          "355:   def canPruneRight(joinType: JoinType): Boolean = joinType match {",
          "356:     case Inner | LeftSemi | LeftOuter => true",
          "357:     case _ => false",
          "358:   }",
          "",
          "---------------"
        ],
        "sql/catalyst/src/main/scala/org/apache/spark/sql/internal/SQLConf.scala||sql/catalyst/src/main/scala/org/apache/spark/sql/internal/SQLConf.scala": [
          "File: sql/catalyst/src/main/scala/org/apache/spark/sql/internal/SQLConf.scala -> sql/catalyst/src/main/scala/org/apache/spark/sql/internal/SQLConf.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "375:       .createWithDefaultString(\"10MB\")",
          "377:   val RUNTIME_BLOOM_FILTER_APPLICATION_SIDE_SCAN_SIZE_THRESHOLD =",
          "379:       .doc(\"Byte size threshold of the Bloom filter application side plan's aggregated scan \" +",
          "380:         \"size. Aggregated scan byte size of the Bloom filter application side needs to be over \" +",
          "381:         \"this value to inject a bloom filter.\")",
          "",
          "[Removed Lines]",
          "378:     buildConf(\"spark.sql.optimizer.runtime.bloomFilter.applicationSideScanSizethreshold\")",
          "",
          "[Added Lines]",
          "378:     buildConf(\"spark.sql.optimizer.runtime.bloomFilter.applicationSideScanSizeThreshold\")",
          "",
          "---------------"
        ],
        "sql/core/src/main/scala/org/apache/spark/sql/execution/dynamicpruning/PartitionPruning.scala||sql/core/src/main/scala/org/apache/spark/sql/execution/dynamicpruning/PartitionPruning.scala": [
          "File: sql/core/src/main/scala/org/apache/spark/sql/execution/dynamicpruning/PartitionPruning.scala -> sql/core/src/main/scala/org/apache/spark/sql/execution/dynamicpruning/PartitionPruning.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: import org.apache.spark.sql.catalyst.catalog.HiveTableRelation",
          "21: import org.apache.spark.sql.catalyst.expressions._",
          "22: import org.apache.spark.sql.catalyst.planning.ExtractEquiJoinKeys",
          "24: import org.apache.spark.sql.catalyst.plans.logical._",
          "25: import org.apache.spark.sql.catalyst.rules.Rule",
          "26: import org.apache.spark.sql.connector.read.SupportsRuntimeFiltering",
          "",
          "[Removed Lines]",
          "23: import org.apache.spark.sql.catalyst.plans._",
          "",
          "[Added Lines]",
          "22: import org.apache.spark.sql.catalyst.optimizer.JoinSelectionHelper",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "52: object PartitionPruning extends Rule[LogicalPlan] with PredicateHelper {",
          "",
          "[Added Lines]",
          "52: object PartitionPruning extends Rule[LogicalPlan] with PredicateHelper with JoinSelectionHelper {",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "215:     !plan.isStreaming && hasSelectivePredicate(plan)",
          "216:   }",
          "228:   private def prune(plan: LogicalPlan): LogicalPlan = {",
          "229:     plan transformUp {",
          "",
          "[Removed Lines]",
          "218:   private def canPruneLeft(joinType: JoinType): Boolean = joinType match {",
          "219:     case Inner | LeftSemi | RightOuter => true",
          "220:     case _ => false",
          "221:   }",
          "223:   private def canPruneRight(joinType: JoinType): Boolean = joinType match {",
          "224:     case Inner | LeftSemi | LeftOuter => true",
          "225:     case _ => false",
          "226:   }",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "sql/core/src/test/scala/org/apache/spark/sql/InjectRuntimeFilterSuite.scala||sql/core/src/test/scala/org/apache/spark/sql/InjectRuntimeFilterSuite.scala": [
          "File: sql/core/src/test/scala/org/apache/spark/sql/InjectRuntimeFilterSuite.scala -> sql/core/src/test/scala/org/apache/spark/sql/InjectRuntimeFilterSuite.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "526:         \"bf1.c1 = square(bf2.c2) where bf2.a2 = 62\" )",
          "527:     }",
          "528:   }",
          "529: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "530:   test(\"Support Left Semi join in row level runtime filters\") {",
          "531:     withSQLConf(SQLConf.RUNTIME_BLOOM_FILTER_APPLICATION_SIDE_SCAN_SIZE_THRESHOLD.key -> \"3000\",",
          "532:       SQLConf.AUTO_BROADCASTJOIN_THRESHOLD.key -> \"32\") {",
          "533:       assertRewroteWithBloomFilter(",
          "534:         \"\"\"",
          "535:           |SELECT *",
          "536:           |FROM   bf1 LEFT SEMI",
          "537:           |JOIN   (SELECT * FROM bf2 WHERE bf2.a2 = 62) tmp",
          "538:           |ON     bf1.c1 = tmp.c2",
          "539:         \"\"\".stripMargin)",
          "540:     }",
          "541:   }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "60bd91f257f601985de144fde84a019327cf23f2",
      "candidate_info": {
        "commit_hash": "60bd91f257f601985de144fde84a019327cf23f2",
        "repo": "apache/spark",
        "commit_url": "https://github.com/apache/spark/commit/60bd91f257f601985de144fde84a019327cf23f2",
        "files": [
          "core/src/main/scala/org/apache/spark/util/collection/BitSet.scala",
          "sql/core/src/test/scala/org/apache/spark/sql/SQLQuerySuite.scala"
        ],
        "message": "[SPARK-40247][SQL] Fix BitSet equality check\n\n### What changes were proposed in this pull request?\nSpark's `BitSet` doesn't implement `equals()` and `hashCode()` but it is used in `FileSourceScanExec` for bucket pruning.\n\n### Why are the changes needed?\nWithout proper equality check reuse issues can occur.\n\n### Does this PR introduce _any_ user-facing change?\nNo.\n\n### How was this patch tested?\nAdded new UT.\n\nCloses #37696 from peter-toth/SPARK-40247-fix-bitset-equals.\n\nAuthored-by: Peter Toth <ptoth@cloudera.com>\nSigned-off-by: Wenchen Fan <wenchen@databricks.com>\n(cherry picked from commit 527ddece8fdbe703dcd239401c97ddb2c6122182)\nSigned-off-by: Wenchen Fan <wenchen@databricks.com>",
        "before_after_code_files": [
          "core/src/main/scala/org/apache/spark/util/collection/BitSet.scala||core/src/main/scala/org/apache/spark/util/collection/BitSet.scala",
          "sql/core/src/test/scala/org/apache/spark/sql/SQLQuerySuite.scala||sql/core/src/test/scala/org/apache/spark/sql/SQLQuerySuite.scala"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/jack-steven-root/spark/pull/1"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "core/src/main/scala/org/apache/spark/util/collection/BitSet.scala||core/src/main/scala/org/apache/spark/util/collection/BitSet.scala": [
          "File: core/src/main/scala/org/apache/spark/util/collection/BitSet.scala -> core/src/main/scala/org/apache/spark/util/collection/BitSet.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "252:   private def bit2words(numBits: Int) = ((numBits - 1) >> 6) + 1",
          "253: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "254:   override def equals(other: Any): Boolean = other match {",
          "255:     case otherSet: BitSet => Arrays.equals(words, otherSet.words)",
          "256:     case _ => false",
          "257:   }",
          "259:   override def hashCode(): Int = {",
          "260:     Arrays.hashCode(words)",
          "261:   }",
          "",
          "---------------"
        ],
        "sql/core/src/test/scala/org/apache/spark/sql/SQLQuerySuite.scala||sql/core/src/test/scala/org/apache/spark/sql/SQLQuerySuite.scala": [
          "File: sql/core/src/test/scala/org/apache/spark/sql/SQLQuerySuite.scala -> sql/core/src/test/scala/org/apache/spark/sql/SQLQuerySuite.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "4085:     }",
          "4086:   }",
          "4088:   test(\"SPARK-35331: Fix resolving original expression in RepartitionByExpression after aliased\") {",
          "4089:     Seq(\"CLUSTER\", \"DISTRIBUTE\").foreach { keyword =>",
          "4090:       Seq(\"a\", \"substr(a, 0, 3)\").foreach { expr =>",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "4088:   test(\"SPARK-40247: Fix BitSet equals\") {",
          "4089:     withTable(\"td\") {",
          "4090:       testData",
          "4091:         .withColumn(\"bucket\", $\"key\" % 3)",
          "4092:         .write",
          "4093:         .mode(SaveMode.Overwrite)",
          "4094:         .bucketBy(2, \"bucket\")",
          "4095:         .format(\"parquet\")",
          "4096:         .saveAsTable(\"td\")",
          "4097:       val df = sql(",
          "4098:         \"\"\"",
          "4099:           |SELECT t1.key, t2.key, t3.key",
          "4100:           |FROM td AS t1",
          "4101:           |JOIN td AS t2 ON t2.key = t1.key",
          "4102:           |JOIN td AS t3 ON t3.key = t2.key",
          "4103:           |WHERE t1.bucket = 1 AND t2.bucket = 1 AND t3.bucket = 1",
          "4104:           |\"\"\".stripMargin)",
          "4105:       df.collect()",
          "4106:       val reusedExchanges = collect(df.queryExecution.executedPlan) {",
          "4107:         case r: ReusedExchangeExec => r",
          "4108:       }",
          "4109:       assert(reusedExchanges.size == 1)",
          "4110:     }",
          "4111:   }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "60ce69df029b1e1d7cf7f7eece02e668de24cca8",
      "candidate_info": {
        "commit_hash": "60ce69df029b1e1d7cf7f7eece02e668de24cca8",
        "repo": "apache/spark",
        "commit_url": "https://github.com/apache/spark/commit/60ce69df029b1e1d7cf7f7eece02e668de24cca8",
        "files": [
          "python/pyspark/mllib/_typing.pyi",
          "python/pyspark/mllib/stat/_statistics.py",
          "python/pyspark/mllib/stat/_statistics.pyi"
        ],
        "message": "[SPARK-37234][PYTHON] Inline type hints for python/pyspark/mllib/stat/_statistics.py\n\n### What changes were proposed in this pull request?\nInline type hints for python/pyspark/mllib/stat/_statistics.py\n### Why are the changes needed?\nWe can take advantage of static type checking within the functions by inlining the type hints.\n### Does this PR introduce _any_ user-facing change?\nNo\n### How was this patch tested?\nExisting tests\n\nCloses #34513 from dchvn/SPARK-37234.\n\nLead-authored-by: dch nguyen <dchvn.dgd@gmail.com>\nCo-authored-by: dch nguyen <dgd_contributor@viettel.com.vn>\nSigned-off-by: zero323 <mszymkiewicz@gmail.com>\n(cherry picked from commit c3dcdb118ca403a8fbefc3308a116d9e12a1f038)\nSigned-off-by: zero323 <mszymkiewicz@gmail.com>",
        "before_after_code_files": [
          "python/pyspark/mllib/_typing.pyi||python/pyspark/mllib/_typing.pyi",
          "python/pyspark/mllib/stat/_statistics.py||python/pyspark/mllib/stat/_statistics.py",
          "python/pyspark/mllib/stat/_statistics.pyi||python/pyspark/mllib/stat/_statistics.pyi"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/jack-steven-root/spark/pull/1"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "python/pyspark/mllib/_typing.pyi||python/pyspark/mllib/_typing.pyi": [
          "File: python/pyspark/mllib/_typing.pyi -> python/pyspark/mllib/_typing.pyi",
          "--- Hunk 1 ---",
          "[Context before]",
          "25: VectorLike = Union[ndarray, Vector, List[float], Tuple[float, ...]]",
          "26: C = TypeVar(\"C\", bound=type)",
          "27: JavaObjectOrPickleDump = Union[JavaObject, bytearray, bytes]",
          "28: NormType = Union[None, float, Literal[\"fro\"], Literal[\"nuc\"]]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "31: CorrelationMethod = Union[Literal[\"spearman\"], Literal[\"pearson\"]]",
          "32: DistName = Literal[\"norm\"]",
          "",
          "---------------"
        ],
        "python/pyspark/mllib/stat/_statistics.py||python/pyspark/mllib/stat/_statistics.py": [
          "File: python/pyspark/mllib/stat/_statistics.py -> python/pyspark/mllib/stat/_statistics.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "16: #",
          "18: import sys",
          "20: from pyspark.rdd import RDD",
          "21: from pyspark.mllib.common import callMLlibFunc, JavaModelWrapper",
          "23: from pyspark.mllib.regression import LabeledPoint",
          "24: from pyspark.mllib.stat.test import ChiSqTestResult, KolmogorovSmirnovTestResult",
          "27: __all__ = [\"MultivariateStatisticalSummary\", \"Statistics\"]",
          "",
          "[Removed Lines]",
          "22: from pyspark.mllib.linalg import Matrix, _convert_to_vector",
          "",
          "[Added Lines]",
          "19: from typing import cast, overload, List, Optional, TYPE_CHECKING, Union",
          "21: from numpy import ndarray",
          "22: from py4j.java_gateway import JavaObject",
          "26: from pyspark.mllib.linalg import Matrix, Vector, _convert_to_vector",
          "30: if TYPE_CHECKING:",
          "31:     from pyspark.mllib._typing import CorrelationMethod, DistName",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "33:     Trait for multivariate statistical summary of a data matrix.",
          "34:     \"\"\"",
          "43:         return int(self.call(\"count\"))",
          "61: class Statistics:",
          "62:     @staticmethod",
          "64:         \"\"\"",
          "65:         Computes column-wise summary statistics for the input RDD[Vector].",
          "",
          "[Removed Lines]",
          "36:     def mean(self):",
          "37:         return self.call(\"mean\").toArray()",
          "39:     def variance(self):",
          "40:         return self.call(\"variance\").toArray()",
          "42:     def count(self):",
          "45:     def numNonzeros(self):",
          "46:         return self.call(\"numNonzeros\").toArray()",
          "48:     def max(self):",
          "49:         return self.call(\"max\").toArray()",
          "51:     def min(self):",
          "52:         return self.call(\"min\").toArray()",
          "54:     def normL1(self):",
          "55:         return self.call(\"normL1\").toArray()",
          "57:     def normL2(self):",
          "58:         return self.call(\"normL2\").toArray()",
          "63:     def colStats(rdd):",
          "",
          "[Added Lines]",
          "42:     def mean(self) -> ndarray:",
          "43:         return cast(JavaObject, self.call(\"mean\")).toArray()",
          "45:     def variance(self) -> ndarray:",
          "46:         return cast(JavaObject, self.call(\"variance\")).toArray()",
          "48:     def count(self) -> int:",
          "51:     def numNonzeros(self) -> ndarray:",
          "52:         return cast(JavaObject, self.call(\"numNonzeros\")).toArray()",
          "54:     def max(self) -> ndarray:",
          "55:         return cast(JavaObject, self.call(\"max\")).toArray()",
          "57:     def min(self) -> ndarray:",
          "58:         return cast(JavaObject, self.call(\"min\")).toArray()",
          "60:     def normL1(self) -> ndarray:",
          "61:         return cast(JavaObject, self.call(\"normL1\")).toArray()",
          "63:     def normL2(self) -> ndarray:",
          "64:         return cast(JavaObject, self.call(\"normL2\")).toArray()",
          "69:     def colStats(rdd: RDD[Vector]) -> MultivariateStatisticalSummary:",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "98:         cStats = callMLlibFunc(\"colStats\", rdd.map(_convert_to_vector))",
          "99:         return MultivariateStatisticalSummary(cStats)",
          "101:     @staticmethod",
          "103:         \"\"\"",
          "104:         Compute the correlation (matrix) for the input RDD(s) using the",
          "105:         specified method.",
          "",
          "[Removed Lines]",
          "102:     def corr(x, y=None, method=None):",
          "",
          "[Added Lines]",
          "107:     @overload",
          "108:     @staticmethod",
          "109:     def corr(x: RDD[Vector], *, method: Optional[\"CorrelationMethod\"] = ...) -> Matrix:",
          "110:         ...",
          "112:     @overload",
          "114:     def corr(x: RDD[float], y: RDD[float], method: Optional[\"CorrelationMethod\"] = ...) -> float:",
          "115:         ...",
          "117:     @staticmethod",
          "118:     def corr(",
          "119:         x: Union[RDD[Vector], RDD[float]],",
          "120:         y: Optional[RDD[float]] = None,",
          "121:         method: Optional[\"CorrelationMethod\"] = None,",
          "122:     ) -> Union[float, Matrix]:",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "168:             raise TypeError(\"Use 'method=' to specify method name.\")",
          "170:         if not y:",
          "172:         else:",
          "175:     @staticmethod",
          "177:         \"\"\"",
          "178:         If `observed` is Vector, conduct Pearson's chi-squared goodness",
          "179:         of fit test of the observed data against the expected distribution,",
          "",
          "[Removed Lines]",
          "171:             return callMLlibFunc(\"corr\", x.map(_convert_to_vector), method).toArray()",
          "173:             return callMLlibFunc(\"corr\", x.map(float), y.map(float), method)",
          "176:     def chiSqTest(observed, expected=None):",
          "",
          "[Added Lines]",
          "191:             return cast(",
          "192:                 JavaObject, callMLlibFunc(\"corr\", x.map(_convert_to_vector), method)",
          "193:             ).toArray()",
          "195:             return cast(",
          "196:                 float,",
          "197:                 callMLlibFunc(\"corr\", cast(RDD[float], x).map(float), y.map(float), method),",
          "198:             )",
          "200:     @overload",
          "201:     @staticmethod",
          "202:     def chiSqTest(observed: Matrix) -> ChiSqTestResult:",
          "203:         ...",
          "205:     @overload",
          "206:     @staticmethod",
          "207:     def chiSqTest(observed: Vector, expected: Optional[Vector] = ...) -> ChiSqTestResult:",
          "208:         ...",
          "210:     @overload",
          "211:     @staticmethod",
          "212:     def chiSqTest(observed: RDD[LabeledPoint]) -> List[ChiSqTestResult]:",
          "213:         ...",
          "216:     def chiSqTest(",
          "217:         observed: Union[Matrix, RDD[LabeledPoint], Vector], expected: Optional[Vector] = None",
          "218:     ) -> Union[ChiSqTestResult, List[ChiSqTestResult]]:",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "270:         return ChiSqTestResult(jmodel)",
          "272:     @staticmethod",
          "274:         \"\"\"",
          "275:         Performs the Kolmogorov-Smirnov (KS) test for data sampled from",
          "276:         a continuous distribution. It tests the null hypothesis that",
          "",
          "[Removed Lines]",
          "273:     def kolmogorovSmirnovTest(data, distName=\"norm\", *params):",
          "",
          "[Added Lines]",
          "315:     def kolmogorovSmirnovTest(",
          "316:         data: RDD[float], distName: \"DistName\" = \"norm\", *params: float",
          "317:     ) -> KolmogorovSmirnovTestResult:",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "334:         if not isinstance(distName, str):",
          "335:             raise TypeError(\"distName should be a string, got %s.\" % type(distName))",
          "338:         return KolmogorovSmirnovTestResult(",
          "340:         )",
          "344:     import doctest",
          "345:     import numpy",
          "346:     from pyspark.sql import SparkSession",
          "",
          "[Removed Lines]",
          "337:         params = [float(param) for param in params]",
          "339:             callMLlibFunc(\"kolmogorovSmirnovTest\", data, distName, params)",
          "343: def _test():",
          "",
          "[Added Lines]",
          "381:         param_list = [float(param) for param in params]",
          "383:             callMLlibFunc(\"kolmogorovSmirnovTest\", data, distName, param_list)",
          "387: def _test() -> None:",
          "",
          "---------------"
        ],
        "python/pyspark/mllib/stat/_statistics.pyi||python/pyspark/mllib/stat/_statistics.pyi": [
          "File: python/pyspark/mllib/stat/_statistics.pyi -> python/pyspark/mllib/stat/_statistics.pyi",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ]
      }
    }
  ]
}