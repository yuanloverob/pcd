{
  "cve_id": "CVE-2023-34411",
  "cve_desc": "The xml-rs crate before 0.8.14 for Rust and Crab allows a denial of service (panic) via an invalid <! token (such as <!DOCTYPEs/%<!A nesting) in an XML document. The earliest affected version is 0.8.9.",
  "repo": "00xc/xml-rs",
  "patch_hash": "0f084d45aa53e4a27476961785f59f2bd7d59a9f",
  "patch_info": {
    "commit_hash": "0f084d45aa53e4a27476961785f59f2bd7d59a9f",
    "repo": "00xc/xml-rs",
    "commit_url": "https://github.com/00xc/xml-rs/commit/0f084d45aa53e4a27476961785f59f2bd7d59a9f",
    "files": [
      "README.md",
      "src/reader/lexer.rs",
      "src/reader/parser/inside_cdata.rs",
      "src/reader/parser/inside_doctype.rs",
      "src/reader/parser/inside_processing_instruction.rs",
      "src/reader/parser/mod.rs",
      "src/reader/parser/outside_tag.rs",
      "tests/xmlconf.rs"
    ],
    "message": "Parse DOCTYPE markup declarations",
    "before_after_code_files": [
      "src/reader/lexer.rs||src/reader/lexer.rs",
      "src/reader/parser/inside_cdata.rs||src/reader/parser/inside_cdata.rs",
      "src/reader/parser/inside_doctype.rs||src/reader/parser/inside_doctype.rs",
      "src/reader/parser/inside_processing_instruction.rs||src/reader/parser/inside_processing_instruction.rs",
      "src/reader/parser/mod.rs||src/reader/parser/mod.rs",
      "src/reader/parser/outside_tag.rs||src/reader/parser/outside_tag.rs",
      "tests/xmlconf.rs||tests/xmlconf.rs"
    ]
  },
  "patch_diff": {
    "src/reader/lexer.rs||src/reader/lexer.rs": [
      "File: src/reader/lexer.rs -> src/reader/lexer.rs",
      "--- Hunk 1 ---",
      "[Context before]",
      "54:     ReferenceStart,",
      "56:     ReferenceEnd,",
      "57: }",
      "59: impl fmt::Display for Token {",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "58:     MarkupDeclarationStart,",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "143:     }",
      "144: }",
      "146: enum State {",
      "148:     Normal,",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "148: #[derive(Copy, Clone)]",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "154:     CommentStarted,",
      "156:     DoctypeStarted(DoctypeStartedSubstate),",
      "160:     CDataStarted(CDataStartedSubstate),",
      "",
      "[Removed Lines]",
      "158:     DoctypeFinishing(u8),",
      "",
      "[Added Lines]",
      "161:     InsideMarkupDeclaration,",
      "163:     InsideDoctype,",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "174:     InsideCdata,",
      "176:     InsideProcessingInstruction,",
      "177: }",
      "179: #[derive(Copy, Clone)]",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "183:     InsideMarkupDeclarationQuotedString(QuoteStyle),",
      "184: }",
      "186: #[derive(Copy, Clone, Eq, PartialEq)]",
      "187: enum QuoteStyle {",
      "188:     Single, Double",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "229:     head_pos: TextPosition,",
      "230:     char_queue: VecDeque<char>,",
      "231:     st: State,",
      "232:     skip_errors: bool,",
      "233:     inside_token: bool,",
      "234:     eof_handled: bool",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "245:     normal_state: State,",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "248:             head_pos: TextPosition::new(),",
      "249:             char_queue: VecDeque::with_capacity(4),  // TODO: check size",
      "250:             st: State::Normal,",
      "251:             skip_errors: false,",
      "252:             inside_token: false,",
      "253:             eof_handled: false",
      "254:         }",
      "255:     }",
      "268:     #[inline]",
      "",
      "[Removed Lines]",
      "259:     #[inline]",
      "260:     pub fn enable_errors(&mut self) { self.skip_errors = false; }",
      "264:     #[inline]",
      "265:     pub fn disable_errors(&mut self) { self.skip_errors = true; }",
      "",
      "[Added Lines]",
      "265:             normal_state: State::Normal,",
      "274:     pub(crate) fn disable_errors(&mut self) { self.skip_errors = true; }",
      "",
      "---------------",
      "--- Hunk 7 ---",
      "[Context before]",
      "326:             State::TagStarted | State::CommentOrCDataOrDoctypeStarted |",
      "327:             State::CommentStarted | State::CDataStarted(_)| State::DoctypeStarted(_) |",
      "328:             State::CommentClosing(ClosingSubstate::Second) |",
      "330:             State::InsideProcessingInstruction | State::ProcessingInstructionClosing |",
      "332:                 Err(self.error(\"Unexpected end of stream\")),",
      "333:             State::EmptyTagClosing =>",
      "334:                 Ok(Some(Token::Character('/'))),",
      "",
      "[Removed Lines]",
      "329:             State::InsideComment |",
      "331:             State::DoctypeFinishing(_) =>",
      "",
      "[Added Lines]",
      "338:             State::InsideComment | State::InsideMarkupDeclaration |",
      "340:             State::InsideDoctype | State::InsideMarkupDeclarationQuotedString(_) =>",
      "",
      "---------------",
      "--- Hunk 8 ---",
      "[Context before]",
      "369:             State::CommentStarted                 => self.comment_started(c),",
      "370:             State::CDataStarted(s)                => self.cdata_started(c, s),",
      "371:             State::DoctypeStarted(s)              => self.doctype_started(c, s),",
      "373:             State::EmptyTagClosing                => self.empty_element_closing(c),",
      "374:             State::CommentClosing(s)              => self.comment_closing(c, s),",
      "375:             State::CDataClosing(s)                => self.cdata_closing(c, s),",
      "",
      "[Removed Lines]",
      "372:             State::DoctypeFinishing(d)            => self.doctype_finishing(c, d),",
      "",
      "[Added Lines]",
      "381:             State::InsideDoctype                  => self.inside_doctype(c),",
      "",
      "---------------",
      "--- Hunk 9 ---",
      "[Context before]",
      "378:             State::InsideCdata                    => self.inside_cdata(c),",
      "379:             State::InsideProcessingInstruction    => self.inside_processing_instruction(c),",
      "380:             State::ProcessingInstructionClosing   => self.processing_instruction_closing(c),",
      "381:         }",
      "382:     }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "390:             State::InsideMarkupDeclaration       => self.markup_declaration(c),",
      "391:             State::InsideMarkupDeclarationQuotedString(q) => self.markup_declaration_string(c, q),",
      "",
      "---------------",
      "--- Hunk 10 ---",
      "[Context before]",
      "393:         Ok(Some(token))",
      "394:     }",
      "396:     #[inline]",
      "397:     fn move_to_with_unread(&mut self, st: State, cs: &[char], token: Token) -> Result {",
      "398:         self.char_queue.extend(cs.iter().copied());",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "407:     #[inline]",
      "408:     fn move_to_and_reset_normal(&mut self, st: State, token: Token) -> Result {",
      "409:         self.normal_state = st;",
      "410:         self.st = st;",
      "411:         Ok(Some(token))",
      "412:     }",
      "",
      "---------------",
      "--- Hunk 11 ---",
      "[Context before]",
      "461:     fn tag_opened(&mut self, c: char) -> Result {",
      "462:         match c {",
      "463:             '?'                        => self.move_to_with(State::InsideProcessingInstruction, Token::ProcessingInstructionStart),",
      "465:             '!'                        => self.move_to(State::CommentOrCDataOrDoctypeStarted),",
      "468:             _                          => self.handle_error(\"<\", c)",
      "469:         }",
      "470:     }",
      "",
      "[Removed Lines]",
      "464:             '/'                        => self.move_to_with(State::Normal, Token::ClosingTagStart),",
      "466:             _ if is_whitespace_char(c) => self.move_to_with_unread(State::Normal, &[c], Token::OpeningTagStart),",
      "467:             _ if is_name_char(c)       => self.move_to_with_unread(State::Normal, &[c], Token::OpeningTagStart),",
      "",
      "[Added Lines]",
      "483:             '/'                        => self.move_to_with(self.normal_state, Token::ClosingTagStart),",
      "485:             _ if is_whitespace_char(c) => self.move_to_with_unread(self.normal_state, &[c], Token::OpeningTagStart),",
      "486:             _ if is_name_char(c)       => self.move_to_with_unread(self.normal_state, &[c], Token::OpeningTagStart),",
      "",
      "---------------",
      "--- Hunk 12 ---",
      "[Context before]",
      "475:             '-' => self.move_to(State::CommentStarted),",
      "476:             '[' => self.move_to(State::CDataStarted(CDataStartedSubstate::E)),",
      "477:             'D' => self.move_to(State::DoctypeStarted(DoctypeStartedSubstate::D)),",
      "478:             _ => self.handle_error(\"<!\", c),",
      "479:         }",
      "480:     }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "497:             'E' | 'A' | 'N' if matches!(self.normal_state, State::InsideDoctype) => self.move_to_with(State::InsideMarkupDeclaration, Token::MarkupDeclarationStart),",
      "",
      "---------------",
      "--- Hunk 13 ---",
      "[Context before]",
      "500:         )",
      "501:     }",
      "504:     fn doctype_started(&mut self, c: char, s: DoctypeStartedSubstate) -> Result {",
      "505:         use self::DoctypeStartedSubstate::{D, DO, DOC, DOCT, DOCTY, DOCTYP};",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "524:     fn markup_declaration(&mut self, c: char) -> Result {",
      "525:         match c {",
      "526:             '<'                        => self.handle_error(\"<!\", c),",
      "527:             '>'                        => self.move_to_with(self.normal_state, Token::TagEnd),",
      "528:             '&'                        => Ok(Some(Token::ReferenceStart)),",
      "529:             ';'                        => Ok(Some(Token::ReferenceEnd)),",
      "530:             '\"'                        => self.move_to_with(State::InsideMarkupDeclarationQuotedString(QuoteStyle::Double), Token::DoubleQuote),",
      "531:             '\\''                       => self.move_to_with(State::InsideMarkupDeclarationQuotedString(QuoteStyle::Single), Token::SingleQuote),",
      "532:             _ => Ok(None),",
      "533:         }",
      "534:     }",
      "536:     fn markup_declaration_string(&mut self, c: char, q: QuoteStyle) -> Result {",
      "537:         match c {",
      "538:             '\"' if q == QuoteStyle::Double  => self.move_to_with(State::InsideMarkupDeclaration, Token::DoubleQuote),",
      "539:             '\\'' if q == QuoteStyle::Single => self.move_to_with(State::InsideMarkupDeclaration, Token::SingleQuote),",
      "540:             _ => Ok(None),",
      "541:         }",
      "542:     }",
      "",
      "---------------",
      "--- Hunk 14 ---",
      "[Context before]",
      "509:             DOC    ; 'T' ; DOCT   ; \"<!DOC\",",
      "510:             DOCT   ; 'Y' ; DOCTY  ; \"<!DOCT\",",
      "511:             DOCTY  ; 'P' ; DOCTYP ; \"<!DOCTY\";",
      "513:         )",
      "514:     }",
      "518:         match c {",
      "522:             _ => Ok(None),",
      "523:         }",
      "524:     }",
      "",
      "[Removed Lines]",
      "512:             DOCTYP ; 'E' ; \"<!DOCTYP\" ; self.move_to_with(State::DoctypeFinishing(1), Token::DoctypeStart)",
      "517:     fn doctype_finishing(&mut self, c: char, d: u8) -> Result {",
      "519:             '<' => self.move_to(State::DoctypeFinishing(d + 1)),",
      "520:             '>' if d == 1 => self.move_to_with(State::Normal, Token::TagEnd),",
      "521:             '>' => self.move_to(State::DoctypeFinishing(d - 1)),",
      "",
      "[Added Lines]",
      "553:             DOCTYP ; 'E' ; \"<!DOCTYP\" ; self.move_to_and_reset_normal(State::InsideDoctype, Token::DoctypeStart)",
      "558:     fn inside_doctype(&mut self, c: char) -> Result {",
      "560:             '>' => self.move_to_and_reset_normal(State::Normal, Token::TagEnd),",
      "561:             '<'                        => self.move_to(State::TagStarted),",
      "562:             '&'                        => Ok(Some(Token::ReferenceStart)),",
      "563:             ';'                        => Ok(Some(Token::ReferenceEnd)),",
      "",
      "---------------",
      "--- Hunk 15 ---",
      "[Context before]",
      "527:     fn processing_instruction_closing(&mut self, c: char) -> Result {",
      "528:         match c {",
      "530:             _ => self.move_to_with_unread(State::InsideProcessingInstruction, &[c], Token::Character('?')),",
      "531:         }",
      "532:     }",
      "",
      "[Removed Lines]",
      "529:             '>' => self.move_to_with(State::Normal, Token::ProcessingInstructionEnd),",
      "",
      "[Added Lines]",
      "571:             '>' => self.move_to_with(self.normal_state, Token::ProcessingInstructionEnd),",
      "",
      "---------------",
      "--- Hunk 16 ---",
      "[Context before]",
      "535:     fn empty_element_closing(&mut self, c: char) -> Result {",
      "536:         match c {",
      "539:         }",
      "540:     }",
      "",
      "[Removed Lines]",
      "537:             '>' => self.move_to_with(State::Normal, Token::EmptyTagEnd),",
      "538:             _ => self.move_to_with_unread(State::Normal, &[c], Token::Character('/')),",
      "",
      "[Added Lines]",
      "579:             '>' => self.move_to_with(self.normal_state, Token::EmptyTagEnd),",
      "580:             _ => self.move_to_with_unread(self.normal_state, &[c], Token::Character('/')),",
      "",
      "---------------",
      "--- Hunk 17 ---",
      "[Context before]",
      "547:                 _ => self.move_to_with_unread(State::InsideComment, &[c], Token::Character('-')),",
      "548:             },",
      "549:             ClosingSubstate::Second => match c {",
      "552:                 _ => self.handle_error(\"--\", c),",
      "553:             },",
      "",
      "[Removed Lines]",
      "550:                 '>' => self.move_to_with(State::Normal, Token::CommentEnd),",
      "",
      "[Added Lines]",
      "592:                 '>' => self.move_to_with(self.normal_state, Token::CommentEnd),",
      "",
      "---------------",
      "--- Hunk 18 ---",
      "[Context before]",
      "576:                 _ => self.move_to_with_unread(State::Normal, &[c], Token::Character(']')),",
      "577:             },",
      "578:             ClosingSubstate::Second => match c {",
      "580:                 _ => self.move_to_with_unread(State::Normal, &[']', c], Token::Character(']')),",
      "581:             },",
      "582:         }",
      "",
      "[Removed Lines]",
      "579:                 '>' => self.move_to_with(State::Normal, Token::CDataEnd),",
      "",
      "[Added Lines]",
      "621:                 '>' => self.move_to_with(self.normal_state, Token::CDataEnd),",
      "",
      "---------------",
      "--- Hunk 19 ---",
      "[Context before]",
      "825:     #[test]",
      "826:     fn doctype_with_internal_subset_test() {",
      "827:         let (mut lex, mut buf) = make_lex_and_buf(",
      "829:         );",
      "830:         assert_oks!(for lex and buf ;",
      "831:             Token::OpeningTagStart",
      "832:             Token::Character('a')",
      "833:             Token::TagEnd",
      "834:             Token::DoctypeStart",
      "835:             Token::TagEnd",
      "836:             Token::Whitespace(' ')",
      "837:         );",
      "838:         assert_none!(for lex and buf);",
      "839:     }",
      "841:     #[test]",
      "842:     fn end_of_stream_handling_ok() {",
      "843:         macro_rules! eof_check(",
      "",
      "[Removed Lines]",
      "828:             r#\"<a><!DOCTYPE ab[<!ELEMENT ba> ]> \"#",
      "",
      "[Added Lines]",
      "870:             r#\"<a><!DOCTYPE ab[<!ELEMENT ba \">>>>>\"> ]> \"#",
      "877:             Token::MarkupDeclarationStart",
      "878:             Token::DoubleQuote",
      "879:             Token::DoubleQuote",
      "880:             Token::TagEnd",
      "881:             Token::TagEnd",
      "882:             Token::Whitespace(' ')",
      "883:         );",
      "884:         assert_none!(for lex and buf);",
      "885:     }",
      "887:     #[test]",
      "888:     fn doctype_internal_pi_comment() {",
      "889:         let (mut lex, mut buf) = make_lex_and_buf(",
      "890:             \"<!DOCTYPE a [\\n<!ELEMENT leopard ANY> <!-- <?non?>--> <?pi > ?> \\n]>\"",
      "891:         );",
      "892:         assert_oks!(for lex and buf ;",
      "893:             Token::DoctypeStart",
      "894:             Token::MarkupDeclarationStart",
      "896:             Token::CommentStart",
      "898:             Token::Character('<')",
      "899:             Token::Character('?')",
      "900:             Token::Character('n')",
      "901:             Token::Character('o')",
      "902:             Token::Character('n')",
      "903:             Token::Character('?')",
      "904:             Token::Character('>')",
      "905:             Token::CommentEnd",
      "906:             Token::ProcessingInstructionStart",
      "907:             Token::Character('p')",
      "908:             Token::Character('i')",
      "909:             Token::Whitespace(' ')",
      "910:             Token::TagEnd // not really",
      "911:             Token::Whitespace(' ')",
      "912:             Token::ProcessingInstructionEnd",
      "913:             Token::TagEnd // DTD",
      "",
      "---------------"
    ],
    "src/reader/parser/inside_cdata.rs||src/reader/parser/inside_cdata.rs": [
      "File: src/reader/parser/inside_cdata.rs -> src/reader/parser/inside_cdata.rs",
      "--- Hunk 1 ---",
      "[Context before]",
      "7:     pub fn inside_cdata(&mut self, t: Token) -> Option<Result> {",
      "8:         match t {",
      "9:             Token::CDataEnd => {",
      "11:                 let event = if self.config.cdata_to_characters {",
      "12:                     None",
      "13:                 } else {",
      "",
      "[Removed Lines]",
      "10:                 self.lexer.enable_errors();",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------"
    ],
    "src/reader/parser/inside_doctype.rs||src/reader/parser/inside_doctype.rs": [
      "File: src/reader/parser/inside_doctype.rs -> src/reader/parser/inside_doctype.rs",
      "--- Hunk 1 ---",
      "[Context before]",
      "6:     pub fn inside_doctype(&mut self, t: Token) -> Option<Result> {",
      "7:         match t {",
      "8:             Token::TagEnd => {",
      "10:                 self.into_state_continue(State::OutsideTag)",
      "11:             }",
      "13:             _ => None,",
      "14:         }",
      "15:     }",
      "",
      "[Removed Lines]",
      "9:                 self.lexer.enable_errors();",
      "",
      "[Added Lines]",
      "12:             Token::MarkupDeclarationStart => {",
      "13:                 self.into_state_continue(State::InsideDoctypeMarkupDeclaration)",
      "14:             },",
      "16:             _ => None,",
      "17:         }",
      "18:     }",
      "20:     pub fn inside_doctype_markup_declaration(&mut self, t: Token) -> Option<Result> {",
      "21:         match t {",
      "22:             Token::TagEnd => {",
      "23:                 self.into_state_continue(State::InsideDoctype)",
      "24:             }",
      "",
      "---------------"
    ],
    "src/reader/parser/inside_processing_instruction.rs||src/reader/parser/inside_processing_instruction.rs": [
      "File: src/reader/parser/inside_processing_instruction.rs -> src/reader/parser/inside_processing_instruction.rs",
      "--- Hunk 1 ---",
      "[Context before]",
      "69:             ProcessingInstructionSubstate::PIInsideData => match t {",
      "70:                 Token::ProcessingInstructionEnd => {",
      "72:                     let name = self.data.take_name();",
      "73:                     let data = self.take_buf();",
      "74:                     self.into_state_emit(",
      "",
      "[Removed Lines]",
      "71:                     self.lexer.enable_errors();",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------"
    ],
    "src/reader/parser/mod.rs||src/reader/parser/mod.rs": [
      "File: src/reader/parser/mod.rs -> src/reader/parser/mod.rs",
      "--- Hunk 1 ---",
      "[Context before]",
      "139:     InsideCData,",
      "140:     InsideDeclaration(DeclarationSubstate),",
      "141:     InsideDoctype,",
      "142:     InsideReference(Box<State>),",
      "143: }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "142:     InsideDoctypeMarkupDeclaration,",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "337:             State::InsideProcessingInstruction(s) => self.inside_processing_instruction(t, s),",
      "338:             State::InsideDeclaration(s)           => self.inside_declaration(t, s),",
      "339:             State::InsideDoctype                  => self.inside_doctype(t),",
      "340:             State::InsideOpeningTag(s)            => self.inside_opening_tag(t, s),",
      "341:             State::InsideClosingTag(s)            => self.inside_closing_tag_name(t, s),",
      "342:             State::InsideComment                  => self.inside_comment(t),",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "341:             State::InsideDoctypeMarkupDeclaration => self.inside_doctype_markup_declaration(t),",
      "",
      "---------------"
    ],
    "src/reader/parser/outside_tag.rs||src/reader/parser/outside_tag.rs": [
      "File: src/reader/parser/outside_tag.rs -> src/reader/parser/outside_tag.rs",
      "--- Hunk 1 ---",
      "[Context before]",
      "83:                         self.next_pos();",
      "85:                         self.into_state(State::InsideDoctype, next_event)",
      "86:                     }",
      "",
      "[Removed Lines]",
      "84:                         self.lexer.disable_errors();",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------"
    ],
    "tests/xmlconf.rs||tests/xmlconf.rs": [
      "File: tests/xmlconf.rs -> tests/xmlconf.rs",
      "--- Hunk 1 ---",
      "[Context before]",
      "116:         \"rmt-e2e-18\", // External entity containing start of entity declaration is base URI for system identifier",
      "117:         \"rmt-e2e-19\", // Parameter entities and character references are included-in-literal, but general entities are bypassed.",
      "118:         \"rmt-e2e-22\", // UTF-8 entities may start with a BOM",
      "120:         \"rmt-e2e-34\", // A non-deterministic content model is an error even if the element type is not used.",
      "121:         \"rmt-e2e-50\", // All line-ends are normalized, even those not passed to the application. NB this can only be tested effectively in XML 1.1, since CR is in the S production; in 1.1 we can use NEL which isn't.",
      "122:         \"rmt-e2e-55\", // A reference to an unparsed entity in an entity value is an error rather than forbidden (unless the entity is referenced, of course)",
      "",
      "[Removed Lines]",
      "119:         \"rmt-e2e-24\", // Either the built-in entity or a character reference can be used to represent greater-than after two close-square-brackets",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "279: #[test] fn oasis() {",
      "280:     run_suite(\"oasis/oasis.xml\", &[",
      "285:         \"o-p01fail1\", // S cannot occur before the prolog",
      "286:         \"o-p01fail2\", // comments cannot occur before the prolog",
      "287:         \"o-p01fail3\", // only one document element",
      "288:         \"o-p09fail1\", // EntityValue excludes '%'",
      "289:         \"o-p09fail2\", // EntityValue excludes '&'",
      "290:         \"o-p09fail3\", // incomplete character reference",
      "296:         \"o-p12fail2\", // '\\' excluded",
      "297:         \"o-p12fail3\", // entity references excluded",
      "298:         \"o-p12fail6\", // built-in entity refs excluded",
      "299:         \"o-p12fail7\", // The public ID has a tab character, which is disallowed",
      "300:         \"o-p14fail3\", // \"]]>\" excluded",
      "",
      "[Removed Lines]",
      "281:         \"o-p43pass1\", // Valid use of character data, comments, processing instructions and CDATA sections within the start and end tag.",
      "282:         \"o-p68pass1\", // Valid entity references.  Also ensures that a charref to           '&' isn't interpreted as an entity reference open delimiter",
      "283:         \"o-p04pass1\", // names with all valid ASCII characters, and one from each               other class in NameChar",
      "284:         \"o-p05pass1\", // various valid Name constructions",
      "291:         \"o-p09fail4\", // quote types must match",
      "292:         \"o-p09fail5\", // quote types must match",
      "293:         \"o-p11fail1\", // quote types must match",
      "294:         \"o-p11fail2\", // cannot contain delimiting quotes",
      "295:         \"o-p12fail1\", // '\"' excluded",
      "",
      "[Added Lines]",
      "283:         \"o-p04pass1\", // names with all valid ASCII characters, and one from each               other class in NameChar",
      "284:         \"o-p05pass1\", // various valid Name constructions",
      "288:         \"o-p11pass1\", // p11pass1.xml       system literals may not contain     URI fragments",
      "289:         \"o-p12fail1\", // p12fail1.xml       '\"' excluded",
      "292:         \"o-p12fail4\", // p12fail4.xml       '>' excluded",
      "293:         \"o-p12fail5\", // p12fail5.xml       '<' excluded",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "303:         \"o-p22fail2\", // prolog must start with XML decl",
      "304:         \"o-p23fail1\", // \"xml\" must be lower-case",
      "305:         \"o-p27fail1\", // References aren't allowed in Misc,     even if they would resolve to valid Misc.",
      "307:         \"o-p30fail1\", // An XML declaration is not the same as a TextDecl",
      "308:         \"o-p31fail1\", // external subset excludes doctypedecl",
      "309:         \"o-p32fail3\", // initial S is required",
      "310:         \"o-p40fail1\", // S is required between attributes",
      "311:         \"o-p44fail4\", // Whitespace required between attributes.",
      "313:         \"o-p45fail2\", // S before contentspec is required.",
      "314:         \"o-p45fail3\", // only one content spec",
      "315:         \"o-p45fail4\", // no comments in declarations (contrast with SGML)",
      "",
      "[Removed Lines]",
      "306:         \"o-p29fail1\", // A processor must not pass unknown declaration types.",
      "312:         \"o-p45fail1\", // ELEMENT must be upper case.",
      "",
      "[Added Lines]",
      "306:         \"o-p43pass1\", // Valid use of character data, comments, processing instructions and CDATA sections within the start and end tag.",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "371:         \"o-p64fail1\", // section delimiters must balance",
      "372:         \"o-p64fail2\", // section delimiters must balance",
      "373:         \"o-p66fail5\", // no references to non-characters",
      "374:         \"o-p69fail1\", // terminating ';' is required",
      "375:         \"o-p69fail2\", // no S after '%'",
      "376:         \"o-p69fail3\", // no S before ';'",
      "377:         \"o-p70fail1\", // This is neither",
      "378:         \"o-p71fail1\", // S is required before EntityDef",
      "379:         \"o-p71fail2\", // Entity name is a Name, not an NMToken",
      "381:         \"o-p71fail4\", // S is required after \"<!ENTITY\"",
      "382:         \"o-p72fail1\", // S is required after \"<!ENTITY\"",
      "383:         \"o-p72fail2\", // S is required after '%'",
      "384:         \"o-p72fail3\", // S is required after name",
      "385:         \"o-p72fail4\", // Entity name is a name, not an NMToken",
      "386:         \"o-p73fail1\", // No typed replacement text",
      "387:         \"o-p73fail2\", // Only one replacement value",
      "",
      "[Removed Lines]",
      "380:         \"o-p71fail3\", // no S after \"<!\"",
      "",
      "[Added Lines]",
      "369:         \"o-p68pass1\", // Valid entity references.  Also ensures that a charref to           '&' isn't interpreted as an entity reference open delimiter",
      "380:         \"o-p76fail4\", // p76fail4.xml       notation names are Names",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "438:         \"content02\", // No whitespace before \"*\" in content model",
      "439:         \"content03\", // No whitespace before \"+\" in content model",
      "440:         \"decl01\", // External entities may not have standalone decls.",
      "443:         \"dtd02\", // PE name immediately after \"%\"",
      "444:         \"dtd03\", // PE name immediately followed by \";\"",
      "445:         \"dtd04\", // PUBLIC literal must be quoted",
      "",
      "[Removed Lines]",
      "441:         \"nwf-dtd00\", // Comma mandatory in content model",
      "442:         \"nwf-dtd01\", // Can't mix comma and vertical bar in content models",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "451:         \"encoding04\", // Illegal character \":\" in encoding name",
      "452:         \"encoding05\", // Illegal character \"@\" in encoding name",
      "453:         \"encoding06\", // Illegal character \"+\" in encoding name",
      "454:         \"pubid01\", // Illegal entity ref in public ID",
      "455:         \"pubid02\", // Illegal characters in public ID",
      "456:         \"pubid03\", // Illegal characters in public ID",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "448:         \"nwf-dtd00\", // Comma mandatory in content model",
      "449:         \"nwf-dtd01\", // Can't mix comma and vertical bar in content models",
      "450:         \"pi\", // pi.xml      No space between PI target name and data",
      "",
      "---------------",
      "--- Hunk 7 ---",
      "[Context before]",
      "502:         \"not-wf-sa-060\", // Invalid type NAME defined in ATTLIST.",
      "503:         \"not-wf-sa-061\", // External entity declarations require whitespace between public     and system IDs.",
      "504:         \"not-wf-sa-062\", // Entity declarations need space after the entity name.",
      "506:         \"not-wf-sa-064\", // Space is required between attribute type and default values     in <!ATTLIST...> declarations.",
      "507:         \"not-wf-sa-065\", // Space is required between attribute name and type     in <!ATTLIST...> declarations.",
      "508:         \"not-wf-sa-066\", // Required whitespace is missing.",
      "",
      "[Removed Lines]",
      "505:         \"not-wf-sa-063\", // Conditional sections may only appear in the external     DTD subset.",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------",
      "--- Hunk 8 ---",
      "[Context before]",
      "523:         \"not-wf-sa-101\", // Space is not permitted in an encoding name.",
      "524:         \"not-wf-sa-105\", // Invalid placement of CDATA section.",
      "525:         \"not-wf-sa-106\", // Invalid placement of entity declaration.",
      "527:         \"not-wf-sa-113\", // Parameter entity values must use valid reference syntax;     this reference is malformed.",
      "528:         \"not-wf-sa-114\", // General entity values must use valid reference syntax;     this reference is malformed.",
      "529:         \"not-wf-sa-121\", // A name of an ENTITY was started with an invalid character.",
      "",
      "[Removed Lines]",
      "526:         \"not-wf-sa-107\", // Invalid document type declaration.  CDATA alone is invalid.",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------",
      "--- Hunk 9 ---",
      "[Context before]",
      "566:         \"not-wf-sa-174\", // Character FFFF is not legal anywhere in an XML document.",
      "567:         \"not-wf-sa-175\", // Character FFFF is not legal anywhere in an XML document.",
      "568:         \"not-wf-sa-177\", // Character FFFF is not legal anywhere in an XML document.",
      "570:         \"not-wf-sa-180\", // The Entity Declared WFC requires entities to be declared     before they are used in an attribute list declaration.",
      "571:         \"not-wf-sa-183\", // Mixed content declarations may not include content particles.",
      "572:         \"not-wf-sa-184\", // In mixed content models, element names must not be     parenthesized.",
      "",
      "[Removed Lines]",
      "569:         \"not-wf-sa-179\", // Invalid syntax matching double quote is missing.",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "f37af927341350f384fedfdd8e30092f089952a8",
      "candidate_info": {
        "commit_hash": "f37af927341350f384fedfdd8e30092f089952a8",
        "repo": "00xc/xml-rs",
        "commit_url": "https://github.com/00xc/xml-rs/commit/f37af927341350f384fedfdd8e30092f089952a8",
        "files": [
          "src/reader/lexer.rs",
          "src/reader/parser.rs",
          "src/reader/parser/inside_doctype.rs",
          "tests/oasis.fail.txt",
          "tests/xmltest.fail.txt"
        ],
        "message": "Emit character tokens in DTD state",
        "before_after_code_files": [
          "src/reader/lexer.rs||src/reader/lexer.rs",
          "src/reader/parser.rs||src/reader/parser.rs",
          "src/reader/parser/inside_doctype.rs||src/reader/parser/inside_doctype.rs"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "src/reader/lexer.rs||src/reader/lexer.rs",
            "src/reader/parser/inside_doctype.rs||src/reader/parser/inside_doctype.rs"
          ],
          "candidate": [
            "src/reader/lexer.rs||src/reader/lexer.rs",
            "src/reader/parser/inside_doctype.rs||src/reader/parser/inside_doctype.rs"
          ]
        }
      },
      "candidate_diff": {
        "src/reader/lexer.rs||src/reader/lexer.rs": [
          "File: src/reader/lexer.rs -> src/reader/lexer.rs",
          "--- Hunk 1 ---",
          "[Context before]",
          "376:             State::InsideCdata                    => self.inside_cdata(c),",
          "377:             State::InsideProcessingInstruction    => self.inside_processing_instruction(c),",
          "378:             State::ProcessingInstructionClosing   => self.processing_instruction_closing(c),",
          "380:             State::InsideMarkupDeclarationQuotedString(q) => self.markup_declaration_string(c, q),",
          "381:         }",
          "382:     }",
          "",
          "[Removed Lines]",
          "379:             State::InsideMarkupDeclaration       => self.markup_declaration(c),",
          "",
          "[Added Lines]",
          "379:             State::InsideMarkupDeclaration        => self.markup_declaration(c),",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "483:             '-' => self.move_to(State::CommentStarted),",
          "484:             '[' => self.move_to(State::CDataStarted(CDataStartedSubstate::E)),",
          "485:             'D' => self.move_to(State::DoctypeStarted(DoctypeStartedSubstate::D)),",
          "487:             _ => self.handle_error(\"<!\", c),",
          "488:         }",
          "489:     }",
          "",
          "[Removed Lines]",
          "486:             'E' | 'A' | 'N' if matches!(self.normal_state, State::InsideDoctype) => self.move_to_with(State::InsideMarkupDeclaration, Token::MarkupDeclarationStart),",
          "",
          "[Added Lines]",
          "486:             'E' | 'A' | 'N' if matches!(self.normal_state, State::InsideDoctype) => {",
          "487:                 self.move_to_with_unread(State::InsideMarkupDeclaration, &[c], Token::MarkupDeclarationStart)",
          "488:             },",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "518:             ';'                        => Ok(Some(Token::ReferenceEnd)),",
          "519:             '\"'                        => self.move_to_with(State::InsideMarkupDeclarationQuotedString(QuoteStyle::Double), Token::DoubleQuote),",
          "520:             '\\''                       => self.move_to_with(State::InsideMarkupDeclarationQuotedString(QuoteStyle::Single), Token::SingleQuote),",
          "522:         }",
          "523:     }",
          "",
          "[Removed Lines]",
          "521:             _ => Ok(None),",
          "",
          "[Added Lines]",
          "523:             _                          => Ok(Some(Token::Character(c))),",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "526:         match c {",
          "527:             '\"' if q == QuoteStyle::Double  => self.move_to_with(State::InsideMarkupDeclaration, Token::DoubleQuote),",
          "528:             '\\'' if q == QuoteStyle::Single => self.move_to_with(State::InsideMarkupDeclaration, Token::SingleQuote),",
          "530:         }",
          "531:     }",
          "",
          "[Removed Lines]",
          "529:             _ => Ok(None),",
          "",
          "[Added Lines]",
          "531:             _                               => Ok(Some(Token::Character(c))),",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "857:     #[test]",
          "858:     fn doctype_with_internal_subset_test() {",
          "859:         let (mut lex, mut buf) = make_lex_and_buf(",
          "861:         );",
          "862:         assert_oks!(for lex and buf ;",
          "863:             Token::OpeningTagStart",
          "",
          "[Removed Lines]",
          "860:             r#\"<a><!DOCTYPE ab[<!ELEMENT ba \">>>>>\"> ]> \"#",
          "",
          "[Added Lines]",
          "862:             r#\"<a><!DOCTYPE ab[<!ELEMENT ba \">>>\"> ]> \"#",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "865:             Token::TagEnd",
          "866:             Token::DoctypeStart",
          "867:             Token::MarkupDeclarationStart",
          "868:             Token::DoubleQuote",
          "869:             Token::DoubleQuote",
          "870:             Token::TagEnd",
          "871:             Token::TagEnd",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "870:             Token::Character('E')",
          "871:             Token::Character('L')",
          "872:             Token::Character('E')",
          "873:             Token::Character('M')",
          "874:             Token::Character('E')",
          "875:             Token::Character('N')",
          "876:             Token::Character('T')",
          "877:             Token::Character(' ')",
          "878:             Token::Character('b')",
          "879:             Token::Character('a')",
          "880:             Token::Character(' ')",
          "882:             Token::Character('>')",
          "883:             Token::Character('>')",
          "884:             Token::Character('>')",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "877:     #[test]",
          "878:     fn doctype_internal_pi_comment() {",
          "879:         let (mut lex, mut buf) = make_lex_and_buf(",
          "881:         );",
          "882:         assert_oks!(for lex and buf ;",
          "883:             Token::DoctypeStart",
          "884:             Token::MarkupDeclarationStart",
          "885:             Token::TagEnd",
          "886:             Token::CommentStart",
          "887:             Token::Character(' ')",
          "",
          "[Removed Lines]",
          "880:             \"<!DOCTYPE a [\\n<!ELEMENT leopard ANY> <!-- <?non?>--> <?pi > ?> \\n]>\"",
          "",
          "[Added Lines]",
          "896:             \"<!DOCTYPE a [\\n<!ELEMENT l ANY> <!-- <?non?>--> <?pi > ?> \\n]>\"",
          "901:             Token::Character('E')",
          "902:             Token::Character('L')",
          "903:             Token::Character('E')",
          "904:             Token::Character('M')",
          "905:             Token::Character('E')",
          "906:             Token::Character('N')",
          "907:             Token::Character('T')",
          "908:             Token::Character(' ')",
          "909:             Token::Character('l')",
          "910:             Token::Character(' ')",
          "911:             Token::Character('A')",
          "912:             Token::Character('N')",
          "913:             Token::Character('Y')",
          "",
          "---------------"
        ],
        "src/reader/parser.rs||src/reader/parser.rs": [
          "File: src/reader/parser.rs -> src/reader/parser.rs",
          "--- Hunk 1 ---",
          "[Context before]",
          "141:     InsideCData,",
          "142:     InsideDeclaration(DeclarationSubstate),",
          "143:     InsideDoctype,",
          "144:     InsideDoctypeMarkupDeclaration,",
          "145:     InsideReference,",
          "146: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "144:     DoctypeMarkupDeclarationStart,",
          "145:     DoctypeMarkupDeclarationArgs,",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "340:             State::InsideProcessingInstruction(s) => self.inside_processing_instruction(t, s),",
          "341:             State::InsideDeclaration(s)           => self.inside_declaration(t, s),",
          "342:             State::InsideDoctype                  => self.inside_doctype(t),",
          "343:             State::InsideDoctypeMarkupDeclaration => self.inside_doctype_markup_declaration(t),",
          "344:             State::InsideOpeningTag(s)            => self.inside_opening_tag(t, s),",
          "345:             State::InsideClosingTag(s)            => self.inside_closing_tag_name(t, s),",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "345:             State::DoctypeMarkupDeclarationStart  => self.doctype_markup_declaration_start(t),",
          "346:             State::DoctypeMarkupDeclarationArgs   => self.doctype_markup_declaration_args(t),",
          "",
          "---------------"
        ],
        "src/reader/parser/inside_doctype.rs||src/reader/parser/inside_doctype.rs": [
          "File: src/reader/parser/inside_doctype.rs -> src/reader/parser/inside_doctype.rs",
          "--- Hunk 1 ---",
          "[Context before]",
          "3: use super::{PullParser, Result, State};",
          "",
          "[Removed Lines]",
          "1: use crate::reader::lexer::Token;",
          "",
          "[Added Lines]",
          "1: use crate::{reader::lexer::Token, common::is_whitespace_char};",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "10:             }",
          "12:             Token::MarkupDeclarationStart => {",
          "14:             },",
          "16:             _ => None,",
          "",
          "[Removed Lines]",
          "13:                 self.into_state_continue(State::InsideDoctypeMarkupDeclaration)",
          "",
          "[Added Lines]",
          "13:                 self.buf.clear();",
          "14:                 self.into_state_continue(State::DoctypeMarkupDeclarationStart)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "26:             _ => None,",
          "27:         }",
          "28:     }",
          "29: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "31:     pub fn doctype_markup_declaration_args(&mut self, t: Token) -> Option<Result> {",
          "32:         match t {",
          "33:             Token::TagEnd => {",
          "34:                 self.into_state_continue(State::InsideDoctype)",
          "35:             }",
          "36:             _ => None,",
          "37:         }",
          "38:     }",
          "40:     pub fn doctype_markup_declaration_start(&mut self, t: Token) -> Option<Result> {",
          "41:         match t {",
          "42:             Token::TagEnd => {",
          "43:                 self.into_state_continue(State::InsideDoctype)",
          "44:             }",
          "45:             Token::Character(c @ 'A'..='Z') => {",
          "46:                 self.buf.push(c);",
          "47:                 None",
          "48:             },",
          "49:             Token::Character(c) if is_whitespace_char(c) => {",
          "50:                 match self.buf.as_str() {",
          "51:                     \"ENTITY\" | \"NOTATION\" | \"ELEMENT\" | \"ATTLIST\" => self.into_state_continue(State::DoctypeMarkupDeclarationArgs),",
          "52:                     s => Some(self_error!(self; \"Unknown markup declaration: {}\", s)),",
          "53:                 }",
          "55:             },",
          "56:             _ => Some(self_error!(self; \"Incomplete markup declaration: {}\", t)),",
          "57:         }",
          "58:     }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "47f5afceb3cc1b2a67900ca9dc480643ed47537f",
      "candidate_info": {
        "commit_hash": "47f5afceb3cc1b2a67900ca9dc480643ed47537f",
        "repo": "00xc/xml-rs",
        "commit_url": "https://github.com/00xc/xml-rs/commit/47f5afceb3cc1b2a67900ca9dc480643ed47537f",
        "files": [
          "src/reader/lexer.rs"
        ],
        "message": "Don't end CDATA state on ]",
        "before_after_code_files": [
          "src/reader/lexer.rs||src/reader/lexer.rs"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "src/reader/lexer.rs||src/reader/lexer.rs"
          ],
          "candidate": [
            "src/reader/lexer.rs||src/reader/lexer.rs"
          ]
        }
      },
      "candidate_diff": {
        "src/reader/lexer.rs||src/reader/lexer.rs": [
          "File: src/reader/lexer.rs -> src/reader/lexer.rs",
          "--- Hunk 1 ---",
          "[Context before]",
          "164:     EmptyTagClosing,",
          "166:     CommentClosing(ClosingSubstate),",
          "168:     CDataClosing(ClosingSubstate),",
          "170:     InsideComment,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "170:     InvalidCDataClosing(ClosingSubstate),",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "319:         self.eof_handled = true;",
          "320:         self.pos = self.head_pos;",
          "321:         match self.st {",
          "322:             State::TagStarted | State::CommentOrCDataOrDoctypeStarted |",
          "323:             State::CommentStarted | State::CDataStarted(_)| State::DoctypeStarted(_) |",
          "324:             State::CommentClosing(ClosingSubstate::Second) |",
          "326:             State::InsideProcessingInstruction | State::ProcessingInstructionClosing |",
          "327:             State::DoctypeFinishing(_) =>",
          "328:                 Err(self.error(\"Unexpected end of stream\")),",
          "",
          "[Removed Lines]",
          "325:             State::InsideComment | State::InsideCdata |",
          "",
          "[Added Lines]",
          "324:             State::InsideCdata | State::CDataClosing(_) => Err(self.error(\"Unclosed CDATA\")),",
          "329:             State::InsideComment |",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "330:                 Ok(Some(Token::Character('/'))),",
          "331:             State::CommentClosing(ClosingSubstate::First) =>",
          "332:                 Ok(Some(Token::Character('-'))),",
          "334:                 Ok(Some(Token::Character(']'))),",
          "336:                 Ok(Some(Token::Chunk(\"]]\"))),",
          "337:             State::Normal =>",
          "338:                 Ok(None),",
          "",
          "[Removed Lines]",
          "333:             State::CDataClosing(ClosingSubstate::First) =>",
          "335:             State::CDataClosing(ClosingSubstate::Second) =>",
          "",
          "[Added Lines]",
          "337:             State::InvalidCDataClosing(ClosingSubstate::First) =>",
          "339:             State::InvalidCDataClosing(ClosingSubstate::Second) =>",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "369:             State::EmptyTagClosing                => self.empty_element_closing(c),",
          "370:             State::CommentClosing(s)              => self.comment_closing(c, s),",
          "371:             State::CDataClosing(s)                => self.cdata_closing(c, s),",
          "372:             State::InsideComment                  => self.inside_comment_state(c),",
          "373:             State::InsideCdata                    => self.inside_cdata(c),",
          "374:             State::InsideProcessingInstruction    => self.inside_processing_instruction(c),",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "376:             State::InvalidCDataClosing(s)         => self.invalid_cdata_closing(c, s),",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "412:             '='                        => Ok(Some(Token::EqualsSign)),",
          "413:             '\"'                        => Ok(Some(Token::DoubleQuote)),",
          "414:             '\\''                       => Ok(Some(Token::SingleQuote)),",
          "416:             '&'                        => Ok(Some(Token::ReferenceStart)),",
          "417:             ';'                        => Ok(Some(Token::ReferenceEnd)),",
          "418:             _ if is_whitespace_char(c) => Ok(Some(Token::Whitespace(c))),",
          "",
          "[Removed Lines]",
          "415:             ']'                        => self.move_to(State::CDataClosing(ClosingSubstate::First)),",
          "",
          "[Added Lines]",
          "420:             ']'                        => self.move_to(State::InvalidCDataClosing(ClosingSubstate::First)),",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "554:         match s {",
          "555:             ClosingSubstate::First => match c {",
          "556:                 ']' => self.move_to(State::CDataClosing(ClosingSubstate::Second)),",
          "557:                 _ => self.move_to_with_unread(State::Normal, &[c], Token::Character(']')),",
          "558:             },",
          "559:             ClosingSubstate::Second => match c {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "562:                 _ => self.move_to_with_unread(State::InsideCdata, &[c], Token::Character(']')),",
          "563:             },",
          "564:             ClosingSubstate::Second => match c {",
          "565:                 '>' => self.move_to_with(State::Normal, Token::CDataEnd),",
          "566:                 _ => self.move_to_with_unread(State::InsideCdata, &[']', c], Token::Character(']')),",
          "567:             },",
          "568:         }",
          "569:     }",
          "572:     fn invalid_cdata_closing(&mut self, c: char, s: ClosingSubstate) -> Result {",
          "573:         match s {",
          "574:             ClosingSubstate::First => match c {",
          "575:                 ']' => self.move_to(State::InvalidCDataClosing(ClosingSubstate::Second)),",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "737:         assert_none!(for lex and buf);",
          "738:     }",
          "740:     #[test]",
          "741:     fn doctype_test() {",
          "742:         let (mut lex, mut buf) = make_lex_and_buf(",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "759:     #[test]",
          "760:     fn cdata_closers_test() {",
          "761:         let (mut lex, mut buf) = make_lex_and_buf(",
          "762:             r#\"<![CDATA[] > ]> ]]><!---->]]<a>\"#",
          "763:         );",
          "765:         assert_oks!(for lex and buf ;",
          "766:             Token::CDataStart",
          "767:             Token::Character(']')",
          "768:             Token::Whitespace(' ')",
          "769:             Token::Character('>')",
          "770:             Token::Whitespace(' ')",
          "771:             Token::Character(']')",
          "772:             Token::Character('>')",
          "773:             Token::Whitespace(' ')",
          "774:             Token::CDataEnd",
          "775:             Token::CommentStart",
          "776:             Token::CommentEnd",
          "777:             Token::Character(']')",
          "778:             Token::Character(']')",
          "779:             Token::OpeningTagStart",
          "780:             Token::Character('a')",
          "781:             Token::TagEnd",
          "782:         );",
          "783:         assert_none!(for lex and buf);",
          "784:     }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "014d808be900c85a0afc5ccdfe668be040d175aa",
      "candidate_info": {
        "commit_hash": "014d808be900c85a0afc5ccdfe668be040d175aa",
        "repo": "00xc/xml-rs",
        "commit_url": "https://github.com/00xc/xml-rs/commit/014d808be900c85a0afc5ccdfe668be040d175aa",
        "files": [
          "src/reader/lexer.rs",
          "src/reader/parser.rs",
          "src/reader/parser/inside_doctype.rs",
          "tests/errata2e.fail.txt",
          "tests/oasis.fail.txt",
          "tests/sun-not-wf.fail.txt",
          "tests/sun-valid.fail.txt",
          "tests/xmltest.fail.txt"
        ],
        "message": "Parse predefined entities",
        "before_after_code_files": [
          "src/reader/lexer.rs||src/reader/lexer.rs",
          "src/reader/parser.rs||src/reader/parser.rs",
          "src/reader/parser/inside_doctype.rs||src/reader/parser/inside_doctype.rs"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "src/reader/lexer.rs||src/reader/lexer.rs",
            "src/reader/parser/inside_doctype.rs||src/reader/parser/inside_doctype.rs"
          ],
          "candidate": [
            "src/reader/lexer.rs||src/reader/lexer.rs",
            "src/reader/parser/inside_doctype.rs||src/reader/parser/inside_doctype.rs"
          ]
        }
      },
      "candidate_diff": {
        "src/reader/lexer.rs||src/reader/lexer.rs": [
          "File: src/reader/lexer.rs -> src/reader/lexer.rs",
          "--- Hunk 1 ---",
          "[Context before]",
          "590:             '<'                        => self.move_to(State::TagStarted),",
          "591:             '&'                        => Ok(Some(Token::ReferenceStart)),",
          "592:             ';'                        => Ok(Some(Token::ReferenceEnd)),",
          "594:         }",
          "595:     }",
          "",
          "[Removed Lines]",
          "593:             _ => Ok(None),",
          "",
          "[Added Lines]",
          "593:             '\"'                        => Ok(Some(Token::DoubleQuote)),",
          "594:             '\\''                       => Ok(Some(Token::SingleQuote)),",
          "595:             _                          => Ok(Some(Token::Character(c))),",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "886:             Token::Character('a')",
          "887:             Token::TagEnd",
          "888:             Token::DoctypeStart",
          "889:             Token::TagEnd",
          "890:             Token::Character(' ')",
          "891:         );",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "891:             Token::Character(' ')",
          "892:             Token::Character('a')",
          "893:             Token::Character('b')",
          "894:             Token::Character(' ')",
          "895:             Token::Character('x')",
          "896:             Token::Character('x')",
          "897:             Token::Character(' ')",
          "898:             Token::Character('z')",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "925:             Token::Character('a')",
          "926:             Token::TagEnd",
          "927:             Token::DoctypeStart",
          "928:             Token::MarkupDeclarationStart",
          "929:             Token::Character('E')",
          "930:             Token::Character('L')",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "938:             Token::Character(' ')",
          "939:             Token::Character('a')",
          "940:             Token::Character('b')",
          "941:             Token::Character('[')",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "943:             Token::Character('>')",
          "944:             Token::DoubleQuote",
          "945:             Token::TagEnd",
          "946:             Token::TagEnd",
          "947:             Token::Character(' ')",
          "948:         );",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "960:             Token::Character(' ')",
          "961:             Token::Character(']')",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "956:         );",
          "957:         assert_oks!(for lex and buf ;",
          "958:             Token::DoctypeStart",
          "959:             Token::MarkupDeclarationStart",
          "960:             Token::Character('E')",
          "961:             Token::Character('L')",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "975:             Token::Character(' ')",
          "976:             Token::Character('a')",
          "977:             Token::Character(' ')",
          "978:             Token::Character('[')",
          "979:             Token::Character('\\n')",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "971:             Token::Character('N')",
          "972:             Token::Character('Y')",
          "973:             Token::TagEnd",
          "974:             Token::CommentStart",
          "975:             Token::Character(' ')",
          "976:             Token::Character('<')",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "995:             Token::Character(' ')",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "981:             Token::Character('?')",
          "982:             Token::Character('>')",
          "983:             Token::CommentEnd",
          "984:             Token::ProcessingInstructionStart",
          "985:             Token::Character('p')",
          "986:             Token::Character('i')",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1006:             Token::Character(' ')",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "988:             Token::TagEnd // not really",
          "989:             Token::Character(' ')",
          "990:             Token::ProcessingInstructionEnd",
          "991:             Token::TagEnd // DTD",
          "992:         );",
          "993:         assert_none!(for lex and buf);",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1014:             Token::Character(' ')",
          "1015:             Token::Character('\\n')",
          "1016:             Token::Character(']')",
          "",
          "---------------"
        ],
        "src/reader/parser.rs||src/reader/parser.rs": [
          "File: src/reader/parser.rs -> src/reader/parser.rs",
          "--- Hunk 1 ---",
          "[Context before]",
          "193: #[derive(Copy, Clone, PartialEq)]",
          "194: pub enum DoctypeSubstate {",
          "195:     Outside,",
          "196:     InsideName,",
          "197:     BeforeEntityName,",
          "198:     EntityName,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "196:     String,",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "200:     EntityValue,",
          "201:     NumericReferenceStart,",
          "202:     NumericReference,",
          "203:     SkipDeclaration,",
          "204: }",
          "206: #[derive(Copy, Clone, PartialEq)]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "205:     PEReferenceInValue,",
          "206:     PEReferenceInDtd,",
          "208:     PEReferenceDefinitionStart,",
          "209:     PEReferenceDefinition,",
          "211:     Comment,",
          "",
          "---------------"
        ],
        "src/reader/parser/inside_doctype.rs||src/reader/parser/inside_doctype.rs": [
          "File: src/reader/parser/inside_doctype.rs -> src/reader/parser/inside_doctype.rs",
          "--- Hunk 1 ---",
          "[Context before]",
          "8:             DoctypeSubstate::Outside => match t {",
          "9:                 Token::TagEnd => {",
          "10:                     self.into_state_continue(State::OutsideTag)",
          "13:                 Token::MarkupDeclarationStart => {",
          "14:                     self.buf.clear();",
          "15:                     self.into_state_continue(State::InsideDoctype(DoctypeSubstate::InsideName))",
          "16:                 },",
          "18:                 _ => None,",
          "19:             },",
          "20:             DoctypeSubstate::InsideName => match t {",
          "21:                 Token::Character(c @ 'A'..='Z') => {",
          "22:                     self.buf.push(c);",
          "",
          "[Removed Lines]",
          "11:                 }",
          "",
          "[Added Lines]",
          "11:                 },",
          "16:                 Token::Character('%') => {",
          "17:                     self.data.ref_data.clear();",
          "18:                     self.data.ref_data.push('%');",
          "19:                     self.into_state_continue(State::InsideDoctype(DoctypeSubstate::PEReferenceInDtd))",
          "20:                 },",
          "21:                 Token::CommentStart => {",
          "22:                     self.into_state_continue(State::InsideDoctype(DoctypeSubstate::Comment))",
          "23:                 },",
          "24:                 Token::SingleQuote | Token::DoubleQuote => {",
          "26:                     self.data.quote = Some(super::QuoteToken::from_token(&t));",
          "27:                     self.into_state_continue(State::InsideDoctype(DoctypeSubstate::String))",
          "28:                 },",
          "29:                 Token::CDataEnd | Token::CDataStart => Some(self_error!(self; \"Unexpected token {}\", t)),",
          "33:             DoctypeSubstate::String => match t {",
          "34:                 Token::SingleQuote if self.data.quote != Some(QuoteToken::SingleQuoteToken) => { None },",
          "35:                 Token::DoubleQuote if self.data.quote != Some(QuoteToken::DoubleQuoteToken) => { None },",
          "36:                 Token::SingleQuote | Token::DoubleQuote => {",
          "37:                     self.data.quote = None;",
          "38:                     self.into_state_continue(State::InsideDoctype(DoctypeSubstate::Outside))",
          "39:                 },",
          "40:                 _ => None,",
          "41:             },",
          "42:             DoctypeSubstate::Comment => match t {",
          "43:                 Token::CommentEnd => {",
          "44:                     self.into_state_continue(State::InsideDoctype(DoctypeSubstate::Outside))",
          "45:                 },",
          "46:                 _ => None,",
          "47:             },",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "36:                 self.data.name.clear();",
          "37:                 match t {",
          "38:                     Token::Character(c) if is_whitespace_char(c) => None,",
          "41:                     Token::Character(c) if is_name_start_char(c) => {",
          "42:                         self.data.name.push(c);",
          "43:                         self.into_state_continue(State::InsideDoctype(DoctypeSubstate::EntityName))",
          "",
          "[Removed Lines]",
          "40:                     Token::Character('%') => self.into_state_continue(State::InsideDoctype(DoctypeSubstate::SkipDeclaration)),",
          "",
          "[Added Lines]",
          "67:                     Token::Character('%') => { // % is for PEDecl",
          "68:                         self.data.name.push('%');",
          "69:                         self.into_state_continue(State::InsideDoctype(DoctypeSubstate::PEReferenceDefinitionStart))",
          "70:                     },",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "77:                 Token::SingleQuote if self.data.quote != Some(QuoteToken::SingleQuoteToken) => { self.buf.push('\\''); None },",
          "78:                 Token::DoubleQuote if self.data.quote != Some(QuoteToken::DoubleQuoteToken) => { self.buf.push('\"'); None },",
          "79:                 Token::SingleQuote | Token::DoubleQuote => {",
          "80:                     let name = self.data.take_name();",
          "81:                     let val = self.take_buf();",
          "83:                     self.entities.entry(name).or_insert(val); // First wins",
          "84:                     self.into_state_continue(State::InsideDoctype(DoctypeSubstate::SkipDeclaration)) // FIXME",
          "85:                 },",
          "87:                     self.data.ref_data.clear();",
          "88:                     self.into_state_continue(State::InsideDoctype(DoctypeSubstate::NumericReferenceStart))",
          "89:                 },",
          "90:                 Token::Character(c) => {",
          "91:                     self.buf.push(c);",
          "92:                     None",
          "93:                 },",
          "94:                 _ => Some(self_error!(self; \"Expected entity value, found {}\", t)),",
          "95:             },",
          "96:             DoctypeSubstate::NumericReferenceStart => match t {",
          "97:                 Token::Character('#') => {",
          "98:                     self.into_state_continue(State::InsideDoctype(DoctypeSubstate::NumericReference))",
          "",
          "[Removed Lines]",
          "82:                     self.data.quote = None;",
          "86:                 Token::Character('&') => {",
          "",
          "[Added Lines]",
          "110:                     self.data.quote = None;",
          "116:                 Token::ReferenceStart | Token::Character('&') => {",
          "120:                 Token::Character('%') => {",
          "121:                     self.data.ref_data.clear();",
          "122:                     self.data.ref_data.push('%'); // include literal % in the name to distinguish from regular entities",
          "123:                     self.into_state_continue(State::InsideDoctype(DoctypeSubstate::PEReferenceInValue))",
          "124:                 },",
          "131:             DoctypeSubstate::PEReferenceDefinitionStart => match t {",
          "132:                 Token::Character(c) if is_whitespace_char(c) => {",
          "133:                     None",
          "134:                 },",
          "135:                 Token::Character(c) if is_name_start_char(c) => {",
          "136:                     debug_assert_eq!(self.data.name, \"%\");",
          "137:                     self.data.name.push(c);",
          "138:                     self.into_state_continue(State::InsideDoctype(DoctypeSubstate::PEReferenceDefinition))",
          "139:                 },",
          "140:                 _ => Some(self_error!(self; \"Unexpected {} in entity\", t)),",
          "141:             },",
          "142:             DoctypeSubstate::PEReferenceDefinition => match t {",
          "143:                 Token::Character(c) if is_name_char(c) => {",
          "144:                     self.data.name.push(c);",
          "145:                     None",
          "146:                 },",
          "147:                 Token::Character(c) if is_whitespace_char(c) => {",
          "148:                     self.into_state_continue(State::InsideDoctype(DoctypeSubstate::BeforeEntityValue))",
          "149:                 },",
          "150:                 _ => Some(self_error!(self; \"Unexpected {} in entity\", t)),",
          "151:             },",
          "152:             DoctypeSubstate::PEReferenceInDtd => match t {",
          "153:                 Token::Character(c) if is_name_char(c) => {",
          "154:                     self.data.ref_data.push(c);",
          "155:                     None",
          "156:                 },",
          "157:                 Token::ReferenceEnd | Token::Character(';') => {",
          "158:                     let name = self.data.take_ref_data();",
          "159:                     match self.entities.get(&name) {",
          "160:                         Some(ent) => {",
          "161:                             if let Err(e) = self.lexer.reparse(ent) {",
          "162:                                 return Some(Err(e));",
          "163:                             }",
          "164:                             self.into_state_continue(State::InsideDoctype(DoctypeSubstate::Outside))",
          "165:                         },",
          "166:                         None => Some(self_error!(self; \"Undefined PE entity {}\", name)),",
          "167:                     }",
          "168:                 },",
          "169:                 _ => Some(self_error!(self; \"Unexpected {} in entity\", t)),",
          "170:             },",
          "171:             DoctypeSubstate::PEReferenceInValue => match t {",
          "172:                 Token::Character(c) if is_name_char(c) => {",
          "173:                     self.data.ref_data.push(c);",
          "174:                     None",
          "175:                 },",
          "176:                 Token::ReferenceEnd | Token::Character(';') => {",
          "177:                     let name = self.data.take_ref_data();",
          "178:                     match self.entities.get(&name) {",
          "179:                         Some(ent) => {",
          "180:                             self.buf.push_str(ent);",
          "181:                             self.into_state_continue(State::InsideDoctype(DoctypeSubstate::EntityValue))",
          "182:                         },",
          "183:                         None => Some(self_error!(self; \"Undefined PE entity {}\", name)),",
          "184:                     }",
          "185:                 },",
          "186:                 _ => Some(self_error!(self; \"Unexpected {} in entity\", t)),",
          "187:             },",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "100:                 Token::Character(c) => {",
          "101:                     self.buf.push('&');",
          "102:                     self.buf.push(c);",
          "103:                     self.into_state_continue(State::InsideDoctype(DoctypeSubstate::EntityValue))",
          "104:                 },",
          "105:                 _ => Some(self_error!(self; \"Unexpected {} in entity\", t)),",
          "106:             },",
          "107:             DoctypeSubstate::NumericReference => match t {",
          "109:                     let r = self.data.take_ref_data();",
          "111:                     match self.numeric_reference_from_str(&r) {",
          "",
          "[Removed Lines]",
          "108:                 Token::Character(';') => {",
          "",
          "[Added Lines]",
          "201:                 Token::ReferenceEnd | Token::Character(';') => {",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "cf4222887c9e2df2c40ec40c43e3d883be8dfced",
      "candidate_info": {
        "commit_hash": "cf4222887c9e2df2c40ec40c43e3d883be8dfced",
        "repo": "00xc/xml-rs",
        "commit_url": "https://github.com/00xc/xml-rs/commit/cf4222887c9e2df2c40ec40c43e3d883be8dfced",
        "files": [
          "src/reader/lexer.rs",
          "src/reader/parser/inside_processing_instruction.rs",
          "src/reader/parser/outside_tag.rs",
          "tests/event_reader.rs",
          "tests/xmlconf.rs"
        ],
        "message": "Make lexer aware of PIs",
        "before_after_code_files": [
          "src/reader/lexer.rs||src/reader/lexer.rs",
          "src/reader/parser/inside_processing_instruction.rs||src/reader/parser/inside_processing_instruction.rs",
          "src/reader/parser/outside_tag.rs||src/reader/parser/outside_tag.rs",
          "tests/event_reader.rs||tests/event_reader.rs",
          "tests/xmlconf.rs||tests/xmlconf.rs"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "src/reader/lexer.rs||src/reader/lexer.rs",
            "src/reader/parser/inside_processing_instruction.rs||src/reader/parser/inside_processing_instruction.rs",
            "src/reader/parser/outside_tag.rs||src/reader/parser/outside_tag.rs",
            "tests/xmlconf.rs||tests/xmlconf.rs"
          ],
          "candidate": [
            "src/reader/lexer.rs||src/reader/lexer.rs",
            "src/reader/parser/inside_processing_instruction.rs||src/reader/parser/inside_processing_instruction.rs",
            "src/reader/parser/outside_tag.rs||src/reader/parser/outside_tag.rs",
            "tests/xmlconf.rs||tests/xmlconf.rs"
          ]
        }
      },
      "candidate_diff": {
        "src/reader/lexer.rs||src/reader/lexer.rs": [
          "File: src/reader/lexer.rs -> src/reader/lexer.rs",
          "--- Hunk 1 ---",
          "[Context before]",
          "170:     InsideComment,",
          "172:     InsideCdata,",
          "173: }",
          "175: #[derive(Copy, Clone)]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "174:     InsideProcessingInstruction,",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "332:             State::CommentStarted | State::CDataStarted(_)| State::DoctypeStarted(_) |",
          "333:             State::CommentClosing(ClosingSubstate::Second) |",
          "334:             State::InsideComment | State::InsideCdata |",
          "335:             State::DoctypeFinishing(_) =>",
          "336:                 Err(self.error(\"Unexpected end of stream\")),",
          "339:             State::EmptyTagClosing =>",
          "340:                 Ok(Some(Token::Character('/'))),",
          "341:             State::CommentClosing(ClosingSubstate::First) =>",
          "",
          "[Removed Lines]",
          "337:             State::ProcessingInstructionClosing =>",
          "338:                 Ok(Some(Token::Character('?'))),",
          "",
          "[Added Lines]",
          "337:             State::InsideProcessingInstruction | State::ProcessingInstructionClosing |",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "376:             State::CDataStarted(s)                => self.cdata_started(c, s),",
          "377:             State::DoctypeStarted(s)              => self.doctype_started(c, s),",
          "378:             State::DoctypeFinishing(d)            => self.doctype_finishing(c, d),",
          "380:             State::EmptyTagClosing                => self.empty_element_closing(c),",
          "381:             State::CommentClosing(s)              => self.comment_closing(c, s),",
          "382:             State::CDataClosing(s)                => self.cdata_closing(c, s),",
          "383:             State::InsideComment                  => self.inside_comment_state(c),",
          "384:             State::InsideCdata                    => self.inside_cdata(c),",
          "385:         }",
          "386:     }",
          "",
          "[Removed Lines]",
          "379:             State::ProcessingInstructionClosing   => self.processing_instruction_closing(c),",
          "",
          "[Added Lines]",
          "385:             State::InsideProcessingInstruction    => self.inside_processing_instruction(c),",
          "386:             State::ProcessingInstructionClosing   => self.processing_instruction_closing(c),",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "421:             '='                        => Ok(Some(Token::EqualsSign)),",
          "422:             '\"'                        => Ok(Some(Token::DoubleQuote)),",
          "423:             '\\''                       => Ok(Some(Token::SingleQuote)),",
          "425:             ']'                        => self.move_to(State::CDataClosing(ClosingSubstate::First)),",
          "426:             '&'                        => Ok(Some(Token::ReferenceStart)),",
          "427:             ';'                        => Ok(Some(Token::ReferenceEnd)),",
          "",
          "[Removed Lines]",
          "424:             '?'                        => self.move_to(State::ProcessingInstructionClosing),",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "438:         }",
          "439:     }",
          "441:     fn inside_comment_state(&mut self, c: char) -> Result {",
          "442:         match c {",
          "443:             '-'                        => self.move_to(State::CommentClosing(ClosingSubstate::First)),",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "442:     fn inside_processing_instruction(&mut self, c: char) -> Result {",
          "443:         match c {",
          "444:             '?'                        => self.move_to(State::ProcessingInstructionClosing),",
          "445:             '<'                        => Ok(Some(Token::OpeningTagStart)),",
          "446:             '>'                        => Ok(Some(Token::TagEnd)),",
          "447:             '/'                        => Ok(Some(Token::ClosingTagStart)),",
          "448:             '='                        => Ok(Some(Token::EqualsSign)),",
          "449:             '\"'                        => Ok(Some(Token::DoubleQuote)),",
          "450:             '\\''                       => Ok(Some(Token::SingleQuote)),",
          "451:             '&'                        => Ok(Some(Token::ReferenceStart)),",
          "452:             ';'                        => Ok(Some(Token::ReferenceEnd)),",
          "453:             _ if is_whitespace_char(c) => Ok(Some(Token::Whitespace(c))),",
          "454:             _                          => Ok(Some(Token::Character(c)))",
          "455:         }",
          "456:     }",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "450:     fn tag_opened(&mut self, c: char) -> Result {",
          "451:         match c {",
          "453:             '/'                        => self.move_to_with(State::Normal, Token::ClosingTagStart),",
          "454:             '!'                        => self.move_to(State::CommentOrCDataOrDoctypeStarted),",
          "455:             _ if is_whitespace_char(c) => self.move_to_with_unread(State::Normal, &[c], Token::OpeningTagStart),",
          "",
          "[Removed Lines]",
          "452:             '?'                        => self.move_to_with(State::Normal, Token::ProcessingInstructionStart),",
          "",
          "[Added Lines]",
          "469:             '?'                        => self.move_to_with(State::InsideProcessingInstruction, Token::ProcessingInstructionStart),",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "516:     fn processing_instruction_closing(&mut self, c: char) -> Result {",
          "517:         match c {",
          "518:             '>' => self.move_to_with(State::Normal, Token::ProcessingInstructionEnd),",
          "520:         }",
          "521:     }",
          "",
          "[Removed Lines]",
          "519:             _ => self.move_to_with_unread(State::Normal, &[c], Token::Character('?')),",
          "",
          "[Added Lines]",
          "536:             _ => self.move_to_with_unread(State::InsideProcessingInstruction, &[c], Token::Character('?')),",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "594:         (Lexer::new(), BufReader::new(Cursor::new(s.to_owned().into_bytes())))",
          "595:     }",
          "597:     #[test]",
          "598:     fn simple_lexer_test() {",
          "599:         let (mut lex, mut buf) = make_lex_and_buf(",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "614:     #[test]",
          "615:     fn tricky_pi() {",
          "616:         let (mut lex, mut buf) = make_lex_and_buf(",
          "617:             r#\"<?x<!-- &??><x>\"#",
          "618:         );",
          "620:         assert_oks!(for lex and buf ;",
          "621:             Token::ProcessingInstructionStart",
          "622:             Token::Character('x')",
          "623:             Token::OpeningTagStart // processing of <?xml?> relies on the extra tokens",
          "624:             Token::Character('!')",
          "625:             Token::Character('-')",
          "626:             Token::Character('-')",
          "627:             Token::Whitespace(' ')",
          "628:             Token::ReferenceStart",
          "629:             Token::Character('?')",
          "630:             Token::ProcessingInstructionEnd",
          "631:             Token::OpeningTagStart",
          "632:             Token::Character('x')",
          "633:             Token::TagEnd",
          "634:         );",
          "635:         assert_none!(for lex and buf);",
          "636:     }",
          "",
          "---------------"
        ],
        "src/reader/parser/inside_processing_instruction.rs||src/reader/parser/inside_processing_instruction.rs": [
          "File: src/reader/parser/inside_processing_instruction.rs -> src/reader/parser/inside_processing_instruction.rs",
          "--- Hunk 1 ---",
          "[Context before]",
          "59:                         _ => {",
          "61:                             self.data.name = name;",
          "62:                             self.into_state_continue(State::InsideProcessingInstruction(ProcessingInstructionSubstate::PIInsideData))",
          "63:                         }",
          "",
          "[Removed Lines]",
          "60:                             self.lexer.disable_errors();  // data is arbitrary, so disable errors",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "src/reader/parser/outside_tag.rs||src/reader/parser/outside_tag.rs": [
          "File: src/reader/parser/outside_tag.rs -> src/reader/parser/outside_tag.rs",
          "--- Hunk 1 ---",
          "[Context before]",
          "53:                     self.push_pos();",
          "54:                 }",
          "57:                 self.into_state_continue(State::InsideCData)",
          "58:             }",
          "",
          "[Removed Lines]",
          "56:                 self.lexer.disable_errors();",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "115:                     }",
          "117:                     Token::CDataStart => {",
          "120:                         self.into_state(State::InsideCData, next_event)",
          "121:                     }",
          "",
          "[Removed Lines]",
          "119:                         self.lexer.disable_errors();",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "tests/event_reader.rs||tests/event_reader.rs": [
          "File: tests/event_reader.rs -> tests/event_reader.rs",
          "--- Hunk 1 ---",
          "[Context before]",
          "181: fn eof_1() {",
          "182:     test(",
          "183:         br#\"<?xml\"#,",
          "185:         ParserConfig::new(),",
          "186:         false,",
          "187:     );",
          "",
          "[Removed Lines]",
          "184:         br#\"1:6 Unexpected end of stream: no root element found\"#,",
          "",
          "[Added Lines]",
          "184:         br#\"1:6 Unexpected end of stream\"#,",
          "",
          "---------------"
        ],
        "tests/xmlconf.rs||tests/xmlconf.rs": [
          "File: tests/xmlconf.rs -> tests/xmlconf.rs",
          "--- Hunk 1 ---",
          "[Context before]",
          "282:         \"o-p68pass1\", // Valid entity references.  Also ensures that a charref to           '&' isn't interpreted as an entity reference open delimiter",
          "283:         \"o-p04pass1\", // names with all valid ASCII characters, and one from each               other class in NameChar",
          "284:         \"o-p05pass1\", // various valid Name constructions",
          "286:         \"o-p01fail1\", // S cannot occur before the prolog",
          "287:         \"o-p01fail2\", // comments cannot occur before the prolog",
          "288:         \"o-p01fail3\", // only one document element",
          "",
          "[Removed Lines]",
          "285:         \"o-p16pass1\", // Valid form of Processing Instruction. Shows that whitespace character data is valid before end of processing instruction.",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "1fa93e3531acfd30b8a4fb2bd01e9bcb3e99a38f",
      "candidate_info": {
        "commit_hash": "1fa93e3531acfd30b8a4fb2bd01e9bcb3e99a38f",
        "repo": "00xc/xml-rs",
        "commit_url": "https://github.com/00xc/xml-rs/commit/1fa93e3531acfd30b8a4fb2bd01e9bcb3e99a38f",
        "files": [
          "src/lib.rs",
          "src/reader/error.rs",
          "src/reader/lexer.rs",
          "src/util.rs",
          "src/writer/config.rs",
          "src/writer/emitter.rs"
        ],
        "message": "Remove unused",
        "before_after_code_files": [
          "src/lib.rs||src/lib.rs",
          "src/reader/error.rs||src/reader/error.rs",
          "src/reader/lexer.rs||src/reader/lexer.rs",
          "src/util.rs||src/util.rs",
          "src/writer/config.rs||src/writer/config.rs",
          "src/writer/emitter.rs||src/writer/emitter.rs"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "src/reader/lexer.rs||src/reader/lexer.rs"
          ],
          "candidate": [
            "src/reader/lexer.rs||src/reader/lexer.rs"
          ]
        }
      },
      "candidate_diff": {
        "src/lib.rs||src/lib.rs": [
          "File: src/lib.rs -> src/lib.rs",
          "--- Hunk 1 ---",
          "[Context before]",
          "4: #![forbid(non_camel_case_types)]",
          "5: #![forbid(unsafe_code)]",
          "6: #![allow(clippy::redundant_closure_for_method_calls)]",
          "",
          "[Removed Lines]",
          "2: #![allow(dead_code)]",
          "3: #![allow(unused_variables)]",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "20: pub mod attribute;",
          "21: pub mod common;",
          "22: pub mod escape;",
          "23: pub mod macros;",
          "24: pub mod name;",
          "25: pub mod namespace;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "21: #[doc(hidden)] // FIXME: not supposed to be public",
          "",
          "---------------"
        ],
        "src/reader/error.rs||src/reader/error.rs": [
          "File: src/reader/error.rs -> src/reader/error.rs",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: }",
          "22: #[derive(Debug, Clone, PartialEq)]",
          "23: pub(crate) enum SyntaxError {",
          "24:     CannotRedefineXmlnsPrefix,",
          "25:     CannotRedefineXmlPrefix,",
          "29:     EntityTooBig,",
          "31:     EmptyEntity,",
          "32:     NoRootElement,",
          "33:     ProcessingInstructionWithoutName,",
          "",
          "[Removed Lines]",
          "27:     DoubleDashInComment,",
          "",
          "[Added Lines]",
          "23: #[non_exhaustive]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "43:     UnexpectedTokenInEntity(Token),",
          "44:     UnexpectedTokenInClosingTag(Token),",
          "45:     UnexpectedTokenInOpeningTag(Token),",
          "47:     InvalidQualifiedName(Box<str>),",
          "48:     UnboundAttribute(Box<str>),",
          "49:     UnboundElementPrefix(Box<str>),",
          "50:     UnexpectedClosingTag(Box<str>),",
          "51:     UnexpectedName(Box<str>),",
          "55:     CannotUndefinePrefix(Box<str>),",
          "56:     InvalidCharacterEntity(u32),",
          "57:     InvalidDefaultNamespace(Box<str>),",
          "",
          "[Removed Lines]",
          "46:     UnexpectedTokenInsideXml(Token),",
          "52:     UnexpectedProcessingInstruction(Box<str>, Token),",
          "",
          "[Added Lines]",
          "51:     UnexpectedProcessingInstruction(Box<str>, Token),",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "84:         match *self {",
          "85:             Self::CannotRedefineXmlnsPrefix => \"Cannot redefine XMLNS prefix\".into(),",
          "86:             Self::CannotRedefineXmlPrefix => \"Default XMLNS prefix cannot be rebound to another value\".into(),",
          "88:             Self::EmptyEntity => \"Encountered empty entity\".into(),",
          "89:             Self::EntityTooBig => \"Entity too big\".into(),",
          "90:             Self::NoRootElement => \"Unexpected end of stream: no root element found\".into(),",
          "",
          "[Removed Lines]",
          "87:             Self::DoubleDashInComment => \"Double dash \\\"--\\\" is not allowed in comments\".into(),",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "118:             Self::UnexpectedTokenInClosingTag(token) => format!(\"Unexpected token inside closing tag: {token}\").into(),",
          "119:             Self::UnexpectedTokenInEntity(token) => format!(\"Unexpected token inside entity: {token}\").into(),",
          "120:             Self::UnexpectedTokenInOpeningTag(token) => format!(\"Unexpected token inside opening tag: {token}\").into(),",
          "122:             Self::UnexpectedTokenOutsideRoot(token) => format!(\"Unexpected characters outside the root element: {token}\").into(),",
          "123:             Self::UnexpectedXmlVersion(ref version) => format!(\"Invalid XML version: {version}\").into(),",
          "124:             Self::UnknownMarkupDeclaration(ref v) => format!(\"Unknown markup declaration: {v}\").into(),",
          "",
          "[Removed Lines]",
          "121:             Self::UnexpectedTokenInsideXml(token) => format!(\"Unexpected token inside XML declaration: {token}\").into(),",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "src/reader/lexer.rs||src/reader/lexer.rs": [
          "File: src/reader/lexer.rs -> src/reader/lexer.rs",
          "--- Hunk 1 ---",
          "[Context before]",
          "235:     char_queue: VecDeque<char>,",
          "237:     normal_state: State,",
          "239:     inside_token: bool,",
          "240:     eof_handled: bool,",
          "241:     reparse_depth: u8,",
          "242: }",
          "244: impl Position for Lexer {",
          "",
          "[Removed Lines]",
          "238:     skip_errors: bool,",
          "",
          "[Added Lines]",
          "241:     #[cfg(test)]",
          "242:     skip_errors: bool,",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "257:             char_queue: VecDeque::with_capacity(4),  // TODO: check size",
          "258:             st: State::Normal,",
          "259:             normal_state: State::Normal,",
          "261:             inside_token: false,",
          "262:             eof_handled: false,",
          "263:             reparse_depth: 0,",
          "264:         }",
          "265:     }",
          "",
          "[Removed Lines]",
          "260:             skip_errors: false,",
          "",
          "[Added Lines]",
          "264:             #[cfg(test)]",
          "265:             skip_errors: false,",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "280:     #[inline]",
          "",
          "[Removed Lines]",
          "277:     pub(crate) fn disable_errors(&mut self) { self.skip_errors = true; }",
          "",
          "[Added Lines]",
          "279:     #[cfg(test)] fn disable_errors(&mut self) { self.skip_errors = true; }",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "450:     fn handle_error(&mut self, chunk: &'static str, c: char) -> Result {",
          "451:         debug_assert!(!chunk.is_empty());",
          "453:         if self.skip_errors {",
          "454:             let mut chars = chunk.chars();",
          "455:             let first = chars.next().unwrap_or('\\0');",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "455:         #[cfg(test)]",
          "",
          "---------------"
        ],
        "src/util.rs||src/util.rs": [
          "File: src/util.rs -> src/util.rs",
          "--- Hunk 1 ---",
          "[Context before]",
          "291:         struct ErrorReader;",
          "292:         impl io::Read for ErrorReader {",
          "294:                 Err(io::Error::new(io::ErrorKind::Other, \"test error\"))",
          "295:             }",
          "296:         }",
          "",
          "[Removed Lines]",
          "293:             fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {",
          "",
          "[Added Lines]",
          "293:             fn read(&mut self, _: &mut [u8]) -> io::Result<usize> {",
          "",
          "---------------"
        ],
        "src/writer/config.rs||src/writer/config.rs": [
          "File: src/writer/config.rs -> src/writer/config.rs"
        ],
        "src/writer/emitter.rs||src/writer/emitter.rs": [
          "File: src/writer/emitter.rs -> src/writer/emitter.rs",
          "--- Hunk 1 ---",
          "[Context before]",
          "133:         }",
          "134:     }",
          "143:     fn write_newline<W: Write>(&mut self, target: &mut W, level: usize) -> Result<()> {",
          "144:         target.write_all(self.config.line_separator.as_bytes())?;",
          "145:         for _ in 0..level {",
          "",
          "[Removed Lines]",
          "136:     #[inline]",
          "137:     fn reset_state(&mut self) {",
          "138:         if let Some(e) = self.indent_stack.last_mut() {",
          "140:         }",
          "141:     }",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ]
      }
    }
  ]
}