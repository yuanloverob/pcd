{
  "cve_id": "CVE-2024-56128",
  "cve_desc": "Incorrect Implementation of Authentication Algorithm in Apache Kafka's SCRAM implementation.\n\nIssue Summary:\nApache Kafka's implementation of the Salted Challenge Response Authentication Mechanism (SCRAM) did not fully adhere to the requirements of RFC 5802 [1].\nSpecifically, as per RFC 5802, the server must verify that the nonce sent by the client in the second message matches the nonce sent by the server in its first message.\nHowever, Kafka's SCRAM implementation did not perform this validation.\n\nImpact:\nThis vulnerability is exploitable only when an attacker has plaintext access to the SCRAM authentication exchange. However, the usage of SCRAM over plaintext is strongly\ndiscouraged as it is considered an insecure practice [2]. Apache Kafka recommends deploying SCRAM exclusively with TLS encryption to protect SCRAM exchanges from interception [3].\nDeployments using SCRAM with TLS are not affected by this issue.\n\nHow to Detect If You Are Impacted:\nIf your deployment uses SCRAM authentication over plaintext communication channels (without TLS encryption), you are likely impacted.\nTo check if TLS is enabled, review your server.properties configuration file for listeners property. If you have SASL_PLAINTEXT in the listeners, then you are likely impacted.\n\nFix Details:\nThe issue has been addressed by introducing nonce verification in the final message of the SCRAM authentication exchange to ensure compliance with RFC 5802.\n\nAffected Versions:\nApache Kafka versions 0.10.2.0 through 3.9.0, excluding the fixed versions below.\n\nFixed Versions:\n3.9.0\n3.8.1\n3.7.2\n\nUsers are advised to upgrade to 3.7.2 or later to mitigate this issue.\n\nRecommendations for Mitigation:\nUsers unable to upgrade to the fixed versions can mitigate the issue by:\n- Using TLS with SCRAM Authentication:\nAlways deploy SCRAM over TLS to encrypt authentication exchanges and protect against interception.\n- Considering Alternative Authentication Mechanisms:\nEvaluate alternative authentication mechanisms, such as PLAIN, Kerberos or OAuth with TLS, which provide additional layers of security.",
  "repo": "apache/kafka",
  "patch_hash": "2cbc5bd3ca22185d9cd357c9db23a2cfb43a0fff",
  "patch_info": {
    "commit_hash": "2cbc5bd3ca22185d9cd357c9db23a2cfb43a0fff",
    "repo": "apache/kafka",
    "commit_url": "https://github.com/apache/kafka/commit/2cbc5bd3ca22185d9cd357c9db23a2cfb43a0fff",
    "files": [
      "core/src/main/scala/kafka/tools/StorageTool.scala",
      "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
    ],
    "message": "KAFKA-17636 Fix missing SCRAM bootstrap records (#17305)\n\nFixes a regression introduced by #16669 which inadvertently stopped processing SCRAM arguments from kafka-storage.sh\n\nReviewers: Colin P. McCabe <cmccabe@apache.org>, Federico Valeri <fedevaleri@gmail.com>",
    "before_after_code_files": [
      "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
      "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
    ]
  },
  "patch_diff": {
    "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala": [
      "File: core/src/main/scala/kafka/tools/StorageTool.scala -> core/src/main/scala/kafka/tools/StorageTool.scala",
      "--- Hunk 1 ---",
      "[Context before]",
      "130:     if (namespace.getBoolean(\"standalone\")) {",
      "131:       formatter.setInitialVoters(createStandaloneDynamicVoters(config))",
      "132:     }",
      "133:     configToLogDirectories(config).foreach(formatter.addDirectory(_))",
      "134:     formatter.run()",
      "135:   }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "133:     Option(namespace.getList(\"add_scram\")).",
      "134:       foreach(scramArgs => formatter.setScramArguments(scramArgs.asInstanceOf[util.List[String]]))",
      "",
      "---------------"
    ],
    "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala": [
      "File: core/src/test/scala/unit/kafka/tools/StorageToolTest.scala -> core/src/test/scala/unit/kafka/tools/StorageToolTest.scala",
      "--- Hunk 1 ---",
      "[Context before]",
      "21: import java.nio.charset.StandardCharsets",
      "22: import java.nio.file.Files",
      "23: import java.util",
      "25: import kafka.server.KafkaConfig",
      "26: import kafka.utils.TestUtils",
      "27: import net.sourceforge.argparse4j.inf.ArgumentParserException",
      "28: import org.apache.kafka.common.utils.Utils",
      "29: import org.apache.kafka.server.common.Features",
      "30: import org.apache.kafka.metadata.properties.{MetaPropertiesEnsemble, PropertiesUtils}",
      "31: import org.apache.kafka.metadata.storage.FormatterException",
      "32: import org.apache.kafka.raft.QuorumConfig",
      "",
      "[Removed Lines]",
      "24: import java.util.Properties",
      "",
      "[Added Lines]",
      "24: import java.util.{Optional, Properties}",
      "28: import org.apache.kafka.common.metadata.UserScramCredentialRecord",
      "31: import org.apache.kafka.metadata.bootstrap.BootstrapDirectory",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "37: import org.junit.jupiter.params.provider.ValueSource",
      "39: import scala.collection.mutable.ListBuffer",
      "41: @Timeout(value = 40)",
      "42: class StorageToolTest {",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "42: import scala.jdk.CollectionConverters.IterableHasAsScala",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "433:       contains(\"Formatting dynamic metadata voter directory %s\".format(availableDirs.head)),",
      "434:       \"Failed to find content in output: \" + stream.toString())",
      "435:   }",
      "",
      "[Removed Lines]",
      "436: }",
      "",
      "[Added Lines]",
      "440:   @Test",
      "441:   def testBootstrapScramRecords(): Unit = {",
      "442:     val availableDirs = Seq(TestUtils.tempDir())",
      "443:     val properties = new Properties()",
      "444:     properties.putAll(defaultDynamicQuorumProperties)",
      "445:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
      "446:     val stream = new ByteArrayOutputStream()",
      "447:     val arguments = ListBuffer[String](",
      "448:       \"--release-version\", \"3.9-IV0\",",
      "449:       \"--add-scram\", \"SCRAM-SHA-512=[name=alice,password=changeit]\",",
      "450:       \"--add-scram\", \"SCRAM-SHA-512=[name=bob,password=changeit]\"",
      "451:     )",
      "453:     assertEquals(0, runFormatCommand(stream, properties, arguments.toSeq))",
      "457:     val bootstrapMetadata = new BootstrapDirectory(availableDirs.head.toString, Optional.empty).read",
      "458:     val scramRecords = bootstrapMetadata.records().asScala",
      "459:       .filter(apiMessageAndVersion => apiMessageAndVersion.message().isInstanceOf[UserScramCredentialRecord])",
      "460:       .map(apiMessageAndVersion => apiMessageAndVersion.message().asInstanceOf[UserScramCredentialRecord])",
      "461:       .toList",
      "462:     assertEquals(2, scramRecords.size)",
      "463:     assertEquals(\"alice\", scramRecords.head.name())",
      "464:     assertEquals(\"bob\", scramRecords.last.name())",
      "465:   }",
      "467:   @Test",
      "468:   def testScramRecordsOldReleaseVersion(): Unit = {",
      "469:     val availableDirs = Seq(TestUtils.tempDir())",
      "470:     val properties = new Properties()",
      "471:     properties.putAll(defaultDynamicQuorumProperties)",
      "472:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
      "473:     val stream = new ByteArrayOutputStream()",
      "474:     val arguments = ListBuffer[String](",
      "475:       \"--release-version\", \"3.4\",",
      "476:       \"--add-scram\", \"SCRAM-SHA-512=[name=alice,password=changeit]\",",
      "477:       \"--add-scram\", \"SCRAM-SHA-512=[name=bob,password=changeit]\"",
      "478:     )",
      "480:     assertEquals(",
      "481:       \"SCRAM is only supported in metadata.version 3.5-IV2 or later.\",",
      "482:       assertThrows(classOf[FormatterException], () => runFormatCommand(stream, properties, arguments.toSeq)).getMessage)",
      "483:   }",
      "484: }",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "0a70c3a61e7b1961e2d9a5faed801bde0493d0d9",
      "candidate_info": {
        "commit_hash": "0a70c3a61e7b1961e2d9a5faed801bde0493d0d9",
        "repo": "apache/kafka",
        "commit_url": "https://github.com/apache/kafka/commit/0a70c3a61e7b1961e2d9a5faed801bde0493d0d9",
        "files": [
          "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
        ],
        "message": "KAFKA-17714 Fix StorageToolTest.scala to compile under Scala 2.12 (#17400)\n\nReviewers: David Arthur <mumrah@gmail.com>, Justine Olshan <jolshan@confluent.io>, Chia-Ping Tsai <chia7712@gmail.com>",
        "before_after_code_files": [
          "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
          ],
          "candidate": [
            "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
          ]
        }
      },
      "candidate_diff": {
        "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala": [
          "File: core/src/test/scala/unit/kafka/tools/StorageToolTest.scala -> core/src/test/scala/unit/kafka/tools/StorageToolTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: import java.nio.charset.StandardCharsets",
          "22: import java.nio.file.Files",
          "23: import java.util",
          "25: import kafka.server.KafkaConfig",
          "26: import kafka.utils.TestUtils",
          "27: import net.sourceforge.argparse4j.inf.ArgumentParserException",
          "",
          "[Removed Lines]",
          "24: import java.util.{Optional, Properties}",
          "",
          "[Added Lines]",
          "24: import java.util.Properties",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "39: import org.junit.jupiter.params.provider.ValueSource",
          "41: import scala.collection.mutable.ListBuffer",
          "44: @Timeout(value = 40)",
          "45: class StorageToolTest {",
          "",
          "[Removed Lines]",
          "42: import scala.jdk.CollectionConverters.IterableHasAsScala",
          "",
          "[Added Lines]",
          "42: import scala.jdk.CollectionConverters._",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "458:     val scramRecords = bootstrapMetadata.records().asScala",
          "459:       .filter(apiMessageAndVersion => apiMessageAndVersion.message().isInstanceOf[UserScramCredentialRecord])",
          "460:       .map(apiMessageAndVersion => apiMessageAndVersion.message().asInstanceOf[UserScramCredentialRecord])",
          "",
          "[Removed Lines]",
          "457:     val bootstrapMetadata = new BootstrapDirectory(availableDirs.head.toString, Optional.empty).read",
          "",
          "[Added Lines]",
          "457:     val bootstrapMetadata = new BootstrapDirectory(availableDirs.head.toString, java.util.Optional.empty()).read",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "5e3df22095fb68ebb472243aca5d2ab55df74c71",
      "candidate_info": {
        "commit_hash": "5e3df22095fb68ebb472243aca5d2ab55df74c71",
        "repo": "apache/kafka",
        "commit_url": "https://github.com/apache/kafka/commit/5e3df22095fb68ebb472243aca5d2ab55df74c71",
        "files": [
          "clients/src/main/java/org/apache/kafka/common/feature/BaseVersionRange.java",
          "core/src/main/scala/kafka/server/ApiVersionManager.scala",
          "core/src/main/scala/kafka/server/BrokerFeatures.scala",
          "core/src/main/scala/kafka/server/MetadataCache.scala",
          "core/src/main/scala/kafka/server/metadata/KRaftMetadataCache.scala",
          "core/src/main/scala/kafka/server/metadata/ZkMetadataCache.scala",
          "core/src/main/scala/kafka/tools/StorageTool.scala",
          "core/src/main/scala/kafka/tools/TestRaftServer.scala",
          "core/src/test/scala/unit/kafka/network/SocketServerTest.scala",
          "core/src/test/scala/unit/kafka/server/ControllerApisTest.scala",
          "core/src/test/scala/unit/kafka/server/FinalizedFeatureChangeListenerTest.scala",
          "core/src/test/scala/unit/kafka/server/KafkaApisTest.scala",
          "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala",
          "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/KRaftMetadataRequestBenchmark.java",
          "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/MetadataRequestBenchmark.java",
          "metadata/src/main/java/org/apache/kafka/controller/ClusterControlManager.java",
          "metadata/src/main/java/org/apache/kafka/controller/QuorumFeatures.java",
          "metadata/src/main/java/org/apache/kafka/metadata/FinalizedControllerFeatures.java",
          "metadata/src/main/java/org/apache/kafka/metadata/publisher/FeaturesPublisher.java",
          "metadata/src/test/java/org/apache/kafka/controller/QuorumFeaturesTest.java",
          "server-common/src/main/java/org/apache/kafka/server/common/FeatureVersion.java",
          "server-common/src/main/java/org/apache/kafka/server/common/Features.java",
          "server-common/src/main/java/org/apache/kafka/server/common/FinalizedFeatures.java",
          "server-common/src/main/java/org/apache/kafka/server/common/MetadataVersion.java",
          "server-common/src/main/java/org/apache/kafka/server/common/TestFeatureVersion.java",
          "server-common/src/test/java/org/apache/kafka/server/common/FeaturesTest.java",
          "server-common/src/test/java/org/apache/kafka/server/common/FinalizedFeaturesTest.java"
        ],
        "message": "KAFKA-16308 [1/N]: Create FeatureVersion interface and add `--feature` flag and handling to StorageTool (#15685)\n\nAs part of KIP-1022, I have created an interface for all the new features to be used when parsing the command line arguments, doing validations, getting default versions, etc.\n\nI've also added the --feature flag to the storage tool to show how it will be used.\n\nCreated a TestFeatureVersion to show an implementation of the interface (besides MetadataVersion which is unique) and added tests using this new test feature.\n\nI will add the unstable config and tests in a followup.\n\nReviewers: David Mao <dmao@confluent.io>, David Jacot <djacot@confluent.io>, Artem Livshits <alivshits@confluent.io>, Jun Rao <junrao@apache.org>",
        "before_after_code_files": [
          "clients/src/main/java/org/apache/kafka/common/feature/BaseVersionRange.java||clients/src/main/java/org/apache/kafka/common/feature/BaseVersionRange.java",
          "core/src/main/scala/kafka/server/ApiVersionManager.scala||core/src/main/scala/kafka/server/ApiVersionManager.scala",
          "core/src/main/scala/kafka/server/BrokerFeatures.scala||core/src/main/scala/kafka/server/BrokerFeatures.scala",
          "core/src/main/scala/kafka/server/MetadataCache.scala||core/src/main/scala/kafka/server/MetadataCache.scala",
          "core/src/main/scala/kafka/server/metadata/KRaftMetadataCache.scala||core/src/main/scala/kafka/server/metadata/KRaftMetadataCache.scala",
          "core/src/main/scala/kafka/server/metadata/ZkMetadataCache.scala||core/src/main/scala/kafka/server/metadata/ZkMetadataCache.scala",
          "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
          "core/src/main/scala/kafka/tools/TestRaftServer.scala||core/src/main/scala/kafka/tools/TestRaftServer.scala",
          "core/src/test/scala/unit/kafka/network/SocketServerTest.scala||core/src/test/scala/unit/kafka/network/SocketServerTest.scala",
          "core/src/test/scala/unit/kafka/server/ControllerApisTest.scala||core/src/test/scala/unit/kafka/server/ControllerApisTest.scala",
          "core/src/test/scala/unit/kafka/server/FinalizedFeatureChangeListenerTest.scala||core/src/test/scala/unit/kafka/server/FinalizedFeatureChangeListenerTest.scala",
          "core/src/test/scala/unit/kafka/server/KafkaApisTest.scala||core/src/test/scala/unit/kafka/server/KafkaApisTest.scala",
          "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala",
          "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/KRaftMetadataRequestBenchmark.java||jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/KRaftMetadataRequestBenchmark.java",
          "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/MetadataRequestBenchmark.java||jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/MetadataRequestBenchmark.java",
          "metadata/src/main/java/org/apache/kafka/controller/ClusterControlManager.java||metadata/src/main/java/org/apache/kafka/controller/ClusterControlManager.java",
          "metadata/src/main/java/org/apache/kafka/controller/QuorumFeatures.java||metadata/src/main/java/org/apache/kafka/controller/QuorumFeatures.java",
          "metadata/src/main/java/org/apache/kafka/metadata/FinalizedControllerFeatures.java||metadata/src/main/java/org/apache/kafka/metadata/FinalizedControllerFeatures.java",
          "metadata/src/main/java/org/apache/kafka/metadata/publisher/FeaturesPublisher.java||metadata/src/main/java/org/apache/kafka/metadata/publisher/FeaturesPublisher.java",
          "metadata/src/test/java/org/apache/kafka/controller/QuorumFeaturesTest.java||metadata/src/test/java/org/apache/kafka/controller/QuorumFeaturesTest.java",
          "server-common/src/main/java/org/apache/kafka/server/common/FeatureVersion.java||server-common/src/main/java/org/apache/kafka/server/common/FeatureVersion.java",
          "server-common/src/main/java/org/apache/kafka/server/common/Features.java||server-common/src/main/java/org/apache/kafka/server/common/Features.java",
          "server-common/src/main/java/org/apache/kafka/server/common/FinalizedFeatures.java||server-common/src/main/java/org/apache/kafka/server/common/FinalizedFeatures.java",
          "server-common/src/main/java/org/apache/kafka/server/common/MetadataVersion.java||server-common/src/main/java/org/apache/kafka/server/common/MetadataVersion.java",
          "server-common/src/main/java/org/apache/kafka/server/common/TestFeatureVersion.java||server-common/src/main/java/org/apache/kafka/server/common/TestFeatureVersion.java",
          "server-common/src/test/java/org/apache/kafka/server/common/FeaturesTest.java||server-common/src/test/java/org/apache/kafka/server/common/FeaturesTest.java",
          "server-common/src/test/java/org/apache/kafka/server/common/FinalizedFeaturesTest.java||server-common/src/test/java/org/apache/kafka/server/common/FinalizedFeaturesTest.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
            "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
          ],
          "candidate": [
            "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
            "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
          ]
        }
      },
      "candidate_diff": {
        "clients/src/main/java/org/apache/kafka/common/feature/BaseVersionRange.java||clients/src/main/java/org/apache/kafka/common/feature/BaseVersionRange.java": [
          "File: clients/src/main/java/org/apache/kafka/common/feature/BaseVersionRange.java -> clients/src/main/java/org/apache/kafka/common/feature/BaseVersionRange.java"
        ],
        "core/src/main/scala/kafka/server/ApiVersionManager.scala||core/src/main/scala/kafka/server/ApiVersionManager.scala": [
          "File: core/src/main/scala/kafka/server/ApiVersionManager.scala -> core/src/main/scala/kafka/server/ApiVersionManager.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "23: import org.apache.kafka.common.protocol.ApiKeys",
          "24: import org.apache.kafka.common.requests.ApiVersionsResponse",
          "25: import org.apache.kafka.server.ClientMetricsManager",
          "28: import scala.collection.mutable",
          "29: import scala.jdk.CollectionConverters._",
          "",
          "[Removed Lines]",
          "26: import org.apache.kafka.server.common.Features",
          "",
          "[Added Lines]",
          "26: import org.apache.kafka.server.common.FinalizedFeatures",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "40:   }",
          "41:   def newRequestMetrics: RequestChannel.Metrics = new network.RequestChannel.Metrics(enabledApis)",
          "44: }",
          "46: object ApiVersionManager {",
          "",
          "[Removed Lines]",
          "43:   def features: Features",
          "",
          "[Added Lines]",
          "43:   def features: FinalizedFeatures",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "80:   brokerFeatures: org.apache.kafka.common.feature.Features[SupportedVersionRange],",
          "81:   val enableUnstableLastVersion: Boolean,",
          "82:   val zkMigrationEnabled: Boolean,",
          "84: ) extends ApiVersionManager {",
          "86:   def this(",
          "87:     listenerType: ListenerType,",
          "88:     enableUnstableLastVersion: Boolean,",
          "89:     zkMigrationEnabled: Boolean,",
          "91:   ) = {",
          "92:     this(",
          "93:       listenerType,",
          "",
          "[Removed Lines]",
          "83:   val featuresProvider: () => Features",
          "90:     featuresProvider: () => Features",
          "",
          "[Added Lines]",
          "84:   val featuresProvider: () => FinalizedFeatures",
          "91:     featuresProvider: () => FinalizedFeatures",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "113:     )",
          "114:   }",
          "117: }",
          "",
          "[Removed Lines]",
          "116:   override def features: Features = featuresProvider.apply()",
          "",
          "[Added Lines]",
          "117:   override def features: FinalizedFeatures = featuresProvider.apply()",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "164:     )",
          "165:   }",
          "168: }",
          "",
          "[Removed Lines]",
          "167:   override def features: Features = metadataCache.features()",
          "",
          "[Added Lines]",
          "168:   override def features: FinalizedFeatures = metadataCache.features()",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/server/BrokerFeatures.scala||core/src/main/scala/kafka/server/BrokerFeatures.scala": [
          "File: core/src/main/scala/kafka/server/BrokerFeatures.scala -> core/src/main/scala/kafka/server/BrokerFeatures.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: import kafka.utils.Logging",
          "21: import org.apache.kafka.common.feature.{Features, SupportedVersionRange}",
          "22: import org.apache.kafka.server.common.MetadataVersion",
          "24: import java.util",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "22: import org.apache.kafka.server.common.Features.PRODUCTION_FEATURES",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "75:   }",
          "77:   def defaultSupportedFeatures(unstableMetadataVersionsEnabled: Boolean): Features[SupportedVersionRange] = {",
          "80:         new SupportedVersionRange(",
          "81:           MetadataVersion.MINIMUM_KRAFT_VERSION.featureLevel(),",
          "82:           if (unstableMetadataVersionsEnabled) {",
          "83:             MetadataVersion.latestTesting.featureLevel",
          "84:           } else {",
          "85:             MetadataVersion.latestProduction.featureLevel",
          "88:   }",
          "90:   def createEmpty(): BrokerFeatures = {",
          "",
          "[Removed Lines]",
          "78:     Features.supportedFeatures(",
          "79:       java.util.Collections.singletonMap(MetadataVersion.FEATURE_NAME,",
          "86:           }",
          "87:         )))",
          "",
          "[Added Lines]",
          "79:     val features = new util.HashMap[String, SupportedVersionRange]()",
          "80:       features.put(MetadataVersion.FEATURE_NAME,",
          "87:           }))",
          "88:     PRODUCTION_FEATURES.forEach { feature =>",
          "89:         features.put(feature.featureName, new SupportedVersionRange(0, feature.latestProduction()))",
          "90:     }",
          "91:     Features.supportedFeatures(features)",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/server/MetadataCache.scala||core/src/main/scala/kafka/server/MetadataCache.scala": [
          "File: core/src/main/scala/kafka/server/MetadataCache.scala -> core/src/main/scala/kafka/server/MetadataCache.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: import org.apache.kafka.common.message.{MetadataResponseData, UpdateMetadataRequestData}",
          "23: import org.apache.kafka.common.network.ListenerName",
          "24: import org.apache.kafka.common.{Cluster, Node, TopicPartition, Uuid}",
          "27: import java.util",
          "28: import scala.collection._",
          "",
          "[Removed Lines]",
          "25: import org.apache.kafka.server.common.{Features, MetadataVersion}",
          "",
          "[Added Lines]",
          "25: import org.apache.kafka.server.common.{FinalizedFeatures, MetadataVersion}",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "110:   def getRandomAliveBrokerId: Option[Int]",
          "113: }",
          "115: object MetadataCache {",
          "",
          "[Removed Lines]",
          "112:   def features(): Features",
          "",
          "[Added Lines]",
          "112:   def features(): FinalizedFeatures",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/server/metadata/KRaftMetadataCache.scala||core/src/main/scala/kafka/server/metadata/KRaftMetadataCache.scala": [
          "File: core/src/main/scala/kafka/server/metadata/KRaftMetadataCache.scala -> core/src/main/scala/kafka/server/metadata/KRaftMetadataCache.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "33: import org.apache.kafka.common.requests.MetadataResponse",
          "34: import org.apache.kafka.image.MetadataImage",
          "35: import org.apache.kafka.metadata.{BrokerRegistration, PartitionRegistration, Replicas}",
          "38: import java.util",
          "39: import java.util.concurrent.ThreadLocalRandom",
          "",
          "[Removed Lines]",
          "36: import org.apache.kafka.server.common.{Features, MetadataVersion}",
          "",
          "[Added Lines]",
          "36: import org.apache.kafka.server.common.{FinalizedFeatures, MetadataVersion}",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "540:   override def metadataVersion(): MetadataVersion = _currentImage.features().metadataVersion()",
          "543:     val image = _currentImage",
          "545:       image.features().finalizedVersions(),",
          "546:       image.highestOffsetAndEpoch().offset,",
          "547:       true)",
          "",
          "[Removed Lines]",
          "542:   override def features(): Features = {",
          "544:     new Features(image.features().metadataVersion(),",
          "",
          "[Added Lines]",
          "542:   override def features(): FinalizedFeatures = {",
          "544:     new FinalizedFeatures(image.features().metadataVersion(),",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/server/metadata/ZkMetadataCache.scala||core/src/main/scala/kafka/server/metadata/ZkMetadataCache.scala": [
          "File: core/src/main/scala/kafka/server/metadata/ZkMetadataCache.scala -> core/src/main/scala/kafka/server/metadata/ZkMetadataCache.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "40: import org.apache.kafka.common.protocol.Errors",
          "41: import org.apache.kafka.common.requests.{AbstractControlRequest, ApiVersionsResponse, MetadataResponse, UpdateMetadataRequest}",
          "42: import org.apache.kafka.common.security.auth.SecurityProtocol",
          "45: import java.util.concurrent.{ThreadLocalRandom, TimeUnit}",
          "46: import scala.concurrent.TimeoutException",
          "",
          "[Removed Lines]",
          "43: import org.apache.kafka.server.common.{Features, MetadataVersion}",
          "",
          "[Added Lines]",
          "43: import org.apache.kafka.server.common.{FinalizedFeatures, MetadataVersion}",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "53: trait ZkFinalizedFeatureCache {",
          "54:   def waitUntilFeatureEpochOrThrow(minExpectedEpoch: Long, timeoutMs: Long): Unit",
          "57: }",
          "59: case class MetadataSnapshot(partitionStates: mutable.AnyRefMap[String, mutable.LongMap[UpdateMetadataPartitionState]],",
          "",
          "[Removed Lines]",
          "56:   def getFeatureOption: Option[Features]",
          "",
          "[Added Lines]",
          "56:   def getFeatureOption: Option[FinalizedFeatures]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "177:   private val stateChangeLogger = new StateChangeLogger(brokerId, inControllerContext = false, None)",
          "181:   private val featureLock = new ReentrantLock()",
          "182:   private val featureCond = featureLock.newCondition()",
          "",
          "[Removed Lines]",
          "180:   @volatile private var _features: Option[Features] = Option.empty",
          "",
          "[Added Lines]",
          "180:   @volatile private var _features: Option[FinalizedFeatures] = Option.empty",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "618:   override def metadataVersion(): MetadataVersion = metadataVersion",
          "621:     case Some(features) => features",
          "623:       Collections.emptyMap(),",
          "624:       ApiVersionsResponse.UNKNOWN_FINALIZED_FEATURES_EPOCH,",
          "625:       false)",
          "",
          "[Removed Lines]",
          "620:   override def features(): Features = _features match {",
          "622:     case None => new Features(metadataVersion,",
          "",
          "[Added Lines]",
          "620:   override def features(): FinalizedFeatures = _features match {",
          "622:     case None => new FinalizedFeatures(metadataVersion,",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "641:   def updateFeaturesOrThrow(latestFeatures: Map[String, Short], latestEpoch: Long): Unit = {",
          "643:       latestFeatures.map(kv => (kv._1, kv._2.asInstanceOf[java.lang.Short])).asJava,",
          "644:       latestEpoch,",
          "645:       false)",
          "",
          "[Removed Lines]",
          "642:     val latest = new Features(metadataVersion,",
          "",
          "[Added Lines]",
          "642:     val latest = new FinalizedFeatures(metadataVersion,",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "711:     }",
          "712:   }",
          "715: }",
          "",
          "[Removed Lines]",
          "714:   override def getFeatureOption: Option[Features] = _features",
          "",
          "[Added Lines]",
          "714:   override def getFeatureOption: Option[FinalizedFeatures] = _features",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala": [
          "File: core/src/main/scala/kafka/tools/StorageTool.scala -> core/src/main/scala/kafka/tools/StorageTool.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "28: import org.apache.kafka.common.Uuid",
          "29: import org.apache.kafka.common.utils.Utils",
          "30: import org.apache.kafka.metadata.bootstrap.{BootstrapDirectory, BootstrapMetadata}",
          "32: import org.apache.kafka.common.metadata.FeatureLevelRecord",
          "33: import org.apache.kafka.common.metadata.UserScramCredentialRecord",
          "34: import org.apache.kafka.common.security.scram.internals.ScramMechanism",
          "",
          "[Removed Lines]",
          "31: import org.apache.kafka.server.common.{ApiMessageAndVersion, MetadataVersion}",
          "",
          "[Added Lines]",
          "31: import org.apache.kafka.server.common.{ApiMessageAndVersion, Features, MetadataVersion}",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "36: import org.apache.kafka.server.config.ReplicationConfigs",
          "37: import org.apache.kafka.metadata.properties.MetaPropertiesEnsemble.VerificationFlag",
          "38: import org.apache.kafka.metadata.properties.{MetaProperties, MetaPropertiesEnsemble, MetaPropertiesVersion, PropertiesUtils}",
          "40: import java.util",
          "43: import scala.collection.mutable",
          "44: import scala.jdk.CollectionConverters._",
          "45: import scala.collection.mutable.ArrayBuffer",
          "",
          "[Removed Lines]",
          "41: import java.util.Base64",
          "42: import java.util.Optional",
          "",
          "[Added Lines]",
          "39: import org.apache.kafka.server.common.FeatureVersion",
          "42: import java.util.{Base64, Collections, Optional}",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "60:         case \"format\" =>",
          "61:           val directories = configToLogDirectories(config.get)",
          "62:           val clusterId = namespace.getString(\"cluster_id\")",
          "75:           val metaProperties = new MetaProperties.Builder().",
          "76:             setVersion(MetaPropertiesVersion.V1).",
          "77:             setClusterId(clusterId).",
          "78:             setNodeId(config.get.nodeId).",
          "79:             build()",
          "80:           val metadataRecords : ArrayBuffer[ApiMessageAndVersion] = ArrayBuffer()",
          "81:           getUserScramCredentialRecords(namespace).foreach(userScramCredentialRecords => {",
          "82:             if (!metadataVersion.isScramSupported) {",
          "83:               throw new TerseFailure(s\"SCRAM is only supported in metadata.version ${MetadataVersion.IBP_3_5_IV2} or later.\")",
          "",
          "[Removed Lines]",
          "63:           val metadataVersion = getMetadataVersion(namespace,",
          "64:             Option(config.get.originals.get(ReplicationConfigs.INTER_BROKER_PROTOCOL_VERSION_CONFIG)).map(_.toString))",
          "65:           if (!metadataVersion.isKRaftSupported) {",
          "66:             throw new TerseFailure(s\"Must specify a valid KRaft metadata.version of at least ${MetadataVersion.IBP_3_0_IV0}.\")",
          "67:           }",
          "68:           if (!metadataVersion.isProduction) {",
          "69:             if (config.get.unstableMetadataVersionsEnabled) {",
          "70:               System.out.println(s\"WARNING: using pre-production metadata.version $metadataVersion.\")",
          "71:             } else {",
          "72:               throw new TerseFailure(s\"The metadata.version $metadataVersion is not ready for production use yet.\")",
          "73:             }",
          "74:           }",
          "",
          "[Added Lines]",
          "69:           val specifiedFeatures: util.List[String] = namespace.getList(\"feature\")",
          "70:           val releaseVersionFlagSpecified = namespace.getString(\"release_version\") != null",
          "71:           if (releaseVersionFlagSpecified && specifiedFeatures != null) {",
          "72:             throw new TerseFailure(\"Both --release-version and --feature were set. Only one of the two flags can be set.\")",
          "73:           }",
          "74:           val featureNamesAndLevelsMap = featureNamesAndLevels(Option(specifiedFeatures).getOrElse(Collections.emptyList).asScala.toList)",
          "75:           val metadataVersion = getMetadataVersion(namespace, featureNamesAndLevelsMap,",
          "76:             Option(config.get.originals.get(ReplicationConfigs.INTER_BROKER_PROTOCOL_VERSION_CONFIG)).map(_.toString))",
          "77:           validateMetadataVersion(metadataVersion, config)",
          "80:           generateFeatureRecords(",
          "81:             metadataRecords,",
          "82:             metadataVersion,",
          "83:             featureNamesAndLevelsMap,",
          "84:             Features.PRODUCTION_FEATURES.asScala.toList,",
          "85:             releaseVersionFlagSpecified",
          "86:           )",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "109:     }",
          "110:   }",
          "112:   def parseArguments(args: Array[String]): Namespace = {",
          "113:     val parser = ArgumentParsers.",
          "114:       newArgumentParser(\"kafka-storage\", /* defaultHelp */ true, /* prefixChars */ \"-\", /* fromFilePrefix */ \"@\").",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "119:   private def validateMetadataVersion(metadataVersion: MetadataVersion, config: Option[KafkaConfig]): Unit = {",
          "120:     if (!metadataVersion.isKRaftSupported) {",
          "121:       throw new TerseFailure(s\"Must specify a valid KRaft metadata.version of at least ${MetadataVersion.IBP_3_0_IV0}.\")",
          "122:     }",
          "123:     if (!metadataVersion.isProduction) {",
          "124:       if (config.get.unstableMetadataVersionsEnabled) {",
          "125:         System.out.println(s\"WARNING: using pre-production metadata.version $metadataVersion.\")",
          "126:       } else {",
          "127:         throw new TerseFailure(s\"The metadata.version $metadataVersion is not ready for production use yet.\")",
          "128:       }",
          "129:     }",
          "130:   }",
          "132:   private[tools] def generateFeatureRecords(metadataRecords: ArrayBuffer[ApiMessageAndVersion],",
          "133:                                             metadataVersion: MetadataVersion,",
          "134:                                             specifiedFeatures: Map[String, java.lang.Short],",
          "135:                                             allFeatures: List[Features],",
          "136:                                             releaseVersionSpecified: Boolean): Unit = {",
          "138:     val metadataVersionForDefault = if (releaseVersionSpecified) metadataVersion else MetadataVersion.LATEST_PRODUCTION",
          "140:     val allNonZeroFeaturesAndLevels: ArrayBuffer[FeatureVersion] = mutable.ArrayBuffer[FeatureVersion]()",
          "142:     allFeatures.foreach { feature =>",
          "143:       val level: java.lang.Short = specifiedFeatures.getOrElse(feature.featureName, feature.defaultValue(metadataVersionForDefault))",
          "145:       if (level != 0) {",
          "146:        allNonZeroFeaturesAndLevels.append(feature.fromFeatureLevel(level))",
          "147:       }",
          "148:     }",
          "149:     val featuresMap = Features.featureImplsToMap(allNonZeroFeaturesAndLevels.asJava)",
          "150:     featuresMap.put(MetadataVersion.FEATURE_NAME, metadataVersion.featureLevel)",
          "152:     try {",
          "153:       for (feature <- allNonZeroFeaturesAndLevels) {",
          "155:         Features.validateVersion(feature, featuresMap)",
          "156:         metadataRecords.append(new ApiMessageAndVersion(new FeatureLevelRecord().",
          "157:           setName(feature.featureName).",
          "158:           setFeatureLevel(feature.featureLevel), 0.toShort))",
          "159:       }",
          "160:     } catch {",
          "161:       case e: Throwable => throw new TerseFailure(e.getMessage)",
          "162:     }",
          "163:   }",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "141:     formatParser.addArgument(\"--release-version\", \"-r\").",
          "142:       action(store()).",
          "143:       help(s\"A KRaft release version to use for the initial metadata.version. The minimum is ${MetadataVersion.IBP_3_0_IV0}, the default is ${MetadataVersion.LATEST_PRODUCTION}\")",
          "145:     parser.parseArgsOrFail(args)",
          "146:   }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "197:     formatParser.addArgument(\"--feature\", \"-f\").",
          "198:       help(\"A feature upgrade we should perform, in feature=level format. For example: `metadata.version=5`.\").",
          "199:       action(append());",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "157:   def getMetadataVersion(",
          "158:     namespace: Namespace,",
          "159:     defaultVersionString: Option[String]",
          "160:   ): MetadataVersion = {",
          "161:     val defaultValue = defaultVersionString match {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "215:     featureNamesAndLevelsMap: Map[String, java.lang.Short],",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "163:       case None => MetadataVersion.LATEST_PRODUCTION",
          "164:     }",
          "169:   }",
          "171:   private def getUserScramCredentialRecord(",
          "",
          "[Removed Lines]",
          "166:     Option(namespace.getString(\"release_version\"))",
          "167:       .map(ver => MetadataVersion.fromVersionString(ver))",
          "168:       .getOrElse(defaultValue)",
          "",
          "[Added Lines]",
          "223:     val releaseVersionTag = Option(namespace.getString(\"release_version\"))",
          "224:     val featureTag = featureNamesAndLevelsMap.get(MetadataVersion.FEATURE_NAME)",
          "226:     (releaseVersionTag, featureTag) match {",
          "227:       case (Some(_), Some(_)) => // We should throw an error before we hit this case, but include for completeness",
          "228:         throw new IllegalArgumentException(\"Both --release_version and --feature were set. Only one of the two flags can be set.\")",
          "229:       case (Some(version), None) =>",
          "230:         MetadataVersion.fromVersionString(version)",
          "231:       case (None, Some(level)) =>",
          "232:         MetadataVersion.fromFeatureLevel(level)",
          "233:       case (None, None) =>",
          "234:         defaultValue",
          "235:     }",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "469:     }",
          "470:     0",
          "471:   }",
          "472: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "540:   private def parseNameAndLevel(input: String): (String, java.lang.Short) = {",
          "541:     val equalsIndex = input.indexOf(\"=\")",
          "542:     if (equalsIndex < 0)",
          "543:       throw new RuntimeException(\"Can't parse feature=level string \" + input + \": equals sign not found.\")",
          "544:     val name = input.substring(0, equalsIndex).trim",
          "545:     val levelString = input.substring(equalsIndex + 1).trim",
          "546:     try {",
          "547:       levelString.toShort",
          "548:     } catch {",
          "549:       case _: Throwable =>",
          "550:         throw new RuntimeException(\"Can't parse feature=level string \" + input + \": \" + \"unable to parse \" + levelString + \" as a short.\")",
          "551:     }",
          "552:     (name, levelString.toShort)",
          "553:   }",
          "555:   def featureNamesAndLevels(features: List[String]): Map[String, java.lang.Short] = {",
          "556:     features.map { (feature: String) =>",
          "558:       val nameAndLevel = parseNameAndLevel(feature)",
          "559:       (nameAndLevel._1, nameAndLevel._2)",
          "560:     }.toMap",
          "561:   }",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/tools/TestRaftServer.scala||core/src/main/scala/kafka/tools/TestRaftServer.scala": [
          "File: core/src/main/scala/kafka/tools/TestRaftServer.scala -> core/src/main/scala/kafka/tools/TestRaftServer.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "37: import org.apache.kafka.raft.errors.NotLeaderException",
          "38: import org.apache.kafka.raft.{Batch, BatchReader, LeaderAndEpoch, RaftClient, QuorumConfig}",
          "39: import org.apache.kafka.security.CredentialProvider",
          "41: import org.apache.kafka.server.common.serialization.RecordSerde",
          "42: import org.apache.kafka.server.config.KRaftConfigs",
          "43: import org.apache.kafka.server.fault.ProcessTerminatingFaultHandler",
          "",
          "[Removed Lines]",
          "40: import org.apache.kafka.server.common.{Features, MetadataVersion}",
          "",
          "[Added Lines]",
          "40: import org.apache.kafka.server.common.{FinalizedFeatures, MetadataVersion}",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "81:       ListenerType.CONTROLLER,",
          "82:       true,",
          "83:       false,",
          "85:     socketServer = new SocketServer(config, metrics, time, credentialProvider, apiVersionManager)",
          "87:     raftManager = new KafkaRaftManager[Array[Byte]](",
          "",
          "[Removed Lines]",
          "84:       () => Features.fromKRaftVersion(MetadataVersion.MINIMUM_KRAFT_VERSION))",
          "",
          "[Added Lines]",
          "84:       () => FinalizedFeatures.fromKRaftVersion(MetadataVersion.MINIMUM_KRAFT_VERSION))",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/network/SocketServerTest.scala||core/src/test/scala/unit/kafka/network/SocketServerTest.scala": [
          "File: core/src/test/scala/unit/kafka/network/SocketServerTest.scala -> core/src/test/scala/unit/kafka/network/SocketServerTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "37: import org.apache.kafka.common.utils._",
          "38: import org.apache.kafka.network.SocketServerConfigs",
          "39: import org.apache.kafka.security.CredentialProvider",
          "41: import org.apache.kafka.server.config.{ServerConfigs, QuotaConfigs}",
          "42: import org.apache.kafka.server.metrics.KafkaYammerMetrics",
          "43: import org.apache.kafka.test.{TestSslUtils, TestUtils => JTestUtils}",
          "",
          "[Removed Lines]",
          "40: import org.apache.kafka.server.common.{Features, MetadataVersion}",
          "",
          "[Added Lines]",
          "40: import org.apache.kafka.server.common.{FinalizedFeatures, MetadataVersion}",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "80:   TestUtils.clearYammerMetrics()",
          "82:   private val apiVersionManager = new SimpleApiVersionManager(ListenerType.BROKER, true, false,",
          "84:   var server: SocketServer = _",
          "85:   val sockets = new ArrayBuffer[Socket]",
          "",
          "[Removed Lines]",
          "83:     () => new Features(MetadataVersion.latestTesting(), Collections.emptyMap[String, java.lang.Short], 0, true))",
          "",
          "[Added Lines]",
          "83:     () => new FinalizedFeatures(MetadataVersion.latestTesting(), Collections.emptyMap[String, java.lang.Short], 0, true))",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/server/ControllerApisTest.scala||core/src/test/scala/unit/kafka/server/ControllerApisTest.scala": [
          "File: core/src/test/scala/unit/kafka/server/ControllerApisTest.scala -> core/src/test/scala/unit/kafka/server/ControllerApisTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "53: import org.apache.kafka.image.publisher.ControllerRegistrationsPublisher",
          "54: import org.apache.kafka.raft.QuorumConfig",
          "55: import org.apache.kafka.server.authorizer.{Action, AuthorizableRequestContext, AuthorizationResult, Authorizer}",
          "57: import org.apache.kafka.server.config.{KRaftConfigs, ServerConfigs}",
          "58: import org.apache.kafka.server.util.FutureUtils",
          "59: import org.apache.kafka.storage.internals.log.CleanerConfig",
          "",
          "[Removed Lines]",
          "56: import org.apache.kafka.server.common.{ApiMessageAndVersion, Features, MetadataVersion, ProducerIdsBlock}",
          "",
          "[Added Lines]",
          "56: import org.apache.kafka.server.common.{ApiMessageAndVersion, FinalizedFeatures, MetadataVersion, ProducerIdsBlock}",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "169:         ListenerType.CONTROLLER,",
          "170:         true,",
          "171:         false,",
          "173:       metadataCache",
          "174:     )",
          "175:   }",
          "",
          "[Removed Lines]",
          "172:         () => Features.fromKRaftVersion(MetadataVersion.latestTesting())),",
          "",
          "[Added Lines]",
          "172:         () => FinalizedFeatures.fromKRaftVersion(MetadataVersion.latestTesting())),",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/server/FinalizedFeatureChangeListenerTest.scala||core/src/test/scala/unit/kafka/server/FinalizedFeatureChangeListenerTest.scala": [
          "File: core/src/test/scala/unit/kafka/server/FinalizedFeatureChangeListenerTest.scala -> core/src/test/scala/unit/kafka/server/FinalizedFeatureChangeListenerTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: import kafka.utils.TestUtils",
          "22: import kafka.zk.{FeatureZNode, FeatureZNodeStatus, ZkVersion}",
          "23: import org.apache.kafka.common.feature.{Features, SupportedVersionRange}",
          "25: import org.apache.kafka.common.utils.Exit",
          "26: import org.apache.kafka.server.common.MetadataVersion",
          "27: import org.apache.kafka.server.common.MetadataVersion.IBP_3_2_IV0",
          "",
          "[Removed Lines]",
          "24: import org.apache.kafka.server.common.{Features => JFeatures}",
          "",
          "[Added Lines]",
          "24: import org.apache.kafka.server.common.{FinalizedFeatures => JFeatures}",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/server/KafkaApisTest.scala||core/src/test/scala/unit/kafka/server/KafkaApisTest.scala": [
          "File: core/src/test/scala/unit/kafka/server/KafkaApisTest.scala -> core/src/test/scala/unit/kafka/server/KafkaApisTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "79: import org.apache.kafka.server.ClientMetricsManager",
          "80: import org.apache.kafka.server.authorizer.{Action, AuthorizationResult, Authorizer}",
          "81: import org.apache.kafka.server.common.MetadataVersion.{IBP_0_10_2_IV0, IBP_2_2_IV1}",
          "83: import org.apache.kafka.server.config._",
          "84: import org.apache.kafka.server.metrics.ClientMetricsTestUtils",
          "85: import org.apache.kafka.server.util.{FutureUtils, MockTime}",
          "",
          "[Removed Lines]",
          "82: import org.apache.kafka.server.common.{Features, MetadataVersion}",
          "",
          "[Added Lines]",
          "82: import org.apache.kafka.server.common.{FinalizedFeatures, MetadataVersion}",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "199:       BrokerFeatures.defaultSupportedFeatures(true),",
          "200:       true,",
          "201:       false,",
          "204:     val clientMetricsManagerOpt = if (raftSupport) Some(clientMetricsManager) else None",
          "",
          "[Removed Lines]",
          "202:       () => new Features(MetadataVersion.latestTesting(), Collections.emptyMap[String, java.lang.Short], 0, raftSupport))",
          "",
          "[Added Lines]",
          "202:       () => new FinalizedFeatures(MetadataVersion.latestTesting(), Collections.emptyMap[String, java.lang.Short], 0, raftSupport))",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala": [
          "File: core/src/test/scala/unit/kafka/tools/StorageToolTest.scala -> core/src/test/scala/unit/kafka/tools/StorageToolTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: import java.nio.charset.StandardCharsets",
          "22: import java.nio.file.{Files, Paths}",
          "23: import java.util",
          "25: import org.apache.kafka.common.{DirectoryId, KafkaException}",
          "26: import kafka.server.KafkaConfig",
          "27: import kafka.utils.Exit",
          "28: import kafka.utils.TestUtils",
          "29: import org.apache.commons.io.output.NullOutputStream",
          "30: import org.apache.kafka.common.utils.Utils",
          "33: import org.apache.kafka.metadata.properties.{MetaProperties, MetaPropertiesEnsemble, MetaPropertiesVersion, PropertiesUtils}",
          "34: import org.apache.kafka.raft.QuorumConfig",
          "35: import org.apache.kafka.server.config.{KRaftConfigs, ServerConfigs, ServerLogConfigs}",
          "36: import org.junit.jupiter.api.Assertions.{assertEquals, assertFalse, assertThrows, assertTrue}",
          "37: import org.junit.jupiter.api.{Test, Timeout}",
          "38: import org.junit.jupiter.params.ParameterizedTest",
          "41: import scala.collection.mutable",
          "42: import scala.collection.mutable.ArrayBuffer",
          "44: @Timeout(value = 40)",
          "45: class StorageToolTest {",
          "",
          "[Removed Lines]",
          "24: import java.util.Properties",
          "31: import org.apache.kafka.server.common.MetadataVersion",
          "32: import org.apache.kafka.common.metadata.UserScramCredentialRecord",
          "39: import org.junit.jupiter.params.provider.ValueSource",
          "",
          "[Added Lines]",
          "24: import java.util.{Collections, Properties}",
          "29: import net.sourceforge.argparse4j.inf.Namespace",
          "32: import org.apache.kafka.server.common.{ApiMessageAndVersion, Features, MetadataVersion, TestFeatureVersion}",
          "33: import org.apache.kafka.common.metadata.{FeatureLevelRecord, UserScramCredentialRecord}",
          "40: import org.junit.jupiter.params.provider.{EnumSource, ValueSource}",
          "44: import scala.jdk.CollectionConverters._",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "54:     properties",
          "55:   }",
          "57:   @Test",
          "58:   def testConfigToLogDirectories(): Unit = {",
          "59:     val config = new KafkaConfig(newSelfManagedProperties())",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "59:   val allFeatures = Features.FEATURES.toList",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "262:   @Test",
          "263:   def testDefaultMetadataVersion(): Unit = {",
          "264:     val namespace = StorageTool.parseArguments(Array(\"format\", \"-c\", \"config.props\", \"-t\", \"XcZZOzUqS4yHOjhMQB6JLQ\"))",
          "266:     assertEquals(MetadataVersion.LATEST_PRODUCTION.featureLevel(), mv.featureLevel(),",
          "267:       \"Expected the default metadata.version to be the latest production version\")",
          "268:   }",
          "",
          "[Removed Lines]",
          "265:     val mv = StorageTool.getMetadataVersion(namespace, defaultVersionString = None)",
          "",
          "[Added Lines]",
          "269:     val mv = StorageTool.getMetadataVersion(namespace, Map.empty, defaultVersionString = None)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "270:   @Test",
          "271:   def testConfiguredMetadataVersion(): Unit = {",
          "272:     val namespace = StorageTool.parseArguments(Array(\"format\", \"-c\", \"config.props\", \"-t\", \"XcZZOzUqS4yHOjhMQB6JLQ\"))",
          "274:     assertEquals(MetadataVersion.IBP_3_3_IV2.featureLevel(), mv.featureLevel(),",
          "275:       \"Expected the default metadata.version to be 3.3-IV2\")",
          "276:   }",
          "278:   @Test",
          "279:   def testMetadataVersionFlags(): Unit = {",
          "280:     def parseMetadataVersion(strings: String*): MetadataVersion = {",
          "281:       var args = mutable.Seq(\"format\", \"-c\", \"config.props\", \"-t\", \"XcZZOzUqS4yHOjhMQB6JLQ\")",
          "282:       args ++= strings",
          "283:       val namespace = StorageTool.parseArguments(args.toArray)",
          "285:     }",
          "287:     var mv = parseMetadataVersion(\"--release-version\", \"3.0\")",
          "",
          "[Removed Lines]",
          "273:     val mv = StorageTool.getMetadataVersion(namespace, defaultVersionString = Some(MetadataVersion.IBP_3_3_IV2.toString))",
          "284:       StorageTool.getMetadataVersion(namespace, defaultVersionString = None)",
          "",
          "[Added Lines]",
          "277:     val mv = StorageTool.getMetadataVersion(namespace, Map.empty, defaultVersionString = Some(MetadataVersion.IBP_3_3_IV2.toString))",
          "282:   @Test",
          "283:   def testSettingFeatureAndReleaseVersionFails(): Unit = {",
          "284:     val namespace = StorageTool.parseArguments(Array(\"format\", \"-c\", \"config.props\", \"-t\", \"XcZZOzUqS4yHOjhMQB6JLQ\",",
          "285:       \"--release-version\", \"3.0-IV1\", \"--feature\", \"metadata.version=4\"))",
          "286:     assertThrows(classOf[IllegalArgumentException], () => StorageTool.getMetadataVersion(namespace, parseFeatures(namespace), defaultVersionString = None))",
          "287:   }",
          "289:   @Test",
          "290:   def testParseFeatures(): Unit = {",
          "291:     def parseAddFeatures(strings: String*): Map[String, java.lang.Short] = {",
          "292:       var args = mutable.Seq(\"format\", \"-c\", \"config.props\", \"-t\", \"XcZZOzUqS4yHOjhMQB6JLQ\")",
          "293:       args ++= strings",
          "294:       val namespace = StorageTool.parseArguments(args.toArray)",
          "295:       parseFeatures(namespace)",
          "296:     }",
          "298:     assertThrows(classOf[RuntimeException], () => parseAddFeatures(\"--feature\", \"blah\"))",
          "299:     assertThrows(classOf[RuntimeException], () => parseAddFeatures(\"--feature\", \"blah=blah\"))",
          "302:     assertEquals(Map(), parseAddFeatures())",
          "305:     val testFeatureLevel = 1",
          "306:     val testArgument = TestFeatureVersion.FEATURE_NAME + \"=\" + testFeatureLevel.toString",
          "307:     val expectedMap = Map(TestFeatureVersion.FEATURE_NAME -> testFeatureLevel.toShort)",
          "308:     assertEquals(expectedMap, parseAddFeatures(\"--feature\", testArgument))",
          "311:     val metadataFeatureLevel = 5",
          "312:     val metadataArgument = MetadataVersion.FEATURE_NAME + \"=\" + metadataFeatureLevel.toString",
          "313:     val expectedMap2 = expectedMap ++ Map (MetadataVersion.FEATURE_NAME -> metadataFeatureLevel.toShort)",
          "314:     assertEquals(expectedMap2, parseAddFeatures(\"--feature\", testArgument, \"--feature\", metadataArgument))",
          "315:   }",
          "317:   private def parseFeatures(namespace: Namespace): Map[String, java.lang.Short] = {",
          "318:     val specifiedFeatures: util.List[String] = namespace.getList(\"feature\")",
          "319:     StorageTool.featureNamesAndLevels(Option(specifiedFeatures).getOrElse(Collections.emptyList).asScala.toList)",
          "320:   }",
          "328:       StorageTool.getMetadataVersion(namespace, Map.empty, defaultVersionString = None)",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "293:     assertThrows(classOf[IllegalArgumentException], () => parseMetadataVersion(\"--release-version\", \"0.0\"))",
          "294:   }",
          "296:   @Test",
          "297:   def testAddScram():Unit = {",
          "298:     def parseAddScram(strings: String*): Option[ArrayBuffer[UserScramCredentialRecord]] = {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "340:   private def generateRecord(featureName: String, level: Short): ApiMessageAndVersion = {",
          "341:     new ApiMessageAndVersion(new FeatureLevelRecord().",
          "342:       setName(featureName).",
          "343:       setFeatureLevel(level), 0.toShort)",
          "344:   }",
          "346:   @ParameterizedTest",
          "347:   @EnumSource(classOf[TestFeatureVersion])",
          "348:   def testFeatureFlag(testFeatureVersion: TestFeatureVersion): Unit = {",
          "349:     val featureLevel = testFeatureVersion.featureLevel",
          "350:     if (featureLevel <= Features.TEST_VERSION.defaultValue(MetadataVersion.LATEST_PRODUCTION)) {",
          "351:       val records = new ArrayBuffer[ApiMessageAndVersion]()",
          "352:       StorageTool.generateFeatureRecords(",
          "353:         records,",
          "354:         MetadataVersion.LATEST_PRODUCTION,",
          "355:         Map(TestFeatureVersion.FEATURE_NAME -> featureLevel),",
          "356:         allFeatures,",
          "357:         false",
          "358:       )",
          "359:       if (featureLevel > 0) {",
          "360:         assertEquals(List(generateRecord(TestFeatureVersion.FEATURE_NAME, featureLevel)), records)",
          "361:       }",
          "362:     }",
          "363:   }",
          "365:   @ParameterizedTest",
          "366:   @EnumSource(classOf[MetadataVersion])",
          "367:   def testVersionDefault(metadataVersion: MetadataVersion): Unit = {",
          "368:     val records = new ArrayBuffer[ApiMessageAndVersion]()",
          "369:     StorageTool.generateFeatureRecords(",
          "370:       records,",
          "371:       metadataVersion,",
          "372:       Map.empty,",
          "373:       allFeatures,",
          "374:       true",
          "375:     )",
          "377:     val featureLevel = Features.TEST_VERSION.defaultValue(metadataVersion)",
          "378:     if (featureLevel > 0) {",
          "379:       assertEquals(List(generateRecord(TestFeatureVersion.FEATURE_NAME, featureLevel)), records)",
          "380:     }",
          "381:   }",
          "382:   @Test",
          "383:   def testVersionDefaultNoArgs(): Unit = {",
          "384:     val records = new ArrayBuffer[ApiMessageAndVersion]()",
          "385:     StorageTool.generateFeatureRecords(",
          "386:       records,",
          "387:       MetadataVersion.LATEST_PRODUCTION,",
          "388:       Map.empty,",
          "389:       allFeatures,",
          "390:       false",
          "391:     )",
          "393:     assertEquals(List(generateRecord(TestFeatureVersion.FEATURE_NAME, Features.TEST_VERSION.defaultValue(MetadataVersion.LATEST_PRODUCTION))), records)",
          "394:   }",
          "397:   @Test",
          "398:   def testFeatureDependency(): Unit = {",
          "399:     val featureLevel = 1.toShort",
          "400:     assertThrows(classOf[TerseFailure], () => StorageTool.generateFeatureRecords(",
          "401:       new ArrayBuffer[ApiMessageAndVersion](),",
          "402:       MetadataVersion.IBP_2_8_IV1,",
          "403:       Map(TestFeatureVersion.FEATURE_NAME -> featureLevel),",
          "404:       allFeatures,",
          "405:       false",
          "406:     ))",
          "407:   }",
          "409:   @Test",
          "410:   def testLatestFeaturesWithOldMetadataVersion(): Unit = {",
          "411:     val records = new ArrayBuffer[ApiMessageAndVersion]()",
          "412:     StorageTool.generateFeatureRecords(",
          "413:       records,",
          "414:       MetadataVersion.IBP_3_3_IV0,",
          "415:       Map.empty,",
          "416:       allFeatures,",
          "417:       false",
          "418:     )",
          "420:     assertEquals(List(generateRecord(TestFeatureVersion.FEATURE_NAME, Features.TEST_VERSION.defaultValue(MetadataVersion.LATEST_PRODUCTION))), records)",
          "421:   }",
          "423:   @Test",
          "424:   def testFeatureInvalidFlag(): Unit = {",
          "425:     val featureLevel = 99.toShort",
          "426:     assertThrows(classOf[IllegalArgumentException], () => StorageTool.generateFeatureRecords(",
          "427:       new ArrayBuffer[ApiMessageAndVersion](),",
          "428:       MetadataVersion.LATEST_PRODUCTION,",
          "429:       Map(TestFeatureVersion.FEATURE_NAME -> featureLevel),",
          "430:       allFeatures,",
          "431:       false",
          "432:     ))",
          "433:   }",
          "",
          "---------------"
        ],
        "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/KRaftMetadataRequestBenchmark.java||jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/KRaftMetadataRequestBenchmark.java": [
          "File: jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/KRaftMetadataRequestBenchmark.java -> jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/KRaftMetadataRequestBenchmark.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "59: import org.apache.kafka.image.MetadataImage;",
          "60: import org.apache.kafka.image.MetadataProvenance;",
          "61: import org.apache.kafka.raft.QuorumConfig;",
          "63: import org.apache.kafka.server.common.MetadataVersion;",
          "64: import org.apache.kafka.server.config.KRaftConfigs;",
          "",
          "[Removed Lines]",
          "62: import org.apache.kafka.server.common.Features;",
          "",
          "[Added Lines]",
          "62: import org.apache.kafka.server.common.FinalizedFeatures;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "204:                         ApiMessageType.ListenerType.BROKER,",
          "205:                         false,",
          "206:                         false,",
          "208:                 build();",
          "209:     }",
          "",
          "[Removed Lines]",
          "207:                         () -> Features.fromKRaftVersion(MetadataVersion.latestTesting()))).",
          "",
          "[Added Lines]",
          "207:                         () -> FinalizedFeatures.fromKRaftVersion(MetadataVersion.latestTesting()))).",
          "",
          "---------------"
        ],
        "jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/MetadataRequestBenchmark.java||jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/MetadataRequestBenchmark.java": [
          "File: jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/MetadataRequestBenchmark.java -> jmh-benchmarks/src/main/java/org/apache/kafka/jmh/metadata/MetadataRequestBenchmark.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "59: import org.apache.kafka.common.security.auth.SecurityProtocol;",
          "60: import org.apache.kafka.common.utils.Time;",
          "61: import org.apache.kafka.coordinator.group.GroupCoordinator;",
          "63: import org.apache.kafka.server.common.MetadataVersion;",
          "64: import org.apache.kafka.server.config.ServerConfigs;",
          "65: import org.apache.kafka.server.config.ZkConfigs;",
          "",
          "[Removed Lines]",
          "62: import org.apache.kafka.server.common.Features;",
          "",
          "[Added Lines]",
          "62: import org.apache.kafka.server.common.FinalizedFeatures;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "204:                     ApiMessageType.ListenerType.ZK_BROKER,",
          "205:                     false,",
          "206:                     false,",
          "208:             build();",
          "209:     }",
          "",
          "[Removed Lines]",
          "207:                     () -> Features.fromKRaftVersion(MetadataVersion.latestTesting()))).",
          "",
          "[Added Lines]",
          "207:                     () -> FinalizedFeatures.fromKRaftVersion(MetadataVersion.latestTesting()))).",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/controller/ClusterControlManager.java||metadata/src/main/java/org/apache/kafka/controller/ClusterControlManager.java": [
          "File: metadata/src/main/java/org/apache/kafka/controller/ClusterControlManager.java -> metadata/src/main/java/org/apache/kafka/controller/ClusterControlManager.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "50: import org.apache.kafka.metadata.placement.StripedReplicaPlacer;",
          "51: import org.apache.kafka.metadata.placement.UsableBroker;",
          "52: import org.apache.kafka.server.common.ApiMessageAndVersion;",
          "53: import org.apache.kafka.server.common.MetadataVersion;",
          "54: import org.apache.kafka.timeline.SnapshotRegistry;",
          "55: import org.apache.kafka.timeline.TimelineHashMap;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "53: import org.apache.kafka.server.common.Features;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "459:         FinalizedControllerFeatures finalizedFeatures,",
          "460:         BrokerRegistrationRequestData.Feature feature",
          "461:     ) {",
          "471:             log.warn(\"Broker {} registered with feature {} that is unknown to the controller\",",
          "472:                     brokerId, feature.name());",
          "474:         return new BrokerFeature().",
          "475:                 setName(feature.name()).",
          "476:                 setMinSupportedVersion(feature.minSupportedVersion()).",
          "",
          "[Removed Lines]",
          "462:         Optional<Short> finalized = finalizedFeatures.get(feature.name());",
          "463:         if (finalized.isPresent()) {",
          "464:             if (!VersionRange.of(feature.minSupportedVersion(), feature.maxSupportedVersion()).contains(finalized.get())) {",
          "465:                 throw new UnsupportedVersionException(\"Unable to register because the broker \" +",
          "466:                     \"does not support version \" + finalized.get() + \" of \" + feature.name() +",
          "467:                         \". It wants a version between \" + feature.minSupportedVersion() + \" and \" +",
          "468:                         feature.maxSupportedVersion() + \", inclusive.\");",
          "469:             }",
          "470:         } else {",
          "473:         }",
          "",
          "[Added Lines]",
          "463:         int defaultVersion = feature.name().equals(MetadataVersion.FEATURE_NAME) ? 1 : 0; // The default value for MetadataVersion is 1 not 0.",
          "464:         short finalized = finalizedFeatures.versionOrDefault(feature.name(), (short) defaultVersion);",
          "465:         if (!VersionRange.of(feature.minSupportedVersion(), feature.maxSupportedVersion()).contains(finalized)) {",
          "466:             throw new UnsupportedVersionException(\"Unable to register because the broker \" +",
          "467:                 \"does not support version \" + finalized + \" of \" + feature.name() +",
          "468:                     \". It wants a version between \" + feature.minSupportedVersion() + \" and \" +",
          "469:                     feature.maxSupportedVersion() + \", inclusive.\");",
          "470:         }",
          "473:         if (!Features.PRODUCTION_FEATURE_NAMES.contains(feature.name()))",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/controller/QuorumFeatures.java||metadata/src/main/java/org/apache/kafka/controller/QuorumFeatures.java": [
          "File: metadata/src/main/java/org/apache/kafka/controller/QuorumFeatures.java -> metadata/src/main/java/org/apache/kafka/controller/QuorumFeatures.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: import org.apache.kafka.metadata.ControllerRegistration;",
          "21: import org.apache.kafka.metadata.VersionRange;",
          "22: import org.apache.kafka.server.common.MetadataVersion;",
          "24: import java.util.ArrayList;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "22: import org.apache.kafka.server.common.Features;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "61:                 enableUnstable ?",
          "62:                     MetadataVersion.latestTesting().featureLevel() :",
          "63:                     MetadataVersion.latestProduction().featureLevel()));",
          "64:         return features;",
          "65:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "65:         for (Features feature : Features.PRODUCTION_FEATURES) {",
          "66:             features.put(feature.featureName(), VersionRange.of(",
          "67:                 0,",
          "68:                 feature.latestProduction()",
          "69:             ));",
          "70:         }",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/FinalizedControllerFeatures.java||metadata/src/main/java/org/apache/kafka/metadata/FinalizedControllerFeatures.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/FinalizedControllerFeatures.java -> metadata/src/main/java/org/apache/kafka/metadata/FinalizedControllerFeatures.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "40:         return Optional.ofNullable(featureMap.get(name));",
          "41:     }",
          "43:     public Set<String> featureNames() {",
          "44:         return featureMap.keySet();",
          "45:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "43:     public short versionOrDefault(String name, short defaultValue) {",
          "44:         return featureMap.getOrDefault(name, defaultValue);",
          "45:     }",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/publisher/FeaturesPublisher.java||metadata/src/main/java/org/apache/kafka/metadata/publisher/FeaturesPublisher.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/publisher/FeaturesPublisher.java -> metadata/src/main/java/org/apache/kafka/metadata/publisher/FeaturesPublisher.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: import org.apache.kafka.image.MetadataImage;",
          "23: import org.apache.kafka.image.loader.LoaderManifest;",
          "24: import org.apache.kafka.image.publisher.MetadataPublisher;",
          "26: import org.slf4j.Logger;",
          "28: import static org.apache.kafka.server.common.MetadataVersion.MINIMUM_KRAFT_VERSION;",
          "",
          "[Removed Lines]",
          "25: import org.apache.kafka.server.common.Features;",
          "",
          "[Added Lines]",
          "25: import org.apache.kafka.server.common.FinalizedFeatures;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "31: public class FeaturesPublisher implements MetadataPublisher {",
          "32:     private final Logger log;",
          "35:     public FeaturesPublisher(",
          "36:         LogContext logContext",
          "",
          "[Removed Lines]",
          "33:     private volatile Features features = Features.fromKRaftVersion(MINIMUM_KRAFT_VERSION);",
          "",
          "[Added Lines]",
          "33:     private volatile FinalizedFeatures finalizedFeatures = FinalizedFeatures.fromKRaftVersion(MINIMUM_KRAFT_VERSION);",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "38:         log = logContext.logger(FeaturesPublisher.class);",
          "39:     }",
          "43:     }",
          "45:     @Override",
          "",
          "[Removed Lines]",
          "41:     public Features features() {",
          "42:         return features;",
          "",
          "[Added Lines]",
          "41:     public FinalizedFeatures features() {",
          "42:         return finalizedFeatures;",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "54:         LoaderManifest manifest",
          "55:     ) {",
          "56:         if (delta.featuresDelta() != null) {",
          "58:                     newImage.features().finalizedVersions(),",
          "59:                     newImage.provenance().lastContainedOffset(),",
          "60:                     true);",
          "64:             }",
          "65:         }",
          "66:     }",
          "",
          "[Removed Lines]",
          "57:             Features newFeatures = new Features(newImage.features().metadataVersion(),",
          "61:             if (!newFeatures.equals(features)) {",
          "62:                 log.info(\"Loaded new metadata {}.\", newFeatures);",
          "63:                 features = newFeatures;",
          "",
          "[Added Lines]",
          "57:             FinalizedFeatures newFinalizedFeatures = new FinalizedFeatures(newImage.features().metadataVersion(),",
          "61:             if (!newFinalizedFeatures.equals(finalizedFeatures)) {",
          "62:                 log.info(\"Loaded new metadata {}.\", newFinalizedFeatures);",
          "63:                 finalizedFeatures = newFinalizedFeatures;",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/controller/QuorumFeaturesTest.java||metadata/src/test/java/org/apache/kafka/controller/QuorumFeaturesTest.java": [
          "File: metadata/src/test/java/org/apache/kafka/controller/QuorumFeaturesTest.java -> metadata/src/test/java/org/apache/kafka/controller/QuorumFeaturesTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: import org.apache.kafka.common.security.auth.SecurityProtocol;",
          "23: import org.apache.kafka.metadata.ControllerRegistration;",
          "24: import org.apache.kafka.metadata.VersionRange;",
          "25: import org.apache.kafka.server.common.MetadataVersion;",
          "26: import org.junit.jupiter.api.Test;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "25: import org.apache.kafka.server.common.Features;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "55:         expectedFeatures.put(MetadataVersion.FEATURE_NAME, VersionRange.of(",
          "56:             MetadataVersion.MINIMUM_KRAFT_VERSION.featureLevel(),",
          "57:             MetadataVersion.LATEST_PRODUCTION.featureLevel()));",
          "58:         assertEquals(expectedFeatures, QuorumFeatures.defaultFeatureMap(false));",
          "59:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "59:         for (Features feature : Features.PRODUCTION_FEATURES) {",
          "60:             expectedFeatures.put(feature.featureName(), VersionRange.of(",
          "61:                 0,",
          "62:                 feature.defaultValue(MetadataVersion.LATEST_PRODUCTION)",
          "63:             ));",
          "64:         }",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "64:         expectedFeatures.put(MetadataVersion.FEATURE_NAME, VersionRange.of(",
          "65:             MetadataVersion.MINIMUM_KRAFT_VERSION.featureLevel(),",
          "66:             MetadataVersion.latestTesting().featureLevel()));",
          "67:         assertEquals(expectedFeatures, QuorumFeatures.defaultFeatureMap(true));",
          "68:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "74:         for (Features feature : Features.PRODUCTION_FEATURES) {",
          "75:             expectedFeatures.put(feature.featureName(), VersionRange.of(",
          "76:                 0,",
          "77:                 feature.defaultValue(MetadataVersion.LATEST_PRODUCTION)",
          "78:             ));",
          "79:         }",
          "",
          "---------------"
        ],
        "server-common/src/main/java/org/apache/kafka/server/common/FeatureVersion.java||server-common/src/main/java/org/apache/kafka/server/common/FeatureVersion.java": [
          "File: server-common/src/main/java/org/apache/kafka/server/common/FeatureVersion.java -> server-common/src/main/java/org/apache/kafka/server/common/FeatureVersion.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.server.common;",
          "20: import java.util.Map;",
          "22: public interface FeatureVersion {",
          "27:     short featureLevel();",
          "32:     String featureName();",
          "48:     MetadataVersion bootstrapMetadataVersion();",
          "56:     Map<String, Short> dependencies();",
          "57: }",
          "",
          "---------------"
        ],
        "server-common/src/main/java/org/apache/kafka/server/common/Features.java||server-common/src/main/java/org/apache/kafka/server/common/Features.java": [
          "File: server-common/src/main/java/org/apache/kafka/server/common/Features.java -> server-common/src/main/java/org/apache/kafka/server/common/Features.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: package org.apache.kafka.server.common;",
          "21: import java.util.Map;",
          "33:     }",
          "51:     }",
          "55:     }",
          "59:     }",
          "63:     }",
          "72:     }",
          "77:     }",
          "86:     }",
          "87: }",
          "",
          "[Removed Lines]",
          "19: import java.util.Collections;",
          "20: import java.util.HashMap;",
          "22: import java.util.Objects;",
          "24: import static org.apache.kafka.server.common.MetadataVersion.FEATURE_NAME;",
          "26: public final class Features {",
          "27:     private final MetadataVersion version;",
          "28:     private final Map<String, Short> finalizedFeatures;",
          "29:     private final long finalizedFeaturesEpoch;",
          "31:     public static Features fromKRaftVersion(MetadataVersion version) {",
          "32:         return new Features(version, Collections.emptyMap(), -1, true);",
          "35:     public Features(",
          "36:         MetadataVersion version,",
          "37:         Map<String, Short> finalizedFeatures,",
          "38:         long finalizedFeaturesEpoch,",
          "39:         boolean kraftMode",
          "40:     ) {",
          "41:         this.version = version;",
          "42:         this.finalizedFeatures = new HashMap<>(finalizedFeatures);",
          "43:         this.finalizedFeaturesEpoch = finalizedFeaturesEpoch;",
          "46:         if (kraftMode) {",
          "47:             this.finalizedFeatures.put(FEATURE_NAME, version.featureLevel());",
          "48:         } else {",
          "49:             this.finalizedFeatures.remove(FEATURE_NAME);",
          "50:         }",
          "53:     public MetadataVersion metadataVersion() {",
          "54:         return version;",
          "57:     public Map<String, Short> finalizedFeatures() {",
          "58:         return finalizedFeatures;",
          "61:     public long finalizedFeaturesEpoch() {",
          "62:         return finalizedFeaturesEpoch;",
          "65:     @Override",
          "66:     public boolean equals(Object o) {",
          "67:         if (o == null || !(o.getClass().equals(Features.class))) return false;",
          "68:         Features other = (Features) o;",
          "69:         return version == other.version &&",
          "70:             finalizedFeatures.equals(other.finalizedFeatures) &&",
          "71:                 finalizedFeaturesEpoch == other.finalizedFeaturesEpoch;",
          "74:     @Override",
          "75:     public int hashCode() {",
          "76:         return Objects.hash(version, finalizedFeatures, finalizedFeaturesEpoch);",
          "79:     @Override",
          "80:     public String toString() {",
          "81:         return \"Features\" +",
          "82:                 \"(version=\" + version +",
          "83:                 \", finalizedFeatures=\" + finalizedFeatures +",
          "84:                 \", finalizedFeaturesEpoch=\" + finalizedFeaturesEpoch +",
          "85:                 \")\";",
          "",
          "[Added Lines]",
          "19: import java.util.Arrays;",
          "20: import java.util.Iterator;",
          "21: import java.util.List;",
          "23: import java.util.stream.Collectors;",
          "34: public enum Features {",
          "42:     TEST_VERSION(\"test.feature.version\", TestFeatureVersion.values());",
          "44:     public static final Features[] FEATURES;",
          "45:     public static final List<Features> PRODUCTION_FEATURES;",
          "47:     public static final List<String> PRODUCTION_FEATURE_NAMES;",
          "48:     private final String name;",
          "49:     private final FeatureVersion[] featureVersions;",
          "51:     Features(String name,",
          "52:              FeatureVersion[] featureVersions) {",
          "53:         this.name = name;",
          "54:         this.featureVersions = featureVersions;",
          "57:     static {",
          "58:         Features[] enumValues = Features.values();",
          "59:         FEATURES = Arrays.copyOf(enumValues, enumValues.length);",
          "61:         PRODUCTION_FEATURES = Arrays.stream(FEATURES).filter(feature ->",
          "62:                 !feature.name.equals(TEST_VERSION.featureName())).collect(Collectors.toList());",
          "63:         PRODUCTION_FEATURE_NAMES = PRODUCTION_FEATURES.stream().map(feature ->",
          "64:                 feature.name).collect(Collectors.toList());",
          "65:     }",
          "67:     public String featureName() {",
          "68:         return name;",
          "71:     public FeatureVersion[] featureVersions() {",
          "72:         return featureVersions;",
          "75:     public short latestProduction() {",
          "76:         return defaultValue(MetadataVersion.LATEST_PRODUCTION);",
          "86:     public FeatureVersion fromFeatureLevel(short level) {",
          "87:         return Arrays.stream(featureVersions).filter(featureVersion ->",
          "88:             featureVersion.featureLevel() == level).findFirst().orElseThrow(",
          "89:                 () -> new IllegalArgumentException(\"No feature:\" + featureName() + \" with feature level \" + level));",
          "105:     public static void validateVersion(FeatureVersion feature, Map<String, Short> features) {",
          "106:         Short metadataVersion = features.get(MetadataVersion.FEATURE_NAME);",
          "108:         if (feature.featureLevel() >= 1 && (metadataVersion == null || metadataVersion < MetadataVersion.IBP_3_3_IV0.featureLevel()))",
          "109:             throw new IllegalArgumentException(feature.featureName() + \" could not be set to \" + feature.featureLevel() +",
          "110:                     \" because it depends on metadata.version=4 (\" + MetadataVersion.IBP_3_3_IV0 + \")\");",
          "112:         for (Map.Entry<String, Short> dependency: feature.dependencies().entrySet()) {",
          "113:             Short featureLevel = features.get(dependency.getKey());",
          "115:             if (featureLevel == null || featureLevel < dependency.getValue()) {",
          "116:                 throw new IllegalArgumentException(feature.featureName() + \" could not be set to \" + feature.featureLevel() +",
          "117:                         \" because it depends on \" + dependency.getKey() + \" level \" + dependency.getValue());",
          "118:             }",
          "119:         }",
          "132:     public short defaultValue(MetadataVersion metadataVersion) {",
          "133:         short level = 0;",
          "134:         for (Iterator<FeatureVersion> it = Arrays.stream(featureVersions).iterator(); it.hasNext(); ) {",
          "135:             FeatureVersion feature = it.next();",
          "136:             if (feature.bootstrapMetadataVersion().isLessThan(metadataVersion) || feature.bootstrapMetadataVersion().equals(metadataVersion))",
          "137:                 level = feature.featureLevel();",
          "138:             else",
          "139:                 return level;",
          "140:         }",
          "141:         return level;",
          "147:     public static Map<String, Short> featureImplsToMap(List<FeatureVersion> features) {",
          "148:         return features.stream().collect(Collectors.toMap(FeatureVersion::featureName, FeatureVersion::featureLevel));",
          "",
          "---------------"
        ],
        "server-common/src/main/java/org/apache/kafka/server/common/FinalizedFeatures.java||server-common/src/main/java/org/apache/kafka/server/common/FinalizedFeatures.java": [
          "File: server-common/src/main/java/org/apache/kafka/server/common/FinalizedFeatures.java -> server-common/src/main/java/org/apache/kafka/server/common/FinalizedFeatures.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "17: package org.apache.kafka.server.common;",
          "19: import java.util.Collections;",
          "20: import java.util.HashMap;",
          "21: import java.util.Map;",
          "22: import java.util.Objects;",
          "24: public final class FinalizedFeatures {",
          "25:     private final MetadataVersion metadataVersion;",
          "26:     private final Map<String, Short> finalizedFeatures;",
          "27:     private final long finalizedFeaturesEpoch;",
          "29:     public static FinalizedFeatures fromKRaftVersion(MetadataVersion version) {",
          "30:         return new FinalizedFeatures(version, Collections.emptyMap(), -1, true);",
          "31:     }",
          "33:     public FinalizedFeatures(",
          "34:         MetadataVersion metadataVersion,",
          "35:         Map<String, Short> finalizedFeatures,",
          "36:         long finalizedFeaturesEpoch,",
          "37:         boolean kraftMode",
          "38:     ) {",
          "39:         this.metadataVersion = metadataVersion;",
          "40:         this.finalizedFeatures = new HashMap<>(finalizedFeatures);",
          "41:         this.finalizedFeaturesEpoch = finalizedFeaturesEpoch;",
          "44:         if (kraftMode) {",
          "45:             this.finalizedFeatures.put(MetadataVersion.FEATURE_NAME, metadataVersion.featureLevel());",
          "46:         } else {",
          "47:             this.finalizedFeatures.remove(MetadataVersion.FEATURE_NAME);",
          "48:         }",
          "49:     }",
          "51:     public MetadataVersion metadataVersion() {",
          "52:         return metadataVersion;",
          "53:     }",
          "55:     public Map<String, Short> finalizedFeatures() {",
          "56:         return finalizedFeatures;",
          "57:     }",
          "59:     public long finalizedFeaturesEpoch() {",
          "60:         return finalizedFeaturesEpoch;",
          "61:     }",
          "63:     @Override",
          "64:     public boolean equals(Object o) {",
          "65:         if (o == null || !(o.getClass().equals(FinalizedFeatures.class))) return false;",
          "66:         FinalizedFeatures other = (FinalizedFeatures) o;",
          "67:         return metadataVersion == other.metadataVersion &&",
          "68:             finalizedFeatures.equals(other.finalizedFeatures) &&",
          "69:                 finalizedFeaturesEpoch == other.finalizedFeaturesEpoch;",
          "70:     }",
          "72:     @Override",
          "73:     public int hashCode() {",
          "74:         return Objects.hash(metadataVersion, finalizedFeatures, finalizedFeaturesEpoch);",
          "75:     }",
          "77:     @Override",
          "78:     public String toString() {",
          "79:         return \"Features\" +",
          "80:                 \"(metadataVersion=\" + metadataVersion +",
          "81:                 \", finalizedFeatures=\" + finalizedFeatures +",
          "82:                 \", finalizedFeaturesEpoch=\" + finalizedFeaturesEpoch +",
          "83:                 \")\";",
          "84:     }",
          "85: }",
          "",
          "---------------"
        ],
        "server-common/src/main/java/org/apache/kafka/server/common/MetadataVersion.java||server-common/src/main/java/org/apache/kafka/server/common/MetadataVersion.java": [
          "File: server-common/src/main/java/org/apache/kafka/server/common/MetadataVersion.java -> server-common/src/main/java/org/apache/kafka/server/common/MetadataVersion.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "258:         this.didMetadataChange = didMetadataChange;",
          "259:     }",
          "261:     public short featureLevel() {",
          "262:         return featureLevel;",
          "263:     }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "261:     public String featureName() {",
          "262:         return FEATURE_NAME;",
          "263:     }",
          "",
          "---------------"
        ],
        "server-common/src/main/java/org/apache/kafka/server/common/TestFeatureVersion.java||server-common/src/main/java/org/apache/kafka/server/common/TestFeatureVersion.java": [
          "File: server-common/src/main/java/org/apache/kafka/server/common/TestFeatureVersion.java -> server-common/src/main/java/org/apache/kafka/server/common/TestFeatureVersion.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "17: package org.apache.kafka.server.common;",
          "19: import java.util.Collections;",
          "20: import java.util.Map;",
          "22: public enum TestFeatureVersion implements FeatureVersion {",
          "25:     TEST_1(1, MetadataVersion.IBP_3_7_IV0, Collections.emptyMap()),",
          "27:     TEST_2(2, MetadataVersion.IBP_3_8_IV0, Collections.singletonMap(MetadataVersion.FEATURE_NAME, MetadataVersion.IBP_3_8_IV0.featureLevel()));",
          "29:     private final short featureLevel;",
          "30:     private final MetadataVersion metadataVersionMapping;",
          "31:     private final Map<String, Short> dependencies;",
          "33:     public static final String FEATURE_NAME = \"test.feature.version\";",
          "35:     TestFeatureVersion(int featureLevel, MetadataVersion metadataVersionMapping, Map<String, Short> dependencies) {",
          "36:         this.featureLevel = (short) featureLevel;",
          "37:         this.metadataVersionMapping = metadataVersionMapping;",
          "38:         this.dependencies = dependencies;",
          "39:     }",
          "41:     public short featureLevel() {",
          "42:         return featureLevel;",
          "43:     }",
          "45:     public String featureName() {",
          "46:         return FEATURE_NAME;",
          "47:     }",
          "49:     public MetadataVersion bootstrapMetadataVersion() {",
          "50:         return metadataVersionMapping;",
          "51:     }",
          "53:     public Map<String, Short> dependencies() {",
          "54:         return dependencies;",
          "55:     }",
          "56: }",
          "",
          "---------------"
        ],
        "server-common/src/test/java/org/apache/kafka/server/common/FeaturesTest.java||server-common/src/test/java/org/apache/kafka/server/common/FeaturesTest.java": [
          "File: server-common/src/test/java/org/apache/kafka/server/common/FeaturesTest.java -> server-common/src/test/java/org/apache/kafka/server/common/FeaturesTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: package org.apache.kafka.server.common;",
          "20: import org.junit.jupiter.api.Test;",
          "22: import java.util.Collections;",
          "26: import static org.junit.jupiter.api.Assertions.assertEquals;",
          "39:     }",
          "41:     @Test",
          "49:     }",
          "50: }",
          "",
          "[Removed Lines]",
          "24: import static org.apache.kafka.server.common.MetadataVersion.FEATURE_NAME;",
          "25: import static org.apache.kafka.server.common.MetadataVersion.MINIMUM_KRAFT_VERSION;",
          "27: import static org.junit.jupiter.api.Assertions.assertNull;",
          "29: class FeaturesTest {",
          "30:     @Test",
          "31:     public void testKRaftModeFeatures() {",
          "32:         Features features = new Features(MINIMUM_KRAFT_VERSION,",
          "33:                 Collections.singletonMap(\"foo\", (short) 2), 123, true);",
          "34:         assertEquals(MINIMUM_KRAFT_VERSION.featureLevel(),",
          "35:                 features.finalizedFeatures().get(FEATURE_NAME));",
          "36:         assertEquals((short) 2,",
          "37:                 features.finalizedFeatures().get(\"foo\"));",
          "38:         assertEquals(2, features.finalizedFeatures().size());",
          "42:     public void testZkModeFeatures() {",
          "43:         Features features = new Features(MINIMUM_KRAFT_VERSION,",
          "44:                 Collections.singletonMap(\"foo\", (short) 2), 123, false);",
          "45:         assertNull(features.finalizedFeatures().get(FEATURE_NAME));",
          "46:         assertEquals((short) 2,",
          "47:                 features.finalizedFeatures().get(\"foo\"));",
          "48:         assertEquals(1, features.finalizedFeatures().size());",
          "",
          "[Added Lines]",
          "20: import org.junit.jupiter.params.ParameterizedTest;",
          "21: import org.junit.jupiter.params.provider.EnumSource;",
          "24: import java.util.HashMap;",
          "25: import java.util.Map;",
          "28: import static org.junit.jupiter.api.Assertions.assertThrows;",
          "30: public class FeaturesTest {",
          "32:     @ParameterizedTest",
          "33:     @EnumSource(Features.class)",
          "34:     public void testFromFeatureLevelAllFeatures(Features feature) {",
          "35:         FeatureVersion[] featureImplementations = feature.featureVersions();",
          "36:         int numFeatures = featureImplementations.length;",
          "37:         for (short i = 1; i < numFeatures; i++) {",
          "38:             assertEquals(featureImplementations[i - 1], feature.fromFeatureLevel(i));",
          "39:         }",
          "40:     }",
          "42:     @ParameterizedTest",
          "43:     @EnumSource(Features.class)",
          "44:     public void testValidateVersionAllFeatures(Features feature) {",
          "45:         for (FeatureVersion featureImpl : feature.featureVersions()) {",
          "47:             Map<String, Short> deps = new HashMap<>();",
          "48:             deps.putAll(featureImpl.dependencies());",
          "49:             if (!deps.containsKey(MetadataVersion.FEATURE_NAME)) {",
          "50:                 deps.put(MetadataVersion.FEATURE_NAME, MetadataVersion.MINIMUM_BOOTSTRAP_VERSION.featureLevel());",
          "51:             }",
          "55:             Features.validateVersion(featureImpl, deps);",
          "56:         }",
          "60:     public void testInvalidValidateVersion() {",
          "62:         assertThrows(IllegalArgumentException.class,",
          "63:             () -> Features.validateVersion(",
          "64:                 TestFeatureVersion.TEST_1,",
          "65:                 Collections.emptyMap()",
          "66:             )",
          "67:         );",
          "70:         assertThrows(IllegalArgumentException.class,",
          "71:             () -> Features.validateVersion(",
          "72:                 TestFeatureVersion.TEST_1,",
          "73:                 Collections.singletonMap(MetadataVersion.FEATURE_NAME, MetadataVersion.IBP_2_8_IV0.featureLevel())",
          "74:             )",
          "75:         );",
          "78:         assertThrows(IllegalArgumentException.class,",
          "79:              () -> Features.validateVersion(",
          "80:                  TestFeatureVersion.TEST_2,",
          "81:                  Collections.singletonMap(MetadataVersion.FEATURE_NAME, MetadataVersion.IBP_3_7_IV0.featureLevel())",
          "82:              )",
          "83:         );",
          "84:     }",
          "86:     @ParameterizedTest",
          "87:     @EnumSource(Features.class)",
          "88:     public void testDefaultValueAllFeatures(Features feature) {",
          "89:         for (FeatureVersion featureImpl : feature.featureVersions()) {",
          "90:             assertEquals(feature.defaultValue(featureImpl.bootstrapMetadataVersion()), featureImpl.featureLevel(),",
          "91:                     \"Failed to get the correct default for \" + featureImpl);",
          "92:         }",
          "93:     }",
          "95:     @ParameterizedTest",
          "96:     @EnumSource(Features.class)",
          "97:     public void testLatestProductionMapsToLatestMetadataVersion(Features features) {",
          "98:         assertEquals(features.latestProduction(), features.defaultValue(MetadataVersion.LATEST_PRODUCTION));",
          "99:     }",
          "101:     @ParameterizedTest",
          "102:     @EnumSource(MetadataVersion.class)",
          "103:     public void testDefaultTestVersion(MetadataVersion metadataVersion) {",
          "104:         short expectedVersion;",
          "105:         if (!metadataVersion.isLessThan(MetadataVersion.IBP_3_8_IV0)) {",
          "106:             expectedVersion = 2;",
          "107:         } else if (!metadataVersion.isLessThan(MetadataVersion.IBP_3_7_IV0)) {",
          "108:             expectedVersion = 1;",
          "109:         } else {",
          "110:             expectedVersion = 0;",
          "111:         }",
          "112:         assertEquals(expectedVersion, Features.TEST_VERSION.defaultValue(metadataVersion));",
          "",
          "---------------"
        ],
        "server-common/src/test/java/org/apache/kafka/server/common/FinalizedFeaturesTest.java||server-common/src/test/java/org/apache/kafka/server/common/FinalizedFeaturesTest.java": [
          "File: server-common/src/test/java/org/apache/kafka/server/common/FinalizedFeaturesTest.java -> server-common/src/test/java/org/apache/kafka/server/common/FinalizedFeaturesTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.server.common;",
          "20: import org.junit.jupiter.api.Test;",
          "22: import java.util.Collections;",
          "24: import static org.apache.kafka.server.common.MetadataVersion.FEATURE_NAME;",
          "25: import static org.apache.kafka.server.common.MetadataVersion.MINIMUM_KRAFT_VERSION;",
          "26: import static org.junit.jupiter.api.Assertions.assertEquals;",
          "27: import static org.junit.jupiter.api.Assertions.assertNull;",
          "29: class FinalizedFeaturesTest {",
          "30:     @Test",
          "31:     public void testKRaftModeFeatures() {",
          "32:         FinalizedFeatures finalizedFeatures = new FinalizedFeatures(MINIMUM_KRAFT_VERSION,",
          "33:                 Collections.singletonMap(\"foo\", (short) 2), 123, true);",
          "34:         assertEquals(MINIMUM_KRAFT_VERSION.featureLevel(),",
          "35:                 finalizedFeatures.finalizedFeatures().get(FEATURE_NAME));",
          "36:         assertEquals((short) 2,",
          "37:                 finalizedFeatures.finalizedFeatures().get(\"foo\"));",
          "38:         assertEquals(2, finalizedFeatures.finalizedFeatures().size());",
          "39:     }",
          "41:     @Test",
          "42:     public void testZkModeFeatures() {",
          "43:         FinalizedFeatures finalizedFeatures = new FinalizedFeatures(MINIMUM_KRAFT_VERSION,",
          "44:                 Collections.singletonMap(\"foo\", (short) 2), 123, false);",
          "45:         assertNull(finalizedFeatures.finalizedFeatures().get(FEATURE_NAME));",
          "46:         assertEquals((short) 2,",
          "47:                 finalizedFeatures.finalizedFeatures().get(\"foo\"));",
          "48:         assertEquals(1, finalizedFeatures.finalizedFeatures().size());",
          "49:     }",
          "50: }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "129e7fb0b89f56b44164d62e66e1dc8ec70c231b",
      "candidate_info": {
        "commit_hash": "129e7fb0b89f56b44164d62e66e1dc8ec70c231b",
        "repo": "apache/kafka",
        "commit_url": "https://github.com/apache/kafka/commit/129e7fb0b89f56b44164d62e66e1dc8ec70c231b",
        "files": [
          "checkstyle/import-control-metadata.xml",
          "checkstyle/suppressions.xml",
          "core/src/main/scala/kafka/tools/StorageTool.scala",
          "core/src/test/scala/integration/kafka/api/DelegationTokenEndToEndAuthorizationTest.scala",
          "core/src/test/scala/integration/kafka/api/SaslScramSslEndToEndAuthorizationTest.scala",
          "core/src/test/scala/integration/kafka/server/QuorumTestHarness.scala",
          "core/src/test/scala/unit/kafka/server/ReplicaManagerConcurrencyTest.scala",
          "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala",
          "core/src/test/scala/unit/kafka/utils/TestUtils.scala",
          "metadata/src/main/java/org/apache/kafka/metadata/bootstrap/BootstrapMetadata.java",
          "metadata/src/main/java/org/apache/kafka/metadata/storage/Formatter.java",
          "metadata/src/main/java/org/apache/kafka/metadata/storage/FormatterException.java",
          "metadata/src/main/java/org/apache/kafka/metadata/storage/ScramParser.java",
          "metadata/src/test/java/org/apache/kafka/metadata/storage/FormatterTest.java",
          "metadata/src/test/java/org/apache/kafka/metadata/storage/ScramParserTest.java",
          "raft/src/main/java/org/apache/kafka/raft/DynamicVoter.java",
          "raft/src/main/java/org/apache/kafka/raft/DynamicVoters.java",
          "raft/src/main/java/org/apache/kafka/raft/internals/VoterSet.java",
          "raft/src/test/java/org/apache/kafka/raft/DynamicVoterTest.java",
          "raft/src/test/java/org/apache/kafka/raft/DynamicVotersTest.java",
          "server-common/src/main/java/org/apache/kafka/server/common/KRaftVersion.java"
        ],
        "message": "KAFKA-16518: Implement KIP-853 flags for storage-tool.sh (#16669)\n\nAs part of KIP-853, storage-tool.sh now has two new flags: --standalone, and --initial-voters. This PR implements these two flags in storage-tool.sh.\n\nThere are currently two valid ways to format a cluster:\n\nThe pre-KIP-853 way, where you use a statically configured controller quorum. In this case, neither --standalone nor --initial-voters may be specified, and kraft.version must be set to 0.\n\nThe KIP-853 way, where one of --standalone and --initial-voters must be specified with the initial value of the dynamic controller quorum. In this case, kraft.version must be set to 1.\n\nThis PR moves the formatting logic out of StorageTool.scala and into Formatter.java. The tool file was never intended to get so huge, or to implement complex logic like generating metadata records. Those things should be done by code in the metadata or raft gradle modules. This is also useful for junit tests, which often need to do formatting. (The 'info' and 'random-uuid' commands remain in StorageTool.scala, for now.)\n\nReviewers: Jos\u00e9 Armando Garc\u00eda Sancio <jsancio@apache.org>",
        "before_after_code_files": [
          "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
          "core/src/test/scala/integration/kafka/api/DelegationTokenEndToEndAuthorizationTest.scala||core/src/test/scala/integration/kafka/api/DelegationTokenEndToEndAuthorizationTest.scala",
          "core/src/test/scala/integration/kafka/api/SaslScramSslEndToEndAuthorizationTest.scala||core/src/test/scala/integration/kafka/api/SaslScramSslEndToEndAuthorizationTest.scala",
          "core/src/test/scala/integration/kafka/server/QuorumTestHarness.scala||core/src/test/scala/integration/kafka/server/QuorumTestHarness.scala",
          "core/src/test/scala/unit/kafka/server/ReplicaManagerConcurrencyTest.scala||core/src/test/scala/unit/kafka/server/ReplicaManagerConcurrencyTest.scala",
          "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala",
          "core/src/test/scala/unit/kafka/utils/TestUtils.scala||core/src/test/scala/unit/kafka/utils/TestUtils.scala",
          "metadata/src/main/java/org/apache/kafka/metadata/bootstrap/BootstrapMetadata.java||metadata/src/main/java/org/apache/kafka/metadata/bootstrap/BootstrapMetadata.java",
          "metadata/src/main/java/org/apache/kafka/metadata/storage/Formatter.java||metadata/src/main/java/org/apache/kafka/metadata/storage/Formatter.java",
          "metadata/src/main/java/org/apache/kafka/metadata/storage/FormatterException.java||metadata/src/main/java/org/apache/kafka/metadata/storage/FormatterException.java",
          "metadata/src/main/java/org/apache/kafka/metadata/storage/ScramParser.java||metadata/src/main/java/org/apache/kafka/metadata/storage/ScramParser.java",
          "metadata/src/test/java/org/apache/kafka/metadata/storage/FormatterTest.java||metadata/src/test/java/org/apache/kafka/metadata/storage/FormatterTest.java",
          "metadata/src/test/java/org/apache/kafka/metadata/storage/ScramParserTest.java||metadata/src/test/java/org/apache/kafka/metadata/storage/ScramParserTest.java",
          "raft/src/main/java/org/apache/kafka/raft/DynamicVoter.java||raft/src/main/java/org/apache/kafka/raft/DynamicVoter.java",
          "raft/src/main/java/org/apache/kafka/raft/DynamicVoters.java||raft/src/main/java/org/apache/kafka/raft/DynamicVoters.java",
          "raft/src/main/java/org/apache/kafka/raft/internals/VoterSet.java||raft/src/main/java/org/apache/kafka/raft/internals/VoterSet.java",
          "raft/src/test/java/org/apache/kafka/raft/DynamicVoterTest.java||raft/src/test/java/org/apache/kafka/raft/DynamicVoterTest.java",
          "raft/src/test/java/org/apache/kafka/raft/DynamicVotersTest.java||raft/src/test/java/org/apache/kafka/raft/DynamicVotersTest.java",
          "server-common/src/main/java/org/apache/kafka/server/common/KRaftVersion.java||server-common/src/main/java/org/apache/kafka/server/common/KRaftVersion.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
            "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
          ],
          "candidate": [
            "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
            "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
          ]
        }
      },
      "candidate_diff": {
        "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala": [
          "File: core/src/main/scala/kafka/tools/StorageTool.scala -> core/src/main/scala/kafka/tools/StorageTool.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "24: import kafka.utils.{Exit, Logging}",
          "25: import net.sourceforge.argparse4j.ArgumentParsers",
          "26: import net.sourceforge.argparse4j.impl.Arguments.{append, store, storeTrue}",
          "28: import org.apache.kafka.common.Uuid",
          "29: import org.apache.kafka.common.utils.Utils",
          "38: import org.apache.kafka.metadata.properties.{MetaProperties, MetaPropertiesEnsemble, MetaPropertiesVersion, PropertiesUtils}",
          "41: import java.util",
          "43: import scala.collection.mutable",
          "47: object StorageTool extends Logging {",
          "",
          "[Removed Lines]",
          "27: import net.sourceforge.argparse4j.inf.Namespace",
          "30: import org.apache.kafka.metadata.bootstrap.{BootstrapDirectory, BootstrapMetadata}",
          "31: import org.apache.kafka.server.common.{ApiMessageAndVersion, Features, MetadataVersion}",
          "32: import org.apache.kafka.common.metadata.FeatureLevelRecord",
          "33: import org.apache.kafka.common.metadata.UserScramCredentialRecord",
          "34: import org.apache.kafka.common.security.scram.internals.ScramMechanism",
          "35: import org.apache.kafka.common.security.scram.internals.ScramFormatter",
          "36: import org.apache.kafka.server.config.ReplicationConfigs",
          "37: import org.apache.kafka.metadata.properties.MetaPropertiesEnsemble.VerificationFlag",
          "39: import org.apache.kafka.server.common.FeatureVersion",
          "42: import java.util.{Base64, Collections, Optional}",
          "44: import scala.jdk.CollectionConverters._",
          "45: import scala.collection.mutable.ArrayBuffer",
          "",
          "[Added Lines]",
          "27: import net.sourceforge.argparse4j.inf.{ArgumentParserException, Namespace}",
          "30: import org.apache.kafka.server.common.MetadataVersion",
          "32: import org.apache.kafka.metadata.storage.{Formatter, FormatterException}",
          "33: import org.apache.kafka.raft.DynamicVoters",
          "34: import org.apache.kafka.server.ProcessRole",
          "35: import org.apache.kafka.server.config.ReplicationConfigs",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "50:     var exitCode: Integer = 0",
          "51:     var message: Option[String] = None",
          "52:     try {",
          "54:     } catch {",
          "55:       case e: TerseFailure =>",
          "56:         exitCode = 1",
          "57:         message = Some(e.getMessage)",
          "",
          "[Removed Lines]",
          "53:       exitCode = execute(args)",
          "",
          "[Added Lines]",
          "46:       exitCode = execute(args, System.out)",
          "48:       case e: FormatterException =>",
          "49:         exitCode = 1",
          "50:         message = Some(e.getMessage)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "70:     val command = namespace.getString(\"command\")",
          "71:     val config = Option(namespace.getString(\"config\")).flatMap(",
          "72:       p => Some(new KafkaConfig(Utils.loadProps(p))))",
          "73:     command match {",
          "74:       case \"info\" =>",
          "75:         val directories = configToLogDirectories(config.get)",
          "79:       case \"format\" =>",
          "82:       case \"random-uuid\" =>",
          "84:         0",
          "85:       case _ =>",
          "86:         throw new RuntimeException(s\"Unknown command $command\")",
          "",
          "[Removed Lines]",
          "68:   def execute(args: Array[String]): Int = {",
          "69:     val namespace = parseArguments(args)",
          "76:         val selfManagedMode = configToSelfManagedMode(config.get)",
          "77:         infoCommand(System.out, selfManagedMode, directories)",
          "80:         runFormatCommand(namespace, config.get)",
          "83:         System.out.println(Uuid.randomUuid)",
          "",
          "[Added Lines]",
          "64:   def execute(",
          "65:      args: Array[String],",
          "66:      printStream: PrintStream",
          "67:   ): Int = {",
          "68:     val namespace = try {",
          "69:       parseArguments(args)",
          "70:     } catch {",
          "71:       case e: ArgumentParserException =>",
          "72:         e.printStackTrace(printStream)",
          "73:         return 1",
          "74:     }",
          "81:         infoCommand(printStream, config.get.processRoles.nonEmpty, directories)",
          "84:         runFormatCommand(namespace, config.get, printStream)",
          "85:         0",
          "88:         printStream.println(Uuid.randomUuid)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "136:       throw new TerseFailure(\"The kafka configuration file appears to be for \" +",
          "137:         \"a legacy cluster. Formatting is only supported for clusters in KRaft mode.\")",
          "138:     }",
          "153:     }",
          "158:     }",
          "159:   }",
          "178:     }",
          "192:     }",
          "193:   }",
          "195:   def parseArguments(args: Array[String]): Namespace = {",
          "",
          "[Removed Lines]",
          "97:   def runFormatCommand(namespace: Namespace, config: KafkaConfig) = {",
          "98:     val directories = configToLogDirectories(config)",
          "99:     val clusterId = namespace.getString(\"cluster_id\")",
          "100:     val metaProperties = new MetaProperties.Builder().",
          "101:       setVersion(MetaPropertiesVersion.V1).",
          "102:       setClusterId(clusterId).",
          "103:       setNodeId(config.nodeId).",
          "104:       build()",
          "105:     val metadataRecords : ArrayBuffer[ApiMessageAndVersion] = ArrayBuffer()",
          "106:     val specifiedFeatures: util.List[String] = namespace.getList(\"feature\")",
          "107:     val releaseVersionFlagSpecified = namespace.getString(\"release_version\") != null",
          "108:     if (releaseVersionFlagSpecified && specifiedFeatures != null) {",
          "109:       throw new TerseFailure(\"Both --release-version and --feature were set. Only one of the two flags can be set.\")",
          "110:     }",
          "111:     val featureNamesAndLevelsMap = featureNamesAndLevels(Option(specifiedFeatures).getOrElse(Collections.emptyList).asScala.toList)",
          "112:     val metadataVersion = getMetadataVersion(namespace, featureNamesAndLevelsMap,",
          "113:       Option(config.originals.get(ReplicationConfigs.INTER_BROKER_PROTOCOL_VERSION_CONFIG)).map(_.toString))",
          "114:     validateMetadataVersion(metadataVersion, config)",
          "117:     generateFeatureRecords(",
          "118:       metadataRecords,",
          "119:       metadataVersion,",
          "120:       featureNamesAndLevelsMap,",
          "121:       Features.PRODUCTION_FEATURES.asScala.toList,",
          "122:       config.unstableFeatureVersionsEnabled,",
          "123:       releaseVersionFlagSpecified",
          "124:     )",
          "125:     getUserScramCredentialRecords(namespace).foreach(userScramCredentialRecords => {",
          "126:       if (!metadataVersion.isScramSupported) {",
          "127:         throw new TerseFailure(s\"SCRAM is only supported in metadata.version ${MetadataVersion.IBP_3_5_IV2} or later.\")",
          "128:       }",
          "129:       for (record <- userScramCredentialRecords) {",
          "130:         metadataRecords.append(new ApiMessageAndVersion(record, 0.toShort))",
          "131:       }",
          "132:     })",
          "133:     val bootstrapMetadata = buildBootstrapMetadata(metadataVersion, Some(metadataRecords), \"format command\")",
          "134:     val ignoreFormatted = namespace.getBoolean(\"ignore_formatted\")",
          "135:     if (!configToSelfManagedMode(config)) {",
          "139:     formatCommand(System.out, directories, metaProperties, bootstrapMetadata,",
          "140:       metadataVersion,ignoreFormatted)",
          "141:   }",
          "143:   private def validateMetadataVersion(metadataVersion: MetadataVersion, config: KafkaConfig): Unit = {",
          "144:     if (!metadataVersion.isKRaftSupported) {",
          "145:       throw new TerseFailure(s\"Must specify a valid KRaft metadata.version of at least ${MetadataVersion.IBP_3_0_IV0}.\")",
          "146:     }",
          "147:     if (!metadataVersion.isProduction) {",
          "148:       if (config.unstableFeatureVersionsEnabled) {",
          "149:         System.out.println(s\"WARNING: using pre-production metadata.version $metadataVersion.\")",
          "150:       } else {",
          "151:         throw new TerseFailure(s\"The metadata.version $metadataVersion is not ready for production use yet.\")",
          "152:       }",
          "154:     try {",
          "155:       config.validateWithMetadataVersion(metadataVersion)",
          "156:     } catch {",
          "157:       case e: IllegalArgumentException => throw new TerseFailure(s\"Invalid configuration for metadata version: ${e.getMessage}\")",
          "161:   private[tools] def generateFeatureRecords(metadataRecords: ArrayBuffer[ApiMessageAndVersion],",
          "162:                                             metadataVersion: MetadataVersion,",
          "163:                                             specifiedFeatures: Map[String, java.lang.Short],",
          "164:                                             allFeatures: List[Features],",
          "165:                                             unstableFeatureVersionsEnabled: Boolean,",
          "166:                                             releaseVersionSpecified: Boolean): Unit = {",
          "168:     val metadataVersionForDefault = if (releaseVersionSpecified) metadataVersion else MetadataVersion.LATEST_PRODUCTION",
          "170:     val allNonZeroFeaturesAndLevels: ArrayBuffer[FeatureVersion] = mutable.ArrayBuffer[FeatureVersion]()",
          "172:     allFeatures.foreach { feature =>",
          "173:       val level: java.lang.Short = specifiedFeatures.getOrElse(feature.featureName, feature.defaultValue(metadataVersionForDefault))",
          "175:       if (level != 0) {",
          "176:        allNonZeroFeaturesAndLevels.append(feature.fromFeatureLevel(level, unstableFeatureVersionsEnabled))",
          "177:       }",
          "179:     val featuresMap = Features.featureImplsToMap(allNonZeroFeaturesAndLevels.asJava)",
          "180:     featuresMap.put(MetadataVersion.FEATURE_NAME, metadataVersion.featureLevel)",
          "182:     try {",
          "183:       for (feature <- allNonZeroFeaturesAndLevels) {",
          "185:         Features.validateVersion(feature, featuresMap)",
          "186:         metadataRecords.append(new ApiMessageAndVersion(new FeatureLevelRecord().",
          "187:           setName(feature.featureName).",
          "188:           setFeatureLevel(feature.featureLevel), 0.toShort))",
          "189:       }",
          "190:     } catch {",
          "191:       case e: Throwable => throw new TerseFailure(e.getMessage)",
          "",
          "[Added Lines]",
          "103:   def runFormatCommand(",
          "104:     namespace: Namespace,",
          "105:     config: KafkaConfig,",
          "106:     printStream: PrintStream",
          "107:   ): Unit = {",
          "108:     if (config.processRoles.isEmpty) {",
          "112:     val formatter = new Formatter().",
          "113:       setPrintStream(printStream).",
          "114:       setNodeId(config.nodeId).",
          "115:       setClusterId(namespace.getString(\"cluster_id\")).",
          "116:       setUnstableFeatureVersionsEnabled(config.unstableFeatureVersionsEnabled).",
          "117:       setIgnoreFormatted(namespace.getBoolean(\"ignore_formatted\")).",
          "118:       setControllerListenerName(config.controllerListenerNames.head).",
          "119:       setMetadataLogDirectory(config.metadataLogDir)",
          "120:     Option(namespace.getString(\"release_version\")) match {",
          "121:       case Some(releaseVersion) => formatter.setReleaseVersion(MetadataVersion.fromVersionString(releaseVersion))",
          "122:       case None => Option(config.originals.get(ReplicationConfigs.INTER_BROKER_PROTOCOL_VERSION_CONFIG)).",
          "123:         foreach(v => formatter.setReleaseVersion(MetadataVersion.fromVersionString(v.toString)))",
          "125:     Option(namespace.getString(\"initial_controllers\")).",
          "126:       foreach(v => formatter.setInitialVoters(DynamicVoters.parse(v)))",
          "127:     if (namespace.getBoolean(\"standalone\")) {",
          "128:       formatter.setInitialVoters(createStandaloneDynamicVoters(config))",
          "130:     configToLogDirectories(config).foreach(formatter.addDirectory(_))",
          "131:     formatter.run()",
          "134:   def createStandaloneDynamicVoters(",
          "135:     config: KafkaConfig",
          "136:   ): DynamicVoters = {",
          "137:     if (!config.processRoles.contains(ProcessRole.ControllerRole)) {",
          "138:       throw new TerseFailure(\"You cannot use --standalone on a broker node.\")",
          "140:     if (config.controllerListeners.isEmpty) {",
          "141:       throw new RuntimeException(\"No controller listeners found.\")",
          "143:     val host = if (config.controllerListeners.head.host == null) {",
          "144:       \"localhost\"",
          "145:     } else {",
          "146:       config.controllerListeners.head.host",
          "147:     }",
          "148:     val port = config.controllerListeners.head.port",
          "149:     DynamicVoters.parse(s\"${config.nodeId}@${host}:${port}:${Uuid.randomUuid()}\")",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "223:       action(storeTrue())",
          "224:     formatParser.addArgument(\"--release-version\", \"-r\").",
          "225:       action(store()).",
          "227:     formatParser.addArgument(\"--feature\", \"-f\").",
          "232:   }",
          "234:   def configToLogDirectories(config: KafkaConfig): Seq[String] = {",
          "",
          "[Removed Lines]",
          "226:       help(s\"A KRaft release version to use for the initial metadata.version. The minimum is ${MetadataVersion.IBP_3_0_IV0}, the default is ${MetadataVersion.LATEST_PRODUCTION}\")",
          "228:       help(\"A feature upgrade we should perform, in feature=level format. For example: `metadata.version=5`.\").",
          "229:       action(append());",
          "231:     parser.parseArgsOrFail(args)",
          "",
          "[Added Lines]",
          "183:       help(s\"The release version to use for the initial feature settings. The minimum is \" +",
          "184:         s\"${MetadataVersion.IBP_3_0_IV0}; the default is ${MetadataVersion.LATEST_PRODUCTION}\")",
          "186:       help(\"The setting to use for a specific feature, in feature=level format. For example: `kraft.version=1`.\").",
          "187:       action(append())",
          "188:     val reconfigurableQuorumOptions = formatParser.addMutuallyExclusiveGroup()",
          "189:     reconfigurableQuorumOptions.addArgument(\"--standalone\", \"-s\").",
          "190:       help(\"Used to initialize a single-node quorum controller quorum.\").",
          "191:       action(storeTrue())",
          "192:     reconfigurableQuorumOptions.addArgument(\"--initial-controllers\", \"-I\").",
          "193:       help(\"A list of controller quorum voter ids, directories, and hostname:port pairs. The same values must be used to format all nodes. For example:\\n\" +",
          "194:         \"0@localhost:8082:JEXY6aqzQY-32P5TStzaFg@,1@localhost:8083:MvDxzVmcRsaTz33bUuRU6A,2@localhost:8084:07R5amHmR32VDA6jHkGbTA\\n\").",
          "195:       action(store())",
          "196:     parser.parseArgs(args)",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "238:     directories.toSeq",
          "239:   }",
          "383:     val problems = new mutable.ArrayBuffer[String]",
          "384:     val foundDirectories = new mutable.ArrayBuffer[String]",
          "385:     var prevMetadata: Option[MetaProperties] = None",
          "",
          "[Removed Lines]",
          "241:   private def configToSelfManagedMode(config: KafkaConfig): Boolean = config.processRoles.nonEmpty",
          "243:   def getMetadataVersion(",
          "244:     namespace: Namespace,",
          "245:     featureNamesAndLevelsMap: Map[String, java.lang.Short],",
          "246:     defaultVersionString: Option[String]",
          "247:   ): MetadataVersion = {",
          "248:     val defaultValue = defaultVersionString match {",
          "249:       case Some(versionString) => MetadataVersion.fromVersionString(versionString)",
          "250:       case None => MetadataVersion.LATEST_PRODUCTION",
          "251:     }",
          "253:     val releaseVersionTag = Option(namespace.getString(\"release_version\"))",
          "254:     val featureTag = featureNamesAndLevelsMap.get(MetadataVersion.FEATURE_NAME)",
          "256:     (releaseVersionTag, featureTag) match {",
          "257:       case (Some(_), Some(_)) => // We should throw an error before we hit this case, but include for completeness",
          "258:         throw new IllegalArgumentException(\"Both --release_version and --feature were set. Only one of the two flags can be set.\")",
          "259:       case (Some(version), None) =>",
          "260:         MetadataVersion.fromVersionString(version)",
          "261:       case (None, Some(level)) =>",
          "262:         MetadataVersion.fromFeatureLevel(level)",
          "263:       case (None, None) =>",
          "264:         defaultValue",
          "265:     }",
          "266:   }",
          "268:   private def getUserScramCredentialRecord(",
          "269:     mechanism: String,",
          "270:     config: String",
          "271:   ) : UserScramCredentialRecord = {",
          "278:     val argMap = config.substring(1, config.length - 1)",
          "279:                        .split(\",\")",
          "280:                        .map(_.split(\"=(?=(?:[^\\\"]*\\\"[^\\\"]*\\\")*[^\\\"]*$)\"))",
          "281:                        .map(args => args(0) -> args(1).replaceAll(\"\\\"\", \"\")).toMap",
          "283:     val scramMechanism = ScramMechanism.forMechanismName(mechanism)",
          "285:     def getName(argMap: Map[String,String]) : String = {",
          "286:       if (!argMap.contains(\"name\")) {",
          "287:         throw new TerseFailure(s\"You must supply 'name' to add-scram\")",
          "288:       }",
          "289:       argMap(\"name\")",
          "290:     }",
          "292:     def getSalt(argMap: Map[String,String], scramMechanism : ScramMechanism) : Array[Byte] = {",
          "293:       if (argMap.contains(\"salt\")) {",
          "294:         Base64.getDecoder.decode(argMap(\"salt\"))",
          "295:       } else {",
          "296:         new ScramFormatter(scramMechanism).secureRandomBytes()",
          "297:       }",
          "298:     }",
          "300:     def getIterations(argMap: Map[String,String], scramMechanism : ScramMechanism) : Int = {",
          "301:       if (argMap.contains(\"salt\")) {",
          "302:         val iterations = argMap(\"iterations\").toInt",
          "303:         if (iterations < scramMechanism.minIterations()) {",
          "304:             throw new TerseFailure(s\"The 'iterations' value must be >= ${scramMechanism.minIterations()} for add-scram\")",
          "305:         }",
          "306:         if (iterations > scramMechanism.maxIterations()) {",
          "307:             throw new TerseFailure(s\"The 'iterations' value must be <= ${scramMechanism.maxIterations()} for add-scram\")",
          "308:         }",
          "309:         iterations",
          "310:       } else {",
          "311:         4096",
          "312:       }",
          "313:     }",
          "315:     def getSaltedPassword(",
          "316:       argMap: Map[String,String],",
          "317:       scramMechanism : ScramMechanism,",
          "318:       salt : Array[Byte],",
          "319:       iterations: Int",
          "320:     ) : Array[Byte] = {",
          "321:       if (argMap.contains(\"password\")) {",
          "322:         if (argMap.contains(\"saltedpassword\")) {",
          "323:             throw new TerseFailure(s\"You must only supply one of 'password' or 'saltedpassword' to add-scram\")",
          "324:         }",
          "325:         new ScramFormatter(scramMechanism).saltedPassword(argMap(\"password\"), salt, iterations)",
          "326:       } else {",
          "327:         if (!argMap.contains(\"saltedpassword\")) {",
          "328:             throw new TerseFailure(s\"You must supply one of 'password' or 'saltedpassword' to add-scram\")",
          "329:         }",
          "330:         if (!argMap.contains(\"salt\")) {",
          "331:             throw new TerseFailure(s\"You must supply 'salt' with 'saltedpassword' to add-scram\")",
          "332:         }",
          "333:         Base64.getDecoder.decode(argMap(\"saltedpassword\"))",
          "334:       }",
          "335:     }",
          "337:     val name = getName(argMap)",
          "338:     val salt = getSalt(argMap, scramMechanism)",
          "339:     val iterations = getIterations(argMap, scramMechanism)",
          "340:     val saltedPassword = getSaltedPassword(argMap, scramMechanism, salt, iterations)",
          "342:     val myrecord = try {",
          "343:       val formatter = new ScramFormatter(scramMechanism)",
          "345:       new UserScramCredentialRecord()",
          "346:            .setName(name)",
          "347:            .setMechanism(scramMechanism.`type`)",
          "348:            .setSalt(salt)",
          "349:            .setStoredKey(formatter.storedKey(formatter.clientKey(saltedPassword)))",
          "350:            .setServerKey(formatter.serverKey(saltedPassword))",
          "351:            .setIterations(iterations)",
          "352:     } catch {",
          "353:       case e: Throwable =>",
          "354:         throw new TerseFailure(s\"Error attempting to create UserScramCredentialRecord: ${e.getMessage}\")",
          "355:     }",
          "356:     myrecord",
          "357:   }",
          "359:   def getUserScramCredentialRecords(namespace: Namespace): Option[ArrayBuffer[UserScramCredentialRecord]] = {",
          "360:     if (namespace.getList(\"add_scram\") != null) {",
          "361:       val listofAddConfig : List[String] = namespace.getList(\"add_scram\").asScala.toList",
          "362:       val userScramCredentialRecords : ArrayBuffer[UserScramCredentialRecord] = ArrayBuffer()",
          "363:       for (singleAddConfig <- listofAddConfig) {",
          "364:         val singleAddConfigList = singleAddConfig.split(\"\\\\s+\")",
          "367:         val nameValueRecord = singleAddConfigList(0).split(\"=\", 2)",
          "368:         nameValueRecord(0) match {",
          "369:           case \"SCRAM-SHA-256\" =>",
          "370:             userScramCredentialRecords.append(getUserScramCredentialRecord(nameValueRecord(0), nameValueRecord(1)))",
          "371:           case \"SCRAM-SHA-512\" =>",
          "372:             userScramCredentialRecords.append(getUserScramCredentialRecord(nameValueRecord(0), nameValueRecord(1)))",
          "373:           case _ => throw new TerseFailure(s\"The add-scram mechanism ${nameValueRecord(0)} is not supported.\")",
          "374:         }",
          "375:       }",
          "376:       Some(userScramCredentialRecords)",
          "377:     } else {",
          "378:       None",
          "379:     }",
          "380:   }",
          "382:   def infoCommand(stream: PrintStream, selfManagedMode: Boolean, directories: Seq[String]): Int = {",
          "",
          "[Added Lines]",
          "206:   def infoCommand(stream: PrintStream, kraftMode: Boolean, directories: Seq[String]): Int = {",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "419:     })",
          "421:     prevMetadata.foreach { prev =>",
          "423:         if (prev.version.equals(MetaPropertiesVersion.V0)) {",
          "424:           problems += \"The kafka configuration file appears to be for a cluster in KRaft mode, but \" +",
          "425:             \"the directories are formatted for legacy mode.\"",
          "",
          "[Removed Lines]",
          "422:       if (selfManagedMode) {",
          "",
          "[Added Lines]",
          "246:       if (kraftMode) {",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "465:       }",
          "466:     }",
          "467:   }",
          "560: }",
          "",
          "[Removed Lines]",
          "469:   def buildBootstrapMetadata(metadataVersion: MetadataVersion,",
          "470:                              metadataOptionalArguments: Option[ArrayBuffer[ApiMessageAndVersion]],",
          "471:                              source: String): BootstrapMetadata = {",
          "473:     val metadataRecords = new util.ArrayList[ApiMessageAndVersion]",
          "474:     metadataRecords.add(new ApiMessageAndVersion(new FeatureLevelRecord().",
          "475:                         setName(MetadataVersion.FEATURE_NAME).",
          "476:                         setFeatureLevel(metadataVersion.featureLevel()), 0.toShort))",
          "478:     metadataOptionalArguments.foreach { metadataArguments =>",
          "479:       for (record <- metadataArguments) metadataRecords.add(record)",
          "480:     }",
          "482:     BootstrapMetadata.fromRecords(metadataRecords, source)",
          "483:   }",
          "485:   def formatCommand(",
          "486:     stream: PrintStream,",
          "487:     directories: Seq[String],",
          "488:     metaProperties: MetaProperties,",
          "489:     bootstrapMetadata: BootstrapMetadata,",
          "490:     metadataVersion: MetadataVersion,",
          "491:     ignoreFormatted: Boolean",
          "492:   ): Int = {",
          "493:     if (directories.isEmpty) {",
          "494:       throw new TerseFailure(\"No log directories found in the configuration.\")",
          "495:     }",
          "496:     val loader = new MetaPropertiesEnsemble.Loader()",
          "497:       .addLogDirs(directories.asJava)",
          "498:     val metaPropertiesEnsemble = loader.load()",
          "499:     metaPropertiesEnsemble.verify(metaProperties.clusterId(), metaProperties.nodeId(),",
          "500:       util.EnumSet.noneOf(classOf[VerificationFlag]))",
          "502:     val copier = new MetaPropertiesEnsemble.Copier(metaPropertiesEnsemble)",
          "503:     if (!(ignoreFormatted || copier.logDirProps().isEmpty)) {",
          "504:       val firstLogDir = copier.logDirProps().keySet().iterator().next()",
          "505:       throw new TerseFailure(s\"Log directory $firstLogDir is already formatted. \" +",
          "506:         \"Use --ignore-formatted to ignore this directory and format the others.\")",
          "507:     }",
          "508:     if (!copier.errorLogDirs().isEmpty) {",
          "509:       copier.errorLogDirs().forEach(errorLogDir => {",
          "510:         stream.println(s\"I/O error trying to read log directory $errorLogDir. Ignoring...\")",
          "511:       })",
          "512:       if (metaPropertiesEnsemble.emptyLogDirs().isEmpty && copier.logDirProps().isEmpty) {",
          "513:         throw new TerseFailure(\"No available log directories to format.\")",
          "514:       }",
          "515:     }",
          "516:     if (metaPropertiesEnsemble.emptyLogDirs().isEmpty) {",
          "517:       stream.println(\"All of the log directories are already formatted.\")",
          "518:     } else {",
          "519:       metaPropertiesEnsemble.emptyLogDirs().forEach(logDir => {",
          "520:         copier.setLogDirProps(logDir, new MetaProperties.Builder(metaProperties).",
          "521:           setDirectoryId(copier.generateValidDirectoryId()).",
          "522:           build())",
          "523:         copier.setPreWriteHandler((logDir, _, _) => {",
          "524:           stream.println(s\"Formatting $logDir with metadata.version $metadataVersion.\")",
          "525:           Files.createDirectories(Paths.get(logDir))",
          "526:           val bootstrapDirectory = new BootstrapDirectory(logDir, Optional.empty())",
          "527:           bootstrapDirectory.writeBinaryFile(bootstrapMetadata)",
          "528:         })",
          "529:         copier.setWriteErrorHandler((logDir, e) => {",
          "530:           throw new TerseFailure(s\"Error while writing meta.properties file $logDir: ${e.getMessage}\")",
          "531:         })",
          "532:       })",
          "533:       copier.writeLogDirChanges()",
          "534:     }",
          "535:     0",
          "536:   }",
          "538:   private def parseNameAndLevel(input: String): (String, java.lang.Short) = {",
          "539:     val equalsIndex = input.indexOf(\"=\")",
          "540:     if (equalsIndex < 0)",
          "541:       throw new RuntimeException(\"Can't parse feature=level string \" + input + \": equals sign not found.\")",
          "542:     val name = input.substring(0, equalsIndex).trim",
          "543:     val levelString = input.substring(equalsIndex + 1).trim",
          "544:     try {",
          "545:       levelString.toShort",
          "546:     } catch {",
          "547:       case _: Throwable =>",
          "548:         throw new RuntimeException(\"Can't parse feature=level string \" + input + \": \" + \"unable to parse \" + levelString + \" as a short.\")",
          "549:     }",
          "550:     (name, levelString.toShort)",
          "551:   }",
          "553:   def featureNamesAndLevels(features: List[String]): Map[String, java.lang.Short] = {",
          "554:     features.map { (feature: String) =>",
          "556:       val nameAndLevel = parseNameAndLevel(feature)",
          "557:       (nameAndLevel._1, nameAndLevel._2)",
          "558:     }.toMap",
          "559:   }",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "core/src/test/scala/integration/kafka/api/DelegationTokenEndToEndAuthorizationTest.scala||core/src/test/scala/integration/kafka/api/DelegationTokenEndToEndAuthorizationTest.scala": [
          "File: core/src/test/scala/integration/kafka/api/DelegationTokenEndToEndAuthorizationTest.scala -> core/src/test/scala/integration/kafka/api/DelegationTokenEndToEndAuthorizationTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: import java.util.Properties",
          "20: import kafka.utils._",
          "22: import kafka.zk.ConfigEntityChangeNotificationZNode",
          "23: import org.apache.kafka.clients.admin.{Admin, AdminClientConfig, CreateDelegationTokenOptions, ScramCredentialInfo, UserScramCredentialAlteration, UserScramCredentialUpsertion, ScramMechanism => PublicScramMechanism}",
          "24: import org.apache.kafka.common.config.SaslConfigs",
          "25: import org.apache.kafka.common.security.auth.{KafkaPrincipal, SecurityProtocol}",
          "26: import org.apache.kafka.common.security.scram.internals.ScramMechanism",
          "27: import org.apache.kafka.common.security.token.delegation.DelegationToken",
          "28: import org.junit.jupiter.api.Assertions._",
          "29: import org.junit.jupiter.params.ParameterizedTest",
          "30: import org.junit.jupiter.params.provider.ValueSource",
          "31: import org.junit.jupiter.api.{BeforeEach, TestInfo}",
          "33: import scala.jdk.CollectionConverters._",
          "36: import org.apache.kafka.server.config.DelegationTokenManagerConfigs",
          "38: class DelegationTokenEndToEndAuthorizationTest extends EndToEndAuthorizationTest {",
          "",
          "[Removed Lines]",
          "21: import kafka.tools.StorageTool",
          "34: import scala.collection.mutable.ArrayBuffer",
          "35: import org.apache.kafka.server.common.ApiMessageAndVersion",
          "",
          "[Added Lines]",
          "27: import org.apache.kafka.metadata.storage.Formatter",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "69:   }",
          "83:   }",
          "85:   override def createPrivilegedAdminClient(): Admin = createScramAdminClient(kafkaClientSaslMechanism, kafkaPrincipal.getName, kafkaPassword)",
          "",
          "[Removed Lines]",
          "72:   override def optionalMetadataRecords: Option[ArrayBuffer[ApiMessageAndVersion]] = {",
          "73:     val args = Seq(\"format\", \"-c\", \"config.props\", \"-t\", \"XcZZOzUqS4yHOjhMQB6JLQ\", \"-S\",",
          "74:                    s\"SCRAM-SHA-256=[name=${JaasTestUtils.KafkaScramAdmin},password=${JaasTestUtils.KafkaScramAdminPassword}]\")",
          "75:     val namespace = StorageTool.parseArguments(args.toArray)",
          "76:     val metadataRecords : ArrayBuffer[ApiMessageAndVersion] = ArrayBuffer()",
          "77:     StorageTool.getUserScramCredentialRecords(namespace).foreach {",
          "78:       userScramCredentialRecords => for (record <- userScramCredentialRecords) {",
          "79:         metadataRecords.append(new ApiMessageAndVersion(record, 0.toShort))",
          "80:       }",
          "81:     }",
          "82:     Some(metadataRecords)",
          "",
          "[Added Lines]",
          "71:   override def addFormatterSettings(formatter: Formatter): Unit = {",
          "72:     formatter.setClusterId(\"XcZZOzUqS4yHOjhMQB6JLQ\")",
          "73:     formatter.setScramArguments(",
          "74:       List(s\"SCRAM-SHA-256=[name=${JaasTestUtils.KafkaScramAdmin},password=${JaasTestUtils.KafkaScramAdminPassword}]\").asJava)",
          "",
          "---------------"
        ],
        "core/src/test/scala/integration/kafka/api/SaslScramSslEndToEndAuthorizationTest.scala||core/src/test/scala/integration/kafka/api/SaslScramSslEndToEndAuthorizationTest.scala": [
          "File: core/src/test/scala/integration/kafka/api/SaslScramSslEndToEndAuthorizationTest.scala -> core/src/test/scala/integration/kafka/api/SaslScramSslEndToEndAuthorizationTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: package kafka.api",
          "19: import java.util.Properties",
          "21: import kafka.utils._",
          "23: import kafka.zk.ConfigEntityChangeNotificationZNode",
          "24: import org.apache.kafka.common.security.auth.KafkaPrincipal",
          "25: import org.apache.kafka.common.security.scram.internals.ScramMechanism",
          "26: import org.apache.kafka.test.TestSslUtils",
          "28: import scala.jdk.CollectionConverters._",
          "",
          "[Removed Lines]",
          "22: import kafka.tools.StorageTool",
          "",
          "[Added Lines]",
          "24: import org.apache.kafka.metadata.storage.Formatter",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "31: import org.junit.jupiter.params.ParameterizedTest",
          "32: import org.junit.jupiter.params.provider.ValueSource",
          "37: class SaslScramSslEndToEndAuthorizationTest extends SaslEndToEndAuthorizationTest {",
          "38:   override protected def kafkaClientSaslMechanism = \"SCRAM-SHA-256\"",
          "39:   override protected def kafkaServerSaslMechanisms = ScramMechanism.mechanismNames.asScala.toList",
          "",
          "[Removed Lines]",
          "34: import scala.collection.mutable.ArrayBuffer",
          "35: import org.apache.kafka.server.common.ApiMessageAndVersion",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "55:   }",
          "69:   }",
          "71:   override def configureListeners(props: collection.Seq[Properties]): Unit = {",
          "",
          "[Removed Lines]",
          "58:   override def optionalMetadataRecords: Option[ArrayBuffer[ApiMessageAndVersion]] = {",
          "59:     val args = Seq(\"format\", \"-c\", \"config.props\", \"-t\", \"XcZZOzUqS4yHOjhMQB6JLQ\", \"-S\",",
          "60:                    s\"SCRAM-SHA-256=[name=${JaasTestUtils.KafkaScramAdmin},password=${JaasTestUtils.KafkaScramAdminPassword}]\")",
          "61:     val namespace = StorageTool.parseArguments(args.toArray)",
          "62:     val metadataRecords : ArrayBuffer[ApiMessageAndVersion] = ArrayBuffer()",
          "63:     StorageTool.getUserScramCredentialRecords(namespace).foreach {",
          "64:       userScramCredentialRecords => for (record <- userScramCredentialRecords) {",
          "65:         metadataRecords.append(new ApiMessageAndVersion(record, 0.toShort))",
          "66:       }",
          "67:     }",
          "68:     Some(metadataRecords)",
          "",
          "[Added Lines]",
          "54:   override def addFormatterSettings(formatter: Formatter): Unit = {",
          "55:     formatter.setClusterId(\"XcZZOzUqS4yHOjhMQB6JLQ\")",
          "56:     formatter.setScramArguments(List(",
          "57:       s\"SCRAM-SHA-256=[name=${JaasTestUtils.KafkaScramAdmin},password=${JaasTestUtils.KafkaScramAdminPassword}]\").asJava)",
          "",
          "---------------"
        ],
        "core/src/test/scala/integration/kafka/server/QuorumTestHarness.scala||core/src/test/scala/integration/kafka/server/QuorumTestHarness.scala": [
          "File: core/src/test/scala/integration/kafka/server/QuorumTestHarness.scala -> core/src/test/scala/integration/kafka/server/QuorumTestHarness.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "26: import kafka.utils.{CoreUtils, Logging, TestInfoUtils, TestUtils}",
          "27: import kafka.zk.{AdminZkClient, EmbeddedZookeeper, KafkaZkClient}",
          "28: import org.apache.kafka.clients.consumer.GroupProtocol",
          "30: import org.apache.kafka.common.metrics.Metrics",
          "31: import org.apache.kafka.common.security.JaasUtils",
          "32: import org.apache.kafka.common.security.auth.SecurityProtocol",
          "33: import org.apache.kafka.common.utils.{Exit, Time}",
          "34: import org.apache.kafka.common.{DirectoryId, Uuid}",
          "36: import org.apache.kafka.metadata.properties.MetaPropertiesEnsemble.VerificationFlag.{REQUIRE_AT_LEAST_ONE_VALID, REQUIRE_METADATA_LOG_DIR}",
          "37: import org.apache.kafka.metadata.properties.{MetaProperties, MetaPropertiesEnsemble, MetaPropertiesVersion}",
          "38: import org.apache.kafka.network.SocketServerConfigs",
          "39: import org.apache.kafka.raft.QuorumConfig",
          "41: import org.apache.kafka.server.config.{KRaftConfigs, ServerConfigs, ServerLogConfigs}",
          "42: import org.apache.kafka.server.fault.{FaultHandler, MockFaultHandler}",
          "43: import org.apache.zookeeper.client.ZKClientConfig",
          "",
          "[Removed Lines]",
          "29: import org.apache.kafka.common.metadata.FeatureLevelRecord",
          "35: import org.apache.kafka.metadata.bootstrap.BootstrapMetadata",
          "40: import org.apache.kafka.server.common.{ApiMessageAndVersion, Features, MetadataVersion}",
          "",
          "[Added Lines]",
          "36: import org.apache.kafka.metadata.storage.Formatter",
          "39: import org.apache.kafka.server.common.MetadataVersion",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "46: import org.junit.jupiter.api.{AfterAll, AfterEach, BeforeAll, BeforeEach, Tag, TestInfo}",
          "48: import java.nio.file.{Files, Paths}",
          "52: import scala.compat.java8.OptionConverters._",
          "53: import scala.jdk.CollectionConverters._",
          "",
          "[Removed Lines]",
          "49: import scala.collection.mutable.ArrayBuffer",
          "50: import scala.collection.mutable.ListBuffer",
          "51: import scala.collection.{Seq, immutable}",
          "",
          "[Added Lines]",
          "48: import scala.collection.Seq",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "104:   ): KafkaBroker = {",
          "105:     val metaPropertiesEnsemble = {",
          "106:       val loader = new MetaPropertiesEnsemble.Loader()",
          "108:       loader.addMetadataLogDir(config.metadataLogDir)",
          "109:       val ensemble = loader.load()",
          "110:       val copier = new MetaPropertiesEnsemble.Copier(ensemble)",
          "",
          "[Removed Lines]",
          "107:         .addLogDirs(config.logDirs.asJava)",
          "",
          "[Added Lines]",
          "104:       loader.addLogDirs(config.logDirs.asJava)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "186:   private var testInfo: TestInfo = _",
          "187:   protected var implementation: QuorumImplementation = _",
          "191:   def isKRaftTest(): Boolean = {",
          "192:     TestInfoUtils.isKRaft(testInfo)",
          "193:   }",
          "",
          "[Removed Lines]",
          "189:   val bootstrapRecords: ListBuffer[ApiMessageAndVersion] = ListBuffer()",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "313:     CoreUtils.swallow(kRaftQuorumImplementation.controllerServer.shutdown(), kRaftQuorumImplementation.log)",
          "314:   }",
          "318:   private def newKRaftQuorum(testInfo: TestInfo): KRaftQuorumImplementation = {",
          "319:     newKRaftQuorum(new Properties())",
          "",
          "[Removed Lines]",
          "316:   def optionalMetadataRecords: Option[ArrayBuffer[ApiMessageAndVersion]] = None",
          "",
          "[Added Lines]",
          "311:   def addFormatterSettings(formatter: Formatter): Unit = {}",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "334:     }",
          "335:     val nodeId = Integer.parseInt(props.getProperty(KRaftConfigs.NODE_ID_CONFIG))",
          "336:     val metadataDir = TestUtils.tempDir()",
          "362:     props.setProperty(KRaftConfigs.METADATA_LOG_DIR_CONFIG, metadataDir.getAbsolutePath)",
          "363:     val proto = controllerListenerSecurityProtocol.toString",
          "364:     props.setProperty(SocketServerConfigs.LISTENER_SECURITY_PROTOCOL_MAP_CONFIG, s\"CONTROLLER:$proto\")",
          "",
          "[Removed Lines]",
          "337:     val metaProperties = new MetaProperties.Builder().",
          "338:       setVersion(MetaPropertiesVersion.V1).",
          "339:       setClusterId(Uuid.randomUuid().toString).",
          "340:       setNodeId(nodeId).",
          "341:       build()",
          "342:     TestUtils.formatDirectories(immutable.Seq(metadataDir.getAbsolutePath), metaProperties, metadataVersion, optionalMetadataRecords)",
          "344:     val metadataRecords = new util.ArrayList[ApiMessageAndVersion]",
          "345:     metadataRecords.add(new ApiMessageAndVersion(new FeatureLevelRecord().",
          "346:                         setName(MetadataVersion.FEATURE_NAME).",
          "347:                         setFeatureLevel(metadataVersion.featureLevel()), 0.toShort))",
          "349:     metadataRecords.add(new ApiMessageAndVersion(",
          "350:       new FeatureLevelRecord()",
          "351:         .setName(Features.TRANSACTION_VERSION.featureName)",
          "352:         .setFeatureLevel(Features.TRANSACTION_VERSION.latestTesting),",
          "353:       0.toShort",
          "354:     ))",
          "356:     optionalMetadataRecords.foreach { metadataArguments =>",
          "357:       for (record <- metadataArguments) metadataRecords.add(record)",
          "358:     }",
          "360:     val bootstrapMetadata = BootstrapMetadata.fromRecords(metadataRecords, \"test harness\")",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "369:     props.setProperty(ServerLogConfigs.LOG_DELETE_DELAY_MS_CONFIG, \"1000\")",
          "370:     val config = new KafkaConfig(props)",
          "371:     val controllerQuorumVotersFuture = new CompletableFuture[util.Map[Integer, InetSocketAddress]]",
          "372:     val metaPropertiesEnsemble = new MetaPropertiesEnsemble.Loader().",
          "373:       addMetadataLogDir(metadataDir.getAbsolutePath).",
          "374:       load()",
          "376:       OptionalInt.of(nodeId),",
          "377:       util.EnumSet.of(REQUIRE_AT_LEAST_ONE_VALID, REQUIRE_METADATA_LOG_DIR))",
          "378:     val sharedServer = new SharedServer(",
          "",
          "[Removed Lines]",
          "375:     metaPropertiesEnsemble.verify(Optional.of(metaProperties.clusterId().get()),",
          "",
          "[Added Lines]",
          "342:     val formatter = new Formatter().",
          "343:       setClusterId(Uuid.randomUuid().toString).",
          "344:       setNodeId(nodeId)",
          "345:     formatter.addDirectory(metadataDir.getAbsolutePath)",
          "346:     formatter.setReleaseVersion(metadataVersion)",
          "347:     formatter.setUnstableFeatureVersionsEnabled(true)",
          "348:     formatter.setControllerListenerName(config.controllerListenerNames.head)",
          "349:     formatter.setMetadataLogDirectory(config.metadataLogDir)",
          "350:     addFormatterSettings(formatter)",
          "351:     formatter.run()",
          "352:     val bootstrapMetadata = formatter.bootstrapMetadata()",
          "358:     metaPropertiesEnsemble.verify(Optional.of(formatter.clusterId()),",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "413:       faultHandlerFactory,",
          "414:       metadataDir,",
          "415:       controllerQuorumVotersFuture,",
          "417:       this,",
          "418:       faultHandler",
          "419:     )",
          "",
          "[Removed Lines]",
          "416:       metaProperties.clusterId.get(),",
          "",
          "[Added Lines]",
          "399:       formatter.clusterId(),",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/server/ReplicaManagerConcurrencyTest.scala||core/src/test/scala/unit/kafka/server/ReplicaManagerConcurrencyTest.scala": [
          "File: core/src/test/scala/unit/kafka/server/ReplicaManagerConcurrencyTest.scala -> core/src/test/scala/unit/kafka/server/ReplicaManagerConcurrencyTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "39: import org.apache.kafka.image.{MetadataDelta, MetadataImage}",
          "40: import org.apache.kafka.metadata.LeaderRecoveryState",
          "41: import org.apache.kafka.metadata.PartitionRegistration",
          "43: import org.apache.kafka.raft.QuorumConfig",
          "44: import org.apache.kafka.server.config.{KRaftConfigs, ReplicationConfigs, ServerLogConfigs}",
          "46: import org.apache.kafka.server.util.{MockTime, ShutdownableThread}",
          "47: import org.apache.kafka.storage.internals.log.{AppendOrigin, FetchIsolation, FetchParams, FetchPartitionData, LogConfig, LogDirFailureChannel}",
          "48: import org.junit.jupiter.api.Assertions._",
          "49: import org.junit.jupiter.api.{AfterEach, Test}",
          "50: import org.mockito.Mockito",
          "53: import scala.jdk.CollectionConverters._",
          "54: import scala.util.Random",
          "",
          "[Removed Lines]",
          "42: import org.apache.kafka.metadata.properties.{MetaProperties, MetaPropertiesVersion}",
          "45: import org.apache.kafka.server.common.{KRaftVersion, MetadataVersion}",
          "52: import scala.collection.{immutable, mutable}",
          "",
          "[Added Lines]",
          "42: import org.apache.kafka.metadata.storage.Formatter",
          "44: import org.apache.kafka.server.common.KRaftVersion",
          "52: import scala.collection.mutable",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "159:     metadataCache: MetadataCache,",
          "160:   ): ReplicaManager = {",
          "161:     val logDir = TestUtils.tempDir()",
          "164:       setClusterId(Uuid.randomUuid().toString).",
          "169:     val props = new Properties",
          "170:     props.put(QuorumConfig.QUORUM_VOTERS_CONFIG, \"100@localhost:12345\")",
          "",
          "[Removed Lines]",
          "162:     val metaProperties = new MetaProperties.Builder().",
          "163:       setVersion(MetaPropertiesVersion.V1).",
          "165:       setNodeId(1).",
          "166:       build()",
          "167:     TestUtils.formatDirectories(immutable.Seq(logDir.getAbsolutePath), metaProperties, MetadataVersion.latestTesting(), None)",
          "",
          "[Added Lines]",
          "162:     val formatter = new Formatter().",
          "164:       setNodeId(1)",
          "165:     formatter.addDirectory(logDir.getAbsolutePath)",
          "166:     formatter.setControllerListenerName(\"CONTROLLER\")",
          "167:     formatter.setMetadataLogDirectory(logDir.getAbsolutePath)",
          "168:     formatter.run()",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala": [
          "File: core/src/test/scala/unit/kafka/tools/StorageToolTest.scala -> core/src/test/scala/unit/kafka/tools/StorageToolTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: package kafka.tools",
          "21: import java.nio.charset.StandardCharsets",
          "23: import java.util",
          "26: import kafka.server.KafkaConfig",
          "28: import kafka.utils.TestUtils",
          "31: import org.apache.kafka.common.utils.Utils",
          "35: import org.apache.kafka.raft.QuorumConfig",
          "37: import org.junit.jupiter.api.Assertions.{assertEquals, assertFalse, assertThrows, assertTrue}",
          "38: import org.junit.jupiter.api.{Test, Timeout}",
          "39: import org.junit.jupiter.params.ParameterizedTest",
          "47: @Timeout(value = 40)",
          "48: class StorageToolTest {",
          "",
          "[Removed Lines]",
          "20: import java.io.{ByteArrayOutputStream, PrintStream}",
          "22: import java.nio.file.{Files, Paths}",
          "24: import java.util.{Collections, Properties}",
          "25: import org.apache.kafka.common.{DirectoryId, KafkaException}",
          "27: import kafka.utils.Exit",
          "29: import net.sourceforge.argparse4j.inf.Namespace",
          "30: import org.apache.commons.io.output.NullOutputStream",
          "32: import org.apache.kafka.server.common.{ApiMessageAndVersion, Features, MetadataVersion, TestFeatureVersion}",
          "33: import org.apache.kafka.common.metadata.{FeatureLevelRecord, UserScramCredentialRecord}",
          "34: import org.apache.kafka.metadata.properties.{MetaProperties, MetaPropertiesEnsemble, MetaPropertiesVersion, PropertiesUtils}",
          "36: import org.apache.kafka.server.config.{KRaftConfigs, ReplicationConfigs, ServerConfigs, ServerLogConfigs}",
          "40: import org.junit.jupiter.params.provider.{EnumSource, ValueSource}",
          "41: import org.mockito.Mockito",
          "43: import scala.collection.mutable",
          "44: import scala.collection.mutable.ArrayBuffer",
          "45: import scala.jdk.CollectionConverters._",
          "",
          "[Added Lines]",
          "20: import java.io.{ByteArrayOutputStream, File, PrintStream}",
          "22: import java.nio.file.Files",
          "24: import java.util.Properties",
          "28: import org.apache.kafka.server.common.Features",
          "29: import org.apache.kafka.metadata.properties.{MetaPropertiesEnsemble, PropertiesUtils}",
          "30: import org.apache.kafka.metadata.storage.FormatterException",
          "32: import org.apache.kafka.server.config.{KRaftConfigs, ServerConfigs, ServerLogConfigs}",
          "36: import org.junit.jupiter.params.provider.ValueSource",
          "38: import scala.collection.mutable.ListBuffer",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "146:   }",
          "148:   @Test",
          "150:     val stream = new ByteArrayOutputStream()",
          "151:     val tempDir = TestUtils.tempDir()",
          "152:     try {",
          "",
          "[Removed Lines]",
          "149:   def testInfoWithMismatchedSelfManagedKafkaConfig(): Unit = {",
          "",
          "[Added Lines]",
          "142:   def testInfoWithMismatchedKRaftConfig(): Unit = {",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "170:     } finally Utils.delete(tempDir)",
          "171:   }",
          "175:     val tempDir = TestUtils.tempDir()",
          "176:     try {",
          "193:       }",
          "210:   }",
          "212:   @Test",
          "213:   def testFormatSucceedsIfAllDirectoriesAreAvailable(): Unit = {",
          "215:     val stream = new ByteArrayOutputStream()",
          "223:   }",
          "225:   @Test",
          "226:   def testFormatSucceedsIfAtLeastOneDirectoryIsAvailable(): Unit = {",
          "227:     val availableDir1 = TestUtils.tempDir()",
          "228:     val unavailableDir1 = TestUtils.tempFile()",
          "229:     val stream = new ByteArrayOutputStream()",
          "245:   }",
          "247:   @Test",
          "250:     val stream = new ByteArrayOutputStream()",
          "253:     val stream2 = new ByteArrayOutputStream()",
          "312:   }",
          "314:   @Test",
          "397:   }",
          "400:   @Test",
          "411:   }",
          "413:   @Test",
          "426:   }",
          "428:   @Test",
          "439:   }",
          "441:   @Test",
          "451:   }",
          "453:   @Test",
          "528:   }",
          "530:   @Test",
          "555:   }",
          "557:   @Test",
          "586:   }",
          "588:   @Test",
          "609:   }",
          "611:   @ParameterizedTest",
          "612:   @ValueSource(booleans = Array(false, true))",
          "649:     }",
          "650:   }",
          "652:   @Test",
          "662:   }",
          "674:     }",
          "682:   }",
          "683: }",
          "",
          "[Removed Lines]",
          "173:   @Test",
          "174:   def testFormatEmptyDirectory(): Unit = {",
          "177:       val metaProperties = new MetaProperties.Builder().",
          "178:         setVersion(MetaPropertiesVersion.V1).",
          "179:         setClusterId(\"XcZZOzUqS4yHOjhMQB6JLQ\").",
          "180:         setNodeId(2).",
          "181:         build()",
          "182:       val stream = new ByteArrayOutputStream()",
          "183:       val bootstrapMetadata = StorageTool.buildBootstrapMetadata(MetadataVersion.latestTesting(), None, \"test format command\")",
          "184:       assertEquals(0, StorageTool.",
          "185:         formatCommand(new PrintStream(stream), Seq(tempDir.toString), metaProperties, bootstrapMetadata, MetadataVersion.latestTesting(), ignoreFormatted = false))",
          "186:       assertTrue(stream.toString().startsWith(\"Formatting %s\".format(tempDir)))",
          "188:       try assertEquals(1, StorageTool.",
          "189:         formatCommand(new PrintStream(new ByteArrayOutputStream()), Seq(tempDir.toString), metaProperties, bootstrapMetadata, MetadataVersion.latestTesting(), ignoreFormatted = false)) catch {",
          "190:         case e: TerseFailure => assertEquals(s\"Log directory ${tempDir} is already \" +",
          "191:           \"formatted. Use --ignore-formatted to ignore this directory and format the \" +",
          "192:           \"others.\", e.getMessage)",
          "195:       val stream2 = new ByteArrayOutputStream()",
          "196:       assertEquals(0, StorageTool.",
          "197:         formatCommand(new PrintStream(stream2), Seq(tempDir.toString), metaProperties, bootstrapMetadata, MetadataVersion.latestTesting(), ignoreFormatted = true))",
          "198:       assertEquals(\"All of the log directories are already formatted.%n\".format(), stream2.toString())",
          "199:     } finally Utils.delete(tempDir)",
          "200:   }",
          "202:   private def runFormatCommand(stream: ByteArrayOutputStream, directories: Seq[String], ignoreFormatted: Boolean = false): Int = {",
          "203:     val metaProperties = new MetaProperties.Builder().",
          "204:       setVersion(MetaPropertiesVersion.V1).",
          "205:       setClusterId(\"XcZZOzUqS4yHOjhMQB6JLQ\").",
          "206:       setNodeId(2).",
          "207:       build()",
          "208:     val bootstrapMetadata = StorageTool.buildBootstrapMetadata(MetadataVersion.latestTesting(), None, \"test format command\")",
          "209:     StorageTool.formatCommand(new PrintStream(stream), directories, metaProperties, bootstrapMetadata, MetadataVersion.latestTesting(), ignoreFormatted)",
          "214:     val availableDirs = Seq(TestUtils.tempDir(), TestUtils.tempDir(), TestUtils.tempDir()).map(dir => dir.toString)",
          "216:     assertEquals(0, runFormatCommand(stream, availableDirs))",
          "217:     val actual = stream.toString().split(\"\\\\r?\\\\n\")",
          "218:     val expect = availableDirs.map(\"Formatting %s\".format(_))",
          "219:     assertEquals(availableDirs.size, actual.size)",
          "220:     expect.foreach(dir => {",
          "221:       assertEquals(1, actual.count(_.startsWith(dir)))",
          "222:     })",
          "230:     assertEquals(0, runFormatCommand(stream, Seq(availableDir1.toString, unavailableDir1.toString)))",
          "231:     assertTrue(stream.toString().contains(\"I/O error trying to read log directory %s. Ignoring...\".format(unavailableDir1)))",
          "232:     assertTrue(stream.toString().contains(\"Formatting %s\".format(availableDir1)))",
          "233:     assertFalse(stream.toString().contains(\"Formatting %s\".format(unavailableDir1)))",
          "234:   }",
          "236:   @Test",
          "237:   def testFormatFailsIfAllDirectoriesAreUnavailable(): Unit = {",
          "238:     val unavailableDir1 = TestUtils.tempFile()",
          "239:     val unavailableDir2 = TestUtils.tempFile()",
          "240:     val stream = new ByteArrayOutputStream()",
          "241:     assertEquals(\"No available log directories to format.\", assertThrows(classOf[TerseFailure],",
          "242:       () => runFormatCommand(stream, Seq(unavailableDir1.toString, unavailableDir2.toString))).getMessage)",
          "243:     assertTrue(stream.toString().contains(\"I/O error trying to read log directory %s. Ignoring...\".format(unavailableDir1)))",
          "244:     assertTrue(stream.toString().contains(\"I/O error trying to read log directory %s. Ignoring...\".format(unavailableDir2)))",
          "248:   def testFormatSucceedsIfAtLeastOneFormattedDirectoryIsAvailable(): Unit = {",
          "249:     val availableDir1 = TestUtils.tempDir()",
          "251:     assertEquals(0, runFormatCommand(stream, Seq(availableDir1.toString)))",
          "254:     val unavailableDir1 = TestUtils.tempFile()",
          "255:     assertEquals(0, runFormatCommand(stream2, Seq(availableDir1.toString, unavailableDir1.toString), ignoreFormatted = true))",
          "256:   }",
          "258:   @Test",
          "259:   def testDefaultMetadataVersion(): Unit = {",
          "260:     val namespace = StorageTool.parseArguments(Array(\"format\", \"-c\", \"config.props\", \"-t\", \"XcZZOzUqS4yHOjhMQB6JLQ\"))",
          "261:     val mv = StorageTool.getMetadataVersion(namespace, Map.empty, defaultVersionString = None)",
          "262:     assertEquals(MetadataVersion.LATEST_PRODUCTION.featureLevel(), mv.featureLevel(),",
          "263:       \"Expected the default metadata.version to be the latest production version\")",
          "264:   }",
          "266:   @Test",
          "267:   def testConfiguredMetadataVersion(): Unit = {",
          "268:     val namespace = StorageTool.parseArguments(Array(\"format\", \"-c\", \"config.props\", \"-t\", \"XcZZOzUqS4yHOjhMQB6JLQ\"))",
          "269:     val mv = StorageTool.getMetadataVersion(namespace, Map.empty, defaultVersionString = Some(MetadataVersion.IBP_3_3_IV2.toString))",
          "270:     assertEquals(MetadataVersion.IBP_3_3_IV2.featureLevel(), mv.featureLevel(),",
          "271:       \"Expected the default metadata.version to be 3.3-IV2\")",
          "272:   }",
          "274:   @Test",
          "275:   def testSettingFeatureAndReleaseVersionFails(): Unit = {",
          "276:     val namespace = StorageTool.parseArguments(Array(\"format\", \"-c\", \"config.props\", \"-t\", \"XcZZOzUqS4yHOjhMQB6JLQ\",",
          "277:       \"--release-version\", \"3.0-IV1\", \"--feature\", \"metadata.version=4\"))",
          "278:     assertThrows(classOf[IllegalArgumentException], () => StorageTool.getMetadataVersion(namespace, parseFeatures(namespace), defaultVersionString = None))",
          "279:   }",
          "281:   @Test",
          "282:   def testParseFeatures(): Unit = {",
          "283:     def parseAddFeatures(strings: String*): Map[String, java.lang.Short] = {",
          "284:       var args = mutable.Seq(\"format\", \"-c\", \"config.props\", \"-t\", \"XcZZOzUqS4yHOjhMQB6JLQ\")",
          "285:       args ++= strings",
          "286:       val namespace = StorageTool.parseArguments(args.toArray)",
          "287:       parseFeatures(namespace)",
          "288:     }",
          "290:     assertThrows(classOf[RuntimeException], () => parseAddFeatures(\"--feature\", \"blah\"))",
          "291:     assertThrows(classOf[RuntimeException], () => parseAddFeatures(\"--feature\", \"blah=blah\"))",
          "294:     assertEquals(Map(), parseAddFeatures())",
          "297:     val testFeatureLevel = 1",
          "298:     val testArgument = TestFeatureVersion.FEATURE_NAME + \"=\" + testFeatureLevel.toString",
          "299:     val expectedMap = Map(TestFeatureVersion.FEATURE_NAME -> testFeatureLevel.toShort)",
          "300:     assertEquals(expectedMap, parseAddFeatures(\"--feature\", testArgument))",
          "303:     val metadataFeatureLevel = 5",
          "304:     val metadataArgument = MetadataVersion.FEATURE_NAME + \"=\" + metadataFeatureLevel.toString",
          "305:     val expectedMap2 = expectedMap ++ Map (MetadataVersion.FEATURE_NAME -> metadataFeatureLevel.toShort)",
          "306:     assertEquals(expectedMap2, parseAddFeatures(\"--feature\", testArgument, \"--feature\", metadataArgument))",
          "307:   }",
          "309:   private def parseFeatures(namespace: Namespace): Map[String, java.lang.Short] = {",
          "310:     val specifiedFeatures: util.List[String] = namespace.getList(\"feature\")",
          "311:     StorageTool.featureNamesAndLevels(Option(specifiedFeatures).getOrElse(Collections.emptyList).asScala.toList)",
          "315:   def testMetadataVersionFlags(): Unit = {",
          "316:     def parseMetadataVersion(strings: String*): MetadataVersion = {",
          "317:       var args = mutable.Seq(\"format\", \"-c\", \"config.props\", \"-t\", \"XcZZOzUqS4yHOjhMQB6JLQ\")",
          "318:       args ++= strings",
          "319:       val namespace = StorageTool.parseArguments(args.toArray)",
          "320:       StorageTool.getMetadataVersion(namespace, Map.empty, defaultVersionString = None)",
          "321:     }",
          "323:     var mv = parseMetadataVersion(\"--release-version\", \"3.0\")",
          "324:     assertEquals(\"3.0\", mv.shortVersion())",
          "326:     mv = parseMetadataVersion(\"--release-version\", \"3.0-IV1\")",
          "327:     assertEquals(MetadataVersion.IBP_3_0_IV1, mv)",
          "329:     assertThrows(classOf[IllegalArgumentException], () => parseMetadataVersion(\"--release-version\", \"0.0\"))",
          "330:   }",
          "332:   private def generateRecord(featureName: String, level: Short): ApiMessageAndVersion = {",
          "333:     new ApiMessageAndVersion(new FeatureLevelRecord().",
          "334:       setName(featureName).",
          "335:       setFeatureLevel(level), 0.toShort)",
          "336:   }",
          "338:   @ParameterizedTest",
          "339:   @EnumSource(classOf[TestFeatureVersion])",
          "340:   def testFeatureFlag(testFeatureVersion: TestFeatureVersion): Unit = {",
          "341:     val featureLevel = testFeatureVersion.featureLevel",
          "342:     if (featureLevel <= Features.TEST_VERSION.defaultValue(MetadataVersion.LATEST_PRODUCTION)) {",
          "343:       val records = new ArrayBuffer[ApiMessageAndVersion]()",
          "344:       StorageTool.generateFeatureRecords(",
          "345:         records,",
          "346:         MetadataVersion.LATEST_PRODUCTION,",
          "347:         Map(TestFeatureVersion.FEATURE_NAME -> featureLevel),",
          "348:         allFeatures,",
          "349:         false,",
          "350:         false",
          "351:       )",
          "352:       if (featureLevel > 0) {",
          "353:         assertEquals(List(generateRecord(TestFeatureVersion.FEATURE_NAME, featureLevel)), records)",
          "354:       }",
          "355:     }",
          "356:   }",
          "358:   @ParameterizedTest",
          "359:   @EnumSource(classOf[MetadataVersion])",
          "360:   def testVersionDefault(metadataVersion: MetadataVersion): Unit = {",
          "361:     val records = new ArrayBuffer[ApiMessageAndVersion]()",
          "362:     StorageTool.generateFeatureRecords(",
          "363:       records,",
          "364:       metadataVersion,",
          "365:       Map.empty,",
          "366:       allFeatures,",
          "367:       true,",
          "368:       true",
          "369:     )",
          "371:     val expectedRecords = new ArrayBuffer[ApiMessageAndVersion]()",
          "373:     def maybeAddRecordFor(features: Features): Unit = {",
          "374:       val featureLevel = features.defaultValue(metadataVersion)",
          "375:       if (featureLevel > 0) {",
          "376:         expectedRecords += generateRecord(features.featureName, featureLevel)",
          "377:       }",
          "378:     }",
          "380:     Features.FEATURES.foreach(maybeAddRecordFor)",
          "382:     assertEquals(expectedRecords, records)",
          "383:   }",
          "384:   @Test",
          "385:   def testVersionDefaultNoArgs(): Unit = {",
          "386:     val records = new ArrayBuffer[ApiMessageAndVersion]()",
          "387:     StorageTool.generateFeatureRecords(",
          "388:       records,",
          "389:       MetadataVersion.LATEST_PRODUCTION,",
          "390:       Map.empty,",
          "391:       allFeatures,",
          "392:       false,",
          "393:       false",
          "394:     )",
          "396:     assertEquals(List(generateRecord(TestFeatureVersion.FEATURE_NAME, Features.TEST_VERSION.defaultValue(MetadataVersion.LATEST_PRODUCTION))), records)",
          "401:   def testFeatureDependency(): Unit = {",
          "402:     val featureLevel = 1.toShort",
          "403:     assertThrows(classOf[TerseFailure], () => StorageTool.generateFeatureRecords(",
          "404:       new ArrayBuffer[ApiMessageAndVersion](),",
          "405:       MetadataVersion.IBP_2_8_IV1,",
          "406:       Map(TestFeatureVersion.FEATURE_NAME -> featureLevel),",
          "407:       allFeatures,",
          "408:       false,",
          "409:       false",
          "410:     ))",
          "414:   def testLatestFeaturesWithOldMetadataVersion(): Unit = {",
          "415:     val records = new ArrayBuffer[ApiMessageAndVersion]()",
          "416:     StorageTool.generateFeatureRecords(",
          "417:       records,",
          "418:       MetadataVersion.IBP_3_3_IV0,",
          "419:       Map.empty,",
          "420:       allFeatures,",
          "421:       false,",
          "422:       false",
          "423:     )",
          "425:     assertEquals(List(generateRecord(TestFeatureVersion.FEATURE_NAME, Features.TEST_VERSION.defaultValue(MetadataVersion.LATEST_PRODUCTION))), records)",
          "429:   def testFeatureInvalidFlag(): Unit = {",
          "430:     val featureLevel = 99.toShort",
          "431:     assertThrows(classOf[IllegalArgumentException], () => StorageTool.generateFeatureRecords(",
          "432:       new ArrayBuffer[ApiMessageAndVersion](),",
          "433:       MetadataVersion.LATEST_PRODUCTION,",
          "434:       Map(TestFeatureVersion.FEATURE_NAME -> featureLevel),",
          "435:       allFeatures,",
          "436:       false,",
          "437:       false",
          "438:     ))",
          "442:   def testUnstableFeatureThrowsError(): Unit = {",
          "443:     assertThrows(classOf[IllegalArgumentException], () => StorageTool.generateFeatureRecords(",
          "444:       new ArrayBuffer[ApiMessageAndVersion](),",
          "445:       MetadataVersion.LATEST_PRODUCTION,",
          "446:       Map(TestFeatureVersion.FEATURE_NAME -> Features.TEST_VERSION.latestTesting),",
          "447:       allFeatures,",
          "448:       false,",
          "449:       false",
          "450:     ))",
          "454:   def testAddScram():Unit = {",
          "455:     def parseAddScram(strings: String*): Option[ArrayBuffer[UserScramCredentialRecord]] = {",
          "456:       var args = mutable.Seq(\"format\", \"-c\", \"config.props\", \"-t\", \"XcZZOzUqS4yHOjhMQB6JLQ\")",
          "457:       args ++= strings",
          "458:       val namespace = StorageTool.parseArguments(args.toArray)",
          "459:       StorageTool.getUserScramCredentialRecords(namespace)",
          "460:     }",
          "462:     var scramRecords = parseAddScram()",
          "463:     assertEquals(None, scramRecords)",
          "466:     scramRecords = parseAddScram(\"-S\",",
          "467:     \"SCRAM-SHA-256=[name=alice,salt=\\\"MWx2NHBkbnc0ZndxN25vdGN4bTB5eTFrN3E=\\\",saltedpassword=\\\"mT0yyUUxnlJaC99HXgRTSYlbuqa4FSGtJCJfTMvjYCE=\\\",iterations=8192]\",",
          "468:     \"-S\",",
          "469:     \"SCRAM-SHA-256=[name=george,salt=\\\"MWx2NHBkbnc0ZndxN25vdGN4bTB5eTFrN3E=\\\",saltedpassword=\\\"mT0yyUUxnlJaC99HXgRTSYlbuqa4FSGtJCJfTMvjYCE=\\\",iterations=8192]\")",
          "471:     assertEquals(2, scramRecords.get.size)",
          "474:     try assertEquals(1, parseAddScram(\"-S\",",
          "475:       \"SCRAM-SHA-256=[salt=\\\"MWx2NHBkbnc0ZndxN25vdGN4bTB5eTFrN3E=\\\",saltedpassword=\\\"mT0yyUUxnlJaC99HXgRTSYlbuqa4FSGtJCJfTMvjYCE=\\\",iterations=8192]\")) catch {",
          "476:       case e: TerseFailure => assertEquals(s\"You must supply 'name' to add-scram\", e.getMessage)",
          "477:     }",
          "480:     try assertEquals(1, parseAddScram(\"-S\",",
          "481:       \"SCRAM-SHA-256=[name=alice,salt=\\\"MWx2NHBkbnc0ZndxN25vdGN4bTB5eTFrN3E=\\\",password=alice,saltedpassword=\\\"mT0yyUUxnlJaC99HXgRTSYlbuqa4FSGtJCJfTMvjYCE=\\\",iterations=8192]\"))",
          "482:     catch {",
          "483:       case e: TerseFailure => assertEquals(s\"You must only supply one of 'password' or 'saltedpassword' to add-scram\", e.getMessage)",
          "484:     }",
          "486:     try assertEquals(1, parseAddScram(\"-S\",",
          "487:       \"SCRAM-SHA-256=[name=alice,salt=\\\"MWx2NHBkbnc0ZndxN25vdGN4bTB5eTFrN3E=\\\",iterations=8192]\"))",
          "488:     catch {",
          "489:       case e: TerseFailure => assertEquals(s\"You must supply one of 'password' or 'saltedpassword' to add-scram\", e.getMessage)",
          "490:     }",
          "493:     try assertEquals(1, parseAddScram(\"-S\",",
          "494:       \"SCRAM-SHA-256=[name=alice,saltedpassword=\\\"mT0yyUUxnlJaC99HXgRTSYlbuqa4FSGtJCJfTMvjYCE=\\\",iterations=8192]\"))",
          "495:     catch {",
          "496:       case e: TerseFailure => assertEquals(s\"You must supply 'salt' with 'saltedpassword' to add-scram\", e.getMessage)",
          "497:     }",
          "500:     assertEquals(1, parseAddScram(\"-S\", \"SCRAM-SHA-256=[name=alice,password=alice,iterations=4096]\").get.size)",
          "503:     try assertEquals(1, parseAddScram(\"-S\",",
          "504:       \"SCRAM-SHA-256=[name=alice,salt=\\\"MWx2NHBkbnc0ZndxN25vdGN4bTB5eTFrN3E=\\\",password=alice,iterations=16385]\"))",
          "505:     catch {",
          "506:       case e: TerseFailure => assertEquals(s\"The 'iterations' value must be <= 16384 for add-scram\", e.getMessage)",
          "507:     }",
          "509:     assertEquals(1, parseAddScram(\"-S\",",
          "510:       \"SCRAM-SHA-256=[name=alice,salt=\\\"MWx2NHBkbnc0ZndxN25vdGN4bTB5eTFrN3E=\\\",password=alice,iterations=16384]\")",
          "511:       .get.size)",
          "513:     try assertEquals(1, parseAddScram(\"-S\",",
          "514:       \"SCRAM-SHA-256=[name=alice,salt=\\\"MWx2NHBkbnc0ZndxN25vdGN4bTB5eTFrN3E=\\\",password=alice,iterations=4095]\"))",
          "515:     catch {",
          "516:       case e: TerseFailure => assertEquals(s\"The 'iterations' value must be >= 4096 for add-scram\", e.getMessage)",
          "517:     }",
          "519:     assertEquals(1, parseAddScram(\"-S\",",
          "520:       \"SCRAM-SHA-256=[name=alice,salt=\\\"MWx2NHBkbnc0ZndxN25vdGN4bTB5eTFrN3E=\\\",password=alice,iterations=4096]\")",
          "521:       .get.size)",
          "524:     assertEquals(1, parseAddScram(\"-S\", \"SCRAM-SHA-256=[name=alice,password=alice]\") .get.size)",
          "525:   }",
          "527:   class StorageToolTestException(message: String)  extends KafkaException(message) {",
          "531:   def testScramWithBadMetadataVersion(): Unit = {",
          "532:     var exitString: String = \"\"",
          "533:     def exitProcedure(exitStatus: Int, message: Option[String]) : Nothing = {",
          "534:       exitString = message.getOrElse(\"\")",
          "535:       throw new StorageToolTestException(exitString)",
          "536:     }",
          "537:     Exit.setExitProcedure(exitProcedure)",
          "539:     val properties = newSelfManagedProperties()",
          "540:     val propsFile = TestUtils.tempFile()",
          "541:     val propsStream = Files.newOutputStream(propsFile.toPath)",
          "542:     properties.store(propsStream, \"config.props\")",
          "543:     propsStream.close()",
          "545:     val args = Array(\"format\", \"-c\", s\"${propsFile.toPath}\", \"-t\", \"XcZZOzUqS4yHOjhMQB6JLQ\", \"--release-version\", \"3.4\", \"-S\",",
          "546:       \"SCRAM-SHA-256=[name=alice,salt=\\\"MWx2NHBkbnc0ZndxN25vdGN4bTB5eTFrN3E=\\\",password=alice,iterations=8192]\")",
          "548:     try {",
          "549:       assertEquals(1, StorageTool.main(args))",
          "550:     } catch {",
          "551:       case e: StorageToolTestException => assertEquals(s\"SCRAM is only supported in metadata.version ${MetadataVersion.IBP_3_5_IV2} or later.\", exitString)",
          "552:     } finally {",
          "553:       Exit.resetExitProcedure()",
          "554:     }",
          "558:   def testNoScramWithMetadataVersion(): Unit = {",
          "559:     var exitString: String = \"\"",
          "560:     var exitStatus: Int = 1",
          "561:     def exitProcedure(status: Int, message: Option[String]) : Nothing = {",
          "562:       exitStatus = status",
          "563:       exitString = message.getOrElse(\"\")",
          "564:       throw new StorageToolTestException(exitString)",
          "565:     }",
          "566:     Exit.setExitProcedure(exitProcedure)",
          "568:     val properties = newSelfManagedProperties()",
          "569:     val propsFile = TestUtils.tempFile()",
          "570:     val propsStream = Files.newOutputStream(propsFile.toPath)",
          "572:     properties.setProperty(ServerLogConfigs.LOG_DIRS_CONFIG, TestUtils.tempDir().toString)",
          "573:     properties.store(propsStream, \"config.props\")",
          "574:     propsStream.close()",
          "576:     val args = Array(\"format\", \"-c\", s\"${propsFile.toPath}\", \"-t\", \"XcZZOzUqS4yHOjhMQB6JLQ\", \"--release-version\", \"3.4\")",
          "578:     try {",
          "579:       StorageTool.main(args)",
          "580:     } catch {",
          "581:       case e: StorageToolTestException => assertEquals(\"\", exitString)",
          "582:       assertEquals(0, exitStatus)",
          "583:     } finally {",
          "584:       Exit.resetExitProcedure()",
          "585:     }",
          "589:   def testDirUuidGeneration(): Unit = {",
          "590:     val tempDir = TestUtils.tempDir()",
          "591:     try {",
          "592:       val metaProperties = new MetaProperties.Builder().",
          "593:         setClusterId(\"XcZZOzUqS4yHOjhMQB6JLQ\").",
          "594:         setNodeId(2).",
          "595:         build()",
          "596:       val bootstrapMetadata = StorageTool.",
          "597:         buildBootstrapMetadata(MetadataVersion.latestTesting(), None, \"test format command\")",
          "598:       assertEquals(0, StorageTool.",
          "599:         formatCommand(new PrintStream(NullOutputStream.NULL_OUTPUT_STREAM), Seq(tempDir.toString), metaProperties, bootstrapMetadata, MetadataVersion.latestTesting(), ignoreFormatted = false))",
          "601:       val metaPropertiesFile = Paths.get(tempDir.toURI).resolve(MetaPropertiesEnsemble.META_PROPERTIES_NAME).toFile",
          "602:       assertTrue(metaPropertiesFile.exists())",
          "603:       val metaProps = new MetaProperties.Builder(",
          "604:         PropertiesUtils.readPropertiesFile(metaPropertiesFile.getAbsolutePath())).",
          "605:           build()",
          "606:       assertTrue(metaProps.directoryId().isPresent())",
          "607:       assertFalse(DirectoryId.reserved(metaProps.directoryId().get()))",
          "608:     } finally Utils.delete(tempDir)",
          "613:   def testFormattingUnstableMetadataVersionBlocked(enableUnstable: Boolean): Unit = {",
          "614:     var exitString: String = \"\"",
          "615:     var exitStatus: Int = 1",
          "616:     def exitProcedure(status: Int, message: Option[String]) : Nothing = {",
          "617:       exitStatus = status",
          "618:       exitString = message.getOrElse(\"\")",
          "619:       throw new StorageToolTestException(exitString)",
          "620:     }",
          "621:     Exit.setExitProcedure(exitProcedure)",
          "622:     val properties = newSelfManagedProperties()",
          "623:     val propsFile = TestUtils.tempFile()",
          "624:     val propsStream = Files.newOutputStream(propsFile.toPath)",
          "625:     try {",
          "626:       properties.setProperty(ServerLogConfigs.LOG_DIRS_CONFIG, TestUtils.tempDir().toString)",
          "627:       properties.setProperty(ServerConfigs.UNSTABLE_FEATURE_VERSIONS_ENABLE_CONFIG, enableUnstable.toString)",
          "628:       properties.store(propsStream, \"config.props\")",
          "629:     } finally {",
          "630:       propsStream.close()",
          "631:     }",
          "632:     val args = Array(\"format\", \"-c\", s\"${propsFile.toPath}\",",
          "633:       \"-t\", \"XcZZOzUqS4yHOjhMQB6JLQ\",",
          "634:       \"--release-version\", MetadataVersion.latestTesting().toString)",
          "635:     try {",
          "636:       StorageTool.main(args)",
          "637:     } catch {",
          "638:       case _: StorageToolTestException =>",
          "639:     } finally {",
          "640:       Exit.resetExitProcedure()",
          "641:     }",
          "642:     if (enableUnstable) {",
          "643:       assertEquals(\"\", exitString)",
          "644:       assertEquals(0, exitStatus)",
          "645:     } else {",
          "646:       assertEquals(s\"The metadata.version ${MetadataVersion.latestTesting().toString} is not ready for \" +",
          "647:         \"production use yet.\", exitString)",
          "648:       assertEquals(1, exitStatus)",
          "653:   def testFormatValidatesConfigForMetadataVersion(): Unit = {",
          "654:     val config = Mockito.spy(new KafkaConfig(TestUtils.createBrokerConfig(10, null)))",
          "655:     val args = Array(\"format\",",
          "656:       \"-c\", \"dummy.properties\",",
          "657:       \"-t\", \"XcZZOzUqS4yHOjhMQB6JLQ\",",
          "658:       \"--release-version\", MetadataVersion.LATEST_PRODUCTION.toString)",
          "659:     val exitCode = StorageTool.runFormatCommand(StorageTool.parseArguments(args), config)",
          "660:     Mockito.verify(config, Mockito.times(1)).validateWithMetadataVersion(MetadataVersion.LATEST_PRODUCTION)",
          "661:     assertEquals(0, exitCode)",
          "664:   @Test",
          "665:   def testJbodSupportValidation(): Unit = {",
          "666:     def formatWith(logDirCount: Int, metadataVersion: MetadataVersion): Integer = {",
          "667:       val properties = TestUtils.createBrokerConfig(10, null, logDirCount = logDirCount)",
          "668:       properties.remove(ReplicationConfigs.INTER_BROKER_PROTOCOL_VERSION_CONFIG)",
          "669:       val configFile = TestUtils.tempPropertiesFile(properties.asScala.toMap).toPath.toString",
          "670:       StorageTool.execute(Array(\"format\",",
          "671:         \"-c\", configFile,",
          "672:         \"-t\", \"XcZZOzUqS4yHOjhMQB6JLQ\",",
          "673:         \"--release-version\", metadataVersion.toString))",
          "676:     assertEquals(0, formatWith(1, MetadataVersion.IBP_3_6_IV2))",
          "677:     assertEquals(\"Invalid configuration for metadata version: \" +",
          "678:       \"requirement failed: Multiple log directories (aka JBOD) are not supported in the current MetadataVersion 3.6-IV2. Need 3.7-IV2 or higher\",",
          "679:       assertThrows(classOf[TerseFailure], () => formatWith(2, MetadataVersion.IBP_3_6_IV2)).getMessage)",
          "680:     assertEquals(0, formatWith(1, MetadataVersion.IBP_3_7_IV2))",
          "681:     assertEquals(0, formatWith(2, MetadataVersion.IBP_3_7_IV2))",
          "",
          "[Added Lines]",
          "166:   val defaultStaticQuorumProperties = new Properties()",
          "167:   defaultStaticQuorumProperties.setProperty(\"process.roles\", \"broker\")",
          "168:   defaultStaticQuorumProperties.setProperty(\"node.id\", \"0\")",
          "169:   defaultStaticQuorumProperties.setProperty(\"controller.listener.names\", \"CONTROLLER\")",
          "170:   defaultStaticQuorumProperties.setProperty(\"controller.quorum.voters\", \"100@localhost:9093\")",
          "172:   val defaultDynamicQuorumProperties = new Properties()",
          "173:   defaultDynamicQuorumProperties.setProperty(\"process.roles\", \"controller\")",
          "174:   defaultDynamicQuorumProperties.setProperty(\"node.id\", \"0\")",
          "175:   defaultDynamicQuorumProperties.setProperty(\"controller.listener.names\", \"CONTROLLER\")",
          "176:   defaultDynamicQuorumProperties.setProperty(\"controller.quorum.voters\", \"0@localhost:9093\")",
          "177:   defaultDynamicQuorumProperties.setProperty(\"listeners\", \"CONTROLLER://127.0.0.1:9093\")",
          "178:   defaultDynamicQuorumProperties.setProperty(ServerConfigs.UNSTABLE_API_VERSIONS_ENABLE_CONFIG, \"true\")",
          "179:   defaultDynamicQuorumProperties.setProperty(ServerConfigs.UNSTABLE_FEATURE_VERSIONS_ENABLE_CONFIG , \"true\")",
          "181:   private def runFormatCommand(",
          "182:     stream: ByteArrayOutputStream,",
          "183:     properties: Properties,",
          "184:     extraArguments: Seq[String] = Seq(),",
          "185:     ignoreFormatted: Boolean = false",
          "186:    ): Int = {",
          "189:       val configPathString = new File(tempDir.getAbsolutePath(), \"format.props\").toString",
          "190:       PropertiesUtils.writePropertiesFile(properties, configPathString, true)",
          "191:       val arguments = ListBuffer[String](\"format\",",
          "192:         \"--cluster-id\", \"XcZZOzUqS4yHOjhMQB6JLQ\")",
          "193:       if (ignoreFormatted) {",
          "194:         arguments += \"--ignore-formatted\"",
          "196:       arguments += \"--config\"",
          "197:       arguments += configPathString",
          "198:       extraArguments.foreach(arguments += _)",
          "199:       StorageTool.execute(arguments.toArray, new PrintStream(stream))",
          "200:     } finally {",
          "201:       Utils.delete(tempDir)",
          "202:     }",
          "207:     val availableDirs = Seq(TestUtils.tempDir(), TestUtils.tempDir(), TestUtils.tempDir())",
          "208:     val properties = new Properties()",
          "209:     properties.putAll(defaultStaticQuorumProperties)",
          "210:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
          "212:     assertEquals(0, runFormatCommand(stream, properties))",
          "214:     assertTrue(stream.toString().",
          "215:       contains(\"Formatting metadata directory %s\".format(availableDirs.head)),",
          "216:         \"Failed to find content in output: \" + stream.toString())",
          "217:     availableDirs.tail.foreach {",
          "218:       dir => assertTrue(",
          "219:         stream.toString().contains(\"Formatting data directory %s\".format(dir)),",
          "220:           \"Failed to find content in output: \" + stream.toString())",
          "221:     }",
          "228:     val properties = new Properties()",
          "229:     properties.putAll(defaultStaticQuorumProperties)",
          "230:     properties.setProperty(\"log.dirs\", s\"${availableDir1},${unavailableDir1}\")",
          "232:     assertEquals(0, runFormatCommand(stream, properties))",
          "234:     assertTrue(stream.toString().contains(\"Formatting metadata directory %s\".format(availableDir1)),",
          "235:       \"Failed to find content in output: \" + stream.toString())",
          "237:     assertFalse(stream.toString().contains(\"Formatting log directory %s\".format(unavailableDir1)),",
          "238:       \"Failed to find content in output: \" + stream.toString())",
          "239:     assertTrue(stream.toString().contains(",
          "240:       \"I/O error trying to read log directory %s. Ignoring...\".format(unavailableDir1)),",
          "241:         \"Failed to find content in output: \" + stream.toString())",
          "245:   def testFormatFailsOnAlreadyFormatted(): Unit = {",
          "246:     val availableDirs = Seq(TestUtils.tempDir(), TestUtils.tempDir(), TestUtils.tempDir())",
          "247:     val properties = new Properties()",
          "248:     properties.putAll(defaultStaticQuorumProperties)",
          "249:     properties.setProperty(\"log.dirs\", s\"${availableDirs(0)}\")",
          "251:     assertEquals(0, runFormatCommand(stream, properties))",
          "252:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
          "254:     assertTrue(assertThrows(classOf[FormatterException],",
          "255:       () => runFormatCommand(stream2, properties)).getMessage.contains(",
          "256:         \"already formatted. Use --ignore-formatted to ignore this directory and format the others\"))",
          "260:   def testIgnoreFormatted(): Unit = {",
          "261:     val availableDirs = Seq(TestUtils.tempDir(), TestUtils.tempDir(), TestUtils.tempDir())",
          "262:     val properties = new Properties()",
          "263:     properties.putAll(defaultStaticQuorumProperties)",
          "264:     properties.setProperty(\"log.dirs\", s\"${availableDirs(0)}\")",
          "265:     val stream = new ByteArrayOutputStream()",
          "266:     assertEquals(0, runFormatCommand(stream, properties))",
          "267:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
          "268:     val stream2 = new ByteArrayOutputStream()",
          "269:     assertEquals(0, runFormatCommand(stream2, properties, Seq(), true))",
          "273:   def testFormatFailsIfAllDirectoriesAreUnavailable(): Unit = {",
          "274:     val unavailableDir1 = TestUtils.tempFile()",
          "275:     val unavailableDir2 = TestUtils.tempFile()",
          "276:     val properties = new Properties()",
          "277:     properties.putAll(defaultStaticQuorumProperties)",
          "278:     properties.setProperty(\"log.dirs\", s\"${unavailableDir1},${unavailableDir2}\")",
          "279:     val stream = new ByteArrayOutputStream()",
          "280:     assertEquals(\"No available log directories to format.\", assertThrows(classOf[FormatterException],",
          "281:       () => runFormatCommand(stream, properties)).getMessage)",
          "282:     assertTrue(stream.toString().contains(",
          "283:       \"I/O error trying to read log directory %s. Ignoring...\".format(unavailableDir1)),",
          "284:         \"Failed to find content in output: \" + stream.toString())",
          "285:     assertTrue(stream.toString().contains(",
          "286:       \"I/O error trying to read log directory %s. Ignoring...\".format(unavailableDir2)),",
          "287:         \"Failed to find content in output: \" + stream.toString())",
          "291:   def testFormatFailsInZkMode(): Unit = {",
          "292:     val availableDirs = Seq(TestUtils.tempDir())",
          "293:     val properties = new Properties()",
          "294:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
          "295:     properties.setProperty(\"zookeeper.connect\", \"localhost:2181\")",
          "296:     val stream = new ByteArrayOutputStream()",
          "297:     assertEquals(\"The kafka configuration file appears to be for a legacy cluster. \" +",
          "298:       \"Formatting is only supported for clusters in KRaft mode.\",",
          "299:         assertThrows(classOf[TerseFailure],",
          "300:           () => runFormatCommand(stream, properties)).getMessage)",
          "304:   def testFormatWithReleaseVersion(): Unit = {",
          "305:     val availableDirs = Seq(TestUtils.tempDir())",
          "306:     val properties = new Properties()",
          "307:     properties.putAll(defaultStaticQuorumProperties)",
          "308:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
          "309:     val stream = new ByteArrayOutputStream()",
          "310:     assertEquals(0, runFormatCommand(stream, properties, Seq(\"--release-version\", \"3.8-IV0\")))",
          "311:     assertTrue(stream.toString().contains(\"3.8-IV0\"),",
          "312:       \"Failed to find content in output: \" + stream.toString())",
          "316:   def testFormatWithReleaseVersionAsFeature(): Unit = {",
          "317:     val availableDirs = Seq(TestUtils.tempDir())",
          "318:     val properties = new Properties()",
          "319:     properties.putAll(defaultStaticQuorumProperties)",
          "320:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
          "321:     val stream = new ByteArrayOutputStream()",
          "322:     assertEquals(0, runFormatCommand(stream, properties, Seq(\"--feature\", \"metadata.version=20\")))",
          "323:     assertTrue(stream.toString().contains(\"3.8-IV0\"),",
          "324:       \"Failed to find content in output: \" + stream.toString())",
          "328:   def testFormatWithReleaseVersionAndKRaftVersion(): Unit = {",
          "329:     val availableDirs = Seq(TestUtils.tempDir())",
          "330:     val properties = new Properties()",
          "331:     properties.putAll(defaultStaticQuorumProperties)",
          "332:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
          "333:     val stream = new ByteArrayOutputStream()",
          "334:     assertEquals(0, runFormatCommand(stream, properties, Seq(",
          "335:       \"--release-version\", \"3.7-IV0\",",
          "336:       \"--feature\", \"kraft.version=0\")))",
          "337:     assertTrue(stream.toString().contains(\"3.7-IV0\"),",
          "338:       \"Failed to find content in output: \" + stream.toString())",
          "342:   def testFormatWithReleaseVersionDefault(): Unit = {",
          "343:     val availableDirs = Seq(TestUtils.tempDir())",
          "344:     val properties = new Properties()",
          "345:     properties.putAll(defaultStaticQuorumProperties)",
          "346:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
          "347:     properties.setProperty(\"inter.broker.protocol.version\", \"3.7\")",
          "348:     val stream = new ByteArrayOutputStream()",
          "349:     assertEquals(0, runFormatCommand(stream, properties))",
          "350:     assertTrue(stream.toString().contains(\"3.7-IV4\"),",
          "351:       \"Failed to find content in output: \" + stream.toString())",
          "355:   def testFormatWithReleaseVersionDefaultAndReleaseVersion(): Unit = {",
          "356:     val availableDirs = Seq(TestUtils.tempDir())",
          "357:     val properties = new Properties()",
          "358:     properties.putAll(defaultStaticQuorumProperties)",
          "359:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
          "360:     properties.setProperty(\"inter.broker.protocol.version\", \"3.7\")",
          "361:     val stream = new ByteArrayOutputStream()",
          "362:     assertEquals(0, runFormatCommand(stream, properties, Seq(",
          "363:       \"--release-version\", \"3.6-IV0\",",
          "364:       \"--feature\", \"kraft.version=0\")))",
          "365:     assertTrue(stream.toString().contains(\"3.6-IV0\"),",
          "366:       \"Failed to find content in output: \" + stream.toString())",
          "370:   def testFormatWithStandaloneFlagOnBrokerFails(): Unit = {",
          "371:     val availableDirs = Seq(TestUtils.tempDir())",
          "372:     val properties = new Properties()",
          "373:     properties.putAll(defaultStaticQuorumProperties)",
          "374:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
          "375:     val stream = new ByteArrayOutputStream()",
          "376:     val arguments = ListBuffer[String](\"--release-version\", \"3.9-IV0\", \"--standalone\")",
          "377:     assertEquals(\"You cannot use --standalone on a broker node.\",",
          "378:       assertThrows(classOf[TerseFailure],",
          "379:         () => runFormatCommand(stream, properties, arguments.toSeq)).getMessage)",
          "384:   def testFormatWithStandaloneFlag(setKraftVersionFeature: Boolean): Unit = {",
          "385:     val availableDirs = Seq(TestUtils.tempDir())",
          "386:     val properties = new Properties()",
          "387:     properties.putAll(defaultDynamicQuorumProperties)",
          "388:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
          "389:     val stream = new ByteArrayOutputStream()",
          "390:     val arguments = ListBuffer[String](\"--release-version\", \"3.9-IV0\", \"--standalone\")",
          "391:     if (setKraftVersionFeature) {",
          "392:       arguments += \"--feature\"",
          "393:       arguments += \"kraft.version=1\"",
          "395:     assertEquals(0, runFormatCommand(stream, properties, arguments.toSeq))",
          "396:     assertTrue(stream.toString().",
          "397:       contains(\"Formatting dynamic metadata voter directory %s\".format(availableDirs.head)),",
          "398:         \"Failed to find content in output: \" + stream.toString())",
          "402:   def testFormatWithStandaloneFlagAndInitialControllersFlagFails(): Unit = {",
          "403:     val availableDirs = Seq(TestUtils.tempDir())",
          "404:     val properties = new Properties()",
          "405:     properties.putAll(defaultDynamicQuorumProperties)",
          "406:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
          "407:     val stream = new ByteArrayOutputStream()",
          "408:     val arguments = ListBuffer[String](",
          "409:       \"--release-version\", \"3.9-IV0\",",
          "410:       \"--standalone\", \"--initial-controllers\",",
          "411:       \"0@localhost:8020:K90IZ-0DRNazJ49kCZ1EMQ,\" +",
          "412:       \"1@localhost:8030:aUARLskQTCW4qCZDtS_cwA,\" +",
          "413:       \"2@localhost:8040:2ggvsS4kQb-fSJ_-zC_Ang\")",
          "414:     assertEquals(1, runFormatCommand(stream, properties, arguments.toSeq))",
          "415:     assertTrue(stream.toString().contains(\"net.sourceforge.argparse4j.inf.ArgumentParserException: \" +",
          "416:       \"argument --initial-controllers/-I: not allowed with argument --standalone/-s\"),",
          "417:         \"Failed to find content in output: \" + stream.toString())",
          "420:   @ParameterizedTest",
          "421:   @ValueSource(booleans = Array(false, true))",
          "422:   def testFormatWithInitialControllersFlag(setKraftVersionFeature: Boolean): Unit = {",
          "423:     val availableDirs = Seq(TestUtils.tempDir())",
          "424:     val properties = new Properties()",
          "425:     properties.putAll(defaultDynamicQuorumProperties)",
          "426:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
          "427:     val stream = new ByteArrayOutputStream()",
          "428:     val arguments = ListBuffer[String](",
          "429:       \"--release-version\", \"3.9-IV0\",",
          "430:       \"--initial-controllers\",",
          "431:       \"0@localhost:8020:K90IZ-0DRNazJ49kCZ1EMQ,\" +",
          "432:         \"1@localhost:8030:aUARLskQTCW4qCZDtS_cwA,\" +",
          "433:         \"2@localhost:8040:2ggvsS4kQb-fSJ_-zC_Ang\")",
          "434:     if (setKraftVersionFeature) {",
          "435:       arguments += \"--feature\"",
          "436:       arguments += \"kraft.version=1\"",
          "438:     assertEquals(0, runFormatCommand(stream, properties, arguments.toSeq))",
          "439:     assertTrue(stream.toString().",
          "440:       contains(\"Formatting dynamic metadata voter directory %s\".format(availableDirs.head)),",
          "441:       \"Failed to find content in output: \" + stream.toString())",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/utils/TestUtils.scala||core/src/test/scala/unit/kafka/utils/TestUtils.scala": [
          "File: core/src/test/scala/unit/kafka/utils/TestUtils.scala -> core/src/test/scala/unit/kafka/utils/TestUtils.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "24: import kafka.server._",
          "25: import kafka.server.checkpoints.OffsetCheckpointFile",
          "26: import kafka.server.metadata.{ConfigRepository, MockConfigRepository}",
          "28: import kafka.utils.Implicits._",
          "29: import kafka.zk._",
          "30: import org.apache.kafka.clients.admin.AlterConfigOp.OpType",
          "",
          "[Removed Lines]",
          "27: import kafka.tools.StorageTool",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "54: import org.apache.kafka.common.utils.{Time, Utils}",
          "55: import org.apache.kafka.coordinator.group.GroupCoordinatorConfig",
          "56: import org.apache.kafka.coordinator.transaction.TransactionLogConfigs",
          "58: import org.apache.kafka.network.SocketServerConfigs",
          "59: import org.apache.kafka.queue.KafkaEventQueue",
          "60: import org.apache.kafka.raft.QuorumConfig",
          "61: import org.apache.kafka.server.authorizer.{AuthorizableRequestContext, Authorizer => JAuthorizer}",
          "63: import org.apache.kafka.server.config.{DelegationTokenManagerConfigs, KRaftConfigs, ReplicationConfigs, ServerConfigs, ServerLogConfigs, ZkConfigs}",
          "64: import org.apache.kafka.server.metrics.KafkaYammerMetrics",
          "65: import org.apache.kafka.server.util.MockTime",
          "",
          "[Removed Lines]",
          "57: import org.apache.kafka.metadata.properties.MetaProperties",
          "62: import org.apache.kafka.server.common.{ApiMessageAndVersion, MetadataVersion}",
          "",
          "[Added Lines]",
          "60: import org.apache.kafka.server.common.MetadataVersion",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "86: import java.util.{Arrays, Collections, Optional, Properties}",
          "87: import scala.annotation.nowarn",
          "88: import scala.collection.mutable.ArrayBuffer",
          "90: import scala.concurrent.duration.FiniteDuration",
          "91: import scala.concurrent.{Await, ExecutionContext, Future}",
          "92: import scala.jdk.CollectionConverters._",
          "",
          "[Removed Lines]",
          "89: import scala.collection.{Map, Seq, immutable, mutable}",
          "",
          "[Added Lines]",
          "87: import scala.collection.{Map, Seq, mutable}",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "1168:     assertEquals(0, threadCount, s\"Found unexpected $threadCount NonDaemon threads=${nonDaemonThreads.map(t => t.getName).mkString(\", \")}\")",
          "1169:   }",
          "",
          "[Removed Lines]",
          "1171:   def formatDirectories(",
          "1172:     directories: immutable.Seq[String],",
          "1173:     metaProperties: MetaProperties,",
          "1174:     metadataVersion: MetadataVersion,",
          "1175:     optionalMetadataRecords: Option[ArrayBuffer[ApiMessageAndVersion]]",
          "1176:   ): Unit = {",
          "1177:     val stream = new ByteArrayOutputStream()",
          "1178:     var out: PrintStream = null",
          "1179:     try {",
          "1180:       out = new PrintStream(stream)",
          "1181:       val bootstrapMetadata = StorageTool.buildBootstrapMetadata(metadataVersion, optionalMetadataRecords, \"format command\")",
          "1182:       if (StorageTool.formatCommand(out, directories, metaProperties, bootstrapMetadata, metadataVersion, ignoreFormatted = false) != 0) {",
          "1183:         throw new RuntimeException(stream.toString())",
          "1184:       }",
          "1185:       debug(s\"Formatted storage directory(ies) ${directories}\")",
          "1186:     } finally {",
          "1187:       if (out != null) out.close()",
          "1188:       stream.close()",
          "1189:     }",
          "1190:   }",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/bootstrap/BootstrapMetadata.java||metadata/src/main/java/org/apache/kafka/metadata/bootstrap/BootstrapMetadata.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/bootstrap/BootstrapMetadata.java -> metadata/src/main/java/org/apache/kafka/metadata/bootstrap/BootstrapMetadata.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: import org.apache.kafka.common.metadata.FeatureLevelRecord;",
          "21: import org.apache.kafka.common.protocol.ApiMessage;",
          "22: import org.apache.kafka.server.common.ApiMessageAndVersion;",
          "23: import org.apache.kafka.server.common.MetadataVersion;",
          "25: import java.util.Collections;",
          "26: import java.util.List;",
          "27: import java.util.Objects;",
          "28: import java.util.Optional;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "23: import org.apache.kafka.server.common.KRaftVersion;",
          "26: import java.util.ArrayList;",
          "29: import java.util.Map;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "40:     private final MetadataVersion metadataVersion;",
          "41:     private final String source;",
          "43:     public static BootstrapMetadata fromVersion(MetadataVersion metadataVersion, String source) {",
          "44:         List<ApiMessageAndVersion> records = Collections.singletonList(",
          "45:             new ApiMessageAndVersion(new FeatureLevelRecord().",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "46:     public static BootstrapMetadata fromVersions(",
          "47:         MetadataVersion metadataVersion,",
          "48:         Map<String, Short> featureVersions,",
          "49:         String source",
          "50:     ) {",
          "51:         List<ApiMessageAndVersion> records = new ArrayList<>();",
          "52:         records.add(new ApiMessageAndVersion(new FeatureLevelRecord().",
          "53:             setName(MetadataVersion.FEATURE_NAME).",
          "54:             setFeatureLevel(metadataVersion.featureLevel()), (short) 0));",
          "55:         List<String> featureNames = new ArrayList<>(featureVersions.size());",
          "56:         featureVersions.keySet().forEach(n -> {",
          "59:             if (!(n.equals(MetadataVersion.FEATURE_NAME) ||",
          "60:                     n.equals(KRaftVersion.FEATURE_NAME))) {",
          "61:                 featureNames.add(n);",
          "62:             }",
          "63:         });",
          "64:         featureNames.sort(String::compareTo);",
          "65:         for (String featureName : featureNames) {",
          "66:             short level = featureVersions.get(featureName);",
          "67:             if (level > 0) {",
          "68:                 records.add(new ApiMessageAndVersion(new FeatureLevelRecord().",
          "69:                     setName(featureName).",
          "70:                     setFeatureLevel(level), (short) 0));",
          "71:             }",
          "72:         }",
          "73:         return new BootstrapMetadata(records, metadataVersion, source);",
          "74:     }",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/storage/Formatter.java||metadata/src/main/java/org/apache/kafka/metadata/storage/Formatter.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/storage/Formatter.java -> metadata/src/main/java/org/apache/kafka/metadata/storage/Formatter.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.metadata.storage;",
          "20: import org.apache.kafka.common.Uuid;",
          "21: import org.apache.kafka.common.utils.Time;",
          "22: import org.apache.kafka.metadata.MetadataRecordSerde;",
          "23: import org.apache.kafka.metadata.bootstrap.BootstrapDirectory;",
          "24: import org.apache.kafka.metadata.bootstrap.BootstrapMetadata;",
          "25: import org.apache.kafka.metadata.properties.MetaProperties;",
          "26: import org.apache.kafka.metadata.properties.MetaPropertiesEnsemble;",
          "27: import org.apache.kafka.metadata.properties.MetaPropertiesVersion;",
          "28: import org.apache.kafka.raft.DynamicVoters;",
          "29: import org.apache.kafka.raft.KafkaRaftClient;",
          "30: import org.apache.kafka.raft.internals.VoterSet;",
          "31: import org.apache.kafka.server.common.ApiMessageAndVersion;",
          "32: import org.apache.kafka.server.common.FeatureVersion;",
          "33: import org.apache.kafka.server.common.Features;",
          "34: import org.apache.kafka.server.common.KRaftVersion;",
          "35: import org.apache.kafka.server.common.MetadataVersion;",
          "36: import org.apache.kafka.snapshot.FileRawSnapshotWriter;",
          "37: import org.apache.kafka.snapshot.RecordsSnapshotWriter;",
          "38: import org.apache.kafka.snapshot.Snapshots;",
          "40: import java.io.File;",
          "41: import java.io.PrintStream;",
          "42: import java.nio.file.Files;",
          "43: import java.nio.file.Paths;",
          "44: import java.util.ArrayList;",
          "45: import java.util.Collection;",
          "46: import java.util.Collections;",
          "47: import java.util.EnumSet;",
          "48: import java.util.HashMap;",
          "49: import java.util.List;",
          "50: import java.util.Map;",
          "51: import java.util.Optional;",
          "52: import java.util.OptionalInt;",
          "53: import java.util.TreeMap;",
          "54: import java.util.TreeSet;",
          "55: import java.util.stream.Collectors;",
          "57: import static org.apache.kafka.common.internals.Topic.CLUSTER_METADATA_TOPIC_PARTITION;",
          "58: import static org.apache.kafka.server.common.KRaftVersion.KRAFT_VERSION_0;",
          "59: import static org.apache.kafka.server.common.KRaftVersion.KRAFT_VERSION_1;",
          "64: public class Formatter {",
          "68:     private PrintStream printStream = System.out;",
          "73:     private List<Features> supportedFeatures = Features.PRODUCTION_FEATURES;",
          "78:     private int nodeId = -1;",
          "83:     private String clusterId = null;",
          "88:     private final TreeSet<String> directories = new TreeSet<>();",
          "93:     private MetadataVersion releaseVersion = null;",
          "98:     private Map<String, Short> featureLevels = new TreeMap<>();",
          "103:     private BootstrapMetadata bootstrapMetadata;",
          "108:     private boolean unstableFeatureVersionsEnabled = false;",
          "113:     private boolean ignoreFormatted = false;",
          "118:     private List<String> scramArguments = Collections.emptyList();",
          "123:     private String controllerListenerName = null;",
          "128:     private String metadataLogDirectory = null;",
          "133:     private Optional<DynamicVoters> initialControllers = Optional.empty();",
          "135:     public Formatter setPrintStream(PrintStream printStream) {",
          "136:         this.printStream = printStream;",
          "137:         return this;",
          "138:     }",
          "140:     public Formatter setSupportedFeatures(List<Features> supportedFeatures) {",
          "141:         this.supportedFeatures = supportedFeatures;",
          "142:         return this;",
          "143:     }",
          "145:     public Formatter setNodeId(int nodeId) {",
          "146:         this.nodeId = nodeId;",
          "147:         return this;",
          "148:     }",
          "150:     public Formatter setClusterId(String clusterId) {",
          "151:         this.clusterId = clusterId;",
          "152:         return this;",
          "153:     }",
          "155:     public String clusterId() {",
          "156:         return clusterId;",
          "157:     }",
          "159:     public Formatter setDirectories(Collection<String> directories) {",
          "160:         this.directories.clear();",
          "161:         this.directories.addAll(directories);",
          "162:         return this;",
          "163:     }",
          "165:     public Formatter addDirectory(String directory) {",
          "166:         this.directories.add(directory);",
          "167:         return this;",
          "168:     }",
          "170:     public Formatter setReleaseVersion(MetadataVersion releaseVersion) {",
          "171:         this.releaseVersion = releaseVersion;",
          "172:         return this;",
          "173:     }",
          "175:     public Formatter setFeatureLevel(String featureName, Short level) {",
          "176:         this.featureLevels.put(featureName, level);",
          "177:         return this;",
          "178:     }",
          "180:     public Formatter setUnstableFeatureVersionsEnabled(boolean unstableFeatureVersionsEnabled) {",
          "181:         this.unstableFeatureVersionsEnabled = unstableFeatureVersionsEnabled;",
          "182:         return this;",
          "183:     }",
          "185:     public Formatter setIgnoreFormatted(boolean ignoreFormatted) {",
          "186:         this.ignoreFormatted = ignoreFormatted;",
          "187:         return this;",
          "188:     }",
          "190:     public Formatter setScramArguments(List<String> scramArguments) {",
          "191:         this.scramArguments = scramArguments;",
          "192:         return this;",
          "193:     }",
          "195:     public Formatter setControllerListenerName(String controllerListenerName) {",
          "196:         this.controllerListenerName = controllerListenerName;",
          "197:         return this;",
          "198:     }",
          "200:     public Formatter setMetadataLogDirectory(String metadataLogDirectory) {",
          "201:         this.metadataLogDirectory = metadataLogDirectory;",
          "202:         return this;",
          "203:     }",
          "205:     public Formatter setInitialVoters(DynamicVoters initialControllers) {",
          "206:         this.initialControllers = Optional.of(initialControllers);",
          "207:         return this;",
          "208:     }",
          "210:     boolean hasDynamicQuorum() {",
          "211:         if (initialControllers.isPresent()) {",
          "212:             return true;",
          "213:         }",
          "214:         return false;",
          "215:     }",
          "217:     public BootstrapMetadata bootstrapMetadata() {",
          "218:         return bootstrapMetadata;",
          "219:     }",
          "221:     public void run() throws Exception {",
          "222:         if (nodeId < 0) {",
          "223:             throw new RuntimeException(\"You must specify a valid non-negative node ID.\");",
          "224:         }",
          "225:         if (clusterId == null) {",
          "226:             throw new FormatterException(\"You must specify the cluster id.\");",
          "227:         }",
          "228:         if (directories.isEmpty()) {",
          "229:             throw new FormatterException(\"You must specify at least one directory to format\");",
          "230:         }",
          "231:         if (controllerListenerName == null) {",
          "232:             throw new FormatterException(\"You must specify the name of the initial controller listener.\");",
          "233:         }",
          "234:         if (metadataLogDirectory == null) {",
          "235:             throw new FormatterException(\"You must specify the metadata log directory.\");",
          "236:         }",
          "237:         if (!directories.contains(metadataLogDirectory)) {",
          "238:             throw new FormatterException(\"The specified metadata log directory, \" + metadataLogDirectory +",
          "239:                     \" was not one of the given directories: \" + directories);",
          "240:         }",
          "241:         releaseVersion = calculateEffectiveReleaseVersion();",
          "242:         featureLevels = calculateEffectiveFeatureLevels();",
          "243:         this.bootstrapMetadata = calculateBootstrapMetadata();",
          "244:         doFormat(bootstrapMetadata);",
          "245:     }",
          "253:     MetadataVersion calculateEffectiveReleaseVersion() {",
          "254:         if (featureLevels.containsKey(MetadataVersion.FEATURE_NAME)) {",
          "255:             if (releaseVersion != null) {",
          "256:                 throw new FormatterException(\"Use --release-version instead of \" +",
          "257:                     \"--feature \" + MetadataVersion.FEATURE_NAME + \"=X to avoid ambiguity.\");",
          "258:             }",
          "259:             return verifyReleaseVersion(MetadataVersion.fromFeatureLevel(",
          "260:                     featureLevels.get(MetadataVersion.FEATURE_NAME)));",
          "261:         } else if (releaseVersion != null) {",
          "262:             return verifyReleaseVersion(releaseVersion);",
          "263:         } else if (unstableFeatureVersionsEnabled) {",
          "264:             return MetadataVersion.latestTesting();",
          "265:         } else {",
          "266:             return MetadataVersion.latestProduction();",
          "267:         }",
          "268:     }",
          "270:     MetadataVersion verifyReleaseVersion(MetadataVersion metadataVersion) {",
          "271:         if (!metadataVersion.isKRaftSupported()) {",
          "272:             throw new FormatterException(MetadataVersion.FEATURE_NAME + \" \" + metadataVersion +",
          "273:                 \" is too old to be supported.\");",
          "274:         }",
          "275:         if (!unstableFeatureVersionsEnabled) {",
          "276:             if (!metadataVersion.isProduction()) {",
          "277:                 throw new FormatterException(MetadataVersion.FEATURE_NAME + \" \" + metadataVersion +",
          "278:                         \" is not yet stable.\");",
          "279:             }",
          "280:         }",
          "281:         return metadataVersion;",
          "282:     }",
          "284:     Map<String, Short> calculateEffectiveFeatureLevels() {",
          "285:         Map<String, Features> nameToSupportedFeature = new TreeMap<>();",
          "286:         supportedFeatures.forEach(feature -> nameToSupportedFeature.put(feature.featureName(), feature));",
          "287:         Map<String, Short> newFeatureLevels = new TreeMap<>();",
          "289:         for (Map.Entry<String, Short> entry : featureLevels.entrySet()) {",
          "290:             String featureName = entry.getKey();",
          "291:             short level = entry.getValue();",
          "292:             if (!featureName.equals(MetadataVersion.FEATURE_NAME)) {",
          "293:                 if (!nameToSupportedFeature.containsKey(featureName)) {",
          "294:                     throw new FormatterException(\"Unsupported feature: \" + featureName +",
          "295:                             \". Supported features are: \" + nameToSupportedFeature.keySet().stream().",
          "296:                             collect(Collectors.joining(\", \")));",
          "297:                 }",
          "298:             }",
          "299:             newFeatureLevels.put(featureName, level);",
          "300:         }",
          "301:         newFeatureLevels.put(MetadataVersion.FEATURE_NAME, releaseVersion.featureLevel());",
          "303:         supportedFeatures.forEach(supportedFeature -> {",
          "304:             if (supportedFeature.featureName().equals(KRaftVersion.FEATURE_NAME)) {",
          "305:                 newFeatureLevels.put(KRaftVersion.FEATURE_NAME, effectiveKRaftFeatureLevel(",
          "306:                     Optional.ofNullable(newFeatureLevels.get(KRaftVersion.FEATURE_NAME))));",
          "307:             } else if (!newFeatureLevels.containsKey(supportedFeature.featureName())) {",
          "308:                 newFeatureLevels.put(supportedFeature.featureName(),",
          "309:                     supportedFeature.defaultValue(releaseVersion));",
          "310:             }",
          "311:         });",
          "314:         for (Map.Entry<String, Short> entry : newFeatureLevels.entrySet()) {",
          "315:             String featureName = entry.getKey();",
          "316:             if (!featureName.equals(MetadataVersion.FEATURE_NAME)) {",
          "317:                 short level = entry.getValue();",
          "318:                 Features supportedFeature = nameToSupportedFeature.get(featureName);",
          "319:                 FeatureVersion featureVersion =",
          "320:                     supportedFeature.fromFeatureLevel(level, unstableFeatureVersionsEnabled);",
          "321:                 Features.validateVersion(featureVersion, newFeatureLevels);",
          "322:             }",
          "323:         }",
          "324:         return newFeatureLevels;",
          "325:     }",
          "336:     private short effectiveKRaftFeatureLevel(Optional<Short> configuredKRaftVersionLevel) {",
          "337:         if (configuredKRaftVersionLevel.isPresent()) {",
          "338:             if (configuredKRaftVersionLevel.get() == 0) {",
          "339:                 if (hasDynamicQuorum()) {",
          "340:                     throw new FormatterException(\"Cannot set kraft.version to \" +",
          "341:                         configuredKRaftVersionLevel.get() + \" if KIP-853 configuration is present. \" +",
          "342:                             \"Try removing the --feature flag for kraft.version.\");",
          "343:                 }",
          "344:             } else {",
          "345:                 if (!hasDynamicQuorum()) {",
          "346:                     throw new FormatterException(\"Cannot set kraft.version to \" +",
          "347:                         configuredKRaftVersionLevel.get() + \" unless KIP-853 configuration is present. \" +",
          "348:                             \"Try removing the --feature flag for kraft.version.\");",
          "349:                 }",
          "350:             }",
          "351:             return configuredKRaftVersionLevel.get();",
          "352:         } else if (hasDynamicQuorum()) {",
          "353:             return KRAFT_VERSION_1.featureLevel();",
          "354:         } else {",
          "355:             return KRAFT_VERSION_0.featureLevel();",
          "356:         }",
          "357:     }",
          "359:     BootstrapMetadata calculateBootstrapMetadata() throws  Exception {",
          "360:         BootstrapMetadata bootstrapMetadata = BootstrapMetadata.",
          "361:             fromVersions(releaseVersion, featureLevels, \"format command\");",
          "362:         List<ApiMessageAndVersion> bootstrapRecords = new ArrayList<>(bootstrapMetadata.records());",
          "363:         if (!scramArguments.isEmpty()) {",
          "364:             if (!releaseVersion.isScramSupported()) {",
          "365:                 throw new FormatterException(\"SCRAM is only supported in \" + MetadataVersion.FEATURE_NAME +",
          "366:                         \" \" + MetadataVersion.IBP_3_5_IV2 + \" or later.\");",
          "367:             }",
          "368:             bootstrapRecords.addAll(ScramParser.parse(scramArguments));",
          "369:         }",
          "370:         return BootstrapMetadata.fromRecords(bootstrapRecords, \"format command\");",
          "371:     }",
          "373:     void doFormat(BootstrapMetadata bootstrapMetadata) throws Exception {",
          "374:         MetaProperties metaProperties = new MetaProperties.Builder().",
          "375:                 setVersion(MetaPropertiesVersion.V1).",
          "376:                 setClusterId(clusterId).",
          "377:                 setNodeId(nodeId).",
          "378:                 build();",
          "379:         MetaPropertiesEnsemble.Loader loader = new MetaPropertiesEnsemble.Loader();",
          "380:         loader.addLogDirs(directories);",
          "381:         MetaPropertiesEnsemble ensemble = loader.load();",
          "382:         ensemble.verify(Optional.of(clusterId),",
          "383:                 OptionalInt.of(nodeId),",
          "384:                 EnumSet.noneOf(MetaPropertiesEnsemble.VerificationFlag.class));",
          "385:         MetaPropertiesEnsemble.Copier copier = new MetaPropertiesEnsemble.Copier(ensemble);",
          "386:         if (!(ignoreFormatted || copier.logDirProps().isEmpty())) {",
          "387:             String firstLogDir = copier.logDirProps().keySet().iterator().next();",
          "388:             throw new FormatterException(\"Log directory \" + firstLogDir + \" is already formatted. \" +",
          "389:                 \"Use --ignore-formatted to ignore this directory and format the others.\");",
          "390:         }",
          "391:         if (!copier.errorLogDirs().isEmpty()) {",
          "392:             copier.errorLogDirs().forEach(errorLogDir ->",
          "393:                 printStream.println(\"I/O error trying to read log directory \" + errorLogDir + \". Ignoring...\"));",
          "394:             if (ensemble.emptyLogDirs().isEmpty() && copier.logDirProps().isEmpty()) {",
          "395:                 throw new FormatterException(\"No available log directories to format.\");",
          "396:             }",
          "397:         }",
          "398:         if (ensemble.emptyLogDirs().isEmpty()) {",
          "399:             printStream.println(\"All of the log directories are already formatted.\");",
          "400:         } else {",
          "401:             Map<String, DirectoryType> directoryTypes = new HashMap<>();",
          "402:             for (String emptyLogDir : ensemble.emptyLogDirs()) {",
          "403:                 DirectoryType directoryType = DirectoryType.calculate(emptyLogDir,",
          "404:                     metadataLogDirectory,",
          "405:                     nodeId,",
          "406:                     initialControllers);",
          "407:                 directoryTypes.put(emptyLogDir, directoryType);",
          "408:                 Uuid directoryId;",
          "409:                 if (directoryType == DirectoryType.DYNAMIC_METADATA_VOTER_DIRECTORY) {",
          "410:                     directoryId = initialControllers.get().voters().get(nodeId).directoryId();",
          "411:                 } else {",
          "412:                     directoryId = copier.generateValidDirectoryId();",
          "413:                 }",
          "414:                 copier.setLogDirProps(emptyLogDir, new MetaProperties.Builder(metaProperties).",
          "415:                     setDirectoryId(directoryId).",
          "416:                     build());",
          "417:             }",
          "418:             copier.setPreWriteHandler((writeLogDir, __, ____) -> {",
          "419:                 printStream.printf(\"Formatting %s %s with %s %s.%n\",",
          "420:                     directoryTypes.get(writeLogDir).description(), writeLogDir,",
          "421:                     MetadataVersion.FEATURE_NAME, releaseVersion);",
          "422:                 Files.createDirectories(Paths.get(writeLogDir));",
          "423:                 BootstrapDirectory bootstrapDirectory = new BootstrapDirectory(writeLogDir, Optional.empty());",
          "424:                 bootstrapDirectory.writeBinaryFile(bootstrapMetadata);",
          "425:                 if (directoryTypes.get(writeLogDir).isDynamicMetadataDirectory()) {",
          "426:                     writeDynamicQuorumSnapshot(writeLogDir,",
          "427:                         initialControllers.get(),",
          "428:                         featureLevels.get(KRaftVersion.FEATURE_NAME),",
          "429:                         controllerListenerName);",
          "430:                 }",
          "431:             });",
          "432:             copier.setWriteErrorHandler((errorLogDir, e) -> {",
          "433:                 throw new FormatterException(\"Error while writing meta.properties file \" +",
          "434:                         errorLogDir + \": \" + e);",
          "435:             });",
          "436:             copier.writeLogDirChanges();",
          "437:         }",
          "438:     }",
          "440:     enum DirectoryType {",
          "441:         LOG_DIRECTORY,",
          "442:         STATIC_METADATA_DIRECTORY,",
          "443:         DYNAMIC_METADATA_NON_VOTER_DIRECTORY,",
          "444:         DYNAMIC_METADATA_VOTER_DIRECTORY;",
          "446:         String description() {",
          "447:             switch (this) {",
          "448:                 case LOG_DIRECTORY:",
          "449:                     return \"data directory\";",
          "450:                 case STATIC_METADATA_DIRECTORY:",
          "451:                     return \"metadata directory\";",
          "452:                 case DYNAMIC_METADATA_NON_VOTER_DIRECTORY:",
          "453:                     return \"dynamic metadata directory\";",
          "454:                 case DYNAMIC_METADATA_VOTER_DIRECTORY:",
          "455:                     return \"dynamic metadata voter directory\";",
          "456:             }",
          "457:             throw new RuntimeException(\"invalid enum type \" + this);",
          "458:         }",
          "460:         boolean isDynamicMetadataDirectory() {",
          "461:             return this == DYNAMIC_METADATA_NON_VOTER_DIRECTORY ||",
          "462:                 this == DYNAMIC_METADATA_VOTER_DIRECTORY;",
          "463:         }",
          "465:         static DirectoryType calculate(",
          "466:             String logDir,",
          "467:             String metadataLogDirectory,",
          "468:             int nodeId,",
          "469:             Optional<DynamicVoters> initialControllers",
          "470:         ) {",
          "471:             if (!logDir.equals(metadataLogDirectory)) {",
          "472:                 return LOG_DIRECTORY;",
          "473:             } else if (!initialControllers.isPresent()) {",
          "474:                 return STATIC_METADATA_DIRECTORY;",
          "475:             } else if (initialControllers.get().voters().containsKey(nodeId)) {",
          "476:                 return DYNAMIC_METADATA_VOTER_DIRECTORY;",
          "477:             } else {",
          "478:                 return DYNAMIC_METADATA_NON_VOTER_DIRECTORY;",
          "479:             }",
          "480:         }",
          "481:     }",
          "483:     static void writeDynamicQuorumSnapshot(",
          "484:         String writeLogDir,",
          "485:         DynamicVoters initialControllers,",
          "486:         short kraftVersion,",
          "487:         String controllerListenerName",
          "488:     ) {",
          "489:         File parentDir = new File(writeLogDir);",
          "490:         File clusterMetadataDirectory = new File(parentDir, String.format(\"%s-%d\",",
          "491:                 CLUSTER_METADATA_TOPIC_PARTITION.topic(),",
          "492:                 CLUSTER_METADATA_TOPIC_PARTITION.partition()));",
          "493:         VoterSet voterSet = initialControllers.toVoterSet(controllerListenerName);",
          "494:         RecordsSnapshotWriter.Builder builder = new RecordsSnapshotWriter.Builder().",
          "495:             setLastContainedLogTimestamp(Time.SYSTEM.milliseconds()).",
          "496:             setMaxBatchSize(KafkaRaftClient.MAX_BATCH_SIZE_BYTES).",
          "497:             setRawSnapshotWriter(FileRawSnapshotWriter.create(",
          "498:                 clusterMetadataDirectory.toPath(),",
          "499:                 Snapshots.BOOTSTRAP_SNAPSHOT_ID)).",
          "500:             setKraftVersion(KRaftVersion.fromFeatureLevel(kraftVersion)).",
          "501:             setVoterSet(Optional.of(voterSet));",
          "502:         try (RecordsSnapshotWriter writer = builder.build(new MetadataRecordSerde())) {",
          "503:             writer.freeze();",
          "504:         }",
          "505:     }",
          "506: }",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/storage/FormatterException.java||metadata/src/main/java/org/apache/kafka/metadata/storage/FormatterException.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/storage/FormatterException.java -> metadata/src/main/java/org/apache/kafka/metadata/storage/FormatterException.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.metadata.storage;",
          "20: public class FormatterException extends RuntimeException {",
          "21:     public FormatterException(String what) {",
          "22:         super(what);",
          "23:     }",
          "25:     public FormatterException(String what, Exception cause) {",
          "26:         super(what, cause);",
          "27:     }",
          "28: }",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/storage/ScramParser.java||metadata/src/main/java/org/apache/kafka/metadata/storage/ScramParser.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/storage/ScramParser.java -> metadata/src/main/java/org/apache/kafka/metadata/storage/ScramParser.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.metadata.storage;",
          "20: import org.apache.kafka.common.metadata.UserScramCredentialRecord;",
          "21: import org.apache.kafka.common.security.scram.internals.ScramFormatter;",
          "22: import org.apache.kafka.common.security.scram.internals.ScramMechanism;",
          "23: import org.apache.kafka.server.common.ApiMessageAndVersion;",
          "25: import java.util.AbstractMap;",
          "26: import java.util.ArrayList;",
          "27: import java.util.Arrays;",
          "28: import java.util.Base64;",
          "29: import java.util.List;",
          "30: import java.util.Map;",
          "31: import java.util.Map.Entry;",
          "32: import java.util.Objects;",
          "33: import java.util.Optional;",
          "34: import java.util.OptionalInt;",
          "35: import java.util.TreeMap;",
          "36: import java.util.stream.Collectors;",
          "38: public class ScramParser {",
          "39:     static List<ApiMessageAndVersion> parse(List<String> arguments) throws Exception {",
          "40:         List<ApiMessageAndVersion> records = new ArrayList<>();",
          "41:         for (String argument : arguments) {",
          "42:             Entry<ScramMechanism, String> entry = parsePerMechanismArgument(argument);",
          "43:             PerMechanismData data = new PerMechanismData(entry.getKey(), entry.getValue());",
          "44:             records.add(new ApiMessageAndVersion(data.toRecord(), (short) 0));",
          "45:         }",
          "46:         return records;",
          "47:     }",
          "49:     static Entry<ScramMechanism, String> parsePerMechanismArgument(String input) {",
          "50:         input = input.trim();",
          "51:         int equalsIndex = input.indexOf('=');",
          "52:         if (equalsIndex < 0) {",
          "53:             throw new FormatterException(\"Failed to find equals sign in SCRAM \" +",
          "54:                     \"argument '\" + input + \"'\");",
          "55:         }",
          "56:         String mechanismString = input.substring(0, equalsIndex);",
          "57:         String configString = input.substring(equalsIndex + 1);",
          "58:         ScramMechanism mechanism = ScramMechanism.forMechanismName(mechanismString);",
          "59:         if (mechanism == null) {",
          "60:             throw new FormatterException(\"The add-scram mechanism \" + mechanismString +",
          "61:                     \" is not supported.\");",
          "62:         }",
          "63:         if (!configString.startsWith(\"[\")) {",
          "64:             throw new FormatterException(\"Expected configuration string to start with [\");",
          "65:         }",
          "66:         if (!configString.endsWith(\"]\")) {",
          "67:             throw new FormatterException(\"Expected configuration string to end with ]\");",
          "68:         }",
          "69:         return new AbstractMap.SimpleImmutableEntry<>(mechanism,",
          "70:             configString.substring(1, configString.length() - 1));",
          "71:     }",
          "73:     static final class PerMechanismData {",
          "74:         private final ScramMechanism mechanism;",
          "75:         private final String configuredName;",
          "76:         private final Optional<byte[]> configuredSalt;",
          "77:         private final OptionalInt configuredIterations;",
          "78:         private final Optional<String> configuredPasswordString;",
          "79:         private final Optional<byte[]> configuredSaltedPassword;",
          "81:         PerMechanismData(",
          "82:             ScramMechanism mechanism,",
          "83:             String configuredName,",
          "84:             Optional<byte[]> configuredSalt,",
          "85:             OptionalInt configuredIterations,",
          "86:             Optional<String> configuredPasswordString,",
          "87:             Optional<byte[]> configuredSaltedPassword",
          "88:         ) {",
          "89:             this.mechanism = mechanism;",
          "90:             this.configuredName = configuredName;",
          "91:             this.configuredSalt = configuredSalt;",
          "92:             this.configuredIterations = configuredIterations;",
          "93:             this.configuredPasswordString = configuredPasswordString;",
          "94:             this.configuredSaltedPassword = configuredSaltedPassword;",
          "95:         }",
          "97:         PerMechanismData(",
          "98:             ScramMechanism mechanism,",
          "99:             String configString",
          "100:         ) {",
          "101:             this.mechanism = mechanism;",
          "102:             String[] configComponents = configString.split(\",\");",
          "103:             Map<String, String> components = new TreeMap<>();",
          "104:             for (String configComponent : configComponents) {",
          "105:                 Entry<String, String> entry = splitTrimmedConfigStringComponent(configComponent);",
          "106:                 components.put(entry.getKey(), entry.getValue());",
          "107:             }",
          "108:             this.configuredName = components.remove(\"name\");",
          "109:             if (this.configuredName == null) {",
          "110:                 throw new FormatterException(\"You must supply 'name' to add-scram\");",
          "111:             }",
          "113:             String saltString = components.remove(\"salt\");",
          "114:             if (saltString == null) {",
          "115:                 this.configuredSalt = Optional.empty();",
          "116:             } else {",
          "117:                 try {",
          "118:                     this.configuredSalt = Optional.of(Base64.getDecoder().decode(saltString));",
          "119:                 } catch (IllegalArgumentException e) {",
          "120:                     throw new FormatterException(\"Failed to decode given salt: \" + saltString, e);",
          "121:                 }",
          "122:             }",
          "123:             String iterationsString = components.remove(\"iterations\");",
          "124:             if (iterationsString == null) {",
          "125:                 this.configuredIterations = OptionalInt.empty();",
          "126:             } else {",
          "127:                 try {",
          "128:                     this.configuredIterations = OptionalInt.of(Integer.parseInt(iterationsString));",
          "129:                 } catch (NumberFormatException e) {",
          "130:                     throw new FormatterException(\"Failed to parse iterations count: \" + iterationsString, e);",
          "131:                 }",
          "132:             }",
          "133:             String passwordString = components.remove(\"password\");",
          "134:             String saltedPasswordString = components.remove(\"saltedpassword\");",
          "135:             if (passwordString == null) {",
          "136:                 if (saltedPasswordString == null) {",
          "137:                     throw new FormatterException(\"You must supply one of 'password' or 'saltedpassword' \" +",
          "138:                             \"to add-scram\");",
          "139:                 } else if (!configuredSalt.isPresent()) {",
          "140:                     throw new FormatterException(\"You must supply 'salt' with 'saltedpassword' to add-scram\");",
          "141:                 }",
          "142:                 try {",
          "143:                     this.configuredPasswordString = Optional.empty();",
          "144:                     this.configuredSaltedPassword = Optional.of(Base64.getDecoder().decode(saltedPasswordString));",
          "145:                 } catch (IllegalArgumentException e) {",
          "146:                     throw new FormatterException(\"Failed to decode given saltedPassword: \" +",
          "147:                             saltedPasswordString, e);",
          "148:                 }",
          "149:             } else {",
          "150:                 this.configuredPasswordString = Optional.of(passwordString);",
          "151:                 this.configuredSaltedPassword = Optional.empty();",
          "152:             }",
          "153:             if (!components.isEmpty()) {",
          "154:                 throw new FormatterException(\"Unknown SCRAM configurations: \" +",
          "155:                     components.keySet().stream().collect(Collectors.joining(\", \")));",
          "156:             }",
          "157:         }",
          "159:         byte[] salt() throws Exception {",
          "160:             if (configuredSalt.isPresent()) {",
          "161:                 return configuredSalt.get();",
          "162:             }",
          "163:             return new ScramFormatter(mechanism).secureRandomBytes();",
          "164:         }",
          "166:         int iterations() {",
          "167:             if (configuredIterations.isPresent()) {",
          "168:                 return configuredIterations.getAsInt();",
          "169:             }",
          "170:             return 4096;",
          "171:         }",
          "173:         byte[] saltedPassword(byte[] salt, int iterations) throws Exception {",
          "174:             if (configuredSaltedPassword.isPresent()) {",
          "175:                 return configuredSaltedPassword.get();",
          "176:             }",
          "177:             return new ScramFormatter(mechanism).saltedPassword(",
          "178:                     configuredPasswordString.get(),",
          "179:                     salt,",
          "180:                     iterations);",
          "181:         }",
          "183:         UserScramCredentialRecord toRecord() throws Exception {",
          "184:             ScramFormatter formatter = new ScramFormatter(mechanism);",
          "185:             byte[] salt = salt();",
          "186:             int iterations = iterations();",
          "187:             if (iterations < mechanism.minIterations()) {",
          "188:                 throw new FormatterException(\"The 'iterations' value must be >= \" +",
          "189:                         mechanism.minIterations() + \" for add-scram using \" + mechanism);",
          "190:             }",
          "191:             if (iterations > mechanism.maxIterations()) {",
          "192:                 throw new FormatterException(\"The 'iterations' value must be <= \" +",
          "193:                         mechanism.maxIterations() + \" for add-scram using \" + mechanism);",
          "194:             }",
          "195:             byte[] saltedPassword = saltedPassword(salt, iterations);",
          "196:             return new UserScramCredentialRecord().",
          "197:                     setName(configuredName).",
          "198:                     setMechanism(mechanism.type()).",
          "199:                     setSalt(salt).",
          "200:                     setStoredKey(formatter.storedKey(formatter.clientKey(saltedPassword))).",
          "201:                     setServerKey(formatter.serverKey(saltedPassword)).",
          "202:                     setIterations(iterations);",
          "203:         }",
          "205:         @Override",
          "206:         public boolean equals(Object o) {",
          "207:             if (o == null || (!(o.getClass().equals(PerMechanismData.class)))) return false;",
          "208:             PerMechanismData other = (PerMechanismData) o;",
          "209:             return mechanism.equals(other.mechanism) &&",
          "210:                 configuredName.equals(other.configuredName) &&",
          "211:                 Arrays.equals(configuredSalt.orElseGet(() -> null),",
          "212:                     other.configuredSalt.orElseGet(() -> null)) &&",
          "213:                 configuredIterations.equals(other.configuredIterations) &&",
          "214:                 configuredPasswordString.equals(other.configuredPasswordString) &&",
          "215:                 Arrays.equals(configuredSaltedPassword.orElseGet(() -> null),",
          "216:                     other.configuredSaltedPassword.orElseGet(() -> null));",
          "217:         }",
          "219:         @Override",
          "220:         public int hashCode() {",
          "221:             return Objects.hash(mechanism,",
          "222:                 configuredName,",
          "223:                 configuredSalt,",
          "224:                 configuredIterations,",
          "225:                 configuredPasswordString,",
          "226:                 configuredSaltedPassword);",
          "227:         }",
          "229:         @Override",
          "230:         public String toString() {",
          "231:             return \"PerMechanismData\" +",
          "232:                 \"(mechanism=\" + mechanism +",
          "233:                 \", configuredName=\" + configuredName +",
          "234:                 \", configuredSalt=\" + configuredSalt.map(v -> Arrays.toString(v)) +",
          "235:                 \", configuredIterations=\" + configuredIterations +",
          "236:                 \", configuredPasswordString=\" + configuredPasswordString +",
          "237:                 \", configuredSaltedPassword=\" + configuredSaltedPassword.map(v -> Arrays.toString(v)) +",
          "238:                 \")\";",
          "239:         }",
          "240:     }",
          "242:     static Entry<String, String> splitTrimmedConfigStringComponent(String input) {",
          "243:         int i;",
          "244:         for (i = 0; i < input.length(); i++) {",
          "245:             if (input.charAt(i) == '=') {",
          "246:                 break;",
          "247:             }",
          "248:         }",
          "249:         if (i == input.length()) {",
          "250:             throw new FormatterException(\"No equals sign found in SCRAM component: \" + input);",
          "251:         }",
          "252:         String value = input.substring(i + 1);",
          "253:         if (value.length() >= 2) {",
          "254:             if (value.startsWith(\"\\\"\") && value.endsWith(\"\\\"\")) {",
          "255:                 value = value.substring(1, value.length() - 1);",
          "256:             }",
          "257:         }",
          "258:         return new AbstractMap.SimpleImmutableEntry<>(input.substring(0, i), value);",
          "259:     }",
          "260: }",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/metadata/storage/FormatterTest.java||metadata/src/test/java/org/apache/kafka/metadata/storage/FormatterTest.java": [
          "File: metadata/src/test/java/org/apache/kafka/metadata/storage/FormatterTest.java -> metadata/src/test/java/org/apache/kafka/metadata/storage/FormatterTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.metadata.storage;",
          "20: import org.apache.kafka.common.Uuid;",
          "21: import org.apache.kafka.common.metadata.FeatureLevelRecord;",
          "22: import org.apache.kafka.common.metadata.UserScramCredentialRecord;",
          "23: import org.apache.kafka.common.security.scram.internals.ScramFormatter;",
          "24: import org.apache.kafka.common.security.scram.internals.ScramMechanism;",
          "25: import org.apache.kafka.common.utils.Utils;",
          "26: import org.apache.kafka.metadata.bootstrap.BootstrapDirectory;",
          "27: import org.apache.kafka.metadata.bootstrap.BootstrapMetadata;",
          "28: import org.apache.kafka.metadata.properties.MetaProperties;",
          "29: import org.apache.kafka.metadata.properties.MetaPropertiesEnsemble;",
          "30: import org.apache.kafka.raft.DynamicVoters;",
          "31: import org.apache.kafka.server.common.ApiMessageAndVersion;",
          "32: import org.apache.kafka.server.common.Features;",
          "33: import org.apache.kafka.server.common.MetadataVersion;",
          "34: import org.apache.kafka.server.common.TestFeatureVersion;",
          "35: import org.apache.kafka.test.TestUtils;",
          "37: import org.junit.jupiter.api.Test;",
          "38: import org.junit.jupiter.api.Timeout;",
          "39: import org.junit.jupiter.params.ParameterizedTest;",
          "40: import org.junit.jupiter.params.provider.ValueSource;",
          "41: import org.slf4j.Logger;",
          "42: import org.slf4j.LoggerFactory;",
          "44: import java.io.ByteArrayOutputStream;",
          "45: import java.io.File;",
          "46: import java.io.IOException;",
          "47: import java.io.PrintStream;",
          "48: import java.util.ArrayList;",
          "49: import java.util.Arrays;",
          "50: import java.util.HashSet;",
          "51: import java.util.List;",
          "52: import java.util.Optional;",
          "53: import java.util.OptionalInt;",
          "54: import java.util.stream.Collectors;",
          "56: import static org.apache.kafka.metadata.storage.ScramParserTest.TEST_SALT;",
          "57: import static org.apache.kafka.metadata.storage.ScramParserTest.TEST_SALTED_PASSWORD;",
          "58: import static org.junit.jupiter.api.Assertions.assertEquals;",
          "59: import static org.junit.jupiter.api.Assertions.assertFalse;",
          "60: import static org.junit.jupiter.api.Assertions.assertNotEquals;",
          "61: import static org.junit.jupiter.api.Assertions.assertNotNull;",
          "62: import static org.junit.jupiter.api.Assertions.assertThrows;",
          "63: import static org.junit.jupiter.api.Assertions.assertTrue;",
          "65: @Timeout(value = 40)",
          "66: public class FormatterTest {",
          "67:     private static final Logger LOG = LoggerFactory.getLogger(FormatterTest.class);",
          "69:     private static final int DEFAULT_NODE_ID = 1;",
          "71:     private static final Uuid DEFAULT_CLUSTER_ID = Uuid.fromString(\"b3dGE68sQQKzfk80C_aLZw\");",
          "73:     static class TestEnv implements AutoCloseable {",
          "74:         final List<String> directories;",
          "76:         TestEnv(int numDirs) {",
          "77:             this.directories = new ArrayList<>(numDirs);",
          "78:             for (int i = 0; i < numDirs; i++) {",
          "79:                 this.directories.add(TestUtils.tempDirectory().getAbsolutePath());",
          "80:             }",
          "81:         }",
          "83:         FormatterContext newFormatter() {",
          "84:             Formatter formatter = new Formatter().",
          "85:                 setNodeId(DEFAULT_NODE_ID).",
          "86:                 setClusterId(DEFAULT_CLUSTER_ID.toString());",
          "87:             directories.forEach(d -> formatter.addDirectory(d));",
          "88:             formatter.setMetadataLogDirectory(directories.get(0));",
          "89:             return new FormatterContext(formatter);",
          "90:         }",
          "92:         String directory(int i) {",
          "93:             return this.directories.get(i);",
          "94:         }",
          "96:         void deleteDirectory(int i) throws IOException {",
          "97:             Utils.delete(new File(directories.get(i)));",
          "98:         }",
          "100:         @Override",
          "101:         public void close() throws Exception {",
          "102:             for (int i = 0; i < directories.size(); i++) {",
          "103:                 try {",
          "104:                     deleteDirectory(i);",
          "105:                 } catch (Exception e) {",
          "106:                     LOG.error(\"Error deleting directory \" + directories.get(i), e);",
          "107:                 }",
          "108:             }",
          "109:         }",
          "110:     }",
          "112:     static class FormatterContext {",
          "113:         final Formatter formatter;",
          "114:         final ByteArrayOutputStream stream;",
          "116:         FormatterContext(Formatter formatter) {",
          "117:             this.formatter = formatter;",
          "118:             this.stream = new ByteArrayOutputStream();",
          "119:             this.formatter.setPrintStream(new PrintStream(stream));",
          "120:             this.formatter.setControllerListenerName(\"CONTROLLER\");",
          "121:         }",
          "123:         String output() {",
          "124:             return stream.toString();",
          "125:         }",
          "127:         List<String> outputLines() {",
          "128:             return Arrays.asList(stream.toString().trim().split(\"\\\\r*\\\\n\"));",
          "129:         }",
          "130:     }",
          "132:     @ParameterizedTest",
          "133:     @ValueSource(ints = {1, 2, 3})",
          "134:     public void testDirectories(int numDirs) throws Exception {",
          "135:         try (TestEnv testEnv = new TestEnv(numDirs)) {",
          "136:             testEnv.newFormatter().formatter.run();",
          "137:             MetaPropertiesEnsemble ensemble = new MetaPropertiesEnsemble.Loader().",
          "138:                 addLogDirs(testEnv.directories).",
          "139:                 load();",
          "140:             assertEquals(OptionalInt.of(DEFAULT_NODE_ID), ensemble.nodeId());",
          "141:             assertEquals(Optional.of(DEFAULT_CLUSTER_ID.toString()), ensemble.clusterId());",
          "142:             assertEquals(new HashSet<>(testEnv.directories), ensemble.logDirProps().keySet());",
          "143:             BootstrapMetadata bootstrapMetadata =",
          "144:                 new BootstrapDirectory(testEnv.directory(0), Optional.empty()).read();",
          "145:             assertEquals(MetadataVersion.latestProduction(), bootstrapMetadata.metadataVersion());",
          "146:         }",
          "147:     }",
          "149:     @Test",
          "150:     public void testFormatterFailsOnAlreadyFormatted() throws Exception {",
          "151:         try (TestEnv testEnv = new TestEnv(1)) {",
          "152:             testEnv.newFormatter().formatter.run();",
          "153:             assertEquals(\"Log directory \" + testEnv.directory(0) + \" is already formatted. \" +",
          "154:                 \"Use --ignore-formatted to ignore this directory and format the others.\",",
          "155:                     assertThrows(FormatterException.class,",
          "156:                         () -> testEnv.newFormatter().formatter.run()).getMessage());",
          "157:         }",
          "158:     }",
          "160:     @Test",
          "161:     public void testFormatterFailsOnUnwritableDirectory() throws Exception {",
          "162:         try (TestEnv testEnv = new TestEnv(1)) {",
          "163:             new File(testEnv.directory(0)).setReadOnly();",
          "164:             FormatterContext formatter1 = testEnv.newFormatter();",
          "165:             String expectedPrefix = \"Error while writing meta.properties file\";",
          "166:             assertEquals(expectedPrefix,",
          "167:                 assertThrows(FormatterException.class,",
          "168:                     () -> formatter1.formatter.run()).",
          "169:                         getMessage().substring(0, expectedPrefix.length()));",
          "170:         }",
          "171:     }",
          "173:     @Test",
          "174:     public void testIgnoreFormatted() throws Exception {",
          "175:         try (TestEnv testEnv = new TestEnv(1)) {",
          "176:             FormatterContext formatter1 = testEnv.newFormatter();",
          "177:             formatter1.formatter.run();",
          "178:             assertEquals(\"Formatting metadata directory \" + testEnv.directory(0) +",
          "179:                 \" with metadata.version \" + MetadataVersion.latestProduction() + \".\",",
          "180:                     formatter1.output().trim());",
          "182:             FormatterContext formatter2 = testEnv.newFormatter();",
          "183:             formatter2.formatter.setIgnoreFormatted(true);",
          "184:             formatter2.formatter.run();",
          "185:             assertEquals(\"All of the log directories are already formatted.\",",
          "186:                 formatter2.output().trim());",
          "187:         }",
          "188:     }",
          "190:     @Test",
          "191:     public void testOneDirectoryFormattedAndOthersNotFormatted() throws Exception {",
          "192:         try (TestEnv testEnv = new TestEnv(2)) {",
          "193:             testEnv.newFormatter().formatter.setDirectories(Arrays.asList(testEnv.directory(0))).run();",
          "194:             assertEquals(\"Log directory \" + testEnv.directory(0) + \" is already formatted. \" +",
          "195:                 \"Use --ignore-formatted to ignore this directory and format the others.\",",
          "196:                     assertThrows(FormatterException.class,",
          "197:                         () -> testEnv.newFormatter().formatter.run()).getMessage());",
          "198:         }",
          "199:     }",
          "201:     @Test",
          "202:     public void testOneDirectoryFormattedAndOthersNotFormattedWithIgnoreFormatted() throws Exception {",
          "203:         try (TestEnv testEnv = new TestEnv(2)) {",
          "204:             testEnv.newFormatter().formatter.setDirectories(Arrays.asList(testEnv.directory(0))).run();",
          "206:             FormatterContext formatter2 = testEnv.newFormatter();",
          "207:             formatter2.formatter.setIgnoreFormatted(true);",
          "208:             formatter2.formatter.run();",
          "209:             assertEquals(\"Formatting data directory \" + testEnv.directory(1) + \" with metadata.version \" +",
          "210:                 MetadataVersion.latestProduction() + \".\",",
          "211:                     formatter2.output().trim());",
          "212:         }",
          "213:     }",
          "215:     @Test",
          "216:     public void testFormatWithOlderReleaseVersion() throws Exception {",
          "217:         try (TestEnv testEnv = new TestEnv(1)) {",
          "218:             FormatterContext formatter1 = testEnv.newFormatter();",
          "219:             formatter1.formatter.setReleaseVersion(MetadataVersion.IBP_3_5_IV0);",
          "220:             formatter1.formatter.run();",
          "221:             assertEquals(\"Formatting metadata directory \" + testEnv.directory(0) +",
          "222:                 \" with metadata.version \" + MetadataVersion.IBP_3_5_IV0 + \".\",",
          "223:                     formatter1.output().trim());",
          "224:             BootstrapMetadata bootstrapMetadata =",
          "225:                 new BootstrapDirectory(testEnv.directory(0), Optional.empty()).read();",
          "226:             assertEquals(MetadataVersion.IBP_3_5_IV0, bootstrapMetadata.metadataVersion());",
          "227:             assertEquals(1, bootstrapMetadata.records().size());",
          "228:         }",
          "229:     }",
          "231:     @Test",
          "232:     public void testFormatWithUnstableReleaseVersionFailsWithoutEnableUnstable() throws Exception {",
          "233:         try (TestEnv testEnv = new TestEnv(1)) {",
          "234:             FormatterContext formatter1 = testEnv.newFormatter();",
          "235:             formatter1.formatter.setReleaseVersion(MetadataVersion.latestTesting());",
          "236:             assertEquals(\"metadata.version \" + MetadataVersion.latestTesting() + \" is not yet stable.\",",
          "237:                 assertThrows(FormatterException.class, () -> formatter1.formatter.run()).getMessage());",
          "238:         }",
          "239:     }",
          "241:     @Test",
          "242:     public void testFormatWithUnstableReleaseVersion() throws Exception {",
          "243:         try (TestEnv testEnv = new TestEnv(1)) {",
          "244:             FormatterContext formatter1 = testEnv.newFormatter();",
          "245:             formatter1.formatter.setReleaseVersion(MetadataVersion.latestTesting());",
          "246:             formatter1.formatter.setUnstableFeatureVersionsEnabled(true);",
          "247:             formatter1.formatter.run();",
          "248:             assertEquals(\"Formatting metadata directory \" + testEnv.directory(0) +",
          "249:                 \" with metadata.version \" + MetadataVersion.latestTesting() + \".\",",
          "250:                     formatter1.output().trim());",
          "251:             BootstrapMetadata bootstrapMetadata =",
          "252:                     new BootstrapDirectory(testEnv.directory(0), Optional.empty()).read();",
          "253:             assertEquals(MetadataVersion.latestTesting(), bootstrapMetadata.metadataVersion());",
          "254:         }",
          "255:     }",
          "257:     @Test",
          "258:     public void testFormattingCreatesLogDirId() throws Exception {",
          "259:         try (TestEnv testEnv = new TestEnv(1)) {",
          "260:             FormatterContext formatter1 = testEnv.newFormatter();",
          "261:             formatter1.formatter.run();",
          "262:             MetaPropertiesEnsemble ensemble = new MetaPropertiesEnsemble.Loader().",
          "263:                 addLogDirs(testEnv.directories).",
          "264:                 load();",
          "265:             MetaProperties logDirProps = ensemble.logDirProps().get(testEnv.directory(0));",
          "266:             assertNotNull(logDirProps);",
          "267:             assertTrue(logDirProps.directoryId().isPresent());",
          "268:         }",
          "269:     }",
          "271:     @Test",
          "272:     public void testFormatWithScramFailsOnUnsupportedReleaseVersions() throws Exception {",
          "273:         try (TestEnv testEnv = new TestEnv(1)) {",
          "274:             FormatterContext formatter1 = testEnv.newFormatter();",
          "275:             formatter1.formatter.setReleaseVersion(MetadataVersion.IBP_3_4_IV0);",
          "276:             formatter1.formatter.setScramArguments(Arrays.asList(",
          "277:                 \"SCRAM-SHA-256=[name=alice,salt=\\\"MWx2NHBkbnc0ZndxN25vdGN4bTB5eTFrN3E=\\\",\" +",
          "278:                     \"saltedpassword=\\\"mT0yyUUxnlJaC99HXgRTSYlbuqa4FSGtJCJfTMvjYCE=\\\"]\",",
          "279:                 \"SCRAM-SHA-512=[name=alice,salt=\\\"MWx2NHBkbnc0ZndxN25vdGN4bTB5eTFrN3E=\\\",\" +",
          "280:                     \"saltedpassword=\\\"mT0yyUUxnlJaC99HXgRTSYlbuqa4FSGtJCJfTMvjYCE=\\\"]\"));",
          "281:             assertEquals(\"SCRAM is only supported in metadata.version 3.5-IV2 or later.\",",
          "282:                 assertThrows(FormatterException.class,",
          "283:                     () -> formatter1.formatter.run()).getMessage());",
          "284:         }",
          "285:     }",
          "287:     @Test",
          "288:     public void testFormatWithScram() throws Exception {",
          "289:         try (TestEnv testEnv = new TestEnv(1)) {",
          "290:             FormatterContext formatter1 = testEnv.newFormatter();",
          "291:             formatter1.formatter.setReleaseVersion(MetadataVersion.IBP_3_8_IV0);",
          "292:             formatter1.formatter.setScramArguments(Arrays.asList(",
          "293:                 \"SCRAM-SHA-256=[name=alice,salt=\\\"MWx2NHBkbnc0ZndxN25vdGN4bTB5eTFrN3E=\\\",\" +",
          "294:                     \"saltedpassword=\\\"mT0yyUUxnlJaC99HXgRTSYlbuqa4FSGtJCJfTMvjYCE=\\\"]\",",
          "295:                 \"SCRAM-SHA-512=[name=alice,salt=\\\"MWx2NHBkbnc0ZndxN25vdGN4bTB5eTFrN3E=\\\",\" +",
          "296:                     \"saltedpassword=\\\"mT0yyUUxnlJaC99HXgRTSYlbuqa4FSGtJCJfTMvjYCE=\\\"]\"));",
          "297:             formatter1.formatter.run();",
          "298:             assertEquals(\"Formatting metadata directory \" + testEnv.directory(0) +",
          "299:                 \" with metadata.version \" + MetadataVersion.IBP_3_8_IV0 + \".\",",
          "300:                     formatter1.output().trim());",
          "301:             BootstrapMetadata bootstrapMetadata =",
          "302:                 new BootstrapDirectory(testEnv.directory(0), Optional.empty()).read();",
          "303:             assertEquals(MetadataVersion.IBP_3_8_IV0, bootstrapMetadata.metadataVersion());",
          "304:             List<ApiMessageAndVersion> scramRecords = bootstrapMetadata.records().stream().",
          "305:                 filter(r -> r.message() instanceof UserScramCredentialRecord).",
          "306:                     collect(Collectors.toList());",
          "307:             ScramFormatter scram256 = new ScramFormatter(ScramMechanism.SCRAM_SHA_256);",
          "308:             ScramFormatter scram512 = new ScramFormatter(ScramMechanism.SCRAM_SHA_512);",
          "309:             assertEquals(Arrays.asList(",
          "310:                 new ApiMessageAndVersion(new UserScramCredentialRecord().",
          "311:                     setName(\"alice\").",
          "312:                     setMechanism(ScramMechanism.SCRAM_SHA_256.type()).",
          "313:                     setSalt(TEST_SALT).",
          "314:                     setStoredKey(scram256.storedKey(scram256.clientKey(TEST_SALTED_PASSWORD))).",
          "315:                     setServerKey(scram256.serverKey(TEST_SALTED_PASSWORD)).",
          "316:                     setIterations(4096), (short) 0),",
          "317:                 new ApiMessageAndVersion(new UserScramCredentialRecord().",
          "318:                     setName(\"alice\").",
          "319:                     setMechanism(ScramMechanism.SCRAM_SHA_512.type()).",
          "320:                     setSalt(TEST_SALT).",
          "321:                     setStoredKey(scram512.storedKey(scram512.clientKey(TEST_SALTED_PASSWORD))).",
          "322:                     setServerKey(scram512.serverKey(TEST_SALTED_PASSWORD)).",
          "323:                     setIterations(4096), (short) 0)),",
          "324:                 scramRecords);",
          "325:         }",
          "326:     }",
          "328:     @ParameterizedTest",
          "329:     @ValueSource(shorts = {0, 1})",
          "330:     public void testFeatureFlag(short version) throws Exception {",
          "331:         try (TestEnv testEnv = new TestEnv(1)) {",
          "332:             FormatterContext formatter1 = testEnv.newFormatter();",
          "333:             formatter1.formatter.setSupportedFeatures(Arrays.asList(Features.values()));",
          "334:             formatter1.formatter.setFeatureLevel(TestFeatureVersion.FEATURE_NAME, version);",
          "335:             formatter1.formatter.run();",
          "336:             BootstrapMetadata bootstrapMetadata =",
          "337:                 new BootstrapDirectory(testEnv.directory(0), Optional.empty()).read();",
          "338:             List<ApiMessageAndVersion> expected = new ArrayList<>();",
          "339:             expected.add(new ApiMessageAndVersion(new FeatureLevelRecord().",
          "340:                 setName(MetadataVersion.FEATURE_NAME).",
          "341:                 setFeatureLevel(MetadataVersion.latestProduction().featureLevel()),",
          "342:                     (short) 0));",
          "343:             if (version > 0) {",
          "344:                 expected.add(new ApiMessageAndVersion(new FeatureLevelRecord().",
          "345:                     setName(TestFeatureVersion.FEATURE_NAME).",
          "346:                     setFeatureLevel(version), (short) 0));",
          "347:             }",
          "348:             assertEquals(expected, bootstrapMetadata.records());",
          "349:         }",
          "350:     }",
          "352:     @Test",
          "353:     public void testInvalidFeatureFlag() throws Exception {",
          "354:         try (TestEnv testEnv = new TestEnv(2)) {",
          "355:             FormatterContext formatter1 = testEnv.newFormatter();",
          "356:             formatter1.formatter.setSupportedFeatures(Arrays.asList(Features.values()));",
          "357:             formatter1.formatter.setFeatureLevel(\"nonexistent.feature\", (short) 1);",
          "358:             assertEquals(\"Unsupported feature: nonexistent.feature. Supported features \" +",
          "359:                     \"are: kraft.version, test.feature.version, transaction.version\",",
          "360:                 assertThrows(FormatterException.class,",
          "361:                     () -> formatter1.formatter.run()).",
          "362:                         getMessage());",
          "363:         }",
          "364:     }",
          "366:     @ParameterizedTest",
          "367:     @ValueSource(booleans = {false, true})",
          "368:     public void testFormatWithInitialVoters(boolean specifyKRaftVersion) throws Exception {",
          "369:         try (TestEnv testEnv = new TestEnv(2)) {",
          "370:             FormatterContext formatter1 = testEnv.newFormatter();",
          "371:             if (specifyKRaftVersion) {",
          "372:                 formatter1.formatter.setFeatureLevel(\"kraft.version\", (short) 1);",
          "373:             }",
          "374:             formatter1.formatter.setUnstableFeatureVersionsEnabled(true);",
          "375:             formatter1.formatter.setInitialVoters(DynamicVoters.",
          "376:                 parse(\"1@localhost:8020:4znU-ou9Taa06bmEJxsjnw\"));",
          "377:             formatter1.formatter.run();",
          "378:             assertEquals(Arrays.asList(",
          "379:                 String.format(\"Formatting data directory %s with %s %s.\",",
          "380:                     testEnv.directory(1),",
          "381:                     MetadataVersion.FEATURE_NAME,",
          "382:                     MetadataVersion.latestTesting()),",
          "383:                 String.format(\"Formatting dynamic metadata voter directory %s with %s %s.\",",
          "384:                     testEnv.directory(0),",
          "385:                     MetadataVersion.FEATURE_NAME,",
          "386:                     MetadataVersion.latestTesting())),",
          "387:                 formatter1.outputLines().stream().sorted().collect(Collectors.toList()));",
          "388:             MetaPropertiesEnsemble ensemble = new MetaPropertiesEnsemble.Loader().",
          "389:                 addLogDirs(testEnv.directories).",
          "390:                 load();",
          "391:             MetaProperties logDirProps0 = ensemble.logDirProps().get(testEnv.directory(0));",
          "392:             assertNotNull(logDirProps0);",
          "393:             assertEquals(Uuid.fromString(\"4znU-ou9Taa06bmEJxsjnw\"), logDirProps0.directoryId().get());",
          "394:             MetaProperties logDirProps1 = ensemble.logDirProps().get(testEnv.directory(1));",
          "395:             assertNotNull(logDirProps1);",
          "396:             assertNotEquals(Uuid.fromString(\"4znU-ou9Taa06bmEJxsjnw\"), logDirProps1.directoryId().get());",
          "397:         }",
          "398:     }",
          "400:     @Test",
          "401:     public void testFormatWithInitialVotersFailsWithOlderKraftVersion() throws Exception {",
          "402:         try (TestEnv testEnv = new TestEnv(2)) {",
          "403:             FormatterContext formatter1 = testEnv.newFormatter();",
          "404:             formatter1.formatter.setFeatureLevel(\"kraft.version\", (short) 0);",
          "405:             formatter1.formatter.setUnstableFeatureVersionsEnabled(true);",
          "406:             formatter1.formatter.setInitialVoters(DynamicVoters.",
          "407:                     parse(\"1@localhost:8020:4znU-ou9Taa06bmEJxsjnw\"));",
          "408:             assertTrue(formatter1.formatter.hasDynamicQuorum());",
          "409:             assertEquals(\"Cannot set kraft.version to 0 if KIP-853 configuration is present. \" +",
          "410:                 \"Try removing the --feature flag for kraft.version.\",",
          "411:                     assertThrows(FormatterException.class,",
          "412:                         () -> formatter1.formatter.run()).getMessage());",
          "413:         }",
          "414:     }",
          "416:     @Test",
          "417:     public void testFormatWithoutInitialVotersFailsWithNewerKraftVersion() throws Exception {",
          "418:         try (TestEnv testEnv = new TestEnv(2)) {",
          "419:             FormatterContext formatter1 = testEnv.newFormatter();",
          "420:             formatter1.formatter.setFeatureLevel(\"kraft.version\", (short) 1);",
          "421:             formatter1.formatter.setUnstableFeatureVersionsEnabled(true);",
          "422:             assertFalse(formatter1.formatter.hasDynamicQuorum());",
          "423:             assertEquals(\"Cannot set kraft.version to 1 unless KIP-853 configuration is present. \" +",
          "424:                 \"Try removing the --feature flag for kraft.version.\",",
          "425:                     assertThrows(FormatterException.class,",
          "426:                         () -> formatter1.formatter.run()).getMessage());",
          "427:         }",
          "428:     }",
          "430:     @Test",
          "431:     public void testFormatWithInitialVotersFailsWithOlderMetadataVersion() throws Exception {",
          "432:         try (TestEnv testEnv = new TestEnv(2)) {",
          "433:             FormatterContext formatter1 = testEnv.newFormatter();",
          "434:             formatter1.formatter.setReleaseVersion(MetadataVersion.IBP_3_8_IV0);",
          "435:             formatter1.formatter.setFeatureLevel(\"kraft.version\", (short) 1);",
          "436:             formatter1.formatter.setInitialVoters(DynamicVoters.",
          "437:                     parse(\"1@localhost:8020:4znU-ou9Taa06bmEJxsjnw\"));",
          "438:             formatter1.formatter.setUnstableFeatureVersionsEnabled(true);",
          "439:             assertEquals(\"kraft.version could not be set to 1 because it depends on \" +",
          "440:                 \"metadata.version level 21\",",
          "441:                     assertThrows(IllegalArgumentException.class,",
          "442:                         () -> formatter1.formatter.run()).getMessage());",
          "443:         }",
          "444:     }",
          "445: }",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/metadata/storage/ScramParserTest.java||metadata/src/test/java/org/apache/kafka/metadata/storage/ScramParserTest.java": [
          "File: metadata/src/test/java/org/apache/kafka/metadata/storage/ScramParserTest.java -> metadata/src/test/java/org/apache/kafka/metadata/storage/ScramParserTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.metadata.storage;",
          "20: import org.apache.kafka.common.metadata.UserScramCredentialRecord;",
          "21: import org.apache.kafka.common.security.scram.internals.ScramFormatter;",
          "22: import org.apache.kafka.common.security.scram.internals.ScramMechanism;",
          "23: import org.apache.kafka.metadata.storage.ScramParser.PerMechanismData;",
          "24: import org.apache.kafka.test.TestUtils;",
          "26: import org.junit.jupiter.api.Test;",
          "27: import org.junit.jupiter.api.Timeout;",
          "29: import java.util.AbstractMap;",
          "30: import java.util.Optional;",
          "31: import java.util.OptionalInt;",
          "33: import static org.junit.jupiter.api.Assertions.assertArrayEquals;",
          "34: import static org.junit.jupiter.api.Assertions.assertEquals;",
          "35: import static org.junit.jupiter.api.Assertions.assertNotEquals;",
          "36: import static org.junit.jupiter.api.Assertions.assertThrows;",
          "38: @Timeout(value = 40)",
          "39: public class ScramParserTest {",
          "40:     static final byte[] TEST_SALT = new byte[] {",
          "41:         49, 108, 118, 52, 112, 100, 110, 119, 52, 102, 119, 113,",
          "42:         55, 110, 111, 116, 99, 120, 109, 48, 121, 121, 49, 107, 55, 113",
          "43:     };",
          "45:     static final byte[] TEST_SALTED_PASSWORD = new byte[] {",
          "46:         -103, 61, 50, -55, 69, 49, -98, 82, 90, 11, -33, 71, 94,",
          "47:         4, 83, 73, -119, 91, -70, -90, -72, 21, 33, -83, 36,",
          "48:         34, 95, 76, -53, -29, 96, 33",
          "49:     };",
          "51:     @Test",
          "52:     public void testSplitTrimmedConfigStringComponentOnNameEqualsFoo() {",
          "53:         assertEquals(new AbstractMap.SimpleImmutableEntry<>(\"name\", \"foo\"),",
          "54:             ScramParser.splitTrimmedConfigStringComponent(\"name=foo\"));",
          "55:     }",
          "57:     @Test",
          "58:     public void testSplitTrimmedConfigStringComponentOnNameEqualsQuotedFoo() {",
          "59:         assertEquals(new AbstractMap.SimpleImmutableEntry<>(\"name\", \"foo\"),",
          "60:             ScramParser.splitTrimmedConfigStringComponent(\"name=\\\"foo\\\"\"));",
          "61:     }",
          "63:     @Test",
          "64:     public void testSplitTrimmedConfigStringComponentOnNameEqualsEmpty() {",
          "65:         assertEquals(new AbstractMap.SimpleImmutableEntry<>(\"name\", \"\"),",
          "66:             ScramParser.splitTrimmedConfigStringComponent(\"name=\"));",
          "67:     }",
          "69:     @Test",
          "70:     public void testSplitTrimmedConfigStringComponentOnNameEqualsQuotedEmpty() {",
          "71:         assertEquals(new AbstractMap.SimpleImmutableEntry<>(\"name\", \"\"),",
          "72:             ScramParser.splitTrimmedConfigStringComponent(\"name=\\\"\\\"\"));",
          "73:     }",
          "75:     @Test",
          "76:     public void testSplitTrimmedConfigStringComponentWithNoEquals() {",
          "77:         assertEquals(\"No equals sign found in SCRAM component: name\",",
          "78:             assertThrows(FormatterException.class,",
          "79:                 () -> ScramParser.splitTrimmedConfigStringComponent(\"name\")).getMessage());",
          "80:     }",
          "82:     @Test",
          "83:     public void testRandomSalt() throws Exception {",
          "84:         PerMechanismData data = new PerMechanismData(ScramMechanism.SCRAM_SHA_256,",
          "85:             \"bob\",",
          "86:             Optional.empty(),",
          "87:             OptionalInt.empty(),",
          "88:             Optional.of(\"my pass\"),",
          "89:             Optional.empty());",
          "90:         TestUtils.retryOnExceptionWithTimeout(10_000, () -> {",
          "91:             assertNotEquals(data.salt().toString(), data.salt().toString());",
          "92:         });",
          "93:     }",
          "95:     @Test",
          "96:     public void testConfiguredSalt() throws Exception {",
          "97:         assertArrayEquals(TEST_SALT, new PerMechanismData(ScramMechanism.SCRAM_SHA_256,",
          "98:             \"bob\",",
          "99:             Optional.of(TEST_SALT),",
          "100:             OptionalInt.empty(),",
          "101:             Optional.of(\"my pass\"),",
          "102:             Optional.empty()).salt());",
          "103:     }",
          "105:     @Test",
          "106:     public void testDefaultIterations() {",
          "107:         assertEquals(4096, new PerMechanismData(ScramMechanism.SCRAM_SHA_256,",
          "108:             \"bob\",",
          "109:             Optional.empty(),",
          "110:             OptionalInt.empty(),",
          "111:             Optional.of(\"my pass\"),",
          "112:             Optional.empty()).iterations());",
          "113:     }",
          "115:     @Test",
          "116:     public void testConfiguredIterations() {",
          "117:         assertEquals(8192, new PerMechanismData(ScramMechanism.SCRAM_SHA_256,",
          "118:             \"bob\",",
          "119:             Optional.empty(),",
          "120:             OptionalInt.of(8192),",
          "121:             Optional.of(\"my pass\"),",
          "122:             Optional.empty()).iterations());",
          "123:     }",
          "124:     @Test",
          "125:     public void testParsePerMechanismArgument() {",
          "126:         assertEquals(new AbstractMap.SimpleImmutableEntry<>(",
          "127:             ScramMechanism.SCRAM_SHA_512, \"name=scram-admin,password=scram-user-secret\"),",
          "128:                 ScramParser.parsePerMechanismArgument(",
          "129:                     \"SCRAM-SHA-512=[name=scram-admin,password=scram-user-secret]\"));",
          "130:     }",
          "132:     @Test",
          "133:     public void testParsePerMechanismArgumentWithoutEqualsSign() {",
          "134:         assertEquals(\"Failed to find equals sign in SCRAM argument 'SCRAM-SHA-512'\",",
          "135:             assertThrows(FormatterException.class,",
          "136:                 () -> ScramParser.parsePerMechanismArgument(",
          "137:                     \"SCRAM-SHA-512\")).getMessage());",
          "138:     }",
          "140:     @Test",
          "141:     public void testParsePerMechanismArgumentWithUnsupportedScramMethod() {",
          "142:         assertEquals(\"The add-scram mechanism SCRAM-SHA-UNSUPPORTED is not supported.\",",
          "143:             assertThrows(FormatterException.class,",
          "144:                 () -> ScramParser.parsePerMechanismArgument(",
          "145:                     \"SCRAM-SHA-UNSUPPORTED=[name=scram-admin,password=scram-user-secret]\")).",
          "146:                         getMessage());",
          "147:     }",
          "149:     @Test",
          "150:     public void testParsePerMechanismArgumentWithConfigStringWithoutBraces() {",
          "151:         assertEquals(\"Expected configuration string to start with [\",",
          "152:             assertThrows(FormatterException.class,",
          "153:                 () -> ScramParser.parsePerMechanismArgument(",
          "154:                     \"SCRAM-SHA-256=name=scram-admin,password=scram-user-secret\")).getMessage());",
          "155:     }",
          "157:     @Test",
          "158:     public void testParsePerMechanismArgumentWithConfigStringWithoutEndBrace() {",
          "159:         assertEquals(\"Expected configuration string to end with ]\",",
          "160:             assertThrows(FormatterException.class,",
          "161:                 () -> ScramParser.parsePerMechanismArgument(",
          "162:                     \"SCRAM-SHA-256=[name=scram-admin,password=scram-user-secret\")).getMessage());",
          "163:     }",
          "165:     @Test",
          "166:     public void testParsePerMechanismData() {",
          "167:         assertEquals(new PerMechanismData(ScramMechanism.SCRAM_SHA_256,",
          "168:             \"bob\",",
          "169:             Optional.empty(),",
          "170:             OptionalInt.empty(),",
          "171:             Optional.of(\"mypass\"),",
          "172:             Optional.empty()),",
          "173:                 new PerMechanismData(ScramMechanism.SCRAM_SHA_256, \"name=bob,password=mypass\"));",
          "174:     }",
          "176:     @Test",
          "177:     public void testParsePerMechanismDataFailsWithoutName() {",
          "178:         assertEquals(\"You must supply 'name' to add-scram\",",
          "179:             assertThrows(FormatterException.class,",
          "180:                 () -> new PerMechanismData(ScramMechanism.SCRAM_SHA_256,",
          "181:                     \"password=mypass\")).",
          "182:                         getMessage());",
          "183:     }",
          "185:     @Test",
          "186:     public void testParsePerMechanismDataFailsWithoutPassword() {",
          "187:         assertEquals(\"You must supply one of 'password' or 'saltedpassword' to add-scram\",",
          "188:             assertThrows(FormatterException.class,",
          "189:                 () -> new PerMechanismData(ScramMechanism.SCRAM_SHA_256,",
          "190:                     \"name=bar\")).",
          "191:                         getMessage());",
          "192:     }",
          "194:     @Test",
          "195:     public void testParsePerMechanismDataFailsWithExtraArguments() {",
          "196:         assertEquals(\"Unknown SCRAM configurations: unknown, unknown2\",",
          "197:             assertThrows(FormatterException.class,",
          "198:                 () -> new PerMechanismData(ScramMechanism.SCRAM_SHA_256,",
          "199:                     \"name=bob,password=mypass,unknown=something,unknown2=somethingelse\")).",
          "200:                         getMessage());",
          "201:     }",
          "203:     @Test",
          "204:     public void testParsePerMechanismDataWithIterations() {",
          "205:         assertEquals(new PerMechanismData(ScramMechanism.SCRAM_SHA_256,",
          "206:             \"bob\",",
          "207:             Optional.empty(),",
          "208:             OptionalInt.of(8192),",
          "209:             Optional.of(\"my pass\"),",
          "210:             Optional.empty()),",
          "211:                 new PerMechanismData(ScramMechanism.SCRAM_SHA_256,",
          "212:                     \"name=bob,password=my pass,iterations=8192\"));",
          "213:     }",
          "215:     @Test",
          "216:     public void testParsePerMechanismDataWithConfiguredSalt() {",
          "217:         assertEquals(new PerMechanismData(ScramMechanism.SCRAM_SHA_512,",
          "218:             \"bob\",",
          "219:             Optional.of(TEST_SALT),",
          "220:             OptionalInt.empty(),",
          "221:             Optional.of(\"my pass\"),",
          "222:             Optional.empty()),",
          "223:                 new PerMechanismData(ScramMechanism.SCRAM_SHA_512,",
          "224:                     \"name=bob,password=my pass,salt=\\\"MWx2NHBkbnc0ZndxN25vdGN4bTB5eTFrN3E=\\\"\"));",
          "225:     }",
          "227:     @Test",
          "228:     public void testParsePerMechanismDataWithIterationsAndConfiguredSalt() {",
          "229:         assertEquals(new PerMechanismData(ScramMechanism.SCRAM_SHA_256,",
          "230:             \"bob\",",
          "231:             Optional.of(TEST_SALT),",
          "232:             OptionalInt.of(8192),",
          "233:             Optional.of(\"my pass\"),",
          "234:             Optional.empty()),",
          "235:                 new PerMechanismData(ScramMechanism.SCRAM_SHA_256,",
          "236:                     \"name=bob,password=my pass,iterations=8192,salt=\\\"MWx2NHBkbnc0ZndxN25vdGN4bTB5eTFrN3E=\\\"\"));",
          "237:     }",
          "239:     @Test",
          "240:     public void testParsePerMechanismDataWithConfiguredSaltedPasswordFailsWithoutSalt() {",
          "241:         assertEquals(\"You must supply 'salt' with 'saltedpassword' to add-scram\",",
          "242:             assertThrows(FormatterException.class,",
          "243:                 () -> new PerMechanismData(ScramMechanism.SCRAM_SHA_256,",
          "244:                     \"name=alice,saltedpassword=\\\"mT0yyUUxnlJaC99HXgRTSYlbuqa4FSGtJCJfTMvjYCE=\\\"\")).",
          "245:                         getMessage());",
          "246:     }",
          "248:     @Test",
          "249:     public void testParsePerMechanismDataWithConfiguredSaltedPassword() {",
          "250:         assertEquals(new PerMechanismData(ScramMechanism.SCRAM_SHA_256,",
          "251:             \"alice\",",
          "252:             Optional.of(TEST_SALT),",
          "253:             OptionalInt.empty(),",
          "254:             Optional.empty(),",
          "255:             Optional.of(TEST_SALTED_PASSWORD)),",
          "256:                 new PerMechanismData(ScramMechanism.SCRAM_SHA_256,",
          "257:                     \"name=alice,salt=\\\"MWx2NHBkbnc0ZndxN25vdGN4bTB5eTFrN3E=\\\",\" +",
          "258:                         \"saltedpassword=\\\"mT0yyUUxnlJaC99HXgRTSYlbuqa4FSGtJCJfTMvjYCE=\\\"\"));",
          "259:     }",
          "261:     @Test",
          "262:     public void testPerMechanismDataToRecord() throws Exception {",
          "263:         ScramFormatter formatter = new ScramFormatter(ScramMechanism.SCRAM_SHA_512);",
          "264:         assertEquals(new UserScramCredentialRecord().",
          "265:             setName(\"alice\").",
          "266:             setMechanism(ScramMechanism.SCRAM_SHA_512.type()).",
          "267:             setSalt(TEST_SALT).",
          "268:             setStoredKey(formatter.storedKey(formatter.clientKey(TEST_SALTED_PASSWORD))).",
          "269:             setServerKey(formatter.serverKey(TEST_SALTED_PASSWORD)).",
          "270:             setIterations(4096),",
          "271:                 new PerMechanismData(ScramMechanism.SCRAM_SHA_512,",
          "272:                     \"alice\",",
          "273:                     Optional.of(TEST_SALT),",
          "274:                     OptionalInt.empty(),",
          "275:                     Optional.empty(),",
          "276:                     Optional.of(TEST_SALTED_PASSWORD)).toRecord());",
          "277:     }",
          "278: }",
          "",
          "---------------"
        ],
        "raft/src/main/java/org/apache/kafka/raft/DynamicVoter.java||raft/src/main/java/org/apache/kafka/raft/DynamicVoter.java": [
          "File: raft/src/main/java/org/apache/kafka/raft/DynamicVoter.java -> raft/src/main/java/org/apache/kafka/raft/DynamicVoter.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.raft;",
          "20: import org.apache.kafka.common.Uuid;",
          "21: import org.apache.kafka.common.feature.SupportedVersionRange;",
          "22: import org.apache.kafka.common.network.ListenerName;",
          "23: import org.apache.kafka.raft.internals.ReplicaKey;",
          "24: import org.apache.kafka.raft.internals.VoterSet;",
          "26: import java.net.InetSocketAddress;",
          "27: import java.util.Collections;",
          "28: import java.util.Objects;",
          "36: public final class DynamicVoter {",
          "37:     private final Uuid directoryId;",
          "38:     private final int nodeId;",
          "39:     private final String host;",
          "40:     private final int port;",
          "51:     public static DynamicVoter parse(String input) {",
          "52:         input = input.trim();",
          "53:         int atIndex = input.indexOf(\"@\");",
          "54:         if (atIndex < 0) {",
          "55:             throw new IllegalArgumentException(\"No @ found in dynamic voter string.\");",
          "56:         }",
          "57:         if (atIndex == 0) {",
          "58:             throw new IllegalArgumentException(\"Invalid @ at beginning of dynamic voter string.\");",
          "59:         }",
          "60:         String idString = input.substring(0, atIndex);",
          "61:         int nodeId;",
          "62:         try {",
          "63:             nodeId = Integer.parseInt(idString);",
          "64:         } catch (NumberFormatException e) {",
          "65:             throw new IllegalArgumentException(\"Failed to parse node id in dynamic voter string.\", e);",
          "66:         }",
          "67:         if (nodeId < 0) {",
          "68:             throw new IllegalArgumentException(\"Invalid negative node id \" + nodeId +",
          "69:                 \" in dynamic voter string.\");",
          "70:         }",
          "71:         input = input.substring(atIndex + 1);",
          "72:         if (input.isEmpty()) {",
          "73:             throw new IllegalArgumentException(\"No hostname found after node id.\");",
          "74:         }",
          "75:         String host;",
          "76:         if (input.startsWith(\"[\")) {",
          "77:             int endBracketIndex = input.indexOf(\"]\");",
          "78:             if (endBracketIndex < 0) {",
          "79:                 throw new IllegalArgumentException(\"Hostname began with left bracket, but no right \" +",
          "80:                         \"bracket was found.\");",
          "81:             }",
          "82:             host = input.substring(1, endBracketIndex);",
          "83:             input = input.substring(endBracketIndex + 1);",
          "84:         } else {",
          "85:             int endColonIndex = input.indexOf(\":\");",
          "86:             if (endColonIndex < 0) {",
          "87:                 throw new IllegalArgumentException(\"No colon following hostname could be found.\");",
          "88:             }",
          "89:             host = input.substring(0, endColonIndex);",
          "90:             input = input.substring(endColonIndex);",
          "91:         }",
          "92:         if (!input.startsWith(\":\")) {",
          "93:             throw new IllegalArgumentException(\"Port section must start with a colon.\");",
          "94:         }",
          "95:         input = input.substring(1);",
          "96:         int endColonIndex = input.indexOf(\":\");",
          "97:         if (endColonIndex < 0) {",
          "98:             throw new IllegalArgumentException(\"No colon following port could be found.\");",
          "99:         }",
          "100:         String portString = input.substring(0, endColonIndex);",
          "101:         int port;",
          "102:         try {",
          "103:             port = Integer.parseInt(portString);",
          "104:         } catch (NumberFormatException e) {",
          "105:             throw new IllegalArgumentException(\"Failed to parse port in dynamic voter string.\", e);",
          "106:         }",
          "107:         if (port < 0 || port > 65535) {",
          "108:             throw new IllegalArgumentException(\"Invalid port \" + port + \" in dynamic voter string.\");",
          "109:         }",
          "110:         String directoryIdString = input.substring(endColonIndex + 1);",
          "111:         Uuid directoryId;",
          "112:         try {",
          "113:             directoryId = Uuid.fromString(directoryIdString);",
          "114:         } catch (IllegalArgumentException e) {",
          "115:             throw new IllegalArgumentException(\"Failed to parse directory ID in dynamic voter string.\", e);",
          "116:         }",
          "117:         return new DynamicVoter(directoryId, nodeId, host, port);",
          "118:     }",
          "128:     public DynamicVoter(",
          "129:         Uuid directoryId,",
          "130:         int nodeId,",
          "131:         String host,",
          "132:         int port",
          "133:     ) {",
          "134:         this.directoryId = directoryId;",
          "135:         this.nodeId = nodeId;",
          "136:         this.host = host;",
          "137:         this.port = port;",
          "138:     }",
          "140:     public Uuid directoryId() {",
          "141:         return directoryId;",
          "142:     }",
          "144:     public int nodeId() {",
          "145:         return nodeId;",
          "146:     }",
          "148:     public String host() {",
          "149:         return host;",
          "150:     }",
          "152:     public int port() {",
          "153:         return port;",
          "154:     }",
          "156:     public VoterSet.VoterNode toVoterNode(String controllerListenerName) {",
          "157:         ReplicaKey voterKey = ReplicaKey.of(nodeId, directoryId);",
          "158:         Endpoints listeners = Endpoints.fromInetSocketAddresses(Collections.singletonMap(",
          "159:                 ListenerName.normalised(controllerListenerName),",
          "160:                 new InetSocketAddress(host, port)));",
          "161:         SupportedVersionRange supportedKRaftVersion =",
          "162:                 new SupportedVersionRange((short) 0, (short) 1);",
          "163:         return VoterSet.VoterNode.of(voterKey, listeners, supportedKRaftVersion);",
          "164:     }",
          "166:     @Override",
          "167:     public boolean equals(Object o) {",
          "168:         if (o == null || (!(o.getClass().equals(DynamicVoter.class)))) return false;",
          "169:         DynamicVoter other = (DynamicVoter) o;",
          "170:         return directoryId.equals(other.directoryId) &&",
          "171:             nodeId == other.nodeId &&",
          "172:             host.equals(other.host) &&",
          "173:             port == other.port;",
          "174:     }",
          "176:     @Override",
          "177:     public int hashCode() {",
          "178:         return Objects.hash(directoryId,",
          "179:             nodeId,",
          "180:             host,",
          "181:             port);",
          "182:     }",
          "184:     @Override",
          "185:     public String toString() {",
          "186:         return nodeId + \"@\" + host + \":\" + port + \":\" + directoryId;",
          "187:     }",
          "188: }",
          "",
          "---------------"
        ],
        "raft/src/main/java/org/apache/kafka/raft/DynamicVoters.java||raft/src/main/java/org/apache/kafka/raft/DynamicVoters.java": [
          "File: raft/src/main/java/org/apache/kafka/raft/DynamicVoters.java -> raft/src/main/java/org/apache/kafka/raft/DynamicVoters.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package org.apache.kafka.raft;",
          "20: import org.apache.kafka.raft.internals.VoterSet;",
          "22: import java.util.ArrayList;",
          "23: import java.util.Collection;",
          "24: import java.util.Collections;",
          "25: import java.util.HashMap;",
          "26: import java.util.List;",
          "27: import java.util.Map;",
          "28: import java.util.NavigableMap;",
          "29: import java.util.TreeMap;",
          "37: public final class DynamicVoters {",
          "47:     public static DynamicVoters parse(String input) {",
          "48:         input = input.trim();",
          "49:         List<DynamicVoter> voters = new ArrayList<>();",
          "50:         for (String voterString : input.split(\",\")) {",
          "51:             if (!voterString.isEmpty()) {",
          "52:                 voters.add(DynamicVoter.parse(voterString));",
          "53:             }",
          "54:         }",
          "55:         return new DynamicVoters(voters);",
          "56:     }",
          "61:     private final NavigableMap<Integer, DynamicVoter> voters;",
          "68:     public DynamicVoters(Collection<DynamicVoter> voters) {",
          "69:         if (voters.isEmpty()) {",
          "70:             throw new IllegalArgumentException(\"No voters given.\");",
          "71:         }",
          "72:         TreeMap<Integer, DynamicVoter> votersMap = new TreeMap<>();",
          "73:         for (DynamicVoter voter : voters) {",
          "74:             if (votersMap.put(voter.nodeId(), voter) != null) {",
          "75:                 throw new IllegalArgumentException(\"Node id \" + voter.nodeId() +",
          "76:                         \" was specified more than once.\");",
          "77:             }",
          "78:         }",
          "79:         this.voters = Collections.unmodifiableNavigableMap(votersMap);",
          "80:     }",
          "82:     public NavigableMap<Integer, DynamicVoter> voters() {",
          "83:         return voters;",
          "84:     }",
          "86:     public VoterSet toVoterSet(String controllerListenerName) {",
          "87:         Map<Integer, VoterSet.VoterNode> voterSetMap = new HashMap<>();",
          "88:         for (DynamicVoter voter : voters.values()) {",
          "89:             voterSetMap.put(voter.nodeId(), voter.toVoterNode(controllerListenerName));",
          "90:         }",
          "91:         return VoterSet.fromMap(voterSetMap);",
          "92:     }",
          "94:     @Override",
          "95:     public boolean equals(Object o) {",
          "96:         if (o == null || (!(o.getClass().equals(DynamicVoters.class)))) return false;",
          "97:         DynamicVoters other = (DynamicVoters) o;",
          "98:         return voters.equals(other.voters);",
          "99:     }",
          "101:     @Override",
          "102:     public int hashCode() {",
          "103:         return voters.hashCode();",
          "104:     }",
          "106:     @Override",
          "107:     public String toString() {",
          "108:         StringBuilder builder = new StringBuilder();",
          "109:         String prefix = \"\";",
          "110:         for (DynamicVoter voter : voters.values()) {",
          "111:             builder.append(prefix);",
          "112:             prefix = \",\";",
          "113:             builder.append(voter.toString());",
          "114:         }",
          "115:         return builder.toString();",
          "116:     }",
          "117: }",
          "",
          "---------------"
        ],
        "raft/src/main/java/org/apache/kafka/raft/internals/VoterSet.java||raft/src/main/java/org/apache/kafka/raft/internals/VoterSet.java": [
          "File: raft/src/main/java/org/apache/kafka/raft/internals/VoterSet.java -> raft/src/main/java/org/apache/kafka/raft/internals/VoterSet.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "427:         return new VoterSet(voterNodes);",
          "428:     }",
          "429: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "430:     public static VoterSet fromMap(Map<Integer, VoterNode> voters) {",
          "431:         return new VoterSet(new HashMap<>(voters));",
          "432:     }",
          "",
          "---------------"
        ],
        "raft/src/test/java/org/apache/kafka/raft/DynamicVoterTest.java||raft/src/test/java/org/apache/kafka/raft/DynamicVoterTest.java": [
          "File: raft/src/test/java/org/apache/kafka/raft/DynamicVoterTest.java -> raft/src/test/java/org/apache/kafka/raft/DynamicVoterTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "17: package org.apache.kafka.raft;",
          "19: import org.apache.kafka.common.Uuid;",
          "20: import org.apache.kafka.common.feature.SupportedVersionRange;",
          "21: import org.apache.kafka.common.network.ListenerName;",
          "22: import org.apache.kafka.raft.internals.ReplicaKey;",
          "23: import org.apache.kafka.raft.internals.VoterSet;",
          "25: import org.junit.jupiter.api.Test;",
          "27: import java.net.InetSocketAddress;",
          "28: import java.util.Collections;",
          "30: import static org.junit.jupiter.api.Assertions.assertEquals;",
          "31: import static org.junit.jupiter.api.Assertions.assertThrows;",
          "33: public class DynamicVoterTest {",
          "34:     @Test",
          "35:     public void testParseDynamicVoter() {",
          "36:         assertEquals(new DynamicVoter(Uuid.fromString(\"K90IZ-0DRNazJ49kCZ1EMQ\"),",
          "37:                 2,",
          "38:                 \"localhost\",",
          "39:                 (short) 8020),",
          "40:             DynamicVoter.parse(\"2@localhost:8020:K90IZ-0DRNazJ49kCZ1EMQ\"));",
          "41:     }",
          "43:     @Test",
          "44:     public void testParseDynamicVoter2() {",
          "45:         assertEquals(new DynamicVoter(Uuid.fromString(\"__0IZ-0DRNazJ49kCZ1EMQ\"),",
          "46:                 100,",
          "47:                 \"192.128.0.100\",",
          "48:                 (short) 800),",
          "49:             DynamicVoter.parse(\"100@192.128.0.100:800:__0IZ-0DRNazJ49kCZ1EMQ\"));",
          "50:     }",
          "52:     @Test",
          "53:     public void testParseDynamicVoterWithBrackets() {",
          "54:         assertEquals(new DynamicVoter(Uuid.fromString(\"__0IZ-0DRNazJ49kCZ1EMQ\"),",
          "55:                 5,",
          "56:                 \"2001:4860:4860::8888\",",
          "57:                 (short) 8020),",
          "58:             DynamicVoter.parse(\"5@[2001:4860:4860::8888]:8020:__0IZ-0DRNazJ49kCZ1EMQ\"));",
          "59:     }",
          "61:     @Test",
          "62:     public void testParseDynamicVoterWithoutId() {",
          "63:         assertEquals(\"No @ found in dynamic voter string.\",",
          "64:             assertThrows(IllegalArgumentException.class,",
          "65:                 () -> DynamicVoter.parse(\"localhost:8020:K90IZ-0DRNazJ49kCZ1EMQ\")).",
          "66:                     getMessage());",
          "67:     }",
          "69:     @Test",
          "70:     public void testParseDynamicVoterWithoutId2() {",
          "71:         assertEquals(\"Invalid @ at beginning of dynamic voter string.\",",
          "72:             assertThrows(IllegalArgumentException.class,",
          "73:                 () -> DynamicVoter.parse(\"@localhost:8020:K90IZ-0DRNazJ49kCZ1EMQ\")).",
          "74:                     getMessage());",
          "75:     }",
          "77:     @Test",
          "78:     public void testParseDynamicVoterWithInvalidNegativeId() {",
          "79:         assertEquals(\"Invalid negative node id -1 in dynamic voter string.\",",
          "80:             assertThrows(IllegalArgumentException.class,",
          "81:                 () -> DynamicVoter.parse(\"-1@localhost:8020:K90IZ-0DRNazJ49kCZ1EMQ\")).",
          "82:                     getMessage());",
          "83:     }",
          "85:     @Test",
          "86:     public void testFailedToParseNodeId() {",
          "87:         assertEquals(\"Failed to parse node id in dynamic voter string.\",",
          "88:             assertThrows(IllegalArgumentException.class,",
          "89:                 () -> DynamicVoter.parse(\"blah@localhost:8020:K90IZ-0DRNazJ49kCZ1EMQ\")).",
          "90:                     getMessage());",
          "91:     }",
          "93:     @Test",
          "94:     public void testParseDynamicVoterWithoutHostname() {",
          "95:         assertEquals(\"No hostname found after node id.\",",
          "96:             assertThrows(IllegalArgumentException.class,",
          "97:                 () -> DynamicVoter.parse(\"2@\")).",
          "98:                     getMessage());",
          "99:     }",
          "101:     @Test",
          "102:     public void testParseDynamicVoterWithUnbalancedBrackets() {",
          "103:         assertEquals(\"Hostname began with left bracket, but no right bracket was found.\",",
          "104:             assertThrows(IllegalArgumentException.class,",
          "105:                 () -> DynamicVoter.parse(\"5@[2001:4860:4860::8888:8020:__0IZ-0DRNazJ49kCZ1EMQ\")).",
          "106:                     getMessage());",
          "107:     }",
          "109:     @Test",
          "110:     public void testNoColonFollowingHostname() {",
          "111:         assertEquals(\"No colon following hostname could be found.\",",
          "112:             assertThrows(IllegalArgumentException.class,",
          "113:                 () -> DynamicVoter.parse(\"2@localhost8020K90IZ-0DRNazJ49kCZ1EMQ\")).",
          "114:                     getMessage());",
          "115:     }",
          "117:     @Test",
          "118:     public void testPortSectionMustStartWithAColon() {",
          "119:         assertEquals(\"Port section must start with a colon.\",",
          "120:             assertThrows(IllegalArgumentException.class,",
          "121:                 () -> DynamicVoter.parse(\"5@[2001:4860:4860::8888]8020:__0IZ-0DRNazJ49kCZ1EMQ\")).",
          "122:                     getMessage());",
          "123:     }",
          "125:     @Test",
          "126:     public void testParseDynamicVoterWithNoColonFollowingPort() {",
          "127:         assertEquals(\"No colon following port could be found.\",",
          "128:             assertThrows(IllegalArgumentException.class,",
          "129:                 () -> DynamicVoter.parse(\"5@[2001:4860:4860::8888]:8020__0IZ-0DRNazJ49kCZ1EMQ\")).",
          "130:                     getMessage());",
          "131:     }",
          "133:     @Test",
          "134:     public void testFailedToParsePort() {",
          "135:         assertEquals(\"Failed to parse port in dynamic voter string.\",",
          "136:             assertThrows(IllegalArgumentException.class,",
          "137:                 () -> DynamicVoter.parse(\"5@[2001:4860:4860::8888]:8020m:__0IZ-0DRNazJ49kCZ1EMQ\")).",
          "138:                     getMessage());",
          "139:     }",
          "141:     @Test",
          "142:     public void testInvalidNegativePort() {",
          "143:         assertEquals(\"Invalid port -8020 in dynamic voter string.\",",
          "144:             assertThrows(IllegalArgumentException.class,",
          "145:                 () -> DynamicVoter.parse(\"5@[2001:4860:4860::8888]:-8020:__0IZ-0DRNazJ49kCZ1EMQ\")).",
          "146:                     getMessage());",
          "147:     }",
          "149:     @Test",
          "150:     public void testInvalidPositivePort() {",
          "151:         assertEquals(\"Invalid port 666666 in dynamic voter string.\",",
          "152:             assertThrows(IllegalArgumentException.class,",
          "153:                 () -> DynamicVoter.parse(\"5@[2001:4860:4860::8888]:666666:__0IZ-0DRNazJ49kCZ1EMQ\")).",
          "154:                     getMessage());",
          "155:     }",
          "157:     @Test",
          "158:     public void testFailedToParseDirectoryId() {",
          "159:         assertEquals(\"Failed to parse directory ID in dynamic voter string.\",",
          "160:             assertThrows(IllegalArgumentException.class,",
          "161:                 () -> DynamicVoter.parse(\"5@[2001:4860:4860::8888]:8020:%_0IZ-0DRNazJ49kCZ1EMQ\")).",
          "162:                     getMessage());",
          "163:     }",
          "165:     @Test",
          "166:     public void testFailedToParseDirectoryId2() {",
          "167:         assertEquals(\"Failed to parse directory ID in dynamic voter string.\",",
          "168:             assertThrows(IllegalArgumentException.class,",
          "169:                 () -> DynamicVoter.parse(\"5@[2001:4860:4860::8888]:8020:\")).",
          "170:                     getMessage());",
          "171:     }",
          "173:     @Test",
          "174:     public void testToVoterNode() {",
          "175:         ReplicaKey voterKey = ReplicaKey.of(5, Uuid.fromString(\"__0IZ-0DRNazJ49kCZ1EMQ\"));",
          "176:         Endpoints listeners = Endpoints.fromInetSocketAddresses(Collections.singletonMap(",
          "177:             new ListenerName(\"CONTROLLER\"),",
          "178:             new InetSocketAddress(\"localhost\", 8020)));",
          "179:         SupportedVersionRange supportedKRaftVersion =",
          "180:             new SupportedVersionRange((short) 0, (short) 1);",
          "181:         assertEquals(VoterSet.VoterNode.of(voterKey, listeners, supportedKRaftVersion),",
          "182:             DynamicVoter.parse(\"5@localhost:8020:__0IZ-0DRNazJ49kCZ1EMQ\").",
          "183:                 toVoterNode(\"CONTROLLER\"));",
          "184:     }",
          "185: }",
          "",
          "---------------"
        ],
        "raft/src/test/java/org/apache/kafka/raft/DynamicVotersTest.java||raft/src/test/java/org/apache/kafka/raft/DynamicVotersTest.java": [
          "File: raft/src/test/java/org/apache/kafka/raft/DynamicVotersTest.java -> raft/src/test/java/org/apache/kafka/raft/DynamicVotersTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "17: package org.apache.kafka.raft;",
          "19: import org.apache.kafka.common.Uuid;",
          "20: import org.apache.kafka.raft.internals.VoterSet;",
          "22: import org.junit.jupiter.api.Test;",
          "24: import java.util.Arrays;",
          "25: import java.util.HashMap;",
          "26: import java.util.Map;",
          "28: import static org.junit.jupiter.api.Assertions.assertEquals;",
          "29: import static org.junit.jupiter.api.Assertions.assertThrows;",
          "31: public class DynamicVotersTest {",
          "32:     @Test",
          "33:     public void testParsingEmptyStringFails() {",
          "34:         assertEquals(\"No voters given.\",",
          "35:             assertThrows(IllegalArgumentException.class,",
          "36:                 () -> DynamicVoters.parse(\"\")).",
          "37:                     getMessage());",
          "38:     }",
          "40:     @Test",
          "41:     public void testParsingSingleDynamicVoter() {",
          "42:         assertEquals(new DynamicVoters(Arrays.asList(",
          "43:             new DynamicVoter(",
          "44:                 Uuid.fromString(\"K90IZ-0DRNazJ49kCZ1EMQ\"),",
          "45:                 2,",
          "46:                 \"localhost\",",
          "47:                 (short) 8020))),",
          "48:             DynamicVoters.parse(\"2@localhost:8020:K90IZ-0DRNazJ49kCZ1EMQ\"));",
          "49:     }",
          "51:     @Test",
          "52:     public void testParsingThreeDynamicVoters() {",
          "53:         assertEquals(new DynamicVoters(Arrays.asList(",
          "54:             new DynamicVoter(",
          "55:                 Uuid.fromString(\"K90IZ-0DRNazJ49kCZ1EMQ\"),",
          "56:                 0,",
          "57:                 \"localhost\",",
          "58:                 (short) 8020),",
          "59:             new DynamicVoter(",
          "60:                 Uuid.fromString(\"aUARLskQTCW4qCZDtS_cwA\"),",
          "61:                 1,",
          "62:                 \"localhost\",",
          "63:                 (short) 8030),",
          "64:             new DynamicVoter(",
          "65:                 Uuid.fromString(\"2ggvsS4kQb-fSJ_-zC_Ang\"),",
          "66:                 2,",
          "67:                 \"localhost\",",
          "68:                 (short) 8040))),",
          "69:             DynamicVoters.parse(",
          "70:                 \"0@localhost:8020:K90IZ-0DRNazJ49kCZ1EMQ,\" +",
          "71:                 \"1@localhost:8030:aUARLskQTCW4qCZDtS_cwA,\" +",
          "72:                 \"2@localhost:8040:2ggvsS4kQb-fSJ_-zC_Ang\"));",
          "73:     }",
          "75:     @Test",
          "76:     public void testParsingInvalidStringWithDuplicateNodeIds() {",
          "77:         assertEquals(\"Node id 1 was specified more than once.\",",
          "78:             assertThrows(IllegalArgumentException.class,",
          "79:                 () -> DynamicVoters.parse(",
          "80:                     \"0@localhost:8020:K90IZ-0DRNazJ49kCZ1EMQ,\" +",
          "81:                     \"1@localhost:8030:aUARLskQTCW4qCZDtS_cwA,\" +",
          "82:                     \"1@localhost:8040:2ggvsS4kQb-fSJ_-zC_Ang\")).",
          "83:                         getMessage());",
          "84:     }",
          "86:     private static void testRoundTrip(String input) {",
          "87:         DynamicVoters voters = DynamicVoters.parse(input);",
          "88:         assertEquals(input, voters.toString());",
          "89:     }",
          "91:     @Test",
          "92:     public void testRoundTripSingleVoter() {",
          "93:         testRoundTrip(\"2@localhost:8020:K90IZ-0DRNazJ49kCZ1EMQ\");",
          "94:     }",
          "96:     @Test",
          "97:     public void testRoundTripThreeVoters() {",
          "98:         testRoundTrip(",
          "99:             \"0@localhost:8020:K90IZ-0DRNazJ49kCZ1EMQ,\" +",
          "100:             \"1@localhost:8030:aUARLskQTCW4qCZDtS_cwA,\" +",
          "101:             \"2@localhost:8040:2ggvsS4kQb-fSJ_-zC_Ang\");",
          "102:     }",
          "104:     @Test",
          "105:     public void testToVoterSet() {",
          "106:         Map<Integer, VoterSet.VoterNode> voterMap = new HashMap<>();",
          "107:         voterMap.put(0, DynamicVoter.parse(",
          "108:             \"0@localhost:8020:K90IZ-0DRNazJ49kCZ1EMQ\").toVoterNode(\"CONTROLLER2\"));",
          "109:         voterMap.put(1, DynamicVoter.parse(",
          "110:             \"1@localhost:8030:aUARLskQTCW4qCZDtS_cwA\").toVoterNode(\"CONTROLLER2\"));",
          "111:         voterMap.put(2, DynamicVoter.parse(",
          "112:             \"2@localhost:8040:2ggvsS4kQb-fSJ_-zC_Ang\").toVoterNode(\"CONTROLLER2\"));",
          "113:         assertEquals(VoterSet.fromMap(voterMap),",
          "114:             DynamicVoters.parse(",
          "115:                 \"0@localhost:8020:K90IZ-0DRNazJ49kCZ1EMQ,\" +",
          "116:                 \"1@localhost:8030:aUARLskQTCW4qCZDtS_cwA,\" +",
          "117:                 \"2@localhost:8040:2ggvsS4kQb-fSJ_-zC_Ang\").toVoterSet(\"CONTROLLER2\"));",
          "118:     }",
          "119: }",
          "",
          "---------------"
        ],
        "server-common/src/main/java/org/apache/kafka/server/common/KRaftVersion.java||server-common/src/main/java/org/apache/kafka/server/common/KRaftVersion.java": [
          "File: server-common/src/main/java/org/apache/kafka/server/common/KRaftVersion.java -> server-common/src/main/java/org/apache/kafka/server/common/KRaftVersion.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "72:     @Override",
          "73:     public Map<String, Short> dependencies() {",
          "75:     }",
          "77:     public short quorumStateVersion() {",
          "",
          "[Removed Lines]",
          "74:         return Collections.emptyMap();",
          "",
          "[Added Lines]",
          "74:         if (this.featureLevel == 0) {",
          "75:             return Collections.emptyMap();",
          "76:         } else {",
          "77:             return Collections.singletonMap(",
          "78:                 MetadataVersion.FEATURE_NAME, MetadataVersion.IBP_3_9_IV0.featureLevel());",
          "79:         }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "6b2f2aa2f15d36ffcbc565e39ea8dc7574565e05",
      "candidate_info": {
        "commit_hash": "6b2f2aa2f15d36ffcbc565e39ea8dc7574565e05",
        "repo": "apache/kafka",
        "commit_url": "https://github.com/apache/kafka/commit/6b2f2aa2f15d36ffcbc565e39ea8dc7574565e05",
        "files": [
          "core/src/main/scala/kafka/tools/StorageTool.scala",
          "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala",
          "metadata/src/main/java/org/apache/kafka/metadata/storage/Formatter.java",
          "metadata/src/test/java/org/apache/kafka/metadata/storage/FormatterTest.java"
        ],
        "message": "KAFKA-18028 the effective kraft version of --no-initial-controllers should be 1 rather than 0 (#17836)\n\nReviewers: Chia-Ping Tsai <chia7712@gmail.com>",
        "before_after_code_files": [
          "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
          "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala",
          "metadata/src/main/java/org/apache/kafka/metadata/storage/Formatter.java||metadata/src/main/java/org/apache/kafka/metadata/storage/Formatter.java",
          "metadata/src/test/java/org/apache/kafka/metadata/storage/FormatterTest.java||metadata/src/test/java/org/apache/kafka/metadata/storage/FormatterTest.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
            "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
          ],
          "candidate": [
            "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
            "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
          ]
        }
      },
      "candidate_diff": {
        "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala": [
          "File: core/src/main/scala/kafka/tools/StorageTool.scala -> core/src/main/scala/kafka/tools/StorageTool.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "133:     if (namespace.getBoolean(\"standalone\")) {",
          "134:       formatter.setInitialControllers(createStandaloneDynamicVoters(config))",
          "135:     }",
          "137:       if (config.processRoles.contains(ProcessRole.ControllerRole)) {",
          "144:         }",
          "145:       }",
          "146:     }",
          "",
          "[Removed Lines]",
          "136:     if (!namespace.getBoolean(\"no_initial_controllers\")) {",
          "138:         if (config.quorumVoters.isEmpty) {",
          "139:           if (!formatter.initialVoters().isPresent()) {",
          "140:             throw new TerseFailure(\"Because \" + QuorumConfig.QUORUM_VOTERS_CONFIG +",
          "141:               \" is not set on this controller, you must specify one of the following: \" +",
          "142:               \"--standalone, --initial-controllers, or --no-initial-controllers.\");",
          "143:           }",
          "",
          "[Added Lines]",
          "136:     if (namespace.getBoolean(\"no_initial_controllers\")) {",
          "137:       formatter.setNoInitialControllersFlag(true)",
          "138:     } else {",
          "140:         if (config.quorumVoters.isEmpty() && !formatter.initialVoters().isPresent()) {",
          "141:           throw new TerseFailure(\"Because \" + QuorumConfig.QUORUM_VOTERS_CONFIG +",
          "142:             \" is not set on this controller, you must specify one of the following: \" +",
          "143:             \"--standalone, --initial-controllers, or --no-initial-controllers.\");",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala": [
          "File: core/src/test/scala/unit/kafka/tools/StorageToolTest.scala -> core/src/test/scala/unit/kafka/tools/StorageToolTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "483:               Seq(\"--release-version\", \"3.9-IV0\"))).getMessage)",
          "484:   }",
          "488:     val availableDirs = Seq(TestUtils.tempDir())",
          "489:     val properties = new Properties()",
          "490:     properties.putAll(defaultDynamicQuorumProperties)",
          "491:     properties.setProperty(\"log.dirs\", availableDirs.mkString(\",\"))",
          "492:     val stream = new ByteArrayOutputStream()",
          "495:     assertTrue(stream.toString().",
          "496:       contains(\"Formatting metadata directory %s\".format(availableDirs.head)),",
          "497:       \"Failed to find content in output: \" + stream.toString())",
          "498:   }",
          "500:   @Test",
          "501:   def testFormatWithoutStaticQuorumSucceedsWithoutInitialControllersOnBroker(): Unit = {",
          "502:     val availableDirs = Seq(TestUtils.tempDir())",
          "",
          "[Removed Lines]",
          "486:   @Test",
          "487:   def testFormatWithNoInitialControllersSucceedsOnController(): Unit = {",
          "493:     assertEquals(0, runFormatCommand(stream, properties,",
          "494:       Seq(\"--no-initial-controllers\", \"--release-version\", \"3.9-IV0\")))",
          "",
          "[Added Lines]",
          "486:   @ParameterizedTest",
          "487:   @ValueSource(booleans = Array(false, true))",
          "488:   def testFormatWithNoInitialControllersSucceedsOnController(setKraftVersionFeature: Boolean): Unit = {",
          "494:     val arguments = ListBuffer[String](\"--release-version\", \"3.9-IV0\", \"--no-initial-controllers\")",
          "495:     if (setKraftVersionFeature) {",
          "496:       arguments += \"--feature\"",
          "497:       arguments += \"kraft.version=1\"",
          "498:     }",
          "499:     assertEquals(0, runFormatCommand(stream, properties, arguments.toSeq))",
          "505:   @Test",
          "506:   def testFormatWithNoInitialControllersFlagAndStandaloneFlagFails(): Unit = {",
          "507:     val arguments = ListBuffer[String](",
          "508:       \"format\", \"--cluster-id\", \"XcZZOzUqS4yHOjhMQB6JLQ\",",
          "509:       \"--release-version\", \"3.9-IV0\",",
          "510:       \"--no-initial-controllers\", \"--standalone\")",
          "511:     val exception = assertThrows(classOf[ArgumentParserException], () => StorageTool.parseArguments(arguments.toArray))",
          "512:     assertEquals(\"argument --standalone/-s: not allowed with argument --no-initial-controllers/-N\", exception.getMessage)",
          "513:   }",
          "515:   @Test",
          "516:   def testFormatWithNoInitialControllersFlagAndInitialControllersFlagFails(): Unit = {",
          "517:     val arguments = ListBuffer[String](",
          "518:       \"format\", \"--cluster-id\", \"XcZZOzUqS4yHOjhMQB6JLQ\",",
          "519:       \"--release-version\", \"3.9-IV0\",",
          "520:       \"--no-initial-controllers\", \"--initial-controllers\",",
          "521:       \"0@localhost:8020:K90IZ-0DRNazJ49kCZ1EMQ,\" +",
          "522:       \"1@localhost:8030:aUARLskQTCW4qCZDtS_cwA,\" +",
          "523:       \"2@localhost:8040:2ggvsS4kQb-fSJ_-zC_Ang\")",
          "524:     val exception = assertThrows(classOf[ArgumentParserException], () => StorageTool.parseArguments(arguments.toArray))",
          "525:     assertEquals(\"argument --initial-controllers/-I: not allowed with argument --no-initial-controllers/-N\", exception.getMessage)",
          "526:   }",
          "",
          "---------------"
        ],
        "metadata/src/main/java/org/apache/kafka/metadata/storage/Formatter.java||metadata/src/main/java/org/apache/kafka/metadata/storage/Formatter.java": [
          "File: metadata/src/main/java/org/apache/kafka/metadata/storage/Formatter.java -> metadata/src/main/java/org/apache/kafka/metadata/storage/Formatter.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "98:     private Map<String, Short> featureLevels = new TreeMap<>();",
          "",
          "[Added Lines]",
          "100:     protected Map<String, Short> featureLevels = new TreeMap<>();",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "133:     private Optional<DynamicVoters> initialControllers = Optional.empty();",
          "135:     public Formatter setPrintStream(PrintStream printStream) {",
          "136:         this.printStream = printStream;",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "136:     private boolean noInitialControllersFlag = false;",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "207:         return this;",
          "208:     }",
          "210:     public Optional<DynamicVoters> initialVoters() {",
          "211:         return initialControllers;",
          "212:     }",
          "214:     boolean hasDynamicQuorum() {",
          "219:     }",
          "221:     public BootstrapMetadata bootstrapMetadata() {",
          "",
          "[Removed Lines]",
          "215:         if (initialControllers.isPresent()) {",
          "216:             return true;",
          "217:         }",
          "218:         return false;",
          "",
          "[Added Lines]",
          "213:     public Formatter setNoInitialControllersFlag(boolean noInitialControllersFlag) {",
          "214:         this.noInitialControllersFlag = noInitialControllersFlag;",
          "215:         return this;",
          "216:     }",
          "223:         return initialControllers.isPresent() || noInitialControllersFlag;",
          "",
          "---------------"
        ],
        "metadata/src/test/java/org/apache/kafka/metadata/storage/FormatterTest.java||metadata/src/test/java/org/apache/kafka/metadata/storage/FormatterTest.java": [
          "File: metadata/src/test/java/org/apache/kafka/metadata/storage/FormatterTest.java -> metadata/src/test/java/org/apache/kafka/metadata/storage/FormatterTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "375:             formatter1.formatter.setInitialControllers(DynamicVoters.",
          "376:                 parse(\"1@localhost:8020:4znU-ou9Taa06bmEJxsjnw\"));",
          "377:             formatter1.formatter.run();",
          "378:             assertEquals(Arrays.asList(",
          "379:                 String.format(\"Formatting data directory %s with %s %s.\",",
          "380:                     testEnv.directory(1),",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "378:             assertEquals((short) 1, formatter1.formatter.featureLevels.getOrDefault(\"kraft.version\", (short) 0));",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "442:                         () -> formatter1.formatter.run()).getMessage());",
          "443:         }",
          "444:     }",
          "445: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "447:     @ParameterizedTest",
          "448:     @ValueSource(booleans = {false, true})",
          "449:     public void testFormatWithNoInitialControllers(boolean specifyKRaftVersion) throws Exception {",
          "450:         try (TestEnv testEnv = new TestEnv(2)) {",
          "451:             FormatterContext formatter1 = testEnv.newFormatter();",
          "452:             if (specifyKRaftVersion) {",
          "453:                 formatter1.formatter.setFeatureLevel(\"kraft.version\", (short) 1);",
          "454:             }",
          "455:             formatter1.formatter.setUnstableFeatureVersionsEnabled(true);",
          "456:             formatter1.formatter.setNoInitialControllersFlag(true);",
          "457:             assertTrue(formatter1.formatter.hasDynamicQuorum());",
          "459:             formatter1.formatter.run();",
          "460:             assertEquals((short) 1, formatter1.formatter.featureLevels.getOrDefault(\"kraft.version\", (short) 0));",
          "461:             assertEquals(Arrays.asList(",
          "462:                     String.format(\"Formatting data directory %s with %s %s.\",",
          "463:                         testEnv.directory(1),",
          "464:                         MetadataVersion.FEATURE_NAME,",
          "465:                         MetadataVersion.latestTesting()),",
          "466:                     String.format(\"Formatting metadata directory %s with %s %s.\",",
          "467:                         testEnv.directory(0),",
          "468:                         MetadataVersion.FEATURE_NAME,",
          "469:                         MetadataVersion.latestTesting())),",
          "470:                 formatter1.outputLines().stream().sorted().collect(Collectors.toList()));",
          "471:             MetaPropertiesEnsemble ensemble = new MetaPropertiesEnsemble.Loader().",
          "472:                 addLogDirs(testEnv.directories).",
          "473:                 load();",
          "474:             MetaProperties logDirProps0 = ensemble.logDirProps().get(testEnv.directory(0));",
          "475:             assertNotNull(logDirProps0);",
          "476:             MetaProperties logDirProps1 = ensemble.logDirProps().get(testEnv.directory(1));",
          "477:             assertNotNull(logDirProps1);",
          "478:         }",
          "479:     }",
          "481:     @Test",
          "482:     public void testFormatWithoutNoInitialControllersFailsWithNewerKraftVersion() throws Exception {",
          "483:         try (TestEnv testEnv = new TestEnv(2)) {",
          "484:             FormatterContext formatter1 = testEnv.newFormatter();",
          "485:             formatter1.formatter.setFeatureLevel(\"kraft.version\", (short) 1);",
          "486:             formatter1.formatter.setUnstableFeatureVersionsEnabled(true);",
          "487:             formatter1.formatter.setNoInitialControllersFlag(false);",
          "488:             assertFalse(formatter1.formatter.hasDynamicQuorum());",
          "489:             assertEquals(\"Cannot set kraft.version to 1 unless KIP-853 configuration is present. \" +",
          "490:                     \"Try removing the --feature flag for kraft.version.\",",
          "491:                 assertThrows(FormatterException.class,",
          "492:                     formatter1.formatter::run).getMessage());",
          "493:         }",
          "494:     }",
          "496:     @Test",
          "497:     public void testFormatWithNoInitialControllersFailsWithOlderKraftVersion() throws Exception {",
          "498:         try (TestEnv testEnv = new TestEnv(2)) {",
          "499:             FormatterContext formatter1 = testEnv.newFormatter();",
          "500:             formatter1.formatter.setFeatureLevel(\"kraft.version\", (short) 0);",
          "501:             formatter1.formatter.setUnstableFeatureVersionsEnabled(true);",
          "502:             formatter1.formatter.setNoInitialControllersFlag(true);",
          "503:             assertTrue(formatter1.formatter.hasDynamicQuorum());",
          "504:             assertEquals(\"Cannot set kraft.version to 0 if KIP-853 configuration is present. \" +",
          "505:                     \"Try removing the --feature flag for kraft.version.\",",
          "506:                 assertThrows(FormatterException.class,",
          "507:                     formatter1.formatter::run).getMessage());",
          "508:         }",
          "509:     }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "7c0fff7c36ddd4c4ab44b5aefdb7f6bb72662054",
      "candidate_info": {
        "commit_hash": "7c0fff7c36ddd4c4ab44b5aefdb7f6bb72662054",
        "repo": "apache/kafka",
        "commit_url": "https://github.com/apache/kafka/commit/7c0fff7c36ddd4c4ab44b5aefdb7f6bb72662054",
        "files": [
          "core/src/main/java/kafka/server/MetadataVersionConfigValidator.java",
          "core/src/main/scala/kafka/server/BrokerServer.scala",
          "core/src/main/scala/kafka/server/KafkaConfig.scala",
          "core/src/main/scala/kafka/tools/StorageTool.scala",
          "core/src/test/java/kafka/server/MetadataVersionConfigValidatorTest.java",
          "core/src/test/scala/unit/kafka/log/LogConfigTest.scala",
          "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
        ],
        "message": "KAFKA-16606 Gate JBOD configuration on 3.7-IV2 (#15834)\n\nSupport for multiple log directories in KRaft exists from\nMetataVersion 3.7-IV2.\n\nWhen migrating a ZK broker to KRaft, we already check that\nthe IBP is high enough before allowing the broker to startup.\n\nWith KIP-584 and KIP-778, Brokers in KRaft mode do not require\nthe IBP configuration - the configuration is deprecated.\nIn KRaft mode inter.broker.protocol.version defaults to\nMetadataVersion.MINIMUM_KRAFT_VERSION (IBP_3_0_IV1).\n\nInstead KRaft brokers discover the MetadataVersion by reading\nthe \"metadata.version\" FeatureLevelRecord from the cluster metadata.\n\nThis change adds a new configuration validation step upon discovering\nthe \"metadata.version\" from the cluster metadata.\n\nReviewers: Mickael Maison <mickael.maison@gmail.com>",
        "before_after_code_files": [
          "core/src/main/java/kafka/server/MetadataVersionConfigValidator.java||core/src/main/java/kafka/server/MetadataVersionConfigValidator.java",
          "core/src/main/scala/kafka/server/BrokerServer.scala||core/src/main/scala/kafka/server/BrokerServer.scala",
          "core/src/main/scala/kafka/server/KafkaConfig.scala||core/src/main/scala/kafka/server/KafkaConfig.scala",
          "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
          "core/src/test/java/kafka/server/MetadataVersionConfigValidatorTest.java||core/src/test/java/kafka/server/MetadataVersionConfigValidatorTest.java",
          "core/src/test/scala/unit/kafka/log/LogConfigTest.scala||core/src/test/scala/unit/kafka/log/LogConfigTest.scala",
          "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
            "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
          ],
          "candidate": [
            "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala",
            "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala"
          ]
        }
      },
      "candidate_diff": {
        "core/src/main/java/kafka/server/MetadataVersionConfigValidator.java||core/src/main/java/kafka/server/MetadataVersionConfigValidator.java": [
          "File: core/src/main/java/kafka/server/MetadataVersionConfigValidator.java -> core/src/main/java/kafka/server/MetadataVersionConfigValidator.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package kafka.server;",
          "20: import org.apache.kafka.image.MetadataDelta;",
          "21: import org.apache.kafka.image.MetadataImage;",
          "22: import org.apache.kafka.image.loader.LoaderManifest;",
          "23: import org.apache.kafka.image.publisher.MetadataPublisher;",
          "24: import org.apache.kafka.server.common.MetadataVersion;",
          "25: import org.apache.kafka.server.fault.FaultHandler;",
          "27: public class MetadataVersionConfigValidator implements MetadataPublisher {",
          "28:     private final String name;",
          "29:     private final KafkaConfig config;",
          "30:     private final FaultHandler faultHandler;",
          "32:     public MetadataVersionConfigValidator(",
          "33:             KafkaConfig config,",
          "34:             FaultHandler faultHandler",
          "35:     ) {",
          "36:         int id = config.brokerId();",
          "37:         this.name = \"MetadataVersionPublisher(id=\" + id + \")\";",
          "38:         this.config = config;",
          "39:         this.faultHandler = faultHandler;",
          "40:     }",
          "42:     @Override",
          "43:     public String name() {",
          "44:         return name;",
          "45:     }",
          "47:     @Override",
          "48:     public void onMetadataUpdate(",
          "49:             MetadataDelta delta,",
          "50:             MetadataImage newImage,",
          "51:             LoaderManifest manifest",
          "52:     ) {",
          "53:         if (delta.featuresDelta() != null) {",
          "54:             if (delta.metadataVersionChanged().isPresent()) {",
          "55:                 onMetadataVersionChanged(newImage.features().metadataVersion());",
          "56:             }",
          "57:         }",
          "58:     }",
          "60:     private void onMetadataVersionChanged(MetadataVersion metadataVersion) {",
          "61:         try {",
          "62:             this.config.validateWithMetadataVersion(metadataVersion);",
          "63:         } catch (Throwable t) {",
          "64:             RuntimeException exception = this.faultHandler.handleFault(",
          "65:                     \"Broker configuration does not support the cluster MetadataVersion\", t);",
          "66:             if (exception != null) {",
          "67:                 throw exception;",
          "68:             }",
          "69:         }",
          "70:     }",
          "71: }",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/server/BrokerServer.scala||core/src/main/scala/kafka/server/BrokerServer.scala": [
          "File: core/src/main/scala/kafka/server/BrokerServer.scala -> core/src/main/scala/kafka/server/BrokerServer.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "447:         rlm.startup()",
          "448:       }",
          "450:       brokerMetadataPublisher = new BrokerMetadataPublisher(config,",
          "451:         metadataCache,",
          "452:         logManager,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "450:       metadataPublishers.add(new MetadataVersionConfigValidator(config, sharedServer.metadataPublishingFaultHandler))",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/server/KafkaConfig.scala||core/src/main/scala/kafka/server/KafkaConfig.scala": [
          "File: core/src/main/scala/kafka/server/KafkaConfig.scala -> core/src/main/scala/kafka/server/KafkaConfig.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "1363:       }",
          "1364:       validateAdvertisedListenersNonEmptyForBroker()",
          "1365:     }",
          "1367:     val listenerNames = listeners.map(_.listenerName).toSet",
          "1368:     if (processRoles.isEmpty || processRoles.contains(ProcessRole.BrokerRole)) {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1366:     if (processRoles.contains(ProcessRole.BrokerRole)",
          "1367:       && originals.containsKey(ReplicationConfigs.INTER_BROKER_PROTOCOL_VERSION_CONFIG)",
          "1368:       && logDirs.size > 1) {",
          "1369:         require(interBrokerProtocolVersion.isDirectoryAssignmentSupported,",
          "1370:           s\"Multiple log directories (aka JBOD) are not supported with the configured \" +",
          "1371:             s\"${interBrokerProtocolVersion} ${ReplicationConfigs.INTER_BROKER_PROTOCOL_VERSION_CONFIG}. \" +",
          "1372:             s\"Need ${MetadataVersion.IBP_3_7_IV2} or higher\")",
          "1373:     }",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1460:     }",
          "1461:   }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1475:   def validateWithMetadataVersion(metadataVersion: MetadataVersion): Unit = {",
          "1476:     if (processRoles.contains(ProcessRole.BrokerRole) && logDirs.size > 1) {",
          "1477:       require(metadataVersion.isDirectoryAssignmentSupported,",
          "1478:         s\"Multiple log directories (aka JBOD) are not supported in the current MetadataVersion ${metadataVersion}. \" +",
          "1479:           s\"Need ${MetadataVersion.IBP_3_7_IV2} or higher\")",
          "1480:     }",
          "1481:   }",
          "",
          "---------------"
        ],
        "core/src/main/scala/kafka/tools/StorageTool.scala||core/src/main/scala/kafka/tools/StorageTool.scala": [
          "File: core/src/main/scala/kafka/tools/StorageTool.scala -> core/src/main/scala/kafka/tools/StorageTool.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "45: import scala.collection.mutable.ArrayBuffer",
          "47: object StorageTool extends Logging {",
          "48:   def main(args: Array[String]): Unit = {",
          "49:     try {",
          "112:       }",
          "117:     }",
          "118:   }",
          "121:     if (!metadataVersion.isKRaftSupported) {",
          "122:       throw new TerseFailure(s\"Must specify a valid KRaft metadata.version of at least ${MetadataVersion.IBP_3_0_IV0}.\")",
          "123:     }",
          "124:     if (!metadataVersion.isProduction) {",
          "126:         System.out.println(s\"WARNING: using pre-production metadata.version $metadataVersion.\")",
          "127:       } else {",
          "128:         throw new TerseFailure(s\"The metadata.version $metadataVersion is not ready for production use yet.\")",
          "129:       }",
          "130:     }",
          "131:   }",
          "133:   private[tools] def generateFeatureRecords(metadataRecords: ArrayBuffer[ApiMessageAndVersion],",
          "",
          "[Removed Lines]",
          "50:       val namespace = parseArguments(args)",
          "51:       val command = namespace.getString(\"command\")",
          "52:       val config = Option(namespace.getString(\"config\")).flatMap(",
          "53:         p => Some(new KafkaConfig(Utils.loadProps(p))))",
          "54:       command match {",
          "55:         case \"info\" =>",
          "56:           val directories = configToLogDirectories(config.get)",
          "57:           val selfManagedMode = configToSelfManagedMode(config.get)",
          "58:           Exit.exit(infoCommand(System.out, selfManagedMode, directories))",
          "60:         case \"format\" =>",
          "61:           val directories = configToLogDirectories(config.get)",
          "62:           val clusterId = namespace.getString(\"cluster_id\")",
          "63:           val metaProperties = new MetaProperties.Builder().",
          "64:             setVersion(MetaPropertiesVersion.V1).",
          "65:             setClusterId(clusterId).",
          "66:             setNodeId(config.get.nodeId).",
          "67:             build()",
          "68:           val metadataRecords : ArrayBuffer[ApiMessageAndVersion] = ArrayBuffer()",
          "69:           val specifiedFeatures: util.List[String] = namespace.getList(\"feature\")",
          "70:           val releaseVersionFlagSpecified = namespace.getString(\"release_version\") != null",
          "71:           if (releaseVersionFlagSpecified && specifiedFeatures != null) {",
          "72:             throw new TerseFailure(\"Both --release-version and --feature were set. Only one of the two flags can be set.\")",
          "73:           }",
          "74:           val featureNamesAndLevelsMap = featureNamesAndLevels(Option(specifiedFeatures).getOrElse(Collections.emptyList).asScala.toList)",
          "75:           val metadataVersion = getMetadataVersion(namespace, featureNamesAndLevelsMap,",
          "76:             Option(config.get.originals.get(ReplicationConfigs.INTER_BROKER_PROTOCOL_VERSION_CONFIG)).map(_.toString))",
          "77:           validateMetadataVersion(metadataVersion, config)",
          "80:           generateFeatureRecords(",
          "81:             metadataRecords,",
          "82:             metadataVersion,",
          "83:             featureNamesAndLevelsMap,",
          "84:             Features.PRODUCTION_FEATURES.asScala.toList,",
          "85:             config.get.unstableFeatureVersionsEnabled,",
          "86:             releaseVersionFlagSpecified",
          "87:           )",
          "88:           getUserScramCredentialRecords(namespace).foreach(userScramCredentialRecords => {",
          "89:             if (!metadataVersion.isScramSupported) {",
          "90:               throw new TerseFailure(s\"SCRAM is only supported in metadata.version ${MetadataVersion.IBP_3_5_IV2} or later.\")",
          "91:             }",
          "92:             for (record <- userScramCredentialRecords) {",
          "93:               metadataRecords.append(new ApiMessageAndVersion(record, 0.toShort))",
          "94:             }",
          "95:           })",
          "97:           val bootstrapMetadata = buildBootstrapMetadata(metadataVersion, Some(metadataRecords), \"format command\")",
          "98:           val ignoreFormatted = namespace.getBoolean(\"ignore_formatted\")",
          "99:           if (!configToSelfManagedMode(config.get)) {",
          "100:             throw new TerseFailure(\"The kafka configuration file appears to be for \" +",
          "101:               \"a legacy cluster. Formatting is only supported for clusters in KRaft mode.\")",
          "102:           }",
          "103:           Exit.exit(formatCommand(System.out, directories, metaProperties, bootstrapMetadata,",
          "104:                                   metadataVersion,ignoreFormatted))",
          "106:         case \"random-uuid\" =>",
          "107:           System.out.println(Uuid.randomUuid)",
          "108:           Exit.exit(0)",
          "110:         case _ =>",
          "111:           throw new RuntimeException(s\"Unknown command $command\")",
          "113:     } catch {",
          "114:       case e: TerseFailure =>",
          "115:         System.err.println(e.getMessage)",
          "116:         Exit.exit(1, Some(e.getMessage))",
          "120:   private def validateMetadataVersion(metadataVersion: MetadataVersion, config: Option[KafkaConfig]): Unit = {",
          "125:       if (config.get.unstableFeatureVersionsEnabled) {",
          "",
          "[Added Lines]",
          "50:     var exitCode: Integer = 0",
          "51:     var message: Option[String] = None",
          "53:       exitCode = execute(args)",
          "54:     } catch {",
          "55:       case e: TerseFailure =>",
          "56:         exitCode = 1",
          "57:         message = Some(e.getMessage)",
          "58:     }",
          "59:     message.foreach(System.err.println)",
          "60:     Exit.exit(exitCode, message)",
          "61:   }",
          "68:   def execute(args: Array[String]): Int = {",
          "69:     val namespace = parseArguments(args)",
          "70:     val command = namespace.getString(\"command\")",
          "71:     val config = Option(namespace.getString(\"config\")).flatMap(",
          "72:       p => Some(new KafkaConfig(Utils.loadProps(p))))",
          "73:     command match {",
          "74:       case \"info\" =>",
          "75:         val directories = configToLogDirectories(config.get)",
          "76:         val selfManagedMode = configToSelfManagedMode(config.get)",
          "77:         infoCommand(System.out, selfManagedMode, directories)",
          "79:       case \"format\" =>",
          "80:         runFormatCommand(namespace, config.get)",
          "82:       case \"random-uuid\" =>",
          "83:         System.out.println(Uuid.randomUuid)",
          "84:         0",
          "85:       case _ =>",
          "86:         throw new RuntimeException(s\"Unknown command $command\")",
          "87:     }",
          "88:   }",
          "97:   def runFormatCommand(namespace: Namespace, config: KafkaConfig) = {",
          "98:     val directories = configToLogDirectories(config)",
          "99:     val clusterId = namespace.getString(\"cluster_id\")",
          "100:     val metaProperties = new MetaProperties.Builder().",
          "101:       setVersion(MetaPropertiesVersion.V1).",
          "102:       setClusterId(clusterId).",
          "103:       setNodeId(config.nodeId).",
          "104:       build()",
          "105:     val metadataRecords : ArrayBuffer[ApiMessageAndVersion] = ArrayBuffer()",
          "106:     val specifiedFeatures: util.List[String] = namespace.getList(\"feature\")",
          "107:     val releaseVersionFlagSpecified = namespace.getString(\"release_version\") != null",
          "108:     if (releaseVersionFlagSpecified && specifiedFeatures != null) {",
          "109:       throw new TerseFailure(\"Both --release-version and --feature were set. Only one of the two flags can be set.\")",
          "110:     }",
          "111:     val featureNamesAndLevelsMap = featureNamesAndLevels(Option(specifiedFeatures).getOrElse(Collections.emptyList).asScala.toList)",
          "112:     val metadataVersion = getMetadataVersion(namespace, featureNamesAndLevelsMap,",
          "113:       Option(config.originals.get(ReplicationConfigs.INTER_BROKER_PROTOCOL_VERSION_CONFIG)).map(_.toString))",
          "114:     validateMetadataVersion(metadataVersion, config)",
          "117:     generateFeatureRecords(",
          "118:       metadataRecords,",
          "119:       metadataVersion,",
          "120:       featureNamesAndLevelsMap,",
          "121:       Features.PRODUCTION_FEATURES.asScala.toList,",
          "122:       config.unstableFeatureVersionsEnabled,",
          "123:       releaseVersionFlagSpecified",
          "124:     )",
          "125:     getUserScramCredentialRecords(namespace).foreach(userScramCredentialRecords => {",
          "126:       if (!metadataVersion.isScramSupported) {",
          "127:         throw new TerseFailure(s\"SCRAM is only supported in metadata.version ${MetadataVersion.IBP_3_5_IV2} or later.\")",
          "129:       for (record <- userScramCredentialRecords) {",
          "130:         metadataRecords.append(new ApiMessageAndVersion(record, 0.toShort))",
          "131:       }",
          "132:     })",
          "133:     val bootstrapMetadata = buildBootstrapMetadata(metadataVersion, Some(metadataRecords), \"format command\")",
          "134:     val ignoreFormatted = namespace.getBoolean(\"ignore_formatted\")",
          "135:     if (!configToSelfManagedMode(config)) {",
          "136:       throw new TerseFailure(\"The kafka configuration file appears to be for \" +",
          "137:         \"a legacy cluster. Formatting is only supported for clusters in KRaft mode.\")",
          "139:     formatCommand(System.out, directories, metaProperties, bootstrapMetadata,",
          "140:       metadataVersion,ignoreFormatted)",
          "143:   private def validateMetadataVersion(metadataVersion: MetadataVersion, config: KafkaConfig): Unit = {",
          "148:       if (config.unstableFeatureVersionsEnabled) {",
          "154:     try {",
          "155:       config.validateWithMetadataVersion(metadataVersion)",
          "156:     } catch {",
          "157:       case e: IllegalArgumentException => throw new TerseFailure(s\"Invalid configuration for metadata version: ${e.getMessage}\")",
          "158:     }",
          "",
          "---------------"
        ],
        "core/src/test/java/kafka/server/MetadataVersionConfigValidatorTest.java||core/src/test/java/kafka/server/MetadataVersionConfigValidatorTest.java": [
          "File: core/src/test/java/kafka/server/MetadataVersionConfigValidatorTest.java -> core/src/test/java/kafka/server/MetadataVersionConfigValidatorTest.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "18: package kafka.server;",
          "20: import org.apache.kafka.common.metadata.FeatureLevelRecord;",
          "21: import org.apache.kafka.image.MetadataDelta;",
          "22: import org.apache.kafka.image.MetadataImage;",
          "23: import org.apache.kafka.image.MetadataProvenance;",
          "24: import org.apache.kafka.image.loader.LogDeltaManifest;",
          "25: import org.apache.kafka.raft.LeaderAndEpoch;",
          "26: import org.apache.kafka.server.common.MetadataVersion;",
          "27: import org.apache.kafka.server.fault.FaultHandler;",
          "28: import org.junit.jupiter.api.Test;",
          "30: import static org.mockito.ArgumentMatchers.eq;",
          "31: import static org.mockito.BDDMockito.willAnswer;",
          "32: import static org.mockito.Mockito.mock;",
          "33: import static org.mockito.Mockito.times;",
          "34: import static org.mockito.Mockito.verify;",
          "35: import static org.mockito.Mockito.verifyNoMoreInteractions;",
          "36: import static org.mockito.Mockito.when;",
          "38: public class MetadataVersionConfigValidatorTest {",
          "40:     private static final LogDeltaManifest TEST_MANIFEST = LogDeltaManifest.newBuilder()",
          "41:             .provenance(MetadataProvenance.EMPTY)",
          "42:             .leaderAndEpoch(LeaderAndEpoch.UNKNOWN)",
          "43:             .numBatches(1)",
          "44:             .elapsedNs(90)",
          "45:             .numBytes(88)",
          "46:             .build();",
          "47:     public static final MetadataProvenance TEST_PROVENANCE =",
          "48:             new MetadataProvenance(50, 3, 8000);",
          "50:     void testWith(MetadataVersion metadataVersion, KafkaConfig config, FaultHandler faultHandler) throws Exception {",
          "51:         try (MetadataVersionConfigValidator validator = new MetadataVersionConfigValidator(config, faultHandler)) {",
          "52:             MetadataDelta delta = new MetadataDelta.Builder()",
          "53:                     .setImage(MetadataImage.EMPTY)",
          "54:                     .build();",
          "55:             if (metadataVersion != null) {",
          "56:                 delta.replay(new FeatureLevelRecord().",
          "57:                         setName(MetadataVersion.FEATURE_NAME).",
          "58:                         setFeatureLevel(metadataVersion.featureLevel()));",
          "59:             }",
          "60:             MetadataImage image = delta.apply(TEST_PROVENANCE);",
          "62:             validator.onMetadataUpdate(delta, image, TEST_MANIFEST);",
          "63:         }",
          "64:     }",
          "66:     @Test",
          "67:     void testValidatesConfigOnMetadataChange() throws Exception {",
          "68:         MetadataVersion metadataVersion = MetadataVersion.IBP_3_7_IV2;",
          "69:         KafkaConfig config = mock(KafkaConfig.class);",
          "70:         FaultHandler faultHandler = mock(FaultHandler.class);",
          "72:         when(config.brokerId()).thenReturn(8);",
          "74:         testWith(metadataVersion, config, faultHandler);",
          "76:         verify(config, times(1)).validateWithMetadataVersion(eq(metadataVersion));",
          "77:         verifyNoMoreInteractions(faultHandler);",
          "78:     }",
          "80:     @SuppressWarnings(\"ThrowableNotThrown\")",
          "81:     @Test",
          "82:     void testInvokesFaultHandlerOnException() throws Exception {",
          "83:         MetadataVersion metadataVersion = MetadataVersion.IBP_3_7_IV2;",
          "84:         Exception exception = new Exception();",
          "85:         KafkaConfig config = mock(KafkaConfig.class);",
          "86:         FaultHandler faultHandler = mock(FaultHandler.class);",
          "88:         when(config.brokerId()).thenReturn(8);",
          "89:         willAnswer(invocation -> {",
          "90:             throw exception;",
          "91:         }).given(config).validateWithMetadataVersion(eq(metadataVersion));",
          "93:         testWith(metadataVersion, config, faultHandler);",
          "95:         verify(config, times(1)).validateWithMetadataVersion(eq(metadataVersion));",
          "96:         verify(faultHandler, times(1)).handleFault(",
          "97:                 eq(\"Broker configuration does not support the cluster MetadataVersion\"),",
          "98:                 eq(exception));",
          "99:     }",
          "100: }",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/log/LogConfigTest.scala||core/src/test/scala/unit/kafka/log/LogConfigTest.scala": [
          "File: core/src/test/scala/unit/kafka/log/LogConfigTest.scala -> core/src/test/scala/unit/kafka/log/LogConfigTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: import org.apache.kafka.common.config.ConfigDef.Importance.MEDIUM",
          "23: import org.apache.kafka.common.config.ConfigDef.Type.INT",
          "24: import org.apache.kafka.common.config.{ConfigException, SslConfigs, TopicConfig}",
          "25: import org.junit.jupiter.api.Assertions._",
          "26: import org.junit.jupiter.api.Test",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "25: import org.apache.kafka.server.common.MetadataVersion",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "419:     assertEquals(oneDayInMillis, logProps.get(TopicConfig.MESSAGE_TIMESTAMP_BEFORE_MAX_MS_CONFIG))",
          "420:     assertEquals(oneDayInMillis, logProps.get(TopicConfig.MESSAGE_TIMESTAMP_AFTER_MAX_MS_CONFIG))",
          "421:   }",
          "422: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "424:   @Test",
          "425:   def testValidateWithMetadataVersionJbodSupport(): Unit = {",
          "426:     def validate(metadataVersion: MetadataVersion, jbodConfig: Boolean): Unit =",
          "427:       KafkaConfig.fromProps(",
          "428:           TestUtils.createBrokerConfig(nodeId = 0, zkConnect = null, logDirCount = if (jbodConfig) 2 else 1)",
          "429:         ).validateWithMetadataVersion(metadataVersion)",
          "431:     validate(MetadataVersion.IBP_3_6_IV2, jbodConfig = false)",
          "432:     validate(MetadataVersion.IBP_3_7_IV0, jbodConfig = false)",
          "433:     validate(MetadataVersion.IBP_3_7_IV2, jbodConfig = false)",
          "434:     assertThrows(classOf[IllegalArgumentException], () =>",
          "435:       validate(MetadataVersion.IBP_3_6_IV2, jbodConfig = true))",
          "436:     assertThrows(classOf[IllegalArgumentException], () =>",
          "437:       validate(MetadataVersion.IBP_3_7_IV0, jbodConfig = true))",
          "438:     validate(MetadataVersion.IBP_3_7_IV2, jbodConfig = true)",
          "439:   }",
          "",
          "---------------"
        ],
        "core/src/test/scala/unit/kafka/tools/StorageToolTest.scala||core/src/test/scala/unit/kafka/tools/StorageToolTest.scala": [
          "File: core/src/test/scala/unit/kafka/tools/StorageToolTest.scala -> core/src/test/scala/unit/kafka/tools/StorageToolTest.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "33: import org.apache.kafka.common.metadata.{FeatureLevelRecord, UserScramCredentialRecord}",
          "34: import org.apache.kafka.metadata.properties.{MetaProperties, MetaPropertiesEnsemble, MetaPropertiesVersion, PropertiesUtils}",
          "35: import org.apache.kafka.raft.QuorumConfig",
          "37: import org.junit.jupiter.api.Assertions.{assertEquals, assertFalse, assertThrows, assertTrue}",
          "38: import org.junit.jupiter.api.{Test, Timeout}",
          "39: import org.junit.jupiter.params.ParameterizedTest",
          "40: import org.junit.jupiter.params.provider.{EnumSource, ValueSource}",
          "42: import scala.collection.mutable",
          "43: import scala.collection.mutable.ArrayBuffer",
          "",
          "[Removed Lines]",
          "36: import org.apache.kafka.server.config.{KRaftConfigs, ServerConfigs, ServerLogConfigs}",
          "",
          "[Added Lines]",
          "36: import org.apache.kafka.server.config.{KRaftConfigs, ReplicationConfigs, ServerConfigs, ServerLogConfigs}",
          "41: import org.mockito.Mockito",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "661:       assertEquals(1, exitStatus)",
          "662:     }",
          "663:   }",
          "664: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "666:   @Test",
          "667:   def testFormatValidatesConfigForMetadataVersion(): Unit = {",
          "668:     val config = Mockito.spy(new KafkaConfig(TestUtils.createBrokerConfig(10, null)))",
          "669:     val args = Array(\"format\",",
          "670:       \"-c\", \"dummy.properties\",",
          "671:       \"-t\", \"XcZZOzUqS4yHOjhMQB6JLQ\",",
          "672:       \"--release-version\", MetadataVersion.LATEST_PRODUCTION.toString)",
          "673:     val exitCode = StorageTool.runFormatCommand(StorageTool.parseArguments(args), config)",
          "674:     Mockito.verify(config, Mockito.times(1)).validateWithMetadataVersion(MetadataVersion.LATEST_PRODUCTION)",
          "675:     assertEquals(0, exitCode)",
          "676:   }",
          "678:   @Test",
          "679:   def testJbodSupportValidation(): Unit = {",
          "680:     def formatWith(logDirCount: Int, metadataVersion: MetadataVersion): Integer = {",
          "681:       val properties = TestUtils.createBrokerConfig(10, null, logDirCount = logDirCount)",
          "682:       properties.remove(ReplicationConfigs.INTER_BROKER_PROTOCOL_VERSION_CONFIG)",
          "683:       val configFile = TestUtils.tempPropertiesFile(properties.asScala.toMap).toPath.toString",
          "684:       StorageTool.execute(Array(\"format\",",
          "685:         \"-c\", configFile,",
          "686:         \"-t\", \"XcZZOzUqS4yHOjhMQB6JLQ\",",
          "687:         \"--release-version\", metadataVersion.toString))",
          "688:     }",
          "690:     assertEquals(0, formatWith(1, MetadataVersion.IBP_3_6_IV2))",
          "691:     assertEquals(\"Invalid configuration for metadata version: \" +",
          "692:       \"requirement failed: Multiple log directories (aka JBOD) are not supported in the current MetadataVersion 3.6-IV2. Need 3.7-IV2 or higher\",",
          "693:       assertThrows(classOf[TerseFailure], () => formatWith(2, MetadataVersion.IBP_3_6_IV2)).getMessage)",
          "694:     assertEquals(0, formatWith(1, MetadataVersion.IBP_3_7_IV2))",
          "695:     assertEquals(0, formatWith(2, MetadataVersion.IBP_3_7_IV2))",
          "696:   }",
          "",
          "---------------"
        ]
      }
    }
  ]
}