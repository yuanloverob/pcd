{
  "cve_id": "CVE-2021-45229",
  "cve_desc": "It was discovered that the \"Trigger DAG with config\" screen was susceptible to XSS attacks via the `origin` query argument. This issue affects Apache Airflow versions 2.2.3 and below.",
  "repo": "apache/airflow",
  "patch_hash": "628aa1f99c865d97d0b1c7c76e630e43a7b8d319",
  "patch_info": {
    "commit_hash": "628aa1f99c865d97d0b1c7c76e630e43a7b8d319",
    "repo": "apache/airflow",
    "commit_url": "https://github.com/apache/airflow/commit/628aa1f99c865d97d0b1c7c76e630e43a7b8d319",
    "files": [
      "airflow/www/templates/airflow/trigger.html",
      "tests/www/views/test_views_trigger_dag.py"
    ],
    "message": "Simplify trigger cancel button (#21591)\n\nCo-authored-by: Jed Cunningham <jedcunningham@apache.org>\n(cherry picked from commit 65297673a318660fba76797e50d0c06804dfcafc)",
    "before_after_code_files": [
      "airflow/www/templates/airflow/trigger.html||airflow/www/templates/airflow/trigger.html",
      "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py"
    ]
  },
  "patch_diff": {
    "airflow/www/templates/airflow/trigger.html||airflow/www/templates/airflow/trigger.html": [
      "File: airflow/www/templates/airflow/trigger.html -> airflow/www/templates/airflow/trigger.html",
      "--- Hunk 1 ---",
      "[Context before]",
      "63:       </label>",
      "64:     </div>",
      "65:     <button type=\"submit\" class=\"btn btn-primary\">Trigger</button>",
      "67:   </form>",
      "68: {% endblock %}",
      "",
      "[Removed Lines]",
      "66:     <button type=\"button\" class=\"btn\" onclick=\"location.href = '{{ origin }}'; return false\">Cancel</button>",
      "",
      "[Added Lines]",
      "66:     <a class=\"btn\" href=\"{{ origin }}\">Cancel</a>",
      "",
      "---------------"
    ],
    "tests/www/views/test_views_trigger_dag.py||tests/www/views/test_views_trigger_dag.py": [
      "File: tests/www/views/test_views_trigger_dag.py -> tests/www/views/test_views_trigger_dag.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "133:         (\"javascript:alert(1)\", \"/home\"),",
      "134:         (\"http://google.com\", \"/home\"),",
      "135:         (\"36539'%3balert(1)%2f%2f166\", \"/home\"),",
      "136:         (",
      "137:             \"%2Ftree%3Fdag_id%3Dexample_bash_operator';alert(33)//\",",
      "138:             \"/home\",",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "136:         (",
      "137:             '\"><script>alert(99)</script><a href=\"',",
      "138:             \"&#34;&gt;&lt;script&gt;alert(99)&lt;/script&gt;&lt;a href=&#34;\",",
      "139:         ),",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "145:     test_dag_id = \"example_bash_operator\"",
      "147:     resp = admin_client.get(f'trigger?dag_id={test_dag_id}&origin={test_origin}')",
      "156: @pytest.mark.parametrize(",
      "",
      "[Removed Lines]",
      "148:     check_content_in_response(",
      "149:         '<button type=\"button\" class=\"btn\" onclick=\"location.href = \\'{}\\'; return false\">'.format(",
      "150:             expected_origin",
      "151:         ),",
      "152:         resp,",
      "153:     )",
      "",
      "[Added Lines]",
      "152:     check_content_in_response(f'<a class=\"btn\" href=\"{expected_origin}\">Cancel</a>', resp)",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "5ccbf30d226a80af4aacccfc39b3528904781d5d",
      "candidate_info": {
        "commit_hash": "5ccbf30d226a80af4aacccfc39b3528904781d5d",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/5ccbf30d226a80af4aacccfc39b3528904781d5d",
        "files": [
          ".github/workflows/build-images.yml",
          ".github/workflows/ci.yml",
          "BREEZE.rst",
          "CI.rst",
          "Dockerfile",
          "Dockerfile.ci",
          "IMAGES.rst",
          "airflow/www/ask_for_recompile_assets_if_needed.sh",
          "breeze",
          "breeze-complete",
          "dev/REFRESHING_CI_CACHE.md",
          "dev/refresh_images.sh",
          "docs/docker-stack/build.rst",
          "docs/docker-stack/docker-examples/customizing/add-build-essential-custom.sh",
          "docs/docker-stack/docker-examples/customizing/custom-sources.sh",
          "docs/docker-stack/docker-examples/customizing/github-different-repository.sh",
          "docs/docker-stack/docker-examples/customizing/github-main.sh",
          "docs/docker-stack/docker-examples/customizing/github-v2-2-test.sh",
          "docs/docker-stack/docker-examples/customizing/pypi-dev-runtime-deps.sh",
          "docs/docker-stack/docker-examples/customizing/pypi-extras-and-deps.sh",
          "docs/docker-stack/docker-examples/customizing/pypi-selected-version.sh",
          "docs/docker-stack/docker-examples/restricted/restricted_environments.sh",
          "docs/docker-stack/entrypoint.rst",
          "docs/docker-stack/recipes.rst",
          "docs/helm-chart/manage-dags-files.rst",
          "docs/helm-chart/quick-start.rst",
          "scripts/ci/images/ci_prepare_ci_image_on_ci.sh",
          "scripts/ci/images/ci_prepare_prod_image_on_ci.sh",
          "scripts/ci/images/ci_push_ci_images.sh",
          "scripts/ci/images/ci_push_production_images.sh",
          "scripts/ci/images/ci_run_prod_image_test.sh",
          "scripts/ci/libraries/_all_libs.sh",
          "scripts/ci/libraries/_build_images.sh",
          "scripts/ci/libraries/_initialization.sh",
          "scripts/ci/libraries/_md5sum.sh",
          "scripts/ci/libraries/_push_pull_remove_images.sh",
          "scripts/ci/libraries/_spinner.sh",
          "scripts/ci/libraries/_verbosity.sh",
          "scripts/ci/pre_commit/pre_commit_ci_build.sh",
          "scripts/ci/tools/build_dockerhub.sh",
          "scripts/docker/common.sh",
          "scripts/in_container/entrypoint_ci.sh"
        ],
        "message": "Switch to 'buildkit' to build Airflow images (#20664)\n\nThe \"buildkit\" is much more modern docker build mechanism and supports\nmultiarchitecture builds which makes it suitable for our future ARM\nsupport, it also has nicer UI and much more sophisticated caching\nmechanisms as well as supports better multi-segment builds.\n\nBuildKit has been promoted to official for quite a while and it is\nrather stable now. Also we can now install BuildKit Plugin to docker\nthat add capabilities of building and managin cache using dedicated\nbuilders (previously BuildKit cache was managed using rather\ncomplex external tools).\n\nThis gives us an opportunity to vastly\nsimplify our build scripts, because it has now much more robust caching\nmechanism than the old docker build (which forced us to pull images\nbefore using them as cache).\n\nWe had a lot of complexity involved in efficient caching\nbut with BuildKit all that can be vastly simplified and we can\nget rid of:\n\n  * keeping base python images in our registry\n  * keeping build segments for prod image in our registry\n  * keeping manifest images in our registry\n  * deciding when to pull or pull&build image (not needed now, we can\n    always build image with --cache-from and buildkit will pull cached\n    layers as needed\n  * building the image when performing pre-commit (rather than that\n    we simply encourage users to rebuild the image via breeze command)\n  * pulling the images before building\n  * separate 'build' cache kept in our registry (not needed any more\n    as buildkit allows to keep cache for all segments of multi-segmented\n    build in a single cache\n  * the nice animated tty UI of buildkit eliminates the need of manual\n    spinner\n  * and a number of other complexities.\n\nDepends on #20238\n\n(cherry picked from commit ad28f69f74f4ba5defd6ad71c3d8b67d220c7fc2)",
        "before_after_code_files": [
          "Dockerfile.ci||Dockerfile.ci",
          "airflow/www/ask_for_recompile_assets_if_needed.sh||airflow/www/ask_for_recompile_assets_if_needed.sh",
          "dev/refresh_images.sh||dev/refresh_images.sh",
          "scripts/ci/images/ci_prepare_ci_image_on_ci.sh||scripts/ci/images/ci_prepare_ci_image_on_ci.sh",
          "scripts/ci/images/ci_prepare_prod_image_on_ci.sh||scripts/ci/images/ci_prepare_prod_image_on_ci.sh",
          "scripts/ci/images/ci_push_ci_images.sh||scripts/ci/images/ci_push_ci_images.sh",
          "scripts/ci/images/ci_push_production_images.sh||scripts/ci/images/ci_push_production_images.sh",
          "scripts/ci/images/ci_run_prod_image_test.sh||scripts/ci/images/ci_run_prod_image_test.sh",
          "scripts/ci/libraries/_all_libs.sh||scripts/ci/libraries/_all_libs.sh",
          "scripts/ci/libraries/_build_images.sh||scripts/ci/libraries/_build_images.sh",
          "scripts/ci/libraries/_initialization.sh||scripts/ci/libraries/_initialization.sh",
          "scripts/ci/libraries/_md5sum.sh||scripts/ci/libraries/_md5sum.sh",
          "scripts/ci/libraries/_push_pull_remove_images.sh||scripts/ci/libraries/_push_pull_remove_images.sh",
          "scripts/ci/libraries/_spinner.sh||scripts/ci/libraries/_spinner.sh",
          "scripts/ci/libraries/_verbosity.sh||scripts/ci/libraries/_verbosity.sh",
          "scripts/ci/pre_commit/pre_commit_ci_build.sh||scripts/ci/pre_commit/pre_commit_ci_build.sh",
          "scripts/ci/tools/build_dockerhub.sh||scripts/ci/tools/build_dockerhub.sh",
          "scripts/docker/common.sh||scripts/docker/common.sh",
          "scripts/in_container/entrypoint_ci.sh||scripts/in_container/entrypoint_ci.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "Dockerfile.ci||Dockerfile.ci": [
          "File: Dockerfile.ci -> Dockerfile.ci",
          "--- Hunk 1 ---",
          "[Context before]",
          "293:         /scripts/docker/install_airflow_dependencies_from_branch_tip.sh; \\",
          "294:     fi",
          "301: # Copy package.json and yarn.lock to install node modules",
          "302: # this way even if other static check files change, node modules will not need to be installed",
          "303: # we want to keep node_modules so we can do this step separately from compiling assets",
          "",
          "[Removed Lines]",
          "296: # Generate random hex dump file so that we can determine whether it's faster to rebuild the image",
          "297: # using current cache (when our dump is the same as the remote onb) or better to pull",
          "298: # the new image (when it is different)",
          "299: RUN head -c 30 /dev/urandom | xxd -ps >/build-cache-hash",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "airflow/www/ask_for_recompile_assets_if_needed.sh||airflow/www/ask_for_recompile_assets_if_needed.sh": [
          "File: airflow/www/ask_for_recompile_assets_if_needed.sh -> airflow/www/ask_for_recompile_assets_if_needed.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "30: md5sum=$(find package.json yarn.lock static/css static/js -type f | sort | xargs md5sum)",
          "31: old_md5sum=$(cat \"${MD5SUM_FILE}\" 2>/dev/null || true)",
          "32: if [[ ${old_md5sum} != \"${md5sum}\" ]]; then",
          "34:         echo",
          "35:         echo -e \"${YELLOW}Recompiling assets as they have changed and you need them for 'start_airflow' command${NO_COLOR}\"",
          "36:         echo",
          "",
          "[Removed Lines]",
          "33:     if [[ ${START_AIRFLOW} == \"true\" && ${USE_AIRFLOW_VERSION} == \"\" ]]; then",
          "",
          "[Added Lines]",
          "33:     if [[ ${START_AIRFLOW:=\"false\"} == \"true\" && ${USE_AIRFLOW_VERSION:=} == \"\" ]]; then",
          "",
          "---------------"
        ],
        "dev/refresh_images.sh||dev/refresh_images.sh": [
          "File: dev/refresh_images.sh -> dev/refresh_images.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "32: python_version=$1",
          "",
          "[Removed Lines]",
          "34: ./breeze build-image --python \"${python_version}\" --build-cache-pulled  --check-if-base-python-image-updated --verbose",
          "35: ./breeze build-image --python \"${python_version}\" --build-cache-pulled  --production-image --verbose",
          "37: ./breeze push-image --python \"${python_version}\"",
          "38: ./breeze push-image --production-image --python \"${python_version}\"",
          "",
          "[Added Lines]",
          "34: ./breeze prepare-build-cache --python \"${python_version}\" --verbose",
          "35: ./breeze prepare-build-cache --python \"${python_version}\" --production-image --verbose",
          "",
          "---------------"
        ],
        "scripts/ci/images/ci_prepare_ci_image_on_ci.sh||scripts/ci/images/ci_prepare_ci_image_on_ci.sh": [
          "File: scripts/ci/images/ci_prepare_ci_image_on_ci.sh -> scripts/ci/images/ci_prepare_ci_image_on_ci.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "38:     else",
          "39:         build_images::rebuild_ci_image_if_needed",
          "40:     fi",
          "46:     # Skip the image check entirely for the rest of the script",
          "47:     export CHECK_IMAGE_FOR_REBUILD=\"false\"",
          "48:     start_end::group_end",
          "",
          "[Removed Lines]",
          "42:     # Disable force pulling forced above this is needed for the subsequent scripts so that",
          "43:     # They do not try to pull/build images again.",
          "44:     unset FORCE_PULL_IMAGES",
          "45:     unset FORCE_BUILD",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "scripts/ci/images/ci_prepare_prod_image_on_ci.sh||scripts/ci/images/ci_prepare_prod_image_on_ci.sh": [
          "File: scripts/ci/images/ci_prepare_prod_image_on_ci.sh -> scripts/ci/images/ci_prepare_prod_image_on_ci.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "38:     else",
          "39:         build_images::build_prod_images_from_locally_built_airflow_packages",
          "40:     fi",
          "45:     unset FORCE_BUILD",
          "46: }",
          "",
          "[Removed Lines]",
          "42:     # Disable force pulling forced above this is needed for the subsequent scripts so that",
          "43:     # They do not try to pull/build images again",
          "44:     unset FORCE_PULL_IMAGES",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "scripts/ci/images/ci_push_ci_images.sh||scripts/ci/images/ci_push_ci_images.sh": [
          "File: scripts/ci/images/ci_push_ci_images.sh -> scripts/ci/images/ci_push_ci_images.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: # shellcheck source=scripts/ci/libraries/_script_init.sh",
          "19: . \"$( dirname \"${BASH_SOURCE[0]}\" )/../libraries/_script_init.sh\"",
          "21: build_images::prepare_ci_build",
          "23: build_images::login_to_docker_registry",
          "",
          "[Removed Lines]",
          "25: push_pull_remove_images::push_ci_images_to_github",
          "",
          "[Added Lines]",
          "21: # Pushes Ci images with tags to registry in GitHub",
          "22: function push_ci_image_with_tag_to_github() {",
          "23:     start_end::group_start \"Push CI image\"",
          "24:     docker_v tag \"${AIRFLOW_CI_IMAGE}\" \"${AIRFLOW_CI_IMAGE}:${GITHUB_REGISTRY_PUSH_IMAGE_TAG}\"",
          "25:     push_pull_remove_images::push_image_with_retries \"${AIRFLOW_CI_IMAGE}:${GITHUB_REGISTRY_PUSH_IMAGE_TAG}\"",
          "26:     start_end::group_end",
          "27: }",
          "33: push_ci_image_with_tag_to_github",
          "",
          "---------------"
        ],
        "scripts/ci/images/ci_push_production_images.sh||scripts/ci/images/ci_push_production_images.sh": [
          "File: scripts/ci/images/ci_push_production_images.sh -> scripts/ci/images/ci_push_production_images.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: # shellcheck source=scripts/ci/libraries/_script_init.sh",
          "19: . \"$( dirname \"${BASH_SOURCE[0]}\" )/../libraries/_script_init.sh\"",
          "21: build_images::prepare_prod_build",
          "23: build_images::login_to_docker_registry",
          "",
          "[Removed Lines]",
          "25: push_pull_remove_images::push_prod_images_to_github",
          "",
          "[Added Lines]",
          "21: # Pushes PROD images with tags to registry in GitHub",
          "22: function push_prod_image_with_tag_to_github () {",
          "23:     start_end::group_start \"Push PROD image\"",
          "24:     local airflow_prod_tagged_image=\"${AIRFLOW_PROD_IMAGE}:${GITHUB_REGISTRY_PUSH_IMAGE_TAG}\"",
          "25:     docker_v tag \"${AIRFLOW_PROD_IMAGE}\" \"${airflow_prod_tagged_image}\"",
          "26:     push_pull_remove_images::push_image_with_retries \"${airflow_prod_tagged_image}\"",
          "27:     start_end::group_end",
          "28: }",
          "34: push_prod_image_with_tag_to_github",
          "",
          "---------------"
        ],
        "scripts/ci/images/ci_run_prod_image_test.sh||scripts/ci/images/ci_run_prod_image_test.sh": [
          "File: scripts/ci/images/ci_run_prod_image_test.sh -> scripts/ci/images/ci_run_prod_image_test.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "36:     echo \"${COLOR_BLUE}Replacing the airflow image version in ${file} with ${latest_airflow_version_released} for testing.${COLOR_RESET}\"",
          "37:     echo",
          "38:     sed  \"s/FROM apache\\/airflow:.*$/FROM apache\\/airflow:${latest_airflow_version_released}/\" <Dockerfile | \\",
          "40:     res=$?",
          "41:     docker rmi --force \"${job_name}\"",
          "42: else",
          "",
          "[Removed Lines]",
          "39:     docker build . --tag \"${job_name}\" -f -",
          "",
          "[Added Lines]",
          "39:     docker build --pull . --tag \"${job_name}\" -f -",
          "",
          "---------------"
        ],
        "scripts/ci/libraries/_all_libs.sh||scripts/ci/libraries/_all_libs.sh": [
          "File: scripts/ci/libraries/_all_libs.sh -> scripts/ci/libraries/_all_libs.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "52: . \"${LIBRARIES_DIR}\"/_push_pull_remove_images.sh",
          "53: # shellcheck source=scripts/ci/libraries/_runs.sh",
          "54: . \"${LIBRARIES_DIR}\"/_runs.sh",
          "57: # shellcheck source=scripts/ci/libraries/_start_end.sh",
          "58: . \"${LIBRARIES_DIR}\"/_start_end.sh",
          "59: # shellcheck source=scripts/ci/libraries/_testing.sh",
          "",
          "[Removed Lines]",
          "55: # shellcheck source=scripts/ci/libraries/_spinner.sh",
          "56: . \"${LIBRARIES_DIR}\"/_spinner.sh",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "scripts/ci/libraries/_build_images.sh||scripts/ci/libraries/_build_images.sh": [
          "File: scripts/ci/libraries/_build_images.sh -> scripts/ci/libraries/_build_images.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "108:     fi",
          "109: }",
          "114:     set +u",
          "115:     if [[ ${#MODIFIED_FILES[@]} != \"\" ]]; then",
          "118:     fi",
          "121:     fi",
          "122:     set -u",
          "126:     # Make sure to use output of tty rather than stdin/stdout when available - this way confirm",
          "127:     # will works also in case of pre-commits (git does not pass stdin/stdout to pre-commit hooks)",
          "128:     # shellcheck disable=SC2094",
          "131:     RES=$?",
          "132: }",
          "134: # Confirms if the image should be rebuilt and interactively checks it with the user.",
          "",
          "[Removed Lines]",
          "111: function build_images::confirm_via_terminal() {",
          "112:     echo >\"${DETECTED_TERMINAL}\"",
          "113:     echo >\"${DETECTED_TERMINAL}\"",
          "116:         echo \"${COLOR_YELLOW}The CI image for Python ${PYTHON_BASE_IMAGE} image likely needs to be rebuilt${COLOR_RESET}\" >\"${DETECTED_TERMINAL}\"",
          "117:         echo \"${COLOR_YELLOW}The files were modified since last build: ${MODIFIED_FILES[*]}${COLOR_RESET}\" >\"${DETECTED_TERMINAL}\"",
          "119:     if [[ ${ACTION} == \"pull and rebuild\" ]]; then",
          "120:         echo \"${COLOR_YELLOW}This build involves pull and it might take some time and network to pull the base image first!${COLOR_RESET}\" >\"${DETECTED_TERMINAL}\"",
          "123:     echo >\"${DETECTED_TERMINAL}\"",
          "124:     echo \"${COLOR_YELLOW}WARNING!!!!:Make sure that you rebased to latest upstream before rebuilding or the rebuild might take a lot of time!${COLOR_RESET}\" >\"${DETECTED_TERMINAL}\"",
          "125:     echo >\"${DETECTED_TERMINAL}\"",
          "129:     \"${AIRFLOW_SOURCES}/confirm\" \"${ACTION} image ${THE_IMAGE_TYPE}-python${PYTHON_MAJOR_MINOR_VERSION}\" \\",
          "130:         <\"${DETECTED_TERMINAL}\" >\"${DETECTED_TERMINAL}\"",
          "",
          "[Added Lines]",
          "112: function build_images::reconfirm_rebuilding_if_not_rebased() {",
          "113:     local latest_main_commit_sha",
          "114:     latest_main_commit_sha=$(curl -s -H \"Accept: application/vnd.github.VERSION.sha\" \\",
          "115:         \"https://api.github.com/repos/${GITHUB_REPOSITORY}/commits/${DEFAULT_BRANCH}\")",
          "116:     if [[ \"$(git log --format=format:%H | grep -c \"${latest_main_commit_sha}\")\" == \"0\" ]]; then",
          "117:          echo",
          "118:          echo \"${COLOR_YELLOW}WARNING!!!!:You are not rebased on top of the latest ${DEFAULT_BRANCH} branch of the airflow repo.${COLOR_RESET}\"",
          "119:          echo \"${COLOR_YELLOW}The rebuild might take a lot of time and you might need to do it again${COLOR_RESET}\"",
          "120:          echo",
          "121:          echo \"${COLOR_YELLOW}It is STRONGLY RECOMMENDED that you rebase your code first!${COLOR_RESET}\"",
          "122:          echo",
          "123:          \"${AIRFLOW_SOURCES}/confirm\" \"You are really sure you want to rebuild ${THE_IMAGE_TYPE}-python${PYTHON_MAJOR_MINOR_VERSION}\"",
          "124:          RES=$?",
          "125:     fi",
          "126: }",
          "128: function build_images::print_modified_files() {",
          "129:     echo \"${MODIFIED_FILES[@]}\" | xargs -n 1 echo \" * \"",
          "130: }",
          "132: function build_images::encourage_rebuilding_on_modified_files() {",
          "133:     echo",
          "136:         echo",
          "137:         echo \"${COLOR_YELLOW}The CI image for Python ${PYTHON_MAJOR_MINOR_VERSION} image might be outdated${COLOR_RESET}\"",
          "138:         echo",
          "139:         echo \"${COLOR_BLUE}Please run this command at earliest convenience: ${COLOR_RESET}\"",
          "140:         echo",
          "141:         echo \"${COLOR_YELLOW}./breeze build-image --python ${PYTHON_MAJOR_MINOR_VERSION}${COLOR_RESET}\"",
          "142:         echo",
          "144: }",
          "146: function build_images::confirm_rebuilding_on_modified_files() {",
          "147:     echo",
          "148:     set +u",
          "149:     if [[ ${#MODIFIED_FILES[@]} != \"\" ]]; then",
          "150:         echo \"${COLOR_BLUE}The CI image for Python ${PYTHON_MAJOR_MINOR_VERSION} image likely needs to be rebuild${COLOR_RESET}\"",
          "151:         echo \"${COLOR_BLUE}The files were modified since last build:${COLOR_RESET}\"",
          "152:         echo",
          "153:         echo \"${COLOR_BLUE}$(build_images::print_modified_files)${COLOR_RESET}\"",
          "154:         echo",
          "160:     \"${AIRFLOW_SOURCES}/confirm\" \"PULL & BUILD the image ${THE_IMAGE_TYPE}-python${PYTHON_MAJOR_MINOR_VERSION}\"",
          "162:     if [[ ${RES} == \"0\" ]]; then",
          "163:         build_images::reconfirm_rebuilding_if_not_rebased",
          "164:     fi",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "137: # So that the script works also from within pre-commit run via git hooks - where stdin is not",
          "138: # available - it tries to find usable terminal and ask the user via this terminal.",
          "139: function build_images::confirm_image_rebuild() {",
          "144:     if [[ -f \"${LAST_FORCE_ANSWER_FILE}\" ]]; then",
          "145:         # set variable from last answered response given in the same pre-commit run - so that it can be",
          "146:         # answered in the first pre-commit check (build) and then used in another (mypy/flake8 etc).",
          "",
          "[Removed Lines]",
          "140:     ACTION=\"rebuild\"",
          "141:     if [[ ${FORCE_PULL_IMAGES:=} == \"true\" ]]; then",
          "142:         ACTION=\"pull and rebuild\"",
          "143:     fi",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "151:     local RES",
          "152:     if [[ ${CI:=\"false\"} == \"true\" ]]; then",
          "153:         verbosity::print_info",
          "155:         verbosity::print_info",
          "156:         RES=\"0\"",
          "157:     elif [[ -n \"${FORCE_ANSWER_TO_QUESTIONS=}\" ]]; then",
          "",
          "[Removed Lines]",
          "154:         verbosity::print_info \"CI environment - forcing rebuild for image ${THE_IMAGE_TYPE}.\"",
          "",
          "[Added Lines]",
          "183:         verbosity::print_info \"CI environment - forcing pull and rebuild for image ${THE_IMAGE_TYPE}.\"",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "171:         esac",
          "172:     elif [[ -t 0 ]]; then",
          "173:         # Check if this script is run interactively with stdin open and terminal attached",
          "186:     elif [[ ${DETECTED_TERMINAL:=$(tty)} != \"not a tty\" ]]; then",
          "187:         export DETECTED_TERMINAL",
          "189:     elif [[ -c /dev/tty ]]; then",
          "190:         export DETECTED_TERMINAL=/dev/tty",
          "192:     else",
          "193:         verbosity::print_info",
          "194:         verbosity::print_info \"No terminal, no stdin - quitting\"",
          "",
          "[Removed Lines]",
          "174:         echo",
          "175:         set +u",
          "176:         if [[ ${#MODIFIED_FILES[@]} != \"\" ]]; then",
          "177:             echo \"${COLOR_YELLOW}The CI image for Python ${PYTHON_BASE_IMAGE} image likely needs to be rebuilt${COLOR_RESET}\"",
          "178:             echo \"${COLOR_YELLOW}The files were modified since last build: ${MODIFIED_FILES[*]}${COLOR_RESET}\"",
          "179:         fi",
          "180:         echo",
          "181:         echo \"${COLOR_YELLOW}WARNING!!!!:Make sure that you rebased to latest upstream before rebuilding or the rebuild might take a lot of time!${COLOR_RESET}\"",
          "182:         echo",
          "183:         set -u",
          "184:         \"${AIRFLOW_SOURCES}/confirm\" \"${ACTION} image ${THE_IMAGE_TYPE}-python${PYTHON_MAJOR_MINOR_VERSION}\"",
          "185:         RES=$?",
          "188:         build_images::confirm_via_terminal",
          "191:         build_images::confirm_via_terminal",
          "",
          "[Added Lines]",
          "203:          build_images::confirm_rebuilding_on_modified_files",
          "206:         # shellcheck disable=SC2094",
          "207:         build_images::encourage_rebuilding_on_modified_files >\"${DETECTED_TERMINAL}\" <\"${DETECTED_TERMINAL}\"",
          "208:         RES=1",
          "211:         # shellcheck disable=SC2094",
          "212:         build_images::encourage_rebuilding_on_modified_files >\"${DETECTED_TERMINAL}\" <\"${DETECTED_TERMINAL}\"",
          "213:         RES=1",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "250:     fi",
          "251: }",
          "375: # Prints summary of the build parameters",
          "376: function build_images::print_build_info() {",
          "377:     verbosity::print_info",
          "",
          "[Removed Lines]",
          "253: # Builds local image manifest. It contains only one random file generated during Docker.ci build",
          "254: function build_images::build_ci_image_manifest() {",
          "255:     docker_v build \\",
          "256:         --tag=\"${AIRFLOW_CI_LOCAL_MANIFEST_IMAGE}\" \\",
          "257:         -f- . <<EOF",
          "258: FROM scratch",
          "259: COPY \"manifests/local-build-cache-hash-${PYTHON_MAJOR_MINOR_VERSION}\" /build-cache-hash",
          "260: LABEL org.opencontainers.image.source=\"https://github.com/${GITHUB_REPOSITORY}\"",
          "261: CMD \"\"",
          "262: EOF",
          "263: }",
          "265: #",
          "266: # Retrieves information about build cache hash random file from the local image",
          "267: # The random file is generated during the build and is best indicator whether your local CI image",
          "268: # has been built using the same pulled image as the remote one",
          "269: #",
          "270: function build_images::get_local_build_cache_hash() {",
          "271:     set +e",
          "272:     local local_image_build_cache_file",
          "273:     local_image_build_cache_file=\"${AIRFLOW_SOURCES}/manifests/local-build-cache-hash-${PYTHON_MAJOR_MINOR_VERSION}\"",
          "274:     # Remove the container just in case",
          "275:     docker_v rm --force \"local-airflow-ci-container\" 2>/dev/null >/dev/null",
          "276:     if ! docker_v inspect \"${AIRFLOW_CI_IMAGE_WITH_TAG}\" 2>/dev/null >/dev/null; then",
          "277:         verbosity::print_info",
          "278:         verbosity::print_info \"Local airflow CI image not available\"",
          "279:         verbosity::print_info",
          "280:         LOCAL_MANIFEST_IMAGE_UNAVAILABLE=\"true\"",
          "281:         export LOCAL_MANIFEST_IMAGE_UNAVAILABLE",
          "282:         touch \"${local_image_build_cache_file}\"",
          "283:         set -e",
          "284:         return",
          "286:     fi",
          "287:     docker_v create --name \"local-airflow-ci-container\" \"${AIRFLOW_CI_IMAGE_WITH_TAG}\" 2>/dev/null >/dev/null",
          "288:     docker_v cp \"local-airflow-ci-container:/build-cache-hash\" \\",
          "289:         \"${local_image_build_cache_file}\" 2>/dev/null ||",
          "290:         touch \"${local_image_build_cache_file}\"",
          "291:     set -e",
          "292:     verbosity::print_info",
          "293:     verbosity::print_info \"Local build cache hash: '$(cat \"${local_image_build_cache_file}\")'\"",
          "294:     verbosity::print_info",
          "295: }",
          "297: # Retrieves information about the build cache hash random file from the remote image.",
          "298: # We use manifest image for that, which is a really, really small image to pull!",
          "299: # The image is a specially prepared manifest image which is built together with the main image and",
          "300: # pushed with it. This special manifest image is prepared during building of the CI image and contains",
          "301: # single file which is generated with random content during the docker",
          "302: # build in the right step of the image build (right after installing all dependencies of Apache Airflow",
          "303: # for the first time).",
          "304: # When this random file gets regenerated it means that either base image has changed before that step",
          "305: # or some of the earlier layers was modified - which means that it is usually faster to pull",
          "306: # that image first and then rebuild it.",
          "307: function build_images::get_remote_image_build_cache_hash() {",
          "308:     set +e",
          "309:     local remote_image_container_id_file",
          "310:     remote_image_container_id_file=\"$(mktemp)\"",
          "311:     local remote_image_build_cache_file",
          "312:     remote_image_build_cache_file=$(mktemp)",
          "313:     local target_remote_cache_file=\"${AIRFLOW_SOURCES}/manifests/remote-build-cache-hash-${PYTHON_MAJOR_MINOR_VERSION}\"",
          "314:     # Pull remote manifest image",
          "315:     if ! docker_v pull \"${AIRFLOW_CI_REMOTE_MANIFEST_IMAGE}\" 2>/dev/null >/dev/null; then",
          "316:         verbosity::print_info",
          "317:         verbosity::print_info \"Remote docker registry unreachable\"",
          "318:         verbosity::print_info",
          "319:         REMOTE_DOCKER_REGISTRY_UNREACHABLE=\"true\"",
          "320:         export REMOTE_DOCKER_REGISTRY_UNREACHABLE",
          "321:         touch \"${remote_image_build_cache_file}\"",
          "322:         set -e",
          "323:         return",
          "324:     fi",
          "325:     set -e",
          "326:     rm -f \"${remote_image_container_id_file}\"",
          "327:     # Create container dump out of the manifest image without actually running it",
          "328:     docker_v create --cidfile \"${remote_image_container_id_file}\" \"${AIRFLOW_CI_REMOTE_MANIFEST_IMAGE}\"",
          "329:     # Extract manifest and store it in local file",
          "330:     docker_v cp \"$(cat \"${remote_image_container_id_file}\"):/build-cache-hash\" \\",
          "331:         \"${remote_image_build_cache_file}\"",
          "332:     # The `mv` is an atomic operation so even if we run it in parallel (for example in flake) it will",
          "333:     # never be empty (happened in the past)",
          "334:     mv \"${remote_image_build_cache_file}\" \"${target_remote_cache_file}\"",
          "335:     docker_v rm --force \"$(cat \"${remote_image_container_id_file}\")\"",
          "336:     rm -f \"${remote_image_container_id_file}\"",
          "337:     verbosity::print_info",
          "338:     verbosity::print_info \"Remote build cache hash: '$(cat \"${target_remote_cache_file}\")'\"",
          "339:     verbosity::print_info",
          "340: }",
          "342: # Compares layers from both remote and local image and set FORCE_PULL_IMAGES to true in case",
          "343: # The random has in remote image is different than that in the local image",
          "344: # indicating that it is likely faster to pull the image from cache rather than let the",
          "345: # image rebuild fully locally",
          "346: function build_images::compare_local_and_remote_build_cache_hash() {",
          "347:     set +e",
          "348:     local local_image_build_cache_file",
          "349:     local_image_build_cache_file=\"${AIRFLOW_SOURCES}/manifests/local-build-cache-hash-${PYTHON_MAJOR_MINOR_VERSION}\"",
          "350:     local remote_image_build_cache_file",
          "351:     remote_image_build_cache_file=\"${AIRFLOW_SOURCES}/manifests/remote-build-cache-hash-${PYTHON_MAJOR_MINOR_VERSION}\"",
          "352:     local remote_hash",
          "353:     remote_hash=$(cat \"${remote_image_build_cache_file}\")",
          "354:     local local_hash",
          "355:     local_hash=$(cat \"${local_image_build_cache_file}\")",
          "357:     if [[ ${remote_hash} != \"${local_hash}\" || -z ${local_hash} ]]; then",
          "358:         echo",
          "359:         echo",
          "360:         echo \"Your image and the dockerhub have different or missing build cache hashes.\"",
          "361:         echo \"Local hash: '${local_hash}'. Remote hash: '${remote_hash}'.\"",
          "362:         echo",
          "363:         echo \"Forcing pulling the images. It will be faster than rebuilding usually.\"",
          "364:         echo \"You can avoid it by setting SKIP_CHECK_REMOTE_IMAGE to true\"",
          "365:         echo",
          "366:         export FORCE_PULL_IMAGES=\"true\"",
          "367:     else",
          "368:         echo",
          "369:         echo \"No need to pull the image. Yours and remote cache hashes are the same!\"",
          "370:         echo",
          "371:     fi",
          "372:     set -e",
          "373: }",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "397:     local image_name",
          "398:     image_name=\"ghcr.io/$(build_images::get_github_container_registry_image_prefix)\"",
          "404:     # Example:",
          "405:     #  ghcr.io/apache/airflow/main/ci/python3.8",
          "406:     export AIRFLOW_CI_IMAGE=\"${image_name}/${BRANCH_NAME}/ci/python${PYTHON_MAJOR_MINOR_VERSION}\"",
          "",
          "[Removed Lines]",
          "400:     # Example:",
          "401:     #  ghcr.io/apache/airflow/main/python:3.8-slim-buster",
          "402:     export AIRFLOW_PYTHON_BASE_IMAGE=\"${image_name}/${BRANCH_NAME}/python:${PYTHON_MAJOR_MINOR_VERSION}-slim-buster\"",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "410:     #  ghcr.io/apache/airflow/main/ci/python3.8:<COMMIT_SHA>",
          "411:     export AIRFLOW_CI_IMAGE_WITH_TAG=\"${image_name}/${BRANCH_NAME}/ci/python${PYTHON_MAJOR_MINOR_VERSION}:${GITHUB_REGISTRY_PULL_IMAGE_TAG}\"",
          "421:     # File that is touched when the CI image is built for the first time locally",
          "422:     export BUILT_CI_IMAGE_FLAG_FILE=\"${BUILD_CACHE_DIR}/${BRANCH_NAME}/.built_${PYTHON_MAJOR_MINOR_VERSION}\"",
          "",
          "[Removed Lines]",
          "413:     # Example:",
          "414:     #  local-airflow-ci-manifest/main/python3.8",
          "415:     export AIRFLOW_CI_LOCAL_MANIFEST_IMAGE=\"local-airflow-ci-manifest/${BRANCH_NAME}/python${PYTHON_MAJOR_MINOR_VERSION}\"",
          "417:     # Example:",
          "418:     #  ghcr.io/apache/airflow/main/ci-manifest/python3.8",
          "419:     export AIRFLOW_CI_REMOTE_MANIFEST_IMAGE=\"${image_name}/${BRANCH_NAME}/ci-manifest/python${PYTHON_MAJOR_MINOR_VERSION}\"",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "425:     #  ghcr.io/apache/airflow/main/prod/python3.8",
          "426:     export AIRFLOW_PROD_IMAGE=\"${image_name}/${BRANCH_NAME}/prod/python${PYTHON_MAJOR_MINOR_VERSION}\"",
          "432:     # Kubernetes image to build",
          "433:     #  ghcr.io/apache/airflow/main/kubernetes/python3.8",
          "434:     export AIRFLOW_IMAGE_KUBERNETES=\"${image_name}/${BRANCH_NAME}/kubernetes/python${PYTHON_MAJOR_MINOR_VERSION}\"",
          "438: }",
          "440: # If GitHub Registry is used, login to the registry using GITHUB_USERNAME and",
          "",
          "[Removed Lines]",
          "428:     # Example:",
          "429:     #   ghcr.io/apache/airflow/main/prod-build/python3.8",
          "430:     export AIRFLOW_PROD_BUILD_IMAGE=\"${image_name}/${BRANCH_NAME}/prod-build/python${PYTHON_MAJOR_MINOR_VERSION}\"",
          "",
          "[Added Lines]",
          "319: }",
          "321: function build_images::check_if_buildx_plugin_available() {",
          "322:     export BUILD_COMMAND=(\"build\")",
          "323:     local buildx_version",
          "324:     buildx_version=$(docker buildx version 2>/dev/null || true)",
          "325:     if [[ ${buildx_version} != \"\" ]]; then",
          "326:         BUILDX_PLUGIN_AVAILABLE=\"true\"",
          "327:         export BUILD_COMMAND=(\"buildx\" \"build\" \"--builder\" \"default\" \"--progress=tty\")",
          "328:     else",
          "329:         BUILDX_PLUGIN_AVAILABLE=\"false\"",
          "330:     fi",
          "331:     if [[ ${PREPARE_BUILDX_CACHE} == \"true\" ]]; then",
          "332:         if [[ ${BUILDX_PLUGIN_AVAILABLE} == \"true\" ]]; then",
          "333:             export BUILD_COMMAND=(\"buildx\" \"build\" \"--builder\" \"airflow_cache\" \"--progress=tty\")",
          "334:             docker_v buildx inspect airflow_cache || docker_v buildx create --name airflow_cache",
          "335:         else",
          "336:             echo",
          "337:             echo \"${COLOR_RED}Buildx cli plugin is not available and you need it to prepare buildx cache.${COLOR_RESET}\"",
          "338:             echo \"${COLOR_RED}Please install it following https://docs.docker.com/buildx/working-with-buildx/${COLOR_RESET}\"",
          "339:             echo",
          "340:             exit 1",
          "341:         fi",
          "342:     fi",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "491: # In case rebuild is needed, it determines (by comparing layers in local and remote image)",
          "492: # Whether pull is needed before rebuild.",
          "493: function build_images::rebuild_ci_image_if_needed() {",
          "497:     if [[ -f \"${BUILT_CI_IMAGE_FLAG_FILE}\" ]]; then",
          "498:         verbosity::print_info",
          "500:         verbosity::print_info",
          "501:     else",
          "502:         verbosity::print_info",
          "512:         verbosity::print_info",
          "515:     fi",
          "516:     local needs_docker_build=\"false\"",
          "517:     md5sum::check_if_docker_build_is_needed",
          "519:     if [[ ${needs_docker_build} == \"true\" ]]; then",
          "521:         SKIP_REBUILD=\"false\"",
          "522:         if [[ ${CI:=} != \"true\" && \"${FORCE_BUILD:=}\" != \"true\" ]]; then",
          "523:             build_images::confirm_image_rebuild",
          "",
          "[Removed Lines]",
          "494:     verbosity::print_info",
          "495:     verbosity::print_info \"Checking if pull or just build for ${THE_IMAGE_TYPE} is needed.\"",
          "496:     verbosity::print_info",
          "499:         verbosity::print_info \"${THE_IMAGE_TYPE} image already built locally.\"",
          "503:         verbosity::print_info \"${THE_IMAGE_TYPE} image not built locally: pulling and building\"",
          "504:         verbosity::print_info",
          "505:         export FORCE_PULL_IMAGES=\"true\"",
          "506:         export FORCE_BUILD_IMAGES=\"true\"",
          "507:     fi",
          "509:     if [[ ${CHECK_IMAGE_FOR_REBUILD} == \"false\" ]]; then",
          "510:         verbosity::print_info",
          "511:         verbosity::print_info \"Skip checking for rebuilds of the CI image but checking if it needs to be pulled\"",
          "513:         push_pull_remove_images::pull_ci_images_if_needed",
          "514:         return",
          "518:     build_images::get_local_build_cache_hash",
          "520:         md5sum::check_if_pull_is_needed",
          "",
          "[Added Lines]",
          "401:         verbosity::print_info \"CI image already built locally.\"",
          "405:         verbosity::print_info \"CI image not built locally: force pulling and building\"",
          "407:         export FORCE_BUILD=\"true\"",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "536:             verbosity::print_info \"Build start: ${THE_IMAGE_TYPE} image.\"",
          "537:             verbosity::print_info",
          "538:             build_images::build_ci_image",
          "540:             md5sum::update_all_md5",
          "542:             verbosity::print_info",
          "543:             verbosity::print_info \"Build completed: ${THE_IMAGE_TYPE} image.\"",
          "544:             verbosity::print_info",
          "",
          "[Removed Lines]",
          "539:             build_images::get_local_build_cache_hash",
          "541:             build_images::build_ci_image_manifest",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "556:     start_end::group_end",
          "557: }",
          "590: # Builds CI image - depending on the caching strategy (pulled, local, disabled) it",
          "592: # it also passes the right Build args depending on the configuration of the build",
          "593: # selected by Breeze flags or environment variables.",
          "594: function build_images::build_ci_image() {",
          "596:     build_images::print_build_info",
          "606:     if [[ \"${DOCKER_CACHE}\" == \"disabled\" ]]; then",
          "608:     elif [[ \"${DOCKER_CACHE}\" == \"local\" ]]; then",
          "610:     elif [[ \"${DOCKER_CACHE}\" == \"pulled\" ]]; then",
          "613:         )",
          "614:     else",
          "615:         echo",
          "",
          "[Removed Lines]",
          "560: # Interactive version of confirming the ci image that is used in pre-commits",
          "561: # it displays additional information - what the user should do in order to bring the local images",
          "562: # back to state that pre-commit will be happy with",
          "563: function build_images::rebuild_ci_image_if_needed_and_confirmed() {",
          "564:     local needs_docker_build=\"false\"",
          "565:     THE_IMAGE_TYPE=\"CI\"",
          "567:     md5sum::check_if_docker_build_is_needed",
          "569:     if [[ ${needs_docker_build} == \"true\" ]]; then",
          "570:         md5sum::check_if_pull_is_needed",
          "571:         verbosity::print_info",
          "572:         verbosity::print_info \"Docker image build is needed!\"",
          "573:         verbosity::print_info",
          "574:     else",
          "575:         verbosity::print_info",
          "576:         verbosity::print_info \"Docker image build is not needed!\"",
          "577:         verbosity::print_info",
          "578:     fi",
          "580:     if [[ \"${needs_docker_build}\" == \"true\" ]]; then",
          "581:         SKIP_REBUILD=\"false\"",
          "582:         build_images::confirm_image_rebuild",
          "584:         if [[ ${SKIP_REBUILD} != \"true\" ]]; then",
          "585:             build_images::rebuild_ci_image_if_needed",
          "586:         fi",
          "587:     fi",
          "588: }",
          "591: # passes the necessary docker build flags via DOCKER_CACHE_CI_DIRECTIVE array",
          "595:     local spin_pid",
          "597:     if [[ -n ${DETECTED_TERMINAL=} ]]; then",
          "598:         echo -n \"Preparing ${AIRFLOW_CI_IMAGE}.",
          "599:         \" >\"${DETECTED_TERMINAL}\"",
          "600:         spinner::spin \"${OUTPUT_LOG}\" &",
          "601:         spin_pid=$!",
          "602:         # shellcheck disable=SC2064,SC2016",
          "603:         traps::add_trap '$(kill '${spin_pid}' || true)' EXIT HUP INT TERM",
          "604:     fi",
          "605:     push_pull_remove_images::pull_ci_images_if_needed",
          "607:         export DOCKER_CACHE_CI_DIRECTIVE=(\"--no-cache\")",
          "609:         export DOCKER_CACHE_CI_DIRECTIVE=()",
          "611:         export DOCKER_CACHE_CI_DIRECTIVE=(",
          "612:             \"--cache-from\" \"${AIRFLOW_CI_IMAGE}\"",
          "",
          "[Added Lines]",
          "449: # passes the necessary docker build flags via docker_ci_cache_directive array",
          "453:     build_images::check_if_buildx_plugin_available",
          "455:     local docker_ci_cache_directive",
          "457:         docker_ci_cache_directive=(\"--no-cache\")",
          "459:         docker_ci_cache_directive=()",
          "461:         docker_ci_cache_directive=(",
          "462:             \"--cache-from=${AIRFLOW_CI_IMAGE}:cache\"",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "617:         echo",
          "618:         exit 1",
          "619:     fi",
          "622:     if [[ ${CI} == \"true\" ]]; then",
          "623:         EXTRA_DOCKER_PROD_BUILD_FLAGS+=(",
          "624:             \"--build-arg\" \"PIP_PROGRESS_BAR=off\"",
          "625:         )",
          "626:     fi",
          "627:     if [[ -n \"${AIRFLOW_CONSTRAINTS_LOCATION}\" ]]; then",
          "629:             \"--build-arg\" \"AIRFLOW_CONSTRAINTS_LOCATION=${AIRFLOW_CONSTRAINTS_LOCATION}\"",
          "630:         )",
          "631:     fi",
          "651:     set +u",
          "653:     local additional_dev_args=()",
          "",
          "[Removed Lines]",
          "620:     EXTRA_DOCKER_CI_BUILD_FLAGS=(",
          "621:     )",
          "628:         EXTRA_DOCKER_CI_BUILD_FLAGS+=(",
          "633:     if [[ -n ${spin_pid=} ]]; then",
          "634:         kill -HUP \"${spin_pid}\" || true",
          "635:         wait \"${spin_pid}\" || true",
          "636:         echo >\"${DETECTED_TERMINAL}\"",
          "637:     fi",
          "638:     if [[ -n ${DETECTED_TERMINAL=} ]]; then",
          "639:         echo -n \"Preparing ${AIRFLOW_CI_IMAGE}.",
          "640:         \" >\"${DETECTED_TERMINAL}\"",
          "641:         spinner::spin \"${OUTPUT_LOG}\" &",
          "642:         spin_pid=$!",
          "643:         # shellcheck disable=SC2064,SC2016",
          "644:         traps::add_trap '$(kill '${spin_pid}' || true)' EXIT HUP INT TERM",
          "645:     fi",
          "646:     if [[ -n ${DETECTED_TERMINAL=} ]]; then",
          "647:         echo -n \"",
          "648: Docker building ${AIRFLOW_CI_IMAGE}.",
          "649: \" >\"${DETECTED_TERMINAL}\"",
          "650:     fi",
          "",
          "[Added Lines]",
          "470:     if [[ ${PREPARE_BUILDX_CACHE} == \"true\" ]]; then",
          "471:         docker_ci_cache_directive+=(",
          "472:             \"--cache-to=type=registry,ref=${AIRFLOW_CI_IMAGE}:cache\"",
          "473:             \"--load\"",
          "474:         )",
          "475:     fi",
          "476:     local extra_docker_ci_flags=()",
          "483:         extra_docker_ci_flags+=(",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "665:     if [[ -n \"${RUNTIME_APT_COMMAND}\" ]]; then",
          "666:         additional_runtime_args+=(\"--build-arg\" \"RUNTIME_APT_COMMAND=\\\"${RUNTIME_APT_COMMAND}\\\"\")",
          "667:     fi",
          "671:         --build-arg AIRFLOW_VERSION=\"${AIRFLOW_VERSION}\" \\",
          "672:         --build-arg AIRFLOW_BRANCH=\"${BRANCH_NAME}\" \\",
          "673:         --build-arg AIRFLOW_EXTRAS=\"${AIRFLOW_EXTRAS}\" \\",
          "",
          "[Removed Lines]",
          "668:     docker_v build \\",
          "669:         \"${EXTRA_DOCKER_CI_BUILD_FLAGS[@]}\" \\",
          "670:         --build-arg PYTHON_BASE_IMAGE=\"${AIRFLOW_PYTHON_BASE_IMAGE}\" \\",
          "",
          "[Added Lines]",
          "504:     docker_v \"${BUILD_COMMAND[@]}\" \\",
          "505:         \"${extra_docker_ci_flags[@]}\" \\",
          "506:         --pull \\",
          "507:         --build-arg PYTHON_BASE_IMAGE=\"${PYTHON_BASE_IMAGE}\" \\",
          "",
          "---------------",
          "--- Hunk 14 ---",
          "[Context before]",
          "690:         --build-arg COMMIT_SHA=\"${COMMIT_SHA}\" \\",
          "691:         \"${additional_dev_args[@]}\" \\",
          "692:         \"${additional_runtime_args[@]}\" \\",
          "694:         -t \"${AIRFLOW_CI_IMAGE}\" \\",
          "695:         --target \"main\" \\",
          "696:         . -f Dockerfile.ci",
          "",
          "[Removed Lines]",
          "693:         \"${DOCKER_CACHE_CI_DIRECTIVE[@]}\" \\",
          "",
          "[Added Lines]",
          "530:         \"${docker_ci_cache_directive[@]}\" \\",
          "",
          "---------------",
          "--- Hunk 15 ---",
          "[Context before]",
          "699:         echo \"Tagging additionally image ${AIRFLOW_CI_IMAGE} with ${IMAGE_TAG}\"",
          "700:         docker_v tag \"${AIRFLOW_CI_IMAGE}\" \"${IMAGE_TAG}\"",
          "701:     fi",
          "707: }",
          "709: # Prepares all variables needed by the CI build. Depending on the configuration used (python version",
          "",
          "[Removed Lines]",
          "702:     if [[ -n ${spin_pid=} ]]; then",
          "703:         kill -HUP \"${spin_pid}\" || true",
          "704:         wait \"${spin_pid}\" || true",
          "705:         echo >\"${DETECTED_TERMINAL}\"",
          "706:     fi",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 16 ---",
          "[Context before]",
          "760: # Builds PROD image - depending on the caching strategy (pulled, local, disabled) it",
          "761: # passes the necessary docker build flags via DOCKER_CACHE_PROD_DIRECTIVE and",
          "763: # it also passes the right Build args depending on the configuration of the build",
          "764: # selected by Breeze flags or environment variables.",
          "765: function build_images::build_prod_images() {",
          "766:     build_images::print_build_info",
          "768:     if [[ ${SKIP_BUILDING_PROD_IMAGE} == \"true\" ]]; then",
          "",
          "[Removed Lines]",
          "762: # DOCKER_CACHE_PROD_BUILD_DIRECTIVE (separate caching options are needed for \"build\" segment of the image)",
          "",
          "[Added Lines]",
          "594: # docker_cache_prod_build_directive (separate caching options are needed for \"build\" segment of the image)",
          "598:     build_images::check_if_buildx_plugin_available",
          "",
          "---------------",
          "--- Hunk 17 ---",
          "[Context before]",
          "772:         echo",
          "773:         return",
          "774:     fi",
          "778:     if [[ \"${DOCKER_CACHE}\" == \"disabled\" ]]; then",
          "781:     elif [[ \"${DOCKER_CACHE}\" == \"local\" ]]; then",
          "784:     elif [[ \"${DOCKER_CACHE}\" == \"pulled\" ]]; then",
          "791:         )",
          "792:     else",
          "793:         echo",
          "",
          "[Removed Lines]",
          "776:     push_pull_remove_images::pull_prod_images_if_needed",
          "779:         export DOCKER_CACHE_PROD_DIRECTIVE=(\"--cache-from\" \"${AIRFLOW_PROD_BUILD_IMAGE}\")",
          "780:         export DOCKER_CACHE_PROD_BUILD_DIRECTIVE=(\"--no-cache\")",
          "782:         export DOCKER_CACHE_PROD_DIRECTIVE=()",
          "783:         export DOCKER_CACHE_PROD_BUILD_DIRECTIVE=()",
          "785:         export DOCKER_CACHE_PROD_DIRECTIVE=(",
          "786:             \"--cache-from\" \"${AIRFLOW_PROD_BUILD_IMAGE}\"",
          "787:             \"--cache-from\" \"${AIRFLOW_PROD_IMAGE}\"",
          "788:         )",
          "789:         export DOCKER_CACHE_PROD_BUILD_DIRECTIVE=(",
          "790:             \"--cache-from\" \"${AIRFLOW_PROD_BUILD_IMAGE}\"",
          "",
          "[Added Lines]",
          "608:     local docker_cache_prod_directive",
          "610:         docker_cache_prod_directive=(\"--no-cache\")",
          "612:         docker_cache_prod_directive=()",
          "614:         docker_cache_prod_directive=(",
          "615:             \"--cache-from=${AIRFLOW_PROD_IMAGE}:cache\"",
          "",
          "---------------",
          "--- Hunk 18 ---",
          "[Context before]",
          "796:         echo",
          "797:         exit 1",
          "798:     fi",
          "799:     set +u",
          "800:     local additional_dev_args=()",
          "801:     if [[ -n \"${DEV_APT_DEPS}\" ]]; then",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "624:     if [[ ${PREPARE_BUILDX_CACHE} == \"true\" ]]; then",
          "625:         # Cache for prod image contains also build stage for buildx when mode=max specified!",
          "626:         docker_cache_prod_directive+=(",
          "627:             \"--cache-to=type=registry,ref=${AIRFLOW_PROD_IMAGE}:cache,mode=max\"",
          "628:             \"--load\"",
          "629:         )",
          "630:     fi",
          "",
          "---------------",
          "--- Hunk 19 ---",
          "[Context before]",
          "804:     if [[ -n \"${DEV_APT_COMMAND}\" ]]; then",
          "805:         additional_dev_args+=(\"--build-arg\" \"DEV_APT_COMMAND=\\\"${DEV_APT_COMMAND}\\\"\")",
          "806:     fi",
          "836:     local additional_runtime_args=()",
          "837:     if [[ -n \"${RUNTIME_APT_DEPS}\" ]]; then",
          "838:         additional_runtime_args+=(\"--build-arg\" \"RUNTIME_APT_DEPS=\\\"${RUNTIME_APT_DEPS}\\\"\")",
          "",
          "[Removed Lines]",
          "807:     docker_v build \\",
          "808:         \"${EXTRA_DOCKER_PROD_BUILD_FLAGS[@]}\" \\",
          "809:         --build-arg PYTHON_BASE_IMAGE=\"${AIRFLOW_PYTHON_BASE_IMAGE}\" \\",
          "810:         --build-arg INSTALL_MYSQL_CLIENT=\"${INSTALL_MYSQL_CLIENT}\" \\",
          "811:         --build-arg INSTALL_MSSQL_CLIENT=\"${INSTALL_MSSQL_CLIENT}\" \\",
          "812:         --build-arg AIRFLOW_VERSION=\"${AIRFLOW_VERSION}\" \\",
          "813:         --build-arg AIRFLOW_BRANCH=\"${AIRFLOW_BRANCH_FOR_PYPI_PRELOADING}\" \\",
          "814:         --build-arg AIRFLOW_EXTRAS=\"${AIRFLOW_EXTRAS}\" \\",
          "815:         --build-arg ADDITIONAL_AIRFLOW_EXTRAS=\"${ADDITIONAL_AIRFLOW_EXTRAS}\" \\",
          "816:         --build-arg ADDITIONAL_PYTHON_DEPS=\"${ADDITIONAL_PYTHON_DEPS}\" \\",
          "817:         \"${additional_dev_args[@]}\" \\",
          "818:         --build-arg INSTALL_PROVIDERS_FROM_SOURCES=\"${INSTALL_PROVIDERS_FROM_SOURCES}\" \\",
          "819:         --build-arg ADDITIONAL_DEV_APT_COMMAND=\"${ADDITIONAL_DEV_APT_COMMAND}\" \\",
          "820:         --build-arg ADDITIONAL_DEV_APT_DEPS=\"${ADDITIONAL_DEV_APT_DEPS}\" \\",
          "821:         --build-arg ADDITIONAL_DEV_APT_ENV=\"${ADDITIONAL_DEV_APT_ENV}\" \\",
          "822:         --build-arg AIRFLOW_PRE_CACHED_PIP_PACKAGES=\"${AIRFLOW_PRE_CACHED_PIP_PACKAGES}\" \\",
          "823:         --build-arg INSTALL_FROM_PYPI=\"${INSTALL_FROM_PYPI}\" \\",
          "824:         --build-arg INSTALL_FROM_DOCKER_CONTEXT_FILES=\"${INSTALL_FROM_DOCKER_CONTEXT_FILES}\" \\",
          "825:         --build-arg UPGRADE_TO_NEWER_DEPENDENCIES=\"${UPGRADE_TO_NEWER_DEPENDENCIES}\" \\",
          "826:         --build-arg BUILD_ID=\"${CI_BUILD_ID}\" \\",
          "827:         --build-arg COMMIT_SHA=\"${COMMIT_SHA}\" \\",
          "828:         --build-arg CONSTRAINTS_GITHUB_REPOSITORY=\"${CONSTRAINTS_GITHUB_REPOSITORY}\" \\",
          "829:         --build-arg AIRFLOW_CONSTRAINTS=\"${AIRFLOW_CONSTRAINTS}\" \\",
          "830:         --build-arg AIRFLOW_IMAGE_REPOSITORY=\"https://github.com/${GITHUB_REPOSITORY}\" \\",
          "831:         --build-arg AIRFLOW_IMAGE_DATE_CREATED=\"$(date -u +'%Y-%m-%dT%H:%M:%SZ')\" \\",
          "832:         \"${DOCKER_CACHE_PROD_BUILD_DIRECTIVE[@]}\" \\",
          "833:         -t \"${AIRFLOW_PROD_BUILD_IMAGE}\" \\",
          "834:         --target \"airflow-build-image\" \\",
          "835:         . -f Dockerfile",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 20 ---",
          "[Context before]",
          "840:     if [[ -n \"${RUNTIME_APT_COMMAND}\" ]]; then",
          "841:         additional_runtime_args+=(\"--build-arg\" \"RUNTIME_APT_COMMAND=\\\"${RUNTIME_APT_COMMAND}\\\"\")",
          "842:     fi",
          "844:         \"${EXTRA_DOCKER_PROD_BUILD_FLAGS[@]}\" \\",
          "846:         --build-arg INSTALL_MYSQL_CLIENT=\"${INSTALL_MYSQL_CLIENT}\" \\",
          "847:         --build-arg INSTALL_MSSQL_CLIENT=\"${INSTALL_MSSQL_CLIENT}\" \\",
          "848:         --build-arg ADDITIONAL_AIRFLOW_EXTRAS=\"${ADDITIONAL_AIRFLOW_EXTRAS}\" \\",
          "",
          "[Removed Lines]",
          "843:     docker_v build \\",
          "845:         --build-arg PYTHON_BASE_IMAGE=\"${AIRFLOW_PYTHON_BASE_IMAGE}\" \\",
          "",
          "[Added Lines]",
          "646:     docker_v \"${BUILD_COMMAND[@]}\" \\",
          "648:         --pull \\",
          "649:         --build-arg PYTHON_BASE_IMAGE=\"${PYTHON_BASE_IMAGE}\" \\",
          "",
          "---------------",
          "--- Hunk 21 ---",
          "[Context before]",
          "869:         --build-arg AIRFLOW_IMAGE_DATE_CREATED=\"$(date -u +'%Y-%m-%dT%H:%M:%SZ')\" \\",
          "870:         \"${additional_dev_args[@]}\" \\",
          "871:         \"${additional_runtime_args[@]}\" \\",
          "873:         -t \"${AIRFLOW_PROD_IMAGE}\" \\",
          "874:         --target \"main\" \\",
          "875:         . -f Dockerfile",
          "",
          "[Removed Lines]",
          "872:         \"${DOCKER_CACHE_PROD_DIRECTIVE[@]}\" \\",
          "",
          "[Added Lines]",
          "676:         \"${docker_cache_prod_directive[@]}\" \\",
          "",
          "---------------",
          "--- Hunk 22 ---",
          "[Context before]",
          "899: # and local to speed up iteration on kerberos tests",
          "900: function build_images::determine_docker_cache_strategy() {",
          "901:     if [[ -z \"${DOCKER_CACHE=}\" ]]; then",
          "907:     fi",
          "908:     verbosity::print_info",
          "909:     verbosity::print_info \"Using ${DOCKER_CACHE} cache strategy for the build.\"",
          "",
          "[Removed Lines]",
          "902:         if [[ \"${PRODUCTION_IMAGE}\" == \"true\" ]]; then",
          "903:             export DOCKER_CACHE=\"local\"",
          "904:         else",
          "905:             export DOCKER_CACHE=\"pulled\"",
          "906:         fi",
          "",
          "[Added Lines]",
          "706:         export DOCKER_CACHE=\"pulled\"",
          "",
          "---------------"
        ],
        "scripts/ci/libraries/_initialization.sh||scripts/ci/libraries/_initialization.sh": [
          "File: scripts/ci/libraries/_initialization.sh -> scripts/ci/libraries/_initialization.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "87:     # so that all breeze commands use emulation",
          "88:     export DOCKER_DEFAULT_PLATFORM=linux/amd64",
          "90:     # Default port numbers for forwarded ports",
          "91:     export SSH_PORT=${SSH_PORT:=\"12322\"}",
          "92:     export WEBSERVER_HOST_PORT=${WEBSERVER_HOST_PORT:=\"28080\"}",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "90:     # enable buildkit for builds",
          "91:     export DOCKER_BUILDKIT=1",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "179:     # Dry run - only show docker-compose and docker commands but do not execute them",
          "180:     export DRY_RUN_DOCKER=${DRY_RUN_DOCKER:=\"false\"}",
          "185: }",
          "187: # Determine current branch",
          "",
          "[Removed Lines]",
          "182:     # By default we only push built ci/prod images - base python images are only pushed",
          "183:     # When requested",
          "184:     export PUSH_PYTHON_BASE_IMAGE=${PUSH_PYTHON_BASE_IMAGE:=\"false\"}",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "291: # Determine values of force settings",
          "292: function initialization::initialize_force_variables() {",
          "300:     # Determines whether to force build without checking if it is needed",
          "301:     # Can be overridden by '--force-build-images' flag.",
          "302:     export FORCE_BUILD_IMAGES=${FORCE_BUILD_IMAGES:=\"false\"}",
          "",
          "[Removed Lines]",
          "293:     # By default we do not pull CI/PROD images. We can force-pull them when needed",
          "294:     export FORCE_PULL_IMAGES=${FORCE_PULL_IMAGES:=\"false\"}",
          "296:     # By default we do not pull python base image. We should do that only when we run upgrade check in",
          "297:     # CI main and when we manually refresh the images to latest versions",
          "298:     export CHECK_IF_BASE_PYTHON_IMAGE_UPDATED=\"false\"",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "485:     #   * wheel - replaces airflow with one specified in the sdist file in /dist",
          "486:     #   * <VERSION> - replaces airflow with the specific version from PyPI",
          "487:     export USE_AIRFLOW_VERSION=${USE_AIRFLOW_VERSION:=\"\"}",
          "488: }",
          "490: # Determine version suffixes used to build provider packages",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "482:     # whether images should be pushed to registry cache after they are built",
          "483:     export PREPARE_BUILDX_CACHE=${PREPARE_BUILDX_CACHE:=\"false\"}",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "578: function initialization::initialize_test_variables() {",
          "580:     # In case we want to force certain test type to run, this variable should be set to this type",
          "581:     # Otherwise TEST_TYPEs to run will be derived from TEST_TYPES space-separated string",
          "582:     export FORCE_TEST_TYPE=${FORCE_TEST_TYPE:=\"\"}",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "576:     #Enables test coverage",
          "577:     export ENABLE_TEST_COVERAGE=${ENABLE_TEST_COVERAGE:=\"\"}",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "664: Force variables:",
          "667:     FORCE_BUILD_IMAGES: ${FORCE_BUILD_IMAGES}",
          "668:     FORCE_ANSWER_TO_QUESTIONS: ${FORCE_ANSWER_TO_QUESTIONS}",
          "669:     SKIP_CHECK_REMOTE_IMAGE: ${SKIP_CHECK_REMOTE_IMAGE}",
          "",
          "[Removed Lines]",
          "666:     FORCE_PULL_IMAGES: ${FORCE_PULL_IMAGES}",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "scripts/ci/libraries/_md5sum.sh||scripts/ci/libraries/_md5sum.sh": [
          "File: scripts/ci/libraries/_md5sum.sh -> scripts/ci/libraries/_md5sum.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "152:         fi",
          "153:     fi",
          "154: }",
          "",
          "[Removed Lines]",
          "157: function md5sum::check_if_pull_is_needed() {",
          "158:    if [[ ${SKIP_CHECK_REMOTE_IMAGE:=} != \"true\" && ${DOCKER_CACHE} == \"pulled\" ]]; then",
          "159:         # Check if remote image is different enough to force pull",
          "160:         # This is an optimisation pull vs. build time. When there",
          "161:         # are enough changes (specifically after setup.py changes) it is faster to pull",
          "162:         # and build the image rather than just build it",
          "163:         verbosity::print_info",
          "164:         verbosity::print_info \"Checking if the remote image needs to be pulled\"",
          "165:         verbosity::print_info",
          "166:         build_images::get_remote_image_build_cache_hash",
          "167:         if [[ ${REMOTE_DOCKER_REGISTRY_UNREACHABLE:=} != \"true\" && ${LOCAL_MANIFEST_IMAGE_UNAVAILABLE:=} != \"true\" ]]; then",
          "168:             build_images::compare_local_and_remote_build_cache_hash",
          "169:         else",
          "170:             export FORCE_PULL_IMAGES=\"true\"",
          "171:         fi",
          "172:     fi",
          "173: }",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "scripts/ci/libraries/_push_pull_remove_images.sh||scripts/ci/libraries/_push_pull_remove_images.sh": [
          "File: scripts/ci/libraries/_push_pull_remove_images.sh -> scripts/ci/libraries/_push_pull_remove_images.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "44: }",
          "48: # Should be run with set +e",
          "49: # Parameters:",
          "50: #   $1 -> image to pull",
          "53:     local image_to_pull=\"${1}\"",
          "54:     local image_hash",
          "55:     image_hash=$(docker images -q \"${image_to_pull}\" 2> /dev/null || true)",
          "58:     if [[ -z \"${image_hash=}\" ]]; then",
          "62:         echo",
          "63:         echo \"Pulling the image ${image_to_pull}\"",
          "64:         echo",
          "",
          "[Removed Lines]",
          "47: # Pulls image in case it is needed (either has never been pulled or pulling was forced",
          "51: #   $2 - fallback image",
          "52: function push_pull_remove_images::pull_image_if_not_present_or_forced() {",
          "56:     local pull_image=${FORCE_PULL_IMAGES}",
          "59:         pull_image=\"true\"",
          "60:     fi",
          "61:     if [[ \"${pull_image}\" == \"true\" ]]; then",
          "",
          "[Added Lines]",
          "47: # Pulls image in case it is missing",
          "51: function push_pull_remove_images::pull_image_if_missing() {",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "66:     fi",
          "67: }",
          "255: # waits for an image to be available in the GitHub registry",
          "256: function push_pull_remove_images::wait_for_image() {",
          "",
          "[Removed Lines]",
          "69: # Rebuilds python base image from the latest available Python version if it has been updated",
          "70: function push_pull_remove_images::check_and_rebuild_python_base_image_if_needed() {",
          "71:    docker_v pull \"${PYTHON_BASE_IMAGE}\"",
          "72:    local dockerhub_python_version",
          "73:    dockerhub_python_version=$(docker run \"${PYTHON_BASE_IMAGE}\" python -c 'import sys; print(sys.version)')",
          "74:    local local_python_version",
          "75:    local_python_version=$(docker run \"${AIRFLOW_PYTHON_BASE_IMAGE}\" python -c 'import sys; print(sys.version)' || true)",
          "76:    if [[ ${local_python_version} != \"${dockerhub_python_version}\" ]]; then",
          "77:        echo",
          "78:        echo \"There is a new Python Base image updated!\"",
          "79:        echo \"The version used in Airflow: ${local_python_version}\"",
          "80:        echo \"The version available in DockerHub: ${dockerhub_python_version}\"",
          "81:        echo \"Rebuilding ${AIRFLOW_PYTHON_BASE_IMAGE} from the latest ${PYTHON_BASE_IMAGE}\"",
          "82:        echo",
          "83:        echo \"FROM ${PYTHON_BASE_IMAGE}\" | \\",
          "84:             docker_v build \\",
          "85:                 --label \"org.opencontainers.image.source=https://github.com/${GITHUB_REPOSITORY}\" \\",
          "86:                 -t \"${AIRFLOW_PYTHON_BASE_IMAGE}\" -",
          "87:   else",
          "88:       echo",
          "89:       echo \"Not rebuilding the base python image - the image has the same python version ${dockerhub_python_version}\"",
          "90:       echo",
          "91:   fi",
          "92: }",
          "94: # Pulls the base Python image. This image is used as base for CI and PROD images, depending on the parameters used:",
          "95: #",
          "96: # * if CHECK_IF_BASE_PYTHON_IMAGE_UPDATED == \"true\", then it checks if new image of Python has been released",
          "97: #     in DockerHub and it will rebuild the base python image and add the `org.opencontainers.image.source`",
          "98: #     label to it, so that it is linked to Airflow repository when we push it to the",
          "99: #     Github Container registry",
          "100: # * Otherwise it pulls the Python base image from GitHub Container Registry registry.",
          "101: #     In case we pull specific build image (via suffix)",
          "102: #     it will pull the right image using the specified suffix",
          "103: function push_pull_remove_images::pull_base_python_image() {",
          "104:     echo",
          "105:     echo \"Docker pull base python image. Upgrade to newer deps: ${UPGRADE_TO_NEWER_DEPENDENCIES}\"",
          "106:     echo",
          "107:     if [[ -n ${DETECTED_TERMINAL=} ]]; then",
          "108:         echo -n \"Docker pull base python image. Upgrade to newer deps: ${UPGRADE_TO_NEWER_DEPENDENCIES}",
          "109: \" > \"${DETECTED_TERMINAL}\"",
          "110:     fi",
          "111:     set +e",
          "112:     push_pull_remove_images::pull_image_if_not_present_or_forced \"${AIRFLOW_PYTHON_BASE_IMAGE}\"",
          "113:     local res=\"$?\"",
          "114:     set -e",
          "115:     if [[ ${CHECK_IF_BASE_PYTHON_IMAGE_UPDATED} == \"true\" || ${res} != \"0\" ]] ; then",
          "116:         # Rebuild the base python image using DockerHub - either when we explicitly want it",
          "117:         # or when there is no image available yet in ghcr.io (usually when you build it for the",
          "118:         # first time in your repository",
          "119:         push_pull_remove_images::check_and_rebuild_python_base_image_if_needed",
          "120:     fi",
          "121: }",
          "123: # Pulls CI image in case caching strategy is \"pulled\" and the image needs to be pulled",
          "124: function push_pull_remove_images::pull_ci_images_if_needed() {",
          "125:     local python_image_hash",
          "126:     python_image_hash=$(docker images -q \"${AIRFLOW_PYTHON_BASE_IMAGE}\" 2> /dev/null || true)",
          "127:     if [[ -z \"${python_image_hash=}\" || \"${FORCE_PULL_IMAGES}\" == \"true\" || \\",
          "128:             ${CHECK_IF_BASE_PYTHON_IMAGE_UPDATED} == \"true\" ]]; then",
          "129:         if [[ ${GITHUB_REGISTRY_PULL_IMAGE_TAG} == \"latest\" ]]; then",
          "130:             # Pull base python image when building latest image",
          "131:             push_pull_remove_images::pull_base_python_image",
          "132:         fi",
          "133:     fi",
          "134:     if [[ \"${DOCKER_CACHE}\" == \"pulled\" ]]; then",
          "135:         set +e",
          "136:         push_pull_remove_images::pull_image_if_not_present_or_forced \"${AIRFLOW_CI_IMAGE_WITH_TAG}\"",
          "137:         local res=\"$?\"",
          "138:         set -e",
          "139:         if [[ ${res} != \"0\" ]]; then",
          "140:             if [[ ${GITHUB_REGISTRY_PULL_IMAGE_TAG} == \"latest\" ]] ; then",
          "141:                 echo",
          "142:                 echo \"The CI image cache does not exist. This is likely the first time you build the image\"",
          "143:                 echo \"Switching to 'local' cache for docker images\"",
          "144:                 echo",
          "145:                 DOCKER_CACHE=\"local\"",
          "146:             else",
          "147:                 echo",
          "148:                 echo \"The CI image cache does not exist and we want to pull tag ${GITHUB_REGISTRY_PULL_IMAGE_TAG}\"",
          "149:                 echo \"Failing as we have to pull the tagged image in order to continue\"",
          "150:                 echo",
          "151:                 return \"${res}\"",
          "152:             fi",
          "153:         fi",
          "154:     fi",
          "155: }",
          "158: # Pulls PROD image in case caching strategy is \"pulled\" and the image needs to be pulled",
          "159: function push_pull_remove_images::pull_prod_images_if_needed() {",
          "160:     local python_image_hash",
          "161:     python_image_hash=$(docker images -q \"${AIRFLOW_PYTHON_BASE_IMAGE}\" 2> /dev/null || true)",
          "162:     if [[ -z \"${python_image_hash=}\" || \"${FORCE_PULL_IMAGES}\" == \"true\"  || \\",
          "163:             ${CHECK_IF_BASE_PYTHON_IMAGE_UPDATED} == \"true\" ]]; then",
          "164:         if [[ ${GITHUB_REGISTRY_PULL_IMAGE_TAG} == \"latest\" ]]; then",
          "165:             # Pull base python image when building latest image",
          "166:             push_pull_remove_images::pull_base_python_image",
          "167:         fi",
          "168:     fi",
          "169:     if [[ \"${DOCKER_CACHE}\" == \"pulled\" ]]; then",
          "170:         set +e",
          "171:         # \"Build\" segment of production image",
          "172:         push_pull_remove_images::pull_image_if_not_present_or_forced \\",
          "173:             \"${AIRFLOW_PROD_BUILD_IMAGE}:${GITHUB_REGISTRY_PULL_IMAGE_TAG}\"",
          "174:         local res=\"$?\"",
          "175:         if [[ ${res} == \"0\" ]]; then",
          "176:             # \"Main\" segment of production image",
          "177:             push_pull_remove_images::pull_image_if_not_present_or_forced \\",
          "178:                 \"${AIRFLOW_PROD_IMAGE}:${GITHUB_REGISTRY_PULL_IMAGE_TAG}\"",
          "179:             res=\"$?\"",
          "180:         fi",
          "181:         set -e",
          "182:         if [[ ${res} != \"0\" ]]; then",
          "183:             if [[ ${GITHUB_REGISTRY_PULL_IMAGE_TAG} == \"latest\" ]] ; then",
          "184:                 echo",
          "185:                 echo \"The PROD image cache does not exist. This is likely the first time you build the image\"",
          "186:                 echo \"Switching to 'local' cache for docker images\"",
          "187:                 echo",
          "188:                 DOCKER_CACHE=\"local\"",
          "189:             else",
          "190:                 echo",
          "191:                 echo \"The PROD image cache does not exist and we want to pull tag ${GITHUB_REGISTRY_PULL_IMAGE_TAG}\"",
          "192:                 echo \"Failing as we have to pull the tagged image in order to continue\"",
          "193:                 echo",
          "194:                 return \"${res}\"",
          "195:             fi",
          "196:         fi",
          "197:     fi",
          "198: }",
          "200: # Push image to GitHub registry with the push tag:",
          "201: #     \"${COMMIT_SHA}\" - in case of pull-request triggered 'workflow_run' builds",
          "202: #     \"latest\"        - in case of push builds",
          "203: # Push python image to GitHub registry with the push tag:",
          "204: #     X.Y-slim-buster-\"${COMMIT_SHA}\" - in case of pull-request triggered 'workflow_run' builds",
          "205: #     X.Y-slim-buster                 - in case of push builds",
          "206: function push_pull_remove_images::push_python_image_to_github() {",
          "207:     local python_tag_suffix=\"\"",
          "208:     if [[ ${GITHUB_REGISTRY_PUSH_IMAGE_TAG} != \"latest\" ]]; then",
          "209:         python_tag_suffix=\"-${GITHUB_REGISTRY_PUSH_IMAGE_TAG}\"",
          "210:     fi",
          "211:     docker_v tag \"${AIRFLOW_PYTHON_BASE_IMAGE}\" \\",
          "212:         \"${AIRFLOW_PYTHON_BASE_IMAGE}${python_tag_suffix}\"",
          "213:     push_pull_remove_images::push_image_with_retries \\",
          "214:         \"${AIRFLOW_PYTHON_BASE_IMAGE}${python_tag_suffix}\"",
          "215: }",
          "217: # Pushes Ci images and their tags to registry in GitHub",
          "218: function push_pull_remove_images::push_ci_images_to_github() {",
          "219:     start_end::group_start \"Push image\"",
          "220:     if [[ \"${PUSH_PYTHON_BASE_IMAGE=}\" != \"false\" ]]; then",
          "221:         push_pull_remove_images::push_python_image_to_github",
          "222:     fi",
          "223:     docker_v tag \"${AIRFLOW_CI_IMAGE}\" \"${AIRFLOW_CI_IMAGE}:${GITHUB_REGISTRY_PUSH_IMAGE_TAG}\"",
          "224:     push_pull_remove_images::push_image_with_retries \"${AIRFLOW_CI_IMAGE}:${GITHUB_REGISTRY_PUSH_IMAGE_TAG}\"",
          "225:     # Also push ci manifest image if GITHUB_REGISTRY_PUSH_IMAGE_TAG is \"latest\"",
          "226:     if [[ ${GITHUB_REGISTRY_PUSH_IMAGE_TAG} == \"latest\" ]]; then",
          "227:         local airflow_ci_manifest_tagged_image=\"${AIRFLOW_CI_REMOTE_MANIFEST_IMAGE}:latest\"",
          "228:         docker_v tag \"${AIRFLOW_CI_LOCAL_MANIFEST_IMAGE}\" \"${airflow_ci_manifest_tagged_image}\"",
          "229:         push_pull_remove_images::push_image_with_retries \"${airflow_ci_manifest_tagged_image}\"",
          "230:     fi",
          "231:     start_end::group_end",
          "232: }",
          "234: # Pushes PROD image to registry in GitHub",
          "235: # Push image to GitHub registry with chosen push tag",
          "236: # the PUSH tag might be:",
          "237: #     \"${COMMIT_SHA}\" - in case of pull-request triggered 'workflow_run' builds",
          "238: #     \"latest\"        - in case of push builds",
          "239: function push_pull_remove_images::push_prod_images_to_github () {",
          "240:     if [[ \"${PUSH_PYTHON_BASE_IMAGE=}\" != \"false\" ]]; then",
          "241:         push_pull_remove_images::push_python_image_to_github",
          "242:     fi",
          "243:     local airflow_prod_tagged_image=\"${AIRFLOW_PROD_IMAGE}:${GITHUB_REGISTRY_PUSH_IMAGE_TAG}\"",
          "244:     docker_v tag \"${AIRFLOW_PROD_IMAGE}\" \"${airflow_prod_tagged_image}\"",
          "245:     push_pull_remove_images::push_image_with_retries \"${airflow_prod_tagged_image}\"",
          "246:     # Also push prod build image if GITHUB_REGISTRY_PUSH_IMAGE_TAG is \"latest\"",
          "247:     if [[ ${GITHUB_REGISTRY_PUSH_IMAGE_TAG} == \"latest\" ]]; then",
          "248:         local airflow_prod_build_tagged_image=\"${AIRFLOW_PROD_BUILD_IMAGE}:latest\"",
          "249:         docker_v tag \"${AIRFLOW_PROD_BUILD_IMAGE}\" \"${airflow_prod_build_tagged_image}\"",
          "250:         push_pull_remove_images::push_image_with_retries \"${airflow_prod_build_tagged_image}\"",
          "251:     fi",
          "252: }",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "261:     local count=0",
          "262:     while true",
          "263:     do",
          "265:             break",
          "266:         fi",
          "267:         if [[ ${count} == \"${MAX_TRIES}\" ]]; then",
          "",
          "[Removed Lines]",
          "264:         if push_pull_remove_images::pull_image_if_not_present_or_forced \"$1\"; then",
          "",
          "[Added Lines]",
          "73:         if push_pull_remove_images::pull_image_if_missing \"$1\"; then",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "276:     done",
          "277:     set -e",
          "278: }",
          "",
          "[Removed Lines]",
          "280: function push_pull_remove_images::pull_image() {",
          "281:     start_end::group_start  \"Pulling image: $1\"",
          "282:     push_pull_remove_images::pull_image_if_not_present_or_forced \"$1\"",
          "283:     start_end::group_end",
          "284: }",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "scripts/ci/libraries/_spinner.sh||scripts/ci/libraries/_spinner.sh": [
          "File: scripts/ci/libraries/_spinner.sh -> scripts/ci/libraries/_spinner.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "scripts/ci/libraries/_verbosity.sh||scripts/ci/libraries/_verbosity.sh": [
          "File: scripts/ci/libraries/_verbosity.sh -> scripts/ci/libraries/_verbosity.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "57:     if [[ ${PRINT_INFO_FROM_SCRIPTS} == \"false\" ]]; then",
          "58:         ${DOCKER_BINARY_PATH} \"${@}\" >>\"${OUTPUT_LOG}\" 2>&1",
          "59:     else",
          "61:     fi",
          "62:     res=\"$?\"",
          "63:     if [[ ${res} == \"0\" || ${exit_on_error} == \"false\" ]]; then",
          "",
          "[Removed Lines]",
          "60:         ${DOCKER_BINARY_PATH} \"${@}\" 1> >(tee -a \"${OUTPUT_LOG}\") 2> >(tee -a \"${OUTPUT_LOG}\" >&2)",
          "",
          "[Added Lines]",
          "60:         \"${DOCKER_BINARY_PATH}\" \"${@}\"",
          "",
          "---------------"
        ],
        "scripts/ci/pre_commit/pre_commit_ci_build.sh||scripts/ci/pre_commit/pre_commit_ci_build.sh": [
          "File: scripts/ci/pre_commit/pre_commit_ci_build.sh -> scripts/ci/pre_commit/pre_commit_ci_build.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: # shellcheck source=scripts/ci/libraries/_script_init.sh",
          "23: . \"$( dirname \"${BASH_SOURCE[0]}\" )/../libraries/_script_init.sh\"",
          "25: build_images::forget_last_answer",
          "27: build_images::prepare_ci_build",
          "",
          "[Removed Lines]",
          "29: build_images::rebuild_ci_image_if_needed_and_confirmed",
          "",
          "[Added Lines]",
          "25: # PRe-commit version of confirming the ci image that is used in pre-commits",
          "26: # it displays additional information - what the user should do in order to bring the local images",
          "27: # back to state that pre-commit will be happy with",
          "28: function build_images::rebuild_ci_image_if_confirmed_for_pre_commit() {",
          "29:     local needs_docker_build=\"false\"",
          "30:     export THE_IMAGE_TYPE=\"CI\"",
          "32:     md5sum::check_if_docker_build_is_needed",
          "34:     if [[ ${needs_docker_build} == \"true\" ]]; then",
          "35:         verbosity::print_info",
          "36:         verbosity::print_info \"Docker image pull and build is needed!\"",
          "37:         verbosity::print_info",
          "38:     else",
          "39:         verbosity::print_info",
          "40:         verbosity::print_info \"Docker image pull and build is not needed!\"",
          "41:         verbosity::print_info",
          "42:     fi",
          "44:     if [[ \"${needs_docker_build}\" == \"true\" ]]; then",
          "45:         SKIP_REBUILD=\"false\"",
          "46:         build_images::confirm_image_rebuild",
          "47:         if [[ ${SKIP_REBUILD} != \"true\" ]]; then",
          "48:             build_images::rebuild_ci_image_if_needed",
          "49:         fi",
          "50:     fi",
          "51: }",
          "57: build_images::rebuild_ci_image_if_confirmed_for_pre_commit",
          "",
          "---------------"
        ],
        "scripts/ci/tools/build_dockerhub.sh||scripts/ci/tools/build_dockerhub.sh": [
          "File: scripts/ci/tools/build_dockerhub.sh -> scripts/ci/tools/build_dockerhub.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "28: export INSTALL_PROVIDERS_FROM_SOURCES=\"false\"",
          "29: export AIRFLOW_PRE_CACHED_PIP_PACKAGES=\"false\"",
          "30: export DOCKER_CACHE=\"local\"",
          "32: export DOCKER_TAG=${INSTALL_AIRFLOW_VERSION}-python${PYTHON_MAJOR_MINOR_VERSION}",
          "33: export AIRFLOW_CONSTRAINTS_REFERENCE=\"constraints-${INSTALL_AIRFLOW_VERSION}\"",
          "34: export AIRFLOW_CONSTRAINTS=\"constraints\"",
          "",
          "[Removed Lines]",
          "31: export CHECK_IF_BASE_PYTHON_IMAGE_UPDATED=\"true\"",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "scripts/docker/common.sh||scripts/docker/common.sh": [
          "File: scripts/docker/common.sh -> scripts/docker/common.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "50: function common::get_constraints_location() {",
          "51:     # auto-detect Airflow-constraint reference and location",
          "52:     if [[ -z \"${AIRFLOW_CONSTRAINTS_REFERENCE=}\" ]]; then",
          "54:             AIRFLOW_CONSTRAINTS_REFERENCE=constraints-${AIRFLOW_VERSION}",
          "55:         else",
          "56:             AIRFLOW_CONSTRAINTS_REFERENCE=${DEFAULT_CONSTRAINTS_BRANCH}",
          "",
          "[Removed Lines]",
          "53:         if  [[ ${AIRFLOW_VERSION} =~ v?2.* ]]; then",
          "",
          "[Added Lines]",
          "53:         if  [[ ${AIRFLOW_VERSION} =~ v?2.* && ! ${AIRFLOW_VERSION} =~ .*dev.* ]]; then",
          "",
          "---------------"
        ],
        "scripts/in_container/entrypoint_ci.sh||scripts/in_container/entrypoint_ci.sh": [
          "File: scripts/in_container/entrypoint_ci.sh -> scripts/in_container/entrypoint_ci.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "185: cd \"${AIRFLOW_SOURCES}\"",
          "188: if [[ ${START_AIRFLOW:=\"false\"} == \"true\" ]]; then",
          "189:     export AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS=${LOAD_DEFAULT_CONNECTIONS}",
          "190:     export AIRFLOW__CORE__LOAD_EXAMPLES=${LOAD_EXAMPLES}",
          "",
          "[Removed Lines]",
          "187: echo \"START_AIRFLOW:=${START_AIRFLOW}\"",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "dfde1bac9245ac441869beb9853063fc5048ee91",
      "candidate_info": {
        "commit_hash": "dfde1bac9245ac441869beb9853063fc5048ee91",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/dfde1bac9245ac441869beb9853063fc5048ee91",
        "files": [
          "scripts/ci/testing/ci_run_airflow_testing.sh"
        ],
        "message": "Bring back Core and Other tests to be run in parallel (#19812)\n\nAfter merging #19809 we can very likely come back to parallel\nrunning of Core and Other tests as we separated them out\nthinking that the parallel runs were the cause of the problems.\n\nThose tests should be perfectly fine to run in parallel now.\n\n(cherry picked from commit 6c80149d0abf84caec8f4c1b4e8795ea5923f89a)",
        "before_after_code_files": [
          "scripts/ci/testing/ci_run_airflow_testing.sh||scripts/ci/testing/ci_run_airflow_testing.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "scripts/ci/testing/ci_run_airflow_testing.sh||scripts/ci/testing/ci_run_airflow_testing.sh": [
          "File: scripts/ci/testing/ci_run_airflow_testing.sh -> scripts/ci/testing/ci_run_airflow_testing.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "88:         echo \"${COLOR_YELLOW}Heavy tests will be run sequentially after parallel tests including cleaning up docker between tests${COLOR_RESET}\"",
          "89:         echo \"\"",
          "90:         if [[ ${test_types_to_run} == *\"Integration\"* ]]; then",
          "91:             test_types_to_run=\"${test_types_to_run//Integration/}\"",
          "103:         fi",
          "104:         if [[ ${BACKEND} == \"mssql\" || ${BACKEND} == \"mysql\" ]]; then",
          "105:             # For mssql/mysql - they take far more memory than postgres (or sqlite) - we skip the Provider",
          "",
          "[Removed Lines]",
          "92:             if [[ ${BACKEND} == \"mssql\" ]]; then",
          "93:                 # Also for mssql we skip Integration tests altogether on Public Runners. Mssql uses far",
          "94:                 # too much memory and often shuts down and similarly as in case of Providers tests,",
          "95:                 # there is no need to run them also for MsSQL engine as those integration tests",
          "96:                 # are not really using any metadata-specific behaviour.",
          "97:                 # Those tests will run in `main` anyway.",
          "98:                 echo \"${COLOR_YELLOW}Do not run integration tests for mssql in small systems due to memory issues.${COLOR_RESET}\"",
          "99:             else",
          "100:                 echo \"${COLOR_YELLOW}Remove Integration from tests_types_to_run and add them to sequential tests due to low memory.${COLOR_RESET}\"",
          "101:                 sequential_tests+=(\"Integration\")",
          "102:             fi",
          "",
          "[Added Lines]",
          "91:             echo \"${COLOR_YELLOW}Remove Integration from tests_types_to_run and add them to sequential tests due to low memory.${COLOR_RESET}\"",
          "93:             sequential_tests+=(\"Integration\")",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "0cd99044df34d9b5dc8019c36795a5a9850b1aca",
      "candidate_info": {
        "commit_hash": "0cd99044df34d9b5dc8019c36795a5a9850b1aca",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/0cd99044df34d9b5dc8019c36795a5a9850b1aca",
        "files": [
          "Dockerfile",
          "Dockerfile.ci",
          "scripts/docker/common.sh",
          "scripts/docker/compile_www_assets.sh",
          "scripts/docker/install_additional_dependencies.sh",
          "scripts/docker/install_airflow.sh",
          "scripts/docker/install_airflow_dependencies_from_branch_tip.sh",
          "scripts/docker/install_from_docker_context_files.sh",
          "scripts/docker/install_mssql.sh",
          "scripts/docker/install_mysql.sh",
          "scripts/docker/install_pip_version.sh"
        ],
        "message": "Cleaner output for Docker image building (#20747)\n\nThere was some \"junk\" output generated by the scripts that are\nused in Airflow image building. The junk has been cleaned up so\nthat no unnecessary warnings are generated.\n\nThis change includes:\n\n* making sure that when everything is fine, there are no\n  warnnings generated by PROD docker build proces\n\n* making sure that when CI image is build the only remaining\n  warning is \"Using root\" - this warning cannot be silenced\n  https://github.com/pypa/pip/issues/10556 and instead\n  in CI build we explain in green that this is invalid warning\n\n* the \"scripted\" steps of docker build have nicely blue headers\n  that visually separate steps of building the iamge and give\n  more information on what's going on\n\n* the current way of printing ouput will play very nicely with\n  BUILDKIT UI where Blue color indicates progress in building\n\nSeparated out from #20238\n\n(cherry picked from commit 4d33ebf76cd101b05476c0f1c840f10013bebd5f)",
        "before_after_code_files": [
          "Dockerfile.ci||Dockerfile.ci",
          "scripts/docker/common.sh||scripts/docker/common.sh",
          "scripts/docker/compile_www_assets.sh||scripts/docker/compile_www_assets.sh",
          "scripts/docker/install_additional_dependencies.sh||scripts/docker/install_additional_dependencies.sh",
          "scripts/docker/install_airflow.sh||scripts/docker/install_airflow.sh",
          "scripts/docker/install_airflow_dependencies_from_branch_tip.sh||scripts/docker/install_airflow_dependencies_from_branch_tip.sh",
          "scripts/docker/install_from_docker_context_files.sh||scripts/docker/install_from_docker_context_files.sh",
          "scripts/docker/install_mssql.sh||scripts/docker/install_mssql.sh",
          "scripts/docker/install_mysql.sh||scripts/docker/install_mysql.sh",
          "scripts/docker/install_pip_version.sh||scripts/docker/install_pip_version.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "Dockerfile.ci||Dockerfile.ci": [
          "File: Dockerfile.ci -> Dockerfile.ci",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: ARG PYTHON_BASE_IMAGE=\"python:3.6-slim-buster\"",
          "19: FROM ${PYTHON_BASE_IMAGE} as main",
          "23: ARG PYTHON_BASE_IMAGE=\"python:3.6-slim-buster\"",
          "24: ARG AIRFLOW_VERSION=\"2.2.0.dev0\"",
          "",
          "[Removed Lines]",
          "21: SHELL [\"/bin/bash\", \"-o\", \"pipefail\", \"-e\", \"-u\", \"-x\", \"-c\"]",
          "",
          "[Added Lines]",
          "21: # Nolog bash flag is currently ignored - but you can replace it with other flags (for example",
          "22: # xtrace - to show commands executed)",
          "23: SHELL [\"/bin/bash\", \"-o\", \"pipefail\", \"-o\", \"errexit\", \"-o\", \"nounset\", \"-o\", \"nolog\", \"-c\"]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "31: ENV PYTHON_BASE_IMAGE=${PYTHON_BASE_IMAGE} AIRFLOW_VERSION=${AIRFLOW_VERSION} \\",
          "32:     DEBIAN_FRONTEND=noninteractive LANGUAGE=C.UTF-8 LANG=C.UTF-8 LC_ALL=C.UTF-8 \\",
          "33:     LC_CTYPE=C.UTF-8 LC_MESSAGES=C.UTF-8 \\",
          "36: # Print versions",
          "37: RUN echo \"Base image: ${PYTHON_BASE_IMAGE}, Airflow version: ${AIRFLOW_VERSION}\"",
          "48: ARG ADDITIONAL_DEV_APT_DEPS=\"\"",
          "49: ARG DEV_APT_COMMAND=\"\\",
          "52:     && echo 'deb https://dl.yarnpkg.com/debian/ stable main' > /etc/apt/sources.list.d/yarn.list\"",
          "53: ARG ADDITIONAL_DEV_APT_COMMAND=\"\"",
          "54: ARG ADDITIONAL_DEV_ENV_VARS=\"\"",
          "",
          "[Removed Lines]",
          "34:     DEPENDENCIES_EPOCH_NUMBER=${DEPENDENCIES_EPOCH_NUMBER}",
          "39: # Install curl and gnupg2 - needed to download nodejs in the next step",
          "40: RUN apt-get update \\",
          "41:     && apt-get install -y --no-install-recommends \\",
          "42:            curl \\",
          "43:            gnupg2 \\",
          "44:     && apt-get autoremove -yqq --purge \\",
          "45:     && apt-get clean \\",
          "46:     && rm -rf /var/lib/apt/lists/*",
          "50:     curl --fail --location https://deb.nodesource.com/setup_14.x | bash - \\",
          "51:     && curl https://dl.yarnpkg.com/debian/pubkey.gpg | apt-key add - > /dev/null \\",
          "",
          "[Added Lines]",
          "36:     DEPENDENCIES_EPOCH_NUMBER=${DEPENDENCIES_EPOCH_NUMBER} \\",
          "37:     INSTALL_MYSQL_CLIENT=\"true\" \\",
          "38:     INSTALL_MSSQL_CLIENT=\"true\"",
          "45:     curl --silent --fail --location https://deb.nodesource.com/setup_14.x | bash - \\",
          "46:     && curl --silent --fail https://dl.yarnpkg.com/debian/pubkey.gpg | apt-key add - >/dev/null 2>&1 \\",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "57:     ADDITIONAL_DEV_APT_DEPS=${ADDITIONAL_DEV_APT_DEPS} \\",
          "58:     ADDITIONAL_DEV_APT_COMMAND=${ADDITIONAL_DEV_APT_COMMAND}",
          "64: # Install basic and additional apt dependencies",
          "66:     && mkdir -pv /usr/share/man/man7 \\",
          "67:     && export ${ADDITIONAL_DEV_ENV_VARS?} \\",
          "70:     && apt-get update \\",
          "71:     && apt-get install -y --no-install-recommends \\",
          "72:            apt-utils \\",
          "",
          "[Removed Lines]",
          "60: # As of August 2021, Debian buster-slim does not include Python2 by default and we need it",
          "61: # as we still support running Python2 via PythonVirtualenvOperator",
          "62: # TODO: Remove python2 when we stop supporting it",
          "65: RUN mkdir -pv /usr/share/man/man1 \\",
          "68:     && bash -o pipefail -e -u -x -c \"${DEV_APT_COMMAND}\" \\",
          "69:     && bash -o pipefail -e -u -x -c \"${ADDITIONAL_DEV_APT_COMMAND}\" \\",
          "",
          "[Added Lines]",
          "56: RUN apt-get update \\",
          "57:     && apt-get install --no-install-recommends -yqq apt-utils >/dev/null 2>&1 \\",
          "58:     && apt-get install -y --no-install-recommends curl gnupg2 \\",
          "59:     && mkdir -pv /usr/share/man/man1 \\",
          "62:     && bash -o pipefail -o errexit -o nounset -o nolog -c \"${DEV_APT_COMMAND}\" \\",
          "63:     && bash -o pipefail -o errexit -o nounset -o nolog -c \"${ADDITIONAL_DEV_APT_COMMAND}\" \\",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "102:     && apt-get clean \\",
          "103:     && rm -rf /var/lib/apt/lists/*",
          "110:     && echo \"airflow ALL=(ALL) NOPASSWD: ALL\" > /etc/sudoers.d/airflow \\",
          "111:     && chmod 0440 /etc/sudoers.d/airflow",
          "115: ARG RUNTIME_APT_DEPS=\"\\",
          "117:       libgcc-8-dev \\",
          "118:       apt-transport-https \\",
          "119:       bash-completion \\",
          "",
          "[Removed Lines]",
          "105: COPY scripts/docker/*.sh /scripts/docker/",
          "106: RUN bash /scripts/docker/install_mysql.sh dev \\",
          "107:     && bash /scripts/docker/install_mssql.sh \\",
          "108:     && adduser airflow \\",
          "109:     && echo \"airflow:airflow\" | chpasswd \\",
          "113: # The latest buster images do not have libpython 2.7 installed and it is needed",
          "114: # To run virtualenv tests with python 2",
          "116:       gnupg \\",
          "",
          "[Added Lines]",
          "99: # Only copy mysql/mssql installation scripts for now - so that changing the other",
          "100: # scripts which are needed much later will not invalidate the docker layer here",
          "101: COPY scripts/docker/install_mysql.sh scripts/docker/install_mssql.sh /scripts/docker/",
          "102: RUN bash -o pipefail -o errexit -o nounset -o nolog /scripts/docker/install_mysql.sh dev \\",
          "103:     && bash -o pipefail -o errexit -o nounset -o nolog /scripts/docker/install_mssql.sh \\",
          "104:     && adduser --gecos \"First Last,RoomNumber,WorkPhone,HomePhone\" --disabled-password \\",
          "105:               --quiet \"airflow\" --home \"/home/airflow\" \\",
          "106:     && echo -e \"airflow\\nairflow\" | passwd airflow 2>&1 \\",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "141: RUN SYSTEM=$(uname -s | tr '[:upper:]' '[:lower:]') \\",
          "142:     && HELM_URL=\"https://get.helm.sh/helm-${HELM_VERSION}-${SYSTEM}-amd64.tar.gz\" \\",
          "144:     && chmod +x /usr/local/bin/helm",
          "146: ARG ADDITIONAL_RUNTIME_APT_DEPS=\"\"",
          "",
          "[Removed Lines]",
          "143:     && curl --location \"${HELM_URL}\" | tar -xvz -O \"${SYSTEM}\"-amd64/helm > /usr/local/bin/helm \\",
          "",
          "[Added Lines]",
          "137:     && curl --silent --location \"${HELM_URL}\" | tar -xz -O \"${SYSTEM}\"-amd64/helm > /usr/local/bin/helm \\",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "170:     && mkdir -pv /usr/share/man/man7 \\",
          "171:     && export ${ADDITIONAL_DEV_APT_ENV?} \\",
          "172:     && export ${ADDITIONAL_RUNTIME_APT_ENV?} \\",
          "175:     && apt-get update \\",
          "176:     && apt-get install --no-install-recommends -y \\",
          "177:       ${RUNTIME_APT_DEPS} \\",
          "",
          "[Removed Lines]",
          "173:     && bash -o pipefail -e -u -x -c \"${RUNTIME_APT_COMMAND}\" \\",
          "174:     && bash -o pipefail -e -u -x -c \"${ADDITIONAL_RUNTIME_APT_COMMAND}\" \\",
          "",
          "[Added Lines]",
          "166:     && bash -o pipefail -o errexit -o nounset -o nolog -c \"${RUNTIME_APT_COMMAND}\" \\",
          "167:     && bash -o pipefail -o errexit -o nounset -o nolog -c \"${ADDITIONAL_RUNTIME_APT_COMMAND}\" \\",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "179:     && apt-get autoremove -yqq --purge \\",
          "180:     && apt-get clean \\",
          "181:     && rm -rf /var/lib/apt/lists/* \\",
          "183:     |  tar -C /usr/bin --strip-components=1 -xvzf - docker/docker",
          "185: WORKDIR ${AIRFLOW_SOURCES}",
          "",
          "[Removed Lines]",
          "182:     && curl https://download.docker.com/linux/static/stable/x86_64/docker-${DOCKER_CLI_VERSION}.tgz \\",
          "",
          "[Added Lines]",
          "175:     && curl --silent \"https://download.docker.com/linux/static/stable/x86_64/docker-${DOCKER_CLI_VERSION}.tgz\" \\",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "197: RUN curl -sSL https://github.com/bats-core/bats-core/archive/v${BATS_VERSION}.tar.gz -o /tmp/bats.tgz \\",
          "198:     && tar -zxf /tmp/bats.tgz -C /tmp \\",
          "200:     && mkdir -p /opt/bats/lib/bats-support \\",
          "201:     && curl -sSL https://github.com/bats-core/bats-support/archive/v${BATS_SUPPORT_VERSION}.tar.gz -o /tmp/bats-support.tgz \\",
          "202:     && tar -zxf /tmp/bats-support.tgz -C /opt/bats/lib/bats-support --strip 1 && rm -rf /tmp/* \\",
          "",
          "[Removed Lines]",
          "199:     && /bin/bash /tmp/bats-core-${BATS_VERSION}/install.sh /opt/bats && rm -rf \\",
          "",
          "[Added Lines]",
          "192:     && bash -o pipefail -o errexit -o nounset -o nolog /tmp/bats-core-${BATS_VERSION}/install.sh /opt/bats && rm -rf \\",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "278: ENV EAGER_UPGRADE_ADDITIONAL_REQUIREMENTS=${EAGER_UPGRADE_ADDITIONAL_REQUIREMENTS} \\",
          "279:     UPGRADE_TO_NEWER_DEPENDENCIES=${UPGRADE_TO_NEWER_DEPENDENCIES}",
          "281: # In case of CI builds we want to pre-install main version of airflow dependencies so that",
          "282: # We do not have to always reinstall it from the scratch.",
          "283: # And is automatically reinstalled from the scratch every time patch release of python gets released",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "274: COPY scripts/docker/*.sh scripts/docker/install_pip_version.sh /scripts/docker/",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "285: # are uninstalled, only dependencies remain.",
          "286: # the cache is only used when \"upgrade to newer dependencies\" is not set to automatically",
          "287: # account for removed dependencies (we do not install them in the first place)",
          "289:     if [[ ${AIRFLOW_PRE_CACHED_PIP_PACKAGES} == \"true\" && \\",
          "290:           ${UPGRADE_TO_NEWER_DEPENDENCIES} == \"false\" ]]; then \\",
          "292:     fi",
          "294: # Generate random hex dump file so that we can determine whether it's faster to rebuild the image",
          "",
          "[Removed Lines]",
          "288: RUN bash /scripts/docker/install_pip_version.sh; \\",
          "291:         bash /scripts/docker/install_airflow_dependencies_from_branch_tip.sh; \\",
          "",
          "[Added Lines]",
          "283: RUN echo -e \"\\n\\e[32mThe 'Running pip as the root user' warnings below are not valid but we can't disable them :(\\e[0m\\n\"; \\",
          "284:     echo -e \"\\n\\e[34mSee https://github.com/pypa/pip/issues/10556 for details.\\e[0m\\n\" ; \\",
          "285:     bash -o pipefail -o errexit -o nounset -o nolog /scripts/docker/install_pip_version.sh; \\",
          "288:         bash -o pipefail -o errexit -o nounset -o nolog /scripts/docker/install_airflow_dependencies_from_branch_tip.sh; \\",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "299: # Link dumb-init for backwards compatibility (so that older images also work)",
          "300: RUN ln -sf /usr/bin/dumb-init /usr/local/bin/dumb-init",
          "309: # Note! We are copying everything with airflow:airflow user:group even if we use root to run the scripts",
          "310: # This is fine as root user will be able to use those dirs anyway.",
          "",
          "[Removed Lines]",
          "302: # Install NPM dependencies here. The NPM dependencies don't change that often and we already have pip",
          "303: # installed dependencies in case of CI optimised build, so it is ok to install NPM deps here",
          "304: # Rather than after setup.py is added.",
          "305: COPY airflow/www/yarn.lock airflow/www/package.json ${AIRFLOW_SOURCES}/airflow/www/",
          "307: RUN yarn --cwd airflow/www install --frozen-lockfile --no-cache && yarn cache clean",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "324: # But in cron job we will install latest versions matching setup.py to see if there is no breaking change",
          "325: # and push the constraints if everything is successful",
          "326: RUN if [[ ${INSTALL_FROM_PYPI} == \"true\" ]]; then \\",
          "328:     fi",
          "330: # Copy all the www/ files we need to compile assets. Done as two separate COPY",
          "331: # commands so as otherwise it copies the _contents_ of static/ in to www/",
          "333: COPY airflow/www/static ${AIRFLOW_SOURCES}/airflow/www/static/",
          "336: # Package JS/css for production",
          "339: COPY scripts/in_container/entrypoint_ci.sh /entrypoint",
          "340: RUN chmod a+x /entrypoint",
          "",
          "[Removed Lines]",
          "327:         bash /scripts/docker/install_airflow.sh; \\",
          "332: COPY airflow/www/webpack.config.js ${AIRFLOW_SOURCES}/airflow/www/",
          "334: COPY airflow/www/compile_assets.sh ${AIRFLOW_SOURCES}/airflow/www/compile_assets.sh",
          "337: RUN bash airflow/www/compile_assets.sh",
          "",
          "[Added Lines]",
          "317:         bash -o pipefail -o errexit -o nounset -o nolog /scripts/docker/install_airflow.sh; \\",
          "322: COPY airflow/www/webpack.config.js airflow/www/package.json airflow/www/yarn.lock ${AIRFLOW_SOURCES}/airflow/www/",
          "326: RUN bash -o pipefail -o errexit -o nounset -o nolog /scripts/docker/compile_www_assets.sh",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "344: # Additional python deps to install",
          "345: ARG ADDITIONAL_PYTHON_DEPS=\"\"",
          "348:     if [[ -n \"${ADDITIONAL_PYTHON_DEPS}\" ]]; then \\",
          "350:     fi",
          "352: # Install autocomplete for airflow",
          "",
          "[Removed Lines]",
          "347: RUN bash /scripts/docker/install_pip_version.sh; \\",
          "349:             bash /scripts/docker/install_additional_dependencies.sh; \\",
          "",
          "[Added Lines]",
          "336: RUN bash -o pipefail -o errexit -o nounset -o nolog /scripts/docker/install_pip_version.sh; \\",
          "338:             bash -o pipefail -o errexit -o nounset -o nolog /scripts/docker/install_additional_dependencies.sh; \\",
          "",
          "---------------"
        ],
        "scripts/docker/common.sh||scripts/docker/common.sh": [
          "File: scripts/docker/common.sh -> scripts/docker/common.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: # under the License.",
          "18: set -euo pipefail",
          "26: function common::get_airflow_version_specification() {",
          "28:         && -n ${AIRFLOW_VERSION}",
          "29:         && ${AIRFLOW_INSTALLATION_METHOD} != \".\" ]]; then",
          "30:         AIRFLOW_VERSION_SPECIFICATION=\"==${AIRFLOW_VERSION}\"",
          "",
          "[Removed Lines]",
          "20: : \"${INSTALL_MYSQL_CLIENT:?Should be true or false}\"",
          "21: : \"${INSTALL_MSSQL_CLIENT:?Should be true or false}\"",
          "22: : \"${AIRFLOW_REPO:?Should be set}\"",
          "23: : \"${AIRFLOW_BRANCH:?Should be set}\"",
          "24: : \"${AIRFLOW_PIP_VERSION:?Should be set}\"",
          "27:     if [[ -z ${AIRFLOW_VERSION_SPECIFICATION}",
          "",
          "[Added Lines]",
          "20: function common::get_colors() {",
          "21:     COLOR_BLUE=$'\\e[34m'",
          "22:     COLOR_GREEN=$'\\e[32m'",
          "23:     COLOR_RED=$'\\e[31m'",
          "24:     COLOR_RESET=$'\\e[0m'",
          "25:     COLOR_YELLOW=$'\\e[33m'",
          "26:     export COLOR_BLUE",
          "27:     export COLOR_GREEN",
          "28:     export COLOR_RED",
          "29:     export COLOR_RESET",
          "30:     export COLOR_YELLOW",
          "31: }",
          "35:     if [[ -z ${AIRFLOW_VERSION_SPECIFICATION=}",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "42: function common::get_constraints_location() {",
          "43:     # auto-detect Airflow-constraint reference and location",
          "45:         if  [[ ${AIRFLOW_VERSION} =~ v?2.* ]]; then",
          "46:             AIRFLOW_CONSTRAINTS_REFERENCE=constraints-${AIRFLOW_VERSION}",
          "47:         else",
          "",
          "[Removed Lines]",
          "44:     if [[ -z \"${AIRFLOW_CONSTRAINTS_REFERENCE}\" ]]; then",
          "",
          "[Added Lines]",
          "52:     if [[ -z \"${AIRFLOW_CONSTRAINTS_REFERENCE=}\" ]]; then",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "49:         fi",
          "50:     fi",
          "53:         local constraints_base=\"https://raw.githubusercontent.com/${CONSTRAINTS_GITHUB_REPOSITORY}/${AIRFLOW_CONSTRAINTS_REFERENCE}\"",
          "54:         local python_version",
          "55:         python_version=\"$(python --version 2>/dev/stdout | cut -d \" \" -f 2 | cut -d \".\" -f 1-2)\"",
          "",
          "[Removed Lines]",
          "52:     if [[ -z ${AIRFLOW_CONSTRAINTS_LOCATION} ]]; then",
          "",
          "[Added Lines]",
          "60:     if [[ -z ${AIRFLOW_CONSTRAINTS_LOCATION=} ]]; then",
          "",
          "---------------"
        ],
        "scripts/docker/compile_www_assets.sh||scripts/docker/compile_www_assets.sh": [
          "File: scripts/docker/compile_www_assets.sh -> scripts/docker/compile_www_assets.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "18: # shellcheck disable=SC2086",
          "19: set -euo pipefail",
          "21: # Installs additional dependencies passed as Argument to the Docker build command",
          "22: function compile_www_assets() {",
          "23:     echo",
          "25:     echo",
          "26:     local md5sum_file",
          "27:     md5sum_file=\"static/dist/sum.md5\"",
          "",
          "[Removed Lines]",
          "24:     echo Compiling WWW assets",
          "",
          "[Added Lines]",
          "21: BUILD_TYPE=${BUILD_TYPE=\"prod\"}",
          "23: COLOR_BLUE=$'\\e[34m'",
          "24: readonly COLOR_BLUE",
          "25: COLOR_RESET=$'\\e[0m'",
          "26: readonly COLOR_RESET",
          "31:     echo \"${COLOR_BLUE}Compiling www assets${COLOR_RESET}\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "29:     local www_dir",
          "30:     if [[ ${AIRFLOW_INSTALLATION_METHOD=} == \".\" ]]; then",
          "31:         # In case we are building from sources in production image, we should build the assets",
          "33:     else",
          "34:         www_dir=\"$(python -m site --user-site)/airflow/www\"",
          "35:     fi",
          "",
          "[Removed Lines]",
          "32:         www_dir=\"${AIRFLOW_SOURCES_TO}/airflow/www\"",
          "",
          "[Added Lines]",
          "39:         www_dir=\"${AIRFLOW_SOURCES_TO=${AIRFLOW_SOURCES}}/airflow/www\"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "44:         >&2 cat /tmp/out-yarn-install.txt && rm -f /tmp/out-yarn-install.txt",
          "45:         exit 1",
          "46:     fi",
          "48:     res=$?",
          "49:     if [[ ${res} != 0 ]]; then",
          "50:         >&2 echo",
          "51:         >&2 echo \"Error when running yarn install:\"",
          "52:         >&2 echo",
          "54:         exit 1",
          "55:     fi",
          "56:     rm -f /tmp/out-yarn-run.txt",
          "",
          "[Removed Lines]",
          "47:     yarn run prod 2>/tmp/out-yarn-run.txt",
          "53:         >&2 cat /tmp/out-yarn-run.txt && rm -f /tmp/out-yarn-run.txt",
          "",
          "[Added Lines]",
          "54:     rm -f /tmp/out-yarn-install.txt",
          "55:     yarn run \"${BUILD_TYPE}\" 2>/tmp/out-yarn-run.txt",
          "61:         >&2 cat /tmp/out-yarn-run.txt && rm -rf /tmp/out-yarn-run.txt",
          "",
          "---------------"
        ],
        "scripts/docker/install_additional_dependencies.sh||scripts/docker/install_additional_dependencies.sh": [
          "File: scripts/docker/install_additional_dependencies.sh -> scripts/docker/install_additional_dependencies.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "33: function install_additional_dependencies() {",
          "34:     if [[ \"${UPGRADE_TO_NEWER_DEPENDENCIES}\" != \"false\" ]]; then",
          "35:         echo",
          "37:         echo",
          "38:         pip install --upgrade --upgrade-strategy eager \\",
          "39:             ${ADDITIONAL_PYTHON_DEPS} ${EAGER_UPGRADE_ADDITIONAL_REQUIREMENTS}",
          "40:         # make sure correct PIP version is used",
          "41:         pip install --disable-pip-version-check \"pip==${AIRFLOW_PIP_VERSION}\"",
          "42:         pip check",
          "43:     else",
          "44:         echo",
          "46:         echo",
          "47:         pip install --upgrade --upgrade-strategy only-if-needed \\",
          "48:             ${ADDITIONAL_PYTHON_DEPS}",
          "49:         # make sure correct PIP version is used",
          "50:         pip install --disable-pip-version-check \"pip==${AIRFLOW_PIP_VERSION}\"",
          "51:         pip check",
          "52:     fi",
          "53: }",
          "55: common::get_airflow_version_specification",
          "56: common::override_pip_version_if_needed",
          "57: common::get_constraints_location",
          "",
          "[Removed Lines]",
          "36:         echo Installing additional dependencies while upgrading to newer dependencies",
          "45:         echo Installing additional dependencies upgrading only if needed",
          "",
          "[Added Lines]",
          "36:         echo \"${COLOR_BLUE}Installing additional dependencies while upgrading to newer dependencies${COLOR_RESET}\"",
          "42:         echo",
          "43:         echo \"${COLOR_BLUE}Running 'pip check'${COLOR_RESET}\"",
          "44:         echo",
          "48:         echo \"${COLOR_BLUE}Installing additional dependencies upgrading only if needed${COLOR_RESET}\"",
          "54:         echo",
          "55:         echo \"${COLOR_BLUE}Running 'pip check'${COLOR_RESET}\"",
          "56:         echo",
          "61: common::get_colors",
          "",
          "---------------"
        ],
        "scripts/docker/install_airflow.sh||scripts/docker/install_airflow.sh": [
          "File: scripts/docker/install_airflow.sh -> scripts/docker/install_airflow.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "29: # shellcheck source=scripts/docker/common.sh",
          "30: . \"$( dirname \"${BASH_SOURCE[0]}\" )/common.sh\"",
          "32: function install_airflow() {",
          "33:     # Coherence check for editable installation mode.",
          "34:     if [[ ${AIRFLOW_INSTALLATION_METHOD} != \".\" && \\",
          "35:           ${AIRFLOW_INSTALL_EDITABLE_FLAG} == \"--editable\" ]]; then",
          "36:         echo",
          "39:         exit 1",
          "40:     fi",
          "41:     # Remove mysql from extras if client is not going to be installed",
          "",
          "[Removed Lines]",
          "37:         echo \"ERROR! You can only use --editable flag when installing airflow from sources!\"",
          "38:         echo \"       Current installation method is '${AIRFLOW_INSTALLATION_METHOD} and should be '.'\"",
          "",
          "[Added Lines]",
          "32: : \"${AIRFLOW_PIP_VERSION:?Should be set}\"",
          "39:         echo \"${COLOR_RED}ERROR! You can only use --editable flag when installing airflow from sources!${COLOR_RESET}\"",
          "40:         echo \"{COLOR_RED}       Current installation method is '${AIRFLOW_INSTALLATION_METHOD} and should be '.'${COLOR_RESET}\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "44:     fi",
          "45:     if [[ \"${UPGRADE_TO_NEWER_DEPENDENCIES}\" != \"false\" ]]; then",
          "46:         echo",
          "48:         echo",
          "49:         # eager upgrade",
          "50:         pip install --upgrade --upgrade-strategy eager \\",
          "",
          "[Removed Lines]",
          "47:         echo Installing all packages with eager upgrade",
          "",
          "[Added Lines]",
          "49:         echo \"${COLOR_BLUE}Installing all packages with eager upgrade${COLOR_RESET}\"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "57:             pip install ${AIRFLOW_INSTALL_EDITABLE_FLAG} \\",
          "58:                 \"${AIRFLOW_INSTALLATION_METHOD}[${AIRFLOW_EXTRAS}]${AIRFLOW_VERSION_SPECIFICATION}\"",
          "59:         fi",
          "61:         # make sure correct PIP version is used",
          "62:         pip install --disable-pip-version-check \"pip==${AIRFLOW_PIP_VERSION}\"",
          "63:         pip check",
          "64:     else \\",
          "65:         echo",
          "67:         echo",
          "68:         pip install ${AIRFLOW_INSTALL_EDITABLE_FLAG} \\",
          "69:             \"${AIRFLOW_INSTALLATION_METHOD}[${AIRFLOW_EXTRAS}]${AIRFLOW_VERSION_SPECIFICATION}\" \\",
          "",
          "[Removed Lines]",
          "66:         echo Installing all packages with constraints and upgrade if needed",
          "",
          "[Added Lines]",
          "64:         echo",
          "65:         echo \"${COLOR_BLUE}Running 'pip check'${COLOR_RESET}\"",
          "66:         echo",
          "70:         echo \"${COLOR_BLUE}Installing all packages with constraints and upgrade if needed${COLOR_RESET}\"",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "76:             \"${AIRFLOW_INSTALLATION_METHOD}[${AIRFLOW_EXTRAS}]${AIRFLOW_VERSION_SPECIFICATION}\"",
          "77:         # make sure correct PIP version is used",
          "78:         pip install --disable-pip-version-check \"pip==${AIRFLOW_PIP_VERSION}\"",
          "79:         pip check",
          "80:     fi",
          "82: }",
          "84: common::get_airflow_version_specification",
          "85: common::override_pip_version_if_needed",
          "86: common::get_constraints_location",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "83:         echo",
          "84:         echo \"${COLOR_BLUE}Running 'pip check'${COLOR_RESET}\"",
          "85:         echo",
          "91: common::get_colors",
          "",
          "---------------"
        ],
        "scripts/docker/install_airflow_dependencies_from_branch_tip.sh||scripts/docker/install_airflow_dependencies_from_branch_tip.sh": [
          "File: scripts/docker/install_airflow_dependencies_from_branch_tip.sh -> scripts/docker/install_airflow_dependencies_from_branch_tip.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "29: # shellcheck source=scripts/docker/common.sh",
          "30: . \"$( dirname \"${BASH_SOURCE[0]}\" )/common.sh\"",
          "33: function install_airflow_dependencies_from_branch_tip() {",
          "34:     echo",
          "36:     echo",
          "37:     if [[ ${INSTALL_MYSQL_CLIENT} != \"true\" ]]; then",
          "38:        AIRFLOW_EXTRAS=${AIRFLOW_EXTRAS/mysql,}",
          "",
          "[Removed Lines]",
          "35:     echo \"Installing airflow from ${AIRFLOW_BRANCH}. It is used to cache dependencies\"",
          "",
          "[Added Lines]",
          "32: : \"${AIRFLOW_REPO:?Should be set}\"",
          "33: : \"${AIRFLOW_BRANCH:?Should be set}\"",
          "34: : \"${INSTALL_MYSQL_CLIENT:?Should be true or false}\"",
          "35: : \"${AIRFLOW_PIP_VERSION:?Should be set}\"",
          "39:     echo \"${COLOR_BLUE}Installing airflow from ${AIRFLOW_BRANCH}. It is used to cache dependencies${COLOR_RESET}\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "46:     pip install --disable-pip-version-check \"pip==${AIRFLOW_PIP_VERSION}\"",
          "47:     pip freeze | grep apache-airflow-providers | xargs pip uninstall --yes 2>/dev/null || true",
          "48:     echo",
          "50:     echo",
          "51:     pip uninstall --yes apache-airflow || true",
          "52: }",
          "54: common::get_airflow_version_specification",
          "55: common::override_pip_version_if_needed",
          "56: common::get_constraints_location",
          "",
          "[Removed Lines]",
          "49:     echo Uninstalling just airflow. Dependencies remain.",
          "",
          "[Added Lines]",
          "53:     echo \"${COLOR_BLUE}Uninstalling just airflow. Dependencies remain. Now target airflow can be reinstalled using mostly cached dependencies${COLOR_RESET}\"",
          "58: common::get_colors",
          "",
          "---------------"
        ],
        "scripts/docker/install_from_docker_context_files.sh||scripts/docker/install_from_docker_context_files.sh": [
          "File: scripts/docker/install_from_docker_context_files.sh -> scripts/docker/install_from_docker_context_files.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "25: # shellcheck source=scripts/docker/common.sh",
          "26: . \"$( dirname \"${BASH_SOURCE[0]}\" )/common.sh\"",
          "28: function install_airflow_and_providers_from_docker_context_files(){",
          "29:     if [[ ${INSTALL_MYSQL_CLIENT} != \"true\" ]]; then",
          "30:         AIRFLOW_EXTRAS=${AIRFLOW_EXTRAS/mysql,}",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "28: : \"${AIRFLOW_PIP_VERSION:?Should be set}\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "66:     if [[ \"${UPGRADE_TO_NEWER_DEPENDENCIES}\" != \"false\" ]]; then",
          "67:         echo",
          "69:         echo",
          "70:         # force reinstall all airflow + provider package local files with eager upgrade",
          "71:         pip install \"${pip_flags[@]}\" --upgrade --upgrade-strategy eager \\",
          "",
          "[Removed Lines]",
          "68:         echo Force re-installing airflow and providers from local files with eager upgrade",
          "",
          "[Added Lines]",
          "70:         echo \"${COLOR_BLUE}Force re-installing airflow and providers from local files with eager upgrade${COLOR_RESET}\"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "73:             ${EAGER_UPGRADE_ADDITIONAL_REQUIREMENTS}",
          "74:     else",
          "75:         echo",
          "77:         echo",
          "78:         if [[ ${AIRFLOW_CONSTRAINTS_LOCATION} == \"/\"* ]]; then",
          "79:             grep -ve '^apache-airflow' <\"${AIRFLOW_CONSTRAINTS_LOCATION}\" > /tmp/constraints.txt",
          "",
          "[Removed Lines]",
          "76:         echo Force re-installing airflow and providers from local files with constraints and upgrade if needed",
          "",
          "[Added Lines]",
          "78:         echo \"${COLOR_BLUE}Force re-installing airflow and providers from local files with constraints and upgrade if needed${COLOR_RESET}\"",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "104: # method on air-gaped system where you do not want to download any dependencies from remote hosts",
          "105: # which is a requirement for serious installations",
          "106: function install_all_other_packages_from_docker_context_files() {",
          "107:     echo",
          "109:     echo",
          "110:     local reinstalling_other_packages",
          "111:     # shellcheck disable=SC2010",
          "",
          "[Removed Lines]",
          "108:     echo Force re-installing all other package from local files without dependencies",
          "",
          "[Added Lines]",
          "111:     echo \"${COLOR_BLUE}Force re-installing all other package from local files without dependencies${COLOR_RESET}\"",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "118:     fi",
          "119: }",
          "121: common::get_airflow_version_specification",
          "122: common::override_pip_version_if_needed",
          "123: common::get_constraints_location",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "124: common::get_colors",
          "",
          "---------------"
        ],
        "scripts/docker/install_mssql.sh||scripts/docker/install_mssql.sh": [
          "File: scripts/docker/install_mssql.sh -> scripts/docker/install_mssql.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "18: set -euo pipefail",
          "19: function install_mssql_client() {",
          "20:     echo",
          "22:     echo",
          "23:     curl --silent https://packages.microsoft.com/keys/microsoft.asc | apt-key add - >/dev/null 2>&1",
          "24:     curl --silent https://packages.microsoft.com/config/debian/10/prod.list > /etc/apt/sources.list.d/mssql-release.list",
          "",
          "[Removed Lines]",
          "21:     echo Installing mssql client",
          "",
          "[Added Lines]",
          "20: : \"${INSTALL_MSSQL_CLIENT:?Should be true or false}\"",
          "22: COLOR_BLUE=$'\\e[34m'",
          "23: readonly COLOR_BLUE",
          "24: COLOR_RESET=$'\\e[0m'",
          "25: readonly COLOR_RESET",
          "28:     echo \"${COLOR_BLUE}Installing mssql client${COLOR_RESET}\"",
          "",
          "---------------"
        ],
        "scripts/docker/install_mysql.sh||scripts/docker/install_mysql.sh": [
          "File: scripts/docker/install_mysql.sh -> scripts/docker/install_mysql.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: MYSQL_VERSION=\"8.0\"",
          "22: readonly MYSQL_VERSION",
          "24: install_mysql_client() {",
          "25:     echo",
          "27:     echo",
          "29:     if [[ \"${1}\" == \"dev\" ]]; then",
          "",
          "[Removed Lines]",
          "26:     echo Installing mysql client",
          "",
          "[Added Lines]",
          "24: COLOR_BLUE=$'\\e[34m'",
          "25: readonly COLOR_BLUE",
          "26: COLOR_RESET=$'\\e[0m'",
          "27: readonly COLOR_RESET",
          "29: : \"${INSTALL_MYSQL_CLIENT:?Should be true or false}\"",
          "33:     echo \"${COLOR_BLUE}Installing mysql client version ${MYSQL_VERSION}${COLOR_RESET}\"",
          "",
          "---------------"
        ],
        "scripts/docker/install_pip_version.sh||scripts/docker/install_pip_version.sh": [
          "File: scripts/docker/install_pip_version.sh -> scripts/docker/install_pip_version.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "28: # shellcheck disable=SC2086",
          "29: # shellcheck source=scripts/docker/common.sh",
          "30: . \"$( dirname \"${BASH_SOURCE[0]}\" )/common.sh\"",
          "32: function install_pip_version() {",
          "33:     pip install --disable-pip-version-check --no-cache-dir --upgrade \"pip==${AIRFLOW_PIP_VERSION}\" &&",
          "34:         mkdir -p ${HOME}/.local/bin",
          "35: }",
          "37: common::get_airflow_version_specification",
          "38: common::override_pip_version_if_needed",
          "40: common::show_pip_version_and_location",
          "42: install_pip_version",
          "",
          "[Removed Lines]",
          "19: # Install airflow using regular 'pip install' command. This install airflow depending on the arguments:",
          "20: # AIRFLOW_INSTALLATION_METHOD - determines where to install airflow form:",
          "21: #             \".\" - installs airflow from local sources",
          "22: #             \"apache-airflow\" - installs airflow from PyPI 'apache-airflow' package",
          "23: # AIRFLOW_VERSION_SPECIFICATION - optional specification for Airflow version to install (",
          "24: #                                 might be ==2.0.2 for example or <3.0.0",
          "25: # UPGRADE_TO_NEWER_DEPENDENCIES - determines whether eager-upgrade should be performed with the",
          "26: #                                 dependencies (with EAGER_UPGRADE_ADDITIONAL_REQUIREMENTS added)",
          "27: #",
          "39: common::get_constraints_location",
          "",
          "[Added Lines]",
          "23: : \"${AIRFLOW_PIP_VERSION:?Should be set}\"",
          "26:     echo",
          "27:     echo \"${COLOR_BLUE}Installing pip version ${AIRFLOW_PIP_VERSION}${COLOR_RESET}\"",
          "28:     echo",
          "33: common::get_colors",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "f466f1c209e44a52fb44f0eb1cbd09e02ffb6897",
      "candidate_info": {
        "commit_hash": "f466f1c209e44a52fb44f0eb1cbd09e02ffb6897",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/f466f1c209e44a52fb44f0eb1cbd09e02ffb6897",
        "files": [
          "scripts/ci/libraries/_build_images.sh"
        ],
        "message": "Fix new buildkit builds on MacOS (#20963)\n\nMacOS requires array variables to be declared on top level\n(Bash3).\n\nThis PR changes BUILD_COMMAND variable to be declared at top level.\n\n(cherry picked from commit 9a1eeeb5c085c9aa8aab0d1f7a814c9e0fc0ecef)",
        "before_after_code_files": [
          "scripts/ci/libraries/_build_images.sh||scripts/ci/libraries/_build_images.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "scripts/ci/libraries/_build_images.sh||scripts/ci/libraries/_build_images.sh": [
          "File: scripts/ci/libraries/_build_images.sh -> scripts/ci/libraries/_build_images.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "19: # For remote installation of airflow (from GitHub or PyPI) when building the image, you need to",
          "20: # pass build flags depending on the version and method of the installation (for example to",
          "21: # get proper requirement constraint files)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19: # Needs to be declared outside of function for MacOS",
          "21: BUILD_COMMAND=()",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "319: }",
          "321: function build_images::check_if_buildx_plugin_available() {",
          "323:     local buildx_version",
          "324:     buildx_version=$(docker buildx version 2>/dev/null || true)",
          "325:     if [[ ${buildx_version} != \"\" ]]; then",
          "334:             docker_v buildx inspect airflow_cache || docker_v buildx create --name airflow_cache",
          "335:         else",
          "336:             echo",
          "337:             echo \"${COLOR_RED}Buildx cli plugin is not available and you need it to prepare buildx cache.${COLOR_RESET}\"",
          "338:             echo \"${COLOR_RED}Please install it following https://docs.docker.com/buildx/working-with-buildx/${COLOR_RESET}\"",
          "339:             echo",
          "340:             exit 1",
          "341:         fi",
          "342:     fi",
          "343: }",
          "",
          "[Removed Lines]",
          "322:     export BUILD_COMMAND=(\"build\")",
          "326:         BUILDX_PLUGIN_AVAILABLE=\"true\"",
          "327:         export BUILD_COMMAND=(\"buildx\" \"build\" \"--builder\" \"default\" \"--progress=tty\")",
          "328:     else",
          "329:         BUILDX_PLUGIN_AVAILABLE=\"false\"",
          "330:     fi",
          "331:     if [[ ${PREPARE_BUILDX_CACHE} == \"true\" ]]; then",
          "332:         if [[ ${BUILDX_PLUGIN_AVAILABLE} == \"true\" ]]; then",
          "333:             export BUILD_COMMAND=(\"buildx\" \"build\" \"--builder\" \"airflow_cache\" \"--progress=tty\")",
          "",
          "[Added Lines]",
          "329:         if [[ ${PREPARE_BUILDX_CACHE} == \"true\" ]]; then",
          "330:             BUILD_COMMAND+=(\"buildx\" \"build\" \"--builder\" \"airflow_cache\" \"--progress=tty\")",
          "333:             BUILD_COMMAND+=(\"buildx\" \"build\" \"--builder\" \"default\" \"--progress=tty\")",
          "334:         fi",
          "335:     else",
          "336:         if [[ ${PREPARE_BUILDX_CACHE} == \"true\" ]]; then",
          "343:         BUILD_COMMAND+=(\"build\")",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "fd5558fe9eb4c82f1aa49244deb75a6d500334bc",
      "candidate_info": {
        "commit_hash": "fd5558fe9eb4c82f1aa49244deb75a6d500334bc",
        "repo": "apache/airflow",
        "commit_url": "https://github.com/apache/airflow/commit/fd5558fe9eb4c82f1aa49244deb75a6d500334bc",
        "files": [
          "airflow/config_templates/config.yml",
          "airflow/config_templates/default_airflow.cfg",
          "airflow/providers/amazon/aws/utils/emailer.py",
          "airflow/utils/email.py",
          "docs/apache-airflow/howto/email-config.rst",
          "tests/providers/amazon/aws/utils/test_emailer.py",
          "tests/utils/test_email.py"
        ],
        "message": "Fixing ses email backend (#18042)\n\n(cherry picked from commit 1543dc28f4a2f1631dfaedd948e646a181ccf7ee)",
        "before_after_code_files": [
          "airflow/config_templates/default_airflow.cfg||airflow/config_templates/default_airflow.cfg",
          "airflow/providers/amazon/aws/utils/emailer.py||airflow/providers/amazon/aws/utils/emailer.py",
          "airflow/utils/email.py||airflow/utils/email.py",
          "tests/providers/amazon/aws/utils/test_emailer.py||tests/providers/amazon/aws/utils/test_emailer.py",
          "tests/utils/test_email.py||tests/utils/test_email.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/airflow/pull/21659"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "airflow/config_templates/default_airflow.cfg||airflow/config_templates/default_airflow.cfg": [
          "File: airflow/config_templates/default_airflow.cfg -> airflow/config_templates/default_airflow.cfg",
          "--- Hunk 1 ---",
          "[Context before]",
          "681: # Example: html_content_template = /path/to/my_html_content_template_file",
          "682: # html_content_template =",
          "684: [smtp]",
          "686: # If you want airflow to send emails on retries, failure, and you want to use",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "684: # Email address that will be used as sender address.",
          "685: # It can either be raw email or the complete address in a format ``Sender Name <sender@email.com>``",
          "686: # Example: from_email = Airflow <airflow@example.com>",
          "687: # from_email =",
          "",
          "---------------"
        ],
        "airflow/providers/amazon/aws/utils/emailer.py||airflow/providers/amazon/aws/utils/emailer.py": [
          "File: airflow/providers/amazon/aws/utils/emailer.py -> airflow/providers/amazon/aws/utils/emailer.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "25: def send_email(",
          "26:     to: Union[List[str], str],",
          "27:     subject: str,",
          "28:     html_content: str,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "26:     from_email: str,",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "37:     \"\"\"Email backend for SES.\"\"\"",
          "38:     hook = SESHook(aws_conn_id=conn_id)",
          "39:     hook.send_email(",
          "41:         to=to,",
          "42:         subject=subject,",
          "43:         html_content=html_content,",
          "",
          "[Removed Lines]",
          "40:         mail_from=None,",
          "",
          "[Added Lines]",
          "41:         mail_from=from_email,",
          "",
          "---------------"
        ],
        "airflow/utils/email.py||airflow/utils/email.py": [
          "File: airflow/utils/email.py -> airflow/utils/email.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "49:     \"\"\"Send email using backend specified in EMAIL_BACKEND.\"\"\"",
          "50:     backend = conf.getimport('email', 'EMAIL_BACKEND')",
          "51:     backend_conn_id = conn_id or conf.get(\"email\", \"EMAIL_CONN_ID\")",
          "52:     to_list = get_email_address_list(to)",
          "53:     to_comma_separated = \", \".join(to_list)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "52:     from_email = conf.get('email', 'from_email', fallback=None)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "63:         mime_subtype=mime_subtype,",
          "64:         mime_charset=mime_charset,",
          "65:         conn_id=backend_conn_id,",
          "67:     )",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "68:         from_email=from_email,",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "78:     mime_subtype: str = 'mixed',",
          "79:     mime_charset: str = 'utf-8',",
          "80:     conn_id: str = \"smtp_default\",",
          "82: ):",
          "83:     \"\"\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "84:     from_email: str = None,",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "87:     \"\"\"",
          "88:     smtp_mail_from = conf.get('smtp', 'SMTP_MAIL_FROM')",
          "90:     msg, recipients = build_mime_message(",
          "92:         to=to,",
          "93:         subject=subject,",
          "94:         html_content=html_content,",
          "",
          "[Removed Lines]",
          "91:         mail_from=smtp_mail_from,",
          "",
          "[Added Lines]",
          "94:     mail_from = smtp_mail_from or from_email",
          "97:         mail_from=mail_from,",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "99:         mime_charset=mime_charset,",
          "100:     )",
          "105: def build_mime_message(",
          "",
          "[Removed Lines]",
          "102:     send_mime_email(e_from=smtp_mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)",
          "",
          "[Added Lines]",
          "108:     send_mime_email(e_from=mail_from, e_to=recipients, mime_msg=msg, conn_id=conn_id, dryrun=dryrun)",
          "",
          "---------------"
        ],
        "tests/providers/amazon/aws/utils/test_emailer.py||tests/providers/amazon/aws/utils/test_emailer.py": [
          "File: tests/providers/amazon/aws/utils/test_emailer.py -> tests/providers/amazon/aws/utils/test_emailer.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "16: # specific language governing permissions and limitations",
          "17: # under the License.",
          "18: #",
          "22: from airflow.providers.amazon.aws.utils.emailer import send_email",
          "",
          "[Removed Lines]",
          "20: from unittest import mock",
          "25: @mock.patch(\"airflow.providers.amazon.aws.utils.emailer.SESHook\")",
          "26: def test_send_email(mock_hook):",
          "27:     send_email(",
          "28:         to=\"to@test.com\",",
          "29:         subject=\"subject\",",
          "30:         html_content=\"content\",",
          "31:     )",
          "32:     mock_hook.return_value.send_email.assert_called_once_with(",
          "33:         mail_from=None,",
          "34:         to=\"to@test.com\",",
          "35:         subject=\"subject\",",
          "36:         html_content=\"content\",",
          "37:         bcc=None,",
          "38:         cc=None,",
          "39:         files=None,",
          "40:         mime_charset=\"utf-8\",",
          "41:         mime_subtype=\"mixed\",",
          "42:     )",
          "",
          "[Added Lines]",
          "19: from unittest import TestCase, mock",
          "24: class TestSendEmailSes(TestCase):",
          "25:     @mock.patch(\"airflow.providers.amazon.aws.utils.emailer.SESHook\")",
          "26:     def test_send_ses_email(self, mock_hook):",
          "27:         send_email(",
          "28:             from_email=\"From Test <from@test.com>\",",
          "29:             to=\"to@test.com\",",
          "30:             subject=\"subject\",",
          "31:             html_content=\"content\",",
          "32:         )",
          "34:         mock_hook.return_value.send_email.assert_called_once_with(",
          "35:             mail_from=\"From Test <from@test.com>\",",
          "36:             to=\"to@test.com\",",
          "37:             subject=\"subject\",",
          "38:             html_content=\"content\",",
          "39:             bcc=None,",
          "40:             cc=None,",
          "41:             files=None,",
          "42:             mime_charset=\"utf-8\",",
          "43:             mime_subtype=\"mixed\",",
          "44:         )",
          "",
          "---------------"
        ],
        "tests/utils/test_email.py||tests/utils/test_email.py": [
          "File: tests/utils/test_email.py -> tests/utils/test_email.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "99:             mime_charset='utf-8',",
          "100:             mime_subtype='mixed',",
          "101:             conn_id='smtp_default',",
          "102:         )",
          "103:         assert not mock_send_email.called",
          "105:     def test_build_mime_message(self):",
          "106:         mail_from = 'from@example.com'",
          "107:         mail_to = 'to@example.com'",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "102:             from_email=None,",
          "106:     @mock.patch('airflow.utils.email.send_email_smtp')",
          "107:     @conf_vars(",
          "108:         {",
          "109:             ('email', 'email_backend'): 'tests.utils.test_email.send_email_test',",
          "110:             ('email', 'from_email'): 'from@test.com',",
          "111:         }",
          "112:     )",
          "113:     def test_custom_backend_sender(self, mock_send_email_smtp):",
          "114:         utils.email.send_email('to', 'subject', 'content')",
          "115:         _, call_kwargs = send_email_test.call_args",
          "116:         assert call_kwargs['from_email'] == 'from@test.com'",
          "117:         assert not mock_send_email_smtp.called",
          "",
          "---------------"
        ]
      }
    }
  ]
}