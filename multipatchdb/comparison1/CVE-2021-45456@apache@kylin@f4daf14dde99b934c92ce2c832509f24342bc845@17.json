{
  "cve_id": "CVE-2021-45456",
  "cve_desc": "Apache kylin checks the legitimacy of the project before executing some commands with the project name passed in by the user. There is a mismatch between what is being checked and what is being used as the shell command argument in DiagnosisService. This may cause an illegal project name to pass the check and perform the following steps, resulting in a command injection vulnerability. This issue affects Apache Kylin 4.0.0.",
  "repo": "apache/kylin",
  "patch_hash": "f4daf14dde99b934c92ce2c832509f24342bc845",
  "patch_info": {
    "commit_hash": "f4daf14dde99b934c92ce2c832509f24342bc845",
    "repo": "apache/kylin",
    "commit_url": "https://github.com/apache/kylin/commit/f4daf14dde99b934c92ce2c832509f24342bc845",
    "files": [
      "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
      "core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java",
      "core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java",
      "server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java",
      "server/src/main/webapp/WEB-INF/web.xml"
    ],
    "message": "test fix",
    "before_after_code_files": [
      "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
      "core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java||core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java",
      "core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java||core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java",
      "server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java||server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java"
    ]
  },
  "patch_diff": {
    "core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java||core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java": [
      "File: core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java -> core-common/src/main/java/org/apache/kylin/common/KylinConfigBase.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "3403:     public String getKerberosPrincipal() {",
      "3404:         return getOptional(\"kylin.kerberos.principal\");",
      "3405:     }",
      "3406: }",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "3407:     public String getEncryptCipherIvSpec() {",
      "3408:         return getOptional(\"kylin.security.encrypt.cipher.ivSpec\", \"AAAAAAAAAAAAAAAA\");",
      "3409:     }",
      "",
      "---------------"
    ],
    "core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java||core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java": [
      "File: core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java -> core-common/src/main/java/org/apache/kylin/common/util/EncryptUtil.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "25: import java.security.NoSuchAlgorithmException;",
      "27: import org.apache.commons.codec.binary.Base64;",
      "29: import javax.crypto.Cipher;",
      "30: import javax.crypto.NoSuchPaddingException;",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "28: import org.apache.kylin.common.KylinConfig;",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "42:             InvalidKeyException, NoSuchPaddingException, NoSuchAlgorithmException, UnsupportedEncodingException {",
      "43:         Cipher cipher = Cipher.getInstance(\"AES/CFB/PKCS5Padding\");",
      "44:         final SecretKeySpec secretKey = new SecretKeySpec(key, \"AES\");",
      "46:         cipher.init(cipherMode, secretKey, ivSpec);",
      "47:         return cipher;",
      "48:     }",
      "",
      "[Removed Lines]",
      "45:         IvParameterSpec ivSpec = new IvParameterSpec(\"AAAAAAAAAAAAAAAA\".getBytes(\"UTF-8\"));",
      "",
      "[Added Lines]",
      "46:         IvParameterSpec ivSpec = new IvParameterSpec(KylinConfig.getInstanceFromEnv().getEncryptCipherIvSpec().getBytes(\"UTF-8\"));",
      "",
      "---------------"
    ],
    "core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java||core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java": [
      "File: core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java -> core-common/src/test/java/org/apache/kylin/common/util/EncryptUtilTest.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "19: package org.apache.kylin.common.util;",
      "21: import org.junit.Assert;",
      "22: import org.junit.Test;",
      "26:     @Test",
      "27:     public void testAESEncrypt(){",
      "",
      "[Removed Lines]",
      "24: public class EncryptUtilTest {",
      "",
      "[Added Lines]",
      "21: import org.junit.After;",
      "23: import org.junit.Before;",
      "26: public class EncryptUtilTest extends LocalFileMetadataTestCase {",
      "27:     @Before",
      "28:     public void setUp() throws Exception {",
      "29:         this.createTestMetadata();",
      "30:     }",
      "32:     @After",
      "33:     public void after() throws Exception {",
      "34:         this.cleanupTestMetadata();",
      "35:     }",
      "",
      "---------------"
    ],
    "server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java||server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java": [
      "File: server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java -> server-base/src/main/java/org/apache/kylin/rest/service/DiagnosisService.java",
      "--- Hunk 1 ---",
      "[Context before]",
      "87:     public String dumpProjectDiagnosisInfo(String project, File exportPath) throws IOException {",
      "88:         Message msg = MsgPicker.getMsg();",
      "89:         ProjectInstance projectInstance =",
      "90:                 ProjectManager.getInstance(KylinConfig.getInstanceFromEnv())",
      "92:         if (null == projectInstance) {",
      "93:             throw new BadRequestException(",
      "95:         }",
      "96:         aclEvaluate.checkProjectOperationPermission(projectInstance);",
      "98:         runDiagnosisCLI(args);",
      "99:         return getDiagnosisPackageName(exportPath);",
      "100:     }",
      "",
      "[Removed Lines]",
      "91:                         .getProject(ValidateUtil.convertStringToBeAlphanumericUnderscore(project));",
      "94:                     String.format(Locale.ROOT, msg.getDIAG_PROJECT_NOT_FOUND(), project));",
      "97:         String[] args = { project, exportPath.getAbsolutePath() };",
      "",
      "[Added Lines]",
      "89:         String projectName = ValidateUtil.convertStringToBeAlphanumericUnderscore(project);",
      "92:                         .getProject(projectName);",
      "95:                     String.format(Locale.ROOT, msg.getDIAG_PROJECT_NOT_FOUND(), projectName));",
      "98:         String[] args = { projectName, exportPath.getAbsolutePath() };",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "5b3859c9d6871cd001a39ece43c856275215e01b",
      "candidate_info": {
        "commit_hash": "5b3859c9d6871cd001a39ece43c856275215e01b",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/5b3859c9d6871cd001a39ece43c856275215e01b",
        "files": [
          ".github/workflows/maven.yml",
          "core-metrics/src/main/java/org/apache/kylin/metrics/lib/impl/BlockingReservoir.java",
          "server/src/main/resources/kylinMetrics.xml"
        ],
        "message": "KYLIN-4653 Make the capacity for the LinkedBlockingQueue of BlockingReservoir configurable\n\n(cherry picked from commit 159a0fffe0aff2babd7d6f97bab7de6c7dc2be35)",
        "before_after_code_files": [
          "core-metrics/src/main/java/org/apache/kylin/metrics/lib/impl/BlockingReservoir.java||core-metrics/src/main/java/org/apache/kylin/metrics/lib/impl/BlockingReservoir.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "core-metrics/src/main/java/org/apache/kylin/metrics/lib/impl/BlockingReservoir.java||core-metrics/src/main/java/org/apache/kylin/metrics/lib/impl/BlockingReservoir.java": [
          "File: core-metrics/src/main/java/org/apache/kylin/metrics/lib/impl/BlockingReservoir.java -> core-metrics/src/main/java/org/apache/kylin/metrics/lib/impl/BlockingReservoir.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "39: public class BlockingReservoir extends AbstractActiveReservoir {",
          "41:     private static final Logger logger = LoggerFactory.getLogger(BlockingReservoir.class);",
          "",
          "[Removed Lines]",
          "42:     private static final int MAX_QUEUE_SIZE = 50000;",
          "",
          "[Added Lines]",
          "42:     private static final int MAX_QUEUE_SIZE = 500000;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "60:     }",
          "62:     public BlockingReservoir(int minReportSize, int maxReportSize, int maxReportTime) {",
          "64:     }",
          "66:     public BlockingReservoir(int minReportSize, int maxReportSize, int maxReportTime, int maxQueueSize) {",
          "",
          "[Removed Lines]",
          "63:         this(minReportSize, maxReportSize, maxReportSize, MAX_QUEUE_SIZE);",
          "",
          "[Added Lines]",
          "63:         this(minReportSize, maxReportSize, maxReportTime, MAX_QUEUE_SIZE);",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "68:         Preconditions.checkArgument(maxReportSize >= minReportSize,",
          "69:                 \"maxReportSize should not be less than minBatchSize\");",
          "70:         Preconditions.checkArgument(maxReportTime > 0, \"maxReportTime should be larger than 0\");",
          "72:         this.maxReportSize = maxReportSize;",
          "73:         this.maxReportTime = maxReportTime * 60 * 1000L;",
          "76:         this.listeners = Lists.newArrayList();",
          "78:         this.records = Lists.newArrayListWithExpectedSize(this.maxReportSize);",
          "",
          "[Removed Lines]",
          "71:         this.minReportSize = minReportSize;",
          "75:         this.recordsQueue = new LinkedBlockingQueue<>(maxQueueSize);",
          "",
          "[Added Lines]",
          "74:         this.recordsQueue = maxQueueSize <= 0 ? new LinkedBlockingQueue<>() : new LinkedBlockingQueue<>(maxQueueSize);",
          "75:         this.minReportSize = minReportSize;",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "fa8e0fccefdaab37e93ff83e1f7d19f3af19f47d",
      "candidate_info": {
        "commit_hash": "fa8e0fccefdaab37e93ff83e1f7d19f3af19f47d",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/fa8e0fccefdaab37e93ff83e1f7d19f3af19f47d",
        "files": [
          "build/deploy/server.xml",
          "build/script/download-tomcat.sh",
          "pom.xml",
          "server/src/main/java/org/apache/kylin/rest/DebugTomcat.java"
        ],
        "message": "KYLIN-5178, upgrade tomcat to 8.5.78 (#1863)\n\n* KYLIN-5178, upgrade tomcat to 8.5.78\n\n* minor fix, comment the JasperListener which already removed from tomcat 8.0",
        "before_after_code_files": [
          "build/script/download-tomcat.sh||build/script/download-tomcat.sh",
          "server/src/main/java/org/apache/kylin/rest/DebugTomcat.java||server/src/main/java/org/apache/kylin/rest/DebugTomcat.java"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "build/script/download-tomcat.sh||build/script/download-tomcat.sh": [
          "File: build/script/download-tomcat.sh -> build/script/download-tomcat.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "27:     alias md5cmd=\"md5 -q\"",
          "28: fi",
          "33: if [ ! -f \"build/apache-tomcat-${tomcat_pkg_version}.tar.gz\" ]",
          "34: then",
          "35:     echo \"no binary file found\"",
          "37: else",
          "38:     if [ `md5cmd build/apache-tomcat-${tomcat_pkg_version}.tar.gz | awk '{print $1}'` != \"${tomcat_pkg_md5}\" ]",
          "39:     then",
          "",
          "[Removed Lines]",
          "30: tomcat_pkg_version=\"7.0.100\"",
          "31: tomcat_pkg_md5=\"79be4ba5a6e770730a4be3d5cb3c7862\"",
          "36:     wget --directory-prefix=build/ http://archive.apache.org/dist/tomcat/tomcat-7/v${tomcat_pkg_version}/bin/apache-tomcat-${tomcat_pkg_version}.tar.gz || echo \"Download tomcat failed\"",
          "",
          "[Added Lines]",
          "30: tomcat_pkg_version=\"8.5.78\"",
          "31: tomcat_pkg_md5=\"2e4752883c3082fad82fd17ba1f35b3a\"",
          "36:     wget --directory-prefix=build/ http://archive.apache.org/dist/tomcat/tomcat-8/v${tomcat_pkg_version}/bin/apache-tomcat-${tomcat_pkg_version}.tar.gz || echo \"Download tomcat failed\"",
          "",
          "---------------"
        ],
        "server/src/main/java/org/apache/kylin/rest/DebugTomcat.java||server/src/main/java/org/apache/kylin/rest/DebugTomcat.java": [
          "File: server/src/main/java/org/apache/kylin/rest/DebugTomcat.java -> server/src/main/java/org/apache/kylin/rest/DebugTomcat.java",
          "--- Hunk 1 ---",
          "[Context before]",
          "21: import org.apache.catalina.Context;",
          "22: import org.apache.catalina.core.AprLifecycleListener;",
          "23: import org.apache.catalina.core.StandardServer;",
          "25: import org.apache.catalina.startup.Tomcat;",
          "26: import org.apache.commons.io.FileUtils;",
          "27: import org.apache.commons.lang3.StringUtils;",
          "28: import org.apache.hadoop.security.UserGroupInformation;",
          "29: import org.apache.hadoop.util.Shell;",
          "30: import org.apache.kylin.common.KylinConfig;",
          "32: import java.io.File;",
          "33: import java.io.IOException;",
          "",
          "[Removed Lines]",
          "24: import org.apache.catalina.deploy.ErrorPage;",
          "",
          "[Added Lines]",
          "24: import org.apache.tomcat.JarScanner;",
          "25: import org.apache.tomcat.util.descriptor.web.ErrorPage;",
          "32: import org.apache.tomcat.util.scan.StandardJarScanner;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "52:             System.setProperty(\"spring.profiles.active\", \"testing\");",
          "56:                 System.setProperty(\"catalina.home\", \".\");",
          "58:             if (StringUtils.isEmpty(System.getProperty(\"hdp.version\"))) {",
          "59:                 System.setProperty(\"hdp.version\", \"2.4.0.0-169\");",
          "",
          "[Removed Lines]",
          "55:             if (System.getProperty(\"catalina.home\") == null)",
          "",
          "[Added Lines]",
          "57:             if (System.getProperty(\"catalina.home\") == null) {",
          "59:             }",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "103:         File[] files = new File(dir).listFiles();",
          "104:         if (files != null) {",
          "105:             for (File f : files) {",
          "107:                     return f;",
          "108:             }",
          "109:         }",
          "110:         return null;",
          "",
          "[Removed Lines]",
          "106:                 if (f.getName().matches(ptn))",
          "",
          "[Added Lines]",
          "109:                 if (f.getName().matches(ptn)) {",
          "111:                 }",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "144:         server.addLifecycleListener(listener);",
          "146:         Context webContext = tomcat.addWebapp(\"/kylin\", webBase.getAbsolutePath());",
          "147:         ErrorPage notFound = new ErrorPage();",
          "148:         notFound.setErrorCode(404);",
          "149:         notFound.setLocation(\"/index.html\");",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "153:         JarScanner jarScanner = webContext.getJarScanner();",
          "154:         if (jarScanner instanceof StandardJarScanner) {",
          "155:             ((StandardJarScanner) jarScanner).setScanManifest(false);",
          "156:         }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "23ecb279f3df849c7c99c304ca63d427a28ee393",
      "candidate_info": {
        "commit_hash": "23ecb279f3df849c7c99c304ca63d427a28ee393",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/23ecb279f3df849c7c99c304ca63d427a28ee393",
        "files": [
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeSnapshotBuilder.scala",
          "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/SparderLookupManager.scala"
        ],
        "message": "KYLIN-5013 Write table_snapshot to wrong cluster in Kylin4.0",
        "before_after_code_files": [
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeSnapshotBuilder.scala||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeSnapshotBuilder.scala",
          "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/SparderLookupManager.scala||kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/SparderLookupManager.scala"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeSnapshotBuilder.scala||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeSnapshotBuilder.scala": [
          "File: kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeSnapshotBuilder.scala -> kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeSnapshotBuilder.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "75:     val newSnapMap = Maps.newHashMap[String, String]",
          "76:     val fs = HadoopUtil.getWorkingFileSystem",
          "77:     val kylinConf = seg.kylinconf",
          "79:     val toBuildTableDesc = seg.snapshotTables",
          "80:     if (kylinConf.isSnapshotParallelBuildEnabled) {",
          "81:       val service = Executors.newCachedThreadPool()",
          "",
          "[Removed Lines]",
          "78:     val baseDir = kylinConf.getReadHdfsWorkingDirectory",
          "",
          "[Added Lines]",
          "78:     val baseDir = kylinConf.getHdfsWorkingDirectory",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/SparderLookupManager.scala||kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/SparderLookupManager.scala": [
          "File: kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/SparderLookupManager.scala -> kylin-spark-project/kylin-spark-query/src/main/scala/org/apache/kylin/query/runtime/SparderLookupManager.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "65:           columns(index).getName).toString,",
          "66:           SparkTypeUtil.toSparkType(columns(index).getType))",
          "67:       }))",
          "69:     SparderContext.getSparkSession.read",
          "70:       .schema(StructType(tableDesc.getColumns.map(column => StructField(column.getName, SparkTypeUtil.toSparkType(column.getType))).toSeq))",
          "71:       .parquet(rsourcePath)",
          "",
          "[Removed Lines]",
          "68:     val rsourcePath = kylinConfig.getReadHdfsWorkingDirectory + sourcePath",
          "",
          "[Added Lines]",
          "68:     val rsourcePath = kylinConfig.getHdfsWorkingDirectory + sourcePath",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "04e216994b9c03e2f1eee44eab3427ab6b46d619",
      "candidate_info": {
        "commit_hash": "04e216994b9c03e2f1eee44eab3427ab6b46d619",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/04e216994b9c03e2f1eee44eab3427ab6b46d619",
        "files": [
          "build/CI/kylin-system-testing/features/step_impl/auto_config/auto_config.py",
          "build/CI/kylin-system-testing/features/step_impl/happy_path/happy_path.py",
          "build/CI/kylin-system-testing/features/step_impl/project_model/model.py",
          "build/CI/kylin-system-testing/features/step_impl/project_model/project.py",
          "kylin-spark-project/kylin-spark-common/src/test/java/org/apache/spark/sql/common/LocalMetadata.scala",
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeDictionaryBuilder.scala",
          "kylin-spark-project/kylin-spark-engine/src/test/scala/org/apache/kylin/engine/spark/builder/TestGlobalDictBuild.scala"
        ],
        "message": "KYLIN-4927 Forbid to use AE when building Global Dict",
        "before_after_code_files": [
          "build/CI/kylin-system-testing/features/step_impl/auto_config/auto_config.py||build/CI/kylin-system-testing/features/step_impl/auto_config/auto_config.py",
          "build/CI/kylin-system-testing/features/step_impl/happy_path/happy_path.py||build/CI/kylin-system-testing/features/step_impl/happy_path/happy_path.py",
          "build/CI/kylin-system-testing/features/step_impl/project_model/model.py||build/CI/kylin-system-testing/features/step_impl/project_model/model.py",
          "build/CI/kylin-system-testing/features/step_impl/project_model/project.py||build/CI/kylin-system-testing/features/step_impl/project_model/project.py",
          "kylin-spark-project/kylin-spark-common/src/test/java/org/apache/spark/sql/common/LocalMetadata.scala||kylin-spark-project/kylin-spark-common/src/test/java/org/apache/spark/sql/common/LocalMetadata.scala",
          "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeDictionaryBuilder.scala||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeDictionaryBuilder.scala",
          "kylin-spark-project/kylin-spark-engine/src/test/scala/org/apache/kylin/engine/spark/builder/TestGlobalDictBuild.scala||kylin-spark-project/kylin-spark-engine/src/test/scala/org/apache/kylin/engine/spark/builder/TestGlobalDictBuild.scala"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "build/CI/kylin-system-testing/features/step_impl/auto_config/auto_config.py||build/CI/kylin-system-testing/features/step_impl/auto_config/auto_config.py": [
          "File: build/CI/kylin-system-testing/features/step_impl/auto_config/auto_config.py -> build/CI/kylin-system-testing/features/step_impl/auto_config/auto_config.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1: from getgauge.python import step",
          "2: import os",
          "3: import json",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: #!/usr/bin/python",
          "2: #",
          "3: # Licensed to the Apache Software Foundation (ASF) under one or more",
          "4: # contributor license agreements.  See the NOTICE file distributed with",
          "5: # this work for additional information regarding copyright ownership.",
          "6: # The ASF licenses this file to You under the Apache License, Version 2.0",
          "7: # (the \"License\"); you may not use this file except in compliance with",
          "8: # the License.  You may obtain a copy of the License at",
          "9: #",
          "10: #    http://www.apache.org/licenses/LICENSE-2.0",
          "11: #",
          "12: # Unless required by applicable law or agreed to in writing, software",
          "13: # distributed under the License is distributed on an \"AS IS\" BASIS,",
          "14: # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
          "15: # See the License for the specific language governing permissions and",
          "16: # limitations under the License.",
          "",
          "---------------"
        ],
        "build/CI/kylin-system-testing/features/step_impl/happy_path/happy_path.py||build/CI/kylin-system-testing/features/step_impl/happy_path/happy_path.py": [
          "File: build/CI/kylin-system-testing/features/step_impl/happy_path/happy_path.py -> build/CI/kylin-system-testing/features/step_impl/happy_path/happy_path.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1: from getgauge.python import step",
          "2: import os",
          "3: import json",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: #!/usr/bin/python",
          "2: #",
          "3: # Licensed to the Apache Software Foundation (ASF) under one or more",
          "4: # contributor license agreements.  See the NOTICE file distributed with",
          "5: # this work for additional information regarding copyright ownership.",
          "6: # The ASF licenses this file to You under the Apache License, Version 2.0",
          "7: # (the \"License\"); you may not use this file except in compliance with",
          "8: # the License.  You may obtain a copy of the License at",
          "9: #",
          "10: #    http://www.apache.org/licenses/LICENSE-2.0",
          "11: #",
          "12: # Unless required by applicable law or agreed to in writing, software",
          "13: # distributed under the License is distributed on an \"AS IS\" BASIS,",
          "14: # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
          "15: # See the License for the specific language governing permissions and",
          "16: # limitations under the License.",
          "",
          "---------------"
        ],
        "build/CI/kylin-system-testing/features/step_impl/project_model/model.py||build/CI/kylin-system-testing/features/step_impl/project_model/model.py": [
          "File: build/CI/kylin-system-testing/features/step_impl/project_model/model.py -> build/CI/kylin-system-testing/features/step_impl/project_model/model.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1: from getgauge.python import step",
          "2: import os",
          "3: import json",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: #!/usr/bin/python",
          "2: #",
          "3: # Licensed to the Apache Software Foundation (ASF) under one or more",
          "4: # contributor license agreements.  See the NOTICE file distributed with",
          "5: # this work for additional information regarding copyright ownership.",
          "6: # The ASF licenses this file to You under the Apache License, Version 2.0",
          "7: # (the \"License\"); you may not use this file except in compliance with",
          "8: # the License.  You may obtain a copy of the License at",
          "9: #",
          "10: #    http://www.apache.org/licenses/LICENSE-2.0",
          "11: #",
          "12: # Unless required by applicable law or agreed to in writing, software",
          "13: # distributed under the License is distributed on an \"AS IS\" BASIS,",
          "14: # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
          "15: # See the License for the specific language governing permissions and",
          "16: # limitations under the License.",
          "",
          "---------------"
        ],
        "build/CI/kylin-system-testing/features/step_impl/project_model/project.py||build/CI/kylin-system-testing/features/step_impl/project_model/project.py": [
          "File: build/CI/kylin-system-testing/features/step_impl/project_model/project.py -> build/CI/kylin-system-testing/features/step_impl/project_model/project.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1: from getgauge.python import step",
          "2: import os",
          "3: import json",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: #!/usr/bin/python",
          "2: #",
          "3: # Licensed to the Apache Software Foundation (ASF) under one or more",
          "4: # contributor license agreements.  See the NOTICE file distributed with",
          "5: # this work for additional information regarding copyright ownership.",
          "6: # The ASF licenses this file to You under the Apache License, Version 2.0",
          "7: # (the \"License\"); you may not use this file except in compliance with",
          "8: # the License.  You may obtain a copy of the License at",
          "9: #",
          "10: #    http://www.apache.org/licenses/LICENSE-2.0",
          "11: #",
          "12: # Unless required by applicable law or agreed to in writing, software",
          "13: # distributed under the License is distributed on an \"AS IS\" BASIS,",
          "14: # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
          "15: # See the License for the specific language governing permissions and",
          "16: # limitations under the License.",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-common/src/test/java/org/apache/spark/sql/common/LocalMetadata.scala||kylin-spark-project/kylin-spark-common/src/test/java/org/apache/spark/sql/common/LocalMetadata.scala": [
          "File: kylin-spark-project/kylin-spark-common/src/test/java/org/apache/spark/sql/common/LocalMetadata.scala -> kylin-spark-project/kylin-spark-common/src/test/java/org/apache/spark/sql/common/LocalMetadata.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "49:   }",
          "51:   def cleanAfterClass(): Unit = {",
          "61:   }",
          "62: }",
          "",
          "[Removed Lines]",
          "52:     val directory = new File(LocalFileMetadataTestCase.LOCALMETA_TEMP_DATA)",
          "53:     try",
          "54:       FileUtils.deleteDirectory(directory)",
          "55:     catch {",
          "56:       case e: IOException =>",
          "57:         if (directory.exists && directory.list.length > 0) throw new IllegalStateException(\"Can't delete directory \" + directory, e)",
          "58:     }",
          "59:     System.clearProperty(KylinConfig.KYLIN_CONF)",
          "60:     KylinConfig.destroyInstance()",
          "",
          "[Added Lines]",
          "52:     LocalFileMetadataTestCase.cleanAfterClass();",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeDictionaryBuilder.scala||kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeDictionaryBuilder.scala": [
          "File: kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeDictionaryBuilder.scala -> kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeDictionaryBuilder.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "45:   @throws[IOException]",
          "46:   def buildDictSet(): Unit = {",
          "47:     logInfo(s\"Start building global dictionaries V2 for seg $seg\")",
          "48:     val m = s\"Build global dictionaries V2 for seg $seg succeeded\"",
          "49:     time(m, colRefSet.asScala.foreach(col => safeBuild(col)))",
          "50:   }",
          "52:   @throws[IOException]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "50:     val aeOriginalValue = ss.conf.get(\"spark.sql.adaptive.enabled\", \"false\").toBoolean",
          "51:     if (aeOriginalValue) {",
          "52:       ss.conf.set(\"spark.sql.adaptive.enabled\", false);",
          "53:     }",
          "58:     ss.conf.set(\"spark.sql.adaptive.enabled\", aeOriginalValue);",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "55:     lock.lock(getLockPath(sourceColumn), Long.MaxValue)",
          "56:     try",
          "57:       if (lock.lock(getLockPath(sourceColumn))) {",
          "59:         ss.sparkContext.setJobDescription(\"Calculate bucket size \" + ref.identity)",
          "60:         val bucketPartitionSize = DictionaryBuilderHelper.calculateBucketSize(seg, ref, dictColDistinct)",
          "61:         val m = s\"Build global dictionaries V2 for column $sourceColumn succeeded\"",
          "",
          "[Removed Lines]",
          "58:         val dictColDistinct = dataset.select(wrapCol(ref)).distinct",
          "",
          "[Added Lines]",
          "67:         val dictColDistinct = dataset.select(CubeDictionaryBuilder.wrapCol(ref)).distinct",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "67:   @throws[IOException]",
          "68:   private[builder] def build(ref: ColumnDesc, bucketPartitionSize: Int, afterDistinct: Dataset[Row]): Unit = {",
          "69:     val columnName = ref.identity",
          "70:     logInfo(s\"Start building global dictionaries V2 for column $columnName.\")",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "78:     assert(!ss.conf.get(\"spark.sql.adaptive.enabled\", \"false\").toBoolean,",
          "79:       \"Parameter 'spark.sql.adaptive.enabled' must be false when building global dictionary.\")",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "89:   private def getLockPath(pathName: String) = s\"/${seg.project}${HadoopUtil.GLOBAL_DICT_STORAGE_ROOT}/$pathName/lock\"",
          "91:   def wrapCol(ref: ColumnDesc): Column = {",
          "92:     val colName = NSparkCubingUtil.convertFromDot(ref.identity)",
          "93:     expr(colName).cast(StringType)",
          "94:   }",
          "96: }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "102: }",
          "104: object CubeDictionaryBuilder {",
          "",
          "---------------"
        ],
        "kylin-spark-project/kylin-spark-engine/src/test/scala/org/apache/kylin/engine/spark/builder/TestGlobalDictBuild.scala||kylin-spark-project/kylin-spark-engine/src/test/scala/org/apache/kylin/engine/spark/builder/TestGlobalDictBuild.scala": [
          "File: kylin-spark-project/kylin-spark-engine/src/test/scala/org/apache/kylin/engine/spark/builder/TestGlobalDictBuild.scala -> kylin-spark-project/kylin-spark-engine/src/test/scala/org/apache/kylin/engine/spark/builder/TestGlobalDictBuild.scala",
          "--- Hunk 1 ---",
          "[Context before]",
          "26: import org.apache.kylin.common.KylinConfig",
          "27: import org.apache.kylin.common.util.DateFormat",
          "28: import org.apache.kylin.cube.{CubeInstance, CubeManager, CubeSegment}",
          "29: import org.apache.kylin.engine.spark.metadata.{ColumnDesc, MetadataConverter, SegmentInfo}",
          "30: import org.apache.kylin.job.engine.JobEngineConfig",
          "31: import org.apache.kylin.job.impl.threadpool.DefaultScheduler",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "29: import org.apache.kylin.engine.spark.job.NSparkCubingUtil",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "36: import org.apache.spark.sql.catalyst.encoders.RowEncoder",
          "37: import org.apache.spark.sql.common.{LocalMetadata, SharedSparkSession, SparderBaseFunSuite}",
          "38: import org.apache.spark.sql.functions.col",
          "40: import org.apache.spark.sql.{Dataset, Row}",
          "41: import org.junit.Assert",
          "43: import scala.collection.JavaConverters.setAsJavaSetConverter",
          "",
          "[Removed Lines]",
          "39: import org.apache.spark.sql.types.{StringType, StructType}",
          "",
          "[Added Lines]",
          "41: import org.apache.spark.sql.types.StructType",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "74:     val meta1 = buildDict(segInfo, seg, randomDataSet, dictColSet)",
          "75:     Assert.assertEquals(20, meta1.getBucketSize)",
          "76:     Assert.assertEquals(1000, meta1.getDictCount)",
          "80:     val meta2 = buildDict(segInfo, seg, randomDataSet, dictColSet)",
          "81:     Assert.assertEquals(60, meta2.getBucketSize)",
          "82:     Assert.assertEquals(4000, meta2.getDictCount)",
          "85:     val meta3 = buildDict(segInfo, seg, randomDataSet, dictColSet)",
          "86:     Assert.assertEquals(60, meta3.getBucketSize)",
          "87:     Assert.assertEquals(7000, meta3.getDictCount)",
          "91:     val meta4 = buildDict(segInfo, seg, randomDataSet, dictColSet)",
          "92:     Assert.assertEquals(140, meta4.getBucketSize)",
          "93:     Assert.assertEquals(7200, meta4.getDictCount)",
          "97:     val meta5 = buildDict(segInfo, seg, randomDataSet, dictColSet)",
          "98:     Assert.assertEquals(140, meta5.getBucketSize)",
          "99:     Assert.assertEquals(7400, meta5.getDictCount)",
          "103:     val meta6 = buildDict(segInfo, seg, randomDataSet, dictColSet)",
          "104:     Assert.assertEquals(280, meta6.getBucketSize)",
          "105:     Assert.assertEquals(7600, meta6.getDictCount)",
          "108:     val meta7 = buildDict(segInfo, seg, randomDataSet, dictColSet)",
          "109:     Assert.assertEquals(280, meta7.getBucketSize)",
          "110:     Assert.assertEquals(9600, meta7.getDictCount)",
          "111:     DefaultScheduler.destroyInstance()",
          "112:   }",
          "115:     val dictionaryBuilder = new CubeDictionaryBuilder(randomDataSet, segInfo, randomDataSet.sparkSession, dictColSet)",
          "122:     dict.getMetaInfo",
          "123:   }",
          "126:     var schema = new StructType",
          "129:     var set = new mutable.LinkedHashSet[Row]",
          "130:     while (set.size != count) {",
          "131:       val objects = new Array[String](1)",
          "",
          "[Removed Lines]",
          "73:     var randomDataSet = generateOriginData(1000, 21)",
          "79:     randomDataSet = generateOriginData(3000, 22)",
          "84:     randomDataSet = generateOriginData(3000, 23)",
          "90:     randomDataSet = generateOriginData(200, 24)",
          "96:     randomDataSet = generateHotOriginData(200, 140)",
          "102:     randomDataSet = generateOriginData(200, 25)",
          "107:     randomDataSet = generateOriginData(2000, 26)",
          "114:   def buildDict(segInfo: SegmentInfo, seg: CubeSegment, randomDataSet: Dataset[Row], dictColSet: Set[ColumnDesc]): NGlobalDictMetaInfo = {",
          "116:     val col = dictColSet.iterator().next()",
          "117:     val ds = randomDataSet.select(\"26\").distinct()",
          "118:     val bucketPartitionSize = DictionaryBuilderHelper.calculateBucketSize(segInfo, col, ds)",
          "119:     dictionaryBuilder.build(col, bucketPartitionSize, ds)",
          "120:     val dict = new NGlobalDictionary(seg.getProject, col.tableName, col.columnName,",
          "121:       seg.getConfig.getHdfsWorkingDirectory)",
          "125:   def generateOriginData(count: Int, length: Int): Dataset[Row] = {",
          "128:     schema = schema.add(\"26\", StringType)",
          "",
          "[Added Lines]",
          "73:     val dictCol = dictColSet.iterator().next()",
          "75:     var randomDataSet = generateOriginData(dictCol, 1000, 21)",
          "81:     randomDataSet = generateOriginData(dictCol, 3000, 22)",
          "86:     randomDataSet = generateOriginData(dictCol, 3000, 23)",
          "92:     randomDataSet = generateOriginData(dictCol, 200, 24)",
          "98:     randomDataSet = generateHotOriginData(dictCol, 200, 140)",
          "104:     spark.conf.set(\"spark.sql.adaptive.enabled\", false)",
          "105:     randomDataSet = generateOriginData(dictCol, 200, 25)",
          "109:     Assert.assertFalse(spark.conf.get(\"spark.sql.adaptive.enabled\").toBoolean)",
          "111:     spark.conf.set(\"spark.sql.adaptive.enabled\", true)",
          "112:     randomDataSet = generateOriginData(dictCol, 2000, 26)",
          "116:     Assert.assertTrue(spark.conf.get(\"spark.sql.adaptive.enabled\").toBoolean)",
          "120:   def buildDict(segInfo: SegmentInfo, seg: CubeSegment, randomDataSet: Dataset[Row],",
          "121:                 dictColSet: Set[ColumnDesc]): NGlobalDictMetaInfo = {",
          "123:     dictionaryBuilder.buildDictSet()",
          "124:     val columnDesc = dictColSet.iterator().next()",
          "125:     val dict = new NGlobalDictionary(seg.getProject, columnDesc.tableName,",
          "126:       columnDesc.columnName, seg.getConfig.getHdfsWorkingDirectory)",
          "130:   def generateOriginData(colDesc: ColumnDesc, count: Int, length: Int): Dataset[Row] = {",
          "132:     val colName = NSparkCubingUtil.convertFromDot(colDesc.identity)",
          "133:     schema = schema.add(colName, colDesc.dataType)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "136:     spark.createDataFrame(spark.sparkContext.parallelize(set.toSeq), schema)",
          "137:   }",
          "140:     var schema = new StructType",
          "144:       .mapPartitions {",
          "145:         iter =>",
          "146:           val partitionID = TaskContext.get().partitionId()",
          "",
          "[Removed Lines]",
          "139:   def generateHotOriginData(threshold: Int, bucketSize: Int): Dataset[Row] = {",
          "141:     schema = schema.add(\"26\", StringType)",
          "142:     var ds = generateOriginData(threshold * bucketSize * 2, 30)",
          "143:     ds = ds.repartition(bucketSize, col(\"26\"))",
          "",
          "[Added Lines]",
          "144:   def generateHotOriginData(colDesc: ColumnDesc, threshold: Int, bucketSize: Int): Dataset[Row] = {",
          "146:     val colName = NSparkCubingUtil.convertFromDot(colDesc.identity)",
          "147:     schema = schema.add(colName, colDesc.dataType)",
          "148:     var ds = generateOriginData(colDesc, threshold * bucketSize * 2, 30)",
          "149:     ds = ds.repartition(bucketSize, col(colName))",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "c94374569a5534a92ab305898698a3943c89c7ef",
      "candidate_info": {
        "commit_hash": "c94374569a5534a92ab305898698a3943c89c7ef",
        "repo": "apache/kylin",
        "commit_url": "https://github.com/apache/kylin/commit/c94374569a5534a92ab305898698a3943c89c7ef",
        "files": [
          "build/script/build.sh",
          "webapp/bower.json"
        ],
        "message": "KYLIN-5003 Remove legacy front end dependencies",
        "before_after_code_files": [
          "build/script/build.sh||build/script/build.sh"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/apache/kylin/pull/1893",
          "https://github.com/apache/kylin/pull/2018",
          "https://github.com/apache/kylin/pull/2125",
          "https://github.com/apache/kylin/pull/2033",
          "https://github.com/apache/kylin/pull/2112",
          "https://github.com/apache/kylin/pull/2115",
          "https://github.com/apache/kylin/pull/1865",
          "https://github.com/apache/kylin/pull/1913",
          "https://github.com/apache/kylin/pull/2135"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "build/script/build.sh||build/script/build.sh": [
          "File: build/script/build.sh -> build/script/build.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "31: bower --allow-root install   || { exit 1; }",
          "32: npm install       || { exit 1; }",
          "33: npm install -g grunt-cli   || { exit 1; }",
          "34: grunt dev --buildEnv=dev --buildNumber=`date \"+%Y%m%d%H%M%S\"`  || { exit 1; }",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "34: PHANTOMJS_CDNURL=https://npm.taobao.org/mirrors/phantomjs npm install phantomjs-prebuilt || { exit 1; }",
          "",
          "---------------"
        ]
      }
    }
  ]
}