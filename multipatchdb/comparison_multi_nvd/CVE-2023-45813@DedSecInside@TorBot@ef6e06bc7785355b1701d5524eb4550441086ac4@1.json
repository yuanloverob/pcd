{
  "cve_id": "CVE-2023-45813",
  "cve_desc": "Torbot is an open source tor network intelligence tool. In affected versions the `torbot.modules.validators.validate_link function` uses the python-validators URL validation regex. This particular regular expression has an exponential complexity which allows an attacker to cause an application crash using a well-crafted argument. An attacker can use a well-crafted URL argument to exploit the vulnerability in the regular expression and cause a Denial of Service on the system. The validators file has been removed in version 4.0.0. Users are advised to upgrade. There are no known workarounds for this vulnerability.",
  "repo": "DedSecInside/TorBot",
  "patch_hash": "ef6e06bc7785355b1701d5524eb4550441086ac4",
  "patch_info": {
    "commit_hash": "ef6e06bc7785355b1701d5524eb4550441086ac4",
    "repo": "DedSecInside/TorBot",
    "commit_url": "https://github.com/DedSecInside/TorBot/commit/ef6e06bc7785355b1701d5524eb4550441086ac4",
    "files": [
      "torbot/modules/validators.py"
    ],
    "message": "remove unused validators file",
    "before_after_code_files": [
      "torbot/modules/validators.py||torbot/modules/validators.py"
    ]
  },
  "patch_diff": {
    "torbot/modules/validators.py||torbot/modules/validators.py": [
      "File: torbot/modules/validators.py -> torbot/modules/validators.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "[No context available]",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "1f2a293fb29bcc10b50d97ce4df5c918141ad8f5",
      "candidate_info": {
        "commit_hash": "1f2a293fb29bcc10b50d97ce4df5c918141ad8f5",
        "repo": "DedSecInside/TorBot",
        "commit_url": "https://github.com/DedSecInside/TorBot/commit/1f2a293fb29bcc10b50d97ce4df5c918141ad8f5",
        "files": [
          "torbot/main.py"
        ],
        "message": "Update main.py to handle new changes",
        "before_after_code_files": [
          "torbot/main.py||torbot/main.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/DedSecInside/TorBot/pull/307"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "torbot/main.py||torbot/main.py": [
          "File: torbot/main.py -> torbot/main.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "5: import sys",
          "7: from .modules import link_io",
          "9: from .modules.color import color",
          "10: from .modules.updater import check_version",
          "11: from .modules.savefile import saveJson",
          "",
          "[Removed Lines]",
          "8: from .modules.linktree import LinkTree",
          "",
          "[Added Lines]",
          "9: from .modules.link_io import pprint_tree, print_tor_ip_address",
          "10: from .modules.api import get_node",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "22:     def __init__(self, args):",
          "23:         self.args = args",
          "25:     def get_header(self):",
          "26:         license_msg = color(\"LICENSE: GNU Public License v3\", \"red\")",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "26:         self.__version__ = version",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "70:         \"\"\"",
          "71:         Outputs tree visual for data",
          "72:         \"\"\"",
          "74:         # -v/--visualize",
          "75:         if args.visualize:",
          "76:             tree.show()",
          "",
          "[Removed Lines]",
          "73:         tree = LinkTree(args.url, args.depth)",
          "",
          "[Added Lines]",
          "76:         '''",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "79:         if args.download:",
          "80:             file_name = str(input(\"File Name (.txt): \"))",
          "81:             tree.save(file_name)",
          "83:     def perform_action(self):",
          "84:         args = self.args",
          "85:         if args.gather:",
          "86:             collect_data(args.url)",
          "89:         # If flag is -v, --update, -q/--quiet then user only runs that operation",
          "90:         # because these are single flags only",
          "91:         if args.version:",
          "93:             sys.exit()",
          "94:         if args.update:",
          "95:             check_version()",
          "96:             sys.exit()",
          "97:         if not args.quiet:",
          "98:             self.get_header()",
          "104:         if args.classify:",
          "105:             result = main.classify(args.url)",
          "106:             print(\"Website Classification: \" + result[0], \"| Accuracy: \" + str(result[1]))",
          "",
          "[Removed Lines]",
          "87:             return",
          "92:             print(\"TorBot Version:\" + self.__version__)",
          "99:         # If url flag is set then check for accompanying flag set. Only one",
          "100:         # additional flag can be set with -u/--url flag",
          "101:         if not args.url:",
          "102:             print(\"usage: See run.py -h for possible arguments.\")",
          "103:         link_io.print_tor_ip_address()",
          "",
          "[Added Lines]",
          "85:             '''",
          "90:         # If url flag is set then check for accompanying flag set. Only one",
          "91:         # additional flag can be set with -u/--url flag",
          "92:         if not args.url:",
          "93:             print(\"usage: See run.py -h for possible arguments.\")",
          "94:             sys.exit()",
          "98:             sys.exit()",
          "103:             print(f\"TorBot Version: {self.__version__}\")",
          "111:         print_tor_ip_address()",
          "113:         tree = get_node(args.url, args.depth)",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "114:             execute_all(args.url)",
          "115:         else:",
          "116:             if args.url:",
          "118:         print(\"\\n\\n\")",
          "",
          "[Removed Lines]",
          "117:                 link_io.print_tree(args.url, args.depth, args.classifyAll)",
          "",
          "[Added Lines]",
          "128:                 pprint_tree(tree)",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "130:     parser.add_argument(\"-s\", \"--save\", action=\"store_true\", help=\"Save results in a file\")",
          "131:     parser.add_argument(\"-m\", \"--mail\", action=\"store_true\", help=\"Get e-mail addresses from the crawled sites\")",
          "132:     parser.add_argument(\"-p\", \"--phone\", action=\"store_true\", help=\"Get phone numbers from the crawled sites\")",
          "134:     parser.add_argument(\"--gather\", action=\"store_true\", help=\"Gather data for analysis\")",
          "135:     parser.add_argument(\"-v\", \"--visualize\", action=\"store_true\", help=\"Visualizes tree of data gathered.\")",
          "136:     parser.add_argument(\"-d\", \"--download\", action=\"store_true\", help=\"Downloads tree of data gathered.\")",
          "",
          "[Removed Lines]",
          "133:     parser.add_argument(\"--depth\", help=\"Specifiy max depth of crawler (default 1)\", default=1)",
          "",
          "[Added Lines]",
          "144:     parser.add_argument(\"--depth\", type=int, help=\"Specifiy max depth of crawler (default 1)\", default=1)",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "0ac5c326aa6b92877ead91d3dd7484485dfb83eb",
      "candidate_info": {
        "commit_hash": "0ac5c326aa6b92877ead91d3dd7484485dfb83eb",
        "repo": "DedSecInside/TorBot",
        "commit_url": "https://github.com/DedSecInside/TorBot/commit/0ac5c326aa6b92877ead91d3dd7484485dfb83eb",
        "files": [
          "poetry.lock",
          "pyproject.toml",
          "torbot/modules/api.py",
          "torbot/modules/linktree.py"
        ],
        "message": "Test support for socks5 proxy using default values",
        "before_after_code_files": [
          "poetry.lock||poetry.lock",
          "torbot/modules/api.py||torbot/modules/api.py",
          "torbot/modules/linktree.py||torbot/modules/linktree.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/DedSecInside/TorBot/pull/307"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "poetry.lock||poetry.lock": [
          "File: poetry.lock -> poetry.lock",
          "--- Hunk 1 ---",
          "[Context before]",
          "148: httpcore = \">=0.18.0,<0.19.0\"",
          "149: idna = \"*\"",
          "150: sniffio = \"*\"",
          "152: [package.extras]",
          "153: brotli = [\"brotli\", \"brotlicffi\"]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "151: socksio = {version = \"==1.*\", optional = true, markers = \"extra == \\\"socks\\\"\"}",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "553:     {file = \"sniffio-1.3.0.tar.gz\", hash = \"sha256:e60305c5e5d314f5389259b7f22aaa33d8f7dee49763119234af3755c55b9101\"},",
          "554: ]",
          "556: [[package]]",
          "557: name = \"soupsieve\"",
          "558: version = \"2.3.2.post1\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "557: [[package]]",
          "558: name = \"socksio\"",
          "559: version = \"1.0.0\"",
          "560: description = \"Sans-I/O implementation of SOCKS4, SOCKS4A, and SOCKS5.\"",
          "561: optional = false",
          "562: python-versions = \">=3.6\"",
          "563: files = [",
          "564:     {file = \"socksio-1.0.0-py3-none-any.whl\", hash = \"sha256:95dc1f15f9b34e8d7b16f06d74b8ccf48f609af32ab33c608d08761c5dcbb1f3\"},",
          "565:     {file = \"socksio-1.0.0.tar.gz\", hash = \"sha256:f88beb3da5b5c38b9890469de67d0cb0f9d494b78b106ca1845f96c10b91c4ac\"},",
          "566: ]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "691: [metadata]",
          "692: lock-version = \"2.0\"",
          "693: python-versions = \">=3.9,<=3.11.4\"",
          "",
          "[Removed Lines]",
          "694: content-hash = \"ebad665d65bb7d8a6b22362b2ada5cca42961b41f25ff95dbd6b25a65ab803f1\"",
          "",
          "[Added Lines]",
          "706: content-hash = \"bc665d85d8bb2537f084f64260e0b84212b7917a530ff79d8c8c9dd896c015d5\"",
          "",
          "---------------"
        ],
        "torbot/modules/api.py||torbot/modules/api.py": [
          "File: torbot/modules/api.py -> torbot/modules/api.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "30:     \"\"\"",
          "31:     Returns the IP address of the current Tor client the service is using.",
          "32:     \"\"\"",
          "34:     soup = BeautifulSoup(resp.text, features='html.parser')",
          "36:     # Get the content of check tor project, this contains the header and body",
          "",
          "[Removed Lines]",
          "33:     resp = httpx.get(\"https://check.torproject.org/\")",
          "",
          "[Added Lines]",
          "33:     resp = httpx.get(\"https://check.torproject.org/\", proxies='socks5://127.0.0.1:9050')",
          "",
          "---------------"
        ],
        "torbot/modules/linktree.py||torbot/modules/linktree.py": [
          "File: torbot/modules/linktree.py -> torbot/modules/linktree.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "2: Module is used for analyzing link relationships",
          "3: \"\"\"",
          "4: import os",
          "6: import httpx",
          "7: import validators",
          "8: import logging",
          "",
          "[Removed Lines]",
          "5: import re",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "35:     Creates a node for a tree using the given ID which corresponds to a URL.",
          "36:     If the parent_id is None, this will be considered a root node.",
          "37:     \"\"\"",
          "39:     soup = BeautifulSoup(resp.text, 'html.parser')",
          "40:     title = soup.title.text.strip() if soup.title is not None else id",
          "41:     try:",
          "",
          "[Removed Lines]",
          "38:     resp = httpx.get(id)",
          "",
          "[Added Lines]",
          "38:     resp = httpx.get(id, proxies='socks5://127.0.0.1:9050')",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "52:     \"\"\"",
          "53:     if depth > 0:",
          "54:         depth -= 1",
          "56:         children = parse_links(resp.text)",
          "57:         for child in children:",
          "58:             append_node(tree, id=child, parent_id=url)",
          "",
          "[Removed Lines]",
          "55:         resp = httpx.get(url)",
          "",
          "[Added Lines]",
          "55:         resp = httpx.get(url, proxies='socks5://127.0.0.1:9050')",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "174d769140a6b808f48ec4755e16e380c762d708",
      "candidate_info": {
        "commit_hash": "174d769140a6b808f48ec4755e16e380c762d708",
        "repo": "DedSecInside/TorBot",
        "commit_url": "https://github.com/DedSecInside/TorBot/commit/174d769140a6b808f48ec4755e16e380c762d708",
        "files": [
          "poetry.lock",
          "pyproject.toml"
        ],
        "message": "Add httpx and tabulate to poetry",
        "before_after_code_files": [
          "poetry.lock||poetry.lock"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/DedSecInside/TorBot/pull/307"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "poetry.lock||poetry.lock": [
          "File: poetry.lock -> poetry.lock",
          "--- Hunk 1 ---",
          "[Context before]",
          "3: [[package]]",
          "4: name = \"altgraph\"",
          "",
          "[Removed Lines]",
          "1: # This file is automatically @generated by Poetry 1.6.1 and should not be changed by hand.",
          "",
          "[Added Lines]",
          "1: # This file is automatically @generated by Poetry 1.5.1 and should not be changed by hand.",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "11:     {file = \"altgraph-0.17.2.tar.gz\", hash = \"sha256:ebf2269361b47d97b3b88e696439f6e4cbc607c17c51feb1754f90fb79839158\"},",
          "12: ]",
          "14: [[package]]",
          "15: name = \"beautifulsoup4\"",
          "16: version = \"4.11.1\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "14: [[package]]",
          "15: name = \"anyio\"",
          "16: version = \"4.0.0\"",
          "17: description = \"High level compatibility layer for multiple asynchronous event loop implementations\"",
          "18: optional = false",
          "19: python-versions = \">=3.8\"",
          "20: files = [",
          "21:     {file = \"anyio-4.0.0-py3-none-any.whl\", hash = \"sha256:cfdb2b588b9fc25ede96d8db56ed50848b0b649dca3dd1df0b11f683bb9e0b5f\"},",
          "22:     {file = \"anyio-4.0.0.tar.gz\", hash = \"sha256:f7ed51751b2c2add651e5747c891b47e26d2a21be5d32d9311dfe9692f3e5d7a\"},",
          "23: ]",
          "25: [package.dependencies]",
          "26: exceptiongroup = {version = \">=1.0.2\", markers = \"python_version < \\\"3.11\\\"\"}",
          "27: idna = \">=2.8\"",
          "28: sniffio = \">=1.1\"",
          "30: [package.extras]",
          "31: doc = [\"Sphinx (>=7)\", \"packaging\", \"sphinx-autodoc-typehints (>=1.2.0)\"]",
          "32: test = [\"anyio[trio]\", \"coverage[toml] (>=7)\", \"hypothesis (>=4.0)\", \"psutil (>=5.9)\", \"pytest (>=7.0)\", \"pytest-mock (>=3.6.1)\", \"trustme\", \"uvloop (>=0.17)\"]",
          "33: trio = [\"trio (>=0.22)\"]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "65:     {file = \"decorator-5.1.1.tar.gz\", hash = \"sha256:637996211036b6385ef91435e4fae22989472f9d571faba8927ba8253acbc330\"},",
          "66: ]",
          "68: [[package]]",
          "69: name = \"idna\"",
          "70: version = \"3.3\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "89: [[package]]",
          "90: name = \"exceptiongroup\"",
          "91: version = \"1.1.3\"",
          "92: description = \"Backport of PEP 654 (exception groups)\"",
          "93: optional = false",
          "94: python-versions = \">=3.7\"",
          "95: files = [",
          "96:     {file = \"exceptiongroup-1.1.3-py3-none-any.whl\", hash = \"sha256:343280667a4585d195ca1cf9cef84a4e178c4b6cf2274caef9859782b567d5e3\"},",
          "97:     {file = \"exceptiongroup-1.1.3.tar.gz\", hash = \"sha256:097acd85d473d75af5bb98e41b61ff7fe35efe6675e4f9370ec6ec5126d160e9\"},",
          "98: ]",
          "100: [package.extras]",
          "101: test = [\"pytest (>=6)\"]",
          "103: [[package]]",
          "104: name = \"h11\"",
          "105: version = \"0.14.0\"",
          "106: description = \"A pure-Python, bring-your-own-I/O implementation of HTTP/1.1\"",
          "107: optional = false",
          "108: python-versions = \">=3.7\"",
          "109: files = [",
          "110:     {file = \"h11-0.14.0-py3-none-any.whl\", hash = \"sha256:e3fe4ac4b851c468cc8363d500db52c2ead036020723024a109d37346efaa761\"},",
          "111:     {file = \"h11-0.14.0.tar.gz\", hash = \"sha256:8f19fbbe99e72420ff35c00b27a34cb9937e902a8b810e2c88300c6f0a3b699d\"},",
          "112: ]",
          "114: [[package]]",
          "115: name = \"httpcore\"",
          "116: version = \"0.18.0\"",
          "117: description = \"A minimal low-level HTTP client.\"",
          "118: optional = false",
          "119: python-versions = \">=3.8\"",
          "120: files = [",
          "121:     {file = \"httpcore-0.18.0-py3-none-any.whl\", hash = \"sha256:adc5398ee0a476567bf87467063ee63584a8bce86078bf748e48754f60202ced\"},",
          "122:     {file = \"httpcore-0.18.0.tar.gz\", hash = \"sha256:13b5e5cd1dca1a6636a6aaea212b19f4f85cd88c366a2b82304181b769aab3c9\"},",
          "123: ]",
          "125: [package.dependencies]",
          "126: anyio = \">=3.0,<5.0\"",
          "127: certifi = \"*\"",
          "128: h11 = \">=0.13,<0.15\"",
          "129: sniffio = \"==1.*\"",
          "131: [package.extras]",
          "132: http2 = [\"h2 (>=3,<5)\"]",
          "133: socks = [\"socksio (==1.*)\"]",
          "135: [[package]]",
          "136: name = \"httpx\"",
          "137: version = \"0.25.0\"",
          "138: description = \"The next generation HTTP client.\"",
          "139: optional = false",
          "140: python-versions = \">=3.8\"",
          "141: files = [",
          "142:     {file = \"httpx-0.25.0-py3-none-any.whl\", hash = \"sha256:181ea7f8ba3a82578be86ef4171554dd45fec26a02556a744db029a0a27b7100\"},",
          "143:     {file = \"httpx-0.25.0.tar.gz\", hash = \"sha256:47ecda285389cb32bb2691cc6e069e3ab0205956f681c5b2ad2325719751d875\"},",
          "144: ]",
          "146: [package.dependencies]",
          "147: certifi = \"*\"",
          "148: httpcore = \">=0.18.0,<0.19.0\"",
          "149: idna = \"*\"",
          "150: sniffio = \"*\"",
          "152: [package.extras]",
          "153: brotli = [\"brotli\", \"brotlicffi\"]",
          "154: cli = [\"click (==8.*)\", \"pygments (==2.*)\", \"rich (>=10,<14)\"]",
          "155: http2 = [\"h2 (>=3,<5)\"]",
          "156: socks = [\"socksio (==1.*)\"]",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "332: socks = [\"PySocks (>=1.5.6,!=1.5.7)\"]",
          "333: use-chardet-on-py3 = [\"chardet (>=3.0.2,<6)\"]",
          "354: [[package]]",
          "355: name = \"scikit-learn\"",
          "356: version = \"1.3.0\"",
          "",
          "[Removed Lines]",
          "335: [[package]]",
          "336: name = \"requests-mock\"",
          "337: version = \"1.9.3\"",
          "338: description = \"Mock out responses from the requests package\"",
          "339: optional = false",
          "340: python-versions = \"*\"",
          "341: files = [",
          "342:     {file = \"requests-mock-1.9.3.tar.gz\", hash = \"sha256:8d72abe54546c1fc9696fa1516672f1031d72a55a1d66c85184f972a24ba0eba\"},",
          "343:     {file = \"requests_mock-1.9.3-py2.py3-none-any.whl\", hash = \"sha256:0a2d38a117c08bb78939ec163522976ad59a6b7fdd82b709e23bb98004a44970\"},",
          "344: ]",
          "346: [package.dependencies]",
          "347: requests = \">=2.3,<3\"",
          "348: six = \"*\"",
          "350: [package.extras]",
          "351: fixture = [\"fixtures\"]",
          "352: test = [\"fixtures\", \"mock\", \"purl\", \"pytest\", \"sphinx\", \"testrepository (>=0.0.18)\", \"testtools\"]",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "471: [package.dependencies]",
          "472: scikit-learn = \"*\"",
          "474: [[package]]",
          "475: name = \"soupsieve\"",
          "476: version = \"2.3.2.post1\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "545: [[package]]",
          "546: name = \"sniffio\"",
          "547: version = \"1.3.0\"",
          "548: description = \"Sniff out which async library your code is running under\"",
          "549: optional = false",
          "550: python-versions = \">=3.7\"",
          "551: files = [",
          "552:     {file = \"sniffio-1.3.0-py3-none-any.whl\", hash = \"sha256:eecefdce1e5bbfb7ad2eeaabf7c1eeb404d7757c379bd1f7e5cce9d8bf425384\"},",
          "553:     {file = \"sniffio-1.3.0.tar.gz\", hash = \"sha256:e60305c5e5d314f5389259b7f22aaa33d8f7dee49763119234af3755c55b9101\"},",
          "554: ]",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "482:     {file = \"soupsieve-2.3.2.post1.tar.gz\", hash = \"sha256:fc53893b3da2c33de295667a0e19f078c14bf86544af307354de5fcf12a3f30d\"},",
          "483: ]",
          "485: [[package]]",
          "486: name = \"termcolor\"",
          "487: version = \"1.1.0\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "567: [[package]]",
          "568: name = \"tabulate\"",
          "569: version = \"0.9.0\"",
          "570: description = \"Pretty-print tabular data\"",
          "571: optional = false",
          "572: python-versions = \">=3.7\"",
          "573: files = [",
          "574:     {file = \"tabulate-0.9.0-py3-none-any.whl\", hash = \"sha256:024ca478df22e9340661486f85298cff5f6dcdba14f3813e8830015b9ed1948f\"},",
          "575:     {file = \"tabulate-0.9.0.tar.gz\", hash = \"sha256:0095b12bf5966de529c0feb1fa08671671b3368eec77d7ef7ab114be2c068b3c\"},",
          "576: ]",
          "578: [package.extras]",
          "579: widechars = [\"wcwidth\"]",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "595: [metadata]",
          "596: lock-version = \"2.0\"",
          "597: python-versions = \">=3.9,<=3.11.4\"",
          "",
          "[Removed Lines]",
          "598: content-hash = \"b8d1390ad998dd46bc5dd5ae402ac9a50158c2a4873a5a2ef1d7a3791870ced7\"",
          "",
          "[Added Lines]",
          "694: content-hash = \"ebad665d65bb7d8a6b22362b2ada5cca42961b41f25ff95dbd6b25a65ab803f1\"",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "36d3480c5afff06f6d58c5b42004a6a26a7c617e",
      "candidate_info": {
        "commit_hash": "36d3480c5afff06f6d58c5b42004a6a26a7c617e",
        "repo": "DedSecInside/TorBot",
        "commit_url": "https://github.com/DedSecInside/TorBot/commit/36d3480c5afff06f6d58c5b42004a6a26a7c617e",
        "files": [
          "torbot/modules/linktree.py"
        ],
        "message": "better formatted JSON for tree",
        "before_after_code_files": [
          "torbot/modules/linktree.py||torbot/modules/linktree.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/DedSecInside/TorBot/pull/307"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "torbot/modules/linktree.py||torbot/modules/linktree.py": [
          "File: torbot/modules/linktree.py -> torbot/modules/linktree.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "3: \"\"\"",
          "4: import http.client",
          "5: import os",
          "6: import httpx",
          "7: import validators",
          "8: import logging",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "6: import json",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "90:         \"\"\"",
          "91:         Saves the tree to the current working directory under the given file name in JSON.",
          "92:         \"\"\"",
          "94:         file_name = self._get_tree_file_name()",
          "95:         with open(f'{file_name}.json', 'w+') as f:",
          "96:             f.write(json_data)",
          "98:     def showJSON(self) -> None:",
          "99:         \"\"\"",
          "100:         Prints tree to console as JSON",
          "101:         \"\"\"",
          "105:     def showTable(self) -> None:",
          "106:         \"\"\"",
          "",
          "[Removed Lines]",
          "93:         json_data = self.to_json()",
          "102:         json_data = self.to_json()",
          "103:         print(json_data)",
          "",
          "[Added Lines]",
          "94:         json_data = self._to_json()",
          "99:     def _to_json(self) -> str:",
          "100:         json_data = self.to_json()",
          "101:         return json.dumps(json.loads(json_data), indent=2)",
          "107:         print(self._to_json())",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "e06fa5000775e3ece5883c5db4479ab2508835af",
      "candidate_info": {
        "commit_hash": "e06fa5000775e3ece5883c5db4479ab2508835af",
        "repo": "DedSecInside/TorBot",
        "commit_url": "https://github.com/DedSecInside/TorBot/commit/e06fa5000775e3ece5883c5db4479ab2508835af",
        "files": [
          "torbot/modules/api.py"
        ],
        "message": "Remove the use of gotor for building trees and retrieving IP address",
        "before_after_code_files": [
          "torbot/modules/api.py||torbot/modules/api.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_pr": 1,
        "olp_pr_links": [
          "https://github.com/DedSecInside/TorBot/pull/307"
        ],
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "torbot/modules/api.py||torbot/modules/api.py": [
          "File: torbot/modules/api.py -> torbot/modules/api.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "4: Provides access to external services using API wrappers",
          "5: \"\"\"",
          "9: from .config import host, port",
          "11: base_url: str = f'http://{host}:{port}'",
          "15:     \"\"\"",
          "16:     Returns the LinkTree for the given link at the specified depth.",
          "17:     \"\"\"",
          "28:     \"\"\"",
          "29:     Returns the IP address of the current Tor client the service is using.",
          "30:     \"\"\"",
          "39: def get_emails(link: str):",
          "",
          "[Removed Lines]",
          "6: import requests",
          "8: from .log import debug",
          "14: def get_node(link: str, depth: int):",
          "18:     endpoint = f'/tree?link={link}&depth={depth}'",
          "19:     url = base_url + endpoint",
          "20:     debug(f'requesting {url}')",
          "21:     resp = requests.get(url)",
          "22:     data = resp.json()",
          "23:     debug(f'retrieved {data}')",
          "24:     return data",
          "27: def get_ip():",
          "31:     endpoint = '/ip'",
          "32:     url = base_url + endpoint",
          "33:     debug(f'requesting {url}')",
          "34:     resp = requests.get(url)",
          "35:     debug(f'retrieved {resp.text}')",
          "36:     return resp.text",
          "",
          "[Added Lines]",
          "6: import httpx",
          "7: import logging",
          "9: from treelib import Tree",
          "10: from bs4 import BeautifulSoup, Tag",
          "13: from .linktree import append_node, build_tree",
          "17: logging.getLogger(\"httpx\").setLevel(logging.WARNING)",
          "19: def get_node(url: str, depth: int):",
          "23:     tree = Tree()",
          "24:     append_node(tree, id=url, parent_id=None)",
          "25:     build_tree(tree, url, depth)",
          "26:     return tree",
          "29: def get_ip() -> dict:",
          "33:     resp = httpx.get(\"https://check.torproject.org/\")",
          "34:     soup = BeautifulSoup(resp.text, features='html.parser')",
          "36:     # Get the content of check tor project, this contains the header and body",
          "37:     content = soup.find(\"div\", {\"class\": \"content\"})",
          "38:     if not content:",
          "39:         raise Exception(\"unable to find content to parse IP.\")",
          "41:     # parse the header",
          "42:     header_tag = content.find(\"h1\")",
          "43:     if not header_tag:",
          "44:         raise Exception(\"unable to find header\")",
          "45:     if not isinstance(header_tag, Tag):",
          "46:         raise Exception(\"invalid header found\")",
          "47:     header = header_tag.get_text().strip()",
          "49:     # parse the main content containing the IP address",
          "50:     body_tag = content.find(\"p\")",
          "51:     if not body_tag:",
          "52:         raise Exception(\"unable to find body\")",
          "53:     if not isinstance(body_tag, Tag):",
          "54:         raise Exception(\"invalid body found\")",
          "55:     body = body_tag.get_text().strip()",
          "57:     return {\"header\": header, \"body\": body}",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "42:     \"\"\"",
          "43:     endpoint = f'/emails?link={link}'",
          "44:     url = base_url + endpoint",
          "47:     data = resp.json()",
          "49:     return data",
          "",
          "[Removed Lines]",
          "45:     debug(f'requesting {url}')",
          "46:     resp = requests.get(url)",
          "48:     debug(f'retrieved {data}')",
          "",
          "[Added Lines]",
          "66:     resp = httpx.get(url)",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "55:     \"\"\"",
          "56:     endpoint = f'/phone?link={link}'",
          "57:     url = base_url + endpoint",
          "60:     data = resp.json()",
          "62:     return data",
          "",
          "[Removed Lines]",
          "58:     debug(f'requesting {url}')",
          "59:     resp = requests.get(url)",
          "61:     debug(f'retrieved {data}')",
          "",
          "[Added Lines]",
          "77:     resp = httpx.get(url)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "69:     endpoint = f'/content?link={link}'",
          "70:     url = base_url + endpoint",
          "71:     debug(f'requesting {url}')",
          "73:     debug(f'retrieved {resp.text}')",
          "74:     return resp.text",
          "",
          "[Removed Lines]",
          "72:     resp = requests.get(url)",
          "",
          "[Added Lines]",
          "89:     resp = httpx.get(url)",
          "",
          "---------------"
        ]
      }
    }
  ]
}