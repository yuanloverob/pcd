{
  "cve_id": "CVE-2020-7212",
  "cve_desc": "The _encode_invalid_chars function in util/url.py in the urllib3 library 1.25.2 through 1.25.7 for Python allows a denial of service (CPU consumption) because of an inefficient algorithm. The percent_encodings array contains all matches of percent encodings. It is not deduplicated. For a URL of length N, the size of percent_encodings may be up to O(N). The next step (normalize existing percent-encoded bytes) also takes up to O(N) for each step, so the total time is O(N^2). If percent_encodings were deduplicated, the time to compute _encode_invalid_chars would be O(kN), where k is at most 484 ((10+6*2)^2).",
  "repo": "urllib3/urllib3",
  "patch_hash": "a74c9cfbaed9f811e7563cfc3dce894928e0221a",
  "patch_info": {
    "commit_hash": "a74c9cfbaed9f811e7563cfc3dce894928e0221a",
    "repo": "urllib3/urllib3",
    "commit_url": "https://github.com/urllib3/urllib3/commit/a74c9cfbaed9f811e7563cfc3dce894928e0221a",
    "files": [
      "CHANGES.rst",
      "src/urllib3/util/url.py",
      "test/test_util.py"
    ],
    "message": "Percent-encode invalid characters with request target (#1586)",
    "before_after_code_files": [
      "src/urllib3/util/url.py||src/urllib3/util/url.py",
      "test/test_util.py||test/test_util.py"
    ]
  },
  "patch_diff": {
    "src/urllib3/util/url.py||src/urllib3/util/url.py": [
      "File: src/urllib3/util/url.py -> src/urllib3/util/url.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "6: from ..packages import six, rfc3986",
      "7: from ..packages.rfc3986.exceptions import RFC3986Exception, ValidationError",
      "8: from ..packages.rfc3986.validators import Validator",
      "11: url_attrs = ['scheme', 'auth', 'host', 'port', 'path', 'query', 'fragment']",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "9: from ..packages.rfc3986 import abnf_regexp, normalizers, compat, misc",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "17: # Regex for detecting URLs with schemes. RFC 3986 Section 3.1",
      "18: SCHEME_REGEX = re.compile(r\"^(?:[a-zA-Z][a-zA-Z0-9+\\-]*:|/)\")",
      "21: class Url(namedtuple('Url', url_attrs)):",
      "22:     \"\"\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "21: PATH_CHARS = abnf_regexp.UNRESERVED_CHARS_SET | abnf_regexp.SUB_DELIMITERS_SET | {':', '@', '/'}",
      "22: QUERY_CHARS = FRAGMENT_CHARS = PATH_CHARS | {'?'}",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "136:     return s[:min_idx], s[min_idx + 1:], min_delim",
      "139: def parse_url(url):",
      "140:     \"\"\"",
      "141:     Given a url, return a parsed :class:`.Url` namedtuple. Best-effort is",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "143: def _encode_invalid_chars(component, allowed_chars, encoding='utf-8'):",
      "144:     \"\"\"Percent-encodes a URI component without reapplying",
      "145:     onto an already percent-encoded component. Based on",
      "146:     rfc3986.normalizers.encode_component()",
      "147:     \"\"\"",
      "148:     if component is None:",
      "149:         return component",
      "151:     # Try to see if the component we're encoding is already percent-encoded",
      "152:     # so we can skip all '%' characters but still encode all others.",
      "153:     percent_encodings = len(normalizers.PERCENT_MATCHER.findall(",
      "154:                             compat.to_str(component, encoding)))",
      "156:     uri_bytes = component.encode('utf-8', 'surrogatepass')",
      "157:     is_percent_encoded = percent_encodings == uri_bytes.count(b'%')",
      "159:     encoded_component = bytearray()",
      "161:     for i in range(0, len(uri_bytes)):",
      "162:         # Will return a single character bytestring on both Python 2 & 3",
      "163:         byte = uri_bytes[i:i+1]",
      "164:         byte_ord = ord(byte)",
      "165:         if ((is_percent_encoded and byte == b'%')",
      "166:                 or (byte_ord < 128 and byte.decode() in allowed_chars)):",
      "167:             encoded_component.extend(byte)",
      "168:             continue",
      "169:         encoded_component.extend('%{0:02x}'.format(byte_ord).encode().upper())",
      "171:     return encoded_component.decode(encoding)",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "160:         return Url()",
      "162:     is_string = not isinstance(url, six.binary_type)",
      "166:     # RFC 3986 doesn't like URLs that have a host but don't start",
      "167:     # with a scheme and we support URLs like that so we need to",
      "",
      "[Removed Lines]",
      "163:     if not is_string:",
      "164:         url = url.decode(\"utf-8\")",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "171:     if not SCHEME_REGEX.search(url):",
      "172:         url = \"//\" + url",
      "179:     def idna_encode(name):",
      "180:         if name and any([ord(x) > 128 for x in name]):",
      "181:             try:",
      "",
      "[Removed Lines]",
      "174:     try:",
      "175:         iri_ref = rfc3986.IRIReference.from_string(url, encoding=\"utf-8\")",
      "176:     except (ValueError, RFC3986Exception):",
      "177:         six.raise_from(LocationParseError(url), None)",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "188:                 raise LocationParseError(u\"Name '%s' is not a valid IDNA label\" % name)",
      "189:         return name",
      "194:     # rfc3986 strips the authority if it's invalid",
      "195:     if has_authority and uri_ref.authority is None:",
      "",
      "[Removed Lines]",
      "191:     has_authority = iri_ref.authority is not None",
      "192:     uri_ref = iri_ref.encode(idna_encoder=idna_encode)",
      "",
      "[Added Lines]",
      "219:     try:",
      "220:         split_iri = misc.IRI_MATCHER.match(compat.to_str(url)).groupdict()",
      "221:         iri_ref = rfc3986.IRIReference(",
      "222:             split_iri['scheme'], split_iri['authority'],",
      "223:             _encode_invalid_chars(split_iri['path'], PATH_CHARS),",
      "224:             _encode_invalid_chars(split_iri['query'], QUERY_CHARS),",
      "225:             _encode_invalid_chars(split_iri['fragment'], FRAGMENT_CHARS)",
      "226:         )",
      "227:         has_authority = iri_ref.authority is not None",
      "228:         uri_ref = iri_ref.encode(idna_encoder=idna_encode)",
      "229:     except (ValueError, RFC3986Exception):",
      "230:         return six.raise_from(LocationParseError(url), None)",
      "",
      "---------------",
      "--- Hunk 7 ---",
      "[Context before]",
      "210:         ).validate(uri_ref)",
      "211:     except ValidationError:",
      "214:     # For the sake of backwards compatibility we put empty",
      "215:     # string values for path if there are any defined values",
      "",
      "[Removed Lines]",
      "212:         six.raise_from(LocationParseError(url), None)",
      "",
      "[Added Lines]",
      "250:         return six.raise_from(LocationParseError(url), None)",
      "",
      "---------------"
    ],
    "test/test_util.py||test/test_util.py": [
      "File: test/test_util.py -> test/test_util.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "135:         'http://user\\\\@google.com',",
      "136:         'http://google\\\\.com',",
      "137:         'user\\\\@google.com',",
      "139:         'http://user@user@google.com/',",
      "140:     ])",
      "141:     def test_invalid_url(self, url):",
      "142:         with pytest.raises(LocationParseError):",
      "",
      "[Removed Lines]",
      "138:         'http://google.com#fragment#',",
      "",
      "[Added Lines]",
      "140:         # Invalid IDNA labels",
      "141:         u'http://\\uD7FF.com',",
      "142:         u'http://\u2764\ufe0f',",
      "144:         # Unicode surrogates",
      "145:         u'http://\\uD800.com',",
      "146:         u'http://\\uDC00.com',",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "149:         ('HTTPS://Example.Com/?Key=Value', 'https://example.com/?Key=Value'),",
      "150:         ('Https://Example.Com/#Fragment', 'https://example.com/#Fragment'),",
      "151:         ('[::Ff%etH0%Ff]/%ab%Af', '[::ff%25etH0%Ff]/%AB%AF'),",
      "152:     ])",
      "153:     def test_parse_url_normalization(self, url, expected_normalized_url):",
      "154:         \"\"\"Assert parse_url normalizes the scheme/host, and only the scheme/host\"\"\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "160:         # Invalid characters for the query/fragment getting encoded",
      "161:         ('http://google.com/p[]?parameter[]=\\\"hello\\\"#fragment#',",
      "162:          'http://google.com/p%5B%5D?parameter%5B%5D=%22hello%22#fragment%23'),",
      "164:         # Percent encoding isn't applied twice despite '%' being invalid",
      "165:         # but the percent encoding is still normalized.",
      "166:         ('http://google.com/p%5B%5d?parameter%5b%5D=%22hello%22#fragment%23',",
      "167:          'http://google.com/p%5B%5D?parameter%5B%5D=%22hello%22#fragment%23')",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "215:         # Uppercase IRI",
      "216:         (u'http://K\u00f6nigsg\u00e4\u00dfchen.de/stra\u00dfe',",
      "218:     ]",
      "220:     @pytest.mark.parametrize(",
      "",
      "[Removed Lines]",
      "217:          Url('http', host='xn--knigsgchen-b4a3dun.de', path='/stra%C3%9Fe'))",
      "",
      "[Added Lines]",
      "233:          Url('http', host='xn--knigsgchen-b4a3dun.de', path='/stra%C3%9Fe')),",
      "235:         # Unicode Surrogates",
      "236:         (u'http://google.com/\\uD800', Url('http', host='google.com', path='%ED%A0%80')),",
      "237:         (u'http://google.com?q=\\uDC00',",
      "238:          Url('http', host='google.com', path='', query='q=%ED%B0%80')),",
      "239:         (u'http://google.com#\\uDC00',",
      "240:          Url('http', host='google.com', path='', fragment='%ED%B0%80')),",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "9167b58128dbfe3ddcbab253166697348d8d364c",
      "candidate_info": {
        "commit_hash": "9167b58128dbfe3ddcbab253166697348d8d364c",
        "repo": "urllib3/urllib3",
        "commit_url": "https://github.com/urllib3/urllib3/commit/9167b58128dbfe3ddcbab253166697348d8d364c",
        "files": [
          "src/urllib3/util/url.py",
          "test/test_util.py"
        ],
        "message": "Don't percent encode tilde character (#1692)",
        "before_after_code_files": [
          "src/urllib3/util/url.py||src/urllib3/util/url.py",
          "test/test_util.py||test/test_util.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "src/urllib3/util/url.py||src/urllib3/util/url.py",
            "test/test_util.py||test/test_util.py"
          ],
          "candidate": [
            "src/urllib3/util/url.py||src/urllib3/util/url.py",
            "test/test_util.py||test/test_util.py"
          ]
        }
      },
      "candidate_diff": {
        "src/urllib3/util/url.py||src/urllib3/util/url.py": [
          "File: src/urllib3/util/url.py -> src/urllib3/util/url.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "50:     \"(?:(?:%(hex)s:){0,6}%(hex)s)?::\",",
          "51: ]",
          "54: IPV6_PAT = \"(?:\" + \"|\".join([x % _subs for x in _variations]) + \")\"",
          "55: ZONE_ID_PAT = \"(?:%25|%)(?:[\" + UNRESERVED_PAT + \"]|%[a-fA-F0-9]{2})+\"",
          "56: IPV6_ADDRZ_PAT = r\"\\[\" + IPV6_PAT + r\"(?:\" + ZONE_ID_PAT + r\")?\\]\"",
          "",
          "[Removed Lines]",
          "53: UNRESERVED_PAT = r\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789._!\\-\"",
          "",
          "[Added Lines]",
          "53: UNRESERVED_PAT = r\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789._!\\-~\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "63: BRACELESS_IPV6_ADDRZ_RE = re.compile(\"^\" + IPV6_ADDRZ_PAT[2:-2] + \"$\")",
          "64: ZONE_ID_RE = re.compile(\"(\" + ZONE_ID_PAT + r\")\\]$\")",
          "67:     REG_NAME_PAT,",
          "68:     IPV4_PAT,",
          "69:     IPV6_ADDRZ_PAT,",
          "70: )",
          "71: SUBAUTHORITY_RE = re.compile(SUBAUTHORITY_PAT, re.UNICODE | re.DOTALL)",
          "75: )",
          "77: PATH_CHARS = USERINFO_CHARS | {\"@\", \"/\"}",
          "78: QUERY_CHARS = FRAGMENT_CHARS = PATH_CHARS | {\"?\"}",
          "",
          "[Removed Lines]",
          "66: SUBAUTHORITY_PAT = (u\"^(?:(.*)@)?\" u\"(%s|%s|%s)\" u\"(?::([0-9]{0,5}))?$\") % (",
          "73: ZONE_ID_CHARS = set(",
          "74:     \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\" \"abcdefghijklmnopqrstuvwxyz\" \"0123456789._!-\"",
          "76: USERINFO_CHARS = ZONE_ID_CHARS | set(\"$&'()*+,;=:\")",
          "",
          "[Added Lines]",
          "66: SUBAUTHORITY_PAT = (u\"^(?:(.*)@)?(%s|%s|%s)(?::([0-9]{0,5}))?$\") % (",
          "73: UNRESERVED_CHARS = set(",
          "74:     \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789._-~\"",
          "76: SUB_DELIM_CHARS = set(\"!$&'()*+,;=\")",
          "77: USERINFO_CHARS = UNRESERVED_CHARS | SUB_DELIM_CHARS | {\":\"}",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "290:                         zone_id = zone_id[3:]",
          "291:                     else:",
          "292:                         zone_id = zone_id[1:]",
          "294:                     return host[:start].lower() + zone_id + host[end:]",
          "295:                 else:",
          "296:                     return host.lower()",
          "",
          "[Removed Lines]",
          "293:                     zone_id = \"%\" + _encode_invalid_chars(zone_id, ZONE_ID_CHARS)",
          "",
          "[Added Lines]",
          "294:                     zone_id = \"%\" + _encode_invalid_chars(zone_id, UNRESERVED_CHARS)",
          "",
          "---------------"
        ],
        "test/test_util.py||test/test_util.py": [
          "File: test/test_util.py -> test/test_util.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "170:         \"url, expected_normalized_url\",",
          "171:         [",
          "172:             (\"HTTP://GOOGLE.COM/MAIL/\", \"http://google.com/MAIL/\"),",
          "173:             (",
          "174:                 \"HTTP://JeremyCline:Hunter2@Example.com:8080/\",",
          "175:                 \"http://JeremyCline:Hunter2@example.com:8080/\",",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "173:             (",
          "174:                 \"http://user@domain.com:password@example.com/~tilde@?@\",",
          "175:                 \"http://user%40domain.com:password@example.com/~tilde@?@\",",
          "176:             ),",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "5b047b645f5f93900d5e2fc31230848c25eb1f5f",
      "candidate_info": {
        "commit_hash": "5b047b645f5f93900d5e2fc31230848c25eb1f5f",
        "repo": "urllib3/urllib3",
        "commit_url": "https://github.com/urllib3/urllib3/commit/5b047b645f5f93900d5e2fc31230848c25eb1f5f",
        "files": [
          "CHANGES.rst",
          "_travis/upload_coverage.sh",
          "noxfile.py",
          "setup.py",
          "src/urllib3/connectionpool.py",
          "src/urllib3/packages/rfc3986/__init__.py",
          "src/urllib3/packages/rfc3986/_mixin.py",
          "src/urllib3/packages/rfc3986/abnf_regexp.py",
          "src/urllib3/packages/rfc3986/api.py",
          "src/urllib3/packages/rfc3986/builder.py",
          "src/urllib3/packages/rfc3986/compat.py",
          "src/urllib3/packages/rfc3986/exceptions.py",
          "src/urllib3/packages/rfc3986/iri.py",
          "src/urllib3/packages/rfc3986/misc.py",
          "src/urllib3/packages/rfc3986/normalizers.py",
          "src/urllib3/packages/rfc3986/parseresult.py",
          "src/urllib3/packages/rfc3986/uri.py",
          "src/urllib3/packages/rfc3986/validators.py",
          "src/urllib3/packages/six.py",
          "src/urllib3/util/ssl_.py",
          "src/urllib3/util/url.py",
          "test/test_util.py"
        ],
        "message": "Percent-encode invalid characters within auth section (#1647)",
        "before_after_code_files": [
          "_travis/upload_coverage.sh||_travis/upload_coverage.sh",
          "noxfile.py||noxfile.py",
          "setup.py||setup.py",
          "src/urllib3/connectionpool.py||src/urllib3/connectionpool.py",
          "src/urllib3/packages/rfc3986/__init__.py||src/urllib3/packages/rfc3986/__init__.py",
          "src/urllib3/packages/rfc3986/_mixin.py||src/urllib3/packages/rfc3986/_mixin.py",
          "src/urllib3/packages/rfc3986/abnf_regexp.py||src/urllib3/packages/rfc3986/abnf_regexp.py",
          "src/urllib3/packages/rfc3986/api.py||src/urllib3/packages/rfc3986/api.py",
          "src/urllib3/packages/rfc3986/builder.py||src/urllib3/packages/rfc3986/builder.py",
          "src/urllib3/packages/rfc3986/compat.py||src/urllib3/packages/rfc3986/compat.py",
          "src/urllib3/packages/rfc3986/exceptions.py||src/urllib3/packages/rfc3986/exceptions.py",
          "src/urllib3/packages/rfc3986/iri.py||src/urllib3/packages/rfc3986/iri.py",
          "src/urllib3/packages/rfc3986/misc.py||src/urllib3/packages/rfc3986/misc.py",
          "src/urllib3/packages/rfc3986/normalizers.py||src/urllib3/packages/rfc3986/normalizers.py",
          "src/urllib3/packages/rfc3986/parseresult.py||src/urllib3/packages/rfc3986/parseresult.py",
          "src/urllib3/packages/rfc3986/uri.py||src/urllib3/packages/rfc3986/uri.py",
          "src/urllib3/packages/rfc3986/validators.py||src/urllib3/packages/rfc3986/validators.py",
          "src/urllib3/packages/six.py||src/urllib3/packages/six.py",
          "src/urllib3/util/ssl_.py||src/urllib3/util/ssl_.py",
          "src/urllib3/util/url.py||src/urllib3/util/url.py",
          "test/test_util.py||test/test_util.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "src/urllib3/util/url.py||src/urllib3/util/url.py",
            "test/test_util.py||test/test_util.py"
          ],
          "candidate": [
            "src/urllib3/util/url.py||src/urllib3/util/url.py",
            "test/test_util.py||test/test_util.py"
          ]
        }
      },
      "candidate_diff": {
        "_travis/upload_coverage.sh||_travis/upload_coverage.sh": [
          "File: _travis/upload_coverage.sh -> _travis/upload_coverage.sh",
          "--- Hunk 1 ---",
          "[Context before]",
          "3: set -exo pipefail",
          "5: if [[ -e .coverage ]]; then",
          "8: fi",
          "",
          "[Removed Lines]",
          "6:     python3.6 -m pip install codecov",
          "7:     python3.6 -m codecov --env TRAVIS_OS_NAME,NOX_SESSION",
          "",
          "[Added Lines]",
          "6:     python3 -m pip install codecov",
          "7:     python3 -m codecov --env TRAVIS_OS_NAME,NOX_SESSION",
          "",
          "---------------"
        ],
        "noxfile.py||noxfile.py": [
          "File: noxfile.py -> noxfile.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "77:     session.install(\"black\")",
          "78:     session.run(\"black\", \"src\", \"dummyserver\", \"test\", \"noxfile.py\", \"setup.py\")",
          "81: @nox.session",
          "82: def lint(session):",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "80:     lint(session)",
          "",
          "---------------"
        ],
        "setup.py||setup.py": [
          "File: setup.py -> setup.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "57:         \"urllib3.packages\",",
          "58:         \"urllib3.packages.ssl_match_hostname\",",
          "59:         \"urllib3.packages.backports\",",
          "61:         \"urllib3.contrib\",",
          "62:         \"urllib3.contrib._securetransport\",",
          "63:         \"urllib3.util\",",
          "",
          "[Removed Lines]",
          "60:         \"urllib3.packages.rfc3986\",",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "src/urllib3/connectionpool.py||src/urllib3/connectionpool.py": [
          "File: src/urllib3/connectionpool.py -> src/urllib3/connectionpool.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "26: from .packages.ssl_match_hostname import CertificateError",
          "27: from .packages import six",
          "28: from .packages.six.moves import queue",
          "30: from .connection import (",
          "31:     port_by_scheme,",
          "32:     DummyConnection,",
          "",
          "[Removed Lines]",
          "29: from .packages.rfc3986.normalizers import normalize_host",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "44: from .util.response import assert_header_parsing",
          "45: from .util.retry import Retry",
          "46: from .util.timeout import Timeout",
          "48: from .util.queue import LifoQueue",
          "",
          "[Removed Lines]",
          "47: from .util.url import get_host, Url, NORMALIZABLE_SCHEMES",
          "",
          "[Added Lines]",
          "46: from .util.url import get_host, Url, _normalize_host as normalize_host",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "1027:     Normalize hosts for comparisons and use with sockets.",
          "1028:     \"\"\"",
          "1030:     # httplib doesn't like it when we include brackets in IPv6 addresses",
          "1031:     # Specifically, if we include brackets but also pass the port then",
          "1032:     # httplib crazily doubles up the square brackets on the Host header.",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1029:     host = normalize_host(host, scheme)",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "1034:     # However, for backward compatibility reasons we can't actually",
          "1035:     # *assert* that.  See http://bugs.python.org/issue28539",
          "1036:     if host.startswith(\"[\") and host.endswith(\"]\"):",
          "1040:     return host",
          "",
          "[Removed Lines]",
          "1037:         host = host.strip(\"[]\")",
          "1038:     if scheme in NORMALIZABLE_SCHEMES:",
          "1039:         host = normalize_host(host)",
          "",
          "[Added Lines]",
          "1038:         host = host[1:-1]",
          "",
          "---------------"
        ],
        "src/urllib3/packages/rfc3986/__init__.py||src/urllib3/packages/rfc3986/__init__.py": [
          "File: src/urllib3/packages/rfc3986/__init__.py -> src/urllib3/packages/rfc3986/__init__.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "src/urllib3/packages/rfc3986/_mixin.py||src/urllib3/packages/rfc3986/_mixin.py": [
          "File: src/urllib3/packages/rfc3986/_mixin.py -> src/urllib3/packages/rfc3986/_mixin.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "src/urllib3/packages/rfc3986/abnf_regexp.py||src/urllib3/packages/rfc3986/abnf_regexp.py": [
          "File: src/urllib3/packages/rfc3986/abnf_regexp.py -> src/urllib3/packages/rfc3986/abnf_regexp.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "src/urllib3/packages/rfc3986/api.py||src/urllib3/packages/rfc3986/api.py": [
          "File: src/urllib3/packages/rfc3986/api.py -> src/urllib3/packages/rfc3986/api.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "src/urllib3/packages/rfc3986/builder.py||src/urllib3/packages/rfc3986/builder.py": [
          "File: src/urllib3/packages/rfc3986/builder.py -> src/urllib3/packages/rfc3986/builder.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "src/urllib3/packages/rfc3986/compat.py||src/urllib3/packages/rfc3986/compat.py": [
          "File: src/urllib3/packages/rfc3986/compat.py -> src/urllib3/packages/rfc3986/compat.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "src/urllib3/packages/rfc3986/exceptions.py||src/urllib3/packages/rfc3986/exceptions.py": [
          "File: src/urllib3/packages/rfc3986/exceptions.py -> src/urllib3/packages/rfc3986/exceptions.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "src/urllib3/packages/rfc3986/iri.py||src/urllib3/packages/rfc3986/iri.py": [
          "File: src/urllib3/packages/rfc3986/iri.py -> src/urllib3/packages/rfc3986/iri.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "src/urllib3/packages/rfc3986/misc.py||src/urllib3/packages/rfc3986/misc.py": [
          "File: src/urllib3/packages/rfc3986/misc.py -> src/urllib3/packages/rfc3986/misc.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "src/urllib3/packages/rfc3986/normalizers.py||src/urllib3/packages/rfc3986/normalizers.py": [
          "File: src/urllib3/packages/rfc3986/normalizers.py -> src/urllib3/packages/rfc3986/normalizers.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "src/urllib3/packages/rfc3986/parseresult.py||src/urllib3/packages/rfc3986/parseresult.py": [
          "File: src/urllib3/packages/rfc3986/parseresult.py -> src/urllib3/packages/rfc3986/parseresult.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "src/urllib3/packages/rfc3986/uri.py||src/urllib3/packages/rfc3986/uri.py": [
          "File: src/urllib3/packages/rfc3986/uri.py -> src/urllib3/packages/rfc3986/uri.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "src/urllib3/packages/rfc3986/validators.py||src/urllib3/packages/rfc3986/validators.py": [
          "File: src/urllib3/packages/rfc3986/validators.py -> src/urllib3/packages/rfc3986/validators.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------"
        ],
        "src/urllib3/packages/six.py||src/urllib3/packages/six.py": [
          "File: src/urllib3/packages/six.py -> src/urllib3/packages/six.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "4: #",
          "5: # Permission is hereby granted, free of charge, to any person obtaining a copy",
          "6: # of this software and associated documentation files (the \"Software\"), to deal",
          "",
          "[Removed Lines]",
          "1: \"\"\"Utilities for writing code that runs on Python 2 and 3\"\"\"",
          "3: # Copyright (c) 2010-2015 Benjamin Peterson",
          "",
          "[Added Lines]",
          "1: # Copyright (c) 2010-2019 Benjamin Peterson",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "20: # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE",
          "21: # SOFTWARE.",
          "23: from __future__ import absolute_import",
          "25: import functools",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "21: \"\"\"Utilities for writing code that runs on Python 2 and 3\"\"\"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "29: import types",
          "31: __author__ = \"Benjamin Peterson <benjamin@python.org>\"",
          "35: # Useful for very coarse version differentiation.",
          "",
          "[Removed Lines]",
          "32: __version__ = \"1.10.0\"",
          "",
          "[Added Lines]",
          "32: __version__ = \"1.12.0\"",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "242:     MovedAttribute(\"map\", \"itertools\", \"builtins\", \"imap\", \"map\"),",
          "243:     MovedAttribute(\"getcwd\", \"os\", \"os\", \"getcwdu\", \"getcwd\"),",
          "244:     MovedAttribute(\"getcwdb\", \"os\", \"os\", \"getcwd\", \"getcwdb\"),",
          "245:     MovedAttribute(\"range\", \"__builtin__\", \"builtins\", \"xrange\", \"range\"),",
          "246:     MovedAttribute(",
          "247:         \"reload_module\", \"__builtin__\", \"importlib\" if PY34 else \"imp\", \"reload\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "245:     MovedAttribute(\"getoutput\", \"commands\", \"subprocess\"),",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "267:     MovedModule(\"html_entities\", \"htmlentitydefs\", \"html.entities\"),",
          "268:     MovedModule(\"html_parser\", \"HTMLParser\", \"html.parser\"),",
          "269:     MovedModule(\"http_client\", \"httplib\", \"http.client\"),",
          "270:     MovedModule(\"email_mime_multipart\", \"email.MIMEMultipart\", \"email.mime.multipart\"),",
          "271:     MovedModule(",
          "272:         \"email_mime_nonmultipart\", \"email.MIMENonMultipart\", \"email.mime.nonmultipart\"",
          "273:     ),",
          "274:     MovedModule(\"email_mime_text\", \"email.MIMEText\", \"email.mime.text\"),",
          "276:     MovedModule(\"BaseHTTPServer\", \"BaseHTTPServer\", \"http.server\"),",
          "277:     MovedModule(\"CGIHTTPServer\", \"CGIHTTPServer\", \"http.server\"),",
          "278:     MovedModule(\"SimpleHTTPServer\", \"SimpleHTTPServer\", \"http.server\"),",
          "",
          "[Removed Lines]",
          "275:     MovedModule(\"email_mime_base\", \"email.MIMEBase\", \"email.mime.base\"),",
          "",
          "[Added Lines]",
          "271:     MovedModule(\"email_mime_base\", \"email.MIMEBase\", \"email.mime.base\"),",
          "272:     MovedModule(\"email_mime_image\", \"email.MIMEImage\", \"email.mime.image\"),",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "339:     MovedAttribute(\"quote_plus\", \"urllib\", \"urllib.parse\"),",
          "340:     MovedAttribute(\"unquote\", \"urllib\", \"urllib.parse\"),",
          "341:     MovedAttribute(\"unquote_plus\", \"urllib\", \"urllib.parse\"),",
          "342:     MovedAttribute(\"urlencode\", \"urllib\", \"urllib.parse\"),",
          "343:     MovedAttribute(\"splitquery\", \"urllib\", \"urllib.parse\"),",
          "344:     MovedAttribute(\"splittag\", \"urllib\", \"urllib.parse\"),",
          "345:     MovedAttribute(\"splituser\", \"urllib\", \"urllib.parse\"),",
          "346:     MovedAttribute(\"uses_fragment\", \"urlparse\", \"urllib.parse\"),",
          "347:     MovedAttribute(\"uses_netloc\", \"urlparse\", \"urllib.parse\"),",
          "348:     MovedAttribute(\"uses_params\", \"urlparse\", \"urllib.parse\"),",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "344:     MovedAttribute(",
          "345:         \"unquote_to_bytes\", \"urllib\", \"urllib.parse\", \"unquote\", \"unquote_to_bytes\"",
          "346:     ),",
          "351:     MovedAttribute(\"splitvalue\", \"urllib\", \"urllib.parse\"),",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "424:     MovedAttribute(\"URLopener\", \"urllib\", \"urllib.request\"),",
          "425:     MovedAttribute(\"FancyURLopener\", \"urllib\", \"urllib.request\"),",
          "426:     MovedAttribute(\"proxy_bypass\", \"urllib\", \"urllib.request\"),",
          "427: ]",
          "428: for attr in _urllib_request_moved_attributes:",
          "429:     setattr(Module_six_moves_urllib_request, attr.name, attr)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "433:     MovedAttribute(\"parse_http_list\", \"urllib2\", \"urllib.request\"),",
          "434:     MovedAttribute(\"parse_keqv_list\", \"urllib2\", \"urllib.request\"),",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "666:     StringIO = io.StringIO",
          "667:     BytesIO = io.BytesIO",
          "668:     _assertCountEqual = \"assertCountEqual\"",
          "669:     if sys.version_info[1] <= 1:",
          "670:         _assertRaisesRegex = \"assertRaisesRegexp\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "676:     del io",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "718:     exec_ = getattr(moves.builtins, \"exec\")",
          "720:     def reraise(tp, value, tb=None):",
          "728: else:",
          "",
          "[Removed Lines]",
          "721:         if value is None:",
          "722:             value = tp()",
          "723:         if value.__traceback__ is not tb:",
          "724:             raise value.with_traceback(tb)",
          "725:         raise value",
          "",
          "[Added Lines]",
          "730:         try:",
          "731:             if value is None:",
          "732:                 value = tp()",
          "733:             if value.__traceback__ is not tb:",
          "734:                 raise value.with_traceback(tb)",
          "735:             raise value",
          "736:         finally:",
          "737:             value = None",
          "738:             tb = None",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "742:     exec_(",
          "743:         \"\"\"def reraise(tp, value, tb=None):",
          "745: \"\"\"",
          "746:     )",
          "",
          "[Removed Lines]",
          "744:     raise tp, value, tb",
          "",
          "[Added Lines]",
          "757:     try:",
          "758:         raise tp, value, tb",
          "759:     finally:",
          "760:         tb = None",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "749: if sys.version_info[:2] == (3, 2):",
          "750:     exec_(",
          "751:         \"\"\"def raise_from(value, from_value):",
          "755: \"\"\"",
          "756:     )",
          "757: elif sys.version_info[:2] > (3, 2):",
          "758:     exec_(",
          "759:         \"\"\"def raise_from(value, from_value):",
          "761: \"\"\"",
          "762:     )",
          "763: else:",
          "",
          "[Removed Lines]",
          "752:     if from_value is None:",
          "753:         raise value",
          "754:     raise value from from_value",
          "760:     raise value from from_value",
          "",
          "[Added Lines]",
          "768:     try:",
          "769:         if from_value is None:",
          "770:             raise value",
          "771:         raise value from from_value",
          "772:     finally:",
          "773:         value = None",
          "779:     try:",
          "780:         raise value from from_value",
          "781:     finally:",
          "782:         value = None",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "864:     # This requires a bit of explanation: the basic idea is to make a dummy",
          "865:     # metaclass for one level of class instantiation that replaces itself with",
          "866:     # the actual metaclass.",
          "868:         def __new__(cls, name, this_bases, d):",
          "869:             return meta(name, bases, d)",
          "871:     return type.__new__(metaclass, \"temporary_class\", (), {})",
          "",
          "[Removed Lines]",
          "867:     class metaclass(meta):",
          "",
          "[Added Lines]",
          "889:     class metaclass(type):",
          "893:         @classmethod",
          "894:         def __prepare__(cls, name, this_bases):",
          "895:             return meta.__prepare__(name, bases)",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "884:                 orig_vars.pop(slots_var)",
          "885:         orig_vars.pop(\"__dict__\", None)",
          "886:         orig_vars.pop(\"__weakref__\", None)",
          "887:         return metaclass(cls.__name__, cls.__bases__, orig_vars)",
          "889:     return wrapper",
          "892: def python_2_unicode_compatible(klass):",
          "893:     \"\"\"",
          "894:     A decorator that defines __unicode__ and __str__ methods under Python 2.",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "913:         if hasattr(cls, \"__qualname__\"):",
          "914:             orig_vars[\"__qualname__\"] = cls.__qualname__",
          "920: def ensure_binary(s, encoding=\"utf-8\", errors=\"strict\"):",
          "921:     \"\"\"Coerce **s** to six.binary_type.",
          "923:     For Python 2:",
          "924:       - `unicode` -> encoded to `str`",
          "925:       - `str` -> `str`",
          "927:     For Python 3:",
          "928:       - `str` -> encoded to `bytes`",
          "929:       - `bytes` -> `bytes`",
          "930:     \"\"\"",
          "931:     if isinstance(s, text_type):",
          "932:         return s.encode(encoding, errors)",
          "933:     elif isinstance(s, binary_type):",
          "934:         return s",
          "935:     else:",
          "936:         raise TypeError(\"not expecting type '%s'\" % type(s))",
          "939: def ensure_str(s, encoding=\"utf-8\", errors=\"strict\"):",
          "940:     \"\"\"Coerce *s* to `str`.",
          "942:     For Python 2:",
          "943:       - `unicode` -> encoded to `str`",
          "944:       - `str` -> `str`",
          "946:     For Python 3:",
          "947:       - `str` -> `str`",
          "948:       - `bytes` -> decoded to `str`",
          "949:     \"\"\"",
          "950:     if not isinstance(s, (text_type, binary_type)):",
          "951:         raise TypeError(\"not expecting type '%s'\" % type(s))",
          "952:     if PY2 and isinstance(s, text_type):",
          "953:         s = s.encode(encoding, errors)",
          "954:     elif PY3 and isinstance(s, binary_type):",
          "955:         s = s.decode(encoding, errors)",
          "956:     return s",
          "959: def ensure_text(s, encoding=\"utf-8\", errors=\"strict\"):",
          "960:     \"\"\"Coerce *s* to six.text_type.",
          "962:     For Python 2:",
          "963:       - `unicode` -> `unicode`",
          "964:       - `str` -> `unicode`",
          "966:     For Python 3:",
          "967:       - `str` -> `str`",
          "968:       - `bytes` -> decoded to `str`",
          "969:     \"\"\"",
          "970:     if isinstance(s, binary_type):",
          "971:         return s.decode(encoding, errors)",
          "972:     elif isinstance(s, text_type):",
          "973:         return s",
          "974:     else:",
          "975:         raise TypeError(\"not expecting type '%s'\" % type(s))",
          "",
          "---------------"
        ],
        "src/urllib3/util/ssl_.py||src/urllib3/util/ssl_.py": [
          "File: src/urllib3/util/ssl_.py -> src/urllib3/util/ssl_.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "2: import errno",
          "3: import warnings",
          "4: import hmac",
          "7: from binascii import hexlify, unhexlify",
          "8: from hashlib import md5, sha1, sha256",
          "10: from ..exceptions import SSLError, InsecurePlatformWarning, SNIMissingWarning",
          "11: from ..packages import six",
          "15: SSLContext = None",
          "",
          "[Removed Lines]",
          "5: import re",
          "12: from ..packages.rfc3986 import abnf_regexp",
          "",
          "[Added Lines]",
          "9: from .url import IPV4_RE, BRACELESS_IPV6_ADDRZ_RE",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "37: _const_compare_digest = getattr(hmac, \"compare_digest\", _const_compare_digest_backport)",
          "46: try:  # Test for SSL features",
          "47:     import ssl",
          "48:     from ssl import wrap_socket, CERT_REQUIRED",
          "",
          "[Removed Lines]",
          "39: # Borrow rfc3986's regular expressions for IPv4",
          "40: # and IPv6 addresses for use in is_ipaddress()",
          "41: _IP_ADDRESS_REGEX = re.compile(",
          "42:     r\"^(?:%s|%s|%s)$\"",
          "43:     % (abnf_regexp.IPv4_RE, abnf_regexp.IPv6_RE, abnf_regexp.IPv6_ADDRZ_RFC4007_RE)",
          "44: )",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "389:     if six.PY3 and isinstance(hostname, bytes):",
          "390:         # IDN A-label bytes are ASCII compatible.",
          "391:         hostname = hostname.decode(\"ascii\")",
          "395: def _is_key_file_encrypted(key_file):",
          "",
          "[Removed Lines]",
          "392:     return _IP_ADDRESS_REGEX.match(hostname) is not None",
          "",
          "[Added Lines]",
          "384:     return bool(IPV4_RE.match(hostname) or BRACELESS_IPV6_ADDRZ_RE.match(hostname))",
          "",
          "---------------"
        ],
        "src/urllib3/util/url.py||src/urllib3/util/url.py": [
          "File: src/urllib3/util/url.py -> src/urllib3/util/url.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "3: from collections import namedtuple",
          "5: from ..exceptions import LocationParseError",
          "12: url_attrs = [\"scheme\", \"auth\", \"host\", \"port\", \"path\", \"query\", \"fragment\"]",
          "",
          "[Removed Lines]",
          "6: from ..packages import six, rfc3986",
          "7: from ..packages.rfc3986.exceptions import RFC3986Exception, ValidationError",
          "8: from ..packages.rfc3986.validators import Validator",
          "9: from ..packages.rfc3986 import abnf_regexp, normalizers, compat, misc",
          "",
          "[Added Lines]",
          "6: from ..packages import six",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "15: # urllib3 infers URLs without a scheme (None) to be http.",
          "16: NORMALIZABLE_SCHEMES = (\"http\", \"https\", None)",
          "23: )",
          "24: QUERY_CHARS = FRAGMENT_CHARS = PATH_CHARS | {\"?\"}",
          "",
          "[Removed Lines]",
          "18: # Regex for detecting URLs with schemes. RFC 3986 Section 3.1",
          "19: SCHEME_REGEX = re.compile(r\"^(?:[a-zA-Z][a-zA-Z0-9+\\-]*:|/)\")",
          "21: PATH_CHARS = (",
          "22:     abnf_regexp.UNRESERVED_CHARS_SET | abnf_regexp.SUB_DELIMITERS_SET | {\":\", \"@\", \"/\"}",
          "",
          "[Added Lines]",
          "15: # Almost all of these patterns were derived from the",
          "16: # 'rfc3986' module: https://github.com/python-hyper/rfc3986",
          "17: PERCENT_RE = re.compile(r\"%[a-fA-F0-9]{2}\")",
          "18: SCHEME_RE = re.compile(r\"^(?:[a-zA-Z][a-zA-Z0-9+-]*:|/)\")",
          "19: URI_RE = re.compile(",
          "20:     r\"^(?:([a-zA-Z][a-zA-Z0-9+.-]*):)?\"",
          "21:     r\"(?://([^/?#]*))?\"",
          "22:     r\"([^?#]*)\"",
          "23:     r\"(?:\\?([^#]*))?\"",
          "24:     r\"(?:#(.*))?$\",",
          "25:     re.UNICODE | re.DOTALL,",
          "26: )",
          "28: IPV4_PAT = r\"(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\"",
          "29: HEX_PAT = \"[0-9A-Fa-f]{1,4}\"",
          "30: LS32_PAT = \"(?:{hex}:{hex}|{ipv4})\".format(hex=HEX_PAT, ipv4=IPV4_PAT)",
          "31: _subs = {\"hex\": HEX_PAT, \"ls32\": LS32_PAT}",
          "32: _variations = [",
          "33:     #                            6( h16 \":\" ) ls32",
          "34:     \"(?:%(hex)s:){6}%(ls32)s\",",
          "35:     #                       \"::\" 5( h16 \":\" ) ls32",
          "36:     \"::(?:%(hex)s:){5}%(ls32)s\",",
          "37:     # [               h16 ] \"::\" 4( h16 \":\" ) ls32",
          "38:     \"(?:%(hex)s)?::(?:%(hex)s:){4}%(ls32)s\",",
          "39:     # [ *1( h16 \":\" ) h16 ] \"::\" 3( h16 \":\" ) ls32",
          "40:     \"(?:(?:%(hex)s:)?%(hex)s)?::(?:%(hex)s:){3}%(ls32)s\",",
          "41:     # [ *2( h16 \":\" ) h16 ] \"::\" 2( h16 \":\" ) ls32",
          "42:     \"(?:(?:%(hex)s:){0,2}%(hex)s)?::(?:%(hex)s:){2}%(ls32)s\",",
          "43:     # [ *3( h16 \":\" ) h16 ] \"::\"    h16 \":\"   ls32",
          "44:     \"(?:(?:%(hex)s:){0,3}%(hex)s)?::%(hex)s:%(ls32)s\",",
          "45:     # [ *4( h16 \":\" ) h16 ] \"::\"              ls32",
          "46:     \"(?:(?:%(hex)s:){0,4}%(hex)s)?::%(ls32)s\",",
          "47:     # [ *5( h16 \":\" ) h16 ] \"::\"              h16",
          "48:     \"(?:(?:%(hex)s:){0,5}%(hex)s)?::%(hex)s\",",
          "49:     # [ *6( h16 \":\" ) h16 ] \"::\"",
          "50:     \"(?:(?:%(hex)s:){0,6}%(hex)s)?::\",",
          "51: ]",
          "53: UNRESERVED_PAT = r\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789._!\\-\"",
          "54: IPV6_PAT = \"(?:\" + \"|\".join([x % _subs for x in _variations]) + \")\"",
          "55: ZONE_ID_PAT = \"(?:%25|%)(?:[\" + UNRESERVED_PAT + \"]|%[a-fA-F0-9]{2})+\"",
          "56: IPV6_ADDRZ_PAT = r\"\\[\" + IPV6_PAT + r\"(?:\" + ZONE_ID_PAT + r\")?\\]\"",
          "57: REG_NAME_PAT = r\"(?:[^\\[\\]%:/?#]|%[a-fA-F0-9]{2})*\"",
          "59: IPV4_RE = re.compile(\"^\" + IPV4_PAT + \"$\")",
          "60: IPV6_RE = re.compile(\"^\" + IPV6_PAT + \"$\")",
          "61: IPV6_ADDRZ_RE = re.compile(\"^\" + IPV6_ADDRZ_PAT + \"$\")",
          "62: BRACELESS_IPV6_ADDRZ_RE = re.compile(\"^\" + IPV6_ADDRZ_PAT[2:-2] + \"$\")",
          "63: ZONE_ID_RE = re.compile(\"(\" + ZONE_ID_PAT + r\")\\]$\")",
          "65: SUBAUTHORITY_PAT = (u\"^(?:(.*)@)?\" u\"(%s|%s|%s)\" u\"(?::([0-9]{0,5}))?$\") % (",
          "66:     REG_NAME_PAT,",
          "67:     IPV4_PAT,",
          "68:     IPV6_ADDRZ_PAT,",
          "69: )",
          "70: SUBAUTHORITY_RE = re.compile(SUBAUTHORITY_PAT, re.UNICODE | re.DOTALL)",
          "72: ZONE_ID_CHARS = set(",
          "73:     \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\" \"abcdefghijklmnopqrstuvwxyz\" \"0123456789._!-\"",
          "75: USERINFO_CHARS = ZONE_ID_CHARS | set(\"$&'()*+,;=:\")",
          "76: PATH_CHARS = USERINFO_CHARS | {\"@\", \"/\"}",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "155: def _encode_invalid_chars(component, allowed_chars, encoding=\"utf-8\"):",
          "156:     \"\"\"Percent-encodes a URI component without reapplying",
          "159:     \"\"\"",
          "160:     if component is None:",
          "161:         return component",
          "163:     # Try to see if the component we're encoding is already percent-encoded",
          "164:     # so we can skip all '%' characters but still encode all others.",
          "169:     uri_bytes = component.encode(\"utf-8\", \"surrogatepass\")",
          "172:     encoded_component = bytearray()",
          "",
          "[Removed Lines]",
          "157:     onto an already percent-encoded component. Based on",
          "158:     rfc3986.normalizers.encode_component()",
          "165:     percent_encodings = len(",
          "166:         normalizers.PERCENT_MATCHER.findall(compat.to_str(component, encoding))",
          "167:     )",
          "170:     is_percent_encoded = percent_encodings == uri_bytes.count(b\"%\")",
          "",
          "[Added Lines]",
          "210:     onto an already percent-encoded component.",
          "215:     component = six.ensure_text(component)",
          "219:     percent_encodings = PERCENT_RE.findall(component)",
          "221:     # Normalize existing percent-encoded bytes.",
          "222:     for enc in percent_encodings:",
          "223:         if not enc.isupper():",
          "224:             component = component.replace(enc, enc.upper())",
          "227:     is_percent_encoded = len(percent_encodings) == uri_bytes.count(b\"%\")",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "180:         ):",
          "181:             encoded_component.extend(byte)",
          "182:             continue",
          "185:     return encoded_component.decode(encoding)",
          "188: def parse_url(url):",
          "189:     \"\"\"",
          "190:     Given a url, return a parsed :class:`.Url` namedtuple. Best-effort is",
          "191:     performed to parse incomplete urls. Fields not provided will be None.",
          "192:     This parser is RFC 3986 compliant.",
          "194:     :param str url: URL to parse into a :class:`.Url` namedtuple.",
          "196:     Partly backwards-compatible with :mod:`urlparse`.",
          "",
          "[Removed Lines]",
          "183:         encoded_component.extend(\"%{0:02x}\".format(byte_ord).encode().upper())",
          "",
          "[Added Lines]",
          "240:         encoded_component.extend(b\"%\" + (hex(byte_ord)[2:].encode().zfill(2).upper()))",
          "245: def _remove_path_dot_segments(path):",
          "246:     # See http://tools.ietf.org/html/rfc3986#section-5.2.4 for pseudo-code",
          "247:     segments = path.split(\"/\")  # Turn the path into a list of segments",
          "248:     output = []  # Initialize the variable to use to store output",
          "250:     for segment in segments:",
          "251:         # '.' is the current directory, so ignore it, it is superfluous",
          "252:         if segment == \".\":",
          "253:             continue",
          "254:         # Anything other than '..', should be appended to the output",
          "255:         elif segment != \"..\":",
          "256:             output.append(segment)",
          "257:         # In this case segment == '..', if we can, we should pop the last",
          "258:         # element",
          "259:         elif output:",
          "260:             output.pop()",
          "262:     # If the path starts with '/' and the output is empty or the first string",
          "263:     # is non-empty",
          "264:     if path.startswith(\"/\") and (not output or output[0]):",
          "265:         output.insert(0, \"\")",
          "267:     # If the path starts with '/.' or '/..' ensure we add one more empty",
          "268:     # string to add a trailing '/'",
          "269:     if path.endswith((\"/.\", \"/..\")):",
          "270:         output.append(\"\")",
          "272:     return \"/\".join(output)",
          "275: def _normalize_host(host, scheme):",
          "276:     if host:",
          "277:         if isinstance(host, six.binary_type):",
          "278:             host = six.ensure_str(host)",
          "280:         if scheme in NORMALIZABLE_SCHEMES:",
          "281:             is_ipv6 = IPV6_ADDRZ_RE.match(host)",
          "282:             if is_ipv6:",
          "283:                 match = ZONE_ID_RE.search(host)",
          "284:                 if match:",
          "285:                     start, end = match.span(1)",
          "286:                     zone_id = host[start:end]",
          "288:                     if zone_id.startswith(\"%25\") and zone_id != \"%25\":",
          "289:                         zone_id = zone_id[3:]",
          "290:                     else:",
          "291:                         zone_id = zone_id[1:]",
          "292:                     zone_id = \"%\" + _encode_invalid_chars(zone_id, ZONE_ID_CHARS)",
          "293:                     return host[:start].lower() + zone_id + host[end:]",
          "294:                 else:",
          "295:                     return host.lower()",
          "296:             elif not IPV4_RE.match(host):",
          "297:                 return six.ensure_str(",
          "298:                     b\".\".join([_idna_encode(label) for label in host.split(\".\")])",
          "299:                 )",
          "300:     return host",
          "303: def _idna_encode(name):",
          "304:     if name and any([ord(x) > 128 for x in name]):",
          "305:         try:",
          "306:             import idna",
          "307:         except ImportError:",
          "308:             six.raise_from(",
          "309:                 LocationParseError(\"Unable to parse URL without the 'idna' module\"),",
          "310:                 None,",
          "311:             )",
          "312:         try:",
          "313:             return idna.encode(name.lower(), strict=True, std3_rules=True)",
          "314:         except idna.IDNAError:",
          "315:             six.raise_from(",
          "316:                 LocationParseError(u\"Name '%s' is not a valid IDNA label\" % name), None",
          "317:             )",
          "318:     return name.lower().encode(\"ascii\")",
          "327:     The parser logic and helper functions are based heavily on",
          "328:     work done in the ``rfc3986`` module.",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "208:         # Empty",
          "209:         return Url()",
          "219:         url = \"//\" + url",
          "262:     try:",
          "267:     # For the sake of backwards compatibility we put empty",
          "268:     # string values for path if there are any defined values",
          "269:     # beyond the path in the URL.",
          "270:     # TODO: Remove this when we break backwards compatibility.",
          "272:     if not path:",
          "274:             path = \"\"",
          "275:         else:",
          "276:             path = None",
          "278:     # Ensure that each part of the URL is a `str` for",
          "279:     # backwards compatibility.",
          "287:     return Url(",
          "295:     )",
          "",
          "[Removed Lines]",
          "211:     is_string = not isinstance(url, six.binary_type)",
          "213:     # RFC 3986 doesn't like URLs that have a host but don't start",
          "214:     # with a scheme and we support URLs like that so we need to",
          "215:     # detect that problem and add an empty scheme indication.",
          "216:     # We don't get hurt on path-only URLs here as it's stripped",
          "217:     # off and given an empty scheme anyways.",
          "218:     if not SCHEME_REGEX.search(url):",
          "221:     def idna_encode(name):",
          "222:         if name and any([ord(x) > 128 for x in name]):",
          "223:             try:",
          "224:                 import idna",
          "225:             except ImportError:",
          "226:                 raise LocationParseError(",
          "227:                     \"Unable to parse URL without the 'idna' module\"",
          "228:                 )",
          "229:             try:",
          "230:                 return idna.encode(name.lower(), strict=True, std3_rules=True)",
          "231:             except idna.IDNAError:",
          "232:                 raise LocationParseError(u\"Name '%s' is not a valid IDNA label\" % name)",
          "233:         return name",
          "235:     try:",
          "236:         split_iri = misc.IRI_MATCHER.match(compat.to_str(url)).groupdict()",
          "237:         iri_ref = rfc3986.IRIReference(",
          "238:             split_iri[\"scheme\"],",
          "239:             split_iri[\"authority\"],",
          "240:             _encode_invalid_chars(split_iri[\"path\"], PATH_CHARS),",
          "241:             _encode_invalid_chars(split_iri[\"query\"], QUERY_CHARS),",
          "242:             _encode_invalid_chars(split_iri[\"fragment\"], FRAGMENT_CHARS),",
          "243:         )",
          "244:         has_authority = iri_ref.authority is not None",
          "245:         uri_ref = iri_ref.encode(idna_encoder=idna_encode)",
          "246:     except (ValueError, RFC3986Exception):",
          "247:         return six.raise_from(LocationParseError(url), None)",
          "249:     # rfc3986 strips the authority if it's invalid",
          "250:     if has_authority and uri_ref.authority is None:",
          "251:         raise LocationParseError(url)",
          "253:     # Only normalize schemes we understand to not break http+unix",
          "254:     # or other schemes that don't follow RFC 3986.",
          "255:     if uri_ref.scheme is None or uri_ref.scheme.lower() in NORMALIZABLE_SCHEMES:",
          "256:         uri_ref = uri_ref.normalize()",
          "258:     # Validate all URIReference components and ensure that all",
          "259:     # components that were set before are still set after",
          "260:     # normalization has completed.",
          "261:     validator = Validator()",
          "263:         validator.check_validity_of(*validator.COMPONENT_NAMES).validate(uri_ref)",
          "264:     except ValidationError:",
          "265:         return six.raise_from(LocationParseError(url), None)",
          "271:     path = uri_ref.path",
          "273:         if uri_ref.query is not None or uri_ref.fragment is not None:",
          "280:     def to_input_type(x):",
          "281:         if x is None:",
          "282:             return None",
          "283:         elif not is_string and not isinstance(x, six.binary_type):",
          "284:             return x.encode(\"utf-8\")",
          "285:         return x",
          "288:         scheme=to_input_type(uri_ref.scheme),",
          "289:         auth=to_input_type(uri_ref.userinfo),",
          "290:         host=to_input_type(uri_ref.host),",
          "291:         port=int(uri_ref.port) if uri_ref.port is not None else None,",
          "292:         path=to_input_type(path),",
          "293:         query=to_input_type(uri_ref.query),",
          "294:         fragment=to_input_type(uri_ref.fragment),",
          "",
          "[Added Lines]",
          "347:     source_url = url",
          "348:     if not SCHEME_RE.search(url):",
          "352:         scheme, authority, path, query, fragment = URI_RE.match(url).groups()",
          "353:         normalize_uri = scheme is None or scheme.lower() in NORMALIZABLE_SCHEMES",
          "355:         if scheme:",
          "356:             scheme = scheme.lower()",
          "358:         if authority:",
          "359:             auth, host, port = SUBAUTHORITY_RE.match(authority).groups()",
          "360:             if auth and normalize_uri:",
          "361:                 auth = _encode_invalid_chars(auth, USERINFO_CHARS)",
          "362:             if port == \"\":",
          "363:                 port = None",
          "364:         else:",
          "365:             auth, host, port = None, None, None",
          "367:         if port is not None:",
          "368:             port = int(port)",
          "369:             if not (0 <= port <= 65535):",
          "370:                 raise LocationParseError(url)",
          "372:         host = _normalize_host(host, scheme)",
          "374:         if normalize_uri and path:",
          "375:             path = _remove_path_dot_segments(path)",
          "376:             path = _encode_invalid_chars(path, PATH_CHARS)",
          "377:         if normalize_uri and query:",
          "378:             query = _encode_invalid_chars(query, QUERY_CHARS)",
          "379:         if normalize_uri and fragment:",
          "380:             fragment = _encode_invalid_chars(fragment, FRAGMENT_CHARS)",
          "382:     except (ValueError, AttributeError):",
          "383:         return six.raise_from(LocationParseError(source_url), None)",
          "390:         if query is not None or fragment is not None:",
          "397:     if isinstance(url, six.text_type):",
          "398:         ensure_func = six.ensure_text",
          "399:     else:",
          "400:         ensure_func = six.ensure_str",
          "402:     def ensure_type(x):",
          "403:         return x if x is None else ensure_func(x)",
          "406:         scheme=ensure_type(scheme),",
          "407:         auth=ensure_type(auth),",
          "408:         host=ensure_type(host),",
          "409:         port=port,",
          "410:         path=ensure_type(path),",
          "411:         query=ensure_type(query),",
          "412:         fragment=ensure_type(fragment),",
          "",
          "---------------"
        ],
        "test/test_util.py||test/test_util.py": [
          "File: test/test_util.py -> test/test_util.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "154:     @pytest.mark.parametrize(",
          "155:         \"url\",",
          "156:         [",
          "161:             # Invalid IDNA labels",
          "162:             u\"http://\\uD7FF.com\",",
          "163:             u\"http://\u2764\ufe0f\",",
          "",
          "[Removed Lines]",
          "157:             \"http://user\\\\@google.com\",",
          "158:             \"http://google\\\\.com\",",
          "159:             \"user\\\\@google.com\",",
          "160:             \"http://user@user@google.com/\",",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "180:             ),",
          "181:             (\"HTTPS://Example.Com/?Key=Value\", \"https://example.com/?Key=Value\"),",
          "182:             (\"Https://Example.Com/#Fragment\", \"https://example.com/#Fragment\"),",
          "184:             # Invalid characters for the query/fragment getting encoded",
          "185:             (",
          "186:                 'http://google.com/p[]?parameter[]=\"hello\"#fragment#',",
          "",
          "[Removed Lines]",
          "183:             (\"[::Ff%etH0%Ff]/%ab%Af\", \"[::ff%25etH0%Ff]/%AB%AF\"),",
          "",
          "[Added Lines]",
          "179:             (\"[::1%25]\", \"[::1%25]\"),",
          "180:             (\"[::Ff%etH0%Ff]/%ab%Af\", \"[::ff%etH0%FF]/%AB%AF\"),",
          "181:             (",
          "182:                 \"http://user:pass@[AaAa::Ff%25etH0%Ff]/%ab%Af\",",
          "183:                 \"http://user:pass@[aaaa::ff%etH0%FF]/%AB%AF\",",
          "184:             ),",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "199:         actual_normalized_url = parse_url(url).url",
          "200:         assert actual_normalized_url == expected_normalized_url",
          "202:     parse_url_host_map = [",
          "203:         (\"http://google.com/mail\", Url(\"http\", host=\"google.com\", path=\"/mail\")),",
          "204:         (\"http://google.com/mail/\", Url(\"http\", host=\"google.com\", path=\"/mail/\")),",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "203:     @pytest.mark.parametrize(\"char\", [chr(i) for i in range(0x00, 0x21)] + [\"\\x7F\"])",
          "204:     def test_control_characters_are_percent_encoded(self, char):",
          "205:         percent_char = \"%\" + (hex(ord(char))[2:].zfill(2).upper())",
          "206:         url = parse_url(",
          "207:             \"http://user{0}@example.com/path{0}?query{0}#fragment{0}\".format(char)",
          "208:         )",
          "210:         assert url == Url(",
          "211:             \"http\",",
          "212:             auth=\"user\" + percent_char,",
          "213:             host=\"example.com\",",
          "214:             path=\"/path\" + percent_char,",
          "215:             query=\"query\" + percent_char,",
          "216:             fragment=\"fragment\" + percent_char,",
          "217:         )",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "260:             u\"http://K\u00f6nigsg\u00e4\u00dfchen.de/stra\u00dfe\",",
          "261:             Url(\"http\", host=\"xn--knigsgchen-b4a3dun.de\", path=\"/stra%C3%9Fe\"),",
          "262:         ),",
          "263:         # Unicode Surrogates",
          "264:         (u\"http://google.com/\\uD800\", Url(\"http\", host=\"google.com\", path=\"%ED%A0%80\")),",
          "265:         (",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "280:         # Percent-encode in userinfo",
          "281:         (",
          "282:             u\"http://user@email.com:password@example.com/\",",
          "283:             Url(\"http\", auth=\"user%40email.com:password\", host=\"example.com\", path=\"/\"),",
          "284:         ),",
          "285:         (",
          "286:             u'http://user\":quoted@example.com/',",
          "287:             Url(\"http\", auth=\"user%22:quoted\", host=\"example.com\", path=\"/\"),",
          "288:         ),",
          "",
          "---------------"
        ]
      }
    }
  ]
}