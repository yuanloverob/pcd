{
  "cve_id": "CVE-2024-8060",
  "cve_desc": "OpenWebUI version 0.3.0 contains a vulnerability in the audio API endpoint `/audio/api/v1/transcriptions` that allows for arbitrary file upload. The application performs insufficient validation on the `file.content_type` and allows user-controlled filenames, leading to a path traversal vulnerability. This can be exploited by an authenticated user to overwrite critical files within the Docker container, potentially leading to remote code execution as the root user.",
  "repo": "open-webui/open-webui",
  "patch_hash": "613a087387c094e71ee91d29c015195ef401e160",
  "patch_info": {
    "commit_hash": "613a087387c094e71ee91d29c015195ef401e160",
    "repo": "open-webui/open-webui",
    "commit_url": "https://github.com/open-webui/open-webui/commit/613a087387c094e71ee91d29c015195ef401e160",
    "files": [
      "backend/open_webui/routers/audio.py"
    ],
    "message": "refac",
    "before_after_code_files": [
      "backend/open_webui/routers/audio.py||backend/open_webui/routers/audio.py"
    ]
  },
  "patch_diff": {
    "backend/open_webui/routers/audio.py||backend/open_webui/routers/audio.py": [
      "File: backend/open_webui/routers/audio.py -> backend/open_webui/routers/audio.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "681:     available_models = []",
      "682:     if request.app.state.config.TTS_ENGINE == \"openai\":",
      "683:         # Use custom endpoint if not using the official OpenAI API URL",
      "685:             try:",
      "687:                 response.raise_for_status()",
      "688:                 data = response.json()",
      "689:                 available_models = data.get(\"models\", [])",
      "690:             except Exception as e:",
      "691:                 log.error(f\"Error fetching models from custom endpoint: {str(e)}\")",
      "693:         else:",
      "694:             available_models = [{\"id\": \"tts-1\"}, {\"id\": \"tts-1-hd\"}]",
      "695:     elif request.app.state.config.TTS_ENGINE == \"elevenlabs\":",
      "",
      "[Removed Lines]",
      "684:         if not request.app.state.config.TTS_OPENAI_API_BASE_URL.startswith(\"https://api.openai.com\"):",
      "686:                 response = requests.get(f\"{request.app.state.config.TTS_OPENAI_API_BASE_URL}/audio/models\")",
      "692:                 available_models = []",
      "",
      "[Added Lines]",
      "684:         if not request.app.state.config.TTS_OPENAI_API_BASE_URL.startswith(",
      "685:             \"https://api.openai.com\"",
      "686:         ):",
      "688:                 response = requests.get(",
      "689:                     f\"{request.app.state.config.TTS_OPENAI_API_BASE_URL}/audio/models\"",
      "690:                 )",
      "696:                 available_models = [{\"id\": \"tts-1\"}, {\"id\": \"tts-1-hd\"}]",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "723:     available_voices = {}",
      "724:     if request.app.state.config.TTS_ENGINE == \"openai\":",
      "725:         # Use custom endpoint if not using the official OpenAI API URL",
      "727:             try:",
      "729:                 response.raise_for_status()",
      "730:                 data = response.json()",
      "731:                 voices_list = data.get(\"voices\", [])",
      "732:                 available_voices = {voice[\"id\"]: voice[\"name\"] for voice in voices_list}",
      "733:             except Exception as e:",
      "734:                 log.error(f\"Error fetching voices from custom endpoint: {str(e)}\")",
      "736:         else:",
      "737:             available_voices = {",
      "738:                 \"alloy\": \"alloy\",",
      "",
      "[Removed Lines]",
      "726:         if not request.app.state.config.TTS_OPENAI_API_BASE_URL.startswith(\"https://api.openai.com\"):",
      "728:                 response = requests.get(f\"{request.app.state.config.TTS_OPENAI_API_BASE_URL}/audio/voices\")",
      "735:                 available_voices = {}",
      "",
      "[Added Lines]",
      "730:         if not request.app.state.config.TTS_OPENAI_API_BASE_URL.startswith(",
      "731:             \"https://api.openai.com\"",
      "732:         ):",
      "734:                 response = requests.get(",
      "735:                     f\"{request.app.state.config.TTS_OPENAI_API_BASE_URL}/audio/voices\"",
      "736:                 )",
      "743:                 available_voices = {",
      "744:                     \"alloy\": \"alloy\",",
      "745:                     \"echo\": \"echo\",",
      "746:                     \"fable\": \"fable\",",
      "747:                     \"onyx\": \"onyx\",",
      "748:                     \"nova\": \"nova\",",
      "749:                     \"shimmer\": \"shimmer\",",
      "750:                 }",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "a4132322d94b77498b767f5c6ff159bb95083e98",
      "candidate_info": {
        "commit_hash": "a4132322d94b77498b767f5c6ff159bb95083e98",
        "repo": "open-webui/open-webui",
        "commit_url": "https://github.com/open-webui/open-webui/commit/a4132322d94b77498b767f5c6ff159bb95083e98",
        "files": [
          "backend/open_webui/env.py"
        ],
        "message": "refac",
        "before_after_code_files": [
          "backend/open_webui/env.py||backend/open_webui/env.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_message": 1,
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "backend/open_webui/env.py||backend/open_webui/env.py": [
          "File: backend/open_webui/env.py -> backend/open_webui/env.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "53: else:",
          "54:     DEVICE_TYPE = \"cpu\"",
          "60: ####################################",
          "61: # LOGGING",
          "",
          "[Removed Lines]",
          "57: if torch.backends.mps.is_available() and torch.backends.mps.is_built():",
          "58:     DEVICE_TYPE = \"mps\"",
          "",
          "[Added Lines]",
          "56: try:",
          "57:     if torch.backends.mps.is_available() and torch.backends.mps.is_built():",
          "58:         DEVICE_TYPE = \"mps\"",
          "59: except Exception:",
          "60:     pass",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "cafc5413f58596a340b090896463e07109ecb0b7",
      "candidate_info": {
        "commit_hash": "cafc5413f58596a340b090896463e07109ecb0b7",
        "repo": "open-webui/open-webui",
        "commit_url": "https://github.com/open-webui/open-webui/commit/cafc5413f58596a340b090896463e07109ecb0b7",
        "files": [
          "backend/open_webui/retrieval/utils.py",
          "backend/open_webui/routers/memories.py",
          "backend/open_webui/routers/retrieval.py"
        ],
        "message": "refac",
        "before_after_code_files": [
          "backend/open_webui/retrieval/utils.py||backend/open_webui/retrieval/utils.py",
          "backend/open_webui/routers/memories.py||backend/open_webui/routers/memories.py",
          "backend/open_webui/routers/retrieval.py||backend/open_webui/routers/retrieval.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_message": 1,
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "backend/open_webui/retrieval/utils.py||backend/open_webui/retrieval/utils.py": [
          "File: backend/open_webui/retrieval/utils.py -> backend/open_webui/retrieval/utils.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "256: ) -> dict:",
          "257:     results = []",
          "258:     for query in queries:",
          "260:         for collection_name in collection_names:",
          "261:             if collection_name:",
          "262:                 try:",
          "",
          "[Removed Lines]",
          "259:         query_embedding = embedding_function(query, RAG_EMBEDDING_QUERY_PREFIX)",
          "",
          "[Added Lines]",
          "259:         query_embedding = embedding_function(query, prefix=RAG_EMBEDDING_QUERY_PREFIX)",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "334:     embedding_batch_size,",
          "335: ):",
          "336:     if embedding_engine == \"\":",
          "338:             query, prompt=prefix if prefix else None",
          "339:         ).tolist()",
          "340:     elif embedding_engine in [\"ollama\", \"openai\"]:",
          "342:             engine=embedding_engine,",
          "343:             model=embedding_model,",
          "344:             text=query,",
          "",
          "[Removed Lines]",
          "337:         return lambda query, prefix, user=None: embedding_function.encode(",
          "341:         func = lambda query, prefix, user=None: generate_embeddings(",
          "",
          "[Added Lines]",
          "337:         return lambda query, prefix=None, user=None: embedding_function.encode(",
          "341:         func = lambda query, prefix=None, user=None: generate_embeddings(",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "363:             else:",
          "364:                 return func(query, prefix, user)",
          "367:             query, prefix, user, func",
          "368:         )",
          "369:     else:",
          "",
          "[Removed Lines]",
          "366:         return lambda query, prefix, user=None: generate_multiple(",
          "",
          "[Added Lines]",
          "366:         return lambda query, prefix=None, user=None: generate_multiple(",
          "",
          "---------------"
        ],
        "backend/open_webui/routers/memories.py||backend/open_webui/routers/memories.py": [
          "File: backend/open_webui/routers/memories.py -> backend/open_webui/routers/memories.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "57:             {",
          "58:                 \"id\": memory.id,",
          "59:                 \"text\": memory.content,",
          "61:                 \"metadata\": {\"created_at\": memory.created_at},",
          "62:             }",
          "63:         ],",
          "",
          "[Removed Lines]",
          "60:                 \"vector\": request.app.state.EMBEDDING_FUNCTION(memory.content, user),",
          "",
          "[Added Lines]",
          "60:                 \"vector\": request.app.state.EMBEDDING_FUNCTION(",
          "61:                     memory.content, user=user",
          "62:                 ),",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "82: ):",
          "83:     results = VECTOR_DB_CLIENT.search(",
          "84:         collection_name=f\"user-memory-{user.id}\",",
          "86:         limit=form_data.k,",
          "87:     )",
          "",
          "[Removed Lines]",
          "85:         vectors=[request.app.state.EMBEDDING_FUNCTION(form_data.content, user)],",
          "",
          "[Added Lines]",
          "87:         vectors=[request.app.state.EMBEDDING_FUNCTION(form_data.content, user=user)],",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "105:             {",
          "106:                 \"id\": memory.id,",
          "107:                 \"text\": memory.content,",
          "109:                 \"metadata\": {",
          "110:                     \"created_at\": memory.created_at,",
          "111:                     \"updated_at\": memory.updated_at,",
          "",
          "[Removed Lines]",
          "108:                 \"vector\": request.app.state.EMBEDDING_FUNCTION(memory.content, user),",
          "",
          "[Added Lines]",
          "110:                 \"vector\": request.app.state.EMBEDDING_FUNCTION(",
          "111:                     memory.content, user=user",
          "112:                 ),",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "161:                     \"id\": memory.id,",
          "162:                     \"text\": memory.content,",
          "163:                     \"vector\": request.app.state.EMBEDDING_FUNCTION(",
          "165:                     ),",
          "166:                     \"metadata\": {",
          "167:                         \"created_at\": memory.created_at,",
          "",
          "[Removed Lines]",
          "164:                         memory.content, user",
          "",
          "[Added Lines]",
          "168:                         memory.content, user=user",
          "",
          "---------------"
        ],
        "backend/open_webui/routers/retrieval.py||backend/open_webui/routers/retrieval.py": [
          "File: backend/open_webui/routers/retrieval.py -> backend/open_webui/routers/retrieval.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1518:             return query_doc_with_hybrid_search(",
          "1519:                 collection_name=form_data.collection_name,",
          "1520:                 query=form_data.query,",
          "1523:                 ),",
          "1524:                 k=form_data.k if form_data.k else request.app.state.config.TOP_K,",
          "1525:                 reranking_function=request.app.state.rf,",
          "",
          "[Removed Lines]",
          "1521:                 embedding_function=lambda query: request.app.state.EMBEDDING_FUNCTION(",
          "1522:                     query, user=user",
          "",
          "[Added Lines]",
          "1521:                 embedding_function=lambda query, prefix: request.app.state.EMBEDDING_FUNCTION(",
          "1522:                     query, prefix=prefix, user=user",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1569:             return query_collection_with_hybrid_search(",
          "1570:                 collection_names=form_data.collection_names,",
          "1571:                 queries=[form_data.query],",
          "1574:                 ),",
          "1575:                 k=form_data.k if form_data.k else request.app.state.config.TOP_K,",
          "1576:                 reranking_function=request.app.state.rf,",
          "",
          "[Removed Lines]",
          "1572:                 embedding_function=lambda query: request.app.state.EMBEDDING_FUNCTION(",
          "1573:                     query, user=user",
          "",
          "[Added Lines]",
          "1572:                 embedding_function=lambda query, prefix: request.app.state.EMBEDDING_FUNCTION(",
          "1573:                     query, prefix=prefix, user=user",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "1586:             return query_collection(",
          "1587:                 collection_names=form_data.collection_names,",
          "1588:                 queries=[form_data.query],",
          "1591:                 ),",
          "1592:                 k=form_data.k if form_data.k else request.app.state.config.TOP_K,",
          "1593:             )",
          "",
          "[Removed Lines]",
          "1589:                 embedding_function=lambda query: request.app.state.EMBEDDING_FUNCTION(",
          "1590:                     query, user=user",
          "",
          "[Added Lines]",
          "1589:                 embedding_function=lambda query, prefix: request.app.state.EMBEDDING_FUNCTION(",
          "1590:                     query, prefix=prefix, user=user",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "1666:     async def get_embeddings(request: Request, text: Optional[str] = \"Hello World!\"):",
          "1667:         return {",
          "1668:             \"result\": request.app.state.EMBEDDING_FUNCTION(",
          "1670:             )",
          "1671:         }",
          "",
          "[Removed Lines]",
          "1669:                 text, RAG_EMBEDDING_QUERY_PREFIX",
          "",
          "[Added Lines]",
          "1669:                 text, prefix=RAG_EMBEDDING_QUERY_PREFIX",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "d9f17225ef4de48009eed6c010afb0d627afd0cb",
      "candidate_info": {
        "commit_hash": "d9f17225ef4de48009eed6c010afb0d627afd0cb",
        "repo": "open-webui/open-webui",
        "commit_url": "https://github.com/open-webui/open-webui/commit/d9f17225ef4de48009eed6c010afb0d627afd0cb",
        "files": [
          "backend/open_webui/utils/middleware.py"
        ],
        "message": "refac",
        "before_after_code_files": [
          "backend/open_webui/utils/middleware.py||backend/open_webui/utils/middleware.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_message": 1,
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "backend/open_webui/utils/middleware.py||backend/open_webui/utils/middleware.py": [
          "File: backend/open_webui/utils/middleware.py -> backend/open_webui/utils/middleware.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1173:                         reasoning_duration = block.get(\"duration\", None)",
          "1176:                             if raw:",
          "1177:                                 content = f'{content}\\n<{block[\"tag\"]}>{block[\"content\"]}</{block[\"tag\"]}>\\n'",
          "1178:                             else:",
          "",
          "[Removed Lines]",
          "1175:                         if reasoning_duration:",
          "",
          "[Added Lines]",
          "1175:                         if reasoning_duration is not None:",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1315:                                             \"content\": leftover_content,",
          "1316:                                         }",
          "1317:                                     )",
          "1318:                         else:",
          "1319:                             # Remove the block if content is empty",
          "1320:                             content_blocks.pop()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1318:                                 else:",
          "1319:                                     content_blocks.append(",
          "1320:                                         {",
          "1321:                                             \"type\": \"text\",",
          "1322:                                             \"content\": \"\",",
          "1323:                                         }",
          "1324:                                     )",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "1326:                                         \"content\": leftover_content,",
          "1327:                                     }",
          "1328:                                 )",
          "1330:                         # Clean processed content",
          "1331:                         content = re.sub(",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1337:                             else:",
          "1338:                                 content_blocks.append(",
          "1339:                                     {",
          "1340:                                         \"type\": \"text\",",
          "1341:                                         \"content\": \"\",",
          "1342:                                     }",
          "1343:                                 )",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "e349e26cd893e59303689ed4f7c5fd4ebe2dcb21",
      "candidate_info": {
        "commit_hash": "e349e26cd893e59303689ed4f7c5fd4ebe2dcb21",
        "repo": "open-webui/open-webui",
        "commit_url": "https://github.com/open-webui/open-webui/commit/e349e26cd893e59303689ed4f7c5fd4ebe2dcb21",
        "files": [
          "backend/open_webui/utils/middleware.py"
        ],
        "message": "refac",
        "before_after_code_files": [
          "backend/open_webui/utils/middleware.py||backend/open_webui/utils/middleware.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_message": 1,
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "backend/open_webui/utils/middleware.py||backend/open_webui/utils/middleware.py": [
          "File: backend/open_webui/utils/middleware.py -> backend/open_webui/utils/middleware.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1134:                         results = block.get(\"results\", [])",
          "1136:                         if results:",
          "1137:                             if not raw:",
          "1139:                         else:",
          "1140:                             if not raw:",
          "1143:                     elif block[\"type\"] == \"reasoning\":",
          "1144:                         reasoning_display_content = \"\\n\".join(",
          "",
          "[Removed Lines]",
          "1138:                                 content = f'{content}\\n<details type=\"tool_calls\" done=\"true\" results=\"{html.escape(json.dumps(results))}\">\\n<summary>Tool Executed</summary>\\n```json\\n{block_content}\\n```\\n```json\\n{results}\\n```\\n</details>\\n'",
          "1141:                                 content = f'{content}\\n<details type=\"tool_calls\" done=\"false\">\\n<summary>Tool Executing...</summary>\\n```json\\n{block_content}\\n```\\n</details>\\n'",
          "",
          "[Added Lines]",
          "1138:                             result_display_content = \"\"",
          "1140:                             for result in results:",
          "1141:                                 tool_call_id = result.get(\"tool_call_id\", \"\")",
          "1142:                                 tool_name = \"\"",
          "1144:                                 for tool_call in block_content:",
          "1145:                                     if tool_call.get(\"id\", \"\") == tool_call_id:",
          "1146:                                         tool_name = tool_call.get(\"function\", {}).get(",
          "1147:                                             \"name\", \"\"",
          "1148:                                         )",
          "1149:                                         break",
          "1151:                                 result_display_content = f\"{result_display_content}\\n> {tool_name}: {result.get('content', '')}\"",
          "1154:                                 content = f'{content}\\n<details type=\"tool_calls\" done=\"true\" content=\"{html.escape(json.dumps(block_content))}\" results=\"{html.escape(json.dumps(results))}\">\\n<summary>Tool Executed</summary>\\n{result_display_content}\\n</details>\\n'",
          "1157:                                 content = f'{content}\\n<details type=\"tool_calls\" done=\"false\" content=\"{html.escape(json.dumps(block_content))}\">\\n<summary>Tool Executing...</summary>\\n</details>\\n'",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "c1a02ec7d8f528ce352b441df08f6efa379f1df6",
      "candidate_info": {
        "commit_hash": "c1a02ec7d8f528ce352b441df08f6efa379f1df6",
        "repo": "open-webui/open-webui",
        "commit_url": "https://github.com/open-webui/open-webui/commit/c1a02ec7d8f528ce352b441df08f6efa379f1df6",
        "files": [
          "backend/open_webui/socket/main.py"
        ],
        "message": "refac",
        "before_after_code_files": [
          "backend/open_webui/socket/main.py||backend/open_webui/socket/main.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_message": 1,
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "backend/open_webui/socket/main.py||backend/open_webui/socket/main.py": [
          "File: backend/open_webui/socket/main.py -> backend/open_webui/socket/main.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "314:                 )",
          "316:             if \"type\" in event_data and event_data[\"type\"] == \"replace\":",
          "327:     return __event_emitter__",
          "",
          "[Removed Lines]",
          "317:             content = event_data.get(\"data\", {}).get(\"content\", \"\")",
          "319:             Chats.upsert_message_to_chat_by_id_and_message_id(",
          "320:                 request_info[\"chat_id\"],",
          "321:                 request_info[\"message_id\"],",
          "322:                 {",
          "323:                     \"content\": content,",
          "324:                 },",
          "325:             )",
          "",
          "[Added Lines]",
          "316:                 content = event_data.get(\"data\", {}).get(\"content\", \"\")",
          "318:                 Chats.upsert_message_to_chat_by_id_and_message_id(",
          "319:                     request_info[\"chat_id\"],",
          "320:                     request_info[\"message_id\"],",
          "321:                     {",
          "322:                         \"content\": content,",
          "323:                     },",
          "324:                 )",
          "",
          "---------------"
        ]
      }
    }
  ]
}