{
  "cve_id": "CVE-2024-10940",
  "cve_desc": "A vulnerability in langchain-core versions >=0.1.17,<0.1.53, >=0.2.0,<0.2.43, and >=0.3.0,<0.3.15 allows unauthorized users to read arbitrary files from the host file system. The issue arises from the ability to create langchain_core.prompts.ImagePromptTemplate's (and by extension langchain_core.prompts.ChatPromptTemplate's) with input variables that can read any user-specified path from the server file system. If the outputs of these prompt templates are exposed to the user, either directly or through downstream model outputs, it can lead to the exposure of sensitive information.",
  "repo": "langchain-ai/langchain",
  "patch_hash": "c1e742347f9701aadba8920e4d1f79a636e50b68",
  "patch_info": {
    "commit_hash": "c1e742347f9701aadba8920e4d1f79a636e50b68",
    "repo": "langchain-ai/langchain",
    "commit_url": "https://github.com/langchain-ai/langchain/commit/c1e742347f9701aadba8920e4d1f79a636e50b68",
    "files": [
      "libs/core/langchain_core/prompts/image.py",
      "libs/core/langchain_core/utils/image.py",
      "libs/core/tests/unit_tests/prompts/test_chat.py"
    ],
    "message": "core[patch]: rm image loading (#27797)",
    "before_after_code_files": [
      "libs/core/langchain_core/prompts/image.py||libs/core/langchain_core/prompts/image.py",
      "libs/core/langchain_core/utils/image.py||libs/core/langchain_core/utils/image.py",
      "libs/core/tests/unit_tests/prompts/test_chat.py||libs/core/tests/unit_tests/prompts/test_chat.py"
    ]
  },
  "patch_diff": {
    "libs/core/langchain_core/prompts/image.py||libs/core/langchain_core/prompts/image.py": [
      "File: libs/core/langchain_core/prompts/image.py -> libs/core/langchain_core/prompts/image.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "9:     PromptTemplateFormat,",
      "10: )",
      "11: from langchain_core.runnables import run_in_executor",
      "15: class ImagePromptTemplate(BasePromptTemplate[ImageURL]):",
      "",
      "[Removed Lines]",
      "12: from langchain_core.utils import image as image_utils",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "80:             A formatted string.",
      "82:         Raises:",
      "86:         Example:",
      "",
      "[Removed Lines]",
      "83:             ValueError: If the url or path is not provided.",
      "84:             ValueError: If the path or url is not a string.",
      "",
      "[Added Lines]",
      "82:             ValueError: If the url is not provided.",
      "83:             ValueError: If the url is not a string.",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "98:             else:",
      "99:                 formatted[k] = v",
      "100:         url = kwargs.get(\"url\") or formatted.get(\"url\")",
      "105:             raise ValueError(msg)",
      "106:         if not url:",
      "112:             msg = \"url must be a string.\"",
      "113:             raise ValueError(msg)",
      "118:         return output",
      "120:     async def aformat(self, **kwargs: Any) -> ImageURL:",
      "",
      "[Removed Lines]",
      "101:         path = kwargs.get(\"path\") or formatted.get(\"path\")",
      "102:         detail = kwargs.get(\"detail\") or formatted.get(\"detail\")",
      "103:         if not url and not path:",
      "104:             msg = \"Must provide either url or path.\"",
      "107:             if not isinstance(path, str):",
      "108:                 msg = \"path must be a string.\"",
      "109:                 raise ValueError(msg)",
      "110:             url = image_utils.image_to_data_url(path)",
      "111:         if not isinstance(url, str):",
      "114:         output: ImageURL = {\"url\": url}",
      "115:         if detail:",
      "116:             # Don't check literal values here: let the API check them",
      "117:             output[\"detail\"] = detail  # type: ignore[typeddict-item]",
      "",
      "[Added Lines]",
      "100:         if kwargs.get(\"path\") or formatted.get(\"path\"):",
      "101:             msg = (",
      "102:                 \"Loading images from 'path' has been removed as of 0.3.15 for security \"",
      "103:                 \"reasons. Please specify images by 'url'.\"",
      "104:             )",
      "106:         detail = kwargs.get(\"detail\") or formatted.get(\"detail\")",
      "108:             msg = \"Must provide url.\"",
      "109:             raise ValueError(msg)",
      "110:         elif not isinstance(url, str):",
      "113:         else:",
      "114:             output: ImageURL = {\"url\": url}",
      "115:             if detail:",
      "116:                 # Don't check literal values here: let the API check them",
      "117:                 output[\"detail\"] = detail  # type: ignore[typeddict-item]",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "127:             A formatted string.",
      "129:         Raises:",
      "131:             ValueError: If the path or url is not a string.",
      "132:         \"\"\"",
      "133:         return await run_in_executor(None, self.format, **kwargs)",
      "",
      "[Removed Lines]",
      "130:             ValueError: If the url or path is not provided.",
      "",
      "[Added Lines]",
      "[None]",
      "",
      "---------------"
    ],
    "libs/core/langchain_core/utils/image.py||libs/core/langchain_core/utils/image.py": [
      "File: libs/core/langchain_core/utils/image.py -> libs/core/langchain_core/utils/image.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "[No context available]",
      "",
      "[Removed Lines]",
      "1: import base64",
      "2: import mimetypes",
      "5: def encode_image(image_path: str) -> str:",
      "6:     \"\"\"Get base64 string from image URI.",
      "8:     Args:",
      "9:         image_path: The path to the image.",
      "11:     Returns:",
      "12:         The base64 string of the image.",
      "13:     \"\"\"",
      "14:     with open(image_path, \"rb\") as image_file:",
      "15:         return base64.b64encode(image_file.read()).decode(\"utf-8\")",
      "18: def image_to_data_url(image_path: str) -> str:",
      "19:     \"\"\"Get data URL from image URI.",
      "21:     Args:",
      "22:         image_path: The path to the image.",
      "24:     Returns:",
      "25:         The data URL of the image.",
      "26:     \"\"\"",
      "27:     encoding = encode_image(image_path)",
      "28:     mime_type = mimetypes.guess_type(image_path)[0]",
      "29:     return f\"data:{mime_type};base64,{encoding}\"",
      "",
      "[Added Lines]",
      "1: from typing import Any",
      "4: def __getattr__(name: str) -> Any:",
      "5:     if name in (\"encode_image\", \"image_to_data_url\"):",
      "6:         msg = f\"'{name}' has been removed for security reasons.\"",
      "7:         raise ValueError(msg)",
      "8:     raise AttributeError(name)",
      "",
      "---------------"
    ],
    "libs/core/tests/unit_tests/prompts/test_chat.py||libs/core/tests/unit_tests/prompts/test_chat.py": [
      "File: libs/core/tests/unit_tests/prompts/test_chat.py -> libs/core/tests/unit_tests/prompts/test_chat.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "721: async def test_chat_tmpl_from_messages_multipart_formatting_with_path() -> None:",
      "723:     in_mem = \"base64mem\"",
      "724:     in_file_data = \"base64file01\"",
      "",
      "[Removed Lines]",
      "722:     \"\"\"Verify that we can pass `path` for an image as a variable.\"\"\"",
      "",
      "[Added Lines]",
      "722:     \"\"\"Verify that we cannot pass `path` for an image as a variable.\"\"\"",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "746:                 ),",
      "747:             ]",
      "748:         )",
      "780: def test_messages_placeholder() -> None:",
      "",
      "[Removed Lines]",
      "749:         expected = [",
      "750:             SystemMessage(content=\"You are an AI assistant named R2D2.\"),",
      "751:             HumanMessage(",
      "752:                 content=[",
      "753:                     {\"type\": \"text\", \"text\": \"What's in this image?\"},",
      "754:                     {",
      "755:                         \"type\": \"image_url\",",
      "756:                         \"image_url\": {\"url\": f\"data:image/jpeg;base64,{in_mem}\"},",
      "757:                     },",
      "758:                     {",
      "759:                         \"type\": \"image_url\",",
      "760:                         \"image_url\": {\"url\": f\"data:image/jpeg;base64,{in_file_data}\"},",
      "761:                     },",
      "762:                 ]",
      "763:             ),",
      "764:         ]",
      "765:         messages = template.format_messages(",
      "766:             name=\"R2D2\",",
      "767:             in_mem=in_mem,",
      "768:             file_path=temp_file.name,",
      "769:         )",
      "770:         assert messages == expected",
      "772:         messages = await template.aformat_messages(",
      "773:             name=\"R2D2\",",
      "774:             in_mem=in_mem,",
      "775:             file_path=temp_file.name,",
      "776:         )",
      "777:         assert messages == expected",
      "",
      "[Added Lines]",
      "749:         with pytest.raises(ValueError):",
      "750:             template.format_messages(",
      "751:                 name=\"R2D2\",",
      "752:                 in_mem=in_mem,",
      "753:                 file_path=temp_file.name,",
      "754:             )",
      "756:         with pytest.raises(ValueError):",
      "757:             await template.aformat_messages(",
      "758:                 name=\"R2D2\",",
      "759:                 in_mem=in_mem,",
      "760:                 file_path=temp_file.name,",
      "761:             )",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "1eca98ec56e2f65a75668c29199f9489223e68f7",
      "candidate_info": {
        "commit_hash": "1eca98ec56e2f65a75668c29199f9489223e68f7",
        "repo": "langchain-ai/langchain",
        "commit_url": "https://github.com/langchain-ai/langchain/commit/1eca98ec56e2f65a75668c29199f9489223e68f7",
        "files": [
          "libs/core/langchain_core/prompts/base.py",
          "libs/core/langchain_core/prompts/chat.py",
          "libs/core/langchain_core/prompts/few_shot.py",
          "libs/core/langchain_core/prompts/few_shot_with_templates.py",
          "libs/core/langchain_core/prompts/image.py",
          "libs/core/langchain_core/prompts/loading.py",
          "libs/core/langchain_core/prompts/pipeline.py",
          "libs/core/langchain_core/prompts/prompt.py",
          "libs/core/langchain_core/prompts/string.py",
          "libs/core/langchain_core/prompts/structured.py"
        ],
        "message": "core: docstrings `prompts` (#23890)\n\nAdded missed docstrings. Formatted docstrings to the consistent form.",
        "before_after_code_files": [
          "libs/core/langchain_core/prompts/base.py||libs/core/langchain_core/prompts/base.py",
          "libs/core/langchain_core/prompts/chat.py||libs/core/langchain_core/prompts/chat.py",
          "libs/core/langchain_core/prompts/few_shot.py||libs/core/langchain_core/prompts/few_shot.py",
          "libs/core/langchain_core/prompts/few_shot_with_templates.py||libs/core/langchain_core/prompts/few_shot_with_templates.py",
          "libs/core/langchain_core/prompts/image.py||libs/core/langchain_core/prompts/image.py",
          "libs/core/langchain_core/prompts/loading.py||libs/core/langchain_core/prompts/loading.py",
          "libs/core/langchain_core/prompts/pipeline.py||libs/core/langchain_core/prompts/pipeline.py",
          "libs/core/langchain_core/prompts/prompt.py||libs/core/langchain_core/prompts/prompt.py",
          "libs/core/langchain_core/prompts/string.py||libs/core/langchain_core/prompts/string.py",
          "libs/core/langchain_core/prompts/structured.py||libs/core/langchain_core/prompts/structured.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "libs/core/langchain_core/prompts/image.py||libs/core/langchain_core/prompts/image.py"
          ],
          "candidate": [
            "libs/core/langchain_core/prompts/image.py||libs/core/langchain_core/prompts/image.py"
          ]
        }
      },
      "candidate_diff": {
        "libs/core/langchain_core/prompts/base.py||libs/core/langchain_core/prompts/base.py": [
          "File: libs/core/langchain_core/prompts/base.py -> libs/core/langchain_core/prompts/base.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "88:     @classmethod",
          "89:     def get_lc_namespace(cls) -> List[str]:",
          "91:         return [\"langchain\", \"schema\", \"prompt_template\"]",
          "93:     @classmethod",
          "94:     def is_lc_serializable(cls) -> bool:",
          "96:         return True",
          "98:     class Config:",
          "",
          "[Removed Lines]",
          "90:         \"\"\"Get the namespace of the langchain object.\"\"\"",
          "95:         \"\"\"Return whether this class is serializable.\"\"\"",
          "",
          "[Added Lines]",
          "90:         \"\"\"Get the namespace of the langchain object.",
          "91:         Returns [\"langchain\", \"schema\", \"prompt_template\"].\"\"\"",
          "96:         \"\"\"Return whether this class is serializable.",
          "97:         Returns True.\"\"\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "103:     @property",
          "104:     def OutputType(self) -> Any:",
          "105:         return Union[StringPromptValue, ChatPromptValueConcrete]",
          "107:     def get_input_schema(",
          "108:         self, config: Optional[RunnableConfig] = None",
          "109:     ) -> Type[BaseModel]:",
          "110:         # This is correct, but pydantic typings/mypy don't think so.",
          "111:         required_input_variables = {",
          "112:             k: (self.input_types.get(k, str), ...) for k in self.input_variables",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "107:         \"\"\"Return the output type of the prompt.\"\"\"",
          "113:         \"\"\"Get the input schema for the prompt.",
          "115:         Args:",
          "116:             config: RunnableConfig, configuration for the prompt.",
          "118:         Returns:",
          "119:             Type[BaseModel]: The input schema for the prompt.",
          "120:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "151:     def invoke(",
          "152:         self, input: Dict, config: Optional[RunnableConfig] = None",
          "153:     ) -> PromptValue:",
          "154:         config = ensure_config(config)",
          "155:         if self.metadata:",
          "156:             config[\"metadata\"] = {**config[\"metadata\"], **self.metadata}",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "165:         \"\"\"Invoke the prompt.",
          "167:         Args:",
          "168:             input: Dict, input to the prompt.",
          "169:             config: RunnableConfig, configuration for the prompt.",
          "171:         Returns:",
          "172:             PromptValue: The output of the prompt.",
          "173:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "166:     async def ainvoke(",
          "167:         self, input: Dict, config: Optional[RunnableConfig] = None, **kwargs: Any",
          "168:     ) -> PromptValue:",
          "169:         config = ensure_config(config)",
          "170:         if self.metadata:",
          "171:             config[\"metadata\"].update(self.metadata)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "189:         \"\"\"Async invoke the prompt.",
          "191:         Args:",
          "192:             input: Dict, input to the prompt.",
          "193:             config: RunnableConfig, configuration for the prompt.",
          "195:         Returns:",
          "196:             PromptValue: The output of the prompt.",
          "197:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "181:     @abstractmethod",
          "182:     def format_prompt(self, **kwargs: Any) -> PromptValue:",
          "185:     async def aformat_prompt(self, **kwargs: Any) -> PromptValue:",
          "187:         return self.format_prompt(**kwargs)",
          "189:     def partial(self, **kwargs: Union[str, Callable[[], str]]) -> BasePromptTemplate:",
          "191:         prompt_dict = self.__dict__.copy()",
          "192:         prompt_dict[\"input_variables\"] = list(",
          "193:             set(self.input_variables).difference(kwargs)",
          "",
          "[Removed Lines]",
          "183:         \"\"\"Create Prompt Value.\"\"\"",
          "186:         \"\"\"Create Prompt Value.\"\"\"",
          "190:         \"\"\"Return a partial of the prompt template.\"\"\"",
          "",
          "[Added Lines]",
          "212:         \"\"\"Create Prompt Value.",
          "214:         Args:",
          "215:             kwargs: Any arguments to be passed to the prompt template.",
          "217:         Returns:",
          "218:             PromptValue: The output of the prompt.",
          "219:         \"\"\"",
          "222:         \"\"\"Async create Prompt Value.",
          "224:         Args:",
          "225:             kwargs: Any arguments to be passed to the prompt template.",
          "227:         Returns:",
          "228:             PromptValue: The output of the prompt.",
          "229:         \"\"\"",
          "233:         \"\"\"Return a partial of the prompt template.",
          "235:         Args:",
          "236:             kwargs: Union[str, Callable[[], str], partial variables to set.",
          "238:         Returns:",
          "239:             BasePromptTemplate: A partial of the prompt template.",
          "240:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "220:         \"\"\"",
          "222:     async def aformat(self, **kwargs: Any) -> FormatOutputType:",
          "225:         Args:",
          "226:             kwargs: Any arguments to be passed to the prompt template.",
          "",
          "[Removed Lines]",
          "223:         \"\"\"Format the prompt with the inputs.",
          "",
          "[Added Lines]",
          "273:         \"\"\"Async format the prompt with the inputs.",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "242:         raise NotImplementedError",
          "244:     def dict(self, **kwargs: Any) -> Dict:",
          "246:         prompt_dict = super().dict(**kwargs)",
          "247:         try:",
          "248:             prompt_dict[\"_type\"] = self._prompt_type",
          "",
          "[Removed Lines]",
          "245:         \"\"\"Return dictionary representation of prompt.\"\"\"",
          "",
          "[Added Lines]",
          "295:         \"\"\"Return dictionary representation of prompt.",
          "297:         Args:",
          "298:             kwargs: Any additional arguments to pass to the dictionary.",
          "300:         Returns:",
          "301:             Dict: Dictionary representation of the prompt.",
          "303:         Raises:",
          "304:             NotImplementedError: If the prompt type is not implemented.",
          "305:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "256:         Args:",
          "257:             file_path: Path to directory to save prompt to.",
          "259:         Example:",
          "260:         .. code-block:: python",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "319:         Raises:",
          "320:             ValueError: If the prompt has partial variables.",
          "321:             ValueError: If the file path is not json or yaml.",
          "322:             NotImplementedError: If the prompt type is not implemented.",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "309:     First, this pulls information from the document from two sources:",
          "312:         This takes the information from the `document.page_content`",
          "313:         and assigns it to a variable named `page_content`.",
          "314:     2. metadata:",
          "",
          "[Removed Lines]",
          "311:     1. `page_content`:",
          "",
          "[Added Lines]",
          "376:     1. page_content:",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "343: async def aformat_document(doc: Document, prompt: BasePromptTemplate[str]) -> str:",
          "346:     First, this pulls information from the document from two sources:",
          "349:         This takes the information from the `document.page_content`",
          "350:         and assigns it to a variable named `page_content`.",
          "351:     2. metadata:",
          "",
          "[Removed Lines]",
          "344:     \"\"\"Format a document into a string based on a prompt template.",
          "348:     1. `page_content`:",
          "",
          "[Added Lines]",
          "409:     \"\"\"Async format a document into a string based on a prompt template.",
          "413:     1. page_content:",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/prompts/chat.py||libs/core/langchain_core/prompts/chat.py": [
          "File: libs/core/langchain_core/prompts/chat.py -> libs/core/langchain_core/prompts/chat.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "49:     @classmethod",
          "50:     def is_lc_serializable(cls) -> bool:",
          "52:         return True",
          "54:     @classmethod",
          "",
          "[Removed Lines]",
          "51:         \"\"\"Return whether or not the class is serializable.\"\"\"",
          "",
          "[Added Lines]",
          "51:         \"\"\"Return whether or not the class is serializable.",
          "52:         Returns: True\"\"\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "68:         \"\"\"",
          "70:     async def aformat_messages(self, **kwargs: Any) -> List[BaseMessage]:",
          "73:         Args:",
          "",
          "[Removed Lines]",
          "71:         \"\"\"Format messages from kwargs. Should return a list of BaseMessages.",
          "",
          "[Added Lines]",
          "72:         \"\"\"Async format messages from kwargs.",
          "73:         Should return a list of BaseMessages.",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "88:         \"\"\"",
          "90:     def pretty_repr(self, html: bool = False) -> str:",
          "92:         raise NotImplementedError",
          "94:     def pretty_print(self) -> None:",
          "95:         print(self.pretty_repr(html=is_interactive_env()))  # noqa: T201",
          "97:     def __add__(self, other: Any) -> ChatPromptTemplate:",
          "",
          "[Removed Lines]",
          "91:         \"\"\"Human-readable representation.\"\"\"",
          "",
          "[Added Lines]",
          "93:         \"\"\"Human-readable representation.",
          "95:         Args:",
          "96:             html: Whether to format as HTML. Defaults to False.",
          "98:         Returns:",
          "99:             Human-readable representation.",
          "100:         \"\"\"",
          "104:         \"\"\"Print a human-readable representation.\"\"\"",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "209:         Returns:",
          "210:             List of BaseMessage.",
          "211:         \"\"\"",
          "212:         value = (",
          "213:             kwargs.get(self.variable_name, [])",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "222:         Raises:",
          "223:             ValueError: If variable is not a list of messages.",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "234:         return [self.variable_name] if not self.optional else []",
          "236:     def pretty_repr(self, html: bool = False) -> str:",
          "237:         var = \"{\" + self.variable_name + \"}\"",
          "238:         if html:",
          "239:             title = get_msg_title_repr(\"Messages Placeholder\", bold=True)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "250:         \"\"\"Human-readable representation.",
          "252:         Args:",
          "253:             html: Whether to format as HTML. Defaults to False.",
          "255:         Returns:",
          "256:             Human-readable representation.",
          "257:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "275:         Args:",
          "276:             template: a template.",
          "278:             partial_variables: A dictionary of variables that can be used to partially",
          "279:                                fill in the template. For example, if the template is",
          "280:                               `\"{variable1} {variable2}\"`, and `partial_variables` is",
          "281:                               `{\"variable1\": \"foo\"}`, then the final prompt will be",
          "282:                               `\"foo {variable2}\"`.",
          "285:         Returns:",
          "",
          "[Removed Lines]",
          "277:             template_format: format of the template.",
          "",
          "[Added Lines]",
          "298:             template_format: format of the template. Defaults to \"f-string\".",
          "304:                               Defaults to None.",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "324:         \"\"\"",
          "326:     async def aformat(self, **kwargs: Any) -> BaseMessage:",
          "329:         Args:",
          "",
          "[Removed Lines]",
          "327:         \"\"\"Format the prompt template.",
          "",
          "[Added Lines]",
          "349:         \"\"\"Async format the prompt template.",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "346:         return [self.format(**kwargs)]",
          "348:     async def aformat_messages(self, **kwargs: Any) -> List[BaseMessage]:",
          "349:         return [await self.aformat(**kwargs)]",
          "351:     @property",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "371:         \"\"\"Async format messages from kwargs.",
          "373:         Args:",
          "376:         Returns:",
          "377:             List of BaseMessages.",
          "378:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "359:         return self.prompt.input_variables",
          "361:     def pretty_repr(self, html: bool = False) -> str:",
          "362:         # TODO: Handle partials",
          "363:         title = self.__class__.__name__.replace(\"MessagePromptTemplate\", \" Message\")",
          "364:         title = get_msg_title_repr(title, bold=html)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "392:         \"\"\"Human-readable representation.",
          "394:         Args:",
          "395:             html: Whether to format as HTML. Defaults to False.",
          "397:         Returns:",
          "398:             Human-readable representation.",
          "399:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 10 ---",
          "[Context before]",
          "391:         )",
          "393:     async def aformat(self, **kwargs: Any) -> BaseMessage:",
          "394:         text = await self.prompt.aformat(**kwargs)",
          "395:         return ChatMessage(",
          "396:             content=text, role=self.role, additional_kwargs=self.additional_kwargs",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "432:         \"\"\"Async format the prompt template.",
          "434:         Args:",
          "437:         Returns:",
          "438:             Formatted message.",
          "439:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 11 ---",
          "[Context before]",
          "441:         Args:",
          "442:             template: a template.",
          "444:             partial_variables: A dictionary of variables that can be used too partially.",
          "447:         Returns:",
          "448:             A new instance of this class.",
          "449:         \"\"\"",
          "450:         if isinstance(template, str):",
          "451:             prompt: Union[StringPromptTemplate, List] = PromptTemplate.from_template(",
          "",
          "[Removed Lines]",
          "443:             template_format: format of the template.",
          "",
          "[Added Lines]",
          "489:             template_format: format of the template. Defaults to \"f-string\".",
          "491:                 Defaults to None.",
          "497:         Raises:",
          "498:             ValueError: If the template is not a string or list of strings.",
          "",
          "---------------",
          "--- Hunk 12 ---",
          "[Context before]",
          "542:         return [self.format(**kwargs)]",
          "544:     async def aformat_messages(self, **kwargs: Any) -> List[BaseMessage]:",
          "545:         return [await self.aformat(**kwargs)]",
          "547:     @property",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "595:         \"\"\"Async format messages from kwargs.",
          "597:         Args:",
          "600:         Returns:",
          "601:             List of BaseMessages.",
          "602:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 13 ---",
          "[Context before]",
          "585:             )",
          "587:     async def aformat(self, **kwargs: Any) -> BaseMessage:",
          "590:         Args:",
          "",
          "[Removed Lines]",
          "588:         \"\"\"Format the prompt template.",
          "",
          "[Added Lines]",
          "646:         \"\"\"Async format the prompt template.",
          "",
          "---------------",
          "--- Hunk 14 ---",
          "[Context before]",
          "613:             )",
          "615:     def pretty_repr(self, html: bool = False) -> str:",
          "616:         # TODO: Handle partials",
          "617:         title = self.__class__.__name__.replace(\"MessagePromptTemplate\", \" Message\")",
          "618:         title = get_msg_title_repr(title, bold=html)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "674:         \"\"\"Human-readable representation.",
          "676:         Args:",
          "677:             html: Whether to format as HTML. Defaults to False.",
          "679:         Returns:",
          "680:             Human-readable representation.",
          "681:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 15 ---",
          "[Context before]",
          "671:                       in all the template messages in this chat template.",
          "673:         Returns:",
          "675:         \"\"\"",
          "676:         return self.format_prompt(**kwargs).to_string()",
          "678:     async def aformat(self, **kwargs: Any) -> str:",
          "681:         Args:",
          "683:                       in all the template messages in this chat template.",
          "685:         Returns:",
          "687:         \"\"\"",
          "688:         return (await self.aformat_prompt(**kwargs)).to_string()",
          "690:     def format_prompt(self, **kwargs: Any) -> PromptValue:",
          "693:         Args:",
          "",
          "[Removed Lines]",
          "674:             formatted string",
          "679:         \"\"\"Format the chat template into a string.",
          "686:             formatted string",
          "691:         \"\"\"",
          "692:         Format prompt. Should return a PromptValue.",
          "",
          "[Added Lines]",
          "740:             formatted string.",
          "745:         \"\"\"Async format the chat template into a string.",
          "752:             formatted string.",
          "757:         \"\"\"Format prompt. Should return a PromptValue.",
          "",
          "---------------",
          "--- Hunk 16 ---",
          "[Context before]",
          "700:         return ChatPromptValue(messages=messages)",
          "702:     async def aformat_prompt(self, **kwargs: Any) -> PromptValue:",
          "703:         messages = await self.aformat_messages(**kwargs)",
          "704:         return ChatPromptValue(messages=messages)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "769:         \"\"\"Async format prompt. Should return a PromptValue.",
          "771:         Args:",
          "774:         Returns:",
          "775:             PromptValue.",
          "776:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 17 ---",
          "[Context before]",
          "708:         \"\"\"Format kwargs into a list of messages.\"\"\"",
          "710:     async def aformat_messages(self, **kwargs: Any) -> List[BaseMessage]:",
          "712:         return self.format_messages(**kwargs)",
          "714:     def pretty_repr(self, html: bool = False) -> str:",
          "716:         raise NotImplementedError",
          "718:     def pretty_print(self) -> None:",
          "719:         print(self.pretty_repr(html=is_interactive_env()))  # noqa: T201",
          "",
          "[Removed Lines]",
          "711:         \"\"\"Format kwargs into a list of messages.\"\"\"",
          "715:         \"\"\"Human-readable representation.\"\"\"",
          "",
          "[Added Lines]",
          "785:         \"\"\"Async format kwargs into a list of messages.\"\"\"",
          "789:         \"\"\"Human-readable representation.",
          "791:         Args:",
          "792:             html: Whether to format as HTML. Defaults to False.",
          "794:         Returns:",
          "795:             Human-readable representation.",
          "796:         \"\"\"",
          "800:         \"\"\"Print a human-readable representation.\"\"\"",
          "",
          "---------------",
          "--- Hunk 18 ---",
          "[Context before]",
          "882:         Returns:",
          "883:             Validated values.",
          "884:         \"\"\"",
          "885:         messages = values[\"messages\"]",
          "886:         input_vars = set()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "967:         Raises:",
          "968:             ValueError: If input variables do not match.",
          "",
          "---------------",
          "--- Hunk 19 ---",
          "[Context before]",
          "947:             string_messages: list of (role, template) tuples.",
          "949:         Returns:",
          "951:         \"\"\"",
          "952:         return cls(  # type: ignore[call-arg]",
          "953:             messages=[",
          "",
          "[Removed Lines]",
          "950:             a chat prompt template",
          "",
          "[Added Lines]",
          "1035:             a chat prompt template.",
          "",
          "---------------",
          "--- Hunk 20 ---",
          "[Context before]",
          "967:             string_messages: list of (role class, template) tuples.",
          "969:         Returns:",
          "971:         \"\"\"",
          "972:         return cls.from_messages(string_messages)",
          "",
          "[Removed Lines]",
          "970:             a chat prompt template",
          "",
          "[Added Lines]",
          "1055:             a chat prompt template.",
          "",
          "---------------",
          "--- Hunk 21 ---",
          "[Context before]",
          "1006:                   (1) BaseMessagePromptTemplate, (2) BaseMessage, (3) 2-tuple of",
          "1007:                   (message type, template); e.g., (\"human\", \"{user_input}\"),",
          "1008:                   (4) 2-tuple of (message class, template), (4) a string which is",
          "1011:         Returns:",
          "1013:         \"\"\"",
          "1014:         _messages = [",
          "1015:             _convert_to_message(message, template_format) for message in messages",
          "",
          "[Removed Lines]",
          "1009:                   shorthand for (\"human\", template); e.g., \"{user_input}\"",
          "1012:             a chat prompt template",
          "",
          "[Added Lines]",
          "1094:                   shorthand for (\"human\", template); e.g., \"{user_input}\".",
          "1095:             template_format: format of the template. Defaults to \"f-string\".",
          "1098:             a chat prompt template.",
          "",
          "---------------",
          "--- Hunk 22 ---",
          "[Context before]",
          "1043:                       in all the template messages in this chat template.",
          "1045:         Returns:",
          "1047:         \"\"\"",
          "1048:         kwargs = self._merge_partial_and_user_variables(**kwargs)",
          "1049:         result = []",
          "",
          "[Removed Lines]",
          "1046:             list of formatted messages",
          "",
          "[Added Lines]",
          "1132:             list of formatted messages.",
          "",
          "---------------",
          "--- Hunk 23 ---",
          "[Context before]",
          "1060:         return result",
          "1062:     async def aformat_messages(self, **kwargs: Any) -> List[BaseMessage]:",
          "1065:         Args:",
          "1067:                       in all the template messages in this chat template.",
          "1069:         Returns:",
          "1071:         \"\"\"",
          "1072:         kwargs = self._merge_partial_and_user_variables(**kwargs)",
          "1073:         result = []",
          "",
          "[Removed Lines]",
          "1063:         \"\"\"Format the chat template into a list of finalized messages.",
          "1070:             list of formatted messages",
          "",
          "[Added Lines]",
          "1149:         \"\"\"Async format the chat template into a list of finalized messages.",
          "1156:             list of formatted messages.",
          "1158:         Raises:",
          "1159:             ValueError: If unexpected input.",
          "",
          "---------------",
          "--- Hunk 24 ---",
          "[Context before]",
          "1120:         return type(self)(**prompt_dict)",
          "1122:     def append(self, message: MessageLikeRepresentation) -> None:",
          "1125:         Args:",
          "1126:             message: representation of a message to append.",
          "",
          "[Removed Lines]",
          "1123:         \"\"\"Append message to the end of the chat template.",
          "",
          "[Added Lines]",
          "1212:         \"\"\"Append a message to the end of the chat template.",
          "",
          "---------------",
          "--- Hunk 25 ---",
          "[Context before]",
          "1128:         self.messages.append(_convert_to_message(message))",
          "1130:     def extend(self, messages: Sequence[MessageLikeRepresentation]) -> None:",
          "1132:         self.messages.extend([_convert_to_message(message) for message in messages])",
          "1134:     @overload",
          "",
          "[Removed Lines]",
          "1131:         \"\"\"Extend the chat template with a sequence of messages.\"\"\"",
          "",
          "[Added Lines]",
          "1220:         \"\"\"Extend the chat template with a sequence of messages.",
          "1222:         Args:",
          "1223:             messages: sequence of message representations to append.",
          "1224:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 26 ---",
          "[Context before]",
          "1155:     @property",
          "1156:     def _prompt_type(self) -> str:",
          "1158:         return \"chat\"",
          "1160:     def save(self, file_path: Union[Path, str]) -> None:",
          "",
          "[Removed Lines]",
          "1157:         \"\"\"Name of prompt type.\"\"\"",
          "",
          "[Added Lines]",
          "1250:         \"\"\"Name of prompt type. Used for serialization.\"\"\"",
          "",
          "---------------",
          "--- Hunk 27 ---",
          "[Context before]",
          "1166:         raise NotImplementedError()",
          "1168:     def pretty_repr(self, html: bool = False) -> str:",
          "1169:         # TODO: handle partials",
          "1170:         return \"\\n\\n\".join(msg.pretty_repr(html=html) for msg in self.messages)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1262:         \"\"\"Human-readable representation.",
          "1264:         Args:",
          "1265:             html: Whether to format as HTML. Defaults to False.",
          "1267:         Returns:",
          "1268:             Human-readable representation.",
          "1269:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 28 ---",
          "[Context before]",
          "1180:     Args:",
          "1181:         message_type: str the type of the message template (e.g., \"human\", \"ai\", etc.)",
          "1182:         template: str the template string.",
          "1184:     Returns:",
          "1185:         a message prompt template of the appropriate type.",
          "1186:     \"\"\"",
          "1187:     if message_type in (\"human\", \"user\"):",
          "1188:         message: BaseMessagePromptTemplate = HumanMessagePromptTemplate.from_template(",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1284:         template_format: format of the template. Defaults to \"f-string\".",
          "1289:     Raises:",
          "1290:         ValueError: If unexpected message type.",
          "",
          "---------------",
          "--- Hunk 29 ---",
          "[Context before]",
          "1249:     - string: shorthand for (\"human\", template); e.g., \"{user_input}\"",
          "1251:     Args:",
          "1254:     Returns:",
          "1256:     \"\"\"",
          "1257:     if isinstance(message, (BaseMessagePromptTemplate, BaseChatPromptTemplate)):",
          "1258:         _message: Union[",
          "",
          "[Removed Lines]",
          "1252:         message: a representation of a message in one of the supported formats",
          "1255:         an instance of a message or a message template",
          "",
          "[Added Lines]",
          "1357:         message: a representation of a message in one of the supported formats.",
          "1358:         template_format: format of the template. Defaults to \"f-string\".",
          "1361:         an instance of a message or a message template.",
          "1363:     Raises:",
          "1364:         ValueError: If unexpected message type.",
          "1365:         ValueError: If 2-tuple does not have 2 elements.",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/prompts/few_shot.py||libs/core/langchain_core/prompts/few_shot.py": [
          "File: libs/core/langchain_core/prompts/few_shot.py -> libs/core/langchain_core/prompts/few_shot.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "41:     @root_validator(pre=True)",
          "42:     def check_examples_and_selector(cls, values: Dict) -> Dict:",
          "44:         examples = values.get(\"examples\", None)",
          "45:         example_selector = values.get(\"example_selector\", None)",
          "46:         if examples and example_selector:",
          "",
          "[Removed Lines]",
          "43:         \"\"\"Check that one and only one of examples/example_selector are provided.\"\"\"",
          "",
          "[Added Lines]",
          "43:         \"\"\"Check that one and only one of examples/example_selector are provided.",
          "45:         Args:",
          "46:             values: The values to check.",
          "48:         Returns:",
          "49:             The values if they are valid.",
          "51:         Raises:",
          "52:             ValueError: If neither or both examples and example_selector are provided.",
          "53:             ValueError: If both examples and example_selector are provided.",
          "54:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "64:         Returns:",
          "65:             List of examples.",
          "66:         \"\"\"",
          "67:         if self.examples is not None:",
          "68:             return self.examples",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "78:         Raises:",
          "79:             ValueError: If neither examples nor example_selector are provided.",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "74:             )",
          "76:     async def _aget_examples(self, **kwargs: Any) -> List[dict]:",
          "79:         Args:",
          "82:         Returns:",
          "83:             List of examples.",
          "84:         \"\"\"",
          "85:         if self.examples is not None:",
          "86:             return self.examples",
          "",
          "[Removed Lines]",
          "77:         \"\"\"Get the examples to use for formatting the prompt.",
          "",
          "[Added Lines]",
          "91:         \"\"\"Async get the examples to use for formatting the prompt.",
          "99:         Raises:",
          "100:             ValueError: If neither examples nor example_selector are provided.",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "144:         arbitrary_types_allowed = True",
          "146:     def format(self, **kwargs: Any) -> str:",
          "147:         kwargs = self._merge_partial_and_user_variables(**kwargs)",
          "148:         # Get the examples to use.",
          "149:         examples = self._get_examples(**kwargs)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "164:         \"\"\"Format the prompt with inputs generating a string.",
          "166:         Use this method to generate a string representation of a prompt.",
          "168:         Args:",
          "171:         Returns:",
          "172:             A string representation of the prompt.",
          "173:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "162:         return DEFAULT_FORMATTER_MAPPING[self.template_format](template, **kwargs)",
          "164:     async def aformat(self, **kwargs: Any) -> str:",
          "165:         kwargs = self._merge_partial_and_user_variables(**kwargs)",
          "166:         # Get the examples to use.",
          "167:         examples = await self._aget_examples(**kwargs)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "192:         \"\"\"Async format the prompt with inputs generating a string.",
          "194:         Use this method to generate a string representation of a prompt.",
          "196:         Args:",
          "199:         Returns:",
          "200:             A string representation of the prompt.",
          "201:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "185:         return \"few_shot\"",
          "187:     def save(self, file_path: Union[Path, str]) -> None:",
          "188:         if self.example_selector:",
          "189:             raise ValueError(\"Saving an example selector is not currently supported\")",
          "190:         return super().save(file_path)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "225:         \"\"\"Save the prompt template to a file.",
          "227:         Args:",
          "228:             file_path: The path to save the prompt template to.",
          "230:         Raises:",
          "231:             ValueError: If example_selector is provided.",
          "232:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "343:         return messages",
          "345:     async def aformat_messages(self, **kwargs: Any) -> List[BaseMessage]:",
          "348:         Args:",
          "",
          "[Removed Lines]",
          "346:         \"\"\"Format kwargs into a list of messages.",
          "",
          "[Added Lines]",
          "391:         \"\"\"Async format kwargs into a list of messages.",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "370:         Use this method to generate a string representation of a prompt consisting",
          "371:         of chat messages.",
          "375:         Args:",
          "",
          "[Removed Lines]",
          "373:         Useful for feeding into a string based completion language model or debugging.",
          "",
          "[Added Lines]",
          "418:         Useful for feeding into a string-based completion language model or debugging.",
          "",
          "---------------",
          "--- Hunk 9 ---",
          "[Context before]",
          "382:         return get_buffer_string(messages)",
          "384:     async def aformat(self, **kwargs: Any) -> str:",
          "385:         messages = await self.aformat_messages(**kwargs)",
          "386:         return get_buffer_string(messages)",
          "388:     def pretty_repr(self, html: bool = False) -> str:",
          "389:         raise NotImplementedError()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "430:         \"\"\"Async format the prompt with inputs generating a string.",
          "432:         Use this method to generate a string representation of a prompt consisting",
          "433:         of chat messages.",
          "435:         Useful for feeding into a string-based completion language model or debugging.",
          "437:         Args:",
          "440:         Returns:",
          "441:             A string representation of the prompt",
          "442:         \"\"\"",
          "447:         \"\"\"Return a pretty representation of the prompt template.",
          "449:         Args:",
          "450:             html: Whether or not to return an HTML formatted string.",
          "452:         Returns:",
          "453:             A pretty representation of the prompt template.",
          "454:         \"\"\"",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/prompts/few_shot_with_templates.py||libs/core/langchain_core/prompts/few_shot_with_templates.py": [
          "File: libs/core/langchain_core/prompts/few_shot_with_templates.py -> libs/core/langchain_core/prompts/few_shot_with_templates.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "156:         return DEFAULT_FORMATTER_MAPPING[self.template_format](template, **kwargs)",
          "158:     async def aformat(self, **kwargs: Any) -> str:",
          "159:         kwargs = self._merge_partial_and_user_variables(**kwargs)",
          "160:         # Get the examples to use.",
          "161:         examples = await self._aget_examples(**kwargs)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "159:         \"\"\"Async format the prompt with the inputs.",
          "161:         Args:",
          "162:             kwargs: Any arguments to be passed to the prompt template.",
          "164:         Returns:",
          "165:             A formatted string.",
          "166:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "197:         return \"few_shot_with_templates\"",
          "199:     def save(self, file_path: Union[Path, str]) -> None:",
          "200:         if self.example_selector:",
          "201:             raise ValueError(\"Saving an example selector is not currently supported\")",
          "202:         return super().save(file_path)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "208:         \"\"\"Save the prompt to a file.",
          "210:         Args:",
          "211:             file_path: The path to save the prompt to.",
          "213:         Raises:",
          "214:             ValueError: If example_selector is provided.",
          "215:         \"\"\"",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/prompts/image.py||libs/core/langchain_core/prompts/image.py": [
          "File: libs/core/langchain_core/prompts/image.py -> libs/core/langchain_core/prompts/image.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "37:         return [\"langchain\", \"prompts\", \"image\"]",
          "39:     def format_prompt(self, **kwargs: Any) -> PromptValue:",
          "40:         return ImagePromptValue(image_url=self.format(**kwargs))",
          "42:     async def aformat_prompt(self, **kwargs: Any) -> PromptValue:",
          "43:         return ImagePromptValue(image_url=await self.aformat(**kwargs))",
          "45:     def format(",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "40:         \"\"\"Format the prompt with the inputs.",
          "42:         Args:",
          "43:             kwargs: Any arguments to be passed to the prompt template.",
          "45:         Returns:",
          "46:             A formatted string.",
          "47:         \"\"\"",
          "51:         \"\"\"Async format the prompt with the inputs.",
          "53:         Args:",
          "54:             kwargs: Any arguments to be passed to the prompt template.",
          "56:         Returns:",
          "57:             A formatted string.",
          "58:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "54:         Returns:",
          "55:             A formatted string.",
          "57:         Example:",
          "59:             .. code-block:: python",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "73:         Raises:",
          "74:             ValueError: If the url or path is not provided.",
          "75:             ValueError: If the path or url is not a string.",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "84:         return output",
          "86:     async def aformat(self, **kwargs: Any) -> ImageURL:",
          "87:         return await run_in_executor(None, self.format, **kwargs)",
          "89:     def pretty_repr(self, html: bool = False) -> str:",
          "90:         raise NotImplementedError()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "107:         \"\"\"Async format the prompt with the inputs.",
          "109:         Args:",
          "110:             kwargs: Any arguments to be passed to the prompt template.",
          "112:         Returns:",
          "113:             A formatted string.",
          "115:         Raises:",
          "116:             ValueError: If the url or path is not provided.",
          "117:             ValueError: If the path or url is not a string.",
          "118:         \"\"\"",
          "122:         \"\"\"Return a pretty representation of the prompt.",
          "124:         Args:",
          "125:             html: Whether to return an html formatted string.",
          "127:         Returns:",
          "128:             A pretty representation of the prompt.",
          "129:         \"\"\"",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/prompts/loading.py||libs/core/langchain_core/prompts/loading.py": [
          "File: libs/core/langchain_core/prompts/loading.py -> libs/core/langchain_core/prompts/loading.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: def load_prompt_from_config(config: dict) -> BasePromptTemplate:",
          "22:     if \"_type\" not in config:",
          "23:         logger.warning(\"No `_type` key found, defaulting to `prompt`.\")",
          "24:     config_type = config.pop(\"_type\", \"prompt\")",
          "",
          "[Removed Lines]",
          "21:     \"\"\"Load prompt from Config Dict.\"\"\"",
          "",
          "[Added Lines]",
          "21:     \"\"\"Load prompt from Config Dict.",
          "23:     Args:",
          "24:         config: Dict containing the prompt configuration.",
          "26:     Returns:",
          "27:         A PromptTemplate object.",
          "29:     Raises:",
          "30:         ValueError: If the prompt type is not supported.",
          "31:     \"\"\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "128: def load_prompt(",
          "129:     path: Union[str, Path], encoding: Optional[str] = None",
          "130: ) -> BasePromptTemplate:",
          "132:     if isinstance(path, str) and path.startswith(\"lc://\"):",
          "133:         raise RuntimeError(",
          "134:             \"Loading from the deprecated github-based Hub is no longer supported. \"",
          "",
          "[Removed Lines]",
          "131:     \"\"\"Unified method for loading a prompt from LangChainHub or local fs.\"\"\"",
          "",
          "[Added Lines]",
          "141:     \"\"\"Unified method for loading a prompt from LangChainHub or local fs.",
          "143:     Args:",
          "144:         path: Path to the prompt file.",
          "145:         encoding: Encoding of the file. Defaults to None.",
          "147:     Returns:",
          "148:         A PromptTemplate object.",
          "150:     Raises:",
          "151:         RuntimeError: If the path is a Lang Chain Hub path.",
          "152:     \"\"\"",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/prompts/pipeline.py||libs/core/langchain_core/prompts/pipeline.py": [
          "File: libs/core/langchain_core/prompts/pipeline.py -> libs/core/langchain_core/prompts/pipeline.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "14:     \"\"\"Prompt template for composing multiple prompt templates together.",
          "16:     This can be useful when you want to reuse parts of prompts.",
          "17:     A PipelinePrompt consists of two main parts:",
          "18:         - final_prompt: This is the final prompt that is returned",
          "19:         - pipeline_prompts: This is a list of tuples, consisting",
          "24:     \"\"\"",
          "26:     final_prompt: BasePromptTemplate",
          "",
          "[Removed Lines]",
          "20:             of a string (`name`) and a Prompt Template.",
          "21:             Each PromptTemplate will be formatted and then passed",
          "22:             to future prompt templates as a variable with",
          "23:             the same name as `name`",
          "",
          "[Added Lines]",
          "21:           of a string (`name`) and a Prompt Template.",
          "22:           Each PromptTemplate will be formatted and then passed",
          "23:           to future prompt templates as a variable with",
          "24:           the same name as `name`",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "45:         return values",
          "47:     def format_prompt(self, **kwargs: Any) -> PromptValue:",
          "48:         for k, prompt in self.pipeline_prompts:",
          "49:             _inputs = _get_inputs(kwargs, prompt.input_variables)",
          "50:             if isinstance(prompt, BaseChatPromptTemplate):",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "49:         \"\"\"Format the prompt with the inputs.",
          "51:         Args:",
          "52:             kwargs: Any arguments to be passed to the prompt template.",
          "54:         Returns:",
          "55:             A formatted string.",
          "56:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "55:         return self.final_prompt.format_prompt(**_inputs)",
          "57:     async def aformat_prompt(self, **kwargs: Any) -> PromptValue:",
          "58:         for k, prompt in self.pipeline_prompts:",
          "59:             _inputs = _get_inputs(kwargs, prompt.input_variables)",
          "60:             if isinstance(prompt, BaseChatPromptTemplate):",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "67:         \"\"\"Async format the prompt with the inputs.",
          "69:         Args:",
          "70:             kwargs: Any arguments to be passed to the prompt template.",
          "72:         Returns:",
          "73:             A formatted string.",
          "74:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "65:         return await self.final_prompt.aformat_prompt(**_inputs)",
          "67:     def format(self, **kwargs: Any) -> str:",
          "68:         return self.format_prompt(**kwargs).to_string()",
          "70:     async def aformat(self, **kwargs: Any) -> str:",
          "71:         return (await self.aformat_prompt(**kwargs)).to_string()",
          "73:     @property",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "85:         \"\"\"Format the prompt with the inputs.",
          "87:         Args:",
          "88:             kwargs: Any arguments to be passed to the prompt template.",
          "90:         Returns:",
          "91:             A formatted string.",
          "92:         \"\"\"",
          "96:         \"\"\"Async format the prompt with the inputs.",
          "98:         Args:",
          "99:             kwargs: Any arguments to be passed to the prompt template.",
          "101:         Returns:",
          "102:             A formatted string.",
          "103:         \"\"\"",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/prompts/prompt.py||libs/core/langchain_core/prompts/prompt.py": [
          "File: libs/core/langchain_core/prompts/prompt.py -> libs/core/langchain_core/prompts/prompt.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "26:     The template can be formatted using either f-strings (default) or jinja2 syntax.",
          "29:         `template_format=\"jinja2\"`, or make sure to NEVER accept jinja2 templates",
          "30:         from untrusted sources as they may lead to arbitrary Python code execution.",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "29:         Prefer using `template_format=\"f-string\"` instead of",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "110:         return values",
          "112:     def get_input_schema(self, config: RunnableConfig | None = None) -> type[BaseModel]:",
          "113:         if self.template_format != \"mustache\":",
          "114:             return super().get_input_schema(config)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "114:         \"\"\"Get the input schema for the prompt.",
          "116:         Args:",
          "117:             config: The runnable configuration.",
          "119:         Returns:",
          "120:             The input schema for the prompt.",
          "121:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "158:         return \"prompt\"",
          "160:     def format(self, **kwargs: Any) -> str:",
          "161:         kwargs = self._merge_partial_and_user_variables(**kwargs)",
          "162:         return DEFAULT_FORMATTER_MAPPING[self.template_format](self.template, **kwargs)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "170:         \"\"\"Format the prompt with the inputs.",
          "172:         Args:",
          "173:             kwargs: Any arguments to be passed to the prompt template.",
          "175:         Returns:",
          "176:             A formatted string.",
          "177:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "204:         Args:",
          "205:             template_file: The path to the file containing the prompt template.",
          "206:             input_variables: [DEPRECATED] A list of variable names the final prompt",
          "209:         input_variables is ignored as from_file now delegates to from_template().",
          "",
          "[Removed Lines]",
          "207:                 template will expect.",
          "",
          "[Added Lines]",
          "224:                 template will expect. Defaults to None.",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "230:     ) -> PromptTemplate:",
          "231:         \"\"\"Load a prompt template from a template.",
          "234:             `template_format=\"jinja2\"`, or make sure to NEVER accept jinja2 templates",
          "235:             from untrusted sources as they may lead to arbitrary Python code execution.",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "251:             Prefer using `template_format=\"f-string\"` instead of",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "239:             be treated as a best-effort approach rather than a guarantee of security,",
          "240:             as it is an opt-out rather than opt-in approach.",
          "243:             from untrusted sources.",
          "245:         Args:",
          "246:             template: The template to load.",
          "247:             template_format: The format of the template. Use `jinja2` for jinja2,",
          "248:                              and `f-string` or None for f-strings.",
          "249:             partial_variables: A dictionary of variables that can be used to partially",
          "250:                                fill in the template. For example, if the template is",
          "251:                               `\"{variable1} {variable2}\"`, and `partial_variables` is",
          "252:                               `{\"variable1\": \"foo\"}`, then the final prompt will be",
          "255:         Returns:",
          "256:             The prompt template loaded from the template.",
          "",
          "[Removed Lines]",
          "242:             Despite the sand-boxing, we recommend to never use jinja2 templates",
          "253:                               `\"foo {variable2}\"`.",
          "",
          "[Added Lines]",
          "260:             Despite the sand-boxing, we recommend never using jinja2 templates",
          "267:                              Defaults to `f-string`.",
          "272:                               `\"foo {variable2}\"`. Defaults to None.",
          "273:             kwargs: Any other arguments to pass to the prompt template.",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/prompts/string.py||libs/core/langchain_core/prompts/string.py": [
          "File: libs/core/langchain_core/prompts/string.py -> libs/core/langchain_core/prompts/string.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "19: def jinja2_formatter(template: str, **kwargs: Any) -> str:",
          "20:     \"\"\"Format a template using jinja2.",
          "23:         SandboxedEnvironment by default. However, this sand-boxing should",
          "24:         be treated as a best-effort approach rather than a guarantee of security.",
          "25:         Do not accept jinja2 templates from untrusted sources as they may lead",
          "26:         to arbitrary Python code execution.",
          "28:         https://jinja.palletsprojects.com/en/3.1.x/sandbox/",
          "29:     \"\"\"",
          "30:     try:",
          "31:         from jinja2.sandbox import SandboxedEnvironment",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "23:         As of LangChain 0.0.329, this method uses Jinja2's",
          "31:     Args:",
          "32:         template: The template string.",
          "35:     Returns:",
          "36:         The formatted string.",
          "38:     Raises:",
          "39:         ImportError: If jinja2 is not installed.",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "90: def mustache_formatter(template: str, **kwargs: Any) -> str:",
          "92:     return mustache.render(template, kwargs)",
          "95: def mustache_template_vars(",
          "96:     template: str,",
          "97: ) -> Set[str]:",
          "99:     vars: Set[str] = set()",
          "100:     section_depth = 0",
          "101:     for type, key in mustache.tokenize(template):",
          "",
          "[Removed Lines]",
          "91:     \"\"\"Format a template using mustache.\"\"\"",
          "98:     \"\"\"Get the variables from a mustache template.\"\"\"",
          "",
          "[Added Lines]",
          "102:     \"\"\"Format a template using mustache.",
          "104:     Args:",
          "105:         template: The template string.",
          "108:     Returns:",
          "109:         The formatted string.",
          "110:     \"\"\"",
          "117:     \"\"\"Get the variables from a mustache template.",
          "119:     Args:",
          "120:         template: The template string.",
          "122:     Returns:",
          "123:         The variables from the template.",
          "124:     \"\"\"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "118: def mustache_schema(",
          "119:     template: str,",
          "120: ) -> Type[BaseModel]:",
          "122:     fields = {}",
          "123:     prefix: Tuple[str, ...] = ()",
          "124:     section_stack: List[Tuple[str, ...]] = []",
          "",
          "[Removed Lines]",
          "121:     \"\"\"Get the variables from a mustache template.\"\"\"",
          "",
          "[Added Lines]",
          "147:     \"\"\"Get the variables from a mustache template.",
          "149:     Args:",
          "150:         template: The template string.",
          "152:     Returns:",
          "153:         The variables from the template as a Pydantic model.",
          "154:     \"\"\"",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "179:     Raises:",
          "180:         ValueError: If the template format is not supported.",
          "181:     \"\"\"",
          "182:     try:",
          "183:         validator_func = DEFAULT_VALIDATOR_MAPPING[template_format]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "214:         ValueError: If the prompt schema is invalid.",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "232:         return [\"langchain\", \"prompts\", \"base\"]",
          "234:     def format_prompt(self, **kwargs: Any) -> PromptValue:",
          "235:         return StringPromptValue(text=self.format(**kwargs))",
          "237:     async def aformat_prompt(self, **kwargs: Any) -> PromptValue:",
          "238:         return StringPromptValue(text=await self.aformat(**kwargs))",
          "240:     def pretty_repr(self, html: bool = False) -> str:",
          "241:         # TODO: handle partials",
          "242:         dummy_vars = {",
          "243:             input_var: \"{\" + f\"{input_var}\" + \"}\" for input_var in self.input_variables",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "269:         \"\"\"Format the prompt with the inputs.",
          "271:         Args:",
          "272:             kwargs: Any arguments to be passed to the prompt template.",
          "274:         Returns:",
          "275:             A formatted string.",
          "276:         \"\"\"",
          "280:         \"\"\"Async format the prompt with the inputs.",
          "282:         Args:",
          "283:             kwargs: Any arguments to be passed to the prompt template.",
          "285:         Returns:",
          "286:             A formatted string.",
          "287:         \"\"\"",
          "291:         \"\"\"Get a pretty representation of the prompt.",
          "293:         Args:",
          "294:             html: Whether to return an HTML-formatted string.",
          "296:         Returns:",
          "297:             A pretty representation of the prompt.",
          "298:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "249:         return self.format(**dummy_vars)",
          "251:     def pretty_print(self) -> None:",
          "252:         print(self.pretty_repr(html=is_interactive_env()))  # noqa: T201",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "310:         \"\"\"Print a pretty representation of the prompt.\"\"\"",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/prompts/structured.py||libs/core/langchain_core/prompts/structured.py": [
          "File: libs/core/langchain_core/prompts/structured.py -> libs/core/langchain_core/prompts/structured.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "139:         name: Optional[str] = None,",
          "140:     ) -> RunnableSerializable[Dict, Other]:",
          "141:         if (",
          "142:             others",
          "143:             and isinstance(others[0], BaseLanguageModel)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "141:         \"\"\"Pipe the structured prompt to a language model.",
          "143:         Args:",
          "144:             others: The language model to pipe the structured prompt to.",
          "145:             name: The name of the pipeline. Defaults to None.",
          "147:         Returns:",
          "148:             A RunnableSequence object.",
          "150:         Raises:",
          "151:             NotImplementedError: If the first element of `others`",
          "152:             is not a language model.",
          "153:         \"\"\"",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "38425c99d22ba88b27657722dcf1db1f8027737d",
      "candidate_info": {
        "commit_hash": "38425c99d22ba88b27657722dcf1db1f8027737d",
        "repo": "langchain-ai/langchain",
        "commit_url": "https://github.com/langchain-ai/langchain/commit/38425c99d22ba88b27657722dcf1db1f8027737d",
        "files": [
          "libs/core/langchain_core/prompt_values.py",
          "libs/core/langchain_core/prompts/base.py",
          "libs/core/langchain_core/prompts/chat.py",
          "libs/core/langchain_core/prompts/image.py",
          "libs/core/langchain_core/utils/__init__.py",
          "libs/core/langchain_core/utils/image.py",
          "libs/core/tests/unit_tests/prompts/test_chat.py",
          "libs/core/tests/unit_tests/utils/test_imports.py"
        ],
        "message": "core[minor]: Image prompt template (#14263)\n\nBuilds on Bagatur's (#13227). See unit test for example usage (below)\n\n```python\ndef test_chat_tmpl_from_messages_multipart_image() -> None:\n    base64_image = \"abcd123\"\n    other_base64_image = \"abcd123\"\n    template = ChatPromptTemplate.from_messages(\n        [\n            (\"system\", \"You are an AI assistant named {name}.\"),\n            (\n                \"human\",\n                [\n                    {\"type\": \"text\", \"text\": \"What's in this image?\"},\n                    # OAI supports all these structures today\n                    {\n                        \"type\": \"image_url\",\n                        \"image_url\": \"data:image/jpeg;base64,{my_image}\",\n                    },\n                    {\n                        \"type\": \"image_url\",\n                        \"image_url\": {\"url\": \"data:image/jpeg;base64,{my_image}\"},\n                    },\n                    {\"type\": \"image_url\", \"image_url\": \"{my_other_image}\"},\n                    {\n                        \"type\": \"image_url\",\n                        \"image_url\": {\"url\": \"{my_other_image}\", \"detail\": \"medium\"},\n                    },\n                    {\n                        \"type\": \"image_url\",\n                        \"image_url\": {\"url\": \"https://www.langchain.com/image.png\"},\n                    },\n                    {\n                        \"type\": \"image_url\",\n                        \"image_url\": {\"url\": \"data:image/jpeg;base64,foobar\"},\n                    },\n                ],\n            ),\n        ]\n    )\n    messages = template.format_messages(\n        name=\"R2D2\", my_image=base64_image, my_other_image=other_base64_image\n    )\n    expected = [\n        SystemMessage(content=\"You are an AI assistant named R2D2.\"),\n        HumanMessage(\n            content=[\n                {\"type\": \"text\", \"text\": \"What's in this image?\"},\n                {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"},\n                },\n                {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\n                        \"url\": f\"data:image/jpeg;base64,{other_base64_image}\"\n                    },\n                },\n                {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\"url\": f\"{other_base64_image}\"},\n                },\n                {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\n                        \"url\": f\"{other_base64_image}\",\n                        \"detail\": \"medium\",\n                    },\n                },\n                {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\"url\": \"https://www.langchain.com/image.png\"},\n                },\n                {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\"url\": \"data:image/jpeg;base64,foobar\"},\n                },\n            ]\n        ),\n    ]\n    assert messages == expected\n```\n\n---------\n\nCo-authored-by: Bagatur <baskaryan@gmail.com>\nCo-authored-by: Brace Sproul <braceasproul@gmail.com>",
        "before_after_code_files": [
          "libs/core/langchain_core/prompt_values.py||libs/core/langchain_core/prompt_values.py",
          "libs/core/langchain_core/prompts/base.py||libs/core/langchain_core/prompts/base.py",
          "libs/core/langchain_core/prompts/chat.py||libs/core/langchain_core/prompts/chat.py",
          "libs/core/langchain_core/prompts/image.py||libs/core/langchain_core/prompts/image.py",
          "libs/core/langchain_core/utils/__init__.py||libs/core/langchain_core/utils/__init__.py",
          "libs/core/langchain_core/utils/image.py||libs/core/langchain_core/utils/image.py",
          "libs/core/tests/unit_tests/prompts/test_chat.py||libs/core/tests/unit_tests/prompts/test_chat.py",
          "libs/core/tests/unit_tests/utils/test_imports.py||libs/core/tests/unit_tests/utils/test_imports.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "libs/core/langchain_core/prompts/image.py||libs/core/langchain_core/prompts/image.py",
            "libs/core/langchain_core/utils/image.py||libs/core/langchain_core/utils/image.py",
            "libs/core/tests/unit_tests/prompts/test_chat.py||libs/core/tests/unit_tests/prompts/test_chat.py"
          ],
          "candidate": [
            "libs/core/langchain_core/prompts/image.py||libs/core/langchain_core/prompts/image.py",
            "libs/core/langchain_core/utils/image.py||libs/core/langchain_core/utils/image.py",
            "libs/core/tests/unit_tests/prompts/test_chat.py||libs/core/tests/unit_tests/prompts/test_chat.py"
          ]
        }
      },
      "candidate_diff": {
        "libs/core/langchain_core/prompt_values.py||libs/core/langchain_core/prompt_values.py": [
          "File: libs/core/langchain_core/prompt_values.py -> libs/core/langchain_core/prompt_values.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "3: from abc import ABC, abstractmethod",
          "4: from typing import List, Literal, Sequence",
          "6: from langchain_core.load.serializable import Serializable",
          "7: from langchain_core.messages import (",
          "8:     AnyMessage,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "6: from typing_extensions import TypedDict",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "82:         return [\"langchain\", \"prompts\", \"chat\"]",
          "85: class ChatPromptValueConcrete(ChatPromptValue):",
          "86:     \"\"\"Chat prompt value which explicitly lists out the message types it accepts.",
          "87:     For use in external schemas.\"\"\"",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "87: class ImageURL(TypedDict, total=False):",
          "88:     detail: Literal[\"auto\", \"low\", \"high\"]",
          "89:     \"\"\"Specifies the detail level of the image.\"\"\"",
          "91:     url: str",
          "92:     \"\"\"Either a URL of the image or the base64 encoded image data.\"\"\"",
          "95: class ImagePromptValue(PromptValue):",
          "96:     \"\"\"Image prompt value.\"\"\"",
          "98:     image_url: ImageURL",
          "99:     \"\"\"Prompt image.\"\"\"",
          "100:     type: Literal[\"ImagePromptValue\"] = \"ImagePromptValue\"",
          "102:     def to_string(self) -> str:",
          "103:         \"\"\"Return prompt as string.\"\"\"",
          "104:         return self.image_url[\"url\"]",
          "106:     def to_messages(self) -> List[BaseMessage]:",
          "107:         \"\"\"Return prompt as messages.\"\"\"",
          "108:         return [HumanMessage(content=[self.image_url])]",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/prompts/base.py||libs/core/langchain_core/prompts/base.py": [
          "File: libs/core/langchain_core/prompts/base.py -> libs/core/langchain_core/prompts/base.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "8:     Any,",
          "9:     Callable,",
          "10:     Dict,",
          "11:     List,",
          "12:     Mapping,",
          "13:     Optional,",
          "14:     Type,",
          "15:     Union,",
          "16: )",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "11:     Generic,",
          "16:     TypeVar,",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "30:     from langchain_core.documents import Document",
          "34:     \"\"\"Base class for all prompt templates, returning a prompt.\"\"\"",
          "36:     input_variables: List[str]",
          "",
          "[Removed Lines]",
          "33: class BasePromptTemplate(RunnableSerializable[Dict, PromptValue], ABC):",
          "",
          "[Added Lines]",
          "35: FormatOutputType = TypeVar(\"FormatOutputType\")",
          "38: class BasePromptTemplate(",
          "39:     RunnableSerializable[Dict, PromptValue], Generic[FormatOutputType], ABC",
          "40: ):",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "142:         return {**partial_kwargs, **kwargs}",
          "144:     @abstractmethod",
          "146:         \"\"\"Format the prompt with the inputs.",
          "148:         Args:",
          "",
          "[Removed Lines]",
          "145:     def format(self, **kwargs: Any) -> str:",
          "",
          "[Added Lines]",
          "152:     def format(self, **kwargs: Any) -> FormatOutputType:",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "210:             raise ValueError(f\"{save_path} must be json or yaml\")",
          "214:     \"\"\"Format a document into a string based on a prompt template.",
          "216:     First, this pulls information from the document from two sources:",
          "",
          "[Removed Lines]",
          "213: def format_document(doc: Document, prompt: BasePromptTemplate) -> str:",
          "",
          "[Added Lines]",
          "220: def format_document(doc: Document, prompt: BasePromptTemplate[str]) -> str:",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "236:     Example:",
          "237:         .. code-block:: python",
          "240:             from langchain_core.prompts import PromptTemplate",
          "242:             doc = Document(page_content=\"This is a joke\", metadata={\"page\": \"1\"})",
          "",
          "[Removed Lines]",
          "239:             from langchain_core import Document",
          "",
          "[Added Lines]",
          "246:             from langchain_core.documents import Document",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/prompts/chat.py||libs/core/langchain_core/prompts/chat.py": [
          "File: libs/core/langchain_core/prompts/chat.py -> libs/core/langchain_core/prompts/chat.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "13:     Set,",
          "14:     Tuple,",
          "15:     Type,",
          "16:     TypeVar,",
          "17:     Union,",
          "18:     overload,",
          "19: )",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "16:     TypedDict,",
          "19:     cast,",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "30:     convert_to_messages,",
          "31: )",
          "32: from langchain_core.messages.base import get_msg_title_repr",
          "34: from langchain_core.prompts.base import BasePromptTemplate",
          "35: from langchain_core.prompts.prompt import PromptTemplate",
          "37: from langchain_core.pydantic_v1 import Field, root_validator",
          "38: from langchain_core.utils import get_colored_text",
          "39: from langchain_core.utils.interactive_env import is_interactive_env",
          "",
          "[Removed Lines]",
          "33: from langchain_core.prompt_values import ChatPromptValue, PromptValue",
          "36: from langchain_core.prompts.string import StringPromptTemplate",
          "",
          "[Added Lines]",
          "35: from langchain_core.prompt_values import ChatPromptValue, ImageURL, PromptValue",
          "37: from langchain_core.prompts.image import ImagePromptTemplate",
          "39: from langchain_core.prompts.string import StringPromptTemplate, get_template_variables",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "288:         )",
          "292:     \"\"\"Human message prompt template. This is a message sent from the user.\"\"\"",
          "294:     @classmethod",
          "295:     def get_lc_namespace(cls) -> List[str]:",
          "296:         \"\"\"Get the namespace of the langchain object.\"\"\"",
          "297:         return [\"langchain\", \"prompts\", \"chat\"]",
          "302:         Args:",
          "305:         Returns:",
          "307:         \"\"\"",
          "320:     def format(self, **kwargs: Any) -> BaseMessage:",
          "321:         \"\"\"Format the prompt template.",
          "",
          "[Removed Lines]",
          "291: class HumanMessagePromptTemplate(BaseStringMessagePromptTemplate):",
          "299:     def format(self, **kwargs: Any) -> BaseMessage:",
          "300:         \"\"\"Format the prompt template.",
          "306:             Formatted message.",
          "308:         text = self.prompt.format(**kwargs)",
          "309:         return HumanMessage(content=text, additional_kwargs=self.additional_kwargs)",
          "312: class AIMessagePromptTemplate(BaseStringMessagePromptTemplate):",
          "313:     \"\"\"AI message prompt template. This is a message sent from the AI.\"\"\"",
          "315:     @classmethod",
          "316:     def get_lc_namespace(cls) -> List[str]:",
          "317:         \"\"\"Get the namespace of the langchain object.\"\"\"",
          "318:         return [\"langchain\", \"prompts\", \"chat\"]",
          "",
          "[Added Lines]",
          "294: _StringImageMessagePromptTemplateT = TypeVar(",
          "295:     \"_StringImageMessagePromptTemplateT\", bound=\"_StringImageMessagePromptTemplate\"",
          "296: )",
          "299: class _TextTemplateParam(TypedDict, total=False):",
          "300:     text: Union[str, Dict]",
          "303: class _ImageTemplateParam(TypedDict, total=False):",
          "304:     image_url: Union[str, Dict]",
          "307: class _StringImageMessagePromptTemplate(BaseMessagePromptTemplate):",
          "310:     prompt: Union[",
          "311:         StringPromptTemplate, List[Union[StringPromptTemplate, ImagePromptTemplate]]",
          "312:     ]",
          "313:     \"\"\"Prompt template.\"\"\"",
          "314:     additional_kwargs: dict = Field(default_factory=dict)",
          "315:     \"\"\"Additional keyword arguments to pass to the prompt template.\"\"\"",
          "317:     _msg_class: Type[BaseMessage]",
          "324:     @classmethod",
          "325:     def from_template(",
          "326:         cls: Type[_StringImageMessagePromptTemplateT],",
          "327:         template: Union[str, List[Union[str, _TextTemplateParam, _ImageTemplateParam]]],",
          "328:         template_format: str = \"f-string\",",
          "330:     ) -> _StringImageMessagePromptTemplateT:",
          "331:         \"\"\"Create a class from a string template.",
          "334:             template: a template.",
          "335:             template_format: format of the template.",
          "339:             A new instance of this class.",
          "341:         if isinstance(template, str):",
          "342:             prompt: Union[StringPromptTemplate, List] = PromptTemplate.from_template(",
          "343:                 template, template_format=template_format",
          "344:             )",
          "345:             return cls(prompt=prompt, **kwargs)",
          "346:         elif isinstance(template, list):",
          "347:             prompt = []",
          "348:             for tmpl in template:",
          "349:                 if isinstance(tmpl, str) or isinstance(tmpl, dict) and \"text\" in tmpl:",
          "350:                     if isinstance(tmpl, str):",
          "351:                         text: str = tmpl",
          "352:                     else:",
          "353:                         text = cast(_TextTemplateParam, tmpl)[\"text\"]  # type: ignore[assignment]  # noqa: E501",
          "354:                     prompt.append(",
          "355:                         PromptTemplate.from_template(",
          "356:                             text, template_format=template_format",
          "357:                         )",
          "358:                     )",
          "359:                 elif isinstance(tmpl, dict) and \"image_url\" in tmpl:",
          "360:                     img_template = cast(_ImageTemplateParam, tmpl)[\"image_url\"]",
          "361:                     if isinstance(img_template, str):",
          "362:                         vars = get_template_variables(img_template, \"f-string\")",
          "363:                         if vars:",
          "364:                             if len(vars) > 1:",
          "365:                                 raise ValueError(",
          "366:                                     \"Only one format variable allowed per image\"",
          "367:                                     f\" template.\\nGot: {vars}\"",
          "368:                                     f\"\\nFrom: {tmpl}\"",
          "369:                                 )",
          "370:                             input_variables = [vars[0]]",
          "371:                         else:",
          "372:                             input_variables = None",
          "373:                         img_template = {\"url\": img_template}",
          "374:                         img_template_obj = ImagePromptTemplate(",
          "375:                             input_variables=input_variables, template=img_template",
          "376:                         )",
          "377:                     elif isinstance(img_template, dict):",
          "378:                         img_template = dict(img_template)",
          "379:                         if \"url\" in img_template:",
          "380:                             input_variables = get_template_variables(",
          "381:                                 img_template[\"url\"], \"f-string\"",
          "382:                             )",
          "383:                         else:",
          "384:                             input_variables = None",
          "385:                         img_template_obj = ImagePromptTemplate(",
          "386:                             input_variables=input_variables, template=img_template",
          "387:                         )",
          "388:                     else:",
          "389:                         raise ValueError()",
          "390:                     prompt.append(img_template_obj)",
          "391:                 else:",
          "392:                     raise ValueError()",
          "393:             return cls(prompt=prompt, **kwargs)",
          "394:         else:",
          "395:             raise ValueError()",
          "397:     @classmethod",
          "398:     def from_template_file(",
          "399:         cls: Type[_StringImageMessagePromptTemplateT],",
          "400:         template_file: Union[str, Path],",
          "401:         input_variables: List[str],",
          "403:     ) -> _StringImageMessagePromptTemplateT:",
          "404:         \"\"\"Create a class from a template file.",
          "406:         Args:",
          "407:             template_file: path to a template file. String or Path.",
          "408:             input_variables: list of input variables.",
          "411:         Returns:",
          "412:             A new instance of this class.",
          "413:         \"\"\"",
          "414:         with open(str(template_file), \"r\") as f:",
          "415:             template = f.read()",
          "416:         return cls.from_template(template, input_variables=input_variables, **kwargs)",
          "418:     def format_messages(self, **kwargs: Any) -> List[BaseMessage]:",
          "419:         \"\"\"Format messages from kwargs.",
          "421:         Args:",
          "424:         Returns:",
          "425:             List of BaseMessages.",
          "426:         \"\"\"",
          "427:         return [self.format(**kwargs)]",
          "429:     @property",
          "430:     def input_variables(self) -> List[str]:",
          "431:         \"\"\"",
          "432:         Input variables for this prompt template.",
          "434:         Returns:",
          "435:             List of input variable names.",
          "436:         \"\"\"",
          "437:         prompts = self.prompt if isinstance(self.prompt, list) else [self.prompt]",
          "438:         input_variables = [iv for prompt in prompts for iv in prompt.input_variables]",
          "439:         return input_variables",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "326:         Returns:",
          "327:             Formatted message.",
          "328:         \"\"\"",
          "338:     @classmethod",
          "339:     def get_lc_namespace(cls) -> List[str]:",
          "340:         \"\"\"Get the namespace of the langchain object.\"\"\"",
          "341:         return [\"langchain\", \"prompts\", \"chat\"]",
          "356: class BaseChatPromptTemplate(BasePromptTemplate, ABC):",
          "",
          "[Removed Lines]",
          "329:         text = self.prompt.format(**kwargs)",
          "330:         return AIMessage(content=text, additional_kwargs=self.additional_kwargs)",
          "333: class SystemMessagePromptTemplate(BaseStringMessagePromptTemplate):",
          "334:     \"\"\"System message prompt template.",
          "335:     This is a message that is not sent to the user.",
          "336:     \"\"\"",
          "343:     def format(self, **kwargs: Any) -> BaseMessage:",
          "344:         \"\"\"Format the prompt template.",
          "346:         Args:",
          "349:         Returns:",
          "350:             Formatted message.",
          "351:         \"\"\"",
          "352:         text = self.prompt.format(**kwargs)",
          "353:         return SystemMessage(content=text, additional_kwargs=self.additional_kwargs)",
          "",
          "[Added Lines]",
          "450:         if isinstance(self.prompt, StringPromptTemplate):",
          "451:             text = self.prompt.format(**kwargs)",
          "452:             return self._msg_class(",
          "453:                 content=text, additional_kwargs=self.additional_kwargs",
          "454:             )",
          "455:         else:",
          "456:             content = []",
          "457:             for prompt in self.prompt:",
          "458:                 inputs = {var: kwargs[var] for var in prompt.input_variables}",
          "459:                 if isinstance(prompt, StringPromptTemplate):",
          "460:                     formatted: Union[str, ImageURL] = prompt.format(**inputs)",
          "461:                     content.append({\"type\": \"text\", \"text\": formatted})",
          "462:                 elif isinstance(prompt, ImagePromptTemplate):",
          "463:                     formatted = prompt.format(**inputs)",
          "464:                     content.append({\"type\": \"image_url\", \"image_url\": formatted})",
          "465:             return self._msg_class(",
          "466:                 content=content, additional_kwargs=self.additional_kwargs",
          "467:             )",
          "470: class HumanMessagePromptTemplate(_StringImageMessagePromptTemplate):",
          "471:     \"\"\"Human message prompt template. This is a message sent from the user.\"\"\"",
          "473:     _msg_class: Type[BaseMessage] = HumanMessage",
          "476: class AIMessagePromptTemplate(_StringImageMessagePromptTemplate):",
          "477:     \"\"\"AI message prompt template. This is a message sent from the AI.\"\"\"",
          "479:     _msg_class: Type[BaseMessage] = AIMessage",
          "487: class SystemMessagePromptTemplate(_StringImageMessagePromptTemplate):",
          "488:     \"\"\"System message prompt template.",
          "489:     This is a message that is not sent to the user.",
          "490:     \"\"\"",
          "492:     _msg_class: Type[BaseMessage] = SystemMessage",
          "494:     @classmethod",
          "495:     def get_lc_namespace(cls) -> List[str]:",
          "496:         \"\"\"Get the namespace of the langchain object.\"\"\"",
          "497:         return [\"langchain\", \"prompts\", \"chat\"]",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "406: MessageLikeRepresentation = Union[",
          "407:     MessageLike,",
          "410:     str,",
          "411: ]",
          "",
          "[Removed Lines]",
          "408:     Tuple[str, str],",
          "409:     Tuple[Type, str],",
          "",
          "[Added Lines]",
          "552:     Tuple[Union[str, Type], Union[str, List[dict], List[object]]],",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "740: def _create_template_from_message_type(",
          "742: ) -> BaseMessagePromptTemplate:",
          "743:     \"\"\"Create a message prompt template from a message type and template string.",
          "",
          "[Removed Lines]",
          "741:     message_type: str, template: str",
          "",
          "[Added Lines]",
          "884:     message_type: str, template: Union[str, list]",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "754:             template",
          "755:         )",
          "756:     elif message_type in (\"ai\", \"assistant\"):",
          "758:     elif message_type == \"system\":",
          "760:     else:",
          "761:         raise ValueError(",
          "762:             f\"Unexpected message type: {message_type}. Use one of 'human',\"",
          "",
          "[Removed Lines]",
          "757:         message = AIMessagePromptTemplate.from_template(template)",
          "759:         message = SystemMessagePromptTemplate.from_template(template)",
          "",
          "[Added Lines]",
          "900:         message = AIMessagePromptTemplate.from_template(cast(str, template))",
          "902:         message = SystemMessagePromptTemplate.from_template(cast(str, template))",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "799:         if isinstance(message_type_str, str):",
          "800:             _message = _create_template_from_message_type(message_type_str, template)",
          "801:         else:",
          "803:     else:",
          "804:         raise NotImplementedError(f\"Unsupported message type: {type(message)}\")",
          "",
          "[Removed Lines]",
          "802:             _message = message_type_str(prompt=PromptTemplate.from_template(template))",
          "",
          "[Added Lines]",
          "945:             _message = message_type_str(",
          "946:                 prompt=PromptTemplate.from_template(cast(str, template))",
          "947:             )",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/prompts/image.py||libs/core/langchain_core/prompts/image.py": [
          "File: libs/core/langchain_core/prompts/image.py -> libs/core/langchain_core/prompts/image.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: from typing import Any",
          "3: from langchain_core.prompt_values import ImagePromptValue, ImageURL, PromptValue",
          "4: from langchain_core.prompts.base import BasePromptTemplate",
          "5: from langchain_core.pydantic_v1 import Field",
          "6: from langchain_core.utils import image as image_utils",
          "9: class ImagePromptTemplate(BasePromptTemplate[ImageURL]):",
          "10:     \"\"\"An image prompt template for a multimodal model.\"\"\"",
          "12:     template: dict = Field(default_factory=dict)",
          "13:     \"\"\"Template for the prompt.\"\"\"",
          "15:     def __init__(self, **kwargs: Any) -> None:",
          "16:         if \"input_variables\" not in kwargs:",
          "17:             kwargs[\"input_variables\"] = []",
          "19:         overlap = set(kwargs[\"input_variables\"]) & set((\"url\", \"path\", \"detail\"))",
          "20:         if overlap:",
          "21:             raise ValueError(",
          "22:                 \"input_variables for the image template cannot contain\"",
          "23:                 \" any of 'url', 'path', or 'detail'.\"",
          "24:                 f\" Found: {overlap}\"",
          "25:             )",
          "26:         super().__init__(**kwargs)",
          "28:     @property",
          "29:     def _prompt_type(self) -> str:",
          "30:         \"\"\"Return the prompt type key.\"\"\"",
          "31:         return \"image-prompt\"",
          "33:     def format_prompt(self, **kwargs: Any) -> PromptValue:",
          "34:         \"\"\"Create Chat Messages.\"\"\"",
          "35:         return ImagePromptValue(image_url=self.format(**kwargs))",
          "37:     def format(",
          "38:         self,",
          "40:     ) -> ImageURL:",
          "41:         \"\"\"Format the prompt with the inputs.",
          "43:         Args:",
          "44:             kwargs: Any arguments to be passed to the prompt template.",
          "46:         Returns:",
          "47:             A formatted string.",
          "49:         Example:",
          "51:             .. code-block:: python",
          "53:                 prompt.format(variable1=\"foo\")",
          "54:         \"\"\"",
          "55:         formatted = {}",
          "56:         for k, v in self.template.items():",
          "57:             if isinstance(v, str):",
          "58:                 formatted[k] = v.format(**kwargs)",
          "59:             else:",
          "60:                 formatted[k] = v",
          "61:         url = kwargs.get(\"url\") or formatted.get(\"url\")",
          "62:         path = kwargs.get(\"path\") or formatted.get(\"path\")",
          "63:         detail = kwargs.get(\"detail\") or formatted.get(\"detail\")",
          "64:         if not url and not path:",
          "65:             raise ValueError(\"Must provide either url or path.\")",
          "66:         if not url:",
          "67:             if not isinstance(path, str):",
          "68:                 raise ValueError(\"path must be a string.\")",
          "69:             url = image_utils.image_to_data_url(path)",
          "70:         if not isinstance(url, str):",
          "71:             raise ValueError(\"url must be a string.\")",
          "72:         output: ImageURL = {\"url\": url}",
          "73:         if detail:",
          "74:             # Don't check literal values here: let the API check them",
          "75:             output[\"detail\"] = detail  # type: ignore[typeddict-item]",
          "76:         return output",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/utils/__init__.py||libs/core/langchain_core/utils/__init__.py": [
          "File: libs/core/langchain_core/utils/__init__.py -> libs/core/langchain_core/utils/__init__.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "4: These functions do not depend on any other LangChain module.",
          "5: \"\"\"",
          "7: from langchain_core.utils.env import get_from_dict_or_env, get_from_env",
          "8: from langchain_core.utils.formatting import StrictFormatter, formatter",
          "9: from langchain_core.utils.input import (",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "7: from langchain_core.utils import image",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "41:     \"xor_args\",",
          "42:     \"try_load_from_hub\",",
          "43:     \"build_extra_kwargs\",",
          "44:     \"get_from_env\",",
          "45:     \"get_from_dict_or_env\",",
          "46:     \"stringify_dict\",",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "45:     \"image\",",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/utils/image.py||libs/core/langchain_core/utils/image.py": [
          "File: libs/core/langchain_core/utils/image.py -> libs/core/langchain_core/utils/image.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: import base64",
          "2: import mimetypes",
          "5: def encode_image(image_path: str) -> str:",
          "6:     \"\"\"Get base64 string from image URI.\"\"\"",
          "7:     with open(image_path, \"rb\") as image_file:",
          "8:         return base64.b64encode(image_file.read()).decode(\"utf-8\")",
          "11: def image_to_data_url(image_path: str) -> str:",
          "12:     encoding = encode_image(image_path)",
          "13:     mime_type = mimetypes.guess_type(image_path)[0]",
          "14:     return f\"data:{mime_type};base64,{encoding}\"",
          "",
          "---------------"
        ],
        "libs/core/tests/unit_tests/prompts/test_chat.py||libs/core/tests/unit_tests/prompts/test_chat.py": [
          "File: libs/core/tests/unit_tests/prompts/test_chat.py -> libs/core/tests/unit_tests/prompts/test_chat.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "4: import pytest",
          "6: from langchain_core.messages import (",
          "7:     AIMessage,",
          "8:     BaseMessage,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "6: from langchain_core._api.deprecation import (",
          "7:     LangChainPendingDeprecationWarning,",
          "8: )",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "244: def test_chat_from_role_strings() -> None:",
          "245:     \"\"\"Test instantiation of chat template from role strings.\"\"\"",
          "255:     messages = template.format_messages(question=\"How are you?\", quack=\"duck\")",
          "256:     assert messages == [",
          "",
          "[Removed Lines]",
          "246:     template = ChatPromptTemplate.from_role_strings(",
          "247:         [",
          "248:             (\"system\", \"You are a bot.\"),",
          "249:             (\"assistant\", \"hello!\"),",
          "250:             (\"human\", \"{question}\"),",
          "251:             (\"other\", \"{quack}\"),",
          "252:         ]",
          "253:     )",
          "",
          "[Added Lines]",
          "249:     with pytest.warns(LangChainPendingDeprecationWarning):",
          "250:         template = ChatPromptTemplate.from_role_strings(",
          "251:             [",
          "252:                 (\"system\", \"You are a bot.\"),",
          "253:                 (\"assistant\", \"hello!\"),",
          "254:                 (\"human\", \"{question}\"),",
          "255:                 (\"other\", \"{quack}\"),",
          "256:             ]",
          "257:         )",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "363:     assert template2.format(input=\"hello\") == get_buffer_string(expected)",
          "366: def test_messages_placeholder() -> None:",
          "367:     prompt = MessagesPlaceholder(\"history\")",
          "368:     with pytest.raises(KeyError):",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "370: def test_chat_tmpl_from_messages_multipart_text() -> None:",
          "371:     template = ChatPromptTemplate.from_messages(",
          "372:         [",
          "373:             (\"system\", \"You are an AI assistant named {name}.\"),",
          "374:             (",
          "375:                 \"human\",",
          "376:                 [",
          "377:                     {\"type\": \"text\", \"text\": \"What's in this image?\"},",
          "378:                     {\"type\": \"text\", \"text\": \"Oh nvm\"},",
          "379:                 ],",
          "380:             ),",
          "381:         ]",
          "382:     )",
          "383:     messages = template.format_messages(name=\"R2D2\")",
          "384:     expected = [",
          "385:         SystemMessage(content=\"You are an AI assistant named R2D2.\"),",
          "386:         HumanMessage(",
          "387:             content=[",
          "388:                 {\"type\": \"text\", \"text\": \"What's in this image?\"},",
          "389:                 {\"type\": \"text\", \"text\": \"Oh nvm\"},",
          "390:             ]",
          "391:         ),",
          "392:     ]",
          "393:     assert messages == expected",
          "396: def test_chat_tmpl_from_messages_multipart_text_with_template() -> None:",
          "397:     template = ChatPromptTemplate.from_messages(",
          "398:         [",
          "399:             (\"system\", \"You are an AI assistant named {name}.\"),",
          "400:             (",
          "401:                 \"human\",",
          "402:                 [",
          "403:                     {\"type\": \"text\", \"text\": \"What's in this {object_name}?\"},",
          "404:                     {\"type\": \"text\", \"text\": \"Oh nvm\"},",
          "405:                 ],",
          "406:             ),",
          "407:         ]",
          "408:     )",
          "409:     messages = template.format_messages(name=\"R2D2\", object_name=\"image\")",
          "410:     expected = [",
          "411:         SystemMessage(content=\"You are an AI assistant named R2D2.\"),",
          "412:         HumanMessage(",
          "413:             content=[",
          "414:                 {\"type\": \"text\", \"text\": \"What's in this image?\"},",
          "415:                 {\"type\": \"text\", \"text\": \"Oh nvm\"},",
          "416:             ]",
          "417:         ),",
          "418:     ]",
          "419:     assert messages == expected",
          "422: def test_chat_tmpl_from_messages_multipart_image() -> None:",
          "423:     base64_image = \"iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAA\"",
          "424:     other_base64_image = \"iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAA\"",
          "425:     template = ChatPromptTemplate.from_messages(",
          "426:         [",
          "427:             (\"system\", \"You are an AI assistant named {name}.\"),",
          "428:             (",
          "429:                 \"human\",",
          "430:                 [",
          "431:                     {\"type\": \"text\", \"text\": \"What's in this image?\"},",
          "432:                     {",
          "433:                         \"type\": \"image_url\",",
          "434:                         \"image_url\": \"data:image/jpeg;base64,{my_image}\",",
          "435:                     },",
          "436:                     {",
          "437:                         \"type\": \"image_url\",",
          "438:                         \"image_url\": {\"url\": \"data:image/jpeg;base64,{my_image}\"},",
          "439:                     },",
          "440:                     {\"type\": \"image_url\", \"image_url\": \"{my_other_image}\"},",
          "441:                     {",
          "442:                         \"type\": \"image_url\",",
          "443:                         \"image_url\": {\"url\": \"{my_other_image}\", \"detail\": \"medium\"},",
          "444:                     },",
          "445:                     {",
          "446:                         \"type\": \"image_url\",",
          "447:                         \"image_url\": {\"url\": \"https://www.langchain.com/image.png\"},",
          "448:                     },",
          "449:                     {",
          "450:                         \"type\": \"image_url\",",
          "451:                         \"image_url\": {\"url\": \"data:image/jpeg;base64,foobar\"},",
          "452:                     },",
          "453:                 ],",
          "454:             ),",
          "455:         ]",
          "456:     )",
          "457:     messages = template.format_messages(",
          "458:         name=\"R2D2\", my_image=base64_image, my_other_image=other_base64_image",
          "459:     )",
          "460:     expected = [",
          "461:         SystemMessage(content=\"You are an AI assistant named R2D2.\"),",
          "462:         HumanMessage(",
          "463:             content=[",
          "464:                 {\"type\": \"text\", \"text\": \"What's in this image?\"},",
          "465:                 {",
          "466:                     \"type\": \"image_url\",",
          "467:                     \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"},",
          "468:                 },",
          "469:                 {",
          "470:                     \"type\": \"image_url\",",
          "471:                     \"image_url\": {",
          "472:                         \"url\": f\"data:image/jpeg;base64,{other_base64_image}\"",
          "473:                     },",
          "474:                 },",
          "475:                 {",
          "476:                     \"type\": \"image_url\",",
          "477:                     \"image_url\": {\"url\": f\"{other_base64_image}\"},",
          "478:                 },",
          "479:                 {",
          "480:                     \"type\": \"image_url\",",
          "481:                     \"image_url\": {",
          "482:                         \"url\": f\"{other_base64_image}\",",
          "483:                         \"detail\": \"medium\",",
          "484:                     },",
          "485:                 },",
          "486:                 {",
          "487:                     \"type\": \"image_url\",",
          "488:                     \"image_url\": {\"url\": \"https://www.langchain.com/image.png\"},",
          "489:                 },",
          "490:                 {",
          "491:                     \"type\": \"image_url\",",
          "492:                     \"image_url\": {\"url\": \"data:image/jpeg;base64,foobar\"},",
          "493:                 },",
          "494:             ]",
          "495:         ),",
          "496:     ]",
          "497:     assert messages == expected",
          "",
          "---------------"
        ],
        "libs/core/tests/unit_tests/utils/test_imports.py||libs/core/tests/unit_tests/utils/test_imports.py": [
          "File: libs/core/tests/unit_tests/utils/test_imports.py -> libs/core/tests/unit_tests/utils/test_imports.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "16:     \"xor_args\",",
          "17:     \"try_load_from_hub\",",
          "18:     \"build_extra_kwargs\",",
          "19:     \"get_from_dict_or_env\",",
          "20:     \"get_from_env\",",
          "21:     \"stringify_dict\",",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "19:     \"image\",",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "e4e2aa0b78e6662bb5cebb06b15c19ddbe96ae43",
      "candidate_info": {
        "commit_hash": "e4e2aa0b78e6662bb5cebb06b15c19ddbe96ae43",
        "repo": "langchain-ai/langchain",
        "commit_url": "https://github.com/langchain-ai/langchain/commit/e4e2aa0b78e6662bb5cebb06b15c19ddbe96ae43",
        "files": [
          "libs/core/langchain_core/utils/image.py"
        ],
        "message": "core[patch]: update image util err msg (#27803)",
        "before_after_code_files": [
          "libs/core/langchain_core/utils/image.py||libs/core/langchain_core/utils/image.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "libs/core/langchain_core/utils/image.py||libs/core/langchain_core/utils/image.py"
          ],
          "candidate": [
            "libs/core/langchain_core/utils/image.py||libs/core/langchain_core/utils/image.py"
          ]
        }
      },
      "candidate_diff": {
        "libs/core/langchain_core/utils/image.py||libs/core/langchain_core/utils/image.py": [
          "File: libs/core/langchain_core/utils/image.py -> libs/core/langchain_core/utils/image.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "4: def __getattr__(name: str) -> Any:",
          "5:     if name in (\"encode_image\", \"image_to_data_url\"):",
          "7:         raise ValueError(msg)",
          "8:     raise AttributeError(name)",
          "",
          "[Removed Lines]",
          "6:         msg = f\"'{name}' has been removed for security reasons.\"",
          "",
          "[Added Lines]",
          "6:         msg = (",
          "7:             f\"'{name}' has been removed for security reasons.\\n\\n\"",
          "8:             f\"Usage of this utility in environments with user-input paths is a \"",
          "9:             f\"security vulnerability. Out of an abundance of caution, the utility \"",
          "10:             f\"has been removed to prevent possible misuse.\"",
          "11:         )",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "36ee0837536d1164b80ae54f21c468fda86a4716",
      "candidate_info": {
        "commit_hash": "36ee0837536d1164b80ae54f21c468fda86a4716",
        "repo": "langchain-ai/langchain",
        "commit_url": "https://github.com/langchain-ai/langchain/commit/36ee0837536d1164b80ae54f21c468fda86a4716",
        "files": [
          "libs/core/langchain_core/utils/_merge.py",
          "libs/core/langchain_core/utils/aiter.py",
          "libs/core/langchain_core/utils/env.py",
          "libs/core/langchain_core/utils/formatting.py",
          "libs/core/langchain_core/utils/function_calling.py",
          "libs/core/langchain_core/utils/html.py",
          "libs/core/langchain_core/utils/image.py",
          "libs/core/langchain_core/utils/input.py",
          "libs/core/langchain_core/utils/iter.py",
          "libs/core/langchain_core/utils/json.py",
          "libs/core/langchain_core/utils/json_schema.py",
          "libs/core/langchain_core/utils/mustache.py",
          "libs/core/langchain_core/utils/pydantic.py",
          "libs/core/langchain_core/utils/strings.py",
          "libs/core/langchain_core/utils/utils.py"
        ],
        "message": "core: docstrings `utils` update (#24213)\n\nAdded missed docstrings. Formatted docstrings to the consistent form.",
        "before_after_code_files": [
          "libs/core/langchain_core/utils/_merge.py||libs/core/langchain_core/utils/_merge.py",
          "libs/core/langchain_core/utils/aiter.py||libs/core/langchain_core/utils/aiter.py",
          "libs/core/langchain_core/utils/env.py||libs/core/langchain_core/utils/env.py",
          "libs/core/langchain_core/utils/formatting.py||libs/core/langchain_core/utils/formatting.py",
          "libs/core/langchain_core/utils/function_calling.py||libs/core/langchain_core/utils/function_calling.py",
          "libs/core/langchain_core/utils/html.py||libs/core/langchain_core/utils/html.py",
          "libs/core/langchain_core/utils/image.py||libs/core/langchain_core/utils/image.py",
          "libs/core/langchain_core/utils/input.py||libs/core/langchain_core/utils/input.py",
          "libs/core/langchain_core/utils/iter.py||libs/core/langchain_core/utils/iter.py",
          "libs/core/langchain_core/utils/json.py||libs/core/langchain_core/utils/json.py",
          "libs/core/langchain_core/utils/json_schema.py||libs/core/langchain_core/utils/json_schema.py",
          "libs/core/langchain_core/utils/mustache.py||libs/core/langchain_core/utils/mustache.py",
          "libs/core/langchain_core/utils/pydantic.py||libs/core/langchain_core/utils/pydantic.py",
          "libs/core/langchain_core/utils/strings.py||libs/core/langchain_core/utils/strings.py",
          "libs/core/langchain_core/utils/utils.py||libs/core/langchain_core/utils/utils.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "libs/core/langchain_core/utils/image.py||libs/core/langchain_core/utils/image.py"
          ],
          "candidate": [
            "libs/core/langchain_core/utils/image.py||libs/core/langchain_core/utils/image.py"
          ]
        }
      },
      "candidate_diff": {
        "libs/core/langchain_core/utils/_merge.py||libs/core/langchain_core/utils/_merge.py": [
          "File: libs/core/langchain_core/utils/_merge.py -> libs/core/langchain_core/utils/_merge.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "8:     dictionaries but has a value of None in 'left'. In such cases, the method uses the",
          "9:     value from 'right' for that key in the merged dictionary.",
          "11:     Example:",
          "12:         If left = {\"function_call\": {\"arguments\": None}} and",
          "13:         right = {\"function_call\": {\"arguments\": \"{\\n\"}}",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "11:     Args:",
          "12:         left: The first dictionary to merge.",
          "13:         others: The other dictionaries to merge.",
          "15:     Returns:",
          "16:         The merged dictionary.",
          "18:     Raises:",
          "19:         TypeError: If the key exists in both dictionaries but has a different type.",
          "20:         TypeError: If the value has an unsupported type.",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "48: def merge_lists(left: Optional[List], *others: Optional[List]) -> Optional[List]:",
          "50:     merged = left.copy() if left is not None else None",
          "51:     for other in others:",
          "52:         if other is None:",
          "",
          "[Removed Lines]",
          "49:     \"\"\"Add many lists, handling None.\"\"\"",
          "",
          "[Added Lines]",
          "60:     \"\"\"Add many lists, handling None.",
          "62:     Args:",
          "63:         left: The first list to merge.",
          "64:         others: The other lists to merge.",
          "66:     Returns:",
          "67:         The merged list.",
          "68:     \"\"\"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "77: def merge_obj(left: Any, right: Any) -> Any:",
          "78:     if left is None or right is None:",
          "79:         return left if left is not None else right",
          "80:     elif type(left) is not type(right):",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "97:     \"\"\"Merge two objects.",
          "99:     It handles specific scenarios where a key exists in both",
          "100:     dictionaries but has a value of None in 'left'. In such cases, the method uses the",
          "101:     value from 'right' for that key in the merged dictionary.",
          "103:     Args:",
          "104:         left: The first object to merge.",
          "105:         right: The other object to merge.",
          "107:     Returns:",
          "108:         The merged object.",
          "110:     Raises:",
          "111:         TypeError: If the key exists in both dictionaries but has a different type.",
          "112:         ValueError: If the two objects cannot be merged.",
          "113:     \"\"\"",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/utils/aiter.py||libs/core/langchain_core/utils/aiter.py": [
          "File: libs/core/langchain_core/utils/aiter.py -> libs/core/langchain_core/utils/aiter.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "44:     Can be used to compare the built-in implementation of the inner",
          "45:     coroutines machinery to C-implementation of __anext__() and send()",
          "46:     or throw() on the returned generator.",
          "47:     \"\"\"",
          "49:     try:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "48:     Args:",
          "49:         iterator: The async iterator to advance.",
          "50:         default: The value to return if the iterator is exhausted.",
          "51:             If not provided, a StopAsyncIteration exception is raised.",
          "53:     Returns:",
          "54:         The next value from the iterator, or the default value",
          "55:             if the iterator is exhausted.",
          "57:     Raises:",
          "58:         TypeError: If the iterator is not an async iterator.",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "73: class NoLock:",
          "76:     async def __aenter__(self) -> None:",
          "77:         pass",
          "",
          "[Removed Lines]",
          "74:     \"\"\"Dummy lock that provides the proper interface but no protection\"\"\"",
          "",
          "[Added Lines]",
          "86:     \"\"\"Dummy lock that provides the proper interface but no protection.\"\"\"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "88:     peers: List[Deque[T]],",
          "89:     lock: AsyncContextManager[Any],",
          "90: ) -> AsyncGenerator[T, None]:",
          "92:     try:",
          "93:         while True:",
          "94:             if not buffer:",
          "",
          "[Removed Lines]",
          "91:     \"\"\"An individual iterator of a :py:func:`~.tee`\"\"\"",
          "",
          "[Added Lines]",
          "103:     \"\"\"An individual iterator of a :py:func:`~.tee`.",
          "105:     This function is a generator that yields items from the shared iterator",
          "106:     ``iterator``. It buffers items until the least advanced iterator has",
          "107:     yielded them as well. The buffer is shared with all other peers.",
          "109:     Args:",
          "110:         iterator: The shared iterator.",
          "111:         buffer: The buffer for this peer.",
          "112:         peers: The buffers of all peers.",
          "113:         lock: The lock to synchronise access to the shared buffers.",
          "115:     Yields:",
          "116:         The next item from the shared iterator.",
          "117:     \"\"\"",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "204:         return False",
          "206:     async def aclose(self) -> None:",
          "207:         for child in self._children:",
          "208:             await child.aclose()",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "233:         \"\"\"Async close all child iterators.\"\"\"",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "258:         iterable: The async iterable to batch.",
          "260:     Returns:",
          "262:     \"\"\"",
          "263:     batch: List[T] = []",
          "264:     async for element in iterable:",
          "",
          "[Removed Lines]",
          "261:         An async iterator over the batches",
          "",
          "[Added Lines]",
          "288:         An async iterator over the batches.",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/utils/env.py||libs/core/langchain_core/utils/env.py": [
          "File: libs/core/langchain_core/utils/env.py -> libs/core/langchain_core/utils/env.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "36:         env_key: The environment variable to look up if the key is not",
          "37:             in the dictionary.",
          "38:         default: The default value to return if the key is not in the dictionary",
          "40:     \"\"\"",
          "41:     if isinstance(key, (list, tuple)):",
          "42:         for k in key:",
          "",
          "[Removed Lines]",
          "39:             or the environment.",
          "",
          "[Added Lines]",
          "39:             or the environment. Defaults to None.",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "58: def get_from_env(key: str, env_key: str, default: Optional[str] = None) -> str:",
          "60:     if env_key in os.environ and os.environ[env_key]:",
          "61:         return os.environ[env_key]",
          "62:     elif default is not None:",
          "",
          "[Removed Lines]",
          "59:     \"\"\"Get a value from a dictionary or an environment variable.\"\"\"",
          "",
          "[Added Lines]",
          "59:     \"\"\"Get a value from a dictionary or an environment variable.",
          "61:     Args:",
          "62:         key: The key to look up in the dictionary.",
          "63:         env_key: The environment variable to look up if the key is not",
          "64:             in the dictionary.",
          "65:         default: The default value to return if the key is not in the dictionary",
          "66:             or the environment. Defaults to None.",
          "68:     Returns:",
          "69:         str: The value of the key.",
          "71:     Raises:",
          "72:         ValueError: If the key is not in the dictionary and no default value is",
          "73:             provided or if the environment variable is not set.",
          "74:     \"\"\"",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/utils/formatting.py||libs/core/langchain_core/utils/formatting.py": [
          "File: libs/core/langchain_core/utils/formatting.py -> libs/core/langchain_core/utils/formatting.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "10:     def vformat(",
          "11:         self, format_string: str, args: Sequence, kwargs: Mapping[str, Any]",
          "12:     ) -> str:",
          "14:         if len(args) > 0:",
          "15:             raise ValueError(",
          "16:                 \"No arguments should be provided, \"",
          "",
          "[Removed Lines]",
          "13:         \"\"\"Check that no arguments are provided.\"\"\"",
          "",
          "[Added Lines]",
          "13:         \"\"\"Check that no arguments are provided.",
          "15:         Args:",
          "16:             format_string: The format string.",
          "17:             args: The arguments.",
          "18:             kwargs: The keyword arguments.",
          "20:         Returns:",
          "21:             The formatted string.",
          "23:         Raises:",
          "24:             ValueError: If any arguments are provided.",
          "25:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "21:     def validate_input_variables(",
          "22:         self, format_string: str, input_variables: List[str]",
          "23:     ) -> None:",
          "24:         dummy_inputs = {input_variable: \"foo\" for input_variable in input_variables}",
          "25:         super().format(format_string, **dummy_inputs)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "36:         \"\"\"Check that all input variables are used in the format string.",
          "38:         Args:",
          "39:             format_string: The format string.",
          "40:             input_variables: The input variables.",
          "42:         Raises:",
          "43:             ValueError: If any input variables are not used in the format string.",
          "44:         \"\"\"",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/utils/function_calling.py||libs/core/langchain_core/utils/function_calling.py": [
          "File: libs/core/langchain_core/utils/function_calling.py -> libs/core/langchain_core/utils/function_calling.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "55:     \"\"\"Representation of a callable function to the OpenAI API.\"\"\"",
          "57:     type: Literal[\"function\"]",
          "58:     function: FunctionDescription",
          "61: def _rm_titles(kv: dict, prev_key: str = \"\") -> dict:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "58:     \"\"\"The type of the tool.\"\"\"",
          "60:     \"\"\"The function description.\"\"\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "85:     description: Optional[str] = None,",
          "86:     rm_titles: bool = True,",
          "87: ) -> FunctionDescription:",
          "89:     schema = dereference_refs(model.schema())",
          "90:     schema.pop(\"definitions\", None)",
          "91:     title = schema.pop(\"title\", \"\")",
          "",
          "[Removed Lines]",
          "88:     \"\"\"Converts a Pydantic model to a function description for the OpenAI API.\"\"\"",
          "",
          "[Added Lines]",
          "90:     \"\"\"Converts a Pydantic model to a function description for the OpenAI API.",
          "92:     Args:",
          "93:         model: The Pydantic model to convert.",
          "94:         name: The name of the function. If not provided, the title of the schema will be",
          "95:             used.",
          "96:         description: The description of the function. If not provided, the description",
          "97:             of the schema will be used.",
          "98:         rm_titles: Whether to remove titles from the schema. Defaults to True.",
          "100:     Returns:",
          "101:         The function description.",
          "102:     \"\"\"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "108:     name: Optional[str] = None,",
          "109:     description: Optional[str] = None,",
          "110: ) -> ToolDescription:",
          "112:     function = convert_pydantic_to_openai_function(",
          "113:         model, name=name, description=description",
          "114:     )",
          "",
          "[Removed Lines]",
          "111:     \"\"\"Converts a Pydantic model to a function description for the OpenAI API.\"\"\"",
          "",
          "[Added Lines]",
          "125:     \"\"\"Converts a Pydantic model to a function description for the OpenAI API.",
          "127:     Args:",
          "128:         model: The Pydantic model to convert.",
          "129:         name: The name of the function. If not provided, the title of the schema will be",
          "130:             used.",
          "131:         description: The description of the function. If not provided, the description",
          "132:             of the schema will be used.",
          "134:     Returns:",
          "135:         The tool description.",
          "136:     \"\"\"",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "133:     Assumes the Python function has type hints and a docstring with a description. If",
          "134:         the docstring has Google Python style argument descriptions, these will be",
          "135:         included as well.",
          "136:     \"\"\"",
          "137:     from langchain_core import tools",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "162:     Args:",
          "163:         function: The Python function to convert.",
          "165:     Returns:",
          "166:         The OpenAI function description.",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "157:     removal=\"0.3.0\",",
          "158: )",
          "159: def format_tool_to_openai_function(tool: BaseTool) -> FunctionDescription:",
          "161:     if tool.args_schema:",
          "162:         return convert_pydantic_to_openai_function(",
          "163:             tool.args_schema, name=tool.name, description=tool.description",
          "",
          "[Removed Lines]",
          "160:     \"\"\"Format tool into the OpenAI function API.\"\"\"",
          "",
          "[Added Lines]",
          "191:     \"\"\"Format tool into the OpenAI function API.",
          "193:     Args:",
          "194:         tool: The tool to format.",
          "196:     Returns:",
          "197:         The function description.",
          "198:     \"\"\"",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "187:     removal=\"0.3.0\",",
          "188: )",
          "189: def format_tool_to_openai_tool(tool: BaseTool) -> ToolDescription:",
          "191:     function = format_tool_to_openai_function(tool)",
          "192:     return {\"type\": \"function\", \"function\": function}",
          "",
          "[Removed Lines]",
          "190:     \"\"\"Format tool into the OpenAI function API.\"\"\"",
          "",
          "[Added Lines]",
          "228:     \"\"\"Format tool into the OpenAI function API.",
          "230:     Args:",
          "231:         tool: The tool to format.",
          "233:     Returns:",
          "234:         The tool description.",
          "235:     \"\"\"",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "206:     Returns:",
          "207:         A dict version of the passed in function which is compatible with the",
          "208:             OpenAI function-calling API.",
          "209:     \"\"\"",
          "210:     from langchain_core.tools import BaseTool",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "255:     Raises:",
          "256:         ValueError: If the function is not in a supported format.",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "284:             BaseModels",
          "285:         tool_outputs: Optional[List[str]], a list of tool call outputs.",
          "286:             Does not need to be provided. If not provided, a placeholder value",
          "289:     Returns:",
          "290:         A list of messages",
          "",
          "[Removed Lines]",
          "287:             will be inserted.",
          "",
          "[Added Lines]",
          "335:             will be inserted. Defaults to None.",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/utils/html.py||libs/core/langchain_core/utils/html.py": [
          "File: libs/core/langchain_core/utils/html.py -> libs/core/langchain_core/utils/html.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "34: def find_all_links(",
          "35:     raw_html: str, *, pattern: Union[str, re.Pattern, None] = None",
          "36: ) -> List[str]:",
          "39:     Args:",
          "43:     Returns:",
          "44:         List[str]: all links",
          "",
          "[Removed Lines]",
          "37:     \"\"\"Extract all links from a raw html string.",
          "40:         raw_html: original html.",
          "41:         pattern: Regex to use for extracting links from raw html.",
          "",
          "[Added Lines]",
          "37:     \"\"\"Extract all links from a raw HTML string.",
          "40:         raw_html: original HTML.",
          "41:         pattern: Regex to use for extracting links from raw HTML.",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "57:     exclude_prefixes: Sequence[str] = (),",
          "58:     continue_on_failure: bool = False,",
          "59: ) -> List[str]:",
          "62:     Args:",
          "67:         prevent_outside: If True, ignore external links which are not children",
          "69:         exclude_prefixes: Exclude any URLs that start with one of these prefixes.",
          "70:         continue_on_failure: If True, continue if parsing a specific link raises an",
          "71:             exception. Otherwise, raise the exception.",
          "72:     Returns:",
          "74:     \"\"\"",
          "75:     base_url_to_use = base_url if base_url is not None else url",
          "76:     parsed_base_url = urlparse(base_url_to_use)",
          "",
          "[Removed Lines]",
          "60:     \"\"\"Extract all links from a raw html string and convert into absolute paths.",
          "63:         raw_html: original html.",
          "64:         url: the url of the html.",
          "65:         base_url: the base url to check for outside links against.",
          "66:         pattern: Regex to use for extracting links from raw html.",
          "68:             of the base url.",
          "73:         List[str]: sub links",
          "",
          "[Added Lines]",
          "60:     \"\"\"Extract all links from a raw HTML string and convert into absolute paths.",
          "63:         raw_html: original HTML.",
          "64:         url: the url of the HTML.",
          "65:         base_url: the base URL to check for outside links against.",
          "66:         pattern: Regex to use for extracting links from raw HTML.",
          "68:             of the base URL.",
          "73:         List[str]: sub links.",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/utils/image.py||libs/core/langchain_core/utils/image.py": [
          "File: libs/core/langchain_core/utils/image.py -> libs/core/langchain_core/utils/image.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "5: def encode_image(image_path: str) -> str:",
          "7:     with open(image_path, \"rb\") as image_file:",
          "8:         return base64.b64encode(image_file.read()).decode(\"utf-8\")",
          "11: def image_to_data_url(image_path: str) -> str:",
          "12:     encoding = encode_image(image_path)",
          "13:     mime_type = mimetypes.guess_type(image_path)[0]",
          "14:     return f\"data:{mime_type};base64,{encoding}\"",
          "",
          "[Removed Lines]",
          "6:     \"\"\"Get base64 string from image URI.\"\"\"",
          "",
          "[Added Lines]",
          "6:     \"\"\"Get base64 string from image URI.",
          "8:     Args:",
          "9:         image_path: The path to the image.",
          "11:     Returns:",
          "12:         The base64 string of the image.",
          "13:     \"\"\"",
          "19:     \"\"\"Get data URL from image URI.",
          "21:     Args:",
          "22:         image_path: The path to the image.",
          "24:     Returns:",
          "25:         The data URL of the image.",
          "26:     \"\"\"",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/utils/input.py||libs/core/langchain_core/utils/input.py": [
          "File: libs/core/langchain_core/utils/input.py -> libs/core/langchain_core/utils/input.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "14: def get_color_mapping(",
          "15:     items: List[str], excluded_colors: Optional[List] = None",
          "16: ) -> Dict[str, str]:",
          "18:     colors = list(_TEXT_COLOR_MAPPING.keys())",
          "19:     if excluded_colors is not None:",
          "20:         colors = [c for c in colors if c not in excluded_colors]",
          "",
          "[Removed Lines]",
          "17:     \"\"\"Get mapping for items to a support color.\"\"\"",
          "",
          "[Added Lines]",
          "17:     \"\"\"Get mapping for items to a support color.",
          "19:     Args:",
          "20:         items: The items to map to colors.",
          "21:         excluded_colors: The colors to exclude.",
          "23:     Returns:",
          "24:         The mapping of items to colors.",
          "25:     \"\"\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "25: def get_colored_text(text: str, color: str) -> str:",
          "27:     color_str = _TEXT_COLOR_MAPPING[color]",
          "28:     return f\"\\u001b[{color_str}m\\033[1;3m{text}\\u001b[0m\"",
          "31: def get_bolded_text(text: str) -> str:",
          "33:     return f\"\\033[1m{text}\\033[0m\"",
          "36: def print_text(",
          "37:     text: str, color: Optional[str] = None, end: str = \"\", file: Optional[TextIO] = None",
          "38: ) -> None:",
          "40:     text_to_print = get_colored_text(text, color) if color else text",
          "41:     print(text_to_print, end=end, file=file)",
          "42:     if file:",
          "",
          "[Removed Lines]",
          "26:     \"\"\"Get colored text.\"\"\"",
          "32:     \"\"\"Get bolded text.\"\"\"",
          "39:     \"\"\"Print text with highlighting and no end characters.\"\"\"",
          "",
          "[Added Lines]",
          "34:     \"\"\"Get colored text.",
          "36:     Args:",
          "37:         text: The text to color.",
          "38:         color: The color to use.",
          "40:     Returns:",
          "41:         The colored text.",
          "42:     \"\"\"",
          "48:     \"\"\"Get bolded text.",
          "50:     Args:",
          "51:         text: The text to bold.",
          "53:     Returns:",
          "54:         The bolded text.",
          "55:     \"\"\"",
          "62:     \"\"\"Print text with highlighting and no end characters.",
          "64:     If a color is provided, the text will be printed in that color.",
          "65:     If a file is provided, the text will be written to that file.",
          "67:     Args:",
          "68:         text: The text to print.",
          "69:         color: The color to use. Defaults to None.",
          "70:         end: The end character to use. Defaults to \"\".",
          "71:         file: The file to write to. Defaults to None.",
          "72:     \"\"\"",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/utils/iter.py||libs/core/langchain_core/utils/iter.py": [
          "File: libs/core/langchain_core/utils/iter.py -> libs/core/langchain_core/utils/iter.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "24: class NoLock:",
          "27:     def __enter__(self) -> None:",
          "28:         pass",
          "",
          "[Removed Lines]",
          "25:     \"\"\"Dummy lock that provides the proper interface but no protection\"\"\"",
          "",
          "[Added Lines]",
          "25:     \"\"\"Dummy lock that provides the proper interface but no protection.\"\"\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "39:     peers: List[Deque[T]],",
          "40:     lock: ContextManager[Any],",
          "41: ) -> Generator[T, None, None]:",
          "43:     try:",
          "44:         while True:",
          "45:             if not buffer:",
          "",
          "[Removed Lines]",
          "42:     \"\"\"An individual iterator of a :py:func:`~.tee`\"\"\"",
          "",
          "[Added Lines]",
          "42:     \"\"\"An individual iterator of a :py:func:`~.tee`.",
          "44:     This function is a generator that yields items from the shared iterator",
          "45:     ``iterator``. It buffers items until the least advanced iterator has",
          "46:     yielded them as well. The buffer is shared with all other peers.",
          "48:     Args:",
          "49:         iterator: The shared iterator.",
          "50:         buffer: The buffer for this peer.",
          "51:         peers: The buffers of all peers.",
          "52:         lock: The lock to synchronise access to the shared buffers.",
          "54:     Yields:",
          "55:         The next item from the shared iterator.",
          "56:     \"\"\"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "119:         lock: Optional[ContextManager[Any]] = None,",
          "120:     ):",
          "121:         self._iterator = iter(iterable)",
          "122:         self._buffers: List[Deque[T]] = [deque() for _ in range(n)]",
          "123:         self._children = tuple(",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "135:         \"\"\"Create a new ``tee``.",
          "137:         Args:",
          "138:             iterable: The iterable to split.",
          "139:             n: The number of iterators to create. Defaults to 2.",
          "140:             lock: The lock to synchronise access to the shared buffers.",
          "141:                 Defaults to None.",
          "142:         \"\"\"",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "170:         size: The size of the batch. If None, returns a single batch.",
          "171:         iterable: The iterable to batch.",
          "175:     \"\"\"",
          "176:     it = iter(iterable)",
          "177:     while True:",
          "",
          "[Removed Lines]",
          "173:     Returns:",
          "174:         An iterator over the batches.",
          "",
          "[Added Lines]",
          "195:     Yields:",
          "196:         The batches of the iterable.",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/utils/json.py||libs/core/langchain_core/utils/json.py": [
          "File: libs/core/langchain_core/utils/json.py -> libs/core/langchain_core/utils/json.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "124: def parse_json_markdown(",
          "125:     json_string: str, *, parser: Callable[[str], Any] = parse_partial_json",
          "126: ) -> dict:",
          "130:     Args:",
          "131:         json_string: The Markdown string.",
          "",
          "[Removed Lines]",
          "127:     \"\"\"",
          "128:     Parse a JSON string from a Markdown string.",
          "",
          "[Added Lines]",
          "127:     \"\"\"Parse a JSON string from a Markdown string.",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "176:     Returns:",
          "177:         The parsed JSON object as a Python dictionary.",
          "178:     \"\"\"",
          "179:     try:",
          "180:         json_obj = parse_json_markdown(text)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "178:     Raises:",
          "179:         OutputParserException: If the JSON string is invalid or does not contain",
          "180:             the expected keys.",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/utils/json_schema.py||libs/core/langchain_core/utils/json_schema.py": [
          "File: libs/core/langchain_core/utils/json_schema.py -> libs/core/langchain_core/utils/json_schema.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "90:     full_schema: Optional[dict] = None,",
          "91:     skip_keys: Optional[Sequence[str]] = None,",
          "92: ) -> dict:",
          "95:     full_schema = full_schema or schema_obj",
          "96:     skip_keys = (",
          "",
          "[Removed Lines]",
          "93:     \"\"\"Try to substitute $refs in JSON Schema.\"\"\"",
          "",
          "[Added Lines]",
          "93:     \"\"\"Try to substitute $refs in JSON Schema.",
          "95:     Args:",
          "96:         schema_obj: The schema object to dereference.",
          "97:         full_schema: The full schema object. Defaults to None.",
          "98:         skip_keys: The keys to skip. Defaults to None.",
          "100:     Returns:",
          "101:         The dereferenced schema object.",
          "102:     \"\"\"",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/utils/mustache.py||libs/core/langchain_core/utils/mustache.py": [
          "File: libs/core/langchain_core/utils/mustache.py -> libs/core/langchain_core/utils/mustache.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "44: def grab_literal(template: str, l_del: str) -> Tuple[str, str]:",
          "47:     global _CURRENT_LINE",
          "",
          "[Removed Lines]",
          "45:     \"\"\"Parse a literal from the template.\"\"\"",
          "",
          "[Added Lines]",
          "45:     \"\"\"Parse a literal from the template.",
          "47:     Args:",
          "48:         template: The template to parse.",
          "49:         l_del: The left delimiter.",
          "51:     Returns:",
          "52:         Tuple[str, str]: The literal and the template.",
          "53:     \"\"\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "61: def l_sa_check(template: str, literal: str, is_standalone: bool) -> bool:",
          "64:     # If there is a newline, or the previous tag was a standalone",
          "65:     if literal.find(\"\\n\") != -1 or is_standalone:",
          "",
          "[Removed Lines]",
          "62:     \"\"\"Do a preliminary check to see if a tag could be a standalone.\"\"\"",
          "",
          "[Added Lines]",
          "70:     \"\"\"Do a preliminary check to see if a tag could be a standalone.",
          "72:     Args:",
          "73:         template: The template. (Not used.)",
          "74:         literal: The literal.",
          "75:         is_standalone: Whether the tag is standalone.",
          "77:     Returns:",
          "78:         bool: Whether the tag could be a standalone.",
          "79:     \"\"\"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "79: def r_sa_check(template: str, tag_type: str, is_standalone: bool) -> bool:",
          "82:     # Check right side if we might be a standalone",
          "83:     if is_standalone and tag_type not in [\"variable\", \"no escape\"]:",
          "",
          "[Removed Lines]",
          "80:     \"\"\"Do a final check to see if a tag could be a standalone.\"\"\"",
          "",
          "[Added Lines]",
          "97:     \"\"\"Do a final check to see if a tag could be a standalone.",
          "99:     Args:",
          "100:         template: The template.",
          "101:         tag_type: The type of the tag.",
          "102:         is_standalone: Whether the tag is standalone.",
          "104:     Returns:",
          "105:         bool: Whether the tag could be a standalone.",
          "106:     \"\"\"",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "97: def parse_tag(template: str, l_del: str, r_del: str) -> Tuple[Tuple[str, str], str]:",
          "99:     global _CURRENT_LINE",
          "100:     global _LAST_TAG_LINE",
          "",
          "[Removed Lines]",
          "98:     \"\"\"Parse a tag from a template.\"\"\"",
          "",
          "[Added Lines]",
          "124:     \"\"\"Parse a tag from a template.",
          "126:     Args:",
          "127:         template: The template.",
          "128:         l_del: The left delimiter.",
          "129:         r_del: The right delimiter.",
          "131:     Returns:",
          "132:         Tuple[Tuple[str, str], str]: The tag and the template.",
          "134:     Raises:",
          "135:         ChevronError: If the tag is unclosed.",
          "136:         ChevronError: If the set delimiter tag is unclosed.",
          "137:     \"\"\"",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "405:     Arguments:",
          "412:                      If set to None, then partials won't be loaded from the file system",
          "415:     partials_ext  -- The extension that you want the parser to look for",
          "418:     partials_dict -- A python dictionary which will be search for partials",
          "419:                      before the filesystem is. {'include': 'foo'} is the same",
          "420:                      as a file called include.mustache",
          "423:     padding       -- This is for padding partials, and shouldn't be used",
          "426:     def_ldel      -- The default left delimiter",
          "429:     def_rdel      -- The default right delimiter",
          "434:     warn          -- Log a warning when a template substitution isn't found in the data",
          "439:     Returns:",
          "",
          "[Removed Lines]",
          "407:     template      -- A file-like object or a string containing the template",
          "409:     data          -- A python dictionary with your data scope",
          "411:     partials_path -- The path to where your partials are stored",
          "413:                      (defaults to '.')",
          "416:                      (defaults to 'mustache')",
          "421:                      (defaults to {})",
          "424:                      (but can be if you really want to)",
          "427:                      (\"{{\" by default, as in spec compliant mustache)",
          "430:                      (\"}}\" by default, as in spec compliant mustache)",
          "432:     scopes        -- The list of scopes that get_key will look through",
          "436:     keep          -- Keep unreplaced tags when a substitution isn't found in the data",
          "",
          "[Added Lines]",
          "446:     template      -- A file-like object or a string containing the template.",
          "448:     data          -- A python dictionary with your data scope.",
          "450:     partials_path -- The path to where your partials are stored.",
          "452:                      (defaults to '.').",
          "455:                      (defaults to 'mustache').",
          "460:                      (defaults to {}).",
          "463:                      (but can be if you really want to).",
          "466:                      (\"{{\" by default, as in spec compliant mustache).",
          "469:                      (\"}}\" by default, as in spec compliant mustache).",
          "471:     scopes        -- The list of scopes that get_key will look through.",
          "475:     keep          -- Keep unreplaced tags when a substitution isn't found in the data.",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/utils/pydantic.py||libs/core/langchain_core/utils/pydantic.py": [
          "File: libs/core/langchain_core/utils/pydantic.py -> libs/core/langchain_core/utils/pydantic.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "22: # How to type hint this?",
          "23: def pre_init(func: Callable) -> Any:",
          "26:     @root_validator(pre=True)",
          "27:     @wraps(func)",
          "28:     def wrapper(cls: Type[BaseModel], values: Dict[str, Any]) -> Dict[str, Any]:",
          "30:         # Insert default values",
          "31:         fields = cls.__fields__",
          "32:         for name, field_info in fields.items():",
          "",
          "[Removed Lines]",
          "24:     \"\"\"Decorator to run a function before model initialization.\"\"\"",
          "29:         \"\"\"Decorator to run a function before model initialization.\"\"\"",
          "",
          "[Added Lines]",
          "24:     \"\"\"Decorator to run a function before model initialization.",
          "26:     Args:",
          "27:         func (Callable): The function to run before model initialization.",
          "29:     Returns:",
          "30:         Any: The decorated function.",
          "31:     \"\"\"",
          "36:         \"\"\"Decorator to run a function before model initialization.",
          "38:         Args:",
          "39:             cls (Type[BaseModel]): The model class.",
          "40:             values (Dict[str, Any]): The values to initialize the model with.",
          "42:         Returns:",
          "43:             Dict[str, Any]: The values to initialize the model with.",
          "44:         \"\"\"",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/utils/strings.py||libs/core/langchain_core/utils/strings.py": [
          "File: libs/core/langchain_core/utils/strings.py -> libs/core/langchain_core/utils/strings.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "38: def comma_list(items: List[Any]) -> str:",
          "40:     return \", \".join(str(item) for item in items)",
          "",
          "[Removed Lines]",
          "39:     \"\"\"Convert a list to a comma-separated string.\"\"\"",
          "",
          "[Added Lines]",
          "39:     \"\"\"Convert a list to a comma-separated string.",
          "41:     Args:",
          "42:         items: The list to convert.",
          "44:     Returns:",
          "45:         str: The comma-separated string.",
          "46:     \"\"\"",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/utils/utils.py||libs/core/langchain_core/utils/utils.py": [
          "File: libs/core/langchain_core/utils/utils.py -> libs/core/langchain_core/utils/utils.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "17: def xor_args(*arg_groups: Tuple[str, ...]) -> Callable:",
          "20:     def decorator(func: Callable) -> Callable:",
          "21:         @functools.wraps(func)",
          "",
          "[Removed Lines]",
          "18:     \"\"\"Validate specified keyword args are mutually exclusive.\"\"\"",
          "",
          "[Added Lines]",
          "18:     \"\"\"Validate specified keyword args are mutually exclusive.\"",
          "20:     Args:",
          "23:     Returns:",
          "24:         Callable: Decorator that validates the specified keyword args",
          "25:             are mutually exclusive",
          "27:     Raises:",
          "28:         ValueError: If more than one arg in a group is defined.",
          "29:     \"\"\"",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "43: def raise_for_status_with_text(response: Response) -> None:",
          "45:     try:",
          "46:         response.raise_for_status()",
          "47:     except HTTPError as e:",
          "",
          "[Removed Lines]",
          "44:     \"\"\"Raise an error with the response text.\"\"\"",
          "",
          "[Added Lines]",
          "55:     \"\"\"Raise an error with the response text.",
          "57:     Args:",
          "58:         response (Response): The response to check for errors.",
          "60:     Raises:",
          "61:         ValueError: If the response has an error status code.",
          "62:     \"\"\"",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "52: def mock_now(dt_value):  # type: ignore",
          "53:     \"\"\"Context manager for mocking out datetime.now() in unit tests.",
          "55:     Example:",
          "56:     with mock_now(datetime.datetime(2011, 2, 3, 10, 11)):",
          "57:         assert datetime.datetime.now() == datetime.datetime(2011, 2, 3, 10, 11)",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "73:     Args:",
          "74:         dt_value: The datetime value to use for datetime.now().",
          "76:     Yields:",
          "77:         datetime.datetime: The mocked datetime class.",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "86:     module_name: str, *, pip_name: Optional[str] = None, package: Optional[str] = None",
          "87: ) -> Any:",
          "88:     \"\"\"Dynamically import a module and raise an exception if the module is not",
          "90:     try:",
          "91:         module = importlib.import_module(module_name, package)",
          "92:     except (ImportError, ModuleNotFoundError):",
          "",
          "[Removed Lines]",
          "89:     installed.\"\"\"",
          "",
          "[Added Lines]",
          "113:     installed.",
          "115:     Args:",
          "116:         module_name (str): The name of the module to import.",
          "117:         pip_name (str, optional): The name of the module to install with pip.",
          "118:             Defaults to None.",
          "119:         package (str, optional): The package to import the module from.",
          "120:             Defaults to None.",
          "122:     Returns:",
          "123:         Any: The imported module.",
          "125:     Raises:",
          "126:         ImportError: If the module is not installed.",
          "127:     \"\"\"",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "105:     gt_version: Optional[str] = None,",
          "106:     gte_version: Optional[str] = None,",
          "107: ) -> None:",
          "109:     imported_version = parse(version(package))",
          "110:     if lt_version is not None and imported_version >= parse(lt_version):",
          "111:         raise ValueError(",
          "",
          "[Removed Lines]",
          "108:     \"\"\"Check the version of a package.\"\"\"",
          "",
          "[Added Lines]",
          "146:     \"\"\"Check the version of a package.",
          "148:     Args:",
          "149:         package (str): The name of the package.",
          "150:         lt_version (str, optional): The version must be less than this.",
          "151:             Defaults to None.",
          "152:         lte_version (str, optional): The version must be less than or equal to this.",
          "153:             Defaults to None.",
          "154:         gt_version (str, optional): The version must be greater than this.",
          "155:             Defaults to None.",
          "156:         gte_version (str, optional): The version must be greater than or equal to this.",
          "157:             Defaults to None.",
          "159:     Raises:",
          "160:         ValueError: If the package version does not meet the requirements.",
          "161:     \"\"\"",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "133:     \"\"\"Get field names, including aliases, for a pydantic class.",
          "135:     Args:",
          "137:     all_required_field_names = set()",
          "138:     for field in pydantic_cls.__fields__.values():",
          "139:         all_required_field_names.add(field.name)",
          "",
          "[Removed Lines]",
          "136:         pydantic_cls: Pydantic class.\"\"\"",
          "",
          "[Added Lines]",
          "189:         pydantic_cls: Pydantic class.",
          "191:     Returns:",
          "192:         Set[str]: Field names.",
          "193:     \"\"\"",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "153:         extra_kwargs: Extra kwargs passed in by user.",
          "154:         values: Values passed in by user.",
          "155:         all_required_field_names: All required field names for the pydantic class.",
          "156:     \"\"\"",
          "157:     for field_name in list(values):",
          "158:         if field_name in extra_kwargs:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "214:     Returns:",
          "215:         Dict[str, Any]: Extra kwargs.",
          "217:     Raises:",
          "218:         ValueError: If a field is specified in both values and extra_kwargs.",
          "219:         ValueError: If a field is specified in model_kwargs.",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "178: def convert_to_secret_str(value: Union[SecretStr, str]) -> SecretStr:",
          "180:     if isinstance(value, SecretStr):",
          "181:         return value",
          "182:     return SecretStr(value)",
          "",
          "[Removed Lines]",
          "179:     \"\"\"Convert a string to a SecretStr if needed.\"\"\"",
          "",
          "[Added Lines]",
          "243:     \"\"\"Convert a string to a SecretStr if needed.",
          "245:     Args:",
          "246:         value (Union[SecretStr, str]): The value to convert.",
          "248:     Returns:",
          "249:         SecretStr: The SecretStr value.",
          "250:     \"\"\"",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "7b214ee83df911d13090fb5376bba004a934c5de",
      "candidate_info": {
        "commit_hash": "7b214ee83df911d13090fb5376bba004a934c5de",
        "repo": "langchain-ai/langchain",
        "commit_url": "https://github.com/langchain-ai/langchain/commit/7b214ee83df911d13090fb5376bba004a934c5de",
        "files": [
          "libs/core/langchain_core/prompts/image.py",
          "libs/core/langchain_core/utils/image.py",
          "libs/core/tests/unit_tests/prompts/test_chat.py"
        ],
        "message": "core[patch]: rm image prompt file loading",
        "before_after_code_files": [
          "libs/core/langchain_core/prompts/image.py||libs/core/langchain_core/prompts/image.py",
          "libs/core/langchain_core/utils/image.py||libs/core/langchain_core/utils/image.py",
          "libs/core/tests/unit_tests/prompts/test_chat.py||libs/core/tests/unit_tests/prompts/test_chat.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "diff_branch_same_aad": 1,
        "olp_code_files": {
          "patch": [
            "libs/core/langchain_core/prompts/image.py||libs/core/langchain_core/prompts/image.py",
            "libs/core/langchain_core/utils/image.py||libs/core/langchain_core/utils/image.py",
            "libs/core/tests/unit_tests/prompts/test_chat.py||libs/core/tests/unit_tests/prompts/test_chat.py"
          ],
          "candidate": [
            "libs/core/langchain_core/prompts/image.py||libs/core/langchain_core/prompts/image.py",
            "libs/core/langchain_core/utils/image.py||libs/core/langchain_core/utils/image.py",
            "libs/core/tests/unit_tests/prompts/test_chat.py||libs/core/tests/unit_tests/prompts/test_chat.py"
          ]
        }
      },
      "candidate_diff": {
        "libs/core/langchain_core/prompts/image.py||libs/core/langchain_core/prompts/image.py": [
          "File: libs/core/langchain_core/prompts/image.py -> libs/core/langchain_core/prompts/image.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "4: from langchain_core.prompts.base import BasePromptTemplate",
          "5: from langchain_core.pydantic_v1 import Field",
          "6: from langchain_core.runnables import run_in_executor",
          "10: class ImagePromptTemplate(BasePromptTemplate[ImageURL]):",
          "",
          "[Removed Lines]",
          "7: from langchain_core.utils import image as image_utils",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "54:         Returns:",
          "55:             A formatted string.",
          "57:         Example:",
          "59:             .. code-block:: python",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "56:         Raises:",
          "57:             ValueError: If the url is not provided.",
          "58:             ValueError: If the url is not a string.",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "67:             else:",
          "68:                 formatted[k] = v",
          "69:         url = kwargs.get(\"url\") or formatted.get(\"url\")",
          "71:         detail = kwargs.get(\"detail\") or formatted.get(\"detail\")",
          "74:         if not url:",
          "84:         return output",
          "86:     async def aformat(self, **kwargs: Any) -> ImageURL:",
          "87:         return await run_in_executor(None, self.format, **kwargs)",
          "89:     def pretty_repr(self, html: bool = False) -> str:",
          "",
          "[Removed Lines]",
          "70:         path = kwargs.get(\"path\") or formatted.get(\"path\")",
          "72:         if not url and not path:",
          "73:             raise ValueError(\"Must provide either url or path.\")",
          "75:             if not isinstance(path, str):",
          "76:                 raise ValueError(\"path must be a string.\")",
          "77:             url = image_utils.image_to_data_url(path)",
          "78:         if not isinstance(url, str):",
          "79:             raise ValueError(\"url must be a string.\")",
          "80:         output: ImageURL = {\"url\": url}",
          "81:         if detail:",
          "82:             # Don't check literal values here: let the API check them",
          "83:             output[\"detail\"] = detail  # type: ignore[typeddict-item]",
          "",
          "[Added Lines]",
          "74:         if kwargs.get(\"path\") or formatted.get(\"path\"):",
          "75:             msg = (",
          "76:                 \"Loading images from 'path' has been removed as of 0.3.15 for security \"",
          "77:                 \"reasons. Please specify images by 'url'.\"",
          "78:             )",
          "79:             raise ValueError(msg)",
          "82:             msg = \"Must provide url.\"",
          "83:             raise ValueError(msg)",
          "84:         elif not isinstance(url, str):",
          "85:             msg = \"url must be a string.\"",
          "86:             raise ValueError(msg)",
          "87:         else:",
          "88:             output: ImageURL = {\"url\": url}",
          "89:             if detail:",
          "90:                 # Don't check literal values here: let the API check them",
          "91:                 output[\"detail\"] = detail  # type: ignore[typeddict-item]",
          "95:         \"\"\"Async format the prompt with the inputs.",
          "97:         Args:",
          "98:             kwargs: Any arguments to be passed to the prompt template.",
          "100:         Returns:",
          "101:             A formatted string.",
          "103:         Raises:",
          "104:             ValueError: If the path or url is not a string.",
          "105:         \"\"\"",
          "",
          "---------------"
        ],
        "libs/core/langchain_core/utils/image.py||libs/core/langchain_core/utils/image.py": [
          "File: libs/core/langchain_core/utils/image.py -> libs/core/langchain_core/utils/image.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "[No context available]",
          "",
          "[Removed Lines]",
          "1: import base64",
          "2: import mimetypes",
          "5: def encode_image(image_path: str) -> str:",
          "6:     \"\"\"Get base64 string from image URI.\"\"\"",
          "7:     with open(image_path, \"rb\") as image_file:",
          "8:         return base64.b64encode(image_file.read()).decode(\"utf-8\")",
          "11: def image_to_data_url(image_path: str) -> str:",
          "12:     encoding = encode_image(image_path)",
          "13:     mime_type = mimetypes.guess_type(image_path)[0]",
          "14:     return f\"data:{mime_type};base64,{encoding}\"",
          "",
          "[Added Lines]",
          "1: from typing import Any",
          "4: def __getattr__(name: str) -> Any:",
          "5:     if name in (\"encode_image\", \"image_to_data_url\"):",
          "6:         msg = f\"'{name}' has been removed for security reasons.\"",
          "7:         raise ValueError(msg)",
          "8:     raise AttributeError(name)",
          "",
          "---------------"
        ],
        "libs/core/tests/unit_tests/prompts/test_chat.py||libs/core/tests/unit_tests/prompts/test_chat.py": [
          "File: libs/core/tests/unit_tests/prompts/test_chat.py -> libs/core/tests/unit_tests/prompts/test_chat.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1: from pathlib import Path",
          "2: from typing import Any, List, Union",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1: import base64",
          "2: import tempfile",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "568:     assert messages == expected",
          "571: def test_messages_placeholder() -> None:",
          "572:     prompt = MessagesPlaceholder(\"history\")",
          "573:     with pytest.raises(KeyError):",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "573: async def test_chat_tmpl_from_messages_multipart_formatting_with_path() -> None:",
          "574:     \"\"\"Verify that we cannot pass `path` for an image as a variable.\"\"\"",
          "575:     in_mem = \"base64mem\"",
          "576:     in_file_data = \"base64file01\"",
          "578:     with tempfile.NamedTemporaryFile(delete=True, suffix=\".jpg\") as temp_file:",
          "579:         temp_file.write(base64.b64decode(in_file_data))",
          "580:         temp_file.flush()",
          "582:         template = ChatPromptTemplate.from_messages(",
          "583:             [",
          "584:                 (\"system\", \"You are an AI assistant named {name}.\"),",
          "585:                 (",
          "586:                     \"human\",",
          "587:                     [",
          "588:                         {\"type\": \"text\", \"text\": \"What's in this image?\"},",
          "589:                         {",
          "590:                             \"type\": \"image_url\",",
          "591:                             \"image_url\": \"data:image/jpeg;base64,{in_mem}\",",
          "592:                         },",
          "593:                         {",
          "594:                             \"type\": \"image_url\",",
          "595:                             \"image_url\": {\"path\": \"{file_path}\"},",
          "596:                         },",
          "597:                     ],",
          "598:                 ),",
          "599:             ]",
          "600:         )",
          "601:         with pytest.raises(ValueError):",
          "602:             template.format_messages(",
          "603:                 name=\"R2D2\",",
          "604:                 in_mem=in_mem,",
          "605:                 file_path=temp_file.name,",
          "606:             )",
          "608:         with pytest.raises(ValueError):",
          "609:             await template.aformat_messages(",
          "610:                 name=\"R2D2\",",
          "611:                 in_mem=in_mem,",
          "612:                 file_path=temp_file.name,",
          "613:             )",
          "",
          "---------------"
        ]
      }
    }
  ]
}