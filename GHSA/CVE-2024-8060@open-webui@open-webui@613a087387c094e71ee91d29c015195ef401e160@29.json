{
  "cve_id": "CVE-2024-8060",
  "cve_desc": "OpenWebUI version 0.3.0 contains a vulnerability in the audio API endpoint `/audio/api/v1/transcriptions` that allows for arbitrary file upload. The application performs insufficient validation on the `file.content_type` and allows user-controlled filenames, leading to a path traversal vulnerability. This can be exploited by an authenticated user to overwrite critical files within the Docker container, potentially leading to remote code execution as the root user.",
  "repo": "open-webui/open-webui",
  "patch_hash": "613a087387c094e71ee91d29c015195ef401e160",
  "patch_info": {
    "commit_hash": "613a087387c094e71ee91d29c015195ef401e160",
    "repo": "open-webui/open-webui",
    "commit_url": "https://github.com/open-webui/open-webui/commit/613a087387c094e71ee91d29c015195ef401e160",
    "files": [
      "backend/open_webui/routers/audio.py"
    ],
    "message": "refac",
    "before_after_code_files": [
      "backend/open_webui/routers/audio.py||backend/open_webui/routers/audio.py"
    ]
  },
  "patch_diff": {
    "backend/open_webui/routers/audio.py||backend/open_webui/routers/audio.py": [
      "File: backend/open_webui/routers/audio.py -> backend/open_webui/routers/audio.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "681:     available_models = []",
      "682:     if request.app.state.config.TTS_ENGINE == \"openai\":",
      "683:         # Use custom endpoint if not using the official OpenAI API URL",
      "685:             try:",
      "687:                 response.raise_for_status()",
      "688:                 data = response.json()",
      "689:                 available_models = data.get(\"models\", [])",
      "690:             except Exception as e:",
      "691:                 log.error(f\"Error fetching models from custom endpoint: {str(e)}\")",
      "693:         else:",
      "694:             available_models = [{\"id\": \"tts-1\"}, {\"id\": \"tts-1-hd\"}]",
      "695:     elif request.app.state.config.TTS_ENGINE == \"elevenlabs\":",
      "",
      "[Removed Lines]",
      "684:         if not request.app.state.config.TTS_OPENAI_API_BASE_URL.startswith(\"https://api.openai.com\"):",
      "686:                 response = requests.get(f\"{request.app.state.config.TTS_OPENAI_API_BASE_URL}/audio/models\")",
      "692:                 available_models = []",
      "",
      "[Added Lines]",
      "684:         if not request.app.state.config.TTS_OPENAI_API_BASE_URL.startswith(",
      "685:             \"https://api.openai.com\"",
      "686:         ):",
      "688:                 response = requests.get(",
      "689:                     f\"{request.app.state.config.TTS_OPENAI_API_BASE_URL}/audio/models\"",
      "690:                 )",
      "696:                 available_models = [{\"id\": \"tts-1\"}, {\"id\": \"tts-1-hd\"}]",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "723:     available_voices = {}",
      "724:     if request.app.state.config.TTS_ENGINE == \"openai\":",
      "725:         # Use custom endpoint if not using the official OpenAI API URL",
      "727:             try:",
      "729:                 response.raise_for_status()",
      "730:                 data = response.json()",
      "731:                 voices_list = data.get(\"voices\", [])",
      "732:                 available_voices = {voice[\"id\"]: voice[\"name\"] for voice in voices_list}",
      "733:             except Exception as e:",
      "734:                 log.error(f\"Error fetching voices from custom endpoint: {str(e)}\")",
      "736:         else:",
      "737:             available_voices = {",
      "738:                 \"alloy\": \"alloy\",",
      "",
      "[Removed Lines]",
      "726:         if not request.app.state.config.TTS_OPENAI_API_BASE_URL.startswith(\"https://api.openai.com\"):",
      "728:                 response = requests.get(f\"{request.app.state.config.TTS_OPENAI_API_BASE_URL}/audio/voices\")",
      "735:                 available_voices = {}",
      "",
      "[Added Lines]",
      "730:         if not request.app.state.config.TTS_OPENAI_API_BASE_URL.startswith(",
      "731:             \"https://api.openai.com\"",
      "732:         ):",
      "734:                 response = requests.get(",
      "735:                     f\"{request.app.state.config.TTS_OPENAI_API_BASE_URL}/audio/voices\"",
      "736:                 )",
      "743:                 available_voices = {",
      "744:                     \"alloy\": \"alloy\",",
      "745:                     \"echo\": \"echo\",",
      "746:                     \"fable\": \"fable\",",
      "747:                     \"onyx\": \"onyx\",",
      "748:                     \"nova\": \"nova\",",
      "749:                     \"shimmer\": \"shimmer\",",
      "750:                 }",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "1635dcb69b3552d6369af9b6254745176ed8d9f4",
      "candidate_info": {
        "commit_hash": "1635dcb69b3552d6369af9b6254745176ed8d9f4",
        "repo": "open-webui/open-webui",
        "commit_url": "https://github.com/open-webui/open-webui/commit/1635dcb69b3552d6369af9b6254745176ed8d9f4",
        "files": [
          "backend/open_webui/utils/middleware.py",
          "src/lib/components/chat/Chat.svelte",
          "src/lib/utils/index.ts"
        ],
        "message": "refac",
        "before_after_code_files": [
          "backend/open_webui/utils/middleware.py||backend/open_webui/utils/middleware.py",
          "src/lib/components/chat/Chat.svelte||src/lib/components/chat/Chat.svelte",
          "src/lib/utils/index.ts||src/lib/utils/index.ts"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_message": 1,
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "backend/open_webui/utils/middleware.py||backend/open_webui/utils/middleware.py": [
          "File: backend/open_webui/utils/middleware.py -> backend/open_webui/utils/middleware.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1120:                             output = html.escape(json.dumps(output))",
          "1122:                             if raw:",
          "1124:                             else:",
          "1125:                                 content = f'{content}<details type=\"code_interpreter\" done=\"true\" output=\"{output}\">\\n<summary>Analyzed</summary>\\n```{lang}\\n{block[\"content\"]}\\n```\\n</details>\\n'",
          "1126:                         else:",
          "",
          "[Removed Lines]",
          "1123:                                 content = f'{content}<details type=\"code_interpreter\" done=\"true\" output=\"{output}\">\\n<summary>Analyzed</summary>\\n```{lang}\\n{block[\"content\"]}\\n```\\n```output\\n{output}\\n```\\n</details>\\n'",
          "",
          "[Added Lines]",
          "1123:                                 content = f'{content}<code_interpreter type=\"code\" lang=\"{lang}\">\\n{block[\"content\"]}\\n</code_interpreter>\\n```output\\n{output}\\n```\\n'",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1312:                                         )",
          "1314:                                         if end:",
          "1315:                                             break",
          "1317:                                     if ENABLE_REALTIME_CHAT_SAVE:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1315:                                             data = {",
          "1316:                                                 \"content\": serialize_content_blocks(",
          "1317:                                                     content_blocks",
          "1318:                                                 ),",
          "1319:                                             }",
          "",
          "---------------"
        ],
        "src/lib/components/chat/Chat.svelte||src/lib/components/chat/Chat.svelte": [
          "File: src/lib/components/chat/Chat.svelte -> src/lib/components/chat/Chat.svelte",
          "--- Hunk 1 ---",
          "[Context before]",
          "45:   promptTemplate,",
          "46:   splitStream,",
          "47:   sleep,",
          "49:   getPromptVariables",
          "50:  } from '$lib/utils';",
          "",
          "[Removed Lines]",
          "48:   removeDetailsWithReasoning,",
          "",
          "[Added Lines]",
          "48:   removeDetails,",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "1338:   parentId: string,",
          "1339:   { modelId = null, modelIdx = null, newChat = false } = {}",
          "1340:  ) => {",
          "1344:   if (",
          "1345:    newChat &&",
          "",
          "[Removed Lines]",
          "1341:   const _chatId = JSON.parse(JSON.stringify($chatId));",
          "",
          "[Added Lines]",
          "1342:   let selectedModelIds = modelId",
          "1343:    ? [modelId]",
          "1344:    : atSelectedModel !== undefined",
          "1345:     ? [atSelectedModel.id]",
          "1346:     : selectedModels;",
          "1349:   const responseMessageIds: Record<PropertyKey, string> = {};",
          "1351:   const _chatId = JSON.parse(JSON.stringify($chatId));",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "1351:    await saveChatHandler(_chatId);",
          "1352:   }",
          "1363:   for (const [_modelIdx, modelId] of selectedModelIds.entries()) {",
          "1364:    const model = $models.filter((m) => m.id === modelId).at(0);",
          "",
          "[Removed Lines]",
          "1355:   let selectedModelIds = modelId",
          "1356:    ? [modelId]",
          "1357:    : atSelectedModel !== undefined",
          "1358:     ? [atSelectedModel.id]",
          "1359:     : selectedModels;",
          "1362:   const responseMessageIds: Record<PropertyKey, string> = {};",
          "",
          "[Added Lines]",
          "[None]",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "1515:     : undefined,",
          "1516:    ...createMessagesList(history, responseMessageId).map((message) => ({",
          "1517:     ...message,",
          "1519:    }))",
          "1520:   ]",
          "1521:    .filter((message) => message?.content?.trim())",
          "",
          "[Removed Lines]",
          "1518:     content: removeDetailsWithReasoning(message.content)",
          "",
          "[Added Lines]",
          "1518:     content: removeDetails(message.content, ['reasoning', 'code_interpreter'])",
          "",
          "---------------"
        ],
        "src/lib/utils/index.ts||src/lib/utils/index.ts": [
          "File: src/lib/utils/index.ts -> src/lib/utils/index.ts",
          "--- Hunk 1 ---",
          "[Context before]",
          "668:  return removeFormattings(removeEmojis(content.trim()));",
          "669: };",
          "673: };",
          "",
          "[Removed Lines]",
          "671: export const removeDetailsWithReasoning = (content) => {",
          "672:  return content.replace(/<details\\s+type=\"reasoning\"[^>]*>.*?<\\/details>/gis, '').trim();",
          "",
          "[Added Lines]",
          "671: export const removeDetails = (content, types) => {",
          "672:  for (const type of types) {",
          "673:   content = content.replace(",
          "674:    new RegExp(`<details\\\\s+type=\"${type}\"[^>]*>.*?<\\\\/details>`, 'gis'),",
          "675:    ''",
          "676:   );",
          "677:  }",
          "679:  return content;",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "741: };",
          "743: export const getMessageContentParts = (content: string, split_on: string = 'punctuation') => {",
          "745:  const messageContentParts: string[] = [];",
          "747:  switch (split_on) {",
          "",
          "[Removed Lines]",
          "744:  content = removeDetailsWithReasoning(content);",
          "",
          "[Added Lines]",
          "751:  content = removeDetails(content, ['reasoning', 'code_interpreter']);",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "0425621494b3c2385fa672c372fce070b6b8d89e",
      "candidate_info": {
        "commit_hash": "0425621494b3c2385fa672c372fce070b6b8d89e",
        "repo": "open-webui/open-webui",
        "commit_url": "https://github.com/open-webui/open-webui/commit/0425621494b3c2385fa672c372fce070b6b8d89e",
        "files": [
          "backend/open_webui/config.py",
          "backend/open_webui/main.py",
          "backend/open_webui/routers/images.py",
          "backend/open_webui/utils/middleware.py",
          "src/lib/components/admin/Settings/Images.svelte"
        ],
        "message": "refac",
        "before_after_code_files": [
          "backend/open_webui/config.py||backend/open_webui/config.py",
          "backend/open_webui/main.py||backend/open_webui/main.py",
          "backend/open_webui/routers/images.py||backend/open_webui/routers/images.py",
          "backend/open_webui/utils/middleware.py||backend/open_webui/utils/middleware.py",
          "src/lib/components/admin/Settings/Images.svelte||src/lib/components/admin/Settings/Images.svelte"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_message": 1,
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "backend/open_webui/config.py||backend/open_webui/config.py": [
          "File: backend/open_webui/config.py -> backend/open_webui/config.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "1650:     \"image_generation.enable\",",
          "1651:     os.environ.get(\"ENABLE_IMAGE_GENERATION\", \"\").lower() == \"true\",",
          "1652: )",
          "1653: AUTOMATIC1111_BASE_URL = PersistentConfig(",
          "1654:     \"AUTOMATIC1111_BASE_URL\",",
          "1655:     \"image_generation.automatic1111.base_url\",",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "1654: ENABLE_IMAGE_PROMPT_GENERATION = PersistentConfig(",
          "1655:     \"ENABLE_IMAGE_PROMPT_GENERATION\",",
          "1656:     \"image_generation.prompt.enable\",",
          "1657:     os.environ.get(\"ENABLE_IMAGE_PROMPT_GENERATION\", \"true\").lower() == \"true\",",
          "1658: )",
          "",
          "---------------"
        ],
        "backend/open_webui/main.py||backend/open_webui/main.py": [
          "File: backend/open_webui/main.py -> backend/open_webui/main.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "108:     COMFYUI_WORKFLOW,",
          "109:     COMFYUI_WORKFLOW_NODES,",
          "110:     ENABLE_IMAGE_GENERATION,",
          "111:     IMAGE_GENERATION_ENGINE,",
          "112:     IMAGE_GENERATION_MODEL,",
          "113:     IMAGE_SIZE,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "111:     ENABLE_IMAGE_PROMPT_GENERATION,",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "576: app.state.config.IMAGE_GENERATION_ENGINE = IMAGE_GENERATION_ENGINE",
          "577: app.state.config.ENABLE_IMAGE_GENERATION = ENABLE_IMAGE_GENERATION",
          "579: app.state.config.IMAGES_OPENAI_API_BASE_URL = IMAGES_OPENAI_API_BASE_URL",
          "580: app.state.config.IMAGES_OPENAI_API_KEY = IMAGES_OPENAI_API_KEY",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "579: app.state.config.ENABLE_IMAGE_PROMPT_GENERATION = ENABLE_IMAGE_PROMPT_GENERATION",
          "",
          "---------------"
        ],
        "backend/open_webui/routers/images.py||backend/open_webui/routers/images.py": [
          "File: backend/open_webui/routers/images.py -> backend/open_webui/routers/images.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "43:     return {",
          "44:         \"enabled\": request.app.state.config.ENABLE_IMAGE_GENERATION,",
          "45:         \"engine\": request.app.state.config.IMAGE_GENERATION_ENGINE,",
          "46:         \"openai\": {",
          "47:             \"OPENAI_API_BASE_URL\": request.app.state.config.IMAGES_OPENAI_API_BASE_URL,",
          "48:             \"OPENAI_API_KEY\": request.app.state.config.IMAGES_OPENAI_API_KEY,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "46:         \"prompt_generation\": request.app.state.config.ENABLE_IMAGE_PROMPT_GENERATION,",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "86: class ConfigForm(BaseModel):",
          "87:     enabled: bool",
          "88:     engine: str",
          "89:     openai: OpenAIConfigForm",
          "90:     automatic1111: Automatic1111ConfigForm",
          "91:     comfyui: ComfyUIConfigForm",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "90:     prompt_generation: bool",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "98:     request.app.state.config.IMAGE_GENERATION_ENGINE = form_data.engine",
          "99:     request.app.state.config.ENABLE_IMAGE_GENERATION = form_data.enabled",
          "101:     request.app.state.config.IMAGES_OPENAI_API_BASE_URL = (",
          "102:         form_data.openai.OPENAI_API_BASE_URL",
          "103:     )",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "103:     request.app.state.config.ENABLE_IMAGE_PROMPT_GENERATION = (",
          "104:         form_data.prompt_generation",
          "105:     )",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "137:     return {",
          "138:         \"enabled\": request.app.state.config.ENABLE_IMAGE_GENERATION,",
          "139:         \"engine\": request.app.state.config.IMAGE_GENERATION_ENGINE,",
          "140:         \"openai\": {",
          "141:             \"OPENAI_API_BASE_URL\": request.app.state.config.IMAGES_OPENAI_API_BASE_URL,",
          "142:             \"OPENAI_API_KEY\": request.app.state.config.IMAGES_OPENAI_API_KEY,",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "146:         \"prompt_generation\": request.app.state.config.ENABLE_IMAGE_PROMPT_GENERATION,",
          "",
          "---------------"
        ],
        "backend/open_webui/utils/middleware.py||backend/open_webui/utils/middleware.py": [
          "File: backend/open_webui/utils/middleware.py -> backend/open_webui/utils/middleware.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "504:     messages = form_data[\"messages\"]",
          "505:     user_message = get_last_user_message(messages)",
          "508:     negative_prompt = \"\"",
          "532:         except Exception as e:",
          "533:             prompt = user_message",
          "539:     system_message_content = \"\"",
          "541:     try:",
          "",
          "[Removed Lines]",
          "507:     prompt = \"\"",
          "510:     try:",
          "511:         res = await generate_image_prompt(",
          "512:             request,",
          "513:             {",
          "514:                 \"model\": form_data[\"model\"],",
          "515:                 \"messages\": messages,",
          "516:             },",
          "517:             user,",
          "518:         )",
          "520:         response = res[\"choices\"][0][\"message\"][\"content\"]",
          "522:         try:",
          "523:             bracket_start = response.find(\"{\")",
          "524:             bracket_end = response.rfind(\"}\") + 1",
          "526:             if bracket_start == -1 or bracket_end == -1:",
          "527:                 raise Exception(\"No JSON object found in the response\")",
          "529:             response = response[bracket_start:bracket_end]",
          "530:             response = json.loads(response)",
          "531:             prompt = response.get(\"prompt\", [])",
          "535:     except Exception as e:",
          "536:         log.exception(e)",
          "537:         prompt = user_message",
          "",
          "[Added Lines]",
          "507:     prompt = user_message",
          "510:     if request.app.state.config.ENABLE_IMAGE_PROMPT_GENERATION:",
          "511:         try:",
          "512:             res = await generate_image_prompt(",
          "513:                 request,",
          "514:                 {",
          "515:                     \"model\": form_data[\"model\"],",
          "516:                     \"messages\": messages,",
          "517:                 },",
          "518:                 user,",
          "519:             )",
          "521:             response = res[\"choices\"][0][\"message\"][\"content\"]",
          "523:             try:",
          "524:                 bracket_start = response.find(\"{\")",
          "525:                 bracket_end = response.rfind(\"}\") + 1",
          "527:                 if bracket_start == -1 or bracket_end == -1:",
          "528:                     raise Exception(\"No JSON object found in the response\")",
          "530:                 response = response[bracket_start:bracket_end]",
          "531:                 response = json.loads(response)",
          "532:                 prompt = response.get(\"prompt\", [])",
          "533:             except Exception as e:",
          "534:                 prompt = user_message",
          "537:             log.exception(e)",
          "",
          "---------------"
        ],
        "src/lib/components/admin/Settings/Images.svelte||src/lib/components/admin/Settings/Images.svelte": [
          "File: src/lib/components/admin/Settings/Images.svelte -> src/lib/components/admin/Settings/Images.svelte",
          "--- Hunk 1 ---",
          "[Context before]",
          "234:     <div class=\" mb-1 text-sm font-medium\">{$i18n.t('Image Settings')}</div>",
          "236:     <div>",
          "238:       <div class=\" self-center text-xs font-medium\">",
          "239:        {$i18n.t('Image Generation (Experimental)')}",
          "240:       </div>",
          "",
          "[Removed Lines]",
          "237:      <div class=\" py-0.5 flex w-full justify-between\">",
          "",
          "[Added Lines]",
          "237:      <div class=\" py-1 flex w-full justify-between\">",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "271:      </div>",
          "272:     </div>",
          "275:      <div class=\" self-center text-xs font-medium\">{$i18n.t('Image Generation Engine')}</div>",
          "276:      <div class=\"flex items-center relative\">",
          "277:       <select",
          "",
          "[Removed Lines]",
          "274:     <div class=\" py-0.5 flex w-full justify-between\">",
          "",
          "[Added Lines]",
          "274:     {#if config.enabled}",
          "275:      <div class=\" py-1 flex w-full justify-between\">",
          "276:       <div class=\" self-center text-xs font-medium\">{$i18n.t('Image Prompt Generation')}</div>",
          "277:       <div class=\"px-1\">",
          "278:        <Switch bind:state={config.prompt_generation} />",
          "279:       </div>",
          "280:      </div>",
          "281:     {/if}",
          "283:     <div class=\" py-1 flex w-full justify-between\">",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "0ae7d123435856cc686014f5753bcc45a62a4c2f",
      "candidate_info": {
        "commit_hash": "0ae7d123435856cc686014f5753bcc45a62a4c2f",
        "repo": "open-webui/open-webui",
        "commit_url": "https://github.com/open-webui/open-webui/commit/0ae7d123435856cc686014f5753bcc45a62a4c2f",
        "files": [
          "src/lib/components/chat/MessageInput/InputMenu.svelte"
        ],
        "message": "refac",
        "before_after_code_files": [
          "src/lib/components/chat/MessageInput/InputMenu.svelte||src/lib/components/chat/MessageInput/InputMenu.svelte"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_message": 1,
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "src/lib/components/chat/MessageInput/InputMenu.svelte||src/lib/components/chat/MessageInput/InputMenu.svelte": [
          "File: src/lib/components/chat/MessageInput/InputMenu.svelte -> src/lib/components/chat/MessageInput/InputMenu.svelte",
          "--- Hunk 1 ---",
          "[Context before]",
          "54:   }, {});",
          "55:  };",
          "57:  function handleFileChange(event) {",
          "58:   const inputFiles = Array.from(event.target?.files);",
          "59:   if (inputFiles && inputFiles.length > 0) {",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "57:  const detectMobile = () => {",
          "58:   const userAgent = navigator.userAgent || navigator.vendor || window.opera;",
          "59:   return /android|iphone|ipad|ipod|windows phone/i.test(userAgent);",
          "60:  };",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "148:       : ''}\"",
          "149:      on:click={() => {",
          "150:       if (fileUploadEnabled) {",
          "152:         screenCaptureHandler();",
          "153:        } else {",
          "154:         const cameraInputElement = document.getElementById('camera-input');",
          "",
          "[Removed Lines]",
          "151:        if (!$mobile) {",
          "",
          "[Added Lines]",
          "156:        if (!detectMobile()) {",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "5ce6c8ced30379d6a3fc9f412bd38b888b053ed2",
      "candidate_info": {
        "commit_hash": "5ce6c8ced30379d6a3fc9f412bd38b888b053ed2",
        "repo": "open-webui/open-webui",
        "commit_url": "https://github.com/open-webui/open-webui/commit/5ce6c8ced30379d6a3fc9f412bd38b888b053ed2",
        "files": [
          "src/lib/components/chat/MessageInput/Commands/Prompts.svelte"
        ],
        "message": "refac",
        "before_after_code_files": [
          "src/lib/components/chat/MessageInput/Commands/Prompts.svelte||src/lib/components/chat/MessageInput/Commands/Prompts.svelte"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_message": 1,
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "src/lib/components/chat/MessageInput/Commands/Prompts.svelte||src/lib/components/chat/MessageInput/Commands/Prompts.svelte": [
          "File: src/lib/components/chat/MessageInput/Commands/Prompts.svelte -> src/lib/components/chat/MessageInput/Commands/Prompts.svelte",
          "--- Hunk 1 ---",
          "[Context before]",
          "126:   const lastLineWords = lastLine.split(' ');",
          "127:   const lastWord = lastLineWords.pop();",
          "132:   prompt = lines.join('\\n');",
          "",
          "[Removed Lines]",
          "129:   lastLineWords.push(text);",
          "130:   lines.push(lastLineWords.join(' '));",
          "",
          "[Added Lines]",
          "129:   if ($settings?.richTextInput ?? true) {",
          "130:    lastLineWords.push(`${text.replace(/</g, '&lt;').replace(/>/g, '&gt;')}`);",
          "131:    lines.push(lastLineWords.join(' '));",
          "132:   } else {",
          "133:    lastLineWords.push(text);",
          "134:    lines.push(lastLineWords.join(' '));",
          "135:   }",
          "",
          "---------------"
        ]
      }
    },
    {
      "candidate_hash": "e31f680788910b04a1709271979c1b416f1b839a",
      "candidate_info": {
        "commit_hash": "e31f680788910b04a1709271979c1b416f1b839a",
        "repo": "open-webui/open-webui",
        "commit_url": "https://github.com/open-webui/open-webui/commit/e31f680788910b04a1709271979c1b416f1b839a",
        "files": [
          "backend/open_webui/routers/tasks.py"
        ],
        "message": "refac",
        "before_after_code_files": [
          "backend/open_webui/routers/tasks.py||backend/open_webui/routers/tasks.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 1,
        "same_branch_message": 1,
        "olp_code_files": {
          "patch": [],
          "candidate": []
        }
      },
      "candidate_diff": {
        "backend/open_webui/routers/tasks.py||backend/open_webui/routers/tasks.py": [
          "File: backend/open_webui/routers/tasks.py -> backend/open_webui/routers/tasks.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "20: from open_webui.constants import TASKS",
          "22: from open_webui.routers.pipelines import process_pipeline_inlet_filter",
          "23: from open_webui.utils.task import get_task_model_id",
          "25: from open_webui.config import (",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "23: from open_webui.utils.filter import (",
          "24:     get_sorted_filter_ids,",
          "25:     process_filter_functions,",
          "26: )",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "221:         },",
          "222:     }",
          "224:     try:",
          "225:         return await generate_chat_completion(request, form_data=payload, user=user)",
          "226:     except Exception as e:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "228:     # Process the payload through the pipeline",
          "229:     try:",
          "230:         payload = await process_pipeline_inlet_filter(request, payload, user, models)",
          "231:     except Exception as e:",
          "232:         raise e",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "290:         },",
          "291:     }",
          "293:     try:",
          "294:         return await generate_chat_completion(request, form_data=payload, user=user)",
          "295:     except Exception as e:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "303:     # Process the payload through the pipeline",
          "304:     try:",
          "305:         payload = await process_pipeline_inlet_filter(request, payload, user, models)",
          "306:     except Exception as e:",
          "307:         raise e",
          "",
          "---------------",
          "--- Hunk 4 ---",
          "[Context before]",
          "356:         },",
          "357:     }",
          "359:     try:",
          "360:         return await generate_chat_completion(request, form_data=payload, user=user)",
          "361:     except Exception as e:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "375:     # Process the payload through the pipeline",
          "376:     try:",
          "377:         payload = await process_pipeline_inlet_filter(request, payload, user, models)",
          "378:     except Exception as e:",
          "379:         raise e",
          "",
          "---------------",
          "--- Hunk 5 ---",
          "[Context before]",
          "433:         },",
          "434:     }",
          "436:     try:",
          "437:         return await generate_chat_completion(request, form_data=payload, user=user)",
          "438:     except Exception as e:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "458:     # Process the payload through the pipeline",
          "459:     try:",
          "460:         payload = await process_pipeline_inlet_filter(request, payload, user, models)",
          "461:     except Exception as e:",
          "462:         raise e",
          "",
          "---------------",
          "--- Hunk 6 ---",
          "[Context before]",
          "514:         },",
          "515:     }",
          "517:     try:",
          "518:         return await generate_chat_completion(request, form_data=payload, user=user)",
          "519:     except Exception as e:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "545:     # Process the payload through the pipeline",
          "546:     try:",
          "547:         payload = await process_pipeline_inlet_filter(request, payload, user, models)",
          "548:     except Exception as e:",
          "549:         raise e",
          "",
          "---------------",
          "--- Hunk 7 ---",
          "[Context before]",
          "584:         },",
          "585:     }",
          "587:     try:",
          "588:         return await generate_chat_completion(request, form_data=payload, user=user)",
          "589:     except Exception as e:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "621:     # Process the payload through the pipeline",
          "622:     try:",
          "623:         payload = await process_pipeline_inlet_filter(request, payload, user, models)",
          "624:     except Exception as e:",
          "625:         raise e",
          "",
          "---------------",
          "--- Hunk 8 ---",
          "[Context before]",
          "644:         },",
          "645:     }",
          "647:     try:",
          "648:         return await generate_chat_completion(request, form_data=payload, user=user)",
          "649:     except Exception as e:",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "687:     # Process the payload through the pipeline",
          "688:     try:",
          "689:         payload = await process_pipeline_inlet_filter(request, payload, user, models)",
          "690:     except Exception as e:",
          "691:         raise e",
          "",
          "---------------"
        ]
      }
    }
  ]
}