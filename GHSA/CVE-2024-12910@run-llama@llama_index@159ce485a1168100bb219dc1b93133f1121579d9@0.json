{
  "cve_id": "CVE-2024-12910",
  "cve_desc": "A vulnerability in the `KnowledgeBaseWebReader` class of the run-llama/llama_index repository, version latest, allows an attacker to cause a Denial of Service (DoS) by controlling a URL variable to contain the root URL. This leads to infinite recursive calls to the `get_article_urls` method, exhausting system resources and potentially crashing the application.",
  "repo": "run-llama/llama_index",
  "patch_hash": "159ce485a1168100bb219dc1b93133f1121579d9",
  "patch_info": {
    "commit_hash": "159ce485a1168100bb219dc1b93133f1121579d9",
    "repo": "run-llama/llama_index",
    "commit_url": "https://github.com/run-llama/llama_index/commit/159ce485a1168100bb219dc1b93133f1121579d9",
    "files": [
      "llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/knowledge_base/base.py",
      "llama-index-integrations/readers/llama-index-readers-web/pyproject.toml"
    ],
    "message": "fix: prevent infinite recursion in get_article_urls (#17360)\n\n* fix: prevent infinite recursion in get_article_urls\n\n* bump version",
    "before_after_code_files": [
      "llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/knowledge_base/base.py||llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/knowledge_base/base.py"
    ]
  },
  "patch_diff": {
    "llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/knowledge_base/base.py||llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/knowledge_base/base.py": [
      "File: llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/knowledge_base/base.py -> llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/knowledge_base/base.py",
      "--- Hunk 1 ---",
      "[Context before]",
      "7: class KnowledgeBaseWebReader(BaseReader):",
      "10:     Crawls and reads articles from a knowledge base/help center with Playwright.",
      "11:     Tested on Zendesk and Intercom CMS, may work on others.",
      "",
      "[Removed Lines]",
      "8:     \"\"\"Knowledge base reader.",
      "",
      "[Added Lines]",
      "8:     \"\"\"",
      "9:     Knowledge base reader.",
      "",
      "---------------",
      "--- Hunk 2 ---",
      "[Context before]",
      "36:         title_selector: Optional[str] = None,",
      "37:         subtitle_selector: Optional[str] = None,",
      "38:         body_selector: Optional[str] = None,",
      "39:     ) -> None:",
      "40:         \"\"\"Initialize with parameters.\"\"\"",
      "41:         self.root_url = root_url",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "40:         max_depth: int = 100,",
      "",
      "---------------",
      "--- Hunk 3 ---",
      "[Context before]",
      "44:         self.title_selector = title_selector",
      "45:         self.subtitle_selector = subtitle_selector",
      "46:         self.body_selector = body_selector",
      "48:     def load_data(self) -> List[Document]:",
      "49:         \"\"\"Load data from the knowledge base.\"\"\"",
      "",
      "[Removed Lines]",
      "[None]",
      "",
      "[Added Lines]",
      "49:         self.max_depth = max_depth",
      "",
      "---------------",
      "--- Hunk 4 ---",
      "[Context before]",
      "55:             # Crawl",
      "56:             article_urls = self.get_article_urls(",
      "60:             )",
      "62:             # Scrape",
      "",
      "[Removed Lines]",
      "57:                 browser,",
      "58:                 self.root_url,",
      "59:                 self.root_url,",
      "",
      "[Added Lines]",
      "60:                 browser, self.root_url, self.root_url, self.max_depth",
      "",
      "---------------",
      "--- Hunk 5 ---",
      "[Context before]",
      "82:         browser: Any,",
      "83:         url: str,",
      "84:     ) -> Dict[str, str]:",
      "87:         Args:",
      "88:             browser (Any): a Playwright Chromium browser.",
      "",
      "[Removed Lines]",
      "85:         \"\"\"Scrape a single article url.",
      "",
      "[Added Lines]",
      "86:         \"\"\"",
      "87:         Scrape a single article url.",
      "",
      "---------------",
      "--- Hunk 6 ---",
      "[Context before]",
      "125:         return {\"title\": title, \"subtitle\": subtitle, \"body\": body, \"url\": url}",
      "127:     def get_article_urls(",
      "129:     ) -> List[str]:",
      "132:         Args:",
      "133:             browser (Any): a Playwright Chromium browser.",
      "",
      "[Removed Lines]",
      "128:         self, browser: Any, root_url: str, current_url: str",
      "130:         \"\"\"Recursively crawl through the knowledge base to find a list of articles.",
      "",
      "[Added Lines]",
      "130:         self, browser: Any, root_url: str, current_url: str, max_depth: int = 100",
      "132:         \"\"\"",
      "133:         Recursively crawl through the knowledge base to find a list of articles.",
      "",
      "---------------",
      "--- Hunk 7 ---",
      "[Context before]",
      "159:         for link in links:",
      "160:             url = root_url + page.evaluate(\"(node) => node.getAttribute('href')\", link)",
      "163:         page.close()",
      "",
      "[Removed Lines]",
      "161:             article_urls.extend(self.get_article_urls(browser, root_url, url))",
      "",
      "[Added Lines]",
      "164:             article_urls.extend(",
      "165:                 self.get_article_urls(browser, root_url, url, max_depth)",
      "166:             )",
      "",
      "---------------"
    ]
  },
  "candidates": [
    {
      "candidate_hash": "3c65db2947271de3bd1927dc66a044da385de4da",
      "candidate_info": {
        "commit_hash": "3c65db2947271de3bd1927dc66a044da385de4da",
        "repo": "run-llama/llama_index",
        "commit_url": "https://github.com/run-llama/llama_index/commit/3c65db2947271de3bd1927dc66a044da385de4da",
        "files": [
          "llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/knowledge_base/base.py",
          "llama-index-integrations/readers/llama-index-readers-web/pyproject.toml"
        ],
        "message": "fix: respect max_depth in KnowledgeBaseWebReader (#17949)",
        "before_after_code_files": [
          "llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/knowledge_base/base.py||llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/knowledge_base/base.py"
        ]
      },
      "candidate_patch_features": {
        "candidate_earlier_than_patch": 0,
        "same_branch_evolution": 1,
        "olp_code_files": {
          "patch": [
            "llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/knowledge_base/base.py||llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/knowledge_base/base.py"
          ],
          "candidate": [
            "llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/knowledge_base/base.py||llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/knowledge_base/base.py"
          ]
        }
      },
      "candidate_diff": {
        "llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/knowledge_base/base.py||llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/knowledge_base/base.py": [
          "File: llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/knowledge_base/base.py -> llama-index-integrations/readers/llama-index-readers-web/llama_index/readers/web/knowledge_base/base.py",
          "--- Hunk 1 ---",
          "[Context before]",
          "127:         return {\"title\": title, \"subtitle\": subtitle, \"body\": body, \"url\": url}",
          "129:     def get_article_urls(",
          "131:     ) -> List[str]:",
          "132:         \"\"\"",
          "133:         Recursively crawl through the knowledge base to find a list of articles.",
          "",
          "[Removed Lines]",
          "130:         self, browser: Any, root_url: str, current_url: str, max_depth: int = 100",
          "",
          "[Added Lines]",
          "130:         self,",
          "131:         browser: Any,",
          "132:         root_url: str,",
          "133:         current_url: str,",
          "134:         max_depth: int = 100,",
          "135:         depth: int = 0,",
          "",
          "---------------",
          "--- Hunk 2 ---",
          "[Context before]",
          "136:             browser (Any): a Playwright Chromium browser.",
          "137:             root_url (str): root URL of the knowledge base.",
          "138:             current_url (str): current URL that is being crawled.",
          "140:         Returns:",
          "141:             List[str]: a list of URLs of found articles.",
          "143:         \"\"\"",
          "144:         page = browser.new_page(ignore_https_errors=True)",
          "145:         page.set_default_timeout(60000)",
          "146:         page.goto(current_url, wait_until=\"domcontentloaded\")",
          "",
          "[Removed Lines]",
          "[None]",
          "",
          "[Added Lines]",
          "144:             max_depth (int): maximum recursion level for the crawler",
          "145:             depth (int): current depth level",
          "151:         if depth >= max_depth:",
          "152:             print(f\"Reached max depth ({max_depth}): {current_url}\")",
          "153:             return []",
          "",
          "---------------",
          "--- Hunk 3 ---",
          "[Context before]",
          "162:         for link in links:",
          "163:             url = root_url + page.evaluate(\"(node) => node.getAttribute('href')\", link)",
          "164:             article_urls.extend(",
          "166:             )",
          "168:         page.close()",
          "",
          "[Removed Lines]",
          "165:                 self.get_article_urls(browser, root_url, url, max_depth)",
          "",
          "[Added Lines]",
          "176:                 self.get_article_urls(browser, root_url, url, max_depth, depth + 1)",
          "",
          "---------------"
        ]
      }
    }
  ]
}